<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
							<email>plewis@fb.com</email>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<orgName type="institution" key="instit1">‡ University College London</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ethan</forename><surname>Perez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<orgName type="institution" key="instit1">‡ University College London</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<orgName type="institution" key="instit1">‡ University College London</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<orgName type="institution" key="instit1">‡ University College London</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<orgName type="institution" key="instit1">‡ University College London</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<orgName type="institution" key="instit1">‡ University College London</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Heinrich</forename><surname>Küttler</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<orgName type="institution" key="instit1">‡ University College London</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<orgName type="institution" key="instit1">‡ University College London</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<orgName type="institution" key="instit1">‡ University College London</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<orgName type="institution" key="instit1">‡ University College London</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<orgName type="institution" key="instit1">‡ University College London</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<orgName type="institution" key="instit1">‡ University College London</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit nonparametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Pre-trained neural language models have been shown to learn a substantial amount of in-depth knowledge from data <ref type="bibr" target="#b40">[41]</ref>. They can do so without any access to an external memory, as a parameterized implicit knowledge base <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46]</ref>. While this development is exciting, such models do have downsides: They cannot easily expand or revise their memory, can't straightforwardly provide insight into their predictions, and may produce "hallucinations" <ref type="bibr" target="#b33">[34]</ref>. Hybrid models that combine parametric memory with non-parametric (i.e., retrieval-based) memories <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b41">42]</ref> can address some of these issues because knowledge can be directly revised and expanded, and its access can be inspected and interpreted. REALM <ref type="bibr" target="#b17">[18]</ref> and ORQA <ref type="bibr" target="#b26">[27]</ref>, two recently introduced models that combine masked language models <ref type="bibr" target="#b7">[8]</ref> with a differentiable retriever, have shown promising results, Preprint. Under review.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2005.11401v1 [cs.CL] 22 May 2020</head><p>The Divine Comedy (x) q Query Encoder q(x)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIPS p θ</head><p>Generator p θ (Parametric)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Marginalize</head><p>This 14th century work is divided into 3 sections: "Inferno", "Purgatorio" &amp; "Paradiso" (y)</p><p>End-to-End Backprop through q and p θ Barack Obama was born in Hawaii.(x)</p><p>Fact Verification: Fact Query supports (y)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question Generation</head><p>Fact Verification: Label Generation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document Index</head><p>Define "middle ear"(x)</p><p>Question Answering: Question Query</p><p>The middle ear includes the tympanic cavity and the three ossicles. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>d(z)</head><p>Jeopardy Question Generation: Answer Query</p><p>Figure <ref type="figure">1</ref>: An overview of retrieval-augmented generation (RAG). We combine a pre-trained retriever (Query Encoder + Document Index) with a pre-trained encoder-decoder (Generator) and fine-tune end-to-end. For some query x, we use Maximum Inner Product Search (MIPS) to find the top-K most relevant documents of all documents z i . To make the final prediction y, we treat z as a latent variable and marginalize over the encoder-decoder predictions given different documents.</p><p>but have only explored open-domain extractive question answering. Here, we bring hybrid parametric and non-parametric memory to the "workhorse of NLP," i.e. sequence-to-sequence (seq2seq) models.</p><p>We endow pre-trained, parametric-memory generation models with a non-parametric memory through a general-purpose fine-tuning approach which we refer to as retrieval-augmented generation (RAG). We build RAG models where the parametric memory is a pre-trained generative seq2seq transformer, and the non-parametric memory is a dense vector index of Wikipedia, accessed using a pre-trained neural retriever. We combine these components in an end-to-end probabilistic model; the document retriever (Dense Passage Retriever <ref type="bibr" target="#b21">[22]</ref>, henceforth DPR) provides latent documents conditioned on the input, and the seq2seq model (BART <ref type="bibr" target="#b27">[28]</ref>) then conditions on both these latent documents and the input to generate the output. We marginalize the latent variables through a top-K approximation, either on a per answer basis (assuming the same document is responsible for all tokens) or a per answer token basis (assuming different documents can be responsible for different tokens). Just like T5 <ref type="bibr" target="#b44">[45]</ref> or BART, RAG can be fine-tuned on any seq2seq task, whereby both the sequence generator and retriever are jointly learned.</p><p>There has been extensive previous work proposing architectures to enrich systems with non-parametric memory which are trained from scratch for specific tasks-e.g. in memory networks <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b48">49]</ref>, stackaugmented networks <ref type="bibr" target="#b20">[21]</ref> and memory layers for transformers <ref type="bibr" target="#b25">[26]</ref>. In contrast, we explore a setting where both parametric and non-parametric memory components are pre-trained and pre-loaded with extensive knowledge. Crucially, by using pre-trained knowledge-access mechanisms, the ability to access knowledge is present without additional training.</p><p>Our results highlight the benefits of combining parametric and non-parametric memory with generation for knowledge-intensive tasks. Our RAG models achieve state-of-the-art results on open Natural Questions <ref type="bibr" target="#b24">[25]</ref>, WebQuestions <ref type="bibr" target="#b2">[3]</ref> and CuratedTrec <ref type="bibr" target="#b1">[2]</ref> and strongly outperform recent approaches that use specialised pre-training objectives on TriviaQA <ref type="bibr" target="#b19">[20]</ref>. Despite these being extractive tasks, we find that unconstrained generation outperforms previous extractive approaches.</p><p>For knowledge-intensive generation, we experiment with MS-MARCO <ref type="bibr" target="#b0">[1]</ref> and Jeopardy question generation, and we find that our models generate responses that are more factual, specific, and diverse than a BART baseline. For the FEVER <ref type="bibr" target="#b49">[50]</ref> fact verification task, we achieve results within 4% of sophisticated, state-of-the-art pipeline models which use strong supervision. Finally, we show that the non-parametric memory can be replaced in order to control generation, demonstrating a simple mechanism to update the knowledge that the model uses as facts about the world change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>We explore RAG models which use the input sequence x to retrieve text passages z and use these passages as additional context when generating the target sequence y. As shown in Figure <ref type="figure">1</ref>, our models leverage two components: (i) a retriever p η (z|x) with parameters η that returns (top-K truncated) distributions over text passages given a query x and (ii) a generator p θ (y i |x, z, y</p><formula xml:id="formula_0">1:i−1 )</formula><p>parametrized by θ that generates a current token based on a context of the previous i − 1 tokens y 1:i−1 , the original input x and a retrieved passage z.</p><p>To train the retriever and generator end-to-end, we treat the retrieved document as a latent variable.</p><p>We propose two models that marginalize over the latent documents in different ways to produce a distribution over generated text. In one approach, RAG-Sequence, the model uses the same document to predict each target token. In the other approach, RAG-Token, the model can predict each target token based on a different document. In what follows, we formally introduce both models and then describe the p η and p θ components, as well as the training and decoding procedure in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RAG-Sequence Model</head><p>The RAG-Sequence model uses the same retrieved document to generate the complete sequence. Technically, it treats the retrieved passage as a single latent variable that is marginalized to get the seq2seq probability p(y|x) via a top-K approximation,</p><formula xml:id="formula_1">p RAG-Sequence (y|x) = z∈top-k(p(•|x)) p η (z|x) N i p θ (y i |x, z, y 1:i−1 )</formula><p>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RAG-Token Model</head><p>In the RAG-Token model we can draw a different latent passage for each target token and marginalize accordingly. This allows the generator to choose content from several documents when producing an answer. Formally, we define:</p><formula xml:id="formula_2">p RAG-Token (y|x) = N i z∈top-k(p(•|x)) p η (z i |x)p θ (y i |x, z i , y 1:i−1 ).</formula><p>Finally, we note that RAG can be used for sequence classification tasks by considering the target class as a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Retriever: DPR</head><p>The retrieval component p η (z|x) is based on DPR <ref type="bibr" target="#b21">[22]</ref>. DPR follows a bi-encoder architecture:</p><formula xml:id="formula_3">p η (z|x) ∝ exp d(z), q(x)</formula><p>where d(z) is a dense representation of the document produced by a BERT BASE transformer <ref type="bibr" target="#b7">[8]</ref>, and q(x) a representation of the query by another BERT BASE transformer with a different set of parameters.</p><p>To efficiently calculate top-k(p η (•|x)), the list of k elements z with highest prior probability p η (z|x), DPR employs a Maximum Inner Product Search (MIPS) index provided by the FAISS library <ref type="bibr" target="#b18">[19]</ref>.</p><p>For non-parametric pre-trained memory, we use a pre-trained bi-encoder from <ref type="bibr" target="#b21">[22]</ref> to both initialize our retriever and to build the document index. This retriever was trained to retrieve documents which contain answers to TriviaQA <ref type="bibr" target="#b19">[20]</ref> questions and Natural Questions <ref type="bibr" target="#b24">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Generator: BART</head><p>The generator component p θ (y i |x, z, y 1:i−1 ) could be modelled using any encoder-decoder. We use BART-large <ref type="bibr" target="#b27">[28]</ref>, a pre-trained seq2seq transformer <ref type="bibr" target="#b51">[52]</ref> with 400M parameters. To combine the input x with the retrieved content z when generating from BART, we simply concatenate them.</p><p>BART was pre-trained using a denoising objective and a variety of different noising functions. It has obtained state-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5 models <ref type="bibr" target="#b27">[28]</ref>. We refer to the BART generator parameters θ as the parametric memory henceforth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Training</head><p>We jointly train the retriever and generator components without any direct supervision on what document should be retrieved. Given a fine-tuning training corpus of input/output pairs (x j , y j ), we minimize the negative marginal log-likelihood of each target, j − log p(y j |x j ) using stochastic gradient descent with Adam <ref type="bibr" target="#b23">[24]</ref>. Updating the document encoder during training is costly as it requires the document index to be periodically updated as REALM does during pre-training <ref type="bibr" target="#b17">[18]</ref>. We do not find this step necessary for strong performance, and we keep the document encoder (and index) fixed, only fine-tuning the query encoder and the generator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Decoding</head><p>At test/decoding time, RAG-Sequence and RAG-Token require different ways to approximate arg max y p(y|x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RAG-Token</head><p>The RAG-Token model can be seen as a standard, autoregressive, seq2seq generator with transition probability:</p><formula xml:id="formula_4">p θ (y i |x, y 1:i−1 ) = z∈top-k(p(•|x)) p η (z i |x)p θ (y i |x, z i , y 1:i−1 )</formula><p>To decode, we can plug p θ (y i |x, y 1:i−1 ) into a standard beam decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RAG-Sequence</head><p>The likelihood p(y|x) does not break into a conventional per-token likelihood for the RAG-Sequence, and hence we cannot solve it with a single beam search pass. Instead, we run beam search for each candidate document z, scoring each hypothesis using p θ (y i |x, z, y 1:i−1 ). This yields a set of hypotheses Y of which some might not have appeared in the beams of all documents.</p><p>To estimate the probability of an hypothesis y across all beams, we run an additional forward pass for each document z for which y does not appear in the beam, multiply the generator score with p η (z|x) and then sum up the probabilities across beams for the marginals. We refer to this decoding procedure as "Thorough Decoding."</p><p>For longer output sequences, |Y | can become large, requiring many forward passes. For more efficient decoding, we can make a further approximation that p θ (y|x, z i ) ≈ 0 where y was not generated during beam search from x, z i . This avoids the need to run additional forward passes once the candidate set Y has been generated. We refer to this decoding procedure as "Fast Decoding".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We experiment with RAG in a wide range of knowledge-intensive tasks. For all experiments, we use a single Wikipedia dump for our non-parametric knowledge source. Following Lee et al. <ref type="bibr" target="#b26">[27]</ref> and Karpukhin et al. <ref type="bibr" target="#b21">[22]</ref>, we use the December 2018 dump. Each Wikipedia article is split into disjoint 100-word chunks, to make a total of 21,015,324 documents. <ref type="foot" target="#foot_0">1</ref> We use the DPR document encoder to compute document embeddings for each document, and we build a single MIPS index using FAISS <ref type="bibr" target="#b18">[19]</ref> using Hierarchical Navigable Small World approximation for efficient retrieval <ref type="bibr" target="#b32">[33]</ref>, which is then used for all experiments. During training, we retrieve the top k documents for each query, where we consider k ∈ {5, 10}. We determine k for test time using validation data. In the remainder of this section, we will discuss the experimental details for each of these task settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Open-domain Question Answering</head><p>Open-domain QA is an important real-world NLP application and is often used as test-bed for knowledge-intensive tasks <ref type="bibr" target="#b17">[18]</ref>. We tackle open-domain QA by treating questions and answers as simple input-output text pairs (x, y), and we train RAG by directly minimizing the negative loglikelihood of answers. We compare our results to the popular extractive QA paradigm <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b21">22]</ref>, where answers are extracted as spans from retrieved documents, relying primarily on non-parametric knowledge. In addition, we also compare to "Closed-Book QA" approaches <ref type="bibr" target="#b45">[46]</ref>, which, like RAG, generate answers, but do not exploit latent retrieval, instead relying purely on parametric knowledge.</p><p>We consider four popular open-domain QA datasets: Natural Questions (NQ) <ref type="bibr" target="#b24">[25]</ref>, TriviaQA (TQA) <ref type="bibr" target="#b19">[20]</ref>. WebQuestions (WQ) <ref type="bibr" target="#b2">[3]</ref> and CuratedTrec (CT) <ref type="bibr" target="#b1">[2]</ref>. The answers for CuratedTrec are given in the form of regular expressions, which has been cited as a reason why it is unsuitable for answer-generation models <ref type="bibr" target="#b17">[18]</ref>. To overcome this, we use a pre-processing step where we first retrieve the top 1000 documents for each query, and use the answer that most frequently matches the regex pattern as the supervision target. If no matches are found, we resort to a simple heuristic: generate all possible permutations for each regex, replacing non-deterministic symbols in the regex nested tree structure with a whitespace. As CuratedTrec and WebQuestions are small datasets, we follow DPR <ref type="bibr" target="#b21">[22]</ref> by initializing CuratedTrec and WebQuestions models with our Natural Questions RAG model.</p><p>We use the same training/dev/testing splitting method as in previous work <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b21">22]</ref> and report the standard Exact Match (EM) metric. For TriviaQA, in order to compare to T5 <ref type="bibr" target="#b45">[46]</ref>, we do an additional test evaluation on the TriviaQA Wiki test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Abstractive Question Answering</head><p>Because RAG leverages an encoder-decoder model, it can go beyond extractive question-answering and answer questions with free-form, abstractive text generation. To test RAG's ability to generate natural language responses in a knowledge-intensive setting, we use the MS-MARCO Natural Language Generation task v2.1 <ref type="bibr" target="#b37">[38]</ref>. This task consists of natural language questions submitted to a search engine, ten snippets retrieved from a search engine for each question, and a full sentence natural language answer annotated from these retrieved passages.</p><p>As we are interested in models that can perform their own latent retrieval, we do not use the supplied passages, only the questions and answers, thus treating MS-MARCO as an open-domain abstractive question answering task. MS-MARCO does contain some questions that cannot be answered in a way that matches the reference answer without access to the context passages, such as "What is the weather in volcano, CA?" so we note that performance on Open-MSMARCO will be lower than models that do use these gold context passages.</p><p>We further note that there are questions in MS-MARCO that cannot be answered using a Wikipedia knowledge source alone. In these cases, RAG can rely on the parametric implicit knowledge in its BART parameters in order to generate commonsense responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Jeopardy Question Generation</head><p>In order to further evaluate RAG's generation abilities in a non-question answering setting, we propose to study Open-domain question generation. Rather than repurpose questions from standard open-domain QA tasks, which typically consist of short and simple questions, we instead propose to study the more demanding task of generating of Jeopardy questions. Jeopardy is an unusual format that consists of trying to guess an entity from a fact about that entity. For example, "The World Cup" is the answer to the jeopardy question "In 1986 Mexico scored as the first country to host this international sports competition twice." As Jeopardy "questions" are precise, factual statements, generating Jeopardy-style questions conditioned on the answer entity they refer to constitutes a challenging knowledge-intensive generation task.</p><p>We use the raw Jeopardy data and splits from SearchQA <ref type="bibr" target="#b9">[10]</ref>, consisting of 97,391 training, 13,713 development, and 26,848 test datapoints. As this is a new task, we also train a BART system to compare RAG to. Following <ref type="bibr" target="#b59">[60]</ref>, we evaluate generations using the SQuAD-tuned Q-BLEU-1 metric <ref type="bibr" target="#b36">[37]</ref>. Q-BLEU-1 is a variant of BLEU-1 which puts a higher weight on the matching entities, and has higher correlation with human judgment for question generation compared to standard word overlap metrics.</p><p>As automatic metrics can be unreliable, especially on such open-ended tasks, we also perform a human evaluation of generations. We run two evaluations, one to assess the factuality of generations, and one to assess specificity. We follow the recent best-practice of performing a pairwise comparative evaluation between two systems <ref type="bibr" target="#b29">[30]</ref>. Assessors are shown an answer entity and two generated questions about that entity, one from BART and one from RAG. They are then asked to pick one of four possible options-Sentence A is better, Sentence B is better, both are correct or neither is good.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Fact Verification</head><p>FEVER <ref type="bibr" target="#b49">[50]</ref> is a fact verification dataset that involves classifying whether a natural language claim is supported or refuted by Wikipedia, or whether there is not enough information to decide. The task requires retrieving evidence from Wikipedia relating to the claim and then reasoning about the retrieved evidence to classify whether the claim is true, false, or unverifiable from Wikipedia alone. FEVER is a retrieval problem coupled with an entailment reasoning task. It also provides a good test bed for exploring the RAG models' ability to handle classification rather than generation.</p><p>We map FEVER class labels (supports, refutes, or not enough info) to single output tokens and directly train with claim-class pairs. Crucially, unlike most other approaches to FEVER, we do not use supervision on retrieved evidence. We explore two different FEVER variants: the standard 3-way classification task (supports/refutes/not enough info) and the 2-way FEVER (supports/refutes) task studied in Thorne and Vlachos <ref type="bibr" target="#b50">[51]</ref>. In both cases we report label accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Implementation Details</head><p>For Open-domain QA we report test numbers using 15 retrieved documents for RAG-Token models.</p><p>For RAG-Sequence models, we report test results using 50 retrieved documents, and we use the Thorough Decoding approach since answers are generally short. We use greedy decoding for QA as we did not find beam search improved results. For Open-MSMarco and Jeopardy question generation, we report test numbers using ten retrieved documents for both RAG-Token and RAG-Sequence, and we also train a BART-large model as a baseline. We use a beam size of four, and use the Fast Decoding approach for RAG-Sequence models, as Thorough Decoding did not improve performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Open-domain Question Answering</head><p>Table <ref type="table" target="#tab_0">1</ref> shows results for RAG along with recent state-of-the-art models. On all four open-domain QA tasks, RAG sets a new state-of-the-art (in the case of TQA only on the T5-comparable split).</p><p>RAG combines the generation flexibility of the "closed-book" (parametric only) approaches and the performance of "open-book" retrieval-based approaches. Unlike REALM and T5+SSM, RAG enjoys strong results without expensive specialized "salient span masking" pre-training <ref type="bibr" target="#b17">[18]</ref>, relying on off-the-shelf components. It is worth noting that RAG's retriever is initialized using DPR's retriever,  which does use retrieval supervision on Natural Questions and TriviaQA. RAG compares favourably to DPR QA system on open-domain QA, which uses a BERT-based cross-encoder system to re-rank documents, along with an extractive reader. RAG demonstrates that neither a re-ranker nor extractive reader is necessary for state-of-the-art machine reading performance. Generating answers even when it is possible to extract them has a number of advantages. Documents which contain clues as to the correct answer but do not contain the correct answer verbatim themselves can still contribute probability mass towards a correct answer being generated, which is not possible with standard extractive approaches, leading to more effective marginalization across documents. Furthermore, RAG is able to generate correct answers even when the correct answer is not present in any of the retrieved documents, achieving an accuracy of 11.8% in such cases for Natural Questions, whereas an extractive model would score 0%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Abstractive Question Answering</head><p>As shown in Table <ref type="table" target="#tab_1">2</ref>, RAG-Sequence outperforms BART on Open MS-MARCO generation by 2.6 Bleu points and 2.6 Rouge-L points. It approaches the performance of state-of-the-art models, which is impressive considering that (i) these models have access to passages that contain the specific information required to generate the reference answer, (ii) many questions are unanswerable without access to gold passages, and (iii) other questions are unanswerable from Wikipedia alone. Table <ref type="table" target="#tab_5">4</ref> shows some generated answers from our models. Qualitatively, we find that RAG models hallucinate less and generate factually correct text more often than BART. Later we also show that RAG generations are more diverse than BART generations (see Section 4.6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Jeopardy Question Generation</head><p>Table <ref type="table" target="#tab_1">2</ref> shows automatic metric results on the Jeopardy question generation task. We find that RAG-Token performs better than the RAG-Sequence model in this setting, with both models outperforming BART using the Q-BLEU-1 metric.</p><p>Table <ref type="table" target="#tab_3">3</ref> shows the results from the human evaluation. The human evaluation was carried out with 452 pairs of generations from BART and RAG-Token. The annotators indicated that BART was more factual than RAG in only 7.1% of cases, while RAG was more factual in 42.7% of cases and both RAG and BART were factual in a further 17% of cases, clearly demonstrating the comparative effectiveness of RAG on the task over a state-of-the-art conditional generation model. The annotators also strongly prefer RAG generations in terms of specificity.</p><p>Typical example of generations from each model are shown in Table <ref type="table" target="#tab_5">4</ref>. BART generates a more generic response (which is incorrect), whereas the RAG models generate specific and correct facts about Washington state.</p><p>We hypothesise that RAG-Token performs best for this task as Jeopardy questions often contain two separate pieces of information about the entity, and RAG-Token is able to synthesize a response by combining disparate information from different retrieved documents in one generation. Figure <ref type="figure">2</ref> shows an example where content from two documents has been combined to produce the generated question. Document 2 contains information about Hemingway's "The Sun also rises," and the contribution for "Sun" is very high for document 2. Similarly, "A Farewell to Arms" is mentioned in Document 1, which dominates the posterior when this title is generated. Intriguingly, after the first token of these book titles are generated, the distribution over documents flattens again. This observation suggests that the generator completes the book titles without depending on specific documents. In other words, the model's parametric knowledge is sufficient to complete the titles.</p><p>We show evidence for the above interpretation by feeding the BART-only baseline with the partial decoding "The Sun. BART completes the generation "The Sun Also Rises" is a novel by this   author of "The Sun Also Rises" indicating the title "The Sun Also Rises" is stored in BART's parameters. Similarly, feeding the partial decoding "The Sun Also Rises" is a novel by this author of "A will result in BART completing the generation with "The Sun Also Rises" is a novel by this author of "A Farewell to Arms. This example shows how the parametric and nonparametric memories work together-the non-parametric component helps to guide the generation in a particular direction, drawing out specific knowledge stored in the parametric memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Fact Verification</head><p>Table <ref type="table" target="#tab_1">2</ref> shows our results on the FEVER 3-way and 2-way classification task. For 3-way classification, RAG achieves accuracies that are within 4.3% of state-of-the-art models, which are complex pipeline systems with domain-specific architectures and substantial engineering, trained using intermediate supervision, which RAG does not require.</p><p>For 2-way classification, we compare against the model from <ref type="bibr" target="#b50">[51]</ref>, which trains RoBERTa <ref type="bibr" target="#b30">[31]</ref> to classify the claim as true or false given the gold evidence sentence. RAG achieves an accuracy within 2.7% of this model, despite being supplied with only the claim and retrieving its own evidence.</p><p>We also analyze whether the documents retrieved by RAG correspond to the documents annotated as gold evidence in FEVER. We analyze the overlap in Wikipedia articles between the top k documents retrieved by RAG and the gold, annotated evidence documents. We find that the top article retrieved by RAG is a gold document for the claim in 71% of cases, and a gold article is present in the top 10 retrieved articles in 90% of cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Ablations</head><p>To gain a better understanding of what factors affect RAG's performance, we perform a number of ablation experiments for our tasks on their respective development sets.  Using more documents Models are trained with either 5 or 10 retrieved latent documents, and we do not observe significant differences in performance between them. We also have the flexibility to adjust the number of retrieved documents at test time, which does affect performance. Figure <ref type="figure">3</ref> (left) shows that retrieving more documents at test time monotonically improves Open-domain QA results for RAG-Sequence, but performance peaks for RAG-Token at 10 retrieved documents. Figure <ref type="figure">3</ref> (right) shows that retrieving more documents leads to higher Rouge-L for RAG-Token at the expense of Bleu-1, but the effect is less pronounced for RAG-Sequence.</p><p>Retrieval A key feature of RAG is the ability to learn to retrieve relevant information for the task at hand. To assess the effectiveness of the retrieval mechanism, we run ablations on RAG where we prevent gradients from propagating into the retriever. Table <ref type="table" target="#tab_6">5</ref> shows the results across all tasks. In each case, learned retrieval improves results, with the largest improvements in question answering. Figure <ref type="figure">3</ref> (center) shows that the learned retriever shows a higher recall for gold documents compared to the fixed retriever. The improvements on TriviaQA and Natural Questions are notable, as we initialize the retriever from DPR, which is trained with strong, document-level supervision to perform well on these tasks. We also compare RAG's dense embedding-based retrieval mechanism to a word overlap-based BM25 retriever <ref type="bibr" target="#b46">[47]</ref>. Here, we replace RAG's differentiable retriever with a fixed BM25 system. We use the BM25 retrieval scores as logits when calculating p η (z i |x). Table <ref type="table" target="#tab_6">5</ref> and Figure <ref type="figure">3</ref> show the results. For FEVER, we find that BM25 performs best, perhaps since FEVER claims are heavily entity-centric and thus well-suited for word overlap-based retrieval. On all other tasks, we find the differentiable retrieval to be helpful, especially question answering, where it is crucial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Generation Diversity</head><p>Section 4.3 established that RAG models generate are more factual and specific than BART for Jeopardy question generation. Similar to Li et al. <ref type="bibr" target="#b28">[29]</ref>, Vijayakumar et al. <ref type="bibr" target="#b52">[53]</ref> and Massarelli et al. <ref type="bibr" target="#b34">[35]</ref>, we also investigate the diversity of generations by calculating the ratio of distinct ngrams to total ngrams generated by different models.  diverse than RAG-Token generations, and both generate significantly more diverse outputs than BART without requiring any diversity-promoting decoding strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Hot-swapping indices</head><p>An advantage of non-parametric knowledge models such as RAG is that the knowledge base can be easily updated at test time. Parametric-only models such as T5 or BART require additional training to update their behavior as facts about the world change. As a demonstration, we build an index using the DrQA Wikipedia dump <ref type="bibr" target="#b4">[5]</ref>, (dated December 21st, 2016) and compare generations from RAG using this index to the newer index used in our main results (December 20th, 2018). We prepared a list of 82 heads of states who had changed between these dates and used a template "Who is {position}?" (e.g., "Who is the prime minister of the UK?") to query our Natural Questions -finetuned RAG model with each index. RAG achieved an accuracy of 70% using the 2016 index for 2016 world leaders and an accuracy of 68% using the 2018 index for the 2018 world leaders. Only 21% of the model's predictions were the same using the two indices, and accuracy using mismatched indices is very low (12% using the 2018 index for 2016 leaders and 4% using the 2016 index for 2018 leaders). Our result shows that we can effectively update RAG's behavior with new world knowledge by simply replacing its non-parametric memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Single-Task Retrieval Prior work has shown that retrieval improves performance across a variety of NLP tasks when considered in isolation. Such tasks include open-domain question answering <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b24">25]</ref>, fact checking <ref type="bibr" target="#b49">[50]</ref>, fact completion <ref type="bibr" target="#b41">[42]</ref>, long-form question answering <ref type="bibr" target="#b11">[12]</ref>, Wikipedia article generation <ref type="bibr" target="#b31">[32]</ref>, dialogue <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13]</ref>, translation <ref type="bibr" target="#b15">[16]</ref>, and language modeling <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b22">23]</ref>. Our work unifies previous successes in incorporating retrieval into individual tasks, showing that a single retrieval-based architecture is capable of achieving strong performance across several tasks.</p><p>General-Purpose Architectures for NLP Prior work on general-purpose architectures for NLP tasks has shown great success without the use of retrieval. A single, pre-trained language model has been shown to achieve strong performance on various classification tasks in the GLUE benchmarks <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b54">55]</ref> after fine-tuning <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b7">8]</ref>. GPT-2 <ref type="bibr" target="#b43">[44]</ref> later showed that a single, left-to-right, pre-trained language model could achieve strong performance across both discriminative and generative tasks. For further improvement, BART <ref type="bibr" target="#b27">[28]</ref> and T5 <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46]</ref> propose a single, pre-trained encoder-decoder model that leverages bi-directional attention to achieve stronger performance on discriminative and generative tasks. Our work aims to expand the space of possible tasks with a single, unified architecture, by learning a retrieval module to augment pre-trained, generative language models.</p><p>Learned Retrieval There is significant work on learning to retrieve documents in information retrieval, more recently with pre-trained, neural language models <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b21">22]</ref> similar to ours. Some work optimizes the retrieval module to aid in a specific, downstream task such as question answering, using search <ref type="bibr" target="#b39">[40]</ref>, reinforcement learning <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b55">56]</ref>, or a latent variable approach <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b17">18]</ref> as in our work. These successes leverage different retrieval-based architectures and optimization techniques to achieve strong performance on a single task, while we show that a single retrieval-based architecture can be fine-tuned for strong performance on a variety of tasks.</p><p>Memory-based Architectures Our document index can be seen as a large external memory for neural networks to attend to, analagous to memory networks <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b47">48]</ref>. Concurrent work <ref type="bibr" target="#b13">[14]</ref> learns to retrieve a trained embedding for each entity in the input, rather than to retrieve raw text as in our work. Other work improves the ability of dialog models to generate factual text by attending over fact embeddings <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b12">13]</ref> or, closer to our work, over retrieved text directly <ref type="bibr" target="#b14">[15]</ref>. A key feature of our memory is that it is comprised of raw text rather distributed representations, which makes the memory both (i) human-readable, lending a form of interpretability to our model, and (ii) human-writable, enabling us to dynamically update the model's memory by editing the document index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>In this work, we presented hybrid generation models with access to parametric and non-parametric retrieval-based external memory, in the form of Wikipedia. We showed that our RAG models obtain state-of-the-art performance on open domain question answering. We found that people prefer RAG's generation over purely parametric BART and find RAG more factual, and we conducted a detailed investigation of the learned retrieval component, validating its effectiveness. We also showed that the model's grounding in external data leads it to generate more diverse, and illustrated by how the retrieval index can be hot-swapped on the fly without having to retrain the model. In future work, it would be interesting to investigate if the two components can be jointly pre-trained from scratch, either on a denoising objective similar to BART, or through some other objective. Our work opens new research directions on how parametric and non-parametric memories interact and how to most effectively combine the different components, showing promise in being applied to a wide variety of NLP tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Human evaluation</head><p>Figure <ref type="figure" target="#fig_3">4</ref> shows the user interface for human evaluation. To avoid any biases for screen position, which model corresponded to sentence A and sentence B was randomly selected for each example. Annotators were encouraged to research the topic using the internet, and were given detailed instructions and worked examples in a full instructions tab. We included some gold sentences in order to assess the accuracy of the annotators. Two annotators did not perform well on these examples and their annotations were removed from the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Further details on Open-Domain QA</head><p>For open-domain QA, multiple answer annotations are often available for a given question. These answer annotations are exploited by extractive models during training as typically all the answer annotations are used to find matches within documents when preparing training data. For RAG, we also make use of multiple annotation examples for Natural Questions and WebQuestions by training the model with each (q, a) pair separately, leading to a small increase in accuracy. For TriviaQA, there are often many valid answers to a given question, some of which are not suitable training targets, such as emoji or spelling variants. For TriviaQA, we filter out answer candidates if they do not occur in top 1000 documents for the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TriviaQA Evaluation setups</head><p>The open-domain QA community customarily uses public development datasets as test datasets, as test data for QA datasets is often restricted and dedicated to reading compehension purposes. We report our results using the datasets splits used in DPR <ref type="bibr" target="#b21">[22]</ref>, which are consistent with common practice in Open-domain QA. For TriviaQA, this test dataset is the public TriviaQA Web Development split. Roberts et al. <ref type="bibr" target="#b45">[46]</ref> used the TriviaQA official Wikipedia test set instead. Févry et al. <ref type="bibr" target="#b13">[14]</ref> follow this convention in order to compare with Roberts et al. <ref type="bibr" target="#b45">[46]</ref> (See appendix of <ref type="bibr" target="#b13">[14]</ref>). We report results on both test sets to enable fair comparison to both approaches. We find that our performance is much higher using the official Wiki test set, rather than the more conventional open-domain test set, which we attribute to the official Wiki test set questions being simpler to answer from Wikipedia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Further details on FEVER</head><p>For FEVER classification, we follow the practice from <ref type="bibr" target="#b27">[28]</ref>, and first re-generate the claim, and then classify using the representation of the final hidden state, before finally marginalizing across documents to obtain the class probabilities. The FEVER task traditionally has two sub-tasks. The first is to classify the claim as either "Supported", "Refuted" or "Not Enough Info", which is the task we explore in the main paper. FEVER's other sub-task involves extracting sentences from Wikipedia as evidence supporting the classification prediction. As FEVER uses a different Wikipedia dump to us, directly tackling this task is not straightforward. We hope to address this in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D "Null document" Probabilities</head><p>We experimented with adding "Null document" mechanism to RAG, similar to REALM <ref type="bibr" target="#b17">[18]</ref> in order to model cases where no useful information could be retrieved for a given input. Here, if k documents were retrieved, we would additionally "retrieve" an empty document and predict a logit for the null document, before marginalizing over k + 1 predictions. We explored modelling this null document logit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or (iii) a neural network to predict the logit. We did not find that these improved performance, so in the interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents cannot always be retrieved, we observe that the model learns to always retrieve a particular set of documents for questions that are less likely to benefit from retrieval, suggesting that null document mechanisms may not be necessary for RAG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Parameters</head><p>Our RAG models contain the trainable parameters for the BERT-base query and document encoder of DPR, with 110M parameters each (although we do not train the document encoder ourselves) and 406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable parameters. The best performing "closed-book" (parametric only) open-domain QA model is T5-11B with 11 Billion trainable parameters. The T5 model with the closest number of parameters to our models is T5-large (770M parameters), which achieves a score of 28.9 EM on Natural Questions <ref type="bibr" target="#b45">[46]</ref>, substantially below the 44.5 that RAG-Sequence achieves, indicating that hybrid parametric/nonparametric models require far fewer trainable parameters for strong open-domain QA performance. The non-parametric memory index does not consist of trainable parameters, but does consists of 21M 728 dimensional vectors, consisting of 15.3B values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Retrieval Collapse</head><p>In preliminary experiments, we observed that for some tasks such as story generation <ref type="bibr" target="#b10">[11]</ref>, the retrieval component would "collapse" and learn to retrieve the same documents regardless of the input. In these cases, once retrieval had collapsed, the generator would learn to ignore the documents, and the RAG model would perform equivalently to BART. The collapse could be due to a less-explicit requirement for factual knowledge in some tasks, or the longer target sequences, which could result in less informative gradients for the retriever. Perez et al. <ref type="bibr" target="#b39">[40]</ref> also found spurious retrieval results when optimizing a retrieval component in order to improve performance on downstream tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Document 1 :Figure 2 :</head><label>12</label><figDesc>Figure2: RAG-Token document posterior p(z i |x, y i , y −i ) for each generated token for input "Hemingway" for Jeopardy generation with 5 retrieved documents. The posterior for document 1 is high when generating "A Farewell to Arms" and for document 2 when generating "The Sun Also Rises"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 Figure 3 :</head><label>13</label><figDesc>Figure 3: Left: NQ performance as more documents are retrieved. Center: Fraction of answers in NQ where the answer occurs somewhere in the top K documents. Right: MS-MARCO Bleu-1 and Rouge-L as more documents are retrieved.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Annotation interface for human evaluation of factuality. A pop-out for detailed instructions and a worked example appear when clicking "view tool guide".</figDesc><graphic url="image-2.png" coords="17,108.00,72.00,396.01,151.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Open-Domain QA Test Scores. For TQA, the left column uses the test split commonly used in Open-Domain QA. The right column uses the hidden TQA Wiki test split. See Appendix B for further information.</figDesc><table><row><cell></cell><cell>Model</cell><cell></cell><cell>NQ</cell><cell></cell><cell>TQA</cell><cell>WQ</cell><cell>CT</cell></row><row><cell>Closed-Book</cell><cell cols="4">T5-11B [46] T5-11B + SSM [46] 36.6 34.5</cell><cell cols="2">-/50.1 37.4 -/60.5 44.7</cell><cell>--</cell></row><row><cell>Open-Book</cell><cell cols="2">REALM [18] DPR [22]</cell><cell cols="3">40.4 41.5 57.9/ --/ -</cell><cell cols="2">40.7 46.8 41.1 50.6</cell></row><row><cell></cell><cell cols="2">RAG-Token</cell><cell cols="5">44.1 55.2/66.1 45.5 50.0</cell></row><row><cell></cell><cell cols="2">RAG-Sequence</cell><cell cols="5">44.5 56.1/68.0 45.2 52.2</cell></row><row><cell>Model</cell><cell cols="2">Jeopardy QGen</cell><cell cols="2">MS-MARCO</cell><cell cols="3">FEVER-3 FEVER-2</cell></row><row><cell></cell><cell>B-1</cell><cell>QB-1</cell><cell>R-L</cell><cell>B-1</cell><cell cols="3">Label Accuracy</cell></row><row><cell>SotA</cell><cell>-</cell><cell>-</cell><cell cols="2">49.8* 49.9*</cell><cell>76.8</cell><cell></cell><cell>92.2*</cell></row><row><cell>BART</cell><cell>15.1</cell><cell>19.7</cell><cell>38.2</cell><cell>41.6</cell><cell>64.0</cell><cell></cell><cell>81.1</cell></row><row><cell cols="2">RAG-Token RAG-Sequence 14.7 17.3</cell><cell>22.2 21.4</cell><cell>40.1 40.8</cell><cell>41.5 44.2</cell><cell>72.5</cell><cell></cell><cell>89.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Generation and classification task Test Scores. SotA for MS-MARCO is<ref type="bibr" target="#b3">[4]</ref>, FEVER-3 is<ref type="bibr" target="#b60">[61]</ref> and FEVER-2 is [51] * Uses gold context/evidence, best-performing model without gold access underlined. As FEVER is a classification dataset, RAG-Token and RAG-Sequence are equivalent.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Human assessments for the Jeopardy Question Generation Task.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Pound is the currency needed in Scotland. RAG-S The currency needed in Scotland is the pound sterling. This state has the largest number of counties in the U.S. RAG-T It's the only U.S. state named for a U.S. president RAG-S It's the state where you'll find Mount Rainier National Park</figDesc><table><row><cell>what currency</cell><cell>BART The currency needed in Scotland is Pound sterling.</cell></row><row><cell cols="2">needed in scotland RAG-T Jeopardy Question Gener -ation Washington BART ? The Divine BART</cell></row><row><cell>Comedy</cell><cell></cell></row></table><note>* This epic poem by Dante is divided into 3 parts: the Inferno, the Purgatorio &amp; the Purgatorio RAG-T Dante's "Inferno" is the first part of this epic poem RAG-S This 14th century work is divided into 3 sections: "Inferno", "Purgatorio" &amp; "Paradiso"</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>Example Generations for MS-MARCO and Jeopardy Question generation. RAG models generate mpre specific and factually accurate responses, whereas BART generate more factually incorrect (marked by '?'), or partially correct (marked by *) and more generic responses.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Ablations on the development set. As FEVER is a classification dataset, RAG-Token and RAG-Sequence are equivalent.</figDesc><table><row><cell>Model</cell><cell cols="2">NQ TQA WQ</cell><cell>CT</cell><cell cols="2">Jeopardy-QGen</cell><cell>MSMarco</cell><cell>FVR-3 FVR-2</cell></row><row><cell></cell><cell cols="2">Exact Match</cell><cell></cell><cell>B-1</cell><cell>QB-1</cell><cell>R-L</cell><cell>B-1</cell><cell>Label Accuracy</cell></row><row><cell>RAG-Token-BM25 RAG-Seq-BM25</cell><cell>29.7 41.5 31.8 44.1</cell><cell cols="4">32.1 33.1 17.5 22.3 36.6 33.8 11.1 19.5</cell><cell>55.5 48.4 56.5 46.9</cell><cell>75.1</cell><cell>91.6</cell></row><row><cell cols="2">RAG-Token-Frozen 37.8 50.1 RAG-Seq-Frozen 41.2 52.1</cell><cell cols="4">37.1 51.1 16.7 21.7 41.8 52.6 11.8 19.6</cell><cell>55.9 49.4 56.7 47.3</cell><cell>72.9</cell><cell>89.4</cell></row><row><cell>RAG-Token RAG-Seq</cell><cell>43.5 54.8 44.0 55.8</cell><cell cols="4">46.5 51.9 17.9 22.6 44.9 53.4 15.3 21.5</cell><cell>56.2 49.4 57.2 47.5</cell><cell>74.5</cell><cell>90.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Table 6 shows that RAG-Sequence generations are more</figDesc><table><row><cell>Dataset</cell><cell>Gold</cell><cell cols="3">BART RAG-Token RAG-Sequence</cell></row><row><cell>MSMARCO</cell><cell cols="2">89.6% 70.7%</cell><cell>77.8%</cell><cell>83.5%</cell></row><row><cell cols="3">Jeopardy Generation 90.0% 32.4%</cell><cell>46.8 %</cell><cell>53.8%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Ratio of distinct tri-grams to total tri-grams in the development set generations for MS-MARCO and Jeopardy Question Generation.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">The reader is referred to Karpukhin et al.<ref type="bibr" target="#b21">[22]</ref> for further details on how Wikipedia is pre-processed.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>EP thanks supports from the NSF Graduate Research Fellowship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Payal</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alina</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Marco</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09268</idno>
		<idno>arXiv: 1611.09268</idno>
		<ptr target="http://arxiv.org/abs/1611.09268" />
		<title level="m">A Human Generated MAchine Reading COmprehension Dataset</title>
				<imprint>
			<date type="published" when="2016-11">November 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Modeling of the question answering task in the yodaqa system</title>
		<author>
			<persName><forename type="first">Petr</forename><surname>Baudiš</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Šedivỳ</surname></persName>
		</author>
		<ptr target="https://link.springer.com/chapter/10.1007%2F978-3-319-24027-5_20" />
	</analytic>
	<monogr>
		<title level="m">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="222" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic Parsing on Freebase from Question-Answer Pairs</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D13-1160" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-10">October 2013</date>
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Palm: Pre-training an autoencod-ing&amp;autoregressive language model for context-conditioned generation</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<idno>ArXiv, abs/2004.07159</idno>
		<ptr target="https://arxiv.org/abs/2004.07159" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reading Wikipedia to Answer Open-Domain Questions</title>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1171</idno>
		<ptr target="https://www.aclweb.org/anthology/P17-1171" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-07">July 2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Coarse-to-fine question answering for long documents</title>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hewlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1020</idno>
		<ptr target="https://www.aclweb.org/anthology/P17-1020" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-07">July 2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="209" to="220" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Simple and Effective Multi-Paragraph Reading Comprehension</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10723</idno>
		<idno>arXiv: 1710.10723</idno>
		<ptr target="http://arxiv.org/abs/1710.10723" />
		<imprint>
			<date type="published" when="2017-10">October 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://www.aclweb.org/anthology/N19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">June 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Wizard of wikipedia: Knowledge-powered conversational agents</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=r1l73iRqKm" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">SearchQA: A New Q&amp;A Dataset Augmented with Context from a Search Engine</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Levent</forename><surname>Sagun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Ugur</forename><surname>Guney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Volkan</forename><surname>Cirik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.05179</idno>
		<idno>arXiv: 1704.05179</idno>
		<ptr target="http://arxiv.org/abs/1704.05179" />
		<imprint>
			<date type="published" when="2017-04">April 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hierarchical neural story generation</title>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1082</idno>
		<ptr target="https://www.aclweb.org/anthology/P18-1082" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07">July 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="889" to="898" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ELI5: Long form question answering</title>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1346</idno>
		<ptr target="https://www.aclweb.org/anthology/P19-1346" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page" from="3558" to="3567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Augmenting transformers with KNN-based composite memory</title>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chloe</forename><surname>Braud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=H1gx1CNKPH" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Entities as experts: Sparse memory access with entity supervision</title>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Févry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baldini</forename><surname>Livio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><surname>Kwiatkowski</surname></persName>
		</author>
		<idno>ArXiv, abs/2004.07202</idno>
		<ptr target="https://arxiv.org/abs/2004.07202" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A knowledge-grounded neural conversation model</title>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Tau Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<ptr target="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16710" />
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Search engine guided neural machine translation</title>
		<author>
			<persName><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">K</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<ptr target="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17282" />
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generating sentences by editing prototypes</title>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tatsunori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Oren</surname></persName>
		</author>
		<author>
			<persName><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00030</idno>
		<ptr target="https://www.aclweb.org/anthology/Q18-1031" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="437" to="450" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">REALM: Retrieval-augmented language model pre-training</title>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zora</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<idno>ArXiv, abs/2002.08909</idno>
		<ptr target="https://arxiv.org/abs/2002.08909" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Billion-scale similarity search with gpus</title>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hervé</forename><surname>Jégou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08734</idno>
		<ptr target="https://arxiv.org/abs/1702.08734" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension</title>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1147</idno>
		<ptr target="https://www.aclweb.org/anthology/P17-1147" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-07">July 2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Inferring algorithmic patterns with stackaugmented recurrent nets</title>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<ptr target="https://papers.nips.cc/paper/5857-inferring-algorithmic-patterns-with-stack-augmented-recurrent-nets" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Neural Information Processing Systems</title>
				<meeting>the 28th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="190" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.04906</idno>
		<ptr target="https://arxiv.org/abs/2004.04906" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generalization through memorization: Nearest neighbor language models</title>
		<author>
			<persName><forename type="first">Urvashi</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HklBjCEKvH" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6980" />
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations, ICLR 2015</title>
				<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">May 7-9, 2015. 2015</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Natural Questions: a Benchmark for Question Answering Research</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><forename type="middle">N</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<ptr target="https://tomkwiat.users.x20web.corp.google.com/papers/natural-questions/main-1455-kwiatkowski.pdf" />
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association of Computational Linguistics</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Large memory layers with product keys</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><forename type="middle">'</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludovic</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herve</forename><surname>Jegou</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/9061-large-memory-layers-with-product-keys.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alché-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8548" to="8559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Latent retrieval for weakly supervised open domain question answering</title>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1612</idno>
		<ptr target="https://www.aclweb.org/anthology/P19-1612" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page" from="6086" to="6096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdelrahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.13461</idno>
		<ptr target="https://arxiv.org/abs/1910.13461" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1014</idno>
		<ptr target="https://www.aclweb.org/anthology/N16-1014" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06">June 2016</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons</title>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<idno>ArXiv, abs/1909.03087</idno>
		<ptr target="https://arxiv.org/abs/1909.03087" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Robust neural machine translation with joint textual and phonetic embedding</title>
		<author>
			<persName><forename type="first">Hairong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingbo</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1291</idno>
		<ptr target="https://www.aclweb.org/anthology/P19-1291" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page" from="3044" to="3049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Generating wikipedia by summarizing long sequences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">*</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Etienne</forename><surname>Pot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Hyg0vbWC-" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Malkov</surname></persName>
		</author>
		<author>
			<persName><surname>Yashunin</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1603.09320" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="824" to="836" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Gary</forename><surname>Marcus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.06177</idno>
		<ptr target="https://arxiv.org/abs/2002.06177" />
		<title level="m">The next decade in ai: four steps towards robust artificial intelligence</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">How decoding strategies affect the verifiability of generated text</title>
		<author>
			<persName><forename type="first">Luca</forename><surname>Massarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vassilis</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabrizio</forename><surname>Silvestri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03587</idno>
		<ptr target="https://arxiv.org/abs/1911.03587" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Towards exploiting background knowledge for building conversation systems</title>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Moghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhartha</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suman</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitesh</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1255</idno>
		<ptr target="https://www.aclweb.org/anthology/D18-1255" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11">October-November 2018</date>
			<biblScope unit="page" from="2322" to="2332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Towards a better metric for evaluating question generation systems</title>
		<author>
			<persName><forename type="first">Preksha</forename><surname>Nema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitesh</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1429</idno>
		<ptr target="https://www.aclweb.org/anthology/D18-1429" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11">October-November 2018</date>
			<biblScope unit="page" from="3950" to="3959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A human generated machine reading comprehension dataset</title>
		<author>
			<persName><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><surname>Marco</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1773/CoCoNIPS_2016_paper9.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016)</title>
				<editor>
			<persName><forename type="first">Richard</forename><surname>Tarek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Antoine</forename><surname>Besold</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Artur</forename><forename type="middle">S</forename><surname>Bordes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Greg</forename><surname>Avila Garcez</surname></persName>
		</editor>
		<editor>
			<persName><surname>Wayne</surname></persName>
		</editor>
		<meeting>the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016)<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-09">December 9, 2016. 2016</date>
			<biblScope unit="volume">1773</biblScope>
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings. CEUR-WS.org</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<ptr target="https://arxiv.org/abs/1901.04085" />
		<title level="m">Passage re-ranking with BERT</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Finding generalizable evidence by learning to convince q&amp;a models</title>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Karamcheti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1244</idno>
		<ptr target="https://www.aclweb.org/anthology/D19-1244" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page" from="2402" to="2411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Language models as knowledge bases?</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1250</idno>
		<ptr target="https://www.aclweb.org/anthology/D19-1250" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page" from="2463" to="2473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">How context affects language models&apos; factual predictions</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=025X0zPfn" />
	</analytic>
	<monogr>
		<title level="m">Automated Knowledge Base Construction</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Improving Language Understanding by Generative Pre-Training</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<ptr target="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<ptr target="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1910.10683" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">How much knowledge can you pack into the parameters of a language model? arXiv e-prints</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2002.08910" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The probabilistic relevance framework: Bm25 and beyond</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
		<idno type="DOI">10.1561/1500000019</idno>
		<ptr target="https://doi.org/10.1561/1500000019" />
	</analytic>
	<monogr>
		<title level="j">Found. Trends Inf. Retr</title>
		<idno type="ISSN">1554-0669</idno>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009-04">April 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">End-To-End Memory Networks</title>
		<author>
			<persName><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">FEVER: a large-scale dataset for fact extraction and VERification</title>
		<author>
			<persName><forename type="first">James</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arpit</forename><surname>Mittal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1074</idno>
		<ptr target="https://www.aclweb.org/anthology/N18-1074" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long Papers</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-06">June 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="809" to="819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Avoiding catastrophic forgetting in mitigating model biases in sentence-pair classification with elastic weight consolidation</title>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">H</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<idno>ArXiv, abs/2004.14366</idno>
		<ptr target="https://arxiv.org/abs/2004.14366" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">U V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Diverse beam search for improved description of complex scenes</title>
		<author>
			<persName><forename type="first">Ashwin</forename><surname>Vijayakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramprasaath</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<ptr target="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17329" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">GLUE: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5446</idno>
		<ptr target="https://www.aclweb.org/anthology/W18-5446" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</title>
				<meeting>the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11">November 2018</date>
			<biblScope unit="page" from="353" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yada</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1905.00537" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>D\textquotesingle Alché-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="3261" to="3275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">R 3 : Reinforced ranker-reader for open-domain question answering</title>
		<author>
			<persName><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerry</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<ptr target="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16712" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)</title>
				<editor>
			<persName><forename type="first">Sheila</forename><forename type="middle">A</forename><surname>Mcilraith</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018">February 2-7, 2018. 2018</date>
			<biblScope unit="page" from="5981" to="5988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Evidence aggregation for answer reranking in open-domain question answering</title>
		<author>
			<persName><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Murray</forename><surname>Campbell</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rJl3yM-Ab" />
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Memory networks</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno>ICLR 2015</idno>
		<ptr target="http://arxiv.org/abs/1410.3916" />
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
				<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">May 7-9, 2015. 2015</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Retrieve and refine: Improved sequence generation models for dialogue</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5713</idno>
		<ptr target="https://www.aclweb.org/anthology/W18-5713" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 EMNLP Workshop SCAI: The 2nd International Workshop on Search-Oriented Conversational AI</title>
				<meeting>the 2018 EMNLP Workshop SCAI: The 2nd International Workshop on Search-Oriented Conversational AI<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-10">October 2018</date>
			<biblScope unit="page" from="87" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Addressing semantic drift in question generation for semisupervised question answering</title>
		<author>
			<persName><forename type="first">Shiyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1253</idno>
		<ptr target="https://www.aclweb.org/anthology/D19-1253" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page" from="2495" to="2509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Reasoning over semantic-level graph for fact checking</title>
		<author>
			<persName><forename type="first">Wanjun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zenan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiahai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Yin</surname></persName>
		</author>
		<idno>ArXiv, abs/1909.03745</idno>
		<ptr target="https://arxiv.org/abs/1909.03745" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
