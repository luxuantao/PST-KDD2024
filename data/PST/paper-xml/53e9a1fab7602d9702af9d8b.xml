<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Statically-Directed Dynamic Automated Test Generation *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Domagoj</forename><surname>Babić</surname></persName>
							<email>babic@cs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lorenzo</forename><surname>Martignoni</surname></persName>
							<email>martigno@cs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stephen</forename><surname>Mccamant</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
							<email>dawnsong@cs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Statically-Directed Dynamic Automated Test Generation *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">38410A4117F14E932AA3BE6818B75E20</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>D.2.5 [Software Engineering]: Testing and Debugging Algorithms</term>
					<term>Reliability</term>
					<term>Security automated testing</term>
					<term>static analysis</term>
					<term>dynamic analysis</term>
					<term>prioritization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a new technique for exploiting static analysis to guide dynamic automated test generation for binary programs, prioritizing the paths to be explored. Our technique is a three-stage process, which alternates dynamic and static analysis. In the first stage, we run dynamic analysis with a small number of seed tests to resolve indirect jumps in the binary code and build a visibly pushdown automaton (VPA) reflecting the global control-flow of the program. Further, we augment the computed VPA with statically computable jumps not executed by the seed tests. In the second stage, we apply static analysis to the inferred automaton to find potential vulnerabilities, i.e., targets for the dynamic analysis. In the third stage, we use the results of the prior phases to assign weights to VPA edges. Our symbolic-execution based automated test generation tool then uses the weighted shortest-path lengths in the VPA to direct its exploration to the target potential vulnerabilities. Preliminary experiments on a suite of benchmarks extracted from real applications show that static analysis allows exploration to reach vulnerabilities it otherwise would not, and the generated test inputs prove that the static warnings indicate true positives.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Many techniques have been proposed for software verification and test generation: symbolic model checking <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b5">5]</ref>, explicitstate model checking <ref type="bibr" target="#b25">[25]</ref>, static analysis <ref type="bibr" target="#b14">[14]</ref>, directed automated random testing <ref type="bibr" target="#b21">[21]</ref>, fuzzing <ref type="bibr" target="#b6">[6]</ref>, and numerous variants or combinations of those. Each technique offers different tradeoffs between soundness, completeness, speed, precision, scalability, and the level of automation, but all of them face the same fundamental problem -state-space explosion.</p><p>The first problem we explore is focusing the search during automated test generation. Search heuristics are either look-ahead techniques, which use an analysis cheaper than the search to explore the yet unvisited parts of the search-space, or look-back techniques, which analyze the already explored search-space. Our approach is a look-ahead technique, as we use static analysis to identify possible vulnerabilities and to compute other useful information about identified vulnerabilities, like data-flow slices (e.g., <ref type="bibr" target="#b47">[47,</ref><ref type="bibr" target="#b45">45]</ref>) with respect to the statement triggering the vulnerability. The identified vulnerabilities become targets for the dynamic analysis, while slices are used to guide the search toward those targets.</p><p>The second problem we explore is a combination of static and dynamic analysis, with the goals of (1) using the static analysis to guide the dynamic test generation, and (2) using the dynamic analysis to filter out false positives produced by the static analysis. We refer to our approach to this combination as statically-directed dynamic automated test generation.</p><p>The idea of guiding dynamic with static analysis can be applied at the source level, but our work focuses on test generation for stripped binary programs (without symbol tables or debug information). Our approach is also applicable when the source code of the application is available, but the third-party libraries are closedsource. In that case, the system integrators or even end-users have to test closed-source components before deploying them, especially in settings where security and reliability are paramount.</p><p>Working at the binary level introduces some unique challenges: pervasive address arithmetic, the absence of type information, misaligned memory accesses, and indirect (computed) jumps. To address these challenges, we devise a three-stage approach: The first stage uses a combined dynamic and static analysis to generate an interprocedural control-flow graph, represented as a visibly pushdown automaton (VPA) <ref type="bibr" target="#b1">[1]</ref>. The second stage performs static analysis on the VPA to identify possible vulnerabilities and to compute other information used later to guide the search, like data-flow dependency slices. The third stage uses symbolic execution <ref type="bibr" target="#b28">[28]</ref> and the results of the static analysis from the second stage to generate tests that trigger the vulnerabilities detected by static analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Contributions</head><p>Our three-stage sandwich approach to binary analysis is a new point in the space of tradeoffs (soundness, completeness, speed, precision,. . . ) in binary analysis. In addition to proposing the approach, we make contributions in each stage.</p><p>The first stage of our approach, described in Section 2, constructs an underapproximation of the interprocedural control-flow graphs of a binary without symbols or debug information. We combine dynamic and static analysis to resolve indirect jumps and to decode assembly instructions. Both problems are a challenge, because in the absence of type information or labels, every assembly instruction a potential jump target; with variable-sized CISC instructions, it can be difficult to even distinguish code from data. Our approach computes an underapproximation of the transition relation by resolving some indirect jumps with a set of seed tests, and augmenting the computed relation with statically computed direct jumps.</p><p>The VPA computed by the first stage is the input to our static analysis (Section 3), designed for finding potentially exploitable vulnerabilities, like buffer overflows. Our static analysis is inspired by the Balakrishnan and Reps's VSA analysis <ref type="bibr" target="#b3">[3]</ref>. One difference is that our static analysis combines discovery of abstract memory locations with the data-flow analysis, while VSA alternates discovery and data-flow analysis until a fixed-point. Further, our analysis handles overlapping (mis)aligned reads and writes more precisely, a feature we found particularly useful in analysis of programs that perform a lot of string operations.</p><p>The third stage of our approach, presented in Section 4, performs single-path symbolic execution to search for concrete test inputs that trigger potential vulnerabilities discovered by the static analysis in the second stage. Running on its own, the test generation tool can create many program inputs, each exercising a different path, but often none of them trigger a vulnerability. This motivates our use of static analysis to guide the path search.</p><p>Thus, we propose a new heuristic for guiding dynamic search towards finding the right path towards a vulnerability identified by static analysis in the second stage. Our heuristic works differently when the dynamic search is within a strongly connected component (SCC) such as a loop, and when it is not. For outside an SCC, we develop a two-component heuristic that ranks states according to two statically-computed metrics, one based on the shortest VPA path to the vulnerability, and the other using the vulnerability's data-flow slice. For within an SCC, we develop a heuristic that picks patterns of paths through the SCC according to a geometric distribution and then alternates those paths over multiple iterations.</p><p>The problem of computing the shortest paths on a VPA has not (to our knowledge) been previously posed. We address it by an efficient algorithm that treats well-matched paths first, bottom-up in a call graph, and then extends to all VPA paths by taking an automaton product with an automaton that prohibits mismatched calls. These transformations allow us to use the classic algorithm for shortest paths in a graph. Our algorithm can also be seen as a more efficient case of a weighted pushdown problem <ref type="bibr" target="#b39">[39]</ref>, using the property that the semiring of path lengths is totally ordered.</p><p>In our experiments, the proposed heuristic sped up the dynamic test generation significantly, in one case letting our system find in 11.3 seconds a vulnerability it could otherwise not find even after 6 hours. Both parts of the heuristic were valuable: the SCC part allowed the tool to achieve good coverage of loops with complex internal structure, while the non-SCC part allowed it to efficiently focus on those parts of a program relevant to a vulnerability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Terminology</head><p>An interprocedural control-flow graph, as computed by the first stage of our analysis, can be seen as the combination of a call graph and separate control-flow graphs for each function. But we instead formalize it as a single unified object, a visibly-pushdown automaton <ref type="bibr" target="#b1">[1]</ref>. Though ultimately equivalent, this choice allows our exposition to be at once simpler and more formal.</p><p>States represent basic blocks: a sequence of program statements ending with a branch, call, or return. The flow of control enters a basic block only at its beginning and leaves it by execution of the last statement. For simplicity, we will assume that each basic block ending with an unconditional jump is merged with the target block, duplicating blocks that are a target of multiple jumps. 1  Basic blocks containing exit statements are accepting states. The VPAs considered in this paper accept only matched returns words, meaning that every return must have a matching call. If also every call must have a matching return, we say such words are well-matched.</p><p>We use the standard abstract interpretation notation and terminology <ref type="bibr" target="#b14">[14]</ref>: abstraction (resp. concretization) operator α (resp. γ), abstract post state transformer post # , and join (resp. widening) operator ⊔ (resp. ▽).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">CONTROL-FLOW COMPUTATION</head><p>The first stage of our approach resolves indirect jump targets in binaries by analyzing a set of concrete traces obtained by executing the analyzed application on a set of seed tests. Our dynamic analysis folds multiple traces into a single VPA representing the global flow of control. Additionally, we augment the VPA with missing transitions that can be precisely computed through static analysis. In this section, we describe the computation of the VPA through a combination of dynamic and static analysis.</p><p>We adopt a hybrid approach to VPA construction combining dynamic and static analysis. The dynamic analysis attempts to resolve as many targets of indirect control-flow transitions as possible. The static analysis mitigates the incompleteness of the dynamic analysis. For the purpose of finding a vulnerability in the program, it is sufficient that the model of the program we build includes the vulnerable path, but it is irrelevant whether the edges along the path were discovered through seed tests or static augmentation.</p><p>We use the PIN <ref type="bibr" target="#b31">[31]</ref> framework to instrument binary applications with callbacks at jump and library load events. The instrumented application executes normally, unaware of the callbacks. Traces from multiple seed tests are merged into a single VPA. An underapproximation of the instrumented application's control-flow in the form of a VPA can be computed as follows. Each visited basic block is represented with a single state in VPA. Each visited edge is classified in one of the classes (call, internal, return) and the VPA is updated so that the source and the target basic blocks are linked with an edge of the appropriate class. All basic blocks ending with the exit system call are declared to be final states.</p><p>After the dynamic VPA construction, we use recursive traversal disassembly <ref type="bibr" target="#b42">[42]</ref> to augment VPA with the conditional direct jumps not executed by the seed tests. The resulting VPA is, necessarily, an underapproximation of the complete interprocedural control-flow graph of the analyzed application. The completeness of the constructed VPA depends on the capability of the seed tests to exercise indirect branches and the number of branches that can be accurately resolved with the recursive traversal disassembly. Finally, we use the Vine library from BitBlaze <ref type="bibr" target="#b44">[44]</ref> to decode the instructions into a simplified internal representation to facilitate later analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">STATIC ANALYSIS OF BINARIES</head><p>The static analysis in the second stage of our approach performs an interprocedural context-and flow-sensitive analysis on the VPA computed in the first stage. First, static analysis identifies possible vulnerabilities, which are used as targets for the dynamic analysis in the third stage of our approach. Second, static analysis computes approximate size of stack frames and allocated heap regions. These 1 Merging of targets of unconditional jumps is done in the first stage of our approach.</p><p>sizes are used to detect out-of-bounds accesses. Third, static analysis maintains a map between written abstract locations and statements in the assembly code and this map is then used to compute the backward data-flow slice with respect to the identified vulnerability. The slice is used as a component of the guidance heuristics in the third stage of our approach. The rest of this section discusses the most important aspects of our static analysis: the abstract domains used, the treatment of weak and strong updates, and the handling of overlapping and misaligned reads and writes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Abstract Domains</head><p>The abstract domain we use for static analysis of binaries consists of several hierarchically composed domains: strided intervals (denoted SInterval) <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b2">2]</ref>, value map (ValMap), regions (Region), and abstract states (State). We introduce these abstract domains starting at the bottom of the hierarchy.</p><p>Strided intervals are defined as a triple s[lb, ub], such that<ref type="foot" target="#foot_0">2</ref> </p><formula xml:id="formula_0">γ (s[lb, ub]) := {i | lb ≤ i &lt; ub ∧ s &gt; 0 ∧ ∃k ∈ Z . i = s • k}</formula><p>Binary code often uses indirect addressing base + index × scale, conveniently representable by strided intervals. Arithmetic and logical operations on strided intervals are very similar to operations on simple intervals and can be efficiently computed (e.g., <ref type="bibr" target="#b46">[46]</ref>). Memory regions, in our work, abstract disjoint chunks of memory. Each region has a unique identifier. The set of identifiers is denoted RegionID, while for the elements of the set we will use r, with indices. We treat registers as a special form of a fixedsize region (RegId). Global variables also form a fixed-size region (GlbId). For simplicity, we also place constants and scalar ranges in a special region (CId).</p><p>We create a unique region for each allocation site that allocates a heap object, while for the other types of regions (registers, stack, and globals) we create one unique region per program per region type. Other abstract domain design decisions are possible. For instance, Balakrishnan and Reps <ref type="bibr" target="#b3">[3]</ref> allocate one stack region per function. Our decision to keep a single stack region per program simplifies context-sensitive analysis and allows precise handling of writes to any frame on the calling stack.</p><p>A value can be either an integer or an address within a region. To represent a pointer that could point to multiple regions, or a value that could be either a constant or a pointer, we use value maps ValMap := RegionID → SInterval, where SInterval represents the offset within the RegionID region. Integers are represented as offsets within the distinguished region CId. Further on, we shall use letters a (resp. v), possibly with indices, to denote an address from SInterval (resp. an instance of ValMap). The (RegionID, SInterval) pair is also known as an abstract location, or aloc for short, in the literature. Alocs are used to represent variable-like entries, either on heap, in stack, or in registers.</p><p>Regions are defined as a map Region := SInterval → ValMap. Individual regions are denoted R, possibly with indices. For example, the stack region containing constant 7 at stack slot -4 and a pointer to a global variable at address 1000 at stack slot -12 would be represented as:<ref type="foot" target="#foot_1">3</ref> </p><formula xml:id="formula_1">R = 4[-4, 0] → {CId → 1[7, 8]} , 4[-12, -8] → {GlbId → 4[1000, 1004]} (1) post # (s 0 , if c then S 1 else S 2 ) = post # (s 0 , S 1 ) ⊔ post # (s 0 , S 2 ) post # (s 0 , while c do S) = s 0 ▽post # (s 0 , S) post # (s 0 , write(r, a, v)) = s 0 [r, a ← v]</formula><p>Figure <ref type="figure">1</ref>: Definition of the Transition Relation. The pre-state is denoted s 0 , statements S i , the widening operator ▽, branch condition c, and temporary variable v of the ValMap type. Our instruction decoder creates temporary variables for intermediate results loaded from memory or created by complex assembly instructions. The control-flow construction (Section 2) identifies branches and loops, which can be classified as either if-then-else branches or while-do loops. Thus, the above are all the state-modifying transitions required.</p><formula xml:id="formula_2">⊕v = {(r, a) | (r, a ′ ) ∈ v ∧ a = ⊕a ′ } v 1 ⊗ v 2 = (r, a) a = a 1 ⊗ a 2 if (r, a 1 ) ∈ v 1 ∧ (r, a 2 ) ∈ v 2 a = ⊤ otherwise read(r, a) = s[r, a],</formula><p>where s is the current state Regions with different identifiers are considered to be infinitely far apart. The C standard <ref type="bibr">[26, page 83]</ref> considers the result of address arithmetic pointing outside a region undefined, so our treatment of regions is following the C standard (for binaries compiled from C programs). For binaries compiled from type-safe languages, our assumption is safe.</p><p>Finally, we define an abstract state as a map from region identifiers to regions: State := RegionID → Region. For denoting individual states, we will use the letter s, possibly with indices. The State map is indexed by a region identifier and address (strided interval), e.g., s <ref type="bibr">[GlbId, 4[1000</ref><ref type="bibr">[GlbId, 4[ , 1004]]</ref>]. The indexing operation s[r, a] returns the value map defining the location a in the region with identifier r in state s, or ⊥ if the location is undefined. We define substitution on states s [r, a ← v] as an operator that replaces the value map s[r, a] with v, without changing other regions or addresses, and returns the newly constructed state.</p><p>For efficiency, we represent the maps in each level of the abstract state as persistent red-black trees <ref type="bibr" target="#b35">[35]</ref> (using Eker's optimizations <ref type="bibr" target="#b19">[19]</ref>) to allow fast functional updates with sharing. Regions use interval trees to efficiently detect overlap, and we use hash consing to avoid constructing duplicate objects.</p><p>Formally, our abstract interpretation is a monotone non-distributive framework (e.g., <ref type="bibr" target="#b34">[34]</ref>) with domain (P (State) , ⊑, ⊔, ⊥), where the transition relation post # is defined by the rules in Fig. <ref type="figure">1</ref>, while the operations over value maps are defined in Fig. <ref type="figure" target="#fig_0">2</ref>. To compute the fixed-point, we use a simple aggressive widening operator for strided intervals, described in <ref type="bibr" target="#b2">[2]</ref>. We define the join and widen operators on states later (Section 3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Weak and Strong Updates</head><p>In this section, we discuss our treatment of weak and strong updates in more detail. A strong update overwrites the contents of the written region, and represents a definite change. In contrast, a weak update computes a join of the old and new contents. In general, if a region represents multiple concrete regions (i.e., summarizes them), strong updates are unsound.</p><p>Our analysis begins by creating a single strongly updatable region per allocation site. If that site is revisited during the course of analysis, a new weakly updatable region is created and reused every time the same allocation site is revisited later, as in the allo-cation site abstraction <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b30">30]</ref>. Thus, the analysis creates at most two regions, one strongly and one weakly updatable, per allocation site. The described strategy is exactly the opposite of Balakrishnan and Reps's recency-abstraction <ref type="bibr" target="#b4">[4]</ref>, which maintains the latest region as strongly updatable while summarizing the older regions. Balakrishnan and Reps motivate their recency-abstraction as a necessity for resolving indirect jumps. In contrast, our three-stage technique exploits dynamic seed traces to resolve indirect jumps, so we opted for what we considered an easier-to-implement option, albeit possibly less precise in some cases. In the further exposition, all updates will be weak, as that case exposes more interesting details than strong updates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Identification of Memory Locations</head><p>Unlike prior work <ref type="bibr" target="#b3">[3]</ref> that relied on IDAPro <ref type="bibr" target="#b24">[24]</ref> to detect alocs and then alternated the VSA analysis and aloc detection until the fixed-point is reached, our analysis discovers alocs and performs abstract interpretation at the same time. We detect alocs during the first write that is within the allowed bounds of a region. Writes that are outside the allowed bounds produce a warning. The allowed bounds are computed as a side-result of the analysis.</p><p>The most difficult part of the alocs identification is dealing with overlapping writes, which tend to be relatively frequent in practice. A simple solution, to compute the union of overlapping addresses and set their content to ⊤, tends to be insufficiently precise. A more precise alternative, used in our analysis, is to partition the overlapping addresses into non-overlapping chunks along the stride boundaries, and then compute the value stored at each chunk separately. We found the increase in precision especially important for analyzing programs that operate on strings, which are often loaded from memory or created on stack in four-byte chunks and then accessed byte-by-byte. The algorithm for partitioning sets of addresses into strides is conceptually simple, but tedious to implement because there are many special cases appearing in practice. Due to lack of space, we skip the details, but we illustrate the idea in Figure <ref type="figure" target="#fig_2">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Join and Widening of Regions</head><p>We use the same chunking approach to compute a join of regions. For example, given two regions R 1 and R 2 , their join first partitions addresses into three disjoint sets:</p><formula xml:id="formula_3">S 1 = dom (R 1 ) /dom (R 2 ), S 2 = dom (R 2 ) /dom (R 1 ), and S 3 = dom (R 1 ) ∩ dom (R 2 )</formula><p>, where dom is the domain of a map and '/' is set difference. In example (1), dom (R) = {4[-4, 0], 4[-12, -8]}. Addresses within each set are then partitioned into disjoint strided intervals so as to keep the original strides when possible. Finally, the join operator computes the value stored at each address in S 1 ∪ S 2 ∪ S 3 . The values stored at addresses from S 1 are the (possibly truncated) values in the region before the write. The values stored at S 2 are the newly written values. The values stored at S 3 are the addresses overwritten with new values. Assuming weak updates, the result is a join of the old and new values. The join over states is defined as:</p><formula xml:id="formula_4">s 1 ⊔ s 2 := (r, R 1 ⊔ R 2 ) either (r, R 1 ) ∈ s 1 ∧ (r, R 2 ) ∈ s 2 or (r, R 1 ) ∈ (s 1 ∪ s 2 /s 1 ∩ s 2 ) ∧ R 2 = ⊥ (2) Algorithm 1 computes R = R 1 ▽R 2 .</formula><p>Widening terminates when the contents reach a fixed-point. It might seem that the last case in Algorithm 1 could introduce substantial imprecision. However, since global addresses are most often constants and since writes to the stack are most often constant offsets from the ESP or EBP registers, and neither of those registers is commonly modified within loops, the imprecision of widening rarely impacts the most important regions, globals and the stack. Widening on states is done similarly as in (2), only ⊔ is replaced with ▽.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">GUIDED DYNAMIC ANALYSIS</head><p>The third stage of our approach applies dynamic analysis (based on symbolic execution) to compute concrete test inputs that trigger vulnerabilities in the program under analysis. To direct the dynamic analysis, we introduce a two-component heuristic. The first component of the heuristic is the distance in the VPA; below we give an algorithm to efficiently compute these shortest path lengths. The second component of the heuristic is based on the number of statements in the data-flow slice, which is a transitive closure of readwrite dependencies of all variables used by the statement triggering the vulnerability. We compute this component using standard techniques of interprocedural data-flow analysis <ref type="bibr" target="#b38">[38]</ref>. We note that both components can also be seen as generalized pushdown predecessor problems (GPPP) <ref type="bibr" target="#b29">[29]</ref> on a weighted pushdown system (WPDS). For distances, the semiring is (N, min, +, ∞, 0), where min is a bi-Algorithm 1 Region Widening. Lines 2 and 3 perform chunking, illustrated in Figure <ref type="figure" target="#fig_2">3</ref>. Lines 4 and 5 do point-wise widening on addresses (and their contents) defined in both regions. Lines 6 and 7 union the addresses (and their contents) belonging only to R 1 with the temporary result. The rest of the algorithm handles the case when the region used for widening (R 2 ) defines some addresses not defined in R 1 .</p><p>1: R ← / 0 2:</p><formula xml:id="formula_5">S 1 ← dom (R 1 ) /dom (R 2 ) , S 2 ← dom (R 2 ) /dom (R 1 ) 3: S 3 ← dom (R 1 ) ∩ dom (R 2 ) 4: for (a, v) ∈ S 3 do 5: R ← R ∪ (a, R 1 [a]▽R 2 [a]) 6: for (a, v) ∈ S 1 do 7: R ← R ∪ (a, v) 8: if ∃(a, v) ∈ S 2 then 9:</formula><p>Issue a warning about a possible write out of bounds 10:</p><p>Widen contents of all existing chunks in R with v nary operator returning the minimal value. For counting the number of reachable statements from the slice, we can use the trivial semiring (S, ∪, ∪, / 0, / 0), where S is the set of instructions in all basic blocks of a VPA. The two-component heuristic is a function with an N × N codomain. For a given location of a potential vulnerability, we precompute the values of the function for each VPA state; it is convenient and sufficiently fast to compute all of these values at once, before starting the exploration.</p><formula xml:id="formula_6">f g h k f 0 f 1 f 2 f 3 f 4 g 2 g 1 g 0 h 2 h 3 h 0 h 1 k 1 k 0 (a) f g h k 1 1 2 1 f g h k 1 1 2 1 0 0 0 0 (b) G R G C</formula><p>We also use a second heuristic to attempt to cover a variety of patterns of paths through relevant loops -our system identifies paths using the VPA, then records which paths have been explored and then explores various patterns of these paths. For a given location of a potential vulnerability and a given SCC, we identify paths within SCCs before and construct patterns during the search.</p><p>In the rest of this section, we first describe as background the baseline approach of symbolic execution, with an undirected search strategy (Section 4.1). Next, we present an efficient algorithm for computing shortest paths in a weighted VPA (Section 4.2), which we use to propagate cost information as part of the program-wide two-component heuristic, and describe how we use this heuristic at branches (Section 4.3). Finally, we discuss our approach for covering loop path patterns (Section 4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline: Symbolic Execution</head><p>We describe our exploration system as dynamic because it treats most of the program state as concrete: only values derived from a specified input are treated as symbolic. The system symbolically executes one whole-program execution path at a time; when a branch condition is symbolic, the tool checks whether either the condition or its negation is satisfiable using the Z3 <ref type="bibr" target="#b16">[16]</ref> decision procedure. Operationally, the system works similarly to previous tools such as Klee <ref type="bibr">[9]</ref>, EXE <ref type="bibr" target="#b10">[10]</ref>, and MineSweeper <ref type="bibr" target="#b7">[7]</ref>.</p><p>When both sides of a branch are feasible, our system's default behavior is to choose a direction randomly. Though fair in a sense, this is clearly a very uninformed search strategy. Thus the focus of the rest of this section is on techniques that harness more global information, such as from static analysis, to make better branch choices. However, the symbolic execution engine only takes these suggestions as advice: it will never explore an infeasible path or one that it has previously explored. We refer to the symbolic exe-cution of one such whole-program execution path as an iteration of the dynamic exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">VPA Shortest Paths</head><p>The algorithm we present in this section computes the first component of our heuristic. Intuitively, we would like to direct the dynamic analysis to follow a (whole-program) path that reaches a target, and among such paths we would like one with a low cost. More precisely, we would like to compute, for each basic block in the program, the cost of the least-costly path from that point to the target basic block. It is a convenient analogy to think of the costs as distances, so that our goal is to find the length of the shortest paths from each basic block to a single target.</p><p>If our program representation were a simple graph, Dijkstra's shortest path algorithm <ref type="bibr" target="#b17">[17]</ref> would be appropriate, but it does not follow the restriction that calls and returns must be well-matched. For example, suppose we want to find the shortest path from f 0 to f 3 in Figure <ref type="figure" target="#fig_3">4</ref>.a. The classic shortest path algorithm would find the path f 0 k 0 k 1 h 3 f 3 , which is incorrect, because the return from k to h is executed with stack configuration f 1 that doesn't match the state k is returning to. Instead, the correct shortest path with matched returns is f 0 k 0 k 1 f 1 f 4 g 0 g 2 f 3 (assuming equal edge weights). Such a situation occurs in practice, for instance, if a common function such as printf is called from both main and the function containing a vulnerability. If we ignored call-return matching, our tool might think that the shortest path to the vulnerability was one that started in main, called printf, and then returned from printf to the vulnerable function. But attempting to follow this infeasible path would be unproductive. However, while we match calls and returns within the path, the definition of the path length is otherwise context-insensitive, in the sense that the distance between a point A and a point B does not depend on the call stack at A.</p><p>Thus our goal is to build an analogue of Dijkstra's shortest path algorithm that operates on a VPA, and finds the lengths of the shortest path among those paths in which there are no mismatches between calls and returns. It is not immediately obvious whether such an algorithm could be efficient: a given statement might be reached with many different call stacks, and the shortest path between two points in a VPA can have exponentially many edges.</p><p>The key insight in obtaining an efficient algorithm for this problem is to start with the special case of well-matched paths (with no unmatched calls or returns), since it is easier to combine paths under the invariant that they are well-matched. Then we can extend well-matched paths to general VPA paths by constructing paths out of unmatched returns, well-matched segments, and unmatched calls, in which no unmatched call precedes an unmatched return (thus ensuring that they are unmatched).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Well-Matched Paths</head><p>For the first step of the algorithm, focusing on well-matched paths, our specific goal is to compute, for each function, the length of the shortest well-matched path that starts at the entrance to the function and ends at the return from the function. This per-function shortest path length is a kind of function summary that can be efficiently computed bottom-up. For leaf functions, we apply Dijkstra's algorithm to compute the length of the shortest path from entrance to exit. If for all of the functions g 1 , . . . , g k that might be called by a function f , we have already computed the summary length l i for g i , we can replace the call to g i with an edge of cost l i and then again compute the summary length for f with one intraprocedural invocation of Dijkstra's algorithm.</p><p>The above described bottom-up computation might not compute the shortest entrance-to-exit path for every function in SCCs in the call graph, so another level of iteration is required. Let S be the set of functions in an SCC of the call graph. We start by setting the summary length for each function in the S to ∞. Then, we repeat |S| times a process of updating the summary length for each function in S (|S| 2 updates total). To update the summary length of a function f , we recompute its entry-to-exit path length based on the best estimates found so far for the other functions in the SCC (and the previously-computed correct values for any called functions outside the SCC), updating the summary length if the computed value is smaller. This process is shown in Algorithm 2.</p><p>Algorithm 2 Per-Function Computation of Shortest Paths. The function DFN returns the list of functions sorted by depth-first post-order. The function DSP( f , costs) computes the length of the shortest path from the entry to exit of the function f , using Dijkstra's shortest path algorithm, under the assumption that the shortest paths through called functions are those given in costs. The function SCC(G, f ) returns all the functions in G that are in the same SCC as the function f . 1: let CG ← call-graph of VPA 2: costs ← / 0 3:</p><formula xml:id="formula_7">for f ∈ DFN(CG) do 4: if f ∈ costs then 5: let S ← SCC(CG, f ) 6: for f ′ ∈ S do 7: costs[ f ′ ] ← ∞ 8: for i = 1 . . . |S| do 9: for f ′ ∈ S do 10: costs[ f ′ ] ← min(costs[ f ′ ], DSP( f ′ , costs))</formula><p>The complexity of the part of the algorithm for a single SCC is O M 2 E lg N , where M is the number of functions in the SCC, and N (resp. E) is the number of basic blocks (resp. edges) in the largest function in the SCC. The factor O (E lg N) is the running time of Dijkstra's algorithm using a binary heap. The algorithm is guaranteed to converge after analyzing each function in the SCC M times, because the shortest path always goes through the base case, rather than recursing to a function already on the call stack. After the i-th iteration through all the functions, the algorithm will have correctly computed the shortest length for call paths whose depth within the SCC is at most i. Since the shortest path for each function has no recursive calls, its maximum depth within the SCC is M, so M iterations suffice.</p><p>To see why this the shortest path cannot contain a recursive call, suppose, to the contrary, that the shortest path were one in which a function f contained a recursive call to the same function f . For instance, suppose that g calls f (the "outer" invocation of f ), then f calls itself (the "inner" invocation of f ), and then both invocations return. Then we can construct a strictly shorter path by replacing the outer invocation of f with the inner invocation of f . In the example, this gives the path in which g calls f , then f returns. The new path will be well-matched, but it is shorter, contradicting the assumption that the first path was the shortest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">General VPA Paths</head><p>For the second step of the algorithm, we extend the well-matched paths computed in the first step to general VPA paths (without mismatched calls and returns) by concatenating well-matched segments, unmatched returns, and unmatched calls. The key insight is that this is possible as long as the unmatched returns come before the unmatched calls in the path, which ensures that they do not mismatch with each other. More formally, let C (resp. R) be the set of calls (resp. returns), and W the set of well-matched words. Then any word without mismatched calls and returns can be written in the form (R|W ) * (C |W ) * , where | and * are the standard regular expression operators of alternation (union) and Kleene star (repetition zero or more times).</p><p>Using the lengths for well-matched entrance-to-exit paths computed in the first step, the W symbols in the regular expression can be represented by summary edges from a call site to a return. What remains is to enforce the constraint that unmatched returns (R) precede unmatched calls (C ). This can be seen as requiring paths in the VPA that simultaneously match the regular expression. We can express the regular expression with the NFA shown in Figure <ref type="figure" target="#fig_4">5</ref>, and express the intersection of (R|W ) * (C |W ) * and the VPA by a product of the two automata. This product is equivalent to constructing an automaton with two copies of the VPA, and we take that perspective in describing the construction in more detail.</p><p>To find the lengths of paths that satisfy the no-mismatched-calls constraint expressed by the regular expression (R|W ) * (C |W ) * , we use Dijkstra's algorithm on a graph consisting of two copies of the VPA. For the first half (R|W ) * we construct a graph G R with call edges erased, return edges retained, and a summary edge between each pair of matching calling and return nodes having the weight of the shortest path through the callee. Paths through this graph correspond to executions with unmatched returns and wellmatched function invocations in any order. Dually we construct for the second half (C |W ) * a graph G C with call edges retained, return edges erased, and summary edges as in G R . Paths through G C correspond to executions with unmatched calls and well-matched function invocations in any order. Finally, we construct a combined graph G RC by linking G R and G C with zero-weight edges from each call node in G R to the corresponding call node in G C . (It suffices to link only call nodes because every word in (C |W ) * starts with a call.) Then, we compute the shortest VPA path from one node to another by running Dijkstra's algorithm taking a node from G R as Algorithm 3 VPA Shortest Path Computation. To compute the length of the shortest VPA paths to a single target warning location t w , we construct a graph G RC , representing the combination of graphs G R and G C that allow unmatched returns and unmatched calls respectively. The i -→ symbol denotes an edge with weight i. Lines 1-4 add two copies of each VPA node to G RC (representing the nodes in G R and in G C ); the two copies are labeled with different labels (R and C). Lines 7-9 add call edges ( in Fig. <ref type="figure" target="#fig_3">4</ref>) to G C , edges between corresponding call sites of G R and G C ( ), and summary edges between callers and return nodes ( ) to both G R and G C . Lines 10-11 add return edges ( ) to G R . Lines 12-13 add the intraprocedural edges ( ). Finally, lines 14-16 run Dijkstra's algorithm to compute all-source-single-target distances to the R copy of t w , and return the distances using the C copies as sources.</p><p>1:  </p><formula xml:id="formula_8">G RC ← empty graph 2: for b ∈ nodes of VPA do 3: let b ′ ← b,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">The Two-Component Heuristic</head><p>Obviously, an execution path can only demonstrate a possible vulnerability at an instruction if it executes that instruction, and often the vulnerable instruction depends on values computed earlier in a program. We take these two intuitions as the basis for our guidance approach for path selection.</p><p>More formally, given a warning produced by static analysis, our approach computes for each VPA node a pair of non-negative integers (d, s). The first component d represents the cost of the leastexpensive path from the basic block to the warning. The second component s counts the number of instructions in the data-flow slice of the warning that can be reached from the basic block.</p><p>For computing d, we use the shortest-path algorithm of Section 4.2, assigning a weight of ∞ to loop back edges and 1 to all other edges. Assigning a high cost to loop back edges causes the search to prefer to reach a target at the first opportunity, even if it would also be reachable on a future loop iteration.</p><p>To compute s for a given potential vulnerability, our system first computes the complete backward slice from the vulnerability. Then it makes a single bottom-up pass of standard interprocedural propagation to compute, for each basic block b, the set of instructions in the slice that are reachable from b. The value of s at a location is the cardinality of that set.</p><p>The two components d and s represent goals that are sometimes in tension. We would prefer to take paths that reach the poten-char buf <ref type="bibr" target="#b20">[20]</ref>  tial vulnerability quickly (small d), and we would like to cover many data-flow predecessors of the potential vulnerability (large s). When these desires conflict, our heuristic attempts to balance them, choosing the one that is more salient in a particular instance, while incorporating randomization so that a future path may make a different choice, especially if it was close.</p><p>Specifically, suppose that at a branch, we have a choice between a target with heuristic values (d 1 , s 1 ) and one with (d 2 , s 2 ). Since we prefer a target with large d but small s, we compute the cross difference x = d 1 •(1+ln(1+s 2 ))-d 2 •(1+ln(1+s 1 )). A negative value of x corresponds to a preference for the first target, while a positive value corresponds to a preference for the second. To include randomization, we compute the logistic value r = 1 1+e -kx , and branch according to whether a number selected uniformly at random in [0, 1] is less than r. The parameter k controls how large a difference in costs corresponds to a given probability difference; our system currently has k = ln(1.001).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">The Loop Pattern Heuristic</head><p>The two-component heuristic described above is effective for directing execution towards a desired point in a program; when a program has loops, it will usually explore only a few iterations. But some program behaviors occur only when loops, and in particular certain paths those loops, execute repeatedly. This is especially true for buffer-overflow and integer-overflow vulnerabilities.</p><p>A simple example of a loop for which a pattern of loop paths is needed to cause an overflow is shown in Figure <ref type="figure" target="#fig_6">6</ref> (similar but more complicated loops appear in several of the benchmarks in Section 5). There are four paths through the body of the loop, numbered in comments. Choosing one of the loop body paths randomly on each iteration is very unlikely to produce an overflow (p -buf ≥ 20): only path 1 increments the pointer, and path 4 decrements it, so they tend to cancel each other out. On the other hand because of the mode flag, it is infeasible to execute path 1 on every iteration. A pattern that leads to the overflow is one that alternates between paths 1 and 3. At a high level, our approach is not to statically determine which such pattern of paths leads to an overflow (though this could be an interesting direction for future work). Instead, our approach is to guide the exploration to cover a wide variety of path patterns, so that if a vulnerability can be triggered by a short pattern, the exploration will find it relatively early.</p><p>Thus to improve our coverage of these kinds of behavior, our system directs execution to sometimes repeatedly execute one or more specific paths within a loop as many times as possible. For a loop that either contains the vulnerability, or contains an instruction from the slice of the vulnerability, this heuristic will choose a short pattern of paths from among those loop paths previously observed. Then on each iteration of the loop it will try to execute the next path from the pattern. In order to construct such patterns, we need to be able to uniquely identify paths through a loop body (precisely, the (necessarily acyclic) paths through a control-flow graph SCC that do not pass through any sub-SCCs).</p><p>We begin by identifying all exits from the analyzed SCC. The exits include entries into a sub-SCC. We assign the weight of one to the exit edges and start traversing the acyclic graph (loop body) backwards. For every node, we sum up the weights of all outgoing edges and assign the sum to the node and all the incoming edges. After the process terminates (it terminates because the graphs are finite and acyclic), every node is labeled with the number of distinct paths to exits. The header of the loop is labeled with the number of paths, call it P, from the header to the SCC exits.</p><p>Each acyclic path through the SCC can be assigned a unique number in the range 0 . . . P -1. We call a word w = {0 . . . P -1} * a loop path pattern. As the exploration runs, the system records the unique path numbers of feasible paths. Once the system has observed some feasible paths (currently, after the fifth execution of the program), it will begin to try to traverse a path pattern on some executions. Specifically, the system chooses whether to use a pattern, and if so the length of pattern to use, according to a geometric distribution as follows. For 50% of program executions, it does not use a pattern (rather, chooses a path number randomly). For 25% of executions, it picks a pattern of length 1 (a single path number), and uses this path number for every loop iteration. For 12.5% of executions, it picks a pattern of length 2 (a pair of path numbers P a and P b ), and uses path P a for odd-numbered iterations and P b for even-numbered iterations. In the same way, longer patterns are chosen less frequently. In each case, the pattern is constructed by uniform random selection from the set of feasible paths discovered so far. The constructed loop path pattern is repeated every time the loop is revisited during the search, until the program exits. On each iteration, the heuristic will attempt to follow the path given by the path number, subject to feasibility.</p><p>Observe that, unless one of the paths in a path pattern leads to a loop exit, one effect of a pattern is to attempt to execute as many loop iterations as possible (in contrast, random choice would stop with probability 50% after each iteration). Finally, while we apply the path-pattern approach as described above on every execution when the vulnerable instruction is inside a loop (in the same function), we apply it more selectively for loops which contain only an instruction from the vulnerable statement slice. For these loops, which are less frequently relevant to a vulnerability, we apply the path-pattern approach for a fraction (one-third) of executions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTAL RESULTS</head><p>We evaluate our tool's detection and test generation for buffer overflow vulnerabilities using a suite of examples developed by Zitser et al. <ref type="bibr" target="#b49">[49]</ref>, extracted from historic vulnerabilities in 3 widely used network servers. Though the examples have been reduced to omit most of the irrelevant parts of the programs (they average 665 lines of C code each), they cover a wide variety of kinds of overflow, and demonstrate sufficient complexity to make analysis challenging. Each benchmark represents a conceptually single bug, which can manifest in out of bounds accesses at multiple locations. The original versions of the benchmarks were designed purely for static analysis; we use versions modified by Saxena et al. <ref type="bibr" target="#b41">[41]</ref> to read inputs from files for use with dynamic techniques.</p><p>The experiments were performed on a 4-core Xeon E5540 workstation (our tools are single-threaded) with 12GB of RAM, running Debian GNU/Linux with a 64-bit kernel version 2.6.26. The results of the evaluation are summarized in Table <ref type="table" target="#tab_2">1</ref> and described in more detail in the remainder of the section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Static Analysis</head><p>Our static analysis finds out-of-bounds memory writes, analyzing both the application and the libraries together, rather than depending on hand-written API summaries. We use the dietlibc library as a compatible but simplified replacement for the system's C library. To improve the quality of the results, we also treat some C library functions whose only side-effect is output, such at write and syslog, as no-ops, since these functions do not modify their inputs or global variables visible to the program.</p><p>All benchmarks have labeled vulnerabilities, which enabled us to accurately count false negatives and positives. As shown in Table 1, our approach detects all vulnerabilities in the benchmarks (i.e., there are no false negatives), but reports 72% false positives. The third stage of our approach, the guided dynamic analysis, can prioritize warnings according to whether it finds a concrete input triggering the vulnerability within a given timeframe, but cannot prove a warning to be false positive. The imprecise widening (c.f., Section 3.1) in our implementation caused the majority of false positives. Another source of false positives are weak updates of memory regions. Time and space usage of the static analysis are relatively modest. The figures shown in Table <ref type="table" target="#tab_2">1</ref> are for analyzing a VPA read from disk; VPA construction takes an additional second or two per trace.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Dynamic Analysis</head><p>We next applied the dynamic analysis to confirm one of the true positive static analysis warnings for each of the benchmarks. When there are multiple true positives from static analysis, we report the results for one selected uniformly at random. We obtained similar results when repeating the dynamic analysis with other true positives, as expected given that the warnings relate to a single underlying bug. The symbolic input in each benchmark is a bounded-size character buffer. The dynamic tool produced test cases proving the existence of bugs in all but one of the programs. The guidance from static analysis made the tool more efficient and helped it find bugs it otherwise could not.</p><p>The dynamic analysis results, shown in the right-hand side of Table 1, demonstrate that static-based guidance is a significant advantage. The benchmarks vary significantly in difficulty for symbolic execution. On the easier benchmarks, guidance often improved both the running time and the number of whole-program paths explored (iterations). Guidance sometimes increases the average time per iteration. Often, our loop pattern heuristic picks paths with many loop iterations necessary for triggering vulnerabilities, but in the S2 benchmark such paths are also more expensive. Thus, although the total number of iterations is smaller, the overall time cost is higher. The unguided search explored many paths that were both unproductive and short. The cost of using heuristics during execution is negligible; the reported times include pre-computation of quantities such as distance which required only a fraction of a second. On the more difficult benchmarks, guidance can make the difference between success and failure, as seen in S1, S5, and S6. S6 is a buffer overflow caused by an integer overflow: by directing exploration to consider a long sequence of digits, our guidance leads in under 12 seconds to an overflow that undirected execution failed to find even in 6 hours. S1 and S5 contain loops similar to the example in Figure <ref type="figure" target="#fig_6">6</ref>, in which a particular pattern of loop paths, corresponding to a repeating pattern in the input, is needed to cause a pointer to overflow a buffer. (S3 is similar to S1 and S5, but the heuristic is not effective because the loop spans several functions.) The instruction coverage of the dynamic analysis was usually very similar between the undirected and directed runs, differing by just 1-2%. The only large difference was for S7, when the directed run covered about 40% of the unique instructions versus 60% for the undirected run. This confirms, as also visible in the iteration count, that the directed dynamic analysis finds the vulnerability more quickly because it avoids exploring irrelevant parts of the state space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bmarks.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instrs. Static analysis Undirected dynamic analysis Directed dynamic analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RELATED WORK</head><p>Static Analysis of Binaries. Our static analysis is similar to Balakrishnan and Reps's work <ref type="bibr" target="#b3">[3]</ref>, with a few differences discussed in Section 3. Kinder et al. <ref type="bibr" target="#b27">[27]</ref> explain the "chicken-and-egg" nature of the problem of inferring the control-flow of binaries statically: data-flow analysis is required to infer the control-flow information, and control-flow analysis is required to infer the data-flow information. They combine data-and control-flow analysis and compute a safe approximation of the control-flow. In practice, it is easy to construct examples that defeat the static approach, because even distinguishing CISC assembly instructions from data is a difficult task <ref type="bibr" target="#b42">[42]</ref>. We chose a different tradeoff -to use dynamic analysis with static augmentation only for branches we are certain we can resolve precisely. More exploration is needed to reach a definite conclusion on the comparative merits of the two approaches.</p><p>Guiding the Search. Improvements in the efficiency of search over the state space have been an active research area in verification and testing of protocols and software. In the context of protocol model checking, Yang and Dill <ref type="bibr" target="#b48">[48]</ref> used Hamming distance of states as a greedy best-first-search metric in their Murφ model checker. They compute several pre-images of the negated properties -the process they call target enlargement -and then compare every visited state to the enlarged target. We could apply similar enlargement to targets identified by static analysis, but it remains unclear how enlargement would help with alternating paths within SCCs. Edelkmap et al. <ref type="bibr" target="#b18">[18]</ref> studied several heuristics. They used an approximate distance function to a state where a given LTL formula holds and found that A * search worked best on their protocol benchmarks. We experimented with approaches similar to A * in our domain, but it appeared difficult to determine an appropriate state-ranking function automatically. Godefroid and Khurshid <ref type="bibr" target="#b20">[20]</ref> propose using genetic algorithms for finding errors in large state spaces, focusing specifically on heuristics for deadlock detection and property violations related to enabledness of transitions and message exchanges. Our heuristics are more tailored towards finding buffer overflows, especially in cases with multiple nested loops and multiple paths through the loop body.</p><p>Lal et al. <ref type="bibr" target="#b29">[29]</ref> studied construction of minimal length explanations of crashes (produced by concrete traces) having only partial information about the trace. Their goal is to find a minimal length path passing through a maximal number of observed check-points in the code. In our setting, the data-flow slice produced by static analysis can be seen as partial information about the trace (we don't take control-flow dependencies into account), but we use that information only heuristically and do not attempt to maximize the number of statements from the slice on the path. Their algorithm is exponential in the number of check-points. Since we have only one check-point (i.e., the target), the exponent disappears and our algorithm can be seen as a special case of theirs.</p><p>Groce and Visser describe heuristics for finding property violations with the Java PathFinder model checker <ref type="bibr" target="#b22">[22]</ref>, based on branch coverage and thread inter-dependencies. Burnim and Sen <ref type="bibr" target="#b8">[8]</ref> focus on achieving high line coverage and present several control-flow guided search heuristics, including one that is based on CFG distances but does not include matching of calls and returns. Achieving high line coverage was not sufficient to trigger vulnerabilities in our benchmark suite. Further, without guidance provided by the static analysis and special heuristics for strongly connected components, we were unable to hit vulnerabilities in a number of more difficult benchmarks. Saxena et al.'s loop-extended symbolic execution <ref type="bibr" target="#b41">[41]</ref> uses an abstract interpretation over traces and a known in-put grammar to improve the performance of symbolic execution on binary programs containing buffer overflows. Given an input that differs from an exploit input only in the length or number of repetitions of a grammar construct, they compute the iteration count that causes an overflow. By contrast our loop exploration heuristic is focused on finding the vulnerable path through a single iteration; in our experience any sufficiently large number of iterations is then enough to demonstrate the overflow. Rybalchenko and Singh <ref type="bibr" target="#b40">[40]</ref> propose subsumer-first heuristic to steer symbolic reachability analysis of benchmarks from the transportation domain. Their heuristic is very intuitive: it prefers larger (according to subsumption ordering) states, greedily trying to get to a state large enough to contain the error state. Their technique could be classified as a look-back, while ours exploits static analysis and is inherently a look-ahead technique. We experimented with several state orderings, and were unable to get them to work. Subsumption ordering would be prohibitively expensive in our setting, as path conditions, describing states, can be large.</p><p>Hybrid Static-Dynamic Analysis. The Synergy algorithm <ref type="bibr" target="#b23">[23]</ref> combines model-checking and DART <ref type="bibr" target="#b21">[21]</ref> to try to cover all abstract states of a program. Our work has no ambition to produce proofs, and we expect that our approach could be used to improve the performance of the DART part of Synergy and other algorithms that use test generation as a component. DSD-Crasher <ref type="bibr" target="#b15">[15]</ref> more closely resembles our work in performing dynamic, static, and dynamic analysis in sequence, though the stages are quite different. The closest point of comparison is that DSD-Crasher generates constraints via static analysis and solves them to create dynamic test cases, whereas our second dynamic analysis incorporates both constraint generation and solving.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">LIMITATIONS AND FUTURE WORK</head><p>The first, and the most obvious, limitation is that the completeness of the VPA constructed in the first stage depends on the capability of the seed tests to exercise indirect jumps (or calls). One possible solution would be to use completely static analysis to construct the VPA (e.g., <ref type="bibr" target="#b27">[27]</ref>). Unfortunately, sometimes in practice assembly instructions cannot even be decoded statically, as varying sizes of CISC assembly instructions make the instructions and data difficult to distinguish. Further, static analysis of binaries is inherently imprecise. Another possibility is to use DART or our three-stage approach in a loop for discovering concrete inputs and using them instead of the seed tests.</p><p>The second limitation of our approach is the precision of our static analysis. Currently, our implementation context-sensitively follows all calls in a brute-force manner and does not use function summaries or k-sensitivity <ref type="bibr" target="#b43">[43]</ref>. Such an approach is unlikely to scale to very large applications, and we are planning to explore less precise and more efficient approaches (summaries, k-sensitivity, context-insensitive analysis). A less precise analysis would probably produce more warnings, decreasing the precision of the guiding information provided to the third stage of our approach. The number of warnings produced by a context-insensitive analysis could be reduced by extending the analysis with aggregate structure identification <ref type="bibr" target="#b36">[36]</ref>, affine-relation analysis <ref type="bibr" target="#b33">[33]</ref>, and recency-abstraction <ref type="bibr" target="#b4">[4]</ref>, as in <ref type="bibr" target="#b3">[3]</ref>, but it is obvious that the tradeoff between the precision of the static analysis and computed guidance information requires significantly more research.</p><p>The third, more subtle, limitation of our approach is a possible overfitting of the guidance heuristic to our set of benchmarks and the vulnerabilities (buffer overflows) we are looking for. Design of heuristics is inherently prone to overfitting and designing robust heuristics is a tedious time-consuming task. For example, it took the SAT solving community almost 30 years ( <ref type="bibr" target="#b13">[13]</ref>- <ref type="bibr" target="#b32">[32]</ref>) to come up with effective robust decision heuristics, and they are still being improved. Our paper is a step forward in developing robust dynamic test generation guidance heuristics, but obviously, much more work remains to be done.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSIONS</head><p>We have presented an approach that applies dynamic analysis, static analysis, and dynamic analysis again to explore the large path space of programs given a binary. The analysis revolves around a visibly pushdown automaton (VPA) which represents the programs global control flow structure. Starting with dynamic analysis helps resolving indirect jumps, and the static analysis helps symbolic execution direct exploration towards vulnerabilities based on the shortest paths and loop pattern heuristics. In preliminary experiments, our static analysis finds all of the vulnerabilities in the suite, and dynamic analysis constructs test inputs for all but one.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Operations on Value Sets. The ⊕ symbol stands for a unary, and ⊗ for a binary operation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>lh(x) ⊔ y (b) Misaligned Overlap.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Chunking of Overlapping Addresses. The top rectangle in each figure represents the contents (denoted x) of a weakly updatable region at addresses shown above the rectangle. The addresses are 4[1000, 1012] in (a) and 4[1000, 1008] in (b). The dotted lines represent strides, while full lines represent chunk boundaries. The middle rectangle in each figure represents the newly written data (denoted y). The bottom rectangle represents the contents of the region after write. In (a), the region is split into three aligned chunks. In (b), the region is split into four chunks: chunk 4[1000, 1004] that maintains the old value x, a smaller chunk 2[1004, 1006] that contains the upper half (uh) of x, another chunk 2[1006, 1008] containing a join of the lower half (lh) of x and of y, and finally 2[1008, 1014] containing the newly written data y. Lower and upper halves can be computed using shift and mask operations on strided intervals. Other cases, like writing a single byte in the middle of a double word can be handled similarly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Computation of Shortest Paths on a VPA. The left figure illustrates the shortest well-matched path from f 0 to f 3 , highlighted in gray. The right figure shows the combined graph G RC used for computing shortest distances over the language of calls and returns (R|W ) * (C |W ) * . Each function is enclosed in a grey rectangle with the name of the function at the top. Internal edges (with implicit weight 1) are denoted . Call (resp. return) edges are denoted (resp. ). The edge connects matching call and return nodes, connects G R and G C call sites, and represents the summary edges whose weight is the shortest path through the callee.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: NFA To Constrain a VPA Path. A general VPA path, with no mis-matched calls and returns, is a concatenation of unmatched returns R, unmatched calls C , and well-matched words W , with the restriction that the unmatched returns precede the unmatched calls.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>the source and a node from G C as the target. This construction is shown in Algorithm 3, and demonstrated graphically in Figure4.b.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: An example loop for which a repeating pattern of paths (here, alternating between paths 1 and 3) is required to cause an overflow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>R and b ′′ ← b,C 4: add nodes b ′ and b ′′ to G RC 5: for e ∈ edges of VPA do</figDesc><table><row><cell>6: 7:</cell><cell>let s ← source(e) and t ← target(e) if e is call edge then</cell></row><row><cell>8: 9:</cell><cell>let w ← the length of the shortest path to return from t and r ← the node where t returns add edges s,C</cell></row></table><note><p><p>0 -→ t,C , s, R 0 -→ s,C , s, R w -→ r,</p>R , and s,C w -→ r,C to G RC 10: else if e is a return edge then 11: add edge s, R 0 -→ t, R to G RC 12: else if e is an internal edge of weight w then 13: add edges s, R w -→ t, R and s,C w -→ t,C to G RC 14: D ← Dijkstra(G RC , t w , R ) 15: for s ∈ nodes of VPA do 16: s.d ← D[ s,C ]</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 : Summary of the Experimental Results. The first section of the table lists the benchmarks, the second section shows the size of the benchmarks in machine instructions, and the third section shows the results of the static analysis. The fourth and fifth sections show the results of dynamic test generation, where the directed analysis used the static analysis results for a randomly selected true positive, while the undirected analysis had no such information. The dynamic analysis results are averages over five runs with different random seeds. "Iterations" counts the number of whole-program executions generated until finding a bug-revealing one, while the † symbol indicates the analysis could not trigger the bug within six hours.</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="7">App. libc Warns. Bugs False pos. Time (s) Mem. (Kb) Iterations</cell><cell cols="2">Time (s) Iterations</cell><cell>Time (s)</cell></row><row><cell>BIND</cell><cell cols="2">B1 1705 2120 B2 1290 2178 B3 719 3058</cell><cell>15 22 14</cell><cell>1 1 1</cell><cell>14 21 13</cell><cell>3.3 3.2 14.2</cell><cell>46000 50416 80768</cell><cell>54 137 9</cell><cell>2.8 13.3 1.6</cell><cell>20 72 4</cell><cell>3.6 25.1 2.6</cell></row><row><cell></cell><cell>B4</cell><cell>394 3621</cell><cell>40</cell><cell>2</cell><cell>38</cell><cell>29.2</cell><cell>320480</cell><cell>1</cell><cell>1.9</cell><cell>1</cell><cell>2.0</cell></row><row><cell>Sendmail</cell><cell>S1 S2 S3 S4 S5 S6 S7</cell><cell>929 2021 524 2750 318 1653 370 2447 392 1282 595 2247 957 2595</cell><cell cols="2">33 28 28 2 14 3 20 7 10 3 6 1 42 2</cell><cell>5 26 11 13 7 5 40</cell><cell>24.9 20.2 1.6 10.6 1.2 3.2 15.4</cell><cell>95472 79824 33216 57808 18880 40112 142208</cell><cell>† 16  † 3  †  † 56</cell><cell>† 2.9  † 19.0  †  † 6.9</cell><cell>3347 8  † 1 332 86 46</cell><cell>2990.6 66.1  † 9.1 202.6 11.3 8.8</cell></row><row><cell>WU Ftpd</cell><cell>F1 F2 F3</cell><cell>571 1561 807 2549 684 1639</cell><cell cols="2">11 13 37 27 4 1</cell><cell>7 12 10</cell><cell>1.1 5.8 7.5</cell><cell>30448 53632 78624</cell><cell>309 1455 143</cell><cell>8.1 65.8 60.0</cell><cell>11 11 18</cell><cell>1.1 1.4 11.6</cell></row><row><cell></cell><cell></cell><cell>Total</cell><cell cols="2">305 83</cell><cell cols="2">222 141.4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Note that unlike the prior work, we make the upper bound exclusive. We found this definition of strided intervals to be somewhat more convenient for dealing with misaligned reads and writes, which are frequent in binary</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>code.<ref type="bibr" target="#b3">3</ref> Negative addresses are often used to index the stack frame of the currently executed function.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"> *   <p>This work was partially supported by the NSF under grants 0832943, 0842694, 0842695, 0831501, and 0424422, by the AFRL under grant P010071555, and by the MURI program under ONR grant N000140911081 and AFOSR grants FA9550-08-1-0352 and FA9550-09-1-0539. The first author is also supported by the NSERC (Canada) PDF fellowship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adding nesting structure to words</title>
		<author>
			<persName><forename type="first">R</forename><surname>Alur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Madhusudan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2009-05">May 2009</date>
		</imprint>
	</monogr>
	<note>Article 16</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Analyzing memory accesses in x86 executables</title>
		<author>
			<persName><forename type="first">G</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Reps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Compiler Construction</title>
		<meeting>of the Int. Conf. on Compiler Construction</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="5" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">WYSINWYX: What you see is not what you eXecute</title>
		<author>
			<persName><forename type="first">G</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Reps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Program. Lang. Syst</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2010-08">August 2010</date>
		</imprint>
	</monogr>
	<note>Article 23</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Recency-abstraction for heap-allocated storage</title>
		<author>
			<persName><forename type="first">G</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Reps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Symp. on Static Analysis</title>
		<meeting>of the Int. Symp. on Static Analysis</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4134</biblScope>
			<biblScope unit="page" from="221" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic predicate abstraction of C programs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Millstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Rajamani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conf. on Programming Language Design and Implementation</title>
		<meeting>of the Conf. on Programming Language Design and Implementation</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="203" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automatic generation of random self-checking test cases</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">U</forename><surname>Munoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM System Journal</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="229" to="245" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatically identifying trigger-based behavior in malware</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brumley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hartwig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Newsome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Botnet Detection</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="65" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Heuristics for scalable dynamic test generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Burnim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Automated Software Engineering</title>
		<meeting>of the Int. Conf. on Automated Software Engineering</meeting>
		<imprint>
			<publisher>IEEE Comp. Soc</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="443" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">KLEE: unassisted and automatic generation of high-coverage tests for complex systems programs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cadar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dunbar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Engler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conf. on Operating Systems Design and Implementation</title>
		<meeting>of the Conf. on Operating Systems Design and Implementation</meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="209" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">EXE: automatically generating inputs of death</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cadar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Pawlowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Dill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Engler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conf. on Computer and Communications Security</title>
		<meeting>of the Conf. on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="322" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Analysis of pointers and structures</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Chase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wegman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Zadeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conf. on Programming Language Design and Implementation</title>
		<meeting>of the Conf. on Programming Language Design and Implementation</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="296" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Model checking</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grumberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Peled</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The complexity of theorem-proving procedures</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Symp. on Theory of Computing</title>
		<meeting>of the Symp. on Theory of Computing</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cousot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cousot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Symp. on Principles of Programming Languages</title>
		<meeting>of the Symp. on Principles of Programming Languages</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1977">1977</date>
			<biblScope unit="page" from="238" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">DSD-Crasher: a hybrid analysis tool for bug finding</title>
		<author>
			<persName><forename type="first">C</forename><surname>Csallner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Smaragdakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Symp. on Software Testing and Analysis</title>
		<meeting>of the Int. Symp. on Software Testing and Analysis</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="245" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Z3: An efficient SMT solver</title>
		<author>
			<persName><forename type="first">L</forename><surname>De Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bjørner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Tools and Algorithms for the Construction and Analysis of Systems</title>
		<meeting>of the Int. Conf. on Tools and Algorithms for the Construction and Analysis of Systems</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">4963</biblScope>
			<biblScope unit="page" from="337" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A note on two problems in connexion with graphs</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Dijkstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numerische Mathematik</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="269" to="271" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Directed explicit-state model checking in the validation of communication protocols</title>
		<author>
			<persName><forename type="first">S</forename><surname>Edelkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lluch-Lafuente</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Softw. Tools Technol. Transf</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="247" to="267" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Associative-commutative rewriting on large terms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Eker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Rewriting Techniques and Applications</title>
		<meeting>of the Int. Conf. on Rewriting Techniques and Applications</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="14" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploring very large state spaces using genetic algorithms</title>
		<author>
			<persName><forename type="first">P</forename><surname>Godefroid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Khurshid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Softw. Tools Technol. Transf</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="117" to="127" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">DART: directed automated random testing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Godefroid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Klarlund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conf. on Programming Language Design and Implementation</title>
		<meeting>of the Conf. on Programming Language Design and Implementation</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="213" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Heuristic model checking for Java programs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Groce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Visser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. SPIN Workshop on Model Checking of Software</title>
		<meeting>of the Int. SPIN Workshop on Model Checking of Software</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="242" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">SYNERGY: a new algorithm for property checking</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Gulavani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Henzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Rajamani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Symp. on Foundations of Software Engineering</title>
		<meeting>of the Int. Symp. on Foundations of Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="117" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Hex-Rays. IDAPro disassembler</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Design and Validation of Computer Protocols</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Holzmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Prentice-Hall, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">ISO C standard 1999</title>
		<author>
			<persName><surname>Iso</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>ISO</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An abstract interpretation-based framework for control flow reconstruction from binaries</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zuleger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Veith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Verification, Model Checking, and Abstract Interpretation</title>
		<meeting>of the Int. Conf. on Verification, Model Checking, and Abstract Interpretation</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5403</biblScope>
			<biblScope unit="page" from="214" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Symbolic execution and program testing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="385" to="394" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Path optimization in programs and its application to debugging</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Polishchuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liblit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Eur. Symp. on Programming Languages and Systems</title>
		<meeting>of the Eur. Symp. on Programming Languages and Systems</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="246" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Detecting conflicts between structure accesses</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Larus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Hilfinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conf. on Programming Language Design and Implementation</title>
		<meeting>of the Conf. on Programming Language Design and Implementation</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="24" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">PIN: Building customized program analysis tools with dynamic instrumentation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Muth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Klauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lowney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hazelwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conf. on Programming Language Design and Implementation</title>
		<meeting>of the Conf. on Programming Language Design and Implementation</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="190" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">GRASP: A search algorithm for propositional satisfiability</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Marques-Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Sakallah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="506" to="521" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Analysis of modular arithmetic</title>
		<author>
			<persName><forename type="first">M</forename><surname>Müller-Olm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Seidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Program. Lang. Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Principles of Program Analysis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nielson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Nielson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hankin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Red-black trees in a functional setting</title>
		<author>
			<persName><forename type="first">C</forename><surname>Okasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Functional Programming</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="471" to="477" />
			<date type="published" when="1999-07">July 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Aggregate structure identification and its application to program analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ramalingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Field</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Symp. on Principles of Programming Languages</title>
		<meeting>of the Symp. on Principles of Programming Languages</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="119" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Intermediate-representation recovery from low-level code</title>
		<author>
			<persName><forename type="first">T</forename><surname>Reps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Symp. on Partial Evaluation and Semantics-based Program Manipulation</title>
		<meeting>of the Symp. on Partial Evaluation and Semantics-based Program Manipulation</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="100" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Precise interprocedural dataflow analysis via graph reachability</title>
		<author>
			<persName><forename type="first">T</forename><surname>Reps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Horwitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sagiv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Symp. on Principles of Programming Languages</title>
		<meeting>of the Symp. on Principles of Programming Languages</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="49" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Weighted pushdown systems and their application to interprocedural dataflow analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Reps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schwoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Melski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Comput. Program</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="206" to="263" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Subsumer-first: Steering symbolic reachability analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rybalchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. SPIN Workshop on Model Checking Software</title>
		<meeting>of the Int. SPIN Workshop on Model Checking Software</meeting>
		<imprint>
			<biblScope unit="page" from="192" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Loop-extended symbolic execution on binary programs</title>
		<author>
			<persName><forename type="first">P</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Poosankam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccamant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Symp. on Software Testing and Analysis</title>
		<meeting>of the Int. Symp. on Software Testing and Analysis</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="225" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Disassembly of executable code revisited</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Debray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Andrews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Working Conference on Reverse Engineering</title>
		<meeting>of the Working Conference on Reverse Engineering</meeting>
		<imprint>
			<publisher>IEEE Comp. Soc</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="45" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Two approaches to interprocedural data flow analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sharir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pnueli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Program Flow Analysis: Theory and Applications</title>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="189" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">BitBlaze: A new approach to computer security via binary analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brumley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Jager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Newsome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Poosankam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Saxena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Information Systems Security</title>
		<meeting>of the Int. Conf. on Information Systems Security</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5352</biblScope>
			<biblScope unit="page" from="1" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A survey of program slicing techniques</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CWI (Centre for Mathematics and Computer Science)</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<pubPlace>Amsterdam, The Netherlands</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Hacker&apos;s Delight</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Warren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Program slicing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Software Engineering</title>
		<meeting>of the Int. Conf. on Software Engineering</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="439" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Validation with guided search of the state space</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Dill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Design Automation Conference</title>
		<meeting>of the Annual Design Automation Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="599" to="604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Testing static analysis tools using exploitable buffer overflows from open source code</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zitser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lippmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Symp. on Foundations of Software Engineering</title>
		<meeting>of the Int. Symp. on Foundations of Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="97" to="106" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
