<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Decoding Random Binary Linear Codes in 2 n/20 : How 1 + 1 = 0 Improves Information Set Decoding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Anja</forename><surname>Becker</surname></persName>
							<email>anja.becker@prism.uvsq.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Université de Versailles Saint-Quentin</orgName>
								<address>
									<country>Laboratoire PRISM</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Antoine</forename><surname>Joux</surname></persName>
							<email>antoine.joux@m4x.org</email>
							<affiliation key="aff0">
								<orgName type="institution">Université de Versailles Saint-Quentin</orgName>
								<address>
									<country>Laboratoire PRISM</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">DGA</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexander</forename><surname>May</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Ruhr-University Bochum</orgName>
								<orgName type="institution" key="instit2">Horst Görtz Institute for IT-Security</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexander</forename><surname>Meurer</surname></persName>
							<email>alexander.meurer@rub.de</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Ruhr-University Bochum</orgName>
								<orgName type="institution" key="instit2">Horst Görtz Institute for IT-Security</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Excellence Initiative [DFG GSC 98</orgName>
								<orgName type="institution">Ruhr-University Research School</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Decoding Random Binary Linear Codes in 2 n/20 : How 1 + 1 = 0 Improves Information Set Decoding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8D9D23A220F55B46A6A46792EEFEFCB3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Information Set Decoding, Representation Technique</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Decoding random linear codes is a well studied problem with many applications in complexity theory and cryptography. The security of almost all coding and LPN/LWE-based schemes relies on the assumption that it is hard to decode random linear codes. Recently, there has been progress in improving the running time of the best decoding algorithms for binary random codes. The ball collision technique of Bernstein, Lange and Peters lowered the complexity of Stern's information set decoding algorithm to 2 0.0556n . Using representations this bound was improved to 2 0.0537n by May, Meurer and Thomae. We show how to further increase the number of representations and propose a new information set decoding algorithm with running time 2 0.0494n .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The NP-hard problem of decoding a random linear code is one of the most promising problems for the design of cryptosystems that are secure even in the presence of quantum computers. Almost all code-based cryptosystems, e.g. McEliece, rely on the fact that random linear codes are hard to decode. In order to embed a trapdoor in codingbased cryptography one usually starts with a well-structured secret code C and linearly transforms it into a code C that is supposed to be indistinguishable from a random code.</p><p>An attacker has two options. Either he tries to distinguish the scrambled version C of C from a random code by revealing the underlying structure, see <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b27">28]</ref>. Or he directly tries to run a generic decoding algorithm on the scrambled code C . Also closely related to random linear codes is the learning parity with noise (LPN) problem that is frequently used in cryptography <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17]</ref>. In LPN, one directly starts with a random linear code C and the LPN search problem is a decoding problem in C. It was shown in <ref type="bibr" target="#b26">[27]</ref> that the popular LPN decision variant, a very useful tool for many cryptographic constructions, is equivalent to the LPN search problem, and thus equivalent to decoding a random linear code. The LWE problem of Regev <ref type="bibr" target="#b26">[27]</ref> is a generalization of LPN to codes over a larger field. Our decoding algorithm could be adjusted to work for these larger fields (similar to what was done in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26]</ref>). Since the decoding problem lies at the the heart of coding-based and LPN/LWE-based cryptography it is necessary to study its complexity in order to define proper security parameters for cryptographic constructions.</p><p>Let us start by providing some useful notation. A binary linear code C is a k-dimensional subspace of F n 2 where n is called the length of the code and R := k n is called its rate. A random k-dimensional linear code C of length n can be defined as the kernel of a random full-rank matrix H ∈ R F (n-k)×n 2 , i.e. C = {c ∈ F n 2 | Hc t = 0 t }. The matrix H is called a parity check matrix of C. For ease of presentation, we use the convention that all vectors are column vectors which allows as to omit all transpositions of vectors.</p><p>The distance d of a linear code is defined by the minimal Hamming distance between two codewords. Hence every vector x whose distance to the closest codeword c ∈ C is at most the error correction capacity ω = d-1 2 can be uniquely decoded to c. For any point x = c + e ∈ F n 2 that differs from a codeword c ∈ C by an error vector e, we define its syndrome as s(x) := Hx = H(c + e) = He. Hence, the syndrome only depends on the error vector e and not on the codeword c. The syndrome decoding problem is to recover e from s(x). This is equivalent to decoding in C, since the knowledge of e suffices to recover c from x.</p><p>Usually in cryptographic settings the Hamming weight of e is smaller than the error correction capability, i.e. wt(e) ≤ ω = d-1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>, which ensures unique decoding. This setting is also known as half/bounded distance decoding. All known half distance decoding algorithms achieve their worst case behavior for the choice wt(e) = ω. As a consequence we assume wt(e) = ω throughout this work. In complexity theory, one also studies the so-called full decoding where one has to compute a closest codeword to a given arbitrary vector x ∈ F n 2 . We also give the complexity of our algorithm for full decoding, but in the following we will focus on half-distance decoding.</p><p>The running time of decoding algorithms for linear codes is a function of the three code parameters [n, k, d]. However, with overwhelming probability random binary linear codes attain a rate R := k n which is close to the Gilbert Varshamov bound 1 -H( d n ) <ref type="bibr" target="#b9">[10]</ref>. Therefore, we can express the running time T (n, R) as a function in n, R only. One usually measures the complexity of decoding algorithms asymptotically in the code length n. Since all generic decoding algorithms run in exponential time, a reasonable metric is the complexity coefficient F (R) as defined in <ref type="bibr" target="#b8">[9]</ref>, i.e. F (R) = lim n→∞ 1 n log T (n, R) which suppresses polynomial factors since lim 1 n log p(n) = 0 for any polynomial p(n). Thus, we have T (n, R) = 2 nF (R)+o(n) ≤ 2 n F (R) ρ for large enough n. We obtain the worst-case complexity by taking max 0&lt;R&lt;1 F (R) ρ . Here, x ρ := x • 10 ρ • 10 -ρ denotes rounding up x ∈ R to a certain number of ρ ∈ N decimal places.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work.</head><p>In syndrome decoding one has to compute e from s(x), which means that one has to find a weight-ω linear combination of the columns of H that sums to the syndrome s(x) over F n-k 2 . Thus, a brute-force algorithm would require to compute n ω column sums. Inspired by the work of Prange <ref type="bibr" target="#b24">[25]</ref>, it was already mentioned in the original work of McEliece <ref type="bibr" target="#b21">[22]</ref> and later more carefully studied by Lee and Brickell <ref type="bibr" target="#b18">[19]</ref> that the following approach, called information set decoding, yields better complexity.</p><p>Information set decoding basically proceeds in two steps, an initial transformation step and a search step. Both steps are iterated in a loop until the algorithm succeeds. The initial transformation step starts by randomly permuting the columns of H. In particular, this permutes the ω columns of H that sum to s(x), and thus permutes the coordinates of e. Then we apply Gaussian elimination on the rows of H in order to obtain a systematic form</p><formula xml:id="formula_0">(Q | I n-k ), where Q ∈ F (n-k)×k 2</formula><p>and I n-k is the (nk)-dimensional identity matrix. The Gaussian elimination operations are also applied to s(x) which results in s(x).</p><p>Let us fix an integer p &lt; ω. In the search step, we compute for every linear combination of p columns from Q its Hamming distance to s(x). If the distance is exactly ωp then can we add to our p columns those ωp unit vectors from I n-k that exactly yield s(x). Undoing the Gauss elimination recovers the desired error vector e. Obviously, information set decoding can only succeed if the initial column permutation results in a permuted e that has exactly p ones in its first k coordinates and ωp ones in its last nk coordinates. Optimization of p leads to a running time of 2 0.05752n .</p><p>Leon <ref type="bibr" target="#b19">[20]</ref> and Stern <ref type="bibr" target="#b29">[30]</ref> observed in 1989 that one can improve on the running time when replacing in the search step the brute-force search for weight-p linear combinations by a Meet-in-the-middle approach. Let us fix an integer &lt; nk and let us project (Q | I n-k ) to its first rows. We split the projection of Q into two matrices Q 1 , Q 2 each having k 2 columns. Then we create two lists L 1 , L 2 that contain all weight-p 2 linear combinations of columns from Q 1 and Q 2 , respectively. Moreover, we add the projection of s(x) to every element in L 2 and sort the resulting list.</p><p>Then we search for matching elements from L 1 and L 2 . These elements define weight-p sums of vectors from Q that exactly match s(x) in its first coordinates. As before, if the remaining coordinates differ from s(x) by a weight-(ωp) vector, then we can correct these positions by suitable unit vectors from I n-k . The running time of this algorithm is 2 0.05564n .</p><p>The ball collision technique of Bernstein, Lange and Peters <ref type="bibr" target="#b4">[5]</ref> lowers this complexity to 2 0.05559n by allowing a non-exact matching of the elements of L 1 and L 2 . The same asymptotic complexity can be achieved by transforming H into (Q</p><formula xml:id="formula_1">| 0 I n-k-) with Q ∈ F (n-k)×(k+ ) 2</formula><p>, as proposed by Finiasz and Sendrier <ref type="bibr" target="#b11">[12]</ref>. The lists L 1 , L 2 then each contain all weight-p 2 sums out of k+ 2 columns. The asymptotic analysis of this variant can be found in <ref type="bibr" target="#b22">[23]</ref>.</p><p>Notice that finding a weight-p sum of columns of Q that exactly matches s(x) in coordinates is a vectorial version of the subset sum problem in F 2 . This vectorial version was called the column match problem by May, Meurer and Thomae (MMT) <ref type="bibr" target="#b22">[23]</ref>, who adapted the subset sum representation technique from Howgrave-Graham and Joux <ref type="bibr" target="#b14">[15]</ref> to the column match problem.</p><formula xml:id="formula_2">Let Q ∈ F (n-k)×(k+ ) 2</formula><p>be as before, where q 1 , . . . , q k+ denote the columns of Q. A Meet-in-the-Middle approach matches the first coordinates via the identity</p><formula xml:id="formula_3">i∈I1 q i = i∈I2 q i + s(x) ,<label>(1)</label></formula><p>where</p><formula xml:id="formula_4">I 1 ⊂ 1, k+ 2 , I 2 ⊂ k+ 2 + 1, k + and |I 1 | = |I 2 | = p 2 .</formula><p>Using the representation technique, one chooses I 1 and I 2 no longer from half-sized intervals but they both are chosen from the whole interval <ref type="bibr">[1, k+ ]</ref> such that I 1 ∩I 2 = ∅. Thus, every solution I admits p p/2 representations I = I 1 ∪ I 2 . Notice that increasing the range of I 1 , I 2 also increases the size of the lists L 1 and L 2 from (k+ )/2 p/2 to k+ p/2 . But constructing only a p p/2 -1 -fraction of each list suffices to let a single representation of the solution survive on expectation. This approach leads to an algorithm which runs in time 2 0.05364n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our Contribution. We propose to choose |I</head><formula xml:id="formula_5">1 | = |I 2 | = p 2 + ε for some ε &gt; 0 such that |I 1 ∩ I 2 | = ε.</formula><p>So we allow for ε columns q i that appear on both sides of identity (1). Thus every solution I is written as the symmetric difference</p><formula xml:id="formula_6">I = I 1 ΔI 2 := I 1 ∪ I 2 \ (I 1 ∩ I 2 )</formula><p>, where we cancel out all ε elements in the intersection of I 1 and I 2 .</p><p>Let us compare our approach with the realization of the search step in the algorithms of Stern <ref type="bibr" target="#b29">[30]</ref> and MMT <ref type="bibr" target="#b22">[23]</ref>. In Stern's algorithm both index sets I 1 , I 2 are chosen in a disjoint fashion. Thus every solution I only has a unique representation as the union of I 1 and I 2 . MMT choose fully intersecting sets I 1 , I 2 , but they only consider a union of disjoint sets I 1 , I 2 . Basically, this allows that every of the p elements in I = I 1 ∪ I 2 can appear either as an element of I 1 or as an element of I 2 , so it can appear on both sides of identity <ref type="bibr" target="#b0">(1)</ref>.</p><p>In contrast, we choose fully intersecting sets I 1 , I 2 and additionally allow for a union of intersecting sets. Thus, we additionally allow that even those k +p elements that are outside of I = I 1 ∪ I 2 may appear in I 1 , I 2 as long as they appear in both sets, and thus cancel out. This drastically increases the number of representations, since for random code instances the number of zeros in an error vector e is much larger than the number of ones. Whereas MMT only allow to split each 1-entry of e into two parts, either 1 = 0+1 or 1 = 1+0, we also allow to split each 0-entry of e into two parts, either 0 = 0 + 0 or 0 = 1 + 1. Hence our benefit comes from using the equation 1 + 1 = 0 in F 2 . Notice that our approach therefore increases the number of representation per solution I to p p/2 • k+ -p . Our main algorithmic task that we describe in this work is the construction of two lists L 1 , L 2 such that a single representation of each solution survives. This is realized by a three-level divide-and-conquer algorithm that is similar to Wagner's generalized birthday algorithm <ref type="bibr" target="#b30">[31]</ref>.</p><p>Our enhanced representation technique allows us to significantly lower the asymptotic running time to 2 0.04934n . The following figure shows the curve of the complexity coefficient for the two most recent algorithms <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b22">23]</ref> compared to our new algorithm. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Generalized Information Set Decoding</head><p>We now give a detailed description of a generalized information set decoding (ISD) framework as described by Finiasz and Sendrier <ref type="bibr" target="#b11">[12]</ref> in 2009. Recall that the input to an ISD algorithm is a tuple (H, s) where</p><formula xml:id="formula_7">H ∈ F (n-k)×n 2</formula><p>is a parity check matrix of a random linear [n, k, d]-code and s = He is the syndrome of the unknown error vector e of weight ω := wt(e) = d-1 2 . ISD is a randomized Las Vegas type algorithm that iterates two steps until the solution e is found. The first step is an initial linear transformation of the parity check matrix H, followed by a search phase as the second step.</p><p>In the initial transformation, we permute the columns of H by multiplying with a random permutation matrix P ∈ F n×n 2 . Then we perform Gaussian elimination on the rows of HP by multiplying with an invertible matrix T ∈ F</p><formula xml:id="formula_8">(n-k)×(n-k) 2</formula><p>. This yields a parity check matrix H = THP in quasi-systematic form containing a 0-submatrix in the right upper corner as illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>. Here we denote by Q I the projection of Q to the rows defined by the index set I ⊂ {1, . . . , n -k}. Analogously, we denote by Q I the projection of Q to its columns. In particular we define [ ] := {1, . . . , } and [ , nk] = { , . . . , n -k}. We denote the initial transformation Init(H) := THP.</p><p>We set s := Ts and look for an ISD-solution ẽ of ( H, s), i.e. we look for an ẽ satisfying Hẽ = s and wt(ẽ) = ω. This yields a solution e = Pẽ for the original problem. Notice that applying the permutation matrix to ẽ leaves the weight unchanged, i.e. wt(e) = ω, and THe = Hẽ = s = Ts implies He = s as desired. In the search phase, we try to find all error vectors ẽ that have a specific weight distribution, i.e. we search for vectors that can be decomposed into ẽ (</p><formula xml:id="formula_9">= (ẽ 1 , ẽ2 ) ∈ F k+ 2 × F n-k- H = 0 k + n -k - n -k - p ω -p Q [ ] I n-k- Q [ +1,n-k]</formula><formula xml:id="formula_10">)<label>2</label></formula><p>The inverse probability P -1 is the expected number of repetitions until ẽ has the desired distribution. Then it suffices to find the truncated vector ẽ1 ∈ F k+ 2 that represents the position of the first p ones. To recover the full error vector ẽ = (ẽ 1 , ẽ2 ), the missing coordinates ẽ2 are obtained as the last nkcoordinates of Qẽ 1 + s. Hence, the goal in the ISD search phase is to compute the truncated error vector ẽ1 efficiently. For the computation of ẽ1 we focus on the submatrix</p><formula xml:id="formula_11">Q [ ] ∈ F ×(k+ ) 2</formula><p>. Since we fixed the 0-submatrix in the right-hand part of H, we ensure that Qẽ 1 exactly matches the syndrome s on its first coordinates. Finding an ẽ1 with such a property was called the submatrix matching problem in <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 1 (Submatrix Matching Problem). Given a random matrix</head><formula xml:id="formula_12">Q ∈ R F ×(k+ ) 2</formula><p>and a target vector s ∈ F 2 , the submatrix matching problem (SMP) consists in finding a set I of size p such that the corresponding columns of Q sum up to s, i.e. to find</p><formula xml:id="formula_13">I ⊆ [1, k + ], |I| = p such that σ(Q I ) := i∈I q i = s, where q i is the i-th column of Q.</formula><p>Note that the SMP itself can be seen as just another syndrome decoding instance with parity check matrix Q, syndrome s ∈ F 2 and parameters [k + , , p].</p><p>Our improvement stems from a new algorithm COLUMNMATCH allowing to solve the SMP more efficiently by using more representations of a solution I. In Alg. 1 we describe the resulting ISD algorithm. Here we denote for a vector x ∈ F n </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Merge-Join Building Block</head><p>In order to realize our improved SMP algorithm, we first introduce an essential building block that realizes the following task. Given a matrix Q ∈ F ×(k+ ) 2 and two lists L 1 and L 2 containing binary vectors x 1 , . . . , x |L1| and y 1 , . . . , y |L2| of length k+ , we aim to join those elements x i and y j into a new list L = L 1 L 2 whose sum has weight p, i.e. wt(x i + y j ) = p. Furthermore, we require that the corresponding column-sum of Q already matches a given target t ∈ F r 2 on its right-most r ≤ coordinates, i.e. We call all matching vectors with weight different from p inconsistent solutions. Notice that we might also obtain the same vector sum from two different pairs of vectors from L 1 , L 2 . In this case we obtain a matched vector that we already have, which we call a duplicate. During our matching process we filter out all inconsistent solutions and duplicates.</p><formula xml:id="formula_14">(Q(x i + y j )) [r] = t.</formula><p>The matching process is illustrated in Fig. <ref type="figure" target="#fig_3">3</ref>. The complete algorithm is given as Alg. 2 and is based on a classical algorithm from Knuth <ref type="bibr" target="#b17">[18]</ref> which realizes the collision search as follows. Sort the first list lexicographically according to the r-bit labels L 1 (x i ) := (Qx i ) [r] and the second list according to the labels L 2 (y j ) := (Qy j ) [r] + t. We add t to the labels of the second list to guarantee (Q(x i + y j )) [r] = t. </p><formula xml:id="formula_15">) then i + + If L1(xi) &gt; lex L2(yj) then j + + If L1(xi) = L2(yj) then Let i0, i1 ← i and j0, j1 ← j While i1 &lt; |L1| and L1(xi 1 ) = L1(xi 0 ) do i1 + + While j1 &lt; |L2| and L2(yj 1 ) = L2(yj 0 ) do j1 + + For i ← i0 to i1 -1 do For j ← j0 to j1 -1 do C = C + 1 Insert collision xi + yj into list L (unless filtered out) Let i ← i1 , j ← j1 Output L, C.</formula><p>To detect all collisions, one now initializes two counters i and j starting at the beginning of the lists L 1 and L 2 and pointing at elements x i and y j . As long as those elements do not yield a collision, either i or j is increased depending on the relative order of the labels L 1 (x i ) and L 2 (y j ). Once a collision L 1 (x i ) = L 2 (y j ) occurs, four auxiliary counters i 0 , i 1 and j 0 , j 1 are initialized with i and j, respectively. Then i 1 and j 1 can further be incremented as long as the list elements retain the same labels, while i 0 and j 0 mark the first collision (i, j) between labels L 1 (x i ) and L 2 (y j ). Obviously, this procedure defines two sets C 1 = {x i0 , . . . , x i1 } and C 2 = {y j0 , . . . , y j1 } such that all possible combinations yield a collision, i.e. the set C 1 × C 2 can be added to the output list L.</p><p>This procedure is then continued with i ← i 1 and j ← j 1 until one of the counters i, j arrives at the end of a list. As mentioned before, we remove on the fly inconsistent solutions with incorrect weight wt(x i + y j ) = p and duplicate elements x i + y j = x k + y .</p><p>Note that we introduced a collision counter C which allows us to take into account the time that is spent for removing inconsistent solutions and duplicates. The total running time of MERGE-JOIN is given by</p><formula xml:id="formula_16">T = Õ (max {|L 1 |, |L 2 |, C}) .</formula><p>Assuming uniformly distributed labels L 1 (x j ) and L 2 (y j ) it holds that</p><formula xml:id="formula_17">E [C] = |L 1 | • |L 2 | • 2 -r .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Our New Algorithm for Solving the Submatrix Matching Problem</head><p>As explained in Section 2, improving the submatrix matching problem (SMP) automatically improves information set decoding (ISD).</p><p>Our new SMP algorithm is inspired by using extended representations similar to Becker, Coron and Joux <ref type="bibr" target="#b1">[2]</ref> for the subset sum problem.</p><p>In the MMT algorithm <ref type="bibr" target="#b22">[23]</ref> a weight-p error vector e ∈ F k+ 2 is written as the sum e 1 +e 2 . However, MMT only allow that every 1-entry splits to either a 1-entry in x 1 and a 0-entry in x 2 , or vice versa. If wt(e 1 ) = wt(e 2 ) = p 2 this allows for p p/2 different representations as a sum of two vectors.</p><p>Our key observation is that we can also split the 0-entries of e into either (0, 0) or (1, 1). Hence if we choose wt(e 1 ) = wt(e 2 ) = p 2 + ε then we gain a factor of k+ -p ε , namely the number of positions where we split as <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b0">1)</ref>. Notice that in all coding-based scenarios wt(e) is relatively small compared to k and n. Thus e contains many more zeros than ones, from which our new representation heavily profits.</p><p>To solve the SMP, we proceed as follows. Let I ⊂ [k + ] be the index set of cardinality p with σ(Q I ) = s that we want to find.</p><p>We represent I by two index sets I 1 and I 2 of cardinality p 2 +ε contained in the whole interval [k + l] and require I 1 and I 2 to intersect in a fixed number of ε coordinates as illustrated in Fig. <ref type="figure" target="#fig_5">4</ref>. The resulting index set I is then represented as the symmetric difference I 1 ΔI 2 := (I 1 ∪ I 2 ) \ (I 1 ∩ I 2 ) which yields an index set I of cardinality p as long as I 1 and I 2 intersect in exactly ε positions.</p><p>It turns out that the optimal running time can be obtained by applying the representation technique twice, i.e. we introduce further representations of the index sets I 1 and I 2 on a second computation layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Our COLUMNMATCH Algorithm</head><p>Our algorithm can be described as a computation tree of depth three, see Fig. <ref type="figure">5</ref> for an illustration. We enumerate the layers from bottom to top, i.e. the third layer identifies the initial computation of disjoint base lists B 1 and B 2 and the zero layer identifies the final output list L. </p><formula xml:id="formula_18">weight p1 = p 2 + ε1 weight p r 2 r 2 r 1 L L (1) 1 L (1) 2 L (2) 1 L (2) 2 L (2) 3 L (2) 4</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 5. Illustration of the COLUMNMATCH algorithm</head><p>Recall that we aim to find an index set I of size p with i∈I q i = s. We introduce parameters ε 1 and ε 2 representing the number of additional 1's we allow on the first and second layer, respectively. In the following description, we equip every object with an upper index that indicates its computation layer, e.g. a list L</p><p>(2) j is contained in the second layer.</p><p>On the first layer, we search for index sets I </p><p>2 ) such that wt(e</p><p>2 ) = p and Q(e</p><p>2 ) = s. Note that the number of tuples (e</p><formula xml:id="formula_22">(1)</formula><p>1 , e</p><p>2 ) that represent a single solution vector e is</p><formula xml:id="formula_24">R 1 (p, ; ε 1 ) := p p 2 k + l -p ε 1 . (<label>3</label></formula><formula xml:id="formula_25">)</formula><p>To optimize the running time, we impose a constraint on r 1 ≈ log 2 R 1 coordinates of the corresponding vectors Qe <ref type="bibr" target="#b0">(1)</ref> i such that we can still expect to find one representation of the desired solution e.</p><p>More precisely, the algorithm proceeds as follows. We first fix a random vector t</p><formula xml:id="formula_26">(1) 1 ∈ R F r1 2 , set t<label>(1) 2</label></formula><formula xml:id="formula_27">:= s [r1] + t<label>(1)</label></formula><p>2 and compute two lists</p><formula xml:id="formula_28">L (1) i = {e i (1) ∈ F k+ 2 | wt(e i ) = p 1 and (Qe<label>(1)</label></formula><p>i</p><formula xml:id="formula_29">) [r1] = t<label>(1)</label></formula><p>i } for i = 1, 2.</p><p>Observe that any two elements e</p><p>i , i = 1, 2, already fulfill by construction the equation (Q(e</p><formula xml:id="formula_31">(1) 1 + e (1)</formula><p>2 )) [r1] = s [r1] , i.e. they already match the syndrome s on r 1 coordinates. In order to solve the SMP, we are interested in a solution e = e .</p><p>Clearly, there are</p><formula xml:id="formula_32">R 2 (p, ; ε 1 , ε 2 ) = p 1 p 1 /2 • k + -p 1 ε 2 many representations for e<label>(1)</label></formula><p>j where p 1 = p 2 + ε 1 . Similarly to the first layer, this allows us to fix r 2 ≈ log R 2 coordinates of the partial sums Qe </p><p>i . More precisely, we draw two target vectors t</p><formula xml:id="formula_34">(2) 1 , t (2) 3 ∈ F r2 2 , set t<label>(2) 2j = (t (1)</label></formula><formula xml:id="formula_35">j ) [r2] +t<label>(2) 2j-1</label></formula><p>for j = 1, 2, and compute four lists</p><formula xml:id="formula_36">L (2) i = {e (2) i ∈ F k+l 2 | wt(e<label>(2)</label></formula><p>i ) = p 2 and (Qe</p><formula xml:id="formula_37">(2) i ) [r2] = t<label>(2)</label></formula><p>i } for i = 1, . . . , 4.</p><p>Notice that by construction all combinations of two elements from either L</p><p>(2)</p><formula xml:id="formula_38">1 , L<label>(2)</label></formula><p>2 or L We invoke MERGE-JOIN to compute</p><formula xml:id="formula_39">L (2) 1 = MERGE-JOIN(B 1 , B 2 , r 2 , p 2 , t<label>(2)</label></formula><p>1 ). Let S 3 = |B 1 | = |B 2 | denote the size of the base lists and let C 3 be the total number of matched vectors that occur in MERGEJOIN (since the splitting is disjoint, neither duplicates nor inconsistencies can arise). Then MERGEJOIN needs time</p><formula xml:id="formula_40">T 3 (p, ; ε 1 , ε 2 ) = O (max {S 3 , C 3 }) .</formula><p>Clearly, we have</p><formula xml:id="formula_41">S 3 := S 3 (p, ; ε 1 , ε 2 ) = (k + )/2 p 2 /2 .</formula><p>Assuming uniformly distributed partial sums we obtain</p><formula xml:id="formula_42">E [C 3 ] = S 2 3 2 r2 .</formula><p>We would like to stress that decomposing e</p><p>(2)</p><p>1 into x and y from disjoint sets P 1 and P 2 introduces a probability of loosing the vector e equally distributes its 1-entries over P 1 and P 2 is given by</p><formula xml:id="formula_43">P split = (k+ )/2 p2/2 2 k+ p2</formula><p>which is asymptotically inverse-polynomial in n. Choosing independent partitions P i,1 , P i,2 and appropriate base lists B i,1 , B i,2 for all four lists L</p><p>(2)</p><p>i , we can guarantee independent splitting conditions for all the e <ref type="bibr" target="#b1">(2)</ref> i yielding a total splitting probability of P Split = (P split ) 4 which is still inverse-polynomial in n.</p><p>After having created the lists L</p><p>(2)</p><p>i , i = 1, . . . , 4 on the second layer, two more applications of the MERGEJOIN algorithm suffice to compute the lists L (1) j on the first layer. Eventually, a last application of MERGEJOIN yields L, whose entries are solutions to the SMP. See Alg. 3 for a complete pseudocode description.</p><p>It remains to estimate the complexity of COLUMNMATCH as a function of the parameters (p, ; ε 1 , ε 2 ), where (ε 1 , ε 2 ) are optimization parameters. Notice that the values r i and p i are fully determined by (p, ; ε 1 , ε 2 ). The base lists B 1 and B 2 are of size S 3 (p, ; ε 1 , ε 2 ) as defined above.</p><p>The three consecutive calls to the MERGE-JOIN routine create lists L</p><p>(2) j of size S 2 (p, ; ε 1 , ε 2 ), lists L</p><p>(1) i of size S 1 (p, ; ε 1 , ε 2 ) and the final list L (which has not to be stored). More precisely, we obtain</p><formula xml:id="formula_44">S i (p, ; ε 1 , ε 2 ) = E |L (i) j | = k + p i • 2 -ri for i = 1, 2.</formula><p>Here we assume uniformly distributed partial sums Qe (j)</p><p>i . Let C i for i = 1, 2, 3 denote the number of all matching vectors (including possible inconsistencies or duplicates) that occur in the three MERGE-JOIN steps. If we set r 3 = 0 and r 0 = , then</p><formula xml:id="formula_45">E [C i ] = S 2 i • 2 ri-ri-1</formula><p>. Following the analysis of MERGE-JOIN in Sect. 3, the time complexities T i of the three MERGE-JOIN steps is given by</p><formula xml:id="formula_46">T i (p, ; ε 1 , ε 2 ) = max {S i , C i } .</formula><p>The overall time and space complexity is thus given by</p><formula xml:id="formula_47">T (p, ; ε 1 , ε 2 ) = max {T 3 , T 2 , T 1 }<label>(4)</label></formula><p>and S(p, ; ε 1 , ε 2 ) = max {S 3 , S 2 , S 1 } .</p><p>For optimizing T (p, ; ε 1 , ε 2 ) one has to compute the C i . Heuristically, we can assume that the C i achieve their expected values up to a constant factor. Since our heuristic analysis also relies on the fact that projected partial sums of the form (Qe) [r] yield uniformly distributed vectors in F r 2 , a proper theoretical analysis needs to take care of a certain class of malformed input parity check matrices H. We show how to obtain a provable variant of our algorithm that works for all but a negligible amount of input matrices H in the full version of the paper <ref type="bibr" target="#b2">[3]</ref>. The provable variant simply aborts computation if the C i differ too much from their expectation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Comparison of Asymptotic Complexity</head><p>We now show that we improve information set decoding by an exponential factor in comparison to the latest results <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b22">23]</ref>. To compute the complexity coefficient F (R) for our algorithm for a fixed code rate R, we need to optimize the parameters p, , ε 1 and ε 2 such that the expression</p><formula xml:id="formula_48">T (p, ; ε 1 , ε 2 ) • P(p, ) -1 (5)</formula><p>is minimized under the natural constraints</p><formula xml:id="formula_49">0 &lt; &lt; min{n -k, n -k -ω -p} 0 &lt;p &lt; min{ω, k + } 0 &lt;ε 1 &lt; k + -p 0 &lt;ε 2 &lt; k + -p 1 0 &lt;R 2 (p, ; ε 1 , ε 2 ) &lt; R 1 (p, ; ε 1 , ε 2 ) &lt; .</formula><p>The time per iteration T is given by Eq. ( <ref type="formula" target="#formula_47">4</ref>) and the number of iterations P -1 equals</p><formula xml:id="formula_50">k+ p n-k- ω-p / n ω -1</formula><p>as given in Eq. ( <ref type="formula" target="#formula_10">2</ref>).</p><p>For random linear codes, we can relate R = k/n and D = d/n via the Gilbert-Varshamov bound. Thus asymptotically we obtain D = H -1 (1-R)+o <ref type="bibr" target="#b0">(1)</ref>, where H is the binary entropy function. For bounded distance decoding, we set W := ω/n = D/2. We numerically determined the optimal parameters for several equidistant rates R and interpolated F (R). To calculate F (R) we make use of the well known approximation αn βn = 2 αH(β/α)n+o (n) . The results are shown in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>For full decoding, in the worst-case we need to decode a highest weight coset leader of the code C, its weight ω corresponds to the covering radius of C which is defined as the smallest radius r such that C can be covered by discrete balls of radius r. The Goblick bound <ref type="bibr" target="#b12">[13]</ref> ensures that r ≥ nH -1 (1 -R) + o(n) for all linear codes. Independently, Blinovskii <ref type="bibr" target="#b6">[7]</ref> and Levitin <ref type="bibr" target="#b20">[21]</ref> further proved that this bound is tight for almost all linear codes, i.e. r = nH -1 (1 -R) + o(n). This justifies our choice W = H -1 (1 -R) for the full decoding scenario. We conclude by taking a closer look at the worst-case complexities of decoding algorithms for random linear codes and a typical McEliece setting with relative distance D = 0.04 and rate R = 0.7577. Notice that three out of the four parameter sets for security levels between 80 and 256 bit from <ref type="bibr" target="#b3">[4]</ref> closely match these code parameters. All algorithms were optimized for speed, not for memory. For a comparison of full decoding with fixed memory, we can easily restrict Ball-collision, MMT and our new algorithm to the space complexity coefficient 0.0317 of Stern's algorithm which holds for k ≈ 0.446784. In this case, we obtain time complexities F ball (R) = 0.1163, F MMT (R) = 0.1129 and F our (R) = 0.1110, which shows that our improvement is not a pure time memory tradeoff. For a better verifiability of optimization and the resulting complexities, we make all data including the Mathematica code publicly available at http://cits.rub.de/personen/meurer.html. If needed, this code may also be used to compute optimal parameters for arbitrary code parameters.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Comparison of F (R) for code rates 0 &lt; R &lt; 1 for bounded distance decoding. Our algorithm is represented by the thick curve, MMT is the thin curve and Ball-collision is the dashed curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Parity check matrix H in quasi-systematic form where wt(ẽ 1 ) = p and wt(ẽ 2 ) = ωp. Since P shuffles e's coordinates into random positions, ẽ has the above weight distribution with probability</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>2</head><label>2</label><figDesc>and an index set I ⊂ [n] by x I ∈ F |I| 2 the restriction of x to the coordinates of I. Let T := T (n, R; p, ) denote the running time of COLUMNMATCH. Then the running time of GENERALIZEDISD is P -1 • T . Algorithm 1. GENERALIZEDISD Input: Parity check matrix H ∈ F (n-k)×n 2 , syndrome s = He with wt(e) = ω. Output: Error e ∈ F n 2 Parameters: p, Repeat Compute H ← Init(H) and s ← Ts where H = THP, P random permutation. Compute L =COLUMNMATCH(Q [ ] , s[ ] , p). For all solutions ẽ1 ∈ L do If wt(Qẽ1 + s) = ω -p then Compute e ← (ẽ1, ẽ2) ∈ F n 2 where ẽ2 ← (Qẽ1 + s) [ +1,n-k] Output e = eP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Illustration of the MERGE-JOIN algorithm to obtain L = L1 L2Searching for matching vectors (Qy j ) [r] + t and (Qx i ) [r] accomplishes this task. We call all matching vectors with weight different from p inconsistent solutions. Notice that we might also obtain the same vector sum from two different pairs of vectors from L 1 , L 2 . In this case we obtain a matched vector that we already have, which we call a duplicate. During our matching process we filter out all inconsistent solutions and duplicates.The matching process is illustrated in Fig.3. The complete algorithm is given as Alg. 2 and is based on a classical algorithm from Knuth<ref type="bibr" target="#b17">[18]</ref> which realizes the collision search as follows. Sort the first list lexicographically according to the r-bit labels</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 2 .</head><label>2</label><figDesc>MERGE-JOIN Input: L1, L2, r, p and t ∈ F r 2 Output: L = L1 L2 Lexicographically sort L1 and L2 according to the labels L1(xi) := (Qxi) [r] and L2(yj) := (Qyj ) [r] + t. Set collision counter C ← 0. Let i ← 0 and j ← (|L2| -1) While i &lt; |L1| and j &lt; |L2| do If L1(xi) &lt; lex L2(yj</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Decomposition of an index set I into two overlapping index sets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Disjoint base lists Bi,1 and Bi,2 for i = 1, . . . ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>2 2 .</head><label>2</label><figDesc>in [k + ] of size p 1 := p 2 +ε 1 which intersect in exactly ε 1 coordinates such that I = I In other words, we create lists of binary vectors e p 1 and search for tuples (e</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>syndrome s on all positions and has weight exactly p. Once L created, this can be accomplished by calling the MERGE-JOIN algorithm from Sect. 3 on input L s, weight p and parameter .It remains to show how to construct L weight p 2 := p1 2 + ε 2 , i.e. we require the two vectors to intersect in exactly ε 2 coordinates. Altogether, the solution e is now decomposed as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>4 . 2 ) 1 . 1 = 2 | 2 |</head><label>421122</label><figDesc>We exemplary explain how to create L (The remaining lists can be constructed analogously. We apply a classical Meet-in-the-middle collision search, i.e. we decompose e y+z by two non-overlapping vectors y and z of length k + . To be more precise, we first choose a random partition of [k + ] into two equal sized sets P 1 and P 2 , i.e.[k + ] = P 1 ∪ P 2 with |P 1 | = |P 2 | = k+2 , and force y to have its p2 2 1-entries in P 1 and z to have its p2 2 1-entries in P 2 . That is we construct two base lists B 1 := {y ∈ F k+ wt(y) = p 2 2 and y i = 0∀i ∈ P 2 } and B 2 := {z ∈ F k+ wt(z) = p 2 2 and z i = 0∀i ∈ P 1 }.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>4 .</head><label>4</label><figDesc>For a randomly chosen partition P 1 , P 2 , the probability that e(2) 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. F (R) for full decoding. Our algorithm is represented by the thick curve, MMT is the thin curve and Ball-collision is the dashed curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison of worst-case complexity coefficients, e.g. the time columns represent the maximal complexity coefficient F (R) for 0 &lt; R &lt; 1</figDesc><table><row><cell></cell><cell cols="2">half-dist.</cell><cell cols="2">full dec.</cell><cell cols="2">McEliece</cell></row><row><cell></cell><cell>time</cell><cell>space</cell><cell>time</cell><cell>space</cell><cell>time</cell><cell>space</cell></row><row><cell>Lee-Brickell</cell><cell>0.05752</cell><cell>-</cell><cell>0.1208</cell><cell>-</cell><cell>0.0857</cell><cell>-</cell></row><row><cell>Stern</cell><cell>0.05564</cell><cell>0.0135</cell><cell>0.1167</cell><cell>0.0318</cell><cell>0.0809</cell><cell>0.0327</cell></row><row><cell cols="2">Ball-collision 0.05559</cell><cell>0.0148</cell><cell>0.1164</cell><cell>0.0374</cell><cell>0.0807</cell><cell>0.0348</cell></row><row><cell>MMT</cell><cell>0.05364</cell><cell>0.0216</cell><cell>0.1116</cell><cell>0.0541</cell><cell>0.0760</cell><cell>0.0482</cell></row><row><cell cols="2">Our algorithm 0.04934</cell><cell>0.0286</cell><cell>0.1019</cell><cell>0.0769</cell><cell>0.0672</cell><cell>0.0586</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgment. We would like to thank Dan Bernstein for several excellent comments, in particular he proposed to use random partitions for generating the base lists in the COLUMNMATCH algorithm.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Supported by DFG project MA 2536/7-1 and by ICT-2007-216676 ECRYPT II.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3. COLUMNMATCH</head><p>2 and set t</p><p>(1)</p><p>1 and t</p><p>2</p><p>2 , , p, s). Output L.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">More on Average Case vs Approximation Complexity</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alekhnovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">44th Symposium on Foundations of Computer Science (FOCS)</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="298" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Improved Generic Algorithms for Hard Knapsacks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Coron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUROCRYPT 2011</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Paterson</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">6632</biblScope>
			<biblScope unit="page" from="364" to="385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Decoding Random Binary Linear Codes in 2 n/20 : How 1 + 1 = 0 Improves Information Set Decoding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Meurer</surname></persName>
		</author>
		<ptr target="http://eprint.iacr.org" />
	</analytic>
	<monogr>
		<title level="j">Full Version</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Attacking and Defending the McEliece Cryptosystem</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PQCrypto 2008</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Buchmann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Ding</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5299</biblScope>
			<biblScope unit="page" from="31" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Smaller Decoding Exponents: Ball-Collision Decoding</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CRYPTO 2011</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Rogaway</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">6841</biblScope>
			<biblScope unit="page" from="743" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the inherent intractability of certain coding problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J M</forename><surname>Elwyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Berlekamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Van Tilborg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="384" to="386" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lower asymptotic bound on the number of linear code words in a sphere of given radius in F n q</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Blinovskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Probl. Peredach. Inform</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="50" to="53" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A new algorithm for finding minimum-weight words in a linear code: Application to mceliece&apos;s cryptosystem and to narrow-sense bch codes of length 511</title>
		<author>
			<persName><forename type="first">A</forename><surname>Canteaut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chabaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="367" to="378" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The complexity of information set decoding</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Coffey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1031" to="1037" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Any code of which we cannot think is good</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Coffey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Faugère</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Otmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Perret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Tillich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A Distinguisher for High Rate McEliece Cryptosystems</title>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
	<note>full version available as eprint Report 2010/331</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Security Bounds for the Design of Code-Based Cryptosystems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Finiasz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sendrier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASIACRYPT 2009</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Matsui</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5912</biblScope>
			<biblScope unit="page" from="88" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Coding for a discrete information source with a distortion measure</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Goblick</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ph.D. dissertation, Dept. of Elect. Eng. M.I.T</title>
		<imprint>
			<date type="published" when="1962">1962</date>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Secure Human Identification Protocols</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Hopper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASIACRYPT 2001</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Boyd</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">2248</biblScope>
			<biblScope unit="page" from="52" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">New Generic Algorithms for Hard Knapsacks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Howgrave-Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUROCRYPT 2010</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Gilbert</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6110</biblScope>
			<biblScope unit="page" from="235" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A variant of a public key cryptosystem based on goppa codes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGACT News</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="61" to="66" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient Authentication from Hard Learning Problems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kiltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pietrzak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Venturi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUROCRYPT 2011</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Paterson</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">6632</biblScope>
			<biblScope unit="page" from="7" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Art of Computer Programming: Sorting and Searching, 2nd edn</title>
		<author>
			<persName><forename type="first">D</forename><surname>Knuth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Addison-Wesley Professional</publisher>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An Observation on the Security of McEliece&apos;s Public-Key Cryptosystem</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Brickell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUROCRYPT 1988</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Günther</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">330</biblScope>
			<biblScope unit="page" from="275" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A probabilistic algorithm for computing minimum weights of large errorcorrecting codes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Leon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1354" to="1359" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Covering radius of almost all linear codes satisfies the Goblick bound</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Levitin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internat. Symp. on Information Theory</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<pubPlace>Kobe; Japan</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A public-key cryptosystem based on algebraic coding theory</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mceliece</surname></persName>
		</author>
		<idno>42-44</idno>
		<imprint>
			<date type="published" when="1978">1978</date>
			<biblScope unit="page" from="114" to="116" />
		</imprint>
		<respStmt>
			<orgName>Jet Propulsion Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">DSN Progress Report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Decoding Random Linear Codes in Õ(2 0.054n )</title>
		<author>
			<persName><forename type="first">A</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Meurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Thomae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASIACRYPT 2011</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">7073</biblScope>
			<biblScope unit="page" from="107" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distribution of modular sums and the security of the server aided exponentiation</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">E</forename><surname>Shparlinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Progress in Computer Science and Applied Logic. Final Proceedings of Cryptography and Computational Number Theory Workshop</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999. 2001</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="331" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The Use of Information Sets in Decoding Cyclic Codes</title>
		<author>
			<persName><forename type="first">E</forename><surname>Prange</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IRE Transaction on Information Theory</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="5" to="9" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Information-Set Decoding for Linear Codes over Fq</title>
		<author>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PQCrypto 2010</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Sendrier</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6061</biblScope>
			<biblScope unit="page" from="81" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On lattices, learning with errors, random linear codes, and cryptography</title>
		<author>
			<persName><forename type="first">O</forename><surname>Regev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual ACM Symposium on Theory of Computing (STOC)</title>
		<meeting>the 37th Annual ACM Symposium on Theory of Computing (STOC)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="84" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Finding the permutation between equivalent linear codes: The support splitting algorithm</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sendrier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1193" to="1203" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the security of the McEliece public-key cryptosystem</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sendrier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop honoring Prof</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Blaum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Farrell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Van Tilborg</surname></persName>
		</editor>
		<meeting>Workshop honoring Prof</meeting>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="141" to="163" />
		</imprint>
	</monogr>
	<note>Information, Coding and Mathematics. Bob McEliece on his 60th birthday</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A Method for Finding Codewords of Small Weight</title>
		<author>
			<persName><forename type="first">J</forename><surname>Stern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Coding Theory 1988</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Wolfmann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Cohen</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">388</biblScope>
			<biblScope unit="page" from="106" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A Generalized Birthday Problem</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CRYPTO 2002</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Yung</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2442</biblScope>
			<biblScope unit="page" from="288" to="303" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
