<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automatic Error Analysis for Document-level Information Extraction</title>
				<funder>
					<orgName type="full">Cornell CS Department CSURP</orgName>
				</funder>
				<funder ref="#_nNU6df8">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-09-15">15 Sep 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Aliva</forename><surname>Das</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinya</forename><surname>Du</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Barry</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kejian</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiayuan</forename><surname>Gu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Porter</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Automatic Error Analysis for Document-level Information Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-09-15">15 Sep 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2209.07442v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document-level information extraction (IE)</head><p>tasks have recently begun to be revisited in earnest using the end-to-end neural network techniques that have been successful on their sentence-level IE counterparts. Evaluation of the approaches, however, has been limited in a number of dimensions. In particular, the precision/recall/F1 scores typically reported provide few insights on the range of errors the models make. We build on the work of <ref type="bibr" target="#b16">Kummerfeld and Klein (2013)</ref> to propose a transformation-based framework for automating error analysis in document-level event and (N-ary) relation extraction. We employ our framework to compare two state-of-theart document-level template-filling approaches on datasets from three domains; and then, to gauge progress in IE since its inception 30 years ago, vs. four systems from the MUC-4 (1992) evaluation. 1 * These authors contributed equally to this work. 1 Our code for the error analysis tool and its output on different model predictions are available at https://github. com/IceJinx33/auto-err-template-fill/.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Although information extraction (IE) research has almost uniformly focused on sentence-level relation and event extraction <ref type="bibr" target="#b11">(Grishman, 2019)</ref>, the earliest research in the area formulated the task at the document level. Consider, for example, the first large-scale (for the time) evaluations of IE systems -e.g. <ref type="bibr" target="#b22">MUC-3 (1991)</ref> and <ref type="bibr" target="#b23">MUC-4 (1992)</ref>. Each involved a complex document-level event extraction task: there were 24 types of events, over a dozen event arguments (or roles) to be identified for each event; documents could contain zero to tens of events, and extracting argument entities (or role fillers) required noun phrase coreference resolution to ensure interpretability for the end-user (e.g. to ensure that multiple distinct mentions of the same entity in the output were not misinterpreted as references to distinct entities).</p><p>The task was challenging: information relevant for a single event could be scattered across the document or repeated in multiple places; relevant information might need to be shared across multiple events; information regarding different events could be intermingled. In Figure <ref type="figure" target="#fig_0">1</ref>, for example, the DISEASE "Newcastle" is mentioned well before its associated event is mentioned (via the triggering phrase "the disease has killed"); that same mention of "Newcastle" must again be recognized as the DISEASE in a second event; and the COUNTRY of the first event ("Honduras") appears only in the sentence describing the second event.</p><p>In fact, the problem of document-level information extraction has only recently begun to be revisited <ref type="bibr" target="#b27">(Quirk and Poon, 2017;</ref><ref type="bibr" target="#b12">Jain et al., 2020;</ref><ref type="bibr">Du et al., 2021b,a;</ref><ref type="bibr" target="#b17">Li et al., 2021;</ref><ref type="bibr" target="#b6">Du, 2021;</ref><ref type="bibr" target="#b35">Yang et al., 2021)</ref> in part in an attempt to test the power of endto-end neural network techniques that have been so successful on their sentence-level counterparts.<ref type="foot" target="#foot_0">2</ref> Evaluation, however, has been limited in a number of ways. First, despite the relative complexity of the task, approaches are only evaluated with respect to their overall performance scores (e.g. precision, recall, and F1). Even though scores at the role level are sometimes included, no systematic analysis or characterization of the types of errors that occur is typically done. The latter is needed to determine strategies to improve performance, to obtain more informative cross-system and crossgenre comparisons, and to identify and track broader advances in the field as the underlying approaches evolve. To date, for example, there has been no attempt to directly compare the error land- scape and distribution of newly developed neural IE methods with that of the largely hand-crafted systems of the 1990s.</p><p>In this work, we first introduce a framework for automating error analysis for document-level event and relation extraction, casting both as instances of a general role-filling, or template-filling task (Jurafsky and Martin, 2021). Our approach converts predicted system outputs into their gold standard counterparts through a series of template-level transformations (Figure <ref type="figure" target="#fig_2">2</ref>) and then maps combinations of transformations into a collection of IE-based error types. Examples of errors include duplicates, missing and spurious role fillers, missing and spurious templates, and incorrect role and template assignments for fillers. (See Figure <ref type="figure">3</ref> for the full set).</p><p>Next, we employ the error analysis framework in a comparison of two state-of-the-art documentlevel neural template-filling approaches, DyGIE++ <ref type="bibr" target="#b32">(Wadden et al., 2019)</ref> and GTT <ref type="bibr">(Du et al., 2021b)</ref>, across three template-filling datasets (SciREX, ProMED (Patwardhan and Riloff, 2009) 3 , and  MUC-4).</p><p>Finally, in an attempt to gauge progress in the information extraction field over the past 30 years, we employ the framework to compare the performance of four of the original MUC-4 systems with the two newer deep-learning approaches to document-level IE. <ref type="foot" target="#foot_2">4</ref>We find that (1) the best of the early IE models -which strikes a better balance between precision and recall -outperforms modern models that exhibit much higher precision and much lower recall;</p><p>(2) the modern neural models make more mistakes on scientific vs. news-oriented texts, and missing role fillers is universally the largest source of errors; and (3) modern models have clear advantages over the early IE systems in terms of accurate span extraction, while the early systems make fewer mistakes assigning role fillers to their roles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Aside from the original MUC-4 evaluation scoring reports <ref type="bibr" target="#b5">(Chinchor, 1991)</ref>, which included counts of missing and spurious role filler errors, there have been very few attempts at understanding the types of errors made by IE systems and grounding those errors linguistically. <ref type="bibr" target="#b30">Valls-Vargas et al. (2017)</ref> proposed a framework for studying how different errors propagate through an IE system; however, the framework can only be used for pipelined systems, not end-to-end ones.</p><p>On the other hand, automated error analysis with linguistically motivated error types has been used in other sub-fields of NLP such as machinetranslation <ref type="bibr" target="#b31">(Vilar et al., 2006;</ref><ref type="bibr" target="#b39">Zhou et al., 2008;</ref><ref type="bibr" target="#b10">Farr?s et al., 2010;</ref><ref type="bibr" target="#b14">Kholy and Habash, 2011;</ref><ref type="bibr" target="#b36">Zeman et al., 2011;</ref><ref type="bibr" target="#b26">Popovi? and Ney, 2011)</ref>, coreference resolution <ref type="bibr" target="#b29">(Uryupina, 2008;</ref><ref type="bibr" target="#b16">Kummerfeld and Klein, 2013;</ref><ref type="bibr" target="#b21">Martschat and Strube, 2014;</ref><ref type="bibr" target="#b20">Martschat et al., 2015)</ref> and parsing <ref type="bibr" target="#b15">(Kummerfeld et al., 2012)</ref>. Recently, generalized automated error analysis frameworks involving human-in-the-loop testing like Errudite <ref type="bibr" target="#b34">(Wu et al., 2019)</ref>, <ref type="bibr">CHECK-LIST (Ribeiro et al., 2020)</ref>, CrossCheck <ref type="bibr" target="#b3">(Arendt et al., 2021)</ref>, and AllenNLP Interpret <ref type="bibr" target="#b33">(Wallace et al., 2019)</ref> have successfully been applied to tasks like machine comprehension and relation extraction <ref type="bibr" target="#b2">(Alt et al., 2020)</ref>. Closest to our work are <ref type="bibr" target="#b15">Kummerfeld et al. (2012)</ref> and <ref type="bibr" target="#b16">Kummerfeld and Klein (2013)</ref>, which use model-agnostic transformationbased mapping approaches to automatically obtain error information in the predicted structured output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Template-Filling Task Specification and Evaluation</head><p>As in <ref type="bibr">Jurafsky and Martin (2021)</ref>, we will refer to document-level information extraction tasks as template-filling tasks and use the term going forward to refer to both event extraction and documentlevel relation extraction tasks. Given a document, D, and an IE template specification consisting of a predetermined list of roles R 1 , R 2 , ..., R i associated with each type of relevant event for the task of interest, the goal for template filling is to extract from D, one output template, T for every relevant event/relation e 1 , e 2 , . . . , e n present in the document. Notably, in the general case, n ? 0 and is not specified as part of the input. In each output template, its roles are filled with the corresponding role filler(s), which can be inferred or extracted from the document depending on the predetermined role types. We consider two role types here: <ref type="foot" target="#foot_3">5</ref>Set-fill roles, which must be filled with exactly one role filler from a finite set supplied in the template specification. An example of a set-fill role in Figure <ref type="figure" target="#fig_0">1</ref> is STATUS, which can be confirmed, possible, or suspected.</p><p>String-fill roles, whose role filler(s) are spans extracted from the document, or left empty if no corresponding role filler is found in the document. VICTIMS, DISEASE and COUNTRY are string-fill roles in Figure <ref type="figure" target="#fig_0">1</ref>. Some string-fill roles allow multiple fillers; for example, there might be more than one VICTIMS. Importantly, for document-level template filling, exactly one string should be included for each role filler entity (typically a canonical mention of the entity), i.e. coreferent mentions of the same entity are not permitted.</p><p>Evaluation. We use the standard (exact-match) F1 score <ref type="bibr" target="#b5">(Chinchor, 1991)</ref> to evaluate the output produced by a template-filling system:</p><formula xml:id="formula_0">F 1 = 2 ? Precision ? Recall Precision + Recall</formula><p>4 Methodology: Automatic Transformations for Error Analysis</p><p>Similar to the work of <ref type="bibr" target="#b16">Kummerfeld and Klein (2013)</ref>, our error analysis approach is systemagnostic, i.e. it only uses system output and does not consider intermediate system decisions. This allows for error analysis and comparison across different kinds of systems -end-to-end or pipeline; neural or pattern-based.</p><p>Given inputs consisting of the system-predicted templates and gold standard templates (i.e. desired output) for every document in the target dataset, our error analysis tool operates in three steps. For each document, 1. Perform an optimized mapping of the associated predicted templates and gold templates.</p><p>2. Apply a pre-defined set of transformations to convert each system-predicted template into the desired gold template, keeping track of the transformations applied.</p><p>3. Map the changes made in the conversion process to an IE-based set of error types.</p><p>We describe each step in detail in the subsections below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Optimized Matching</head><p>The first stage of the error analysis tool involves matching each system-predicted template to the best-matching gold template for each document in the dataset. In particular, the overall F1 score for a given document can vary based on how a predicted template is individually matched with a gold template (or left unmatched). Specifically, for each document, we recursively generate all possible template matchings -where each predicted template is matched (if possible) to a gold template. In particular, for a document with P predicted templates and G gold templates, the  total number of possible template matchings is:</p><formula xml:id="formula_1">1 + P 1 G + P 2 G(G -1) + ... + G! (G -P )! , if G -P ? 0 1 + P 1 G + P 2 G(G -1) + ... + P G G!, if G -P &lt; 0 = min(P,G) i=0 P i G! (G -i)!</formula><p>Note that template matching can result in unmatched predicted templates (Spurious Templates), as well as unmatched gold templates (Missing Templates).</p><p>Next, for each predicted-gold pair in a template matching, we iterate through all its roles and recursively generate all possible mention matchings, in each of which a predicted role filler is matched (if possible) to a set of coreferent gold role fillers. Similar to template matching, the process of mention matching can also result in unmatched predicted role fillers (Spurious Role Fillers) and unmatched coreferent sets of gold role fillers (Missing Role Fillers).</p><p>Through the process, each predicted role filler increases the denominator of the total precision by 1, and each set of coreferent gold role fillers increases the denominator of total recall by 1. Whenever there is a matched mention pair in which the predicted role filler has an exact match to an element of the set of coreferent gold role fillers, this adds 1 to the numerator of both precision and recall. These counts are calculated for each template matching.</p><p>Using precision and recall, the total F1 score across all the slots/roles is calculated and the template matching with the highest total F1 score is chosen. If there are ties, the template matching with the fewest errors is chosen (see Section 4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Transformations</head><p>The second part of the error analysis tool involves changing the predicted templates to the desired gold templates with the help of a fixed set of transformations as detailed below.</p><p>? Alter Span transforms a role filler into the gold role filler with the lowest span comparison score (SCS). The tool provides two options for computing the SCS between two spans, and each depends only on the starting and ending indices of the spans.<ref type="foot" target="#foot_4">6</ref> SCS can be interpreted as distance and is 0 between two identical spans, and 1 for non-overlapping spans. The two modes are given as follows:</p><p>a) absolute: This mode captures the (positive) distance between the starting (and ending) character offsets of spans x and y in the document, and scales that value by the sum of the lengths of x and y, capping it at a maximum of 1.</p><formula xml:id="formula_2">SCS = max 1, |xstart-ystart|+|x end -y end | length(x)+length(y) b) geometric mean:</formula><p>This mode captures the degree of disjointedness between spans x and y by dividing the length of the overlap between the two spans with respect to each of their lengths, multiplying those two fractions, and subtracting the final result from 1.</p><p>If si is the length of the intersection of x and y, and neither x nor y have length 0, SCS is calculated as shown below; otherwise, SCS is 1. </p><formula xml:id="formula_3">overlap = min(x end , y end ) -max(x start , y start ) si = max (0, overlap) SCS = 1 - si 2 length(x) * length(y)</formula><p>Thus, if the predicted role filler is an exact match for the gold role filler, the SCS is 0. If there is some overlap between the spans, the SCS is between 0 and 1 (not inclusive), and if there is no overlap between the spans, the SCS is 1. The order of comparison of the spans doesn't change the SCS score for both modes.</p><p>As the absolute mode is less sensitive to changes in span indices as compared to the geometric mean, we chose geometric mean for our analysis, as tiny changes in index positions result in a bigger change in the SCS score.</p><p>? Alter Role changes the role of a role filler to another role within the same template.</p><p>? Remove Duplicate Role Filler removes a role filler that is coreferent to an already matched role filler.</p><p>? Remove Cross Template Spurious Role Filler removes a role filler that would be correct if present in another template (in the same role).</p><p>? Remove Spurious Role Filler removes a role filler that has not been mentioned in any of the gold templates for a given document.</p><p>? Introduce Role Filler introduces a role filler that was not present in the predicted template but was required to be present in the matching gold template.</p><p>? Remove Template removes a predicted template that could not be matched to any gold template for a given document.</p><p>? Introduce Template introduces a template that can be matched to an unmatched gold template for a given document.</p><p>For a given document, all singleton Alter Span and Alter Role transformations, as well as sets of Alter Span + Alter Role transformations, are applied first.</p><p>The other transformations are applied in the order in which they were detected, which is dependent on the order of predicted and gold template pairs in the optimized matching and the order of the slots/roles in the template.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Error Type Mappings</head><p>The transformations in Section 4.2 are mapped onto a set of IE-specific error types as shown in Figure <ref type="figure">3</ref>. In some cases, a single transformation maps onto a single error, while in others a sequence of transformations is associated with a single error. Full details are in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Document-level IE Datasets</head><p>Our experiments employ three document-level information extraction datasets. We briefly describe each below. Dataset statistics are summarized in Table <ref type="table" target="#tab_2">1</ref>. <ref type="bibr" target="#b23">MUC-4 (MUC-4, 1992</ref>) consists of newswire describing terrorist incidents in Latin America provided by the FBIS (Federal Broadcast Information Services). We converted the optional templates to required templates and removed the subtypes of the incidents as done in previous work <ref type="bibr" target="#b4">(Chambers, 2013;</ref><ref type="bibr">Du et al., 2021b)</ref>  We use the tuning data as training data and reserve 10% of the test data, i.e. 12 examples, to create a development/validation set. 19.83% of the documents in the dataset have no templates. The roles that we extract from the dataset are STATUS, COUN-TRY, DISEASE, and VICTIMS. DISEASE, VIC-TIMS, and COUNTRY are string-fill roles<ref type="foot" target="#foot_6">9</ref> ; STATUS is a set-fill role with confirmed, possible, and suspected as the possible role filler options. SciREX <ref type="bibr" target="#b12">(Jain et al., 2020)</ref> consists of annotated computer science articles from Papers with Code<ref type="foot" target="#foot_7">10</ref> . We focus specifically on its 4-ary relation extraction subtask. The roles present in each relation are MATERIAL (DATASET), METRIC, TASK, and METHOD which are all string-fills. We convert the dataset from its original format to templates for our models, and remove individual role fillers (entities) that have no mentions in the text. <ref type="foot" target="#foot_8">11</ref> We also remove any duplicate templates. <ref type="foot" target="#foot_9">12</ref>  processing, we remove malformed words longer than 25 characters, as the majority of these consist of concatenated words that are not present in the corresponding text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">IE Modeling Details</head><p>In our experiments, we train and test two neuralbased IE models, described briefly below, on the MUC-4, ProMED, and SciREX datasets. Note that to create the training data for both the DyGIE++ and GTT models, we use the first mention of each role filler in the document as the mention to be extracted. To aggregate entities detected by DyGIE++ into templates, we use a clustering algorithm. For the SciREX dataset, we adopt a heuristic approach that assumes there is only one template per document, and in that template, we assign the named entities predicted by DyGIE++ for a document to the predicted role types. For the ProMED dataset, we use a different clustering heuristic that ensures that each template has exactly one role filler for the COUNTRY and DISEASE roles, as detailed in the dataset annotation guidelines. Also, since STATUS has the value confirmed in the majority of the templates, every template predicted has its STATUS assigned as confirmed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DyGIE++ with Clustering</head><p>template. Thus, we only keep one of these processed templates.</p><p>GTT is an end-to-end document-level templategenerating model. For the MUC-4 and SciREX datasets, GTT is run for 20 epochs, while for ProMED it is run for 36 epochs, to adjust for the smaller size of the dataset. All other hyperparameters are set as in <ref type="bibr">Du et al. (2021b)</ref>. We use the same BERT and SciBERT base models as described in the DyGIE++ architecture above, both with a maximum input sequence length of 512 tokens.</p><p>The computational budget and optimal hyperparameters for these models can be found in Appendix sections D and E, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Results and Analysis</head><p>We first discuss the results of DyGIE++ and GTT on SciREX, ProMED, and MUC-4; and then examine the performance of these newer neural models on the 1992 MUC-4 dataset vs. a few of the bestperforming IE systems at the time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">DyGIE++ vs. GTT</head><p>Table <ref type="table">2</ref> shows the results of evaluating DyGIE++ and GTT on the SciREX, ProMED, and MUC-4 datasets. We can see that all models perform substantially worse on scientific texts (ProMED, SciREX) as compared to news (MUC-4), likely because the model base is pretrained for general-purpose NLP applications (BERT) or there are not enough examples of scientific-style text in the pretraining corpus (SciB-ERT).</p><p>In addition, models seem to perform better on the news-style ProMED dataset than the scientificpaper-based long-text SciREX dataset. This can be explained by the fact that all four models handle a maximum of 512 tokens as inputs, while the average length of a SciREX document is 5401 tokens. Thus, a majority of the text is truncated and, hence, unavailable to the models.</p><p>Nevertheless, we see an increase in F1 scores for all SciBERT-based models when compared to their BERT counterparts for the SciREX dataset. The same trend is seen for DyGIE++ for ProMED, but not for GTT. This can be explained by the fact that GTT (SciB-ERT) has more Missing Template errors than GTT (BERT). So even if GTT (SciBERT) performs better on the scientific slot VICTIMS, i.e. it extracts more scientific information, it does not identify relevant events as well as GTT (BERT), reducing the F1 score across the remaining slots.</p><p>From the error count results in Figure <ref type="figure" target="#fig_3">4</ref>, we see that GTT makes fewer Missing Template errors than DyGIE++ on the MUC-4 dataset (86 vs. 97). However, there is no significant difference in the number of missing templates between the two models on the ProMED and SciREX datasets. This could be because DyGIE++ is prone to overgeneration -there are significantly more Spurious Role Filler and Spurious Template errors as compared to the results of GTT. Since we use heuristics that create templates based on the extracted role fillers, this increases the probability that there was a possible match to a gold template, reducing the number of Missing Template Errors.</p><p>We can also conclude that DyGIE++ is worse at coreference resolution when compared to GTT as DyGIE++ makes more Duplicate Role Filler errors across all datasets.</p><p>Overall, we find that the major source of error for both GTT and DyGIE++ across all the datasets is missing recall in the form of Missing Role Filler and Missing Template errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Early IE Models vs. DyGIE++ and GTT</head><p>Table <ref type="table" target="#tab_6">3</ref> presents the precision, recall, and F1 performance on the MUC-4 dataset for early models from 1992 alongside those of the more recent DyGIE++ and GTT models. We summarize key findings below.</p><p>The best of the early models (GE NLToolset) performs better than either of the modern models. It does so by doing a better job balancing   <ref type="table">4</ref>: Span Errors in early models. The differences between the predicted mention and its best gold mention match according to our analysis tool are in bold.</p><p>precision and recall, whereas GTT and DyGIE++ exhibit much higher precision and much lower recall.</p><p>The early models have more span errors than the modern DyGIE++ and GTT models. The representative kinds of span errors from the 1992 model outputs are shown in Table <ref type="table">4</ref>. One interesting difference between the span errors in the early models and the modern models is that the predicted mentions include longer spans with more information than is indicated in the best gold mention match. Some could be due to errors in dataset annotation; for example, maoist shining path group versus shining path but a significant number of the span errors occur as the early models seem to extract the entire sentence or clause which contains the desired role filler mention. The modern models tend to leave off parts of the desired spans, and if they do predict larger spans than required, are only off by a few words.</p><p>The early models have fewer Missing Template and Missing Role Filler errors as compared to the modern models. However, the former also have more Spurious Template and Spurious Role  Filler errors than the latter, indicating these models mitigate the issue of Missing Templates through over-generation.</p><p>The early models have fewer Incorrect Role errors as compared to modern models. However, since all the models make relatively few such errors, it suggests that role classification for predicted mentions is not a major problem for modern models.</p><p>The main source of error for both early and modern models is missing recall due to ing templates and missing role fillers. This strongly suggests future systems can maximize their performance by being less conservative in role filler detection and focusing on improvement of the recall, even at the expense of potentially decreasing some precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Limitations and Future Work</head><p>This work explores subtypes of Spurious Role Filler errors extensively, however, we would like to further analyze Missing Role Filler and templatelevel errors for more fine-grained error subtypes and the linguistic reasons behind why they occur. Due to the pairwise comparisons between all predicted and gold mentions in a role for all pairs of predicted and gold templates in an example, the error analysis tool is slow when the number of both the predicted and gold templates as well as the number of role fillers in the templates is high. Thus, we would also like to improve the time complexity of our template (and mention) matching algorithms using an approach like bipartite matching <ref type="bibr" target="#b35">(Yang et al., 2021)</ref>.</p><p>Currently, the error analysis tool reports exact match precision/recall/F1 which is more suitable for string-fill roles. We would like to extend the tool to further analyze set-fill roles by implementing metrics such as false-positive rate.</p><p>We used a limited number of models in this paper as we aimed to develop and test the usability of our error analysis tool. In the future, however, we would like to test our tool on a wider range of models, in addition to running more experiments in order to reach more generalizable conclusions about the behavior of IE models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>As new models for information extraction continue to be developed, we find that their predicted error types contain insights regarding their shortcomings. Analyzing error patterns within model predictions in a more fine-grained manner beyond scores provided by commonly used metrics is important for the progress of the field. We introduce a framework for the automatic categorization of model prediction errors for document-level IE tasks. We used the tool to analyze the errors of two state-of-the-art models on three datasets from varying domains and compared the error profiles of these models to four of the earliest systems in the field on a dataset from that era. We find that state-of-the-art models, when compared to the earlier manual feature-based models, perform better at span extraction but worse at template detection and role assignment. With a better balance between precision and recall, the best early model outperforms the relatively high-precision, low-recall mod-ern models. Missing role fillers remain the main source of errors, and scientific corpora are the most difficult for all systems, suggesting that improvements in these areas should be a priority for future system development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Detailed Error Types Mappings</head><p>The specific list of transformations applied in the error correction process.</p><p>(1) Span Error. Each singleton Alter Span transformation is mapped to a Span Error. A Span Error occurs when a predicted role filler becomes an exact match to the a gold role filer only upon span alteration.</p><p>(2) Duplicate Role Filler. Each singleton Remove Duplicate Role Filler transformation is mapped to a Duplicate Role Filler error. A Duplicate Role Filler error occurs when a spurious role filler is coreferent to an already matched role filler and is treated as a separate entity. This happens when the system fails at coreference resolution.</p><p>(3) Duplicate Partially Matched Role Filler (Spurious). Same as (2) above, but with an added Alter Span transformation applied first to account for partial matching. This happens when the system fails at correct span extraction and coreference resolution.</p><p>(4) Spurious Role Filler. Each singleton Remove Spurious Role Filler transformation is mapped to a Spurious Role Filler error. A Spurious Role Filler error occurs when a mention is extracted from the text with no connection to the gold templates.</p><p>(5) Missing Role Filler. Each singleton Introduce Role Filler transformation is mapped to a Missing Role Filler error. A Missing Role Filler error occurs when a role filler is present in the gold template but not the predicted template for a given role.</p><p>(6) Incorrect Role. Each singleton Alter Role transformation is mapped to an Incorrect Role. An Incorrect Role occurs when a spurious role filler is assigned to the incorrect role within the same template, i.e. the role filler would have been correct if present filled in another slot/role in the same template. This happens when the system fails at correct role assignment.</p><p>(7) Incorrect Role + Partially Matched Filler. Same as ( <ref type="formula">4</ref>) above, but with an added Alter Span transformation applied first to account for partial matching. This happens when the system fails at correct span extraction and role assignment.</p><p>(8) Wrong Template for Role Filler. Each singleton Remove Cross Template Spurious Role Filler transformation is mapped to a Wrong Template for Role Filler error. A Wrong Template for Role Filler occurs when a spurious role filler in one template can be assigned to the correct role in another template, i.e. it would be correct if it had been placed in another template. This happens when the system fails at correct event assignment.</p><p>(9) Wrong Template for Partially Matched Role Filler. Same as (6) above, but with an added Alter Span transformation applied first to account for partial matching. This happens when the system fails at correct span extraction and event assignment.</p><p>(10) Wrong Template + Wrong Role. An Alter Role and Remove Cross Template Spurious Role Filler transformation are applied to the same predicted role filler in that order to be mapped to a Wrong Template + Wrong Role error. A Wrong Template + Wrong Role error occurs when a spurious role filler can be assigned to another role in another template. This happens when the system fails at correct role assignment and event assignment.</p><p>(11) Wrong Template + Wrong Role + Partially Matched Filler. Same as (8) above, but with an added Alter Span transformation applied first to account for partial matching. This happens when the system fails at correct span extraction, role assignment and event assignment.</p><p>(12) Spurious Template.<ref type="foot" target="#foot_10">13</ref> Each singleton Remove Template is mapped to a Spurious Template error. A Spurious Template error occurs when an extra predicted template is present that cannot be matched to a gold template.</p><p>(13) Missing Template.<ref type="foot" target="#foot_11">14</ref> Each singleton Introduce Template transformation is mapped to a Missing Template error. A Missing Template error occurs when there is a gold template remaining that has no matching predicted template.</p><p>Table <ref type="table">5</ref>: Some examples of the Error Types taken from the ProMED dataset. For each template, in every role, the role fillers within brackets refer to the same entity, while role fillers in different brackets refer to different entities. The text in bold black indicates the error in the prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Precision, Recall, and F1 Scores for All Models on all Three Datasets</head><p>We also provide additional precision, recall scores along with the F1 scores. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Computational Budget</head><p>The GTT (BERT) model on the MUC-4 dataset took 1 hour and 21 minutes to train and around 11 minutes to test on Google Colab (GPU).</p><p>The GTT (BERT) model on the ProMED dataset took around 24 minutes to train and 4 minutes to test, while the GTT (SciBERT) model on the ProMED dataset took around 13 minutes to train and 4 minutes to test, both on Google Colab (GPU). The DyGIE++ (BERT) model on the ProMED dataset took around 50 minutes to train, while the DyGIE++ (SciBERT) model on the ProMED dataset took around 1 hour and 30 minutes to train, both on a NVIDIA V100 GPU.</p><p>For the SciREX dataset, it took around 10-20 minutes to run the GTT (BERT) and GTT (SciBERT) models on a NVIDIA V100 GPU. It is worth noting that since the GTT model embeds all inputs before training and SciREX documents are extremely long, more than 25 GB of memory needs to be allocated at the embedding phrase. The training process has normal memory usage. The DyGIE++ (BERT) model took around 2 hours to train, while the DyGIE++ (SciBERT) model took around 4 hours to train, both on a NVIDIA V100 GPU.</p><p>Our error analysis tool can be run completely on a CPU and takes a couple of minutes to run, depending on the size of the dataset and the predicted outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Hyperparameters and Model Configurations</head><p>We did not run the DyGIE++ model on the MUC-4 dataset as the model output was made available to us by Xinya Du.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>-Figure 1 :</head><label>1</label><figDesc>Figure1: The document-level extraction task from the ProMED dataset on disease outbreaks (left) and the automatic error analysis process (right). Our system performs a set of transformations on the predicted templates to convert them into the corresponding gold standard templates. Transformation steps are mapped to corresponding error types to produce informative error statistics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Automatic transformations to convert predicted templates (on the left) to gold templates (on the right). Arrows represent transformations. Colored circles represent role filler entity mentions. Dupl. stands for duplicate.</figDesc><graphic url="image-1.png" coords="4,452.25,101.60,61.69,83.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Automated Error Analysis Results (Error Counts) for Models on the MUC-4 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>so that the dataset is transformed into standardized templates. The roles chosen from the MUC-4 dataset are PERPIND (individual perpetrator), PERPORG (organization perpetrator), TARGET (physical target), VICTIM (human target), and WEAPON which are all string-fill roles, as well as INCIDENT TYPE which is a set-fill role with six possible role fillers: attack, kidnapping, bombing, arson, robbery, and forced work stoppage. As seen in Table 1, 44.59% of the documents have no templates, which makes the identification of relevant vs. irrelevant documents critical to the success of any IE model for this dataset. ProMED 8 (Patwardhan and Riloff, 2009) consists of just 125 annotated tuning examples and 120 annotated test examples, describing global disease outbreaks by subject matter experts from ProMED.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Dataset Statistics. A relevant document has one or more templates.</figDesc><table><row><cell>During pre-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Precision, Recall, and F1  scores for models on the MUC-4 dataset. The first four models were developed in 1992, while the last two models are recent and use neural-based methods.</figDesc><table><row><cell>Predicted</cell><cell>Gold Match</cell></row><row><cell>power lines along the</cell><cell>power lines</cell></row><row><cell>road</cell><cell></cell></row><row><cell>enrique ruiz, retired</cell><cell>enrique ruiz</cell></row><row><cell>maoist shining path</cell><cell>shining path</cell></row><row><cell>group</cell><cell></cell></row><row><cell>group of unidentified in-</cell><cell>group of unidentified indi-</cell></row><row><cell>dividuals who hurled a</cell><cell>viduals</cell></row><row><cell>bomb ... passing vehicle</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Error Counts for Models on the MUC -4 Dataset</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Span Error</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Duplicate Role Filler</cell></row><row><cell>Models</cell><cell>DyGIE++ (BERT) GTT (BERT) GE NYU SRI</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Within Within + Cross</cell><cell>Template Template</cell><cell>Duplicate Partially Matched Role Filler Spurious Role Filler Missing Role Filler Incorrect Role Incorrect Role + Partially Matched Filler Wrong Template Role Filler Wrong Template For Partially Matched Role Filler Wrong Template + Wrong Role Wrong Template + Wrong Role</cell><cell>S D D S M In In W W W W S</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>+ Partially Matched Filler</cell><cell>S</cell></row><row><cell></cell><cell>UMass</cell><cell>0</cell><cell>250</cell><cell>500</cell><cell>750</cell><cell>1000</cell><cell>Template</cell><cell>Detection</cell><cell>Spurious Template Spurious Template Role Filler Missing Template Missing Template Role Filler</cell><cell>M M</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Number of Errors</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Precision, Recall and F1 Scores (%).</figDesc><table><row><cell>Models</cell><cell>SciREX</cell><cell>ProMED</cell><cell>MUC-4</cell></row><row><cell>DyGIE++ (BERT)</cell><cell cols="3">27.85 / 18.83 / 22.47 51.13 / 26.62 / 35.01 61.90 / 36.33 / 45.79</cell></row><row><cell cols="3">DyGIE++ (SciBERT) 30.47 / 21.76 / 25.39 52.55 / 29.94 / 38.15</cell><cell>-</cell></row><row><cell>GTT (BERT)</cell><cell cols="3">52.86 / 13.53 / 21.54 68.58 / 33.09 / 44.64 63.18 / 40.02 / 49.00</cell></row><row><cell>GTT (SciBERT)</cell><cell cols="2">53.68 / 18.65 / 27.68 64.68 / 32.16 / 42.96</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>GTT on the MUC-4 dataset</figDesc><table><row><cell></cell><cell cols="3">GTT (BERT)</cell></row><row><cell cols="2">Hyperparameter Name</cell><cell>Value</cell></row><row><cell cols="2">number of gpus</cell><cell>1</cell></row><row><cell cols="2">number of tpu cores</cell><cell>0</cell></row><row><cell cols="2">max_grad_norm</cell><cell>1.0</cell></row><row><cell cols="2">gradient_accumulation_steps</cell><cell>1</cell></row><row><cell>seed</cell><cell></cell><cell>1</cell></row><row><cell>base_model</cell><cell cols="3">bert_base_uncased</cell></row><row><cell>learning_rate</cell><cell></cell><cell>5e-05</cell></row><row><cell>weight_decay</cell><cell></cell><cell>0.0</cell></row><row><cell>adam_epsilon</cell><cell></cell><cell>1e-08</cell></row><row><cell>warmup_steps</cell><cell></cell><cell>0</cell></row><row><cell cols="2">num_train_epochs</cell><cell>20</cell></row><row><cell cols="2">train_batch_size</cell><cell>1</cell></row><row><cell cols="2">eval_batch_size</cell><cell>1</cell></row><row><cell cols="2">max_seq_length_src</cell><cell>435</cell></row><row><cell cols="2">max_seq_length_tgt</cell><cell>75</cell></row><row><cell>threshold</cell><cell></cell><cell>80.0</cell></row><row><cell></cell><cell>GTT (BERT)</cell><cell></cell><cell>GTT (SciBERT)</cell></row><row><cell>Hyperparameter Name</cell><cell>Value</cell><cell></cell><cell>Value</cell></row><row><cell>number of GPUs</cell><cell>1</cell><cell></cell><cell>1</cell></row><row><cell>number of TPU cores</cell><cell>0</cell><cell></cell><cell>0</cell></row><row><cell>max_grad_norm</cell><cell>1.0</cell><cell></cell><cell>1.0</cell></row><row><cell>gradient_accumulation_steps</cell><cell>1</cell><cell></cell><cell>1</cell></row><row><cell>seed</cell><cell>1</cell><cell></cell><cell>1</cell></row><row><cell>base_model</cell><cell cols="2">bert_base_uncased</cell><cell>allenai_ scibert_</cell></row><row><cell></cell><cell></cell><cell cols="2">scivocab_uncased</cell></row><row><cell>learning_rate</cell><cell>5e-05</cell><cell></cell><cell>5e-05</cell></row><row><cell>weight_decay</cell><cell>0.0</cell><cell></cell><cell>0.0</cell></row><row><cell>adam_epsilon</cell><cell>1e-08</cell><cell></cell><cell>1e-08</cell></row><row><cell>warmup_steps</cell><cell>0</cell><cell></cell><cell>0</cell></row><row><cell>num_train_epochs</cell><cell>36</cell><cell></cell><cell>36</cell></row><row><cell>train_batch_size</cell><cell>1</cell><cell></cell><cell>1</cell></row><row><cell>eval_batch_size</cell><cell>1</cell><cell></cell><cell>1</cell></row><row><cell>max_seq_length_src</cell><cell>435</cell><cell></cell><cell>435</cell></row><row><cell>max_seq_length_tgt</cell><cell>75</cell><cell></cell><cell>75</cell></row><row><cell>threshold</cell><cell>80.0</cell><cell></cell><cell>80.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>GTT Models on the ProMED dataset</figDesc><table><row><cell></cell><cell>GTT (BERT)</cell><cell>GTT (SciBERT)</cell></row><row><cell>Hyperparameter Name</cell><cell>Value</cell><cell>Value</cell></row><row><cell>number of GPUs</cell><cell>1</cell><cell>1</cell></row><row><cell>number of TPU cores</cell><cell>0</cell><cell>0</cell></row><row><cell>max_grad_norm</cell><cell>1.0</cell><cell>1.0</cell></row><row><cell>gradient_accumulation_steps</cell><cell>1</cell><cell>1</cell></row><row><cell>seed</cell><cell>1</cell><cell>1</cell></row><row><cell>base_model</cell><cell>bert_base_uncased</cell><cell>allenai_ scibert_</cell></row><row><cell></cell><cell></cell><cell>scivocab_uncased</cell></row><row><cell>learning_rate</cell><cell>5e-05</cell><cell>5e-05</cell></row><row><cell>weight_decay</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>adam_epsilon</cell><cell>1e-08</cell><cell>1e-08</cell></row><row><cell>warmup_steps</cell><cell>0</cell><cell>0</cell></row><row><cell>num_train_epochs</cell><cell>20</cell><cell>20</cell></row><row><cell>train_batch_size</cell><cell>1</cell><cell>1</cell></row><row><cell>eval_batch_size</cell><cell>1</cell><cell>1</cell></row><row><cell>max_seq_length_src</cell><cell>435</cell><cell>435</cell></row><row><cell>max_seq_length_tgt</cell><cell>75</cell><cell>75</cell></row><row><cell>threshold</cell><cell>80.0</cell><cell>80.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 :</head><label>9</label><figDesc>GTT Models on the SciREX dataset</figDesc><table><row><cell></cell><cell cols="2">DyGIE++ (BERT) DyGIE++ (SciBERT)</cell></row><row><cell>Hyperparameter Name</cell><cell>Value</cell><cell>Value</cell></row><row><cell>number of GPUs</cell><cell>1</cell><cell>1</cell></row><row><cell>max_span_width</cell><cell>11</cell><cell>11</cell></row><row><cell>base_model</cell><cell>bert_base_cased</cell><cell>allenai_ scibert_</cell></row><row><cell></cell><cell></cell><cell>scivocab_cased</cell></row><row><cell>learning_rate</cell><cell>5e-04</cell><cell>5e-04</cell></row><row><cell>patience</cell><cell>5</cell><cell>5</cell></row><row><cell>num_train_epochs</cell><cell>20</cell><cell>20</cell></row><row><cell>train_batch_size</cell><cell>32</cell><cell>32</cell></row><row><cell>num_dataloader_workers</cell><cell>2</cell><cell>2</cell></row><row><cell>max seq length</cell><cell>512</cell><cell>512</cell></row><row><cell>ner loss weight</cell><cell>1.0</cell><cell>1.0</cell></row><row><cell>relation loss weight</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>coreference loss weight</cell><cell>0.2</cell><cell>0.2</cell></row><row><cell>events loss weight</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>target task</cell><cell>ner</cell><cell>ner</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 :</head><label>10</label><figDesc>DyGIE++ Models on the ProMED dataset</figDesc><table><row><cell></cell><cell cols="2">DyGIE++ (BERT) DyGIE++ (SciBERT)</cell></row><row><cell>Hyperparameter Name</cell><cell>Value</cell><cell>Value</cell></row><row><cell>number of GPUs</cell><cell>1</cell><cell>1</cell></row><row><cell>max_span_width</cell><cell>8</cell><cell>8</cell></row><row><cell>base_model</cell><cell>bert_base_cased</cell><cell>allenai_ scibert_</cell></row><row><cell></cell><cell></cell><cell>scivocab_cased</cell></row><row><cell>learning_rate</cell><cell>5e-04</cell><cell>5e-04</cell></row><row><cell>patience</cell><cell>5</cell><cell>5</cell></row><row><cell>num_train_epochs</cell><cell>20</cell><cell>20</cell></row><row><cell>train_batch_size</cell><cell>32</cell><cell>32</cell></row><row><cell>num_dataloader_workers</cell><cell>2</cell><cell>2</cell></row><row><cell>max seq length</cell><cell>512</cell><cell>512</cell></row><row><cell>ner loss weight</cell><cell>1.0</cell><cell>1.0</cell></row><row><cell>relation loss weight</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>coreference loss weight</cell><cell>0.2</cell><cell>0.2</cell></row><row><cell>events loss weight</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>target task</cell><cell>ner</cell><cell>ner</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 11 :</head><label>11</label><figDesc>DyGIE++ Models on the SciREX dataset</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>See, for example,<ref type="bibr" target="#b37">Zhang et al. (2019)</ref>,<ref type="bibr" target="#b7">Du and Cardie (2020)</ref> and<ref type="bibr" target="#b18">Lin et al. (2020)</ref> for within-sentence event extraction;<ref type="bibr" target="#b1">Akbik et al. (2018)</ref>, and<ref type="bibr" target="#b0">Akbik et al. (2019)</ref> for named entity recognition (NER); and<ref type="bibr" target="#b38">Zhang et al. (2018)</ref> and<ref type="bibr" target="#b19">Luan et al. (2019)</ref> for sentence-level relation extraction.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>http://www.promedmail.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>The 1992 model outputs are available in the MUC-4 dataset released by NIST, available at https: //www-nlpir.nist.gov/related_projects/ muc/muc_data/muc_data_index.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>There are potentially more role types depending on the dataset (e.g. normalized dates, times, locations); we will not consider those here.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>This deviates from<ref type="bibr" target="#b16">Kummerfeld and Klein (2013)</ref>, in which incorrect spans are altered to gold mentions that have the same head token, requiring the use of a syntactic parser.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5"><p>http://www.promedmail.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6"><p>In the ProMED dataset, COUNTRY is a set-fill role, but since countries are explicitly mentioned in most of the documents, we can treat this role as a string-fill.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_7"><p>10 https://paperswithcode.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_8"><p>com 11 According toJain et. al., around 50%  of relations in the SciREX dataset contain one or more role fillers that do not appear in the corresponding text. These relations are removed during evaluation for our end-to-end task. https://github.com/allenai/SciREX/blob/master/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_9"><p>README.md12  Removing unmentioned entities sometimes eliminates differences between templates. This results in some templates becoming identical or making some templates contain information that is a subset of the information present in another</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_10"><p>The role fillers in the Spurious Templates are not added to the Spurious Role Filler error counts but are accounted for in the Spurious Template Role Filler counts.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_11"><p>The role fillers in the Missing Templates are not added to the Missing Role Filler error counts but are accounted for in the Missing Template Role Filler counts.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank the anonymous reviewers and <rs type="person">Ellen Riloff</rs> for their helpful comments(!) and <rs type="person">Sienna Hu</rs> for converting the 1992 model outputs to a format compatible with our error analysis tool. Our research was supported, in part, by <rs type="funder">NSF</rs> <rs type="grantName">CISE Grant</rs> <rs type="grantNumber">1815455</rs> and the <rs type="funder">Cornell CS Department CSURP</rs> grants for undergraduate research.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_nNU6df8">
					<idno type="grant-number">1815455</idno>
					<orgName type="grant-name">CISE Grant</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Example Error Types with ProMED</head><p>We also provide example error types with the ProMED dataset. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pooled contextualized embeddings for named entity recognition</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanja</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1078</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="724" to="728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Contextual string embeddings for sequence labeling</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duncan</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1638" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">TACRED revisited: A thorough evaluation of the TACRED relation extraction task</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Alt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Gabryszak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonhard</forename><surname>Hennig</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.142</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1558" to="1569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">CrossCheck: Rapid, reproducible, and interpretable model evaluation</title>
		<author>
			<persName><forename type="first">Dustin</forename><surname>Arendt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuanyi</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasha</forename><surname>Shrestha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellyn</forename><surname>Ayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Glenski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.dash-1.13</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Data Science with Human in the Loop: Language Advances</title>
		<meeting>the Second Workshop on Data Science with Human in the Loop: Language Advances</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="79" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Event schema induction with a probabilistic entity-driven model</title>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1797" to="1807" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">MUC-3 evaluation metrics</title>
		<author>
			<persName><forename type="first">Nancy</forename><surname>Chinchor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third Message Uunderstanding Conference</title>
		<meeting><address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991-05-21">1991. May 21-23, 1991</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings of a Conference Held in</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Xinya</forename><surname>Du</surname></persName>
		</author>
		<title level="m">Towards More Intelligent Extraction of Information from Documents</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
		<respStmt>
			<orgName>Cornell University. Copyright -Database copyright Pro-Quest LLC</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
	<note>ProQuest does not claim copyright in the individual underlying works</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Event extraction by answering (almost) natural questions</title>
		<author>
			<persName><forename type="first">Xinya</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.49</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="671" to="683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">2021a. GRIT: Generative role-filler transformers for document-level event entity extraction</title>
		<author>
			<persName><forename type="first">Xinya</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="634" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">2021b. Template filling with generative transformers</title>
		<author>
			<persName><forename type="first">Xinya</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.70</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="909" to="914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Linguisticbased evaluation criteria to identify statistical machine translation errors</title>
		<author>
			<persName><forename type="first">Mireia</forename><surname>Farr?s</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><forename type="middle">R</forename><surname>Costa-Juss?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jos?</forename><forename type="middle">B</forename><surname>Mari?o</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jos?</forename><forename type="middle">A R</forename><surname>Fonollosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Annual conference of the European Association for Machine Translation</title>
		<meeting>the 14th Annual conference of the European Association for Machine Translation<address><addrLine>Saint Rapha?l, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Association for Machine Translation</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Twenty-five years of information extraction</title>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="677" to="692" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">SciREX: A challenge dataset for document-level information extraction</title>
		<author>
			<persName><forename type="first">Sarthak</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madeleine</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.670</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7506" to="7516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
		<title level="m">2021. Speech and language processing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>rd ed. draft, chapter 17. information extraction</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Automatic error analysis for morphologically rich languages</title>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Kholy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Parser showdown at the Wall Street corral: An empirical investigation of error types in parser output</title>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Jeju Island</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1048" to="1059" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Errordriven analysis of challenges in coreference resolution</title>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="265" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Documentlevel event argument extraction by conditional generation</title>
		<author>
			<persName><forename type="first">Sha</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.69</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="894" to="908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A joint neural model for information extraction with global features</title>
		<author>
			<persName><forename type="first">Ying</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfei</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.713</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7999" to="8009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A general framework for information extraction using dynamic span graphs</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1308</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3036" to="3046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Analyzing and visualizing coreference resolution errors</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Martschat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>G?ckel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/N15-3002</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="6" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Recall error analysis for coreference resolution</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Martschat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1221</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2070" to="2081" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><surname>Muc-3</surname></persName>
		</author>
		<title level="m">Third Message Understanding Conference</title>
		<meeting><address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991-05-21">1991. May 21-23, 1991</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings of a conference held in</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fourth message understanding conference (MUC-4)</title>
		<author>
			<persName><surname>Muc-4</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of FOURTH MES-SAGE UNDERSTANDING CONFERENCE (MUC</title>
		<meeting>FOURTH MES-SAGE UNDERSTANDING CONFERENCE (MUC</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Virginia</forename><surname>Mclean</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A unified model of phrasal and sentential evidence for information extraction</title>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="151" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Towards automatic error analysis of machine translation output</title>
		<author>
			<persName><forename type="first">Maja</forename><surname>Popovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<idno type="DOI">10.1162/COLI_a_00072</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="657" to="688" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction beyond the sentence boundary</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1171" to="1182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Beyond accuracy: Behavioral testing of NLP models with CheckList</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongshuang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.442</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4902" to="4912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Error analysis for learningbased coreference resolution</title>
		<author>
			<persName><forename type="first">Olga</forename><surname>Uryupina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC&apos;08)</title>
		<meeting>the Sixth International Conference on Language Resources and Evaluation (LREC&apos;08)<address><addrLine>Marrakech, Morocco</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Error analysis in an automated narrative information extraction pipeline</title>
		<author>
			<persName><forename type="first">Josep</forename><surname>Valls-Vargas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jichen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santiago</forename><surname>Onta??n</surname></persName>
		</author>
		<idno type="DOI">10.1109/TCIAIG.2016.2575823</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computational Intelligence and AI in Games</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="342" to="353" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Error analysis of statistical machine translation output</title>
		<author>
			<persName><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D'</forename><surname>Haro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC&apos;06)</title>
		<meeting>the Fifth International Conference on Language Resources and Evaluation (LREC&apos;06)<address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Entity, relation, and event extraction with contextualized span representations</title>
		<author>
			<persName><forename type="first">David</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulme</forename><surname>Wennberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1585</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5784" to="5789" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">AllenNLP interpret: A framework for explaining of NLP models</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><surname>Tuyls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junlin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-3002</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Errudite: Scalable, reproducible, and testable error analysis</title>
		<author>
			<persName><forename type="first">Tongshuang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Weld</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1073</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="747" to="763" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Document-level event extraction via parallel prediction networks</title>
		<author>
			<persName><forename type="first">Hang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dianbo</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.492</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6298" to="6308" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Addicter: What is wrong with my translations?</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Daniel Zeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Fishel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondrej</forename><surname>Berka</surname></persName>
		</author>
		<author>
			<persName><surname>Bojar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Prague Bull. Math. Linguistics</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Extracting entities and events as a single task using a transition-based neural model</title>
		<author>
			<persName><forename type="first">Junchi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanxia</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengchi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghong</forename><surname>Ji</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/753</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJ-CAI 2019</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJ-CAI 2019<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-08-10">2019. August 10-16, 2019</date>
			<biblScope unit="page" from="5422" to="5428" />
		</imprint>
	</monogr>
	<note>ijcai.org</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Graph convolution over pruned dependency trees improves relation extraction</title>
		<author>
			<persName><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1244</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2205" to="2215" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Diagnostic evaluation of machine translation systems using automatically constructed linguistic check-points</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008)</title>
		<meeting>the 22nd International Conference on Computational Linguistics (Coling 2008)<address><addrLine>Manchester, UK. Coling</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="1121" to="1128" />
		</imprint>
	</monogr>
	<note>Organizing Committee</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
