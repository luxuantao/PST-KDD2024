<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DSDP: Dual Stream Data Prefetcher</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mingjian</forename><surname>He</surname></persName>
							<email>mingjianhe@hust.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Wuhan National Laboratory for Optoelectronics</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Wuhan National Laboratory for Optoelectronics</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hua</forename><surname>Wang</surname></persName>
							<email>hwang@hust.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Wuhan National Laboratory for Optoelectronics</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Wuhan National Laboratory for Optoelectronics</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ke</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Wuhan National Laboratory for Optoelectronics</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Wuhan National Laboratory for Optoelectronics</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kaichao</forename><surname>Cui</surname></persName>
							<email>kaichaocui@hust.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Wuhan National Laboratory for Optoelectronics</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Wuhan National Laboratory for Optoelectronics</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huabing</forename><surname>Yan</surname></persName>
							<email>yanhuabing@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Huawei Cloud Computing Technologies Co</orgName>
								<address>
									<settlement>Ltd, Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Huawei Cloud Computing Technologies Co</orgName>
								<address>
									<settlement>Ltd, Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chang</forename><surname>Guo</surname></persName>
							<email>guochang8@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Huawei Cloud Computing Technologies Co</orgName>
								<address>
									<settlement>Ltd, Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Huawei Cloud Computing Technologies Co</orgName>
								<address>
									<settlement>Ltd, Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rongfeng</forename><surname>He</surname></persName>
							<email>herongfeng@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Huawei Cloud Computing Technologies Co</orgName>
								<address>
									<settlement>Ltd, Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DSDP: Dual Stream Data Prefetcher</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3559009.3569677</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Data Prefetching</term>
					<term>Caching</term>
					<term>Microarchitecture</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hardware prefetching is an important DRAM latency hiding technology. Designing prefetchers to maximize system performance often requires a delicate balance between coverage and accuracy. As the number of cores increases, the accuracy of the prefetching algorithm becomes more important. Separating streams based on memory access instructions is an effective way to improve accuracy. However, this technique may lose prefetch opportunities by losing cross-PC relationships, and even reduce algorithm coverage.</p><p>In this paper, we propose a spatial prefetcher called Dual Stream Data Prefetcher (DSDP). DSDP achieves high coverage and accuracy with two designs. First, DSDP improves prefetching accuracy by PC localizing. Second, DSDP simultaneously learns cross-PC relationships from the spatial localized stream to compensate for the loss of prefetching opportunities brought by PC localization.</p><p>Our experimental results show that, DSDP improves system performance by 41.9% over a baseline with no data prefetcher and 4.1% over the state-of-the-art spatial data prefetcher.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The long-latency off-chip memory access remains a bottleneck in modern computer systems. Due to the speed difference between processor execution and memory access latency, the processor will stall hundreds of cycles during an off-chip miss, resulting in severe performance loss.</p><p>Hardware prefetching is a well-studied technique to help overcome the memory gap. Prefetchers predict future memory access based on historical access information and fetch the data in the cache before the processor explicitly asks for them to mitigate the latency of cache misses. Designing prefetchers to maximize system performance often requires a delicate balance between coverage and accuracy.</p><p>Coverage is the single primary consideration in the existing prefetchers' design which refers to the ratio of effective prefetches to the total number of demand misses. In the case of low core count and sufficient DRAM bandwidth, maximizing coverage means the most loss reduction and yielding the best performance gains. However, as the number of cores increases, accuracy becomes more critical which refers to the ratio of effective prefetches to the total number of prefetches. Inaccurate prefetches affect performance in two ways. First, prefetching unneeded data into the cache can cause cache pollution, which causes valid data to be evicted before it is used. Second, additional prefetching will put pressure on limited memory bandwidth, which may increase the latency of responses from memory. Therefore, the prefetcher should achieve high coverage and accuracy.</p><p>Existing prefetch algorithms mainly improve accuracy in three ways. (i) Some prefetch algorithms like SPP <ref type="bibr" target="#b16">[18]</ref> will give each prefetch candidate a confidence value. Prefetch is triggered only when the confidence value is higher than the threshold value. Raising the threshold can guarantee the accuracy of the prefetching algorithm. (ii) Some prefetching algorithms such as Bingo <ref type="bibr" target="#b4">[6]</ref> achieve high accuracy by learning long events. These events include Program Counter (PC), offset, and address. Long events mean satisfying multiple events at the same time. By tracking both long and short events, Bingo can become more accurate. (iii) Some prefetch algorithms like ISB <ref type="bibr" target="#b14">[16]</ref> use PC localization to improve coverage and accuracy. Localization is a process that divides the global address stream into multiple streams. PC localization means that this separation is according to the PC of memory access instruction, which is an instance of execution context localization.</p><p>Localization filters out the non-predictable misses and creates a more predictable stream to achieve high accuracy. In previous methods, localization is used as a filtering method, and the prefetcher only learns on streams filtered by a certain localization method. Therefore, the literature <ref type="bibr" target="#b20">[22]</ref> proposes a taxonomy that classifies prefetching algorithms with a pair X/Y. In this taxonomy, X is the localization method when Y is the mechanism for detecting addressing modes. For instance, SPP is referred to as spatial/delta due to its use of spatial localization and capturing address delta correlation. ISB which uses PC localization and learns address relationships is then referred to as PC/address correlation (AC). The predictor in <ref type="bibr" target="#b29">[31]</ref> separates the miss streams according to the time when the misses occur and captures the correlation of the addresses, which is referred to as Time/AC.</p><p>Despite the ability to improve accuracy, existing spatial prefetchers <ref type="bibr" target="#b6">[8,</ref><ref type="bibr" target="#b7">9,</ref><ref type="bibr" target="#b23">25]</ref>   that taking PC localization as a filter would lose many prefetch opportunities, which will result in low coverage. More specifically, PC localization isolates access to different PCs, reducing information entropy and improving accuracy while losing cross-PC information.</p><formula xml:id="formula_0">A1 A5 B1 A2 A3 B5 A4 A2 A4 A1 A3 A1 A1 A2 A3 A2 A3 A1 A5 A4 B1 B5 A4 A1 A1 A5 A2 A3 A4 A2 A4 A1 A3 A1 B1 B5</formula><p>The existing approach treats localization as a filter, making the prefetcher analyze only one stream and only choose between the high accuracy of PC localization and the high coverage of spatial localization. An intuitive solution is to learn cross-PC relationships from other localization methods while benefiting from the accuracy of PC localization. When we consider localization as an event, we can both predict the address to be visited with high probability under event ?? and analyze the streams under event ????? to avoid losing prefetching opportunities by focusing on only one stream.</p><p>Statistically speaking, we get more high probability events by increasing the conditional (PC), while focusing on the unconditional cases to avoid our coverage being too low. However, learning from both streams at the same time faces two problems. First, PC localized streams are essentially a subset of spatially localized streams, which means that the associations learned from both streams are likely to be redundant. Second, increasing the prefetching range (adding cross-PC correlations) often leads to a decrease in accuracy. The relationship between the two needs to be reconciled to obtain a better performance improvement.</p><p>This paper introduces the Dual Stream Data Prefetcher (DSDP), a new spatial prefetcher that tracks high probability events on both the PC localized stream and the spatial localized stream. The main idea is to treat localization as an event rather than a filtering method and track high-probability events occurring on different streams. DSDP ensures the accuracy by PC localization and guarantees the coverage through cooperative prefetching among different streams. DSDP designs two new prefetcher components according to the characteristics of the two streams. In addition, to solve the nonorthogonal problem of the prefetch component, DSDP makes two prefetchers learn from the access stream and the missing stream respectively and adjusts the degree of prefetch aggression according to their respective prefetch accuracy.</p><p>This paper makes the following contributions:</p><p>? We find that taking localization as an event instead of a filtering method can effectively improve the coverage and accuracy of the prefetch algorithm. ? We propose a new classification method for component prefetcher which performs well. ? We propose Dual Stream Data Prefetcher (DSDP), a spatial prefetcher that learns from the PC localized stream and the spatial localized stream. The two prefetch components of DSDP complement each other by prefetching between different streams and guarantee the accuracy and coverage by tracking high-probability events that occur on different streams. ? We show that our proposal improves the system performance by 41.9% on average over a baseline with no prefetcher. Meanwhile, it outperforms the best-performing prior spatial data prefetcher by 4.1% on average. This paper is organized as follows. Section 2 places the background and motivation of this work. Section 3 describes our solution. Section 4 evaluates our solution. In Section 5, we discuss related work and then conclude in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND MOTIVATION</head><p>In this section, we first review the fundamental concepts of localization and then discuss the advantages and disadvantages of this technology.</p><p>Localization is a technique that segregates prefetcher inputs into multiple streams based on different properties to improve coverage and accuracy. These properties include the PC of the instruction <ref type="bibr" target="#b20">[22]</ref>, the region of memory they reference <ref type="bibr" target="#b19">[21]</ref>, and the time period <ref type="bibr" target="#b27">[29]</ref>.</p><p>Figure <ref type="figure" target="#fig_1">1</ref> depicts a simple example of a global address stream and its generated stream under PC and spatial localization. At the top of the figure is a record of the access stream, each access consists of the data address and the PC that generated the address. In this example, there are three different PCs and two address regions (A and B). The global stream is the entire address sequence of the access stream. Below the global stream are the address sequences localized according to different PCs or memory regions.</p><p>Localization can improve the accuracy of the prefetch algorithm. In essence, localization exploits the inherent characteristics of programs and data structures to make streams more predictable. For instance, PC localization takes advantage of the fact that the data-dependent correlation of addresses under the same PC is more stable. Similarly, spatial localization exploits the fact that regular data structures are usually arranged in contiguous parts of the address space and are usually accessed in the same pattern. Taking Figure <ref type="figure" target="#fig_1">1</ref> as an example, a stream localized by ?? ? shows a high degree of predictability. In this example, the flow shows strong repetition after filtering the memory access with other PCs, which is very helpful to increase the accuracy of the prefetch algorithm. As the program becomes more complex and the execution phases become more diverse, predicting future memory access from the global stream is not a simple task. PC localization can form a more predictable flow by using additional execution context to alleviate this problem.</p><p>Using localization as a filtering method will lead to the loss of prefetch opportunities. As part of the information is lost in localization, it will inevitably lead to the loss of our prefetch opportunities. Taking Figure <ref type="figure" target="#fig_1">1</ref> as an example, we can see that ? 5 has a high probability of appearing after ? 1 visits, but this pattern disappeared after PC localization. The disappearance will cause the coverage of the prefetch algorithm to decrease, so most of the existing spatial prefetchers <ref type="bibr" target="#b4">[6,</ref><ref type="bibr" target="#b16">18,</ref><ref type="bibr" target="#b18">20,</ref><ref type="bibr" target="#b26">28]</ref> do not use PC localization. In essence, this is caused by the elimination of cross-PC data correlations after localization. One solution to this problem is that we learn not only on streams of PC localization but also on streams of spatial localization that preserve cross-PC data correlations. High coverage and accuracy can be achieved by learning on two streams simultaneously. However, since the PC localization stream is a part of the spatial localization stream, the rules learned from the two streams will have great redundancy. To address this issue, we further distinguish between access and miss. For the PC localized stream, we learn the global access stream, and for the spatial localized stream, we learn only the miss stream. This approach can make the prefetcher on the spatial localization stream pay more attention to the unlearned rules under the PC localization stream, thereby reducing the redundancy of learning rules.</p><p>Localization will lead to timeliness problems. Localization filters the access into a certain subset according to a certain feature. During this process, the distance information of the access is lost, which may lead to timeliness problems. For example, two consecutive visits in a PC localization stream may be interleaved with many visits from other PCs. Without knowing the access distance, the prefetcher may prefetch prematurely, causing data to be evicted before it is accessed. Similarly, two adjacent accesses of a spatial localized stream may also be interleaved with many accesses from other address ranges.</p><p>To use localization to improve accuracy while solving the above problems, we design Dual Stream Data Prefetcher, which can learn and prefetch from PC localized streams and spatial localized streams at the same time. Through DSDP, each prefetch candidate can be triggered not only by the previous visit of the same PC but also by the previous visit of the same memory region. In addition, DSDP achieves high coverage and accuracy by coordinating cooperation between two prefetchers and controlling the prefetch thresholds of the two streams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DUAL STREAM DATA PREFETCHER</head><p>This section describes our solution by first summarizing the overall DSDP design and then providing details of the components. DSDP is an L2 prefetcher, which is trained by L2 accesses and issues prefetch requests to fill the L2 cache or LLC. Figure <ref type="figure" target="#fig_2">2</ref> depicts the overall architecture of DSDP. The core idea of DSDP is to improve the prefetching accuracy by PC localization and to ensure the coverage of the prefetcher by preserving the cross-PC relationships in the access by Spatial localization. When DSDP receives global access from L2, it first generates two streams via Localization splitter, solving the problem of timeliness and division of labor between prefetcher components. Subsequently, PC localized Prefetcher and Spatial localized Prefetcher learn from their respective localized streams and issue prefetches. Prefetch Filter merges the prefetch requests of the two prefetchers and filters the duplicates to reduce prefetch overhead. In addition, Prefetch Filter can calculate the accuracy of the two prefetch components, which is used for coordinated prefetch throttling. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Localization splitter</head><p>The Localization splitter is responsible for splitting the global access address stream into PC localized stream and spatial localized stream and ensuring the timeliness of the prefetcher.</p><p>Splitting Workflow: The main workflow of the splitter is shown in figure <ref type="figure">3</ref>. When the splitter receives access to L2 cache, it hashes the page number to get a 15-bit hash value. The 7 most significant bits (MSBs) of the hash value are used as the index, and the 8 least significant bits (LSBs) are used as the Page-tag to identify collisions. The splitter then finds the most recently accessed addresses on the same page and the PC of the instruction that generated them (Step ?). Up to three most recently requested addresses are logged. When the most recent access and the current access have the same PC, we compute the delta between the two addresses to get the corresponding PC localized stream (Step ?). At the same time, we compare the recorded addresses with the currently accessed address and generate multiple Spatial localized accesses (Step ?). Finally, the splitter records the current access to the Recent Request Table (Step ?). RRT uses the FIFO replacement algorithm to select the victims to be evicted.</p><p>Signature. The signature is a feature value compressed from multiple recently accessed delta, which is calculated according to the following formula:</p><formula xml:id="formula_1">? ?? ????????? = (??? ????????? ? 3) ??? (?????)</formula><p>where old signature is the most recent one of the same PC. If the corresponding instruction address is not found, the signature value is set to the default value of 0. This method compresses multiple recently accessed deltas into a signature. The number of shifting bits determines how many delta messages the tag contains. We determined the number of bits experimentally.</p><p>Timeliness. The number of indexes determines how many pages are tracked by the Recent Requests Table (RRT) and the probability of hash collisions. Due to a hash collision, the access that happened long ago is probably replaced by more recent access. By limiting the size of the RRT, the accesses recorded in the RRT are the most recent. RRT keeps track of the 128 most recent page accesses.</p><p>Division of labor. Localization splitter completes the division of prefetching components based on the hit status of the access. Only a cache miss triggers the generation of spatial stream, we will explain this in Section 3.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">PC localized Prefetcher</head><p>We designed a signature-based PC localized Prefetcher for two reasons. First, the signature-based prefetcher can use more information, making it more accurate. Compared to PC-stride prefetchers <ref type="bibr" target="#b10">[12]</ref> that only rely on PC for prediction, signature-based prefetchers can accurately predict complex address patterns based on recent stride information. Second, the signature-based prefetcher is able to predict complex address patterns. After using PC localization, the regularity of the access flow is enhanced, and predicting just one stride does not fully exploit this regularity. The signature-based prefetcher can predict multiple deltas to make greater use of PC localization. With the combination of signature-based prefetching methods and PC localization, PC localized Prefetcher can issue accurate prefetches. Figure <ref type="figure">4</ref> illustrates the flow of training and prediction of the PC localized Prefetcher.   Training phase: After receiving the new visit &lt;Signature, delta&gt; from the Localization splitter, find the entry in the PC localized Predictioin Table according to the signature (Step ?). Update delta and confidence (Step ?). Each table entry contains 4 delta entries. For the delta that has been recorded, increase its confidence by one. If there is no such delta, add it to the table. When the delta entries in the PC localized Prediction table are full, the one with the lowest confidence is used for replacement. To reduce storage overhead, the confidence level is recorded using 3 bits. When the confidence reaches its maximum value, all confidences under the entry are shifted to the right by 1 bit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PC localized stream</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Delta * Signature</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PC localized Prediction</head><p>Prediction phase: Find the entry in the PC localized Predictioin Table according to the signature (Step ?). Divide the confidence of the delta by the sum of all confidences in the same entry to obtain the prefetch confidence of the delta. Combine the delta with the prefetch confidence greater than the threshold (0.3 for LLC, 0.65 for L2) with the current access address to produce a prefetch request (Step ?). Compute a new signature from the old signature and prefetch delta, and continue prefetching until the confidence level does not satisfy the condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Spatial localized Prefetcher</head><p>The main goal of Spatial localized Prefetcher is to make up for the prefetch opportunities lost by PC localized Prefetcher. Therefore, the Spatial localized Prefetcher only learns from miss accesses of the L2 cache. Since the delta pattern of miss access is not stable, signature-based prefetching methods are not suitable for Spatial localized Prefetcher. In the process of predicting the spatial localized stream, we design an improved PC-delta prefetcher. Compared to the old PC-stride prefetcher, it records more history information to improve coverage. Figure <ref type="figure" target="#fig_5">5</ref> illustrates the flow of training and prediction of the Spatial localized Prefetcher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spatial localized stream</head><p>Delta * PC-tag * Address 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PC-tag Address</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spatial localized Prediction Table</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Signatu re</head><p>Signatu re</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prefetch Filter</head><p>Send requests when the confidence is satisfied Training phase: After receiving the new visit &lt;PC-tag, delta&gt; from the Localization splitter, find the entry in the Spatial localized Prediction Table (Figure <ref type="figure" target="#fig_5">5</ref>) according to the PC-tag (Step ?), and record the delta in the table (Step ?). The specific update method is consistent with the PC localized Prefetcher. Similarly, each entry also records 4 deltas, and each confidence uses 3 bits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Update Prediction Table</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Address Delta Confidence</head><p>Prediction phase: Find the delta and confidence in the Spatial localized Prediction table through instructions (Step ?). Divide the confidence of the delta by the sum of all confidences in the same entry to obtain the prefetch confidence of the delta. Combine the delta with the confidence greater than the threshold (0.25 for LLC, 0.7 for L2) with the current access address to produce a prefetch request (Step ?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Prefetch Filter</head><p>The prefetch filter is responsible for filtering the same requests from two prefetchers and tracking the accuracy of the two prefetchers. The prefetch filter table is directly mapped and consists of 4 main parts: cacheline-tag, valid bit, used bit, and prefetcher bit.</p><p>Cacheline-tag is responsible for identifying cache lines. When the cache line already exists in the Prefetch Filter, the insertion fails at this time, and the data address to be prefetched is discarded.</p><p>Valid bit is used to record whether the cache line is in the cache. When a prefetch is performed, the valid bit of the corresponding cache line is set to 1. When the cache line is evicted from the cache, the corresponding valid bit is reset to 0.</p><p>Used bit is responsible for recording whether this prefetch is used. When calculating the accuracy of the prefetcher, it is necessary to count how many prefetches were issued and how many of these prefetches were used. The Prefetch Filter will set the used bit to 1 when the prefetch is used for the first time, and subsequent uses will not be considered as prefetch hits.</p><p>Prefetcher bits are used to distinguish which prefetcher triggered the prefetch. The accuracy of the prefetcher component suffers when it issues prefetches that are discarded because of duplicates, but we find that this has essentially no impact on the performance of DSDP.</p><p>In addition, Prefetch Filter has four global counters, which are used to record the number of prefetch requests ? ?? and ? ??????? , and prefetch uses ? ?? and ? ??????? respectively. Whenever a component issues a prefetch, its corresponding prefetch request count C is added by one. When a prefetch issued by a component is used for the first time, its corresponding prefetch used number U is added by one. The accuracy of the prefetcher component ? ?? and ? ??????? is calculated when needed by the formula ? = ? /?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Coordinator Design</head><p>Coordination among multiple prefetchers is an important task in composite prefetchers <ref type="bibr" target="#b9">[11]</ref>. We need to let different prefetching components know their working domain and control the prefetching aggressiveness according to the accuracy of the components to avoid cache pollution and waste of shared resources.</p><p>Division of target relationships. Unlike existing component prefetchers that identify the boundaries between different components based on PC, we propose a new type of division in DSDP, which is to identify the boundaries by the hit states of the accesses. More specifically, the Localization splitter generates the corresponding streams based on the hit states of the accesses. All accesses generate the corresponding PC localized stream, but only the miss accesses generate the corresponding Spatial localized stream. Since PC localized streams are essentially a subset of spatial localized streams, the high-probability things that happen on PC localized streams tend to happen with high probability on spatial localized streams as well. If both prefetchers learn from the access streams, the access patterns they learn are likely to be redundant, which wastes storage resources and does not improve the coverage of the prefetchers. By dividing the work according to the hit status, the spatial localized prefetcher can pay more attention to the prefetching opportunities lost by the PC localized prefetcher.</p><p>Coordinated Prefetch Throttling. Prefetchers often require control of prefetch aggression to further improve efficiency <ref type="bibr" target="#b12">[14,</ref><ref type="bibr" target="#b15">17,</ref><ref type="bibr" target="#b22">24]</ref>. The threshold configuration of DSDP is empirically derived. Since components behave differently under different loads, we make coordinated prefetch throttling adjustments for better performance based on the accuracy of the components. Every 1024 prefetch fills, we calculate the prefetch accuracy and adjust the threshold of the prefetcher according to the following formula: 1) is the prefetch threshold of the previous stage; ? ??????? is the accuracy of the spatial localized prefetcher; ? ?? is the accuracy of the PC localized prefetcher. Through iteration, the prefetch threshold of the more accurate prefetcher will be lowered, thereby issuing more prefetch requests.</p><formula xml:id="formula_2">? (?) ?? = ? (?-1) ?? ? ? ??????? ? ?? ? (?) ??????? = ? (?-1) ??????? ? ? ?? ? ??????? where? (?-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Multilevel prefetch</head><p>The prefetch queue (PQ) and miss-status-holding-registers are limited in each level of prefetcher. To make full use of these resources, DSDP will ask the LLC to issue partial prefetch requests according to the confidence of the prefetch request and the L2 prefetch resources. Modern caches typically have 20 to 30 bits of unused bus width <ref type="bibr" target="#b21">[23]</ref>. DSDP can utilize this bus bandwidth to implement multilevel prefetch. When L2 issues a prefetch request, if the current prefetch resources are insufficient (less than 3 entries left in the prefetch queue) or the confidence of subsequent requests is between the thresholds of L2 and LLC, L2 will simultaneously encode up to three subsequent delta information into the request. When LLC receives a request with delta information it decodes it and issues further prefetches. Each delta consists of 7 bits, and the three deltas use 21 bits of bus bandwidth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">Storage overhead</head><p>The total storage used by DSDP in the preceding experiments is 3.61KB, with the storage requirement for each component shown in Table <ref type="table" target="#tab_3">1</ref>. Compared to both SPP and Bingo, the overhead of DSDP is significantly lower. Specifically, DSDP's overhead is 67% of SPP's and 5.7% of Bingo's.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.9">DSDP and other component prefetchers</head><p>DSDP is essentially a component prefetcher consisting of two prefetcher components. DOL <ref type="bibr" target="#b17">[19]</ref> and Instruction Pointer Classifier based spatial Prefetching (IPCP) <ref type="bibr" target="#b21">[23]</ref> are two recent component prefetchers. However, DSDP is quite different from them. First, both DOL and IPCP classify components according to program semantics, while DSDP classifies components by localization. This is a brand new classification method and its performance also shows obvious potential. Second, DOI and IPCP allow one of the prefetchers to issue prefetch requests in sequence according to priority, while 4 GB 1 channel/1-core, 8 GB 2 channels/multi-core,1600 MT/sec DSDP allows two prefetchers to issue prefetch requests simultaneously. Having multiple components prefetch at the same time can introduce high levels of pollution and even negative impacts. DSDP solves this problem well by the cooperation between the two prefetchers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION</head><p>In the following subsections, we evaluate and analyze DSDP. We first present the evaluation methodology, followed by performance and sensitivity analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Methodology</head><p>We evaluate DSDP with ChampSim <ref type="bibr" target="#b1">[2]</ref> which is a cycle-accurate simulator that models the entire memory system. ChampSim was used in the 2nd and 3rd data prefetching championships (DPC-2 <ref type="bibr" target="#b0">[1]</ref> and DPC-3 <ref type="bibr" target="#b2">[4]</ref>). The simulation parameters are shown in Table <ref type="table" target="#tab_4">2</ref>. Our simulation infrastructure uses a 4KB page size when mapping virtual to physical addresses. In ChampSim, virtual to physical page mappings are arbitrary.</p><p>Workloads. We use the 18 memory intensive applications from SPEC CPU 2006 <ref type="bibr">[3,</ref><ref type="bibr" target="#b13">15]</ref> evaluate DSDP. For all experiments, each trace is warmed up with 50M instructions, and simulation results are collected over the next 200M instructions. The baseline replacement policy is LRU replacement for all caches unless otherwise stated. For four-core simulations, we generated 16 workloads by mixing four SPEC programs and assign each trace to a different core. Mixes are randomly generated to fairly represent the characteristics of multiprogram workloads. We report the normalized weighted speedup compared to a baseline with no prefetching.</p><p>Evaluated Prefetchers. For comparison, three state-of-the-art spatial data prefetchers (BOP <ref type="bibr" target="#b18">[20]</ref>, SPP <ref type="bibr" target="#b16">[18]</ref>, and Bingo <ref type="bibr" target="#b4">[6]</ref>) and a compoent prefetcher (IPCP <ref type="bibr" target="#b21">[23]</ref>) are included. The configurations and storage overhead of these prefetchers are specified in Table <ref type="table" target="#tab_5">3</ref>.</p><p>Best Offset Prefetcher (BOP) is the winner of the second Data Prefetch Championship (DPC-2). BOP prefetches by determining the best offset that matches the stride of most memory accesses in a stage.</p><p>Signature Path Prefetcher (SPP) uses multiple consecutive cache line address deltas to predict the next cache line address deltas. SPP learns complex data access patterns through compressed historical signatures. In addition, SPP can quickly resume prefetching when crossing page boundaries and balance aggressive prefetching with accuracy.</p><p>Bingo is a spatial data prefetcher that uses multiple events to improve coverage and accuracy. In addition, Bingo reduces overhead by eliminating redundancies in the metadata table of history-based predictors by its mechanism.</p><p>Instruction Pointer Classifier (IPCP) is the winner of the third Data Prefetch Championship (DPC-3). Instruction Pointer Classifier (IPCP) is a tiny, high-performance component prefetcher. IPCP identifies different access patterns by classifying PC. IPCP learns at L1 and extends the learned classification information to L2 for use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Single-Core Results</head><p>Figure <ref type="figure" target="#fig_6">6</ref> compares the performance improvement of our five prefetchers on single-core workloads, over a baseline without a prefetcher. On average, DSDP achieves a 41.9% geometric mean speedup, which is 10% and 22% more than BOP and SPP respectively. Also, DSDP outperforms Bingo and IPCP by 4.1% and 6.9%. We also evaluate the entire SPEC CPU 2006 suite where on average, DSDP provides an    average improvement of 25.6%, 2.3% higher than the second place. DSDP shows particularly significant improvement in gcc,leslie3d, milc, and sphinx3. These applications are highly predictable by DSDP and get the biggest performance boost. Specifically, DSDP improves the performance of gcc, leslie3d, milc, and sphinx3 by 47.9%, 94.7%, 58.7%, and 103.9%, respectively. DSDP performs better than competing prefetching approaches on 10 of the 18 memoryintensive traces. This indicates that DSDP can accommodate most loads. In the GemsFDTD, Bingo achieves the highest 148% performance improvement, while DSDP achieves 138% improvement, ranking second. In mcf, the effect of DSDP is lower than BOP. This is because mcf is dominated by irregular memory accesses which spatial prefetchers are not good at processing. BOP can effectively alleviate this situation through aggressive prefetching. In libquantum, The acceleration of IPCP and Bingo are each about 18% higher than DSDP. In bwaves, IPCP, which has the largest speedup ratio, improves by 25% more than DSDP. In the remaining traces, DSDP is not significantly weaker than other methods, thus showing a performance improvement of 4.1% over the second place in geometric mean speedup. Figure <ref type="figure" target="#fig_7">7</ref> shows demand misses covered by DSDP under singlecore workloads. On average, DSDP covers 56.9% and 37.8% of the demand misses at L2 and the LLC, respectively. Note that DSDP's coverage in L2 is not outstanding compared to other prefetchers. This is because DSDP sends the prefetch with lower confidence to LLC for processing. A large part of the effective prefetching is triggered by LLC. If these prefetches can be completed in L2 as much as possible, the performance of DSDP will be further improved. However, this also consumes more L2 prefetch resources. Only by coordinating the relationship between the two can the performance of the prefetcher be optimal.</p><p>Figure <ref type="figure" target="#fig_8">8</ref> shows the coverage and overprediction with DSDP at the L2. Across all memory-intensive benchmarks, DSDP's average L2 overprediction is 26.4%. In particular, DSDP also has the lowest overprediction on the most prominent performing milc. This shows that DSDP's excellent performance with milc owes a lot to his accuracy. With the help of accuracy, DSDP achieves the highest performance improvement with the lowest overprediction. We noticed that DSDP does not issue excessive prefetch requests while achieving good prefetching results. This is also in line with the original intention of our design, to design a prefetcher with high accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Multi-Core Results</head><p>To show results for a multi-core system, we generate 16 mixed workloads, each consisting of 4 random programs, and assign each trace to a different core. Figure <ref type="figure" target="#fig_9">9</ref> shows multi-core performance results. On average, DSDP provides 20% improvement, whereas Bingo provides 18.5% improvement, SPP provides 17% improvement, BOP provides 14.4% improvement and IPCP provides 16.2% improvement. DSDP has an extra 1.5% performance improvement over the second-place Bingo. Note that the storage overhead used by DSDP is only 5.7% of Bingo's on the premise of improving performance. Out of the 16 random mixes, DSDP achieves the best performance on Mix 10. This load contains milc and sphinx3. From the single-core test, we can see that milc and sphinx3 are friendly to PC localization, and DSDP has a good performance on them. In addition, DSDP's overprediction on these traces is very low which means less contention for bandwidth. This is also consistent with the fact that accuracy is important in the case of multi-core  parallelism. As a result, DSDP has achieved 52% performance improvement, which is 12% higher than the second place in Mix 10. In multi-core experiments, BOP performs relatively poorly because BOP's prefetching is relatively more aggressive. It can achieve good performance on random access load alone, but under multi-core load, aggressive prefetching puts a lot of pressure on bandwidth and LLC, resulting in poor performance. This is why we want to design a higher accuracy prefetcher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Contribution to performance improvement</head><p>To analyze the effects and contributions of the two prefetcher components in DSDP. We run PC localized Prefetcher and Spatial localized Prefetcher separately. Figure <ref type="figure" target="#fig_11">11</ref> shows the performance improvement of two prefetchers under single-core workloads. The results show that in different scenarios, the two prefetchers will behave differently. In some scenarios such as bzip2, gcc, GemsFDTD, and leslie3d, PC localized prefetchers perform better while the Spatial localized prefetcher performs better on omnetpp. However, the effect of combining the two is always the best. This shows that the prefetchers under these two streams can always capture the rules that the other one has not learned. The difference in localization makes the two prefetchers observe different memory system behaviors. DSDP increases the adaptability to different loads by combining the prefetchers under two streams and performs well under the different workloads.</p><p>Figure <ref type="figure" target="#fig_10">10</ref> shows the accuracy and coverage of each prefetcher on L2 and LLC. The results shown are averaged over 28 loads. Note that the DSDP_PC and DSDP_SP represent the effect when the two components work together, while the PC localized Prefetcher and the Spatial localized Prefetcher are the results under their separate operations. As shown in Figure <ref type="figure" target="#fig_10">10</ref>, the L2 accuracy of PC localized Prefetcher is only lower than Bingo, with an improvement of nearly 4% compared to SPP. Since Bingo spends 17.5 times the storage space of DSDP to store more event information, it is more accurate than PC localized Prefetcher. On the other hand, Spatial localized Prefetcher, which is used to ensure coverage, is less accurate in L2, making the accuracy and coverage of DSDP in L2 degraded. This is because Spatial localized Prefetcher occupies part of the prefetching resources to issue prefetching to LLC. We can see that with Spatial localized Prefetcher, the accuracy and coverage of DSDP at L3 are significantly improved compared to PC localized Prefetcher. Based on this result, we attribute the high performance of DSDP to the collaboration of the two components, which is consistent with our main idea of improving the accuracy of prefetching through PC localization while learning cross-PC relationships through spatial localization to ensure good coverage. Since IPCP is an L1 prefetcher, it does not have high accuracy and coverage in L2 and L3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">The effectiveness of PC localization</head><p>We also compare the accuracy of the PC localized prefetcher alone with SPP. As shown in figure <ref type="figure" target="#fig_12">12</ref>, the accuracy of the PC localized prefetcher is on average 4% higher than that of SPP at L2. This shows that PC localization can indeed improve the accuracy of the prefetcher. In particular, the accuracy of PC localized prefetcher is 15% higher than that of SPP in milc. As a result, its overprediction was reduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">The effect of the number of delta entries in the Spatial localized Prediction Table</head><p>We quantify the effect of DSDP with different numbers of delta entries in the Spatial localized Prediction Table . Figure <ref type="figure" target="#fig_13">13</ref> shows the performance of DSDP with different numbers of delta entries in the Spatial localized Prediction Table . Although there are different performances on individual traces, overall, the performance of DSDP gradually improves as the number of entries increases. After balancing overhead and performance, we finally chose 4 entries as parameters for our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>Prefetching is an important technique to amortize the effects of the memory wall and has been studied over decades. This section reviews some of the most relevant techniques proposed in data prefetching.</p><p>Stream chaining <ref type="bibr" target="#b8">[10]</ref> is a study of the relationship between different streams. The author found that the relationship between different streams has not been studied, which limits the depth and accuracy of prefetching. Stream chaining builds the relationship between different PCs through miss graphs and uses this relationship to trigger prefetching between different PC localized streams, thereby increasing the depth and accuracy of prefetching. In contrast to DSDP, which directly learns and prefetches directly from two streams, stream chaining instead pays more attention to the relationship between different PCs.</p><p>The spatial prefetcher predicts the addresses that are most likely to be accessed in a spatial region. Variable Length Delta Prefetcher (VLDP) <ref type="bibr" target="#b24">[26]</ref> stores the history of deltas to predict future deltas. Signature Path Prefetcher (SPP) <ref type="bibr" target="#b16">[18]</ref> compresses historical information into a signature, which is used to predict complex address patterns. In addition, SPP can track complex patterns across physical page boundaries. Spatial Memory Streaming (SMS), <ref type="bibr" target="#b26">[28]</ref> found memory accesses often exhibit repetitive layouts and associate '?? +? ? ? ??? ? with this layout for prefetching. Bingo <ref type="bibr" target="#b4">[6]</ref> associates spatial layouts to both short and long events to achieve high accuracy. BOP <ref type="bibr" target="#b18">[20]</ref> selects the offset that is most likely to occur in the future for prefetching.</p><p>The Temporal Prefetchers track the temporal order of accesses for prefetching. Sampled Temporal Memory Streaming (STMS) <ref type="bibr" target="#b28">[30]</ref> keeps the predictor metadata in the main memory by main memory while achieving 90% of the performance potential of an idealized on-chip metadata store. Triage prefetcher <ref type="bibr" target="#b30">[32]</ref> reduces the overhead of off-chip access to metadata by identifying important metadata and using a portion of the LLC to store that metadata. Managed ISB (MISB) <ref type="bibr" target="#b31">[33]</ref> proposes a new metadata management scheme that uses a simple metadata prefetcher to feed the metadata cache. Domino <ref type="bibr" target="#b3">[5]</ref> captures more temporal opportunity by looking up the history with both one and two last miss addresses.</p><p>Several component prefetchers have been proposed recently. Division of labor (DOL) <ref type="bibr" target="#b17">[19]</ref> targets specific program semantics for prefetching. Instruction Pointer Classifier based spatial Prefetching (IPCP) <ref type="bibr" target="#b21">[23]</ref> issues prefetch requests based on the IP's classification. Similar to DSDP, the above two studies are both forming efficient prefetchers through components. The difference is that DSDP selects components based on different streams, while IPCP is based on the classification of PCs and DOI is based on program semantics.</p><p>Previous work has applied machine learning techniques to cache prefetching. <ref type="bibr" target="#b11">[13]</ref> demonstrates the potential of deep learning for prefetching. Voyager <ref type="bibr" target="#b25">[27]</ref> which learns delta correlations and address correlations through hierarchical neural models, while optimizing the structure to reduce the computational cost by 15-20 times and storage overhead by 110-200 times, is an important step towards a practical neural prefetcher. Pythia <ref type="bibr" target="#b5">[7]</ref> uses reinforcement learning to observe many different types of program contextual information to make prefetching decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>In this paper, we introduce DSDP, a new spatial prefetcher that learns and prefetches from two streams at the same time. The key idea of DSDP is to treat localization as an event rather than a means of filtering. DSDP proposes a novel composite prefetcher organization method, which is to organize composite prefetchers according to the localization method. DSDP learns from the PC localized stream and the spatial localized stream at the same time. While benefiting from PC localization, it does not abandon the prefetch opportunities lost by PC localization. The information lost during the PC localization process remains in the spatial localized stream. Therefore, the prefetch opportunity of DSDP has not diminished. Conversely, by learning missing accesses on the spatial localization stream, the spatial localized prefetcher of DSDP can pay more attention to the rules not learned by another prefetcher component, thus achieving an overall better effect. Our evaluations show that using only 3.61 KB of hardware storage, for memory-intensive singlecore SPEC CPU 2006 benchmarks, compared to a baseline system with no prefetching, DSDP provides an average performance improvement of 41.9% and 4.1% over the best-performing prior spatial data prefetcher. In the case of the multi-core benchmarks, DSDP provides an improvement of 20% and extends its lead over the best of the class competitor to 1.5%.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>rarely use PC localization. One important reason is</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples of PC and spatial localization approaches. Different address initials represent different memory region.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Block diagram of the Dual Stream Data Prefetcher.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>1</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>2 3Figure 4 :</head><label>24</label><figDesc>Figure 4: The process of training and prefetching of PC localized Prefetcher.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The process of training and prefetching of Spatial localized Prefetcher.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: IPC speedup versus no prefetching.</figDesc><graphic url="image-2.png" coords="7,79.23,83.69,453.53,170.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Demand misses covered by DSDP at L2 and LLC.</figDesc><graphic url="image-4.png" coords="7,324.69,492.58,226.77,170.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Coverage and Overprediction with DSDP at the L2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Multi-core performance results.</figDesc><graphic url="image-5.png" coords="8,79.23,83.69,453.53,170.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Accuracy and coverage with different prefetcher at L2 and LLC.</figDesc><graphic url="image-6.png" coords="9,79.23,83.69,453.53,170.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: The performance improvement of the two prefetcher components working separately and together.</figDesc><graphic url="image-7.png" coords="9,60.54,291.62,226.77,170.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: L2 Prediction Accuracy of SPP and PC localized Prefetcher.</figDesc><graphic url="image-8.png" coords="9,324.69,291.62,226.77,170.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Performance of DSDP for different numbers of delta entries in Spatial localized Prediction Table.</figDesc><graphic url="image-9.png" coords="10,79.23,83.69,453.53,170.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Figure 3: Recent Request Table for Localization splitter</figDesc><table><row><cell>L2 Access</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">4 Logging new access</cell></row><row><cell cols="3">Address * PC 2 Miss</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">Recent Request Table</cell></row><row><cell>1</cell><cell>Page-tag</cell><cell cols="3">Addres Offset s Addres Offset 1 s 1 Addres Offset 2 s 2 Addres s 3 Offset 3</cell><cell>PC-tag PC-tag 1 PC-tag 2 PC-tag 3</cell><cell>Signature Signature 1 Signature 2 Signature 3</cell></row><row><cell></cell><cell>2</cell><cell cols="2">Access</cell><cell cols="2">PC localized stream</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Signature 2</cell><cell>Delta 2</cell></row><row><cell></cell><cell>3</cell><cell>Miss</cell><cell cols="3">Spatial localized stream</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>PC-tag 1</cell><cell>Delta 1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>PC-tag 2</cell><cell>Delta 2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>PC-tag 3</cell><cell>Delta 3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table</head><label></label><figDesc></figDesc><table><row><cell>Signature</cell><cell>Addres s Delta</cell><cell>Confidence</cell></row><row><cell></cell><cell>Delta 1</cell><cell>2</cell></row><row><cell></cell><cell>Delta 2</cell><cell>3</cell></row><row><cell></cell><cell>Delta 3</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Prefetch Filter Send requests till the confidence is not satisfied Update Prediction Table</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>DSDP storage overhead.</figDesc><table><row><cell>Table Name</cell><cell>Entry</cell><cell>Component</cell><cell>Storage Overhead</cell></row><row><cell></cell><cell></cell><cell>Page-tag(8 bits)</cell><cell></cell></row><row><cell>Recent Requests Table</cell><cell>128</cell><cell>Offset(3 ? 6 bits) PC-tag(3 ? 8 bits)</cell><cell>9088 bits</cell></row><row><cell></cell><cell></cell><cell>Signature(3 ? 7 bits)</cell><cell></cell></row><row><cell>PC localized Prediction Table</cell><cell>128</cell><cell>Delta(4 ? 7 bits) Confidence(4 ? 3 bits)</cell><cell>5120 bits</cell></row><row><cell>Spatial localized Prediction Table</cell><cell>128</cell><cell>PC-Tag(8 bits) Delta(4 ? 7 bits) Confidence(4 ? 3 bits)</cell><cell>6144 bits</cell></row><row><cell></cell><cell></cell><cell>Tag(6 bits)</cell><cell></cell></row><row><cell>Prefetch Filter Table</cell><cell>1024</cell><cell>Valid(1 bit) Useful(1 bit)</cell><cell>9216 bits</cell></row><row><cell></cell><cell></cell><cell>Prefetcher(1 bit)</cell><cell></cell></row><row><cell></cell><cell cols="2">Total:29586 bits ? 3.61 KB</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Simulated System parameters.</figDesc><table><row><cell>Core</cell><cell>Out-of-order,4 GHz,6-wide,256 entries ROB</cell></row><row><cell>TLBs</cell><cell>64 entries ITLB,64 entries DTLB, 1536 entries shared L2 TLB</cell></row><row><cell>L1I</cell><cell>32 KB,8-way,3 cycles,PQ:8,MSHR:8</cell></row><row><cell>L1D</cell><cell>48 KB,12-way,5 cycles,PQ:8,MSHR:16</cell></row><row><cell>L2</cell><cell>512 KB,8-way,10 cycles,PQ:16,MSHR:32</cell></row><row><cell>LLC</cell><cell>2 MB/core,16-way,20 cycles, PQ:32?#cores,MSHR:64?#cores</cell></row><row><cell>DRAM</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Configurations and storage overhead of other evaluated prefetchers.</figDesc><table><row><cell>Prefetcher</cell><cell>Configuration</cell><cell>Storage Overhead</cell></row><row><cell>BOP</cell><cell>512 Entry RR Table, 8Kb Prefetch bits</cell><cell>1.75KB</cell></row><row><cell>SPP</cell><cell>256 Entry ST, 512 Entry PT, 1024 Entry PF, 8 Entry GHR</cell><cell>5.38KB</cell></row><row><cell>Bingo</cell><cell>2KB page region, 128 Entry AT, 64 Entry FT, 8K Entry HT</cell><cell>63.77KB</cell></row><row><cell>IPCP</cell><cell>64 Entry IP Table, 128 Entry CSPT, 8 Entry RST, 32 Entry RRF</cell><cell>0.87KB</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>This research is supported by the National Natural Science Foundation of China under Grant No.62172180.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">2nd data prefetching championship</title>
		<ptr target="http://comparch-conf.gatech.edu/dpc2/" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Champsim simulator</title>
		<ptr target="https://github.com/ChampSim/" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">3rd data prefetching championship</title>
		<ptr target="https://dpc3.compas.cs.stonybrook.edu/" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Domino Temporal Data Prefetcher</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2018.00021</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2018.00021" />
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="131" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bingo spatial data prefetcher</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehran</forename><surname>Shakerinava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2019.00053</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2019.00053" />
	</analytic>
	<monogr>
		<title level="m">Proceedings -25th IEEE International Symposium on High Performance Computer Architecture</title>
		<meeting>-25th IEEE International Symposium on High Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2019-02">2019. 2019 2019, February (2019</date>
			<biblScope unit="page" from="399" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pythia: A Customizable Hardware Prefetching Framework Using Online Reinforcement Learning</title>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Bera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantinos</forename><surname>Kanellopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anant</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taha</forename><surname>Shahroodi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sreenivas</forename><surname>Subramoney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3466752.3480114</idno>
		<ptr target="https://doi.org/10.1145/3466752.3480114" />
	</analytic>
	<monogr>
		<title level="m">MICRO &apos;21: 54th Annual IEEE/ACM International Symposium on Microarchitecture, Virtual Event</title>
		<meeting><address><addrLine>Greece</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021-10-18">2021. October 18-22, 2021</date>
			<biblScope unit="page" from="1121" to="1137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">DSPatch: Dual Spatial Pattern Prefetcher</title>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Bera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anant</forename><forename type="middle">V</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sreenivas</forename><surname>Subramoney</surname></persName>
		</author>
		<idno type="DOI">10.1145/3352460.3358325</idno>
		<ptr target="https://doi.org/10.1145/3352460.3358325" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 52nd Annual IEEE/ACM International Symposium on Microarchitecture<address><addrLine>MICRO; Columbus, OH, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-10-12">2019. 2019. October 12-16, 2019</date>
			<biblScope unit="page" from="531" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Perceptron-based prefetch filtering</title>
		<author>
			<persName><forename type="first">Eshan</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gino</forename><surname>Chacon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elvira</forename><surname>Teran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">V</forename><surname>Gratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
		<idno type="DOI">10.1145/3307650.3322207</idno>
		<ptr target="https://doi.org/10.1145/3307650.3322207" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International Symposium on Computer Architecture, ISCA 2019</title>
		<editor>
			<persName><forename type="first">Bobbie</forename><surname>Srilatha</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hillery</forename><forename type="middle">C</forename><surname>Manne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Erik</forename><forename type="middle">R</forename><surname>Hunter</surname></persName>
		</editor>
		<editor>
			<persName><surname>Altman</surname></persName>
		</editor>
		<meeting>the 46th International Symposium on Computer Architecture, ISCA 2019<address><addrLine>Phoenix, AZ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-06-22">2019. June 22-26, 2019</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Stream chaining: Exploiting multiple levels of correlation in data prefetching</title>
		<author>
			<persName><forename type="first">Pedro</forename><surname>D?az</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcelo</forename><surname>Cintra</surname></persName>
		</author>
		<idno type="DOI">10.1145/1555754.1555767</idno>
		<ptr target="https://doi.org/10.1145/1555754.1555767" />
	</analytic>
	<monogr>
		<title level="m">Proceedings -International Symposium on Computer Architecture</title>
		<meeting>-International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="81" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Coordinated control of multiple prefetchers in multi-core systems</title>
		<author>
			<persName><forename type="first">Eiman</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><forename type="middle">Joo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yale</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
		<idno type="DOI">10.1145/1669112.1669154</idno>
		<ptr target="https://doi.org/10.1145/1669112.1669154" />
	</analytic>
	<monogr>
		<title level="m">42st Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<editor>
			<persName><forename type="first">David</forename><forename type="middle">H</forename><surname>Albonesi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Margaret</forename><surname>Martonosi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">David</forename><forename type="middle">I</forename><surname>August</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jos?</forename><forename type="middle">F</forename><surname>Mart?nez</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009-12-12">2009. 2009. December 12-16, 2009</date>
			<biblScope unit="page" from="316" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Stride directed prefetching in scalar processors</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janak</forename><forename type="middle">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bob</forename><forename type="middle">L</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><surname>Janssens</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.1992.697004</idno>
		<ptr target="https://doi.org/10.1109/MICRO.1992.697004" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual International Symposium on Microarchitecture</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Hwu</surname></persName>
		</editor>
		<meeting>the 25th Annual International Symposium on Microarchitecture<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM / IEEE Computer Society</publisher>
			<date type="published" when="1992-11">1992. November 1992</date>
			<biblScope unit="page" from="102" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning Memory Access Patterns</title>
		<author>
			<persName><forename type="first">Milad</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jichuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Ranganathan</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v80/hashemi18a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning, ICML 2018</title>
		<editor>
			<persName><forename type="first">Jennifer</forename><forename type="middle">G</forename><surname>Dy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</editor>
		<meeting>the 35th International Conference on Machine Learning, ICML 2018<address><addrLine>Stockholmsm?ssan, Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07-10">2018. July 10-15, 2018</date>
			<biblScope unit="volume">80</biblScope>
		</imprint>
	</monogr>
	<note>PMLR, 1924-1933</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Near-side prefetch throttling: adaptive prefetching for highperformance many-core processors</title>
		<author>
			<persName><forename type="first">Wim</forename><surname>Heirman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Du</forename><surname>Kristof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yves</forename><surname>Bois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stijn</forename><surname>Vandriessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ibrahim</forename><surname>Eyerman</surname></persName>
		</author>
		<author>
			<persName><surname>Hur</surname></persName>
		</author>
		<idno type="DOI">10.1145/3243176.3243181</idno>
		<ptr target="https://doi.org/10.1145/3243176.3243181" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Parallel Architectures and Compilation Techniques, PACT 2018</title>
		<editor>
			<persName><forename type="first">Skevos</forename><surname>Evripidou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Per</forename><surname>Stenstr?m</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Michael</surname></persName>
		</editor>
		<editor>
			<persName><surname>O'boyle</surname></persName>
		</editor>
		<meeting>the 27th International Conference on Parallel Architectures and Compilation Techniques, PACT 2018<address><addrLine>Limassol, Cyprus</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018-11-01">2018. November 01-04, 2018</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">SPEC CPU2006 Benchmark Descriptions</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">L</forename><surname>Henning</surname></persName>
		</author>
		<idno type="DOI">10.1145/1186736.1186737</idno>
		<ptr target="https://doi.org/10.1145/1186736.1186737" />
	</analytic>
	<monogr>
		<title level="j">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2006-09">2006. sep 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Linearizing Irregular Memory Accesses for Improved Correlated Prefetching</title>
		<author>
			<persName><forename type="first">Akanksha</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Calvin</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1145/2540708.2540730</idno>
		<ptr target="https://doi.org/10.1145/2540708.2540730" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 46th Annual IEEE/ACM International Symposium on Microarchitecture<address><addrLine>Davis, California; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="247" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Making data prefetch smarter: adaptive prefetching on POWER7</title>
		<author>
			<persName><forename type="first">V?ctor</forename><surname>Jim?nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Gioiosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><forename type="middle">J</forename><surname>Cazorla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alper</forename><surname>Buyuktosunoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradip</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><forename type="middle">P</forename><surname>O'connell</surname></persName>
		</author>
		<idno type="DOI">10.1145/2370816.2370837</idno>
		<ptr target="https://doi.org/10.1145/2370816.2370837" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Parallel Architectures and Compilation Techniques, PACT &apos;12</title>
		<editor>
			<persName><forename type="first">Chung</forename><surname>Yew</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sangyeun</forename><surname>Cho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Luiz</forename><surname>Derose</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Lilja</surname></persName>
		</editor>
		<meeting><address><addrLine>Minneapolis, MN, USA -</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-09-19">2012. September 19 -23, 2012</date>
			<biblScope unit="page" from="137" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Path Confidence Based Lookahead Prefetching</title>
		<author>
			<persName><forename type="first">Jinchun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">V</forename><surname>Gratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Narasimha Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeshan</forename><surname>Chishti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 49th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting><address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Division of Labor: A More Effective Approach to Prefetching</title>
		<author>
			<persName><forename type="first">Sushant</forename><surname>Kondguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISCA.2018.00018</idno>
		<ptr target="https://doi.org/10.1109/ISCA.2018.00018" />
	</analytic>
	<monogr>
		<title level="m">2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="83" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Best-offset hardware prefetching</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Michaud</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2016.7446087</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2016.7446087" />
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="469" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">AC/DC: an adaptive data cache prefetcher</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Nesbit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Dhodapkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1109/PACT.2004.1342548</idno>
		<ptr target="https://doi.org/10.1109/PACT.2004.1342548" />
	</analytic>
	<monogr>
		<title level="m">Proceedings. 13th International Conference on Parallel Architecture and Compilation Techniques</title>
		<meeting>13th International Conference on Parallel Architecture and Compilation Techniques</meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004. 2004</date>
			<biblScope unit="page" from="135" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Data Cache Prefetching Using a Global History Buffer</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Nesbit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="90" to="97" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bouquet of Instruction Pointers: Instruction Pointer Classifier-based Spatial Hardware Prefetching</title>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Pakalapati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biswabandan</forename><surname>Panda</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISCA45697.2020.00021</idno>
		<ptr target="https://doi.org/10.1109/ISCA45697.2020.00021" />
	</analytic>
	<monogr>
		<title level="m">Proceedings -International Symposium on Computer Architecture</title>
		<meeting>-International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2020-05">2020. 2020-May (2020</date>
			<biblScope unit="page" from="118" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">SPAC: A Synergistic Prefetcher Aggressiveness Controller for Multi-Core Systems</title>
		<author>
			<persName><forename type="first">Biswabandan</forename><surname>Panda</surname></persName>
		</author>
		<idno type="DOI">10.1109/TC.2016.2547392</idno>
		<ptr target="https://doi.org/10.1109/TC.2016.2547392" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Computers</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="3740" to="3753" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sandbox Prefetching: Safe run-time evaluation of aggressive prefetchers</title>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeshan</forename><surname>Chishti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng-Fei</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aamer</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shih-Lien</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kingsum</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Balasubramonian</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2014.6835971</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2014.6835971" />
	</analytic>
	<monogr>
		<title level="m">20th IEEE International Symposium on High Performance Computer Architecture, HPCA 2014</title>
		<meeting><address><addrLine>Orlando, FL, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2014-02-15">2014. February 15-19, 2014</date>
			<biblScope unit="page" from="626" to="637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Efficiently prefetching complex address patterns</title>
		<author>
			<persName><forename type="first">Manjunath</forename><surname>Shevgoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sahil</forename><surname>Koladiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Balasubramonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeshan</forename><surname>Chishti</surname></persName>
		</author>
		<idno type="DOI">10.1145/2830772.2830793</idno>
		<ptr target="https://doi.org/10.1145/2830772.2830793" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th International Symposium on Microarchitecture</title>
		<editor>
			<persName><forename type="first">Milos</forename><surname>Prvulovic</surname></persName>
		</editor>
		<meeting>the 48th International Symposium on Microarchitecture<address><addrLine>MICRO; Waikiki, HI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015-09">2015. 2015. December 5-9, 2015</date>
			<biblScope unit="page" from="141" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A hierarchical neural model of data prefetching</title>
		<author>
			<persName><forename type="first">Zhan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akanksha</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milad</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Calvin</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3445814.3446752</idno>
		<ptr target="https://doi.org/10.1145/3445814.3446752" />
	</analytic>
	<monogr>
		<title level="m">ASPLOS &apos;21: 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Virtual Event</title>
		<editor>
			<persName><forename type="first">Tim</forename><surname>Sherwood</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Emery</forename><forename type="middle">D</forename><surname>Berger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</editor>
		<meeting><address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021-04-19">2021. April 19-23, 2021</date>
			<biblScope unit="page" from="861" to="873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Spatial memory streaming</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
		<idno type="DOI">10.1145/1150019.1136508</idno>
		<ptr target="https://doi.org/10.1145/1150019.1136508" />
	</analytic>
	<monogr>
		<title level="j">Journal of Instruction-Level Parallelism</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Branch history guided instruction prefetching</title>
		<author>
			<persName><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Tyson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Charney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Puzak</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2001.903271</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2001.903271" />
	</analytic>
	<monogr>
		<title level="m">Proceedings HPCA Seventh International Symposium on High-Performance Computer Architecture</title>
		<meeting>HPCA Seventh International Symposium on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="291" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Practical off-chip meta-data for temporal memory streaming</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Moshovos</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2009.4798239</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2009.4798239" />
	</analytic>
	<monogr>
		<title level="m">15th International Conference on High-Performance Computer Architecture</title>
		<meeting><address><addrLine>Raleigh, North Carolina, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2009-02-18">2009. 2009. 14-18 February 2009</date>
			<biblScope unit="page" from="79" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Temporal Streaming of Shared Memory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hardavellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Sigarch Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="222" to="233" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Temporal Prefetching Without the Off-Chip Metadata</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishnendra</forename><surname>Nathella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Pusdesris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dam</forename><surname>Sunwoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akanksha</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Calvin</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3352460.3358300</idno>
		<ptr target="https://doi.org/10.1145/3352460.3358300" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 52nd Annual IEEE/ACM International Symposium on Microarchitecture<address><addrLine>MICRO; Columbus, OH, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-10-12">2019. 2019. October 12-16, 2019</date>
			<biblScope unit="page" from="996" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Efficient metadata management for irregular data prefetching</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishnendra</forename><surname>Nathella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dam</forename><surname>Sunwoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akanksha</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Calvin</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3307650.3322225</idno>
		<ptr target="https://doi.org/10.1145/3307650.3322225" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International Symposium on Computer Architecture, ISCA 2019</title>
		<editor>
			<persName><forename type="first">Bobbie</forename><surname>Srilatha</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hillery</forename><forename type="middle">C</forename><surname>Manne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Erik</forename><forename type="middle">R</forename><surname>Hunter</surname></persName>
		</editor>
		<editor>
			<persName><surname>Altman</surname></persName>
		</editor>
		<meeting>the 46th International Symposium on Computer Architecture, ISCA 2019<address><addrLine>Phoenix, AZ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-06-22">2019. June 22-26, 2019</date>
			<biblScope unit="page" from="449" to="461" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
