<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DE-RRD: A Knowledge Distillation Framework for Recommender System</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
							<email>seongku@postech.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engineering</orgName>
								<address>
									<postBox>POSTECH</postBox>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Junyoung</forename><surname>Hwang</surname></persName>
							<email>jyhwang@postech.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engineering</orgName>
								<address>
									<postBox>POSTECH</postBox>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wonbin</forename><surname>Kweon</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engineering</orgName>
								<address>
									<postBox>POSTECH</postBox>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
							<email>hwanjoyu@postech.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engineering</orgName>
								<address>
									<postBox>POSTECH</postBox>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DE-RRD: A Knowledge Distillation Framework for Recommender System</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3340531.3412005</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS</term>
					<term>Information systems → Learning to rank</term>
					<term>Collaborative filtering</term>
					<term>Retrieval efficiency Recommender System</term>
					<term>Knowledge Distillation</term>
					<term>Learning to Rank</term>
					<term>Model Compression</term>
					<term>Retrieval efficiency</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent recommender systems have started to employ knowledge distillation, which is a model compression technique distilling knowledge from a cumbersome model (teacher) to a compact model (student), to reduce inference latency while maintaining performance. The state-of-the-art methods have only focused on making the student model to accurately imitate the predictions of the teacher model. They have a limitation in that the prediction results incompletely reveal the teacher's knowledge. In this paper, we propose a novel knowledge distillation framework for recommender system, called DE-RRD, which enables the student model to learn from the latent knowledge encoded in the teacher model as well as from the teacher's predictions. Concretely, DE-RRD consists of two methods: 1) Distillation Experts (DE) that directly transfers the latent knowledge from the teacher model. DE exploits "experts" and a novel expert selection strategy for effectively distilling the vast teacher's knowledge to the student with limited capacity. 2) Relaxed Ranking Distillation (RRD) that transfers the knowledge revealed from the teacher's prediction with consideration of the relaxed ranking orders among items. Our extensive experiments show that DE-RRD outperforms the state-of-the-art competitors and achieves comparable or even better performance to that of the teacher model with faster inference time.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In recent years, recommender system (RS) has been broadly adopted in various industries, helping users' decisions in the era of information explosion, and playing a key role in promoting corporate profits. However, a growing scale of users (and items) and sophisticated model architecture to capture complex patterns make the size of the model continuously increasing <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30]</ref>. A large model with numerous parameters has a high capacity, and thus usually has better recommendation performance. On the other hand, it requires a large computational time and memory costs, and thus incurs a high latency during the inference phase, which makes it difficult to apply such large model to real-time platform.</p><p>Motivated by the significant success of knowledge distillation (KD) in the computer vision field, a few work <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25]</ref> have employed KD for RS to reduce the size of models while maintaining the performance. KD is a model-agnostic strategy to accelerate the learning of a new compact model (student) by transferring knowledge from a previously trained large model (teacher) <ref type="bibr" target="#b6">[7]</ref>. The knowledge transfer is conducted as follows: First, the teacher model is trained with the user-item interactions in the training set which has binary labels -'1' for observed interactions, and '0' for unobserved interactions. Then, the student model is trained with the "soft" labels generated by the teacher model (i.e., teacher's predictions) along with the available binary labels. The student model trained with KD has comparable performance to that of the teacher, and also has a lower latency due to its small size <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>The core idea behind this process is that the soft labels predicted by the teacher model reveal hidden relations among entities (i.e., users and items) not explicitly included in the training set, so that they accelerate and improve the learning of the student model. Specifically, the items ranked near the top of a user's recommendation list would have strong correlations to the items that the user has interacted before <ref type="bibr" target="#b24">[25]</ref>. Also, the soft labels provide guidance for distinguishing the items that each user would like and the items that each user would not be interested in among numerous unobserved items only labeled as '0' <ref type="bibr" target="#b12">[13]</ref>. By using the additional supervisions from the teacher model, the state-of-the-art methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25]</ref> have achieved comparable or even better performance to the teacher models with faster inference time.</p><p>However, there are still limitations in existing methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25]</ref>. First, the learning of the student is only guided by the teacher's prediction results, which is not sufficient to fully take advantage of the knowledge stored in the teacher. This is because the prediction results incompletely reveal the teacher's knowledge. As illustrated in Figure <ref type="figure">1</ref>, the recommendation list from the teacher only shows that a user has a similar degree of preference on the two items (0.99 and 0.98). However, latent knowledge in the teacher, which is used to make such predictions, contains more detailed information that Figure <ref type="figure">1</ref>: The existing methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25]</ref> distill the knowledge only based on the teacher's predictions (b). The proposed framework directly distills the latent knowledge stored in the teacher (a) along with the knowledge revealed from the predictions (b).</p><p>the user likes different aspects of the two items (marked as navy blue and orange, respectively). In this regard, we argue that the training process and the performance of the student can be further improved by directly distilling such latent knowledge stored in the teacher model. Second, they distill the knowledge from the teacher's predictions in a point-wise manner that considers a single item at a time. Because the point-wise approach does not consider multiple items simultaneously, it has a limitation in accurately maintaining the ranking orders predicted by the teacher model <ref type="bibr" target="#b23">[24]</ref>, which leads to degraded recommendation performance.</p><p>In this paper, we propose a novel knowledge distillation framework for RS, named DE-RRD, which distills both the latent knowledge stored in the teacher model (Fig. <ref type="figure">1a</ref>) and the knowledge revealed from teacher's predictions (Fig. <ref type="figure">1b</ref>). By learning both the teacher's final predictions and the detailed knowledge that provides the bases for such predictions, the student model can be further improved. The proposed framework consists of two methods: 1) Distillation Experts (DE) and 2) Relaxed Ranking Distillation (RRD). The main contributions of this paper lie in the following aspects:</p><p>Distilling latent knowledge in the teacher model. We propose a novel method-DE-for directly distilling latent knowledge stored in the teacher model. Specifically, DE transfers the knowledge from hidden representation space (i.e., the output of the intermediate layer) of the teacher to the representation space of the student. Due to the limited capacity, the student model cannot learn all the knowledge in the teacher representation space. DE first introduces an "expert", which is a small feed-forward network, to distill the summarized knowledge that can restore the detailed knowledge of each entity in the teacher. However, distilling the knowledge of all entities with a single expert intermingles the information of weakly correlated entities and further hinders the entire distillation process. To tackle this problem, DE adopts the multiple experts and a novel expert selection strategy that clearly distinguishes the knowledge that each expert distills based on the correlations among the entities in the teacher representation space. To the best of our knowledge, our approach is the first attempt to directly distill the latent knowledge in the teacher model for RS. We demonstrate its rationality and superiority through extensive experiments and comprehensive analyses.</p><p>Relaxed Ranking Distillation from the teacher's predictions. We propose a new method-RRD-that transfers the knowledge from the teacher's predictions with direct consideration of ranking orders among items. Unlike the existing methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25]</ref> that distill the knowledge of an item at a time, RRD formulates this as a ranking matching problem between the recommendation list of the teacher and that of the student. To this end, RRD adopts the list-wise learning-to-rank approach <ref type="bibr" target="#b28">[29]</ref> and learns to ensure the student to preserve the ranking orders predicted by the teacher. However, directly applying the list-wise approach can have adverse effects on the recommendation performance. Since a user is interested in only a few items among the numerous total items <ref type="bibr" target="#b9">[10]</ref>, learning the detailed ranking orders of all items is not only daunting but also ineffective. To tackle this challenge, RRD reformulates the daunting task to a relaxed ranking matching problem. Concretely, RRD matches the recommendation list from the teacher and that from the student, ignoring the detailed ranking orders among the uninteresting items that the user would not be interested in. RRD achieves superior recommendation performance compared to the state-of-the-art methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25]</ref>. An unified framework. We propose a novel framework-DE-RRD-which enables the student model to learn both from the teacher's predictions and from the latent knowledge stored in the teacher model. Our extensive experiments on real-world datasets show that DE-RRD considerably outperforms the state-of-the-art competitors. DE-RRD achieves comparable performance to that of the teacher with a smaller number of learning parameters than all the competitors. Also, DE-RRD shows the largest performance gain when the student has the identical structure to the teacher model (i.e., self-distillation <ref type="bibr" target="#b4">[5]</ref>). Furthermore, we provide both qualitative and quantitative analyses to further investigate the superiority of each proposed component. The source code of DE-RRD is publicly available<ref type="foot" target="#foot_0">1</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Balancing effectiveness and efficiency is a key requirement for realtime recommender system (RS); the system should provide accurate recommendations with fast inference time. Recently, the size of the recommender model is continuously increasing, and the computational time and memory cost required for the inference are also increasing accordingly <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30]</ref>. Due to the high latency, it becomes difficult to apply such large recommender to the real-time large-scale platform. In this section, we review several approaches to alleviate this problem. Balancing Effectiveness and Efficiency. Several methods have adopted hash techniques to reduce the inference cost <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b29">30]</ref>. They first learn binary representations of users and items, then construct the hash table. Although exploiting the binary representation can significantly reduce the inference costs, due to the constrained capability, their recommendation performance is limited compared to models that use real-values representations. In addition, several work has focused on accelerating the inference of the existing recommenders <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b25">26]</ref>. Specifically, tree-based data structures <ref type="bibr" target="#b1">[2]</ref>, data compression techniques <ref type="bibr" target="#b25">[26]</ref>, and approximated nearest neighbor search techniques <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b22">23]</ref> have been successfully adopted to reduce the search costs. However, they still have problems such as applicable only to specific models (e.g., k-d tree for metric learningbased models <ref type="bibr" target="#b11">[12]</ref>), or easily falling into a local optimum due to the local search. Knowledge Distillation. Knowledge distillation (KD) is a modelagnostic strategy to improve the learning and the performance of a new "compact" model (student) by transferring knowledge from a previously trained "large" model (teacher) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b21">22]</ref>. The student model trained with KD has comparable performance to that of the teacher model, and also has lower inference latency due to its small size. Most KD methods have focused on the image classification problem. An early work <ref type="bibr" target="#b6">[7]</ref> matches the softmax distribution of the teacher and the student. The predicted label distribution contains more rich information (e.g., inter-class correlation) than the one-hot class label, which leads to improved learning of the student model. Subsequent methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b21">22]</ref> have focused on distilling knowledge from intermediate layers. Because teacher's intermediate layers are generally bigger than that of the student, they <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b21">22]</ref> utilize additional layers to bridge the different dimensions. Interestingly, KD has turned out to be effective in improving the teacher model itself by self-distillation <ref type="bibr" target="#b4">[5]</ref>. Knowledge Distillation in Recommender System. Recently, inspired by the huge success of KD in the computer vision field, a few work <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25]</ref> have adopted KD to RS. A pioneer work is Ranking Distillation (RD) <ref type="bibr" target="#b24">[25]</ref> which applies KD for the ranking problem; Providing recommendations of top-𝑁 unobserved items that have not interacted with a user. RD jointly optimizes a base recommender's loss function with a distillation loss. min</p><formula xml:id="formula_0">𝜃 𝑠 L 𝐵𝑎𝑠𝑒 + 𝜆L 𝑅𝐷<label>(1)</label></formula><p>where 𝜃 𝑠 is the learning parameters of the student model, 𝜆 is a hyperparameter that controls the effects of RD. The base recommender can be any existing RS model such as BPR <ref type="bibr" target="#b20">[21]</ref>, NeuMF <ref type="bibr" target="#b5">[6]</ref>, and L 𝐵𝑎𝑠𝑒 is its loss function (e.g., binary cross-entropy). The distillation loss of RD for user 𝑢 is defined as follows:</p><formula xml:id="formula_1">L 𝑅𝐷 = − 𝜋 𝑘 ∈𝝅 𝑤 𝜋 𝑘 log 𝑃 (𝑟𝑒𝑙 = 1|𝑢, 𝜋 𝑘 )<label>(2)</label></formula><p>where 𝝅 is a ranked list of top-𝐾 unobserved items for user 𝑢 predicted by the teacher, 𝜋 𝑘 is the 𝑘-th item in this ranking, and 𝑃 (𝑟𝑒𝑙 = 1|𝑢, 𝜋 𝑘 ) is the relevance probability of user 𝑢 to 𝜋 𝑘 predicted by the student model. 𝑤 𝜋 𝑘 is the weight, which is computed based on each item's ranking from the student and the teacher, for reflecting relative importance among top-𝐾 items.</p><p>A subsequent work Collaborative Distillation (CD) <ref type="bibr" target="#b12">[13]</ref> first samples unobserved items from the teacher's recommendation list according to their ranking; high-ranked items are more frequently sampled, then trains the student to mimic the teacher's prediction score (e.g., relevance probability) on the sampled items. The distillation loss of CD for user 𝑢 is defined as follows:</p><formula xml:id="formula_2">L 𝐶𝐷 = − 𝜋 𝑘 ∈𝝅 𝑞 𝜋 𝑘 log 𝑃 (𝑟𝑒𝑙 = 1|𝑢, 𝜋 𝑘 ) + (1 − 𝑞 𝜋 𝑘 ) log 1 − 𝑃 (𝑟𝑒𝑙 = 1|𝑢, 𝜋 𝑘 ) (3)</formula><p>where 𝝅 is a ranked list of 𝐾 unobserved items sampled from teacher's recommendations for user 𝑢, 𝑞 𝜋 𝑘 is the weight, which is computed based on teacher's prediction score on each item, for reflecting relative importance among the sampled items.</p><p>In summary, the distillation loss of the existing methods makes the student model follow the teacher's predictions on unobserved items with particular emphasis on the high-ranked items. In RS, only high-ranked items in the recommendation list are matter. Also, such high-ranked items reveal hidden patterns among entities (i.e., users and items); the high-ranked items in the recommendation list would have strong correlations to the user <ref type="bibr" target="#b24">[25]</ref>. By using such additional supervisions from the teacher, they have achieved the comparable performance to the teacher with faster inference time.</p><p>However, the existing methods still have room for improvement by the following reasons: First, the student can be further improved by directly distilling the latent knowledge stored in the teacher model. Latent knowledge refers to all information of users, items, and relationships among them that is discovered and stored in the teacher model. Such knowledge is valuable for the student because it provides detailed explanations on the final prediction of the teacher. Second, they transfer the knowledge from the teacher's predictions with a point-wise approach that considers a single item at a time. Since the point-wise approach does not take into account multiple items simultaneously, it has a limitation in accurately maintaining the ranking orders in the teacher's ranking list <ref type="bibr" target="#b23">[24]</ref>. This can lead to limited recommendation performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEM FORMULATION</head><p>In this work, we focus on top-𝑁 recommendations for implicit feedback. Let U and I denote the set of users and items, respectively. Given collaborative filtering (CF) information (i.e., implicit interactions between users and items), we build a binary matrix 𝑹 ∈ {0, 1} | U |× | I | . Each element of 𝑹 has a binary value indicating whether a user has interacted with an item <ref type="bibr" target="#b0">(1)</ref> or not (0). Note that an unobserved interaction does not necessarily mean a user's negative preference on an item, it can be that the user is not aware of the item. For each user, a recommender model ranks all items that have not interacted with the user (i.e., unobserved items) and provides a ranked list of top-𝑁 unobserved items.</p><p>The knowledge distillation is conducted as follows: First, a teacher model with a large number of learning parameters is trained with the training set which has binary labels. Then, a student model with a smaller number of learning parameters is trained with the help from the teacher model in addition to the binary labels. The goal of KD is to fully improve the inference efficiency without compromising the effectiveness; We aim to design a KD framework that enables the student model to maintain the recommendation performance of the teacher with a small number of learning parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DE-RRD: THE PROPOSED FRAMEWORK</head><p>We propose DE-RRD framework which enables the student model to learn both from the teacher's predictions and from the latent knowledge encoded in the teacher model. DE-RRD consists of two methods: 1) Distillation Experts (DE) that directly transfers the latent knowledge from the teacher, 2) Relaxed Ranking Distillation (RRD) that transfers the knowledge revealed from the teacher's predictions with direct consideration of ranking orders among items. This section is organized as follows. We first describe each </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Distillation Experts (DE)</head><p>In this section, we provide the details of DE which distills the latent knowledge from the hidden representation space (i.e., the output of the intermediate layer) of the teacher to the corresponding representation space of the student. We first introduce "expert" to distill the summarized knowledge that can restore the detailed teacher's knowledge of each entity. Then, we introduce a novel expert selection strategy for effectively distilling CF knowledge that contains information of all the entities having diverse preferences and characteristics.</p><p>4.1.1 Expert for distillation. DE exploits "expert" to distill knowledge from the teacher's hidden representation space. An expert, which is a small feed-forward network, is trained to reconstruct the representation on a selected intermediate layer of the teacher from the representation on the corresponding intermediate layer of the student. Let ℎ 𝑡 (•) denote a mapping function to the representation space (∈ R 𝑑 𝑡 ) of the teacher model (i.e., a nested function up to the intermediate layer of the teacher). Similarly, let ℎ 𝑠 (•) denote a mapping function to the student's representation space (∈ R 𝑑 𝑠 ). The output of the mapping function can be a separate representation of a user, an item (e.g., BPR <ref type="bibr" target="#b20">[21]</ref>) or their combined representation (e.g., NeuMF <ref type="bibr" target="#b5">[6]</ref>) based on the base model's structure and the type of selected layer. Here, we use user 𝑢 as an example for convenience. An expert 𝐸 is trained to reconstruct ℎ 𝑡 (𝑢) from ℎ 𝑠 (𝑢) as follows:</p><formula xml:id="formula_3">L (𝑢) = ∥ℎ 𝑡 (𝑢) − 𝐸 ℎ 𝑠 (𝑢) ∥ 2 (4)</formula><p>Note that in the KD process, the teacher model is already trained and frozen. By minimizing the above equation, parameters in the student model (i.e., ℎ 𝑠 (•)) and the expert are updated.</p><p>The student model has smaller capacity compared to the teacher (𝑑 𝑠 &lt;&lt; 𝑑 𝑡 ). By minimizing the equation 4, the student learns compressed information on the user's preference that can restore more detailed knowledge in the teacher as accurate as possible. This approach provides a kind of filtering effect and improves the learning of the student model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Expert selection strategy.</head><p>Training a single expert to distill all the CF knowledge in the teacher is not sufficient to achieve satisfactory performance. The CF knowledge contains vast information of user groups with various preferences and item groups with diverse characteristics. When a single expert is trained to distill the knowledge of all the diverse entities, the information of the weakly correlated entities (e.g., users that have dissimilar preferences) is mixed and reflected in the expert's weights. This leads to the adulterated distillation that hinders the student model from discovering some users' preferences.</p><p>To alleviate the problem, DE puts multiple experts in parallel and clearly distinguishes the knowledge that each expert distills. The key idea is to divide the representation space into exclusive divisions based on the teacher's knowledge and make each expert to be specialized in distilling the knowledge in a division (Fig. <ref type="figure" target="#fig_0">2a</ref>). The representations belonging to the same division has strong correlations with each other, and they are distilled by the same expert without being mixed with weakly correlated representations belonging to the different divisions. The knowledge transfer of DE is conducted in the two steps: 1) a selection network first computes each expert's degree of specialization for the knowledge to be distilled. 2) DE selects an expert based on the computed distribution, then distills the knowledge through the selected expert.</p><p>Concretely, DE has 𝑀 experts (𝐸 1 , 𝐸 2 , ..., 𝐸 𝑀 ) and a selection network 𝑆 whose output is 𝑀-dimensional vector. To distill user 𝑢's knowledge from the teacher, the selection network 𝑆 first computes the normalized specialization score vector 𝜶 𝑢 ∈ R 𝑀 as follows:</p><formula xml:id="formula_4">e 𝑢 = 𝑆 ℎ 𝑡 (𝑢) , 𝛼 𝑢 𝑚 = exp 𝑒 𝑢 𝑚 𝑀 𝑖=1 exp(𝑒 𝑢 𝑖 ) for 𝑚 = 1, ..., 𝑀<label>(5)</label></formula><p>Then, DE selects an expert based on the computed distribution. We represent the selection variable s 𝑢 that determines which expert to be selected for distilling ℎ 𝑡 (𝑢). s 𝑢 is a 𝑀-dimensional onehot vector where an element is set to  </p><formula xml:id="formula_5">s 𝑢 ∼ Multinoulli 𝑀 {𝛼 𝑢 𝑚 } L (𝑢) = ∥ℎ 𝑡 (𝑢) − 𝑀 𝑚=1 𝑠 𝑢 𝑚 • 𝐸 𝑚 ℎ 𝑠 (𝑢) ∥ 2<label>(6)</label></formula><p>However, the sampling process is non-differentiable, which would block the gradient flows and disable the end-to-end training. As a workaround, we adopt a continuous relaxation of the discrete distribution by using Gumbel-Softmax <ref type="bibr" target="#b7">[8]</ref>. The Gumbel-Softmax is a continuous distribution on the simplex that can approximate samples from a categorical distribution; it uses the Gumbel-Max trick <ref type="bibr" target="#b17">[18]</ref> to draw samples from the categorical distribution, then uses the softmax function as a continuous approximation of argmax operation to get the approximated one-hot representation. With the relaxation, the selection network can be trained by the backpropagation.</p><p>DE gets the approximated one-hot selection variable s 𝑢 by using the Gumbel-Softmax and reconstructs the teacher's representation as follows:</p><formula xml:id="formula_6">𝑠 𝑢 𝑚 = exp log 𝛼 𝑢 𝑚 + 𝑔 𝑚 /𝜏 𝑀 𝑖=1 exp log 𝛼 𝑢 𝑖 + 𝑔 𝑖 /𝜏 for 𝑚 = 1, ..., 𝑀 L (𝑢) = ∥ℎ 𝑡 (𝑢) − 𝑀 𝑚=1 𝑠 𝑢 𝑚 • 𝐸 𝑚 ℎ 𝑠 (𝑢) ∥ 2<label>(7)</label></formula><p>where 𝑔 𝑖 is i.i.d drawn from Gumbel(0, 1) distribution 2 . The extent of relaxation is controlled by a temperature parameter 𝜏. In the beginning of the training, we set a large value on 𝜏, and gradually decreases its value during the training. As 𝜏 is decreased to 0, s 𝑢 smoothly becomes one-hot vector where 𝑠 𝑢 𝑚 = 1 with probability 𝛼 𝑢 𝑚 . In other words, during the training, each expert gradually gets specialized on certain information that has strong correlations. This process is illustrated in Figure <ref type="figure" target="#fig_1">3</ref>. Discussion: Effects of expert selection. As the expert selection is based on the teacher's knowledge, correlations among the entities in the teacher representation space are naturally reflected in the expert selection; the user representations with very similar preferences (i.e., located closely in the space) would be distilled by the same expert with a high probability. This allows each expert to be trained to distill only the knowledge of strongly correlated entities, and thus each expert can provide better guidance that does not include the information of weakly correlated entities. 2 𝑔 𝑖 = −log(−log(𝑟 )), where 𝑟 is sampled from 𝑈 𝑛𝑖 𝑓 𝑜𝑟𝑚 (0, 1).</p><p>Discussion: selection vs. attention. Instead of selecting one expert, the attention mechanism (i.e., the softmax function) can be adopted. However, we think the selection is a more appropriate choice to distill the CF knowledge containing all the entities having diverse preferences and characteristics. This is because the attention makes every expert involved in distilling the knowledge of each entity. In other words, like in the case of a single expert, all the experts and attention network are trained to minimize the overall reconstruction errors of all the diverse entities. By doing so, information of weakly relevant entities gets mixed together, and this leads to performance degrade in some user groups. We provide experiment results to support our claims. Please refer to Section 5.3. </p><formula xml:id="formula_7">L 𝐵𝑎𝑠𝑒 + 𝜆 𝐷𝐸 • L 𝐷𝐸 (8)</formula><p>where 𝜃 𝑠 is the learning parameters of the student model, 𝜃 𝐷𝐸 is the learning parameters of DE (i.e., the selection network and the experts), and 𝜆 𝐷𝐸 is a hyperparameter that controls the effects of DE. The base model can be any existing recommender (e.g., BPR, NeuMF), and L 𝐵𝑎𝑠𝑒 corresponds to its loss function. Note that the experts are not used in the inference phase.</p><p>The loss function of DE can be flexibly defined based on the base model's structure and the types of hidden layer chosen for the distillation. Concretely, for NeuMF <ref type="bibr" target="#b5">[6]</ref>, which is a state-ofthe-art deep recommender, the loss function can be defined to 1) separately distill knowledge of users and items in a mini-batch (i.e., 𝑢 ∈𝐵 L (𝑢) + 𝑖 ∈𝐵 L (𝑖)) or 2) distill the combined knowledge (i.e., (𝑢,𝑖) ∈𝐵 L (𝑢, 𝑖)). Also, we adopt a simple temperature annealing schedule, which gradually decays the temperature from 𝜏 0 to 𝜏 𝑃 as done in <ref type="bibr" target="#b10">[11]</ref>: 𝜏 (𝑝) = 𝜏 0 (𝜏 𝑃 /𝜏 0 ) 𝑝/𝑃 where 𝜏 (𝑝) is the temperature at epoch 𝑝, and 𝑃 is the total training epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Relaxed Ranking Distillation (RRD)</head><p>We propose RRD, a new method to distill the knowledge revealed from the teacher's predictions with direct consideration of ranking orders among items. RRD formulates this as a ranking matching problem between the recommendation list of the teacher model and that of the student model. To this end, RRD adopts the classical list-wise learning-to-rank approach <ref type="bibr" target="#b28">[29]</ref>. Its core idea is to define a probability of a permutation (i.e., a ranking order) based on the ranking score predicted by a model, and train the model to maximize the likelihood of the ground-truth ranking order. For more details about the list-wise approach, please refer to <ref type="bibr" target="#b28">[29]</ref>.</p><p>However, merely adopting the list-wise loss can have adverse effects on the ranking performance. Because a user is interested in only a few items among the numerous total items <ref type="bibr" target="#b9">[10]</ref>, learning the detailed ranking orders of all the unobserved items is not only daunting but also ineffective. The recommendation list from the teacher model contains information about a user's potential preference on each unobserved item; A few items that the user would be interested in (i.e., interesting items) are located near the top of the list, whereas the majority of items that the user would not be interested in (i.e., uninteresting items) are located far from the top.</p><p>Based on this information, RRD reformulates the daunting task of learning all the precise ranking orders to a relaxed ranking matching problem. In other words, RRD aims to match the recommendation list from the teacher and that from the student, ignoring the detailed ranking orders among the uninteresting items. Concretely, RRD distills the information of 1) the detailed ranking orders among the interesting items, 2) the relative ranking orders between the interesting items and the uninteresting items. The overview of RRD is provided in Figure <ref type="figure" target="#fig_0">2b</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2.1</head><p>Sampling interesting/uninteresting items. The first step of RRD is to sample items from the teacher's recommendation list. In specific, RRD samples 𝐾 interesting items and 𝐿 uninteresting items for each user. As a user would not be interested in the vast majority of items, the interesting items should be sampled from a very narrow range near the top of the list, whereas the uninteresting items should be sampled from the wide range of the rest. To sample the interesting items, we adopt a ranking position importance scheme <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b24">25]</ref> that places more emphasis on the higher positions in the ranking list. In the scheme, the probability of the 𝑘-th ranked item to be sampled is defined as: 𝑝 𝑘 ∝ 𝑒 −𝑘/𝑇 where 𝑇 is the hyperparameter that controls emphasis on top positions. With the scheme, RRD samples 𝐾 interesting items according to the user's potential preference on each item (i.e., item's ranking) predicted by the teacher. To sample the uninteresting items that corresponds the majority of items, we use a simple uniform sampling. Concretely, RRD uniformly samples 𝐿 uninteresting items from a set of items that have lower rankings than the previously sampled interesting items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2.2</head><p>Relaxed permutation probability. Then, RRD defines a relaxed permutation probability motivated by <ref type="bibr" target="#b28">[29]</ref>. For user 𝑢, 𝝅 𝒖 denotes a ranked list of all the sampled items (𝐾 + 𝐿) sorted by the original order in the teacher's recommendation list. r 𝑢 denotes ranking scores on the sampled items predicted by the student model. The relaxed permutation probability is formulated as follows:</p><formula xml:id="formula_8">𝑝 𝝅 𝑢 1:𝐾 |r 𝑢 = 𝐾 𝑘=1 exp(𝑟 𝑢 𝜋 𝑘 ) 𝐾 𝑖=𝑘 exp(𝑟 𝑢 𝜋 𝑖 ) + 𝐾+𝐿 𝑗=𝐾 exp(𝑟 𝑢 𝜋 𝑗 )<label>(9)</label></formula><p>where 𝑟 𝑢 𝝅 𝑘 denotes a ranking score predicted by the student for the 𝑘-th item in 𝝅 𝑢 , 𝝅 𝑢 1:𝐾 denotes the partial list that contains the interesting items. RRD learns to maximize the log-likelihood log 𝑝 (𝝅 1:𝐾 |r) for all users. The proposed permutation probability is not affected by the detailed ranking orders among the uninteresting items (𝐿). By maximizing the log-likelihood, the student model is trained to locate all the interesting items (𝐾) higher than all the uninteresting items (𝐿) in the recommendation list, while maintaining the detailed ranking orders (from the teacher's recommendation list) among the interesting items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Optimization of RRD.</head><p>RRD is jointly optimized with the base model's loss function in the end-to-end manner as follows: min</p><formula xml:id="formula_9">𝜃 𝑠 L 𝐵𝑎𝑠𝑒 + 𝜆 𝑅𝑅𝐷 • L 𝑅𝑅𝐷 (<label>10</label></formula><formula xml:id="formula_10">)</formula><p>where 𝜃 𝑠 is the learning parameters of the student model and 𝜆 𝑅𝑅𝐷 is a hyperparameter that controls the effects of RRD. The base model can be any existing recommender, and L 𝐵𝑎𝑠𝑒 corresponds to its loss function. The sampling process is conducted at every epoch. The loss function of RRD is defined to distill the knowledge of users in the mini-batch:</p><formula xml:id="formula_11">− 1 |𝐵 | 𝑢 ∈𝐵 log 𝑝 (𝝅 𝑢 1:𝐾 |r 𝑢 ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Optimization of DE-RRD</head><p>The proposed DE-RRD framework is optimized in the end-to-end manner as follows:</p><p>min</p><formula xml:id="formula_12">𝜃 𝑠 ,𝜃 𝐷𝐸 L 𝐵𝑎𝑠𝑒 + 𝜆 𝐷𝐸 • L 𝐷𝐸 + 𝜆 𝑅𝑅𝐷 • L 𝑅𝑅𝐷 (<label>11</label></formula><formula xml:id="formula_13">)</formula><p>where 𝜃 𝑠 is the learning parameters of the student model, 𝜃 𝐷𝐸 is the learning parameters of DE (i.e., the selection network and the experts). The base model can be any existing recommender, and L 𝐵𝑎𝑠𝑒 corresponds to its loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>We validate the superiority of DE-RRD on 12 experiment settings (2 real-world datasets × 2 base models × 3 different student model sizes). We first provide extensive experiment results supporting that DE-RRD outperforms the state-of-the-art competitors (Section 5.2). We also provide both quantitative and qualitative analyses to verify the rationality and superiority of each proposed component (Section 5.3). Lastly, we provide hyperparameter study (Section 5.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>Datasets. We use two public real-world datasets: CiteULike <ref type="bibr" target="#b26">[27]</ref>, Foursquare <ref type="bibr" target="#b16">[17]</ref>. We remove users and items having fewer than five ratings for CiteULike, twenty ratings for Foursquare as done in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b20">21]</ref>. Data statistics are summarized in Table <ref type="table" target="#tab_1">1</ref>. Base Models. We validate the proposed framework on base models that have different architectures and optimization strategies. We choose a latent factor model and a deep learning model that are broadly used for top-𝑁 recommendation with implicit feedback.</p><p>• BPR <ref type="bibr" target="#b20">[21]</ref>: A learning-to-rank model for implicit feedback. It assumes that observed items are more preferred than unobserved items and optimizes Matrix Factorization (MF) with the pair-wise ranking loss function.</p><p>• NeuMF <ref type="bibr" target="#b5">[6]</ref>: The state-of-the-art deep model for implicit feedback. NeuMF combines MF and Multi-Layer Perceptron (MLP) to learn the user-item interaction, and optimizes it with the pointwise objective function (i.e., binary cross-entropy).</p><p>Teacher/Student. For each base model and dataset, we increase the number of learning parameters until the recommendation performance is no longer increased, and use the model with the best performance as Teacher model. For each base model, we build three student models by limiting the number of learning parameters. We adjust the number of parameters based on the size of the last hidden layer. The limiting ratios (𝜙) are {0.1, 0.5, 1.0}. Following the notation of the previous work <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25]</ref>, we call the student model trained without the help of the teacher model (i.e., no distillation) as "Student" in this experiment sections.</p><p>Comparison Methods. The proposed framework is compared with the following methods:</p><p>• Ranking Distillation (RD) <ref type="bibr" target="#b24">[25]</ref>: A KD method for recommender system that uses items with the highest ranking from the teacher's predictions for distilling the knowledge. • Collaborative Distillation (CD) <ref type="bibr" target="#b12">[13]</ref>: The state-of-the-art KD method for recommender system. CD samples items from teacher's predictions based on their ranking, then uses them for distillation. As suggested in the paper, we use unobserved items only for distilling the knowledge.</p><p>Finally, DE-RRD framework consists of the following two methods:</p><p>• Distillation Experts (DE): A KD method that directly distills the latent knowledge stored in the teacher model. It can be combined with any prediction-based KD methods (e.g., RD, CD, RRD). • Relaxed Ranking Distillation (RRD): A KD method that distills the knowledge revealed from the teacher's predictions with consideration of relaxed ranking orders among items.</p><p>Evaluation Protocol. We follow the widely used leave-one-out evaluation protocol <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b18">19]</ref>. For each user, we leave out a single interacted item for testing, and use the rest for training. In our experiments, we leave out an additional interacted item for the validation. To address the time-consuming issue of ranking all the items, we randomly sample 499 items from a set of unobserved items of the user, then evaluate how well each method can rank the test item higher than these sampled unobserved items. We repeat this process of sampling a test/validation item and unobserved items five times and report the average results.</p><p>As we focus on the top-𝑁 recommendation task based on implicit feedback, we evaluate the performance of each method with widely used three ranking metrics <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>: hit ratio (H@𝑁 ), normalized discounted cumulative gain (N@𝑁 ), and mean reciprocal rank (M@𝑁 ). H@𝑁 measures whether the test item is present in the top-𝑁 list, while N@𝑁 and M@𝑁 are position-aware ranking metrics that assign higher scores to the hits at upper ranks. Implementation Details for Reproducibility. We use PyTorch to implement the proposed framework and all the baselines, and use Adam optimizer to train all the methods. For RD, we use the public implementation provided by the authors. For each dataset, hyperparameters are tuned by using grid searches on the validation set. The learning rate for the Adam optimizer is chosen from {0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001}, the model regularizer is chosen from {10 −1 , 10 −2 , 10 −3 , 10 −4 , 10 −5 }. We set the total number of epochs as 1000, and adopt early stopping strategy; stopping if H@5 on the validation set does not increase for 30 successive epochs. For all base models (i.e., BPR, NeuMF), the number of negative sample is set to 1, and no pre-trained technique is used. For NeuMF, the number of the hidden layers is chosen from {1, 2, 3, 4}.</p><p>For all the distillation methods (i.e., RD, CD, DE, RRD), weight for KD loss (𝜆) is chosen from {1, 10 −1 , 10 −2 , 10 −3 , 10 −4 , 10 −5 }. For DE, the number of experts (𝑀) is chosen from {5, 10, 20, 30}, MLP is employed for the experts and the selection network. The shape of the layers of an expert is [𝑑 𝑠 → (𝑑 𝑠 + 𝑑 𝑡 )/2 → 𝑑 𝑡 ] with relu activation, and that of the selection network is [𝑑 𝑡 → 𝑀]. We select the last hidden layer of all the base models to distill latent knowledge. We put the experts according to the structure of the selected layer; For the layer where user and item are separately encoded (i.e., BPR), we put 𝑀 user-side experts and 𝑀 item-side experts, and for the layer where user and items are jointly encoded (i.e., NeuMF), we put 𝑀 experts to distill the combined information. 𝜏 0 and 𝜏 𝑃 are set to 1, 10 −10 , respectively. For prediction-based KD methods (i.e., RD, CD, RRD), the number of high-raked (or interesting) items (𝐾) for distillation is chosen from {10, 20, 30, 40, 50}, weight for controlling the importance of top position (𝑇 ) is chosen from {1, 5, 10, 20}. For RRD, the number of uninteresting items (𝐿) is set to the same with 𝐾, but it can be further tuned. For RD, the number of the warm-up epoch is chosen from {30, 50, 100}, the number of negative items in the dynamic weight is chosen from {50, 100}. Also, RD and CD have additional hyperparameters for reflecting the relative importance of the items used for distillation. We follow the recommended values from the public implementation and from the original papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance Comparison</head><p>Table <ref type="table" target="#tab_2">2</ref> shows top-𝑁 recommendation accuracy of different methods in terms of various ranking metrics. In summary, DE-RRD shows the significant improvement compared to the state-of-the-art KD methods on two base models that have different architectures and optimization strategies. Also, DE-RRD consistently outperforms the existing methods on three different sizes of the student model in Figure <ref type="figure">4</ref>. We analyze the results from various perspectives.</p><p>We first observe that the two methods of the proposed framework (i.e., DE, RRD) improve the performance of the student model. DE directly distills the teacher's latent knowledge that includes detailed information on users, items, and the relationships among them. This enables the student to be more effectively trained than finding such information from scratch with a limited capacity. RRD distills the knowledge from the teacher's predictions based on the relaxed ranking approach which makes the student to effectively maintain the ranking orders of interesting items predicted by the teacher. Unlike the existing methods (i.e., RD, CD), it directly handles the ranking violations among the sampled items, which can lead to better ranking performance.</p><p>Also, we observe that RRD achieves large performance gain particularly in NeuMF (𝜙 = 0.1). One possible reason is that NeuMF is trained with the point-wise loss function (i.e., binary cross-entropy) which considers only one item at a time. In general, it is known that the approaches considering the preference orders between items (e.g., pair-wise, list-wise) can achieve better ranking performance than the point-wise approach <ref type="bibr" target="#b23">[24]</ref>. RRD enables the model to capture the ranking orders among the unobserved items, so that it can lead to the large performance gain. Interestingly, we observe that the prediction-based KD methods (i.e., RD, CD, RRD) can have an adverse effect when the model size is large (NeuMF with 𝜙 = 0.5, 1.0 in Figure <ref type="figure">4</ref>). We conjecture that this is because when a model has sufficient capacity to achieve comparable performance to the teacher, enforcing it to exactly mimic the teacher's prediction results can act as a strong constraint that rather hinders its learning.</p><p>In addition, we observe that DE-RRD achieves the best performance among all the methods in general. DE-RRD enables the student to learn both from the teacher's prediction and from the latent knowledge that provides the bases for such predictions. Interestingly, DE-RRD also shows a large performance gain when the student model has the identical structure to the teacher model (i.e., self-distillation with 𝜙 = 1.0 in Figure <ref type="figure">4</ref>). This result shows that </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Design Choice Analysis</head><p>We provide both quantitative and qualitative analyses on the proposed methods and alternative design choices (i.e., ablations) to verify the superiority of our design choice. The performance comparisons with the ablations are summarized in Table <ref type="table" target="#tab_4">4</ref>.</p><p>For DE, we consider three ablations: (a) Attention (b) One expert (large) (c) One expert (small). As discussed in Section 4.1.2, instead of the selection strategy, attention mechanism can be adopted. We also compare the performance of one large expert <ref type="foot" target="#foot_1">3</ref> and one small expert. Note that DE, attention, and one expert (large) has the exact same number of learning parameters for experts. We observe that the increased numbers of learning parameters do not necessarily contribute to performance improvement ((a) vs. (c) in BPR).</p><p>We also observe that the selection shows the best performance among all the ablations. To further investigate this result, we conduct qualitative analysis on user representation spaces induced by each design choice. Specifically, we first perform clustering <ref type="foot" target="#foot_2">4</ref> on user representation space from the teacher model to find user groups that have strong correlations (or similar preferences). Then, we visualize the average performance gain (per group) map in Figure <ref type="figure" target="#fig_3">5</ref>. We observe that distilling the knowledge by the attention, one large expert can cause performance decreases in many user groups (blue clusters), whereas the selection improves the performance in more numbers of user groups (red clusters). In the ablations (a)-(c), the experts are trained to minimize the overall reconstruction errors on all the diverse entities. This makes the information of weakly correlated entities to be mixed together and further hinders discovering the preference of a particular user group. Unlike the ablations, DE clearly distinguishes the knowledge that each expert distills, and makes each expert to be trained to distill only the knowledge of strongly correlated entities. So, it can alleviate such problem. The expert selection map of DE is visualized in Figure <ref type="figure" target="#fig_5">6</ref>. We can observe that each expert gets gradually specialized in certain user groups that share similar preferences during the training.</p><p>For RRD, we consider two ablations: (d) and (e). The ablations are intended to show the effects of the proposed relaxed ranking. Concretely, we apply the list-wise loss (i.e., no relaxation) on all the sampled items (interesting and uninteresting items) for (d), on the top-ranked items (interesting items) for (e). Note that all the methods use the same number of items for distillation. We observe    that merely the list-wise loss has adverse effects on the ranking performance. First, (d) learns to match the full ranking order among all the sampled items. Learning the detailed order among the uninteresting items is not necessarily helpful to improve the ranking performance, and may further interfere with focusing on the interesting items. Also, (e), which only considers the interesting items, shows even worse performance than Student. The list-wise loss does not take into account the absolute ranking positions of the items; a ranking order can be satisfied regardless of the items' absolute positions. Since (e) does not consider the relative orders between the interesting items and the uninteresting items, it may push such interesting items far from the top of the ranking list. Unlike the ablations, RRD adopts the relaxed ranking approach, which enables the student to better focus on the interesting items while considering the relative orders with the uninteresting items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Hyperparameter Analysis</head><p>We provide analyses to offer guidance of hyperparameter selection of DE-RRD. For the sake of space, we report the results on Foursquare dataset with 𝜙 = 0.1. We observe similar tendencies on CiteULike dataset. For DE, we show the effects of two hyperparameters: 𝜆 𝐷𝐸 that controls the importance of DE and the number of experts in Figure <ref type="figure">7a</ref>. For RRD, we show the effects of two hyperparameters: 𝜆 𝑅𝑅𝐷 that controls the importance of RRD and the number of interesting items (𝐾) in Figure <ref type="figure">7b</ref>. In our experiment, the number of uninteresting items is set to the same with 𝐾. Note that for all graphs value '0' corresponds to Student (i.e., no distillation).</p><p>Because the types of loss function of the proposed methods are different from that of the base models, it is important to properly balance the losses by using 𝜆. For DE, the best performance is achieved when the magnitude of DE loss is approximately 20% (BPR), 2-5% (NeuMF) compared to that of the base model's loss. For RRD, the best performance is achieved when the magnitude of RRD loss is approximately 7-10% (BPR), 1000% (NeuMF) compared to that of the base model's loss. For the number of experts and 𝐾, the best performance is achieved near 10-20 and 30-40, respectively. Lastly, we show the effects of combinations of 𝜆 𝐷𝐸 and 𝜆 𝑅𝑅𝐷 in DE-RRD framework in Table <ref type="table">5</ref>. Generally, the best performance of DE-RRD is observed in the ranges where each method (i.e., DE, RRD) achieves the best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>This paper proposes a novel knowledge distillation framework for recommender system, DE-RRD, that enables the student model to learn both from the teacher's predictions and from the latent knowledge stored in a teacher model. To this end, we propose two novel methods: 1) DE that directly distills latent knowledge from the representation space of the teacher. DE adopts the experts and the expert selection strategy to effectively distill the vast CF knowledge to the student. 2) RRD that distills knowledge revealed from teacher's predictions with direct considerations of ranking orders among items. RRD adopts the relaxed ranking approach to better focus on the interesting items. Extensive experiment results demonstrate that DE-RRD significantly outperforms the state-ofthe-art competitors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustration of DE-RRD framework. (a) Distillation Experts (DE) directly distills the teacher's latent knowledge with the experts and the selection strategy. (b) Relaxed Ranking Distillation (RRD) distills the knowledge from the teacher's prediction based on the relaxed ranking approach that ignores orders among the uninteresting items. Best viewed in color. component of the proposed framework: DE in Section 4.1, RRD in Section 4.2. Then, we explain the end-to-end optimization process in Section 4.3. The overview of DE-RRD is provided in Figure 2.</figDesc><graphic url="image-2.png" coords="4,66.41,83.68,479.17,151.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration of the expert selection process of DE. During the training, s 𝑢 becomes a one-hot vector and selects the most specialized expert in the knowledge to be distilled. 𝑝 𝑠 𝑢 𝑚 = 1|𝑆, ℎ 𝑡 (𝑢) = 𝛼 𝑢 𝑚 , then reconstructs teacher's representation as follows: s 𝑢 ∼ Multinoulli 𝑀 {𝛼 𝑢 𝑚 }</figDesc><graphic url="image-3.png" coords="5,60.43,83.69,226.98,80.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>4 . 1 . 3</head><label>413</label><figDesc>Optimization of DE. DE is jointly optimized with the base model's loss function in the end-to-end manner as follows: min 𝜃 𝑠 ,𝜃 𝐷𝐸</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Performance (N@20) gain map (BPR with 𝜙 = 0.1 on Foursquare).</figDesc><graphic url="image-18.png" coords="9,398.44,361.42,79.28,57.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Expert selection map of DE. Each color corresponds to an expert (BPR with 𝜙 = 0.1 on Foursquare).</figDesc><graphic url="image-17.png" coords="9,319.71,361.42,79.28,57.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>(a) Effects of 𝜆 𝐷𝐸 and the number of experts (b) Effects of 𝜆 𝑅𝑅𝐷 and 𝐾 Figure 7: Effects of the hyperparameters. (a) DE (b) RRD. Table 5: Effects of 𝜆 𝐷𝐸 and 𝜆 𝑅𝑅𝐷 in DE-RRD framework. BPR NeuMF Foursquare (H@5) 𝜆 𝑅𝑅𝐷 𝜆 𝑅𝑅𝐷 10 −4 10 −3 10 −2 10 −1 10 −4 10 −3 10 −2 10 −1 10 −4 0.5081 0.5201 0.4590 0.3901 0.4774 0.4896 0.5014 0.5193 𝜆 𝐷𝐸 10 −3 0.5186 0.5276 0.4688 0.3906 0.4774 0.4858 0.4942 0.5112 10 −2 0.5261 0.5308 0.4791 0.3977 0.4846 0.4868 0.4892 0.5110 10 −1 0.5269 0.5308 0.4928 0.4154 0.4848 0.4881 0.4908 0.5055</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Data Statistics (after preprocessing)</figDesc><table><row><cell>Dataset</cell><cell cols="3">#Users #Items #Interactions Sparsity</cell></row><row><cell cols="2">CiteULike Foursquare 19,466 28,594 5,220 25,182</cell><cell>115,142 609,655</cell><cell>99.91% 99.89%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Recommendation performances (𝜙 = 0.1). Improv.b and Improv.s denote the improvement of DE-RRD over the best baseline and student respectively. *, **, ***, and **** indicate 𝑝 ≤ 0.05, 𝑝 ≤ 0.005, 𝑝 ≤ 0.0005, and 𝑝 ≤ 0.00005 for the paired t-test of vs. the best baseline (for RRD, DE-RRD), vs. Student (for DE) on H@5.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Model compactness and online inference efficiency. Time (seconds) indicates the wall time used for generating recommendation list for every user. H@5 Ratio denotes the ratio of H@5 from DE-RRD over that from Teacher.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Base Model 𝜙</cell><cell cols="3">Time (s) #Params. H@5 Ratio</cell></row><row><cell>CiteULike</cell><cell>BPR NeuMF</cell><cell>1.0 0.5 0.1 1.0 0.5 0.1</cell><cell>59.27s 57.53s 55.39s 79.27s 68.37s 58.27s</cell><cell>6.08M 3.04M 0.61M 15.33M 7.63M 1.52M</cell><cell>1.03 1.01 0.94 1.01 1.01 0.99</cell></row><row><cell>Foursquare</cell><cell>BPR NeuMF</cell><cell cols="2">1.0 257.28s 0.5 249.19s 0.1 244.23s 1.0 342.84s 0.5 297.34s 0.1 255.24s</cell><cell>9.61M 4.81M 0.96M 24.16M 12.05M 2.40M</cell><cell>1.03 1.01 0.95 1.02 1.01 0.95</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Performance comparison for alternative design choices on Foursquare (𝜙 = 0.1). Interesting ranking 0.4641 0.3294 0.6228 0.3809</figDesc><table><row><cell cols="3">Base Model Design choices</cell><cell>H@5 N@5 H@10 N@10</cell></row><row><cell></cell><cell cols="2">DE (a) Attention</cell><cell>0.5283 0.3824 0.6810 0.4316 0.5019 0.3625 0.6575 0.4131</cell></row><row><cell>BPR</cell><cell cols="3">(b) One expert (large) 0.5151 0.3716 0.6733 0.4230 (c) One expert (small) 0.5136 0.3717 0.6683 0.4213</cell></row><row><cell></cell><cell cols="2">RRD (d) Full ranking</cell><cell>0.5132 0.3722 0.6616 0.4202 0.4983 0.3595 0.6474 0.4080</cell></row><row><cell></cell><cell cols="3">(e) Interesting ranking 0.4814 0.3479 0.6416 0.3999</cell></row><row><cell></cell><cell cols="2">DE (a) Attention</cell><cell>0.4862 0.3444 0.6413 0.3938 0.4770 0.3364 0.6364 0.3903</cell></row><row><cell>NeuMF</cell><cell cols="3">(b) One expert (large) 0.4741 0.3367 0.6341 0.3885 (c) One expert (small) 0.4740 0.3339 0.6316 0.3860</cell></row><row><cell></cell><cell cols="2">RRD (d) Full ranking</cell><cell>0.5172 0.3621 0.6739 0.4132 0.4799 0.3457 0.6324 0.3949</cell></row><row><cell cols="2">(e) Attention</cell><cell cols="2">One expert (large)</cell><cell>DE (selection)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://github.com/SeongKu-Kang/DE-RRD_CIKM20</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">We make one large expert by adopting the average pooling.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2">We use 𝑘-Means clustering in Scikit-learn. 𝑘 is set to 20.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements: This research was supported by the NRF grant funded by the MSIT: (No. 2017M3C4A7063570), the IITP grant funded by the MSIT: (No. 2018-0-00584), the IITP grant funded by the MSIP (No. 2019-0-01906, Artificial Intelligence Graduate School Program (POSTECH)) and the MSIT under the ICT Creative Consilience program (IITP-2020-2011-1-00783) supervised by the IITP.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Base Model KD Method H@5 M@5 N@5 H@10 M@10 N@10 H@20 M@20 N@20 Teacher 0.  it can be also used to maximize the performance of the existing recommender.</p><p>Lastly, we provide the result of the online inference efficiency test in Table <ref type="table">3</ref>. All inferences are made using PyTorch with CUDA from Tesla P40 GPU and Xeon on Gold 6148 CPU. The student model trained with DE-RRD achieves comparable performance with only 10-50% of learning parameters compared to the teacher.</p><p>The smaller model requires less computations and memory costs, so it can achieve lower latency. In particular, deep recommender (i.e., NeuMF) which has a large number of learning parameters and complex structures takes more benefits from the smaller model size. On real-time RS application that has larger numbers of users (and items) and has a more complex model structure, DE-RRD can lead to a larger improvement in online inference efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Full Paper Track</head><p>CIKM <ref type="bibr">'20, October 19-23, 2020, Virtual Event, Ireland</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Speeding up the xbox recommender system using a euclidean transformation for inner-product spaces</title>
		<author>
			<persName><forename type="first">Yoram</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Gilad-Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liran</forename><surname>Katzir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Koenigstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nir</forename><surname>Nice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulrich</forename><surname>Paquet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>In RecSys</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multidimensional binary search trees used for associative searching</title>
		<author>
			<persName><forename type="first">Jon</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bentley</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<date type="published" when="1975">1975. 1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning efficient object detection models with knowledge distillation</title>
		<author>
			<persName><forename type="first">Guobin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="742" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Localitysensitive hashing scheme based on p-stable distributions</title>
		<author>
			<persName><forename type="first">Mayur</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicole</forename><surname>Immorlica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName><surname>Vahab</surname></persName>
		</author>
		<author>
			<persName><surname>Mirrokni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twentieth annual symposium on Computational geometry</title>
				<meeting>the twentieth annual symposium on Computational geometry</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="253" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Furlanello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.04770</idno>
		<title level="m">Born again neural networks</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01144</idno>
		<title level="m">Categorical reparameterization with gumbel-softmax</title>
				<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semisupervised learning for cross-domain recommendation to cold-start users</title>
		<author>
			<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongha</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Candidate Generation with Binary Codes for Large-Scale Top-N Recommendation</title>
		<author>
			<persName><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep Rating Elicitation for New Users in Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Wonbin</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Action Space Learning for Heterogeneous User Behavior Prediction</title>
		<author>
			<persName><forename type="first">Dongha</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chanyoung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunjun</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Jaewoong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minjin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jongwuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunjung</forename><surname>Shim</surname></persName>
		</author>
		<title level="m">Collaborative Distillation for Top-N Recommendation. ICDM</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">FEXIPRO: fast and exact inner product retrieval in recommender systems</title>
		<author>
			<persName><forename type="first">Hui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nam</forename><surname>Tsz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Man</forename><forename type="middle">Lung</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Yiu</surname></persName>
		</author>
		<author>
			<persName><surname>Mamoulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM International Conference on Management of Data</title>
				<meeting>the 2017 ACM International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Xing Xie, and Longbing Cao. 2017. Discrete Content-Aware Matrix Factorization</title>
		<author>
			<persName><forename type="first">Defu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Discrete factorization machines for fast feature-based recommendation</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.02232</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">An experimental evaluation of point-of-interest recommendation in location-based social networks</title>
		<author>
			<persName><forename type="first">Yiding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tuan-Anh Nguyen</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gao</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Yuan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A* sampling</title>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Minka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Collaborative Translational Metric Learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Improving pairwise learning for item recommendation from implicit feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">BPR: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
				<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samira</forename><forename type="middle">Ebrahimi</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6550</idno>
		<title level="m">Fitnets: Hints for thin deep nets</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Asymmetric LSH (ALSH) for sublinear time maximum inner product search (MIPS)</title>
		<author>
			<persName><forename type="first">Anshumali</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neural collaborative ranking</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Congfu</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Ranking distillation: Learning compact ranking models with high performance for recommender system</title>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Analysing compression techniques for in-memory collaborative filtering</title>
		<author>
			<persName><forename type="first">Saúl</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Collaborative topic regression with social regularization for tag recommendation</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wu-Jun</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Binarized collaborative filtering with distilling graph convolutional networks</title>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Defu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Listwise approach to learning to rank: theory and algorithm</title>
		<author>
			<persName><forename type="first">Fen</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wensheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Discrete Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fumin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
