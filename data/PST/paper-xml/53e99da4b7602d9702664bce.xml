<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An efficient local Chan-Vese model for image segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiao-Feng</forename><surname>Wang</surname></persName>
							<email>xfwanghf@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Intelligent Computing Lab</orgName>
								<orgName type="department" key="dep2">Hefei Institute of Intelligent Machines</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postBox>P.O. Box 1130</postBox>
									<postCode>230031</postCode>
									<settlement>Hefei Anhui</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<postCode>230027</postCode>
									<settlement>Hefei Anhui</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">Key Lab of Network and Intelligent Information Processing</orgName>
								<orgName type="institution">Hefei University</orgName>
								<address>
									<postCode>230022</postCode>
									<settlement>Hefei Anhui</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">De-Shuang</forename><surname>Huang</surname></persName>
							<email>dshuang@iim.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Intelligent Computing Lab</orgName>
								<orgName type="department" key="dep2">Hefei Institute of Intelligent Machines</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postBox>P.O. Box 1130</postBox>
									<postCode>230031</postCode>
									<settlement>Hefei Anhui</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huan</forename><surname>Xu</surname></persName>
							<email>xuhuan@mail.ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Intelligent Computing Lab</orgName>
								<orgName type="department" key="dep2">Hefei Institute of Intelligent Machines</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postBox>P.O. Box 1130</postBox>
									<postCode>230031</postCode>
									<settlement>Hefei Anhui</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<postCode>230027</postCode>
									<settlement>Hefei Anhui</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An efficient local Chan-Vese model for image segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3C6EEEBB006029794670A6B54040DF73</idno>
					<idno type="DOI">10.1016/j.patcog.2009.08.002</idno>
					<note type="submission">Received 28 September 2008 Received in revised form 14 May 2009 Accepted 2 August 2009</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Extended structure tensor Image segmentation Intensity inhomogeneity Level set method Local Chan-Vese model</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, a new local Chan-Vese (LCV) model is proposed for image segmentation, which is built based on the techniques of curve evolution, local statistical function and level set method. The energy functional for the proposed model consists of three terms, i.e., global term, local term and regularization term. By incorporating the local image information into the proposed model, the images with intensity inhomogeneity can be efficiently segmented. In addition, the time-consuming re-initialization step widely adopted in traditional level set methods can be avoided by introducing a new penalizing energy. To avoid the long iteration process for level set evolution, an efficient termination criterion is presented which is based on the length change of evolving curve. Particularly, we proposed constructing an extended structure tensor (EST) by adding the intensity information into the classical structure tensor for texture image segmentation. It can be found that by combining the EST with our LCV model, the texture image can be efficiently segmented no matter whether it presents intensity inhomogeneity or not. Finally, experiments on some synthetic and real images have demonstrated the efficiency and robustness of our model. Moreover, comparisons with the well-known Chan-Vese (CV) model and recent popular local binary fitting (LBF) model also show that our LCV model can segment images with few iteration times and be less sensitive to the location of initial contour and the selection of governing parameters.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image segmentation has always been a fundamental problem and complex task in the field of image processing and computer vision. Its goal is to change the representation of an image into something that is more meaningful and easier to analyze <ref type="bibr" target="#b0">[1]</ref>. In other words, it is used to partition a given image into several parts in each of which the intensity is homogeneous. Up to now, a wide variety of algorithms have been proposed to solve the image segmentation problem. Researchers have also done great efforts to improve the performance of the image segmentation algorithms.</p><p>Active contour model, or snakes, proposed by Kass et al. <ref type="bibr" target="#b1">[2]</ref>, has been proved to be an efficient framework for image segmentation. The fundamental idea of active contour model is to start with a curve around the object to be detected, and the curve moves toward its interior normal and stops on the true boundary of the object based on an energy-minimizing model. The main drawbacks of this method are its sensitivity to initial conditions and the difficulties associated with topological changes like the merging and splitting of the evolving curve. Since the active contour model was proposed, many methods have been proposed to improve it, in which level set method proposed by Osher and Sethian <ref type="bibr" target="#b2">[3]</ref> is the most important and successful one.</p><p>Level set method is based on active contour model and particularly designed to handle the segmentation of deformable structures. Generally, the classical active contour model uses spline curves to model the boundary of an object. However, the level set method is to use a deformable curve front for approximating the boundary of an object. In the level set framework, the curve is represented by the zero level set of a smooth function, usually called the level set function. Moving the curves can be done by evolving the level set functions instead of directly moving the curves. Therefore, level set methods exhibit interesting elastic behaviors and can efficiently handle the topological changes which is also a main advantage compared with classical active contour model. Formally, the evolution of the curve is driven by a time-dependent partial differential equation (PDE) where the so-called velocity term reflects the image features characterizing the object to be segmented <ref type="bibr" target="#b3">[4]</ref>.</p><p>Generally, a classical level set framework consists of an implicit data representation of a hypersurface, a set of partial differential equations (PDEs) that govern how the curve moves, and the corresponding numerical solution for implementing this method on computers <ref type="bibr" target="#b4">[5]</ref>.</p><p>It should be mentioned that the early edge-based level set methods <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref> usually depend on the gradient of the given image for stopping the evolution of the curve. Therefore, these methods can only detect objects with edges defined by the gradient. However, the corresponding discrete gradients are generally bounded and the energy functional will hardly approach zero on the boundaries in practice. So, the evolving curve may pass through the true boundaries, especially for the models in <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>.</p><p>Recently, region-based level set methods <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref> have been proposed and applied to image segmentation filed by incorporating region-based information into the energy functional. Unlike edgebased level set methods using image gradient, region-based methods usually utilize the global region information to stabilize their responses to local variations (such as weak boundaries and noise). Thus, they can obtain a better performance of segmentation than edge-based level set methods, especially for images with weak object boundaries and noise. Among the region-based methods, Chan-Vese model <ref type="bibr" target="#b9">[10]</ref> is a representative and popular one.</p><p>Based on the Mumford-Shah functional <ref type="bibr" target="#b8">[9]</ref> for segmentation, Chan and Vese <ref type="bibr" target="#b9">[10]</ref> proposed an easily handled model, or called Chan-Vese (CV) model, to detect objects whose boundaries are not necessarily detected by the gradient. Mumford-Shah model was firstly proposed as a general image segmentation model by Mumford and Shah in <ref type="bibr" target="#b8">[9]</ref>. Using this model, the image is decomposed into some regions. Inside each region, the original image is approximated by a smooth function. The optimal partition of the image can be found by minimizing the Mumford-Shah functional. Chan and Vese successfully solved the minimization problem by using level set functions, which utilized the global image statistics inside and outside the evolving curve rather than the gradients on the boundaries.</p><p>CV model has achieved good performance in image segmentation task due to its ability of obtaining a larger convergence range and handling topological changes naturally. However, it still has some intrinsic limitations. First, CV model generally works for images with intensity homogeneity since it assumes that the intensities in each region always maintain constant. Thus, it often leads to poor segmentation results for images with intensity inhomogeneity due to wrong movement of evolving curves guided by global image information. Second, the segmentation of CV model is usually dependent on the placement of the initial contour, especially for the complicated images. Sometimes, the different results will be obtained on the same image by using different initial contours. Thus, the placement of initial contour is still an important issue for CV model to get successful segmentation in complicated images. Third, the CV model may become time-consuming if the periodical re-initialization step is adopted, which is a technique for periodically re-initializing the level set function to a signed distance function during the evolution. It has been regarded as a numerical remedy for maintaining stable curve evolution and ensuring precise results, which also leads to time-consumption as the side effect.</p><p>To solve the limitations of CV model, many efficient implementation schemes have been proposed <ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref>. For example, in <ref type="bibr" target="#b13">[14]</ref>, Vese and Chan extended their original model in <ref type="bibr" target="#b9">[10]</ref> by using a multiphase level set formulation. However, the involved computation in this model is very expensive, which also limits its applications in practice. In addition, to reduce the computational cost, this method usually requires that the initial contour should be near to the object boundaries. In <ref type="bibr" target="#b14">[15]</ref>, an initialization scheme for the CV model was introduced, in which the initial curve is found by searching among the externals of the fidelity term in <ref type="bibr" target="#b9">[10]</ref>. However, this one-dimensional search method is also time-consuming and fails to work when the gray difference between object and background is small. Xia et al. <ref type="bibr" target="#b15">[16]</ref> proposed another initialization method which generates initial closed curves by iteratively connecting edge points obtained by canny detector and morphological filter. This method can efficiently work for some simple images. To reduce the computational load of curve evolution for CV model, the implementation schemes without solving the PDEs were proposed <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>. However, they are still sensitive to the selection of initial curves and sometime sensitive to noise. Li et al. <ref type="bibr" target="#b18">[19]</ref> proposed a so-called penalizing energy which acts as a metric to characterize how close the level set function to a signed distance function. This metric can also be adopted by CV model to avoid the re-initialization step. In <ref type="bibr" target="#b19">[20]</ref>, the penalizing energy proposed in <ref type="bibr" target="#b18">[19]</ref> and a discrimination function based on color information was combined into the CV model for segmenting the color images.</p><p>To efficiently perform the segmentation of images with intensity inhomogeneity, a new class of models has been proposed which not only utilize region-based techniques but also incorporate the benefits of local information. There have been several literatures <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref> which are relevant to the existing works. Paragios et al. <ref type="bibr" target="#b11">[12]</ref> presented a method in which edge-based energies and region-based energies were explicitly summed to create a joint energy which was then minimized. In <ref type="bibr" target="#b20">[21]</ref>, Sum et al. took a similar approach and minimized the sum of a global region-based energy and a local energy based on image contrast. Brox et al. <ref type="bibr" target="#b21">[22]</ref> proposed the idea of incorporating localized statistics into a variational framework which shows that segmentation with local means is a first order approximation of the piecewise smooth simplification of the Mumford-Shah functional. Piovano et al. <ref type="bibr" target="#b22">[23]</ref> employed convolutions to quickly compute localized statistics and yielded results similar to piecewisesmooth segmentation in a much more efficient manner. The work of An et al. <ref type="bibr" target="#b23">[24]</ref> also noted the efficiency of localized approaches versus full piecewise smooth estimation and introduced a way in which localizations at two different scales can be combined to allow sensitivity to both coarse and fine image features. In <ref type="bibr" target="#b24">[25]</ref>, the authors proposed a similar flow based on computing geodesic curves in the space of localized means rather than approximating a piecewisesmooth model. In <ref type="bibr" target="#b25">[26]</ref>, a novel localization framework was proposed which allows the region-based energy to be localized in a fully variational way so that objects with heterogeneous statistics can be successfully segmented with the localized energies. Recently, Li et al. proposed an efficient region-based level set method by introducing a local binary fitting (LBF) energy with a kernel function <ref type="bibr" target="#b26">[27]</ref>. The LBF model enables the extraction of accurate local image and can be used to segment the images with intensity inhomogeneity. It has attracted extensive attentions for its good segmentation performance in limited iterations. However, the LBF model usually needs to perform four convolution operations at each iteration, which greatly increases the computational complexity. In addition, it is also sensitive to the selection of governing parameters and the location of initial curve.</p><p>For CV model using the intensity average only, texture image segmentation is another difficult issue since intensity averages cannot represent the texture information inside and outside the target objects. In many texture images, due to the difference of the intensity averages of neighboring textures, the small textures in objects will be segmented while the desirable whole objects will be not separated. Therefore, other information should be introduced for texture image segmentation. Chan and Vese <ref type="bibr" target="#b9">[10]</ref> suggested using texture information or features extracted from the original image, such as the curvature or the orientation of level sets, to overcome the difficulty. However, the proposed texture information in <ref type="bibr" target="#b9">[10]</ref> cannot work well in many complicated texture images due to their simple properties. Note that the texture image segmentation greatly relies on the extraction of suitable texture information from the image. Recently, Gabor filters have been efficiently incorporated into level set methods and CV model for the texture image segmentation <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref>. Unfortunately, Gabor filters have the fatal drawback that they induce a lot of redundancies and thus lots of feature channels <ref type="bibr" target="#b29">[30]</ref>. As another efficient texture representation, the structure tensor <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref> is a kind of low dimensional feature computed from the spatial derivatives of the image. It is a common tool for local orientation estimation and image structure analysis which is formed as the outer product of the image gradient with itself. So far, the structure tensor has been applied in many image segmentation algorithms, most notably, in the early geodesic active contours framework <ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref>.</p><p>In this paper, we proposed a so-called local Chan-Vese (LCV) model which utilizes both global image information and local image information for image segmentation. The energy functional for the proposed model consists of three parts: global term, local term and regularization term. By using the local image information, the images with intensity inhomogeneity can be efficiently segmented in limited iterations. Moreover, the time-consuming re-initialization step widely adopted in traditional level set methods can be avoided by introducing a new penalizing energy to the regularization term. As a result, the time-consumption is greatly decreased. Specially, the evolving curve in level set evolution process can automatically stop on true boundaries of objects according to a termination criterion which is based on the length change of evolving curve. Finally, we proposed constructing an extended structure tensor (EST) by adding the intensity information into the classical structure tensor for texture image segmentation. By incorporating the EST into the proposed LCV model, the texture image can be easily segmented no matter whether it presents intensity inhomogeneity or not. Moreover, the comparisons with the CV model and recent LBF model show that our LCV model can segment ordinary/texture images with or without intensity inhomogeneity in fewer iterations. Particularly, it can be found that our model is less sensitive to the location of initial contour and the selection of governing parameters.</p><p>The rest of this paper is organized as follows: In Section 2, we briefly review the Mumford-Shah model and Chan-Vese (CV) model. Our local Chan-Vese (LCV) model is presented in Section 3. In Section 4, the proposed model is validated by some experiments on synthetic and real images. Finally, some conclusive remarks are included in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Previous works</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Mumford-Shah model</head><p>The Chan-Vese model is the curve evolution implementation of a piecewise-constant case of the Mumford-Shah model <ref type="bibr" target="#b8">[9]</ref>. The Mumford-Shah model is an energy-based method introduced by Mumford and Shah via an energy functional. The basic idea is to find a pair of (u, C) for a given image u 0 , where u is a nearly piecewise smooth approximation of u 0 , and C denotes the smooth and closed segmenting curve. The general form for the Mumford-Shah energy functional can be written as</p><formula xml:id="formula_0">E MS (u, C) = |u 0 (x, y) -u(x, y)| 2 dx dy + \C |∇u(x, y)| 2 dx dy + • Length(C),<label>(1)</label></formula><p>where and are positive constants, denotes the image domain, the segmenting curve C ⊂ . To solve the Mumford-Shah problem is to minimize the energy functional over u and C. Note that the removal of any of the above three terms in (1) will result in trivial solutions for u and C <ref type="bibr" target="#b8">[9]</ref>. However, with all three terms, it becomes a difficult problem to solve since u is a function in the N-dimensional space (N = 2 in 2D image segmentation), while C is an (N-1)-dimensional data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Chan-Vese model</head><p>The Chan-Vese (CV) model is an alternative solution to the Mumford-Shah problem which solves the minimization of (1) by minimizing the following energy functional:</p><formula xml:id="formula_1">E CV (c 1 , c 2 , C) = • Length(C) + 1 • inside(C) |u 0 (x, y) -c 1 | 2 dx dy + 2 • outside(C) |u 0 (x, y) -c 2 | 2 dx dy,<label>( 2 )</label></formula><p>where , 1 and 2 are positive constants, usually fixing 1 = 2 = 1. c 1 and c 2 are the intensity averages of u 0 inside C and outside C, respectively.</p><p>To solve this minimization problem, the level set method <ref type="bibr" target="#b2">[3]</ref> is used which replaces the unknown curve C by the level-set function (x, y), considering that (x, y) &gt; 0 if the point (x, y) is inside C, (x, y) &lt; 0 if (x, y) is outside (x, y), and (x, y) = 0 if (x, y) is on C. Thus, the energy functional E CV (c 1 , c 2 , C) can be reformulated in terms of the level set function (x, y) as follows:</p><formula xml:id="formula_2">E CV (c 1 , c 2 , ) = • ((x, y))|∇(x, y)| dx dy + 1 • |u 0 (x, y) -c 1 | 2 H ((x, y)) dx dy + 2 • |u 0 (x, y) -c 2 | 2 (1 -H ((x, y))) dx dy,<label>(3)</label></formula><p>where H (z) and (z) are, respectively, the regularized approximation of Heaviside function H(z)and Dirac delta function (z) as follows:</p><formula xml:id="formula_3">H(z) = 1 if z Ն 0, 0 if z &lt; 0, (z) = d dz H(z). (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>This minimization problem is solved by taking the Euler-Lagrange equations and updating the level set function (x, y) by the gradient descent method:</p><formula xml:id="formula_5">* *t = () div ∇ |∇| -1 (u 0 -c 1 ) 2 + 2 (u 0 -c 2 ) 2 ,<label>( 5 )</label></formula><p>where c 1 and c 2 can be, respectively, updated at each iteration by</p><formula xml:id="formula_6">c 1 () = u 0 (x, y)H ((x, y)) dx dy H ((x, y)) dx dy , c 2 () = u 0 (x, y)(1 -H ((x, y))) dx dy (1 -H ((x, y))) dx dy . (<label>6</label></formula><formula xml:id="formula_7">)</formula><p>The main advantages of this model are: First, it can deal with the detection of objects whose boundaries are either smooth or not necessarily defined by gradient. In such cases, the edge-based level set methods commonly fail and result in boundary leakage <ref type="bibr" target="#b35">[36]</ref>. Second, it does not require image smoothing and thus can efficiently process the images with noise. Therefore, the true boundaries are preserved and could be accurately detected. Third, it can automatically detect interior contours with the choice of Dirac delta function (z) that has non-compact support.</p><p>However, CV model also has some drawbacks which have been described in Section 1, i.e., the unsuccessful segmentation of images with intensity inhomogeneity (as shown in Fig. <ref type="figure">3(c</ref>)), the sensitivity to the placement of initial contour and the extraordinary time-consumption if re-initialization step is adopted for maintaining stable curve evolution and ensuring more precise results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Local Chan-Vese model</head><p>In this section, we shall present and discuss the details of our proposed local Chan-Vese (LCV) model and its numerical implementation. What should be stressed is that our model is defined based on the techniques of curve evolution, local statistical function and level set methods. It is well-known that some traditional level set methods used either the image gradient <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref> or the global information <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref> to drive the evolving curve(s) towards the true boundaries. However, none of them can achieve success in segmenting images with intensity inhomogeneity. In the proposed model, we combined both global and local statistical information to overcome the inhomogeneous intensity distribution in some images and provided more satisfying segmentation result. Particularly, by incorporating a so-called extended structure tensor(EST) into the proposed LCV model, the texture image can also be segmented no matter whether it presents intensity inhomogeneity or not. The overall energy functional in our proposed LCV model E LCV consists of three parts: global term E G , local term E L and regularization term E R . Thus the overall energy functional can be described as</p><formula xml:id="formula_8">E LCV = • E G + • E L + E R . (<label>7</label></formula><formula xml:id="formula_9">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Global term</head><p>The global term E G is directly derived from (2) in the Chan-Vese model, in which it is also called the fitting term. It can be seen that the global term is defined based on the global properties, i.e., the averages of u 0 inside C and outside C, which is stated as follows:</p><formula xml:id="formula_10">E G (c 1 , c 2 , C) = F 1 (C) + F 2 (C) = inside(C) |u 0 (x, y) -c 1 | 2 dx dy + outside(C) |u 0 (x, y) -c 2 | 2 dx dy, (<label>8</label></formula><formula xml:id="formula_11">)</formula><p>Using the level set formulation, the boundary C is represented by the zero level set of a Lipschitz function : → R.</p><p>(x, y)</p><formula xml:id="formula_12">⎧ ⎪ ⎨ ⎪ ⎩ &gt; 0 if (x, y) is inside C, = 0, (x, y) ∈ C, &lt; 0 if (x, y) is outside C. (<label>9</label></formula><formula xml:id="formula_13">)</formula><p>Accordingly, the global term in ( <ref type="formula" target="#formula_10">8</ref>) can be rewritten so as to evaluate the level set function on the domain :</p><formula xml:id="formula_14">E G (c 1 , c 2 , ) = |u 0 (x, y) -c 1 | 2 H((x, y)) dx dy + |u 0 (x, y) -c 2 | 2 (1 -H((x, y))) dx dy, (<label>10</label></formula><formula xml:id="formula_15">)</formula><p>where H(z) is the Heaviside function described in (4). Usually, after <ref type="bibr" target="#b9">(10)</ref> comes to a steady state, or approximately to be zero, the evolving curve C (zero level set of ) will separate the object from the background. However, for the images with intensity inhomogeneity, the final obtained curve C can hardly divide the image into object region and background region even after a long iteration time. The reason is that the global term assumes that the image intensity is piecewise constant like the CV model. Thus, the averages c 1 and c 2 actually act as the global information and cannot represent the inhomogeneous intensities of object region and background region in the images with intensity inhomogeneity. So, to achieve a good performance in segmenting the images with intensity inhomogeneity, the local image information needs to be included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Local term</head><p>Before introducing the local term, we should firstly discuss the intensity inhomogeneity problem. Intensity inhomogeneity usually arises from the imperfect factors of acquisition process for ordinary images or medical images, such as non-uniform daylight and artificial illumination, static field inhomogeneity, radio-frequency excitation field non-uniformity and inhomogeneity of reception coil sensitivity, etc. These inhomogeneities are known to appear in images as systematic changes in the local statistical characteristics of target object. Although the presence of intensity inhomogeneity is usually hardly noticeable to a human observer, many image processing methods, including image segmentation methods, are highly sensitive to the spurious variations of image intensities since they are based on the assumptions that the intensities in each region are constant.</p><p>The generally accepted assumption on intensity inhomogeneity is that it manifests itself as a smooth spatial varying function over the image <ref type="bibr" target="#b36">[37]</ref>. The most common model in describing the acquired images X with intensity inhomogeneity effect is</p><formula xml:id="formula_16">X = BX + N, (<label>11</label></formula><formula xml:id="formula_17">)</formula><p>where X is the inhomogeneity-free image, B denotes the intensity inhomogeneity field and N is the noise. To simplify the computation, the noise is often ignored. Also, there have been theoretical modeling approaches to approximate the intensity inhomogeneity field. However, due to the complexity that causes the intensity inhomogeneity, it is difficult for ones to model the intensity inhomogeneity under a variety of image acquisition conditions <ref type="bibr" target="#b37">[38]</ref>.</p><p>Since the intensity inhomogeneity is slowly varying in the image domain, its spectrum in frequency domain will be concentrated in the low-frequency area. Thus, the intensity inhomogeneity effect mainly influences the non-contour pixels in the image, whereas for the pixels belonging to contour, this influence is less. Motivated by this observation, we proposed incorporating the local statistical information into the level set method for segmenting the images with intensity inhomogeneity effect. It should be noted that we do not try to eliminate the intensity inhomogeneity from the images which is still not a completely solved problem <ref type="bibr" target="#b37">[38]</ref>.</p><p>Here, the local term is introduced in (12) which uses the local statistical information as the key to improve the segmentation capability of our model on the images with intensity inhomogeneity.</p><formula xml:id="formula_18">E L (d 1 , d 2 , C) = inside(C) |g k * u 0 (x, y) -u 0 (x, y) -d 1 | 2 dx dy + outside(C) |g k * u 0 (x, y) -u 0 (x, y) -d 2 | 2 dx dy, (<label>12</label></formula><formula xml:id="formula_19">)</formula><p>where g k is a averaging convolution operator with k×k size window. d 1 and d 2 are the intensity averages of difference image (g k * u 0 (x, y)u 0 (x, y)) inside C and outside C, respectively.</p><p>The assumption behind the proposed local term is that smaller image regions are more likely to have approximately homogeneous intensity and the intensity of the object is statistically different from the background. It is significative to statistically analyze each pixel with respect to its local neighborhood. The most simple and fast statistical information function is the average of the local intensity distribution, the rationale being that if the object pixels are brighter than the background, they should also be brighter than the average. It should be noticed that the size of the neighborhood has to be properly selected so as to cover sufficient object and background pixels, which may make the local term less sensitive to the existence of noise. However, at a larger neighborhood size, the local term will probably lose some fine detail of images. So, it needs to be combined with the global term in the image segmentation process.</p><p>By subtracting the original image from the averaging convolution image, the contrast between foreground intensities and background intensities can be significantly increased. Note that the difference image (g k * u 0 (x, y)u 0 (x, y)) with higher image contrast is still not easily to be segmented due to the weak object boundaries and complicated topological structure. It needs under a level set evolution for obtaining better segmentation result. Thus, the structure of the fitting term in ( <ref type="formula" target="#formula_10">8</ref>) is adopted, i.e., local fitting term, with the difference image being used instead of original image. It can be obviously seen that the local fitting term keeps decreasing while the curve evolves towards the true boundaries of objects in difference image, and the true boundary C * is the minimizer of the following local fitting term:</p><formula xml:id="formula_20">inf C (F L 1 (C) + F L 2 (C)) ≈ 0 ≈ F L 1 (C * ) + F L 2 (C * ),<label>(13)</label></formula><p>where (F L 1 (C) + F L 2 (C)) denotes the local fitting term. In the same manner as global term, the local term <ref type="bibr" target="#b11">(12)</ref> can also be reformulated in terms of the level set function (x, y) as follows:</p><formula xml:id="formula_21">E L (d 1 , d 2 , ) = |g k * u 0 (x, y) -u 0 (x, y) -d 1 | 2 H((x, y)) dx dy + |g k * u 0 (x, y) -u 0 (x, y) -d 2 | 2 (1 -H((x, y))) dx dy. (<label>14</label></formula><formula xml:id="formula_22">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Regularization term</head><p>In order to control the smoothness of the zero level set and further avoid the occurrence of small, isolated regions in the final segmentation, we add to the regularization term a length penalty term L(C) which is defined related to the length of the evolving curve C. Let C be a smooth closed planar curve C(p) : [0, 1] → parameterized by parameter p ∈ [0, 1]. The length functional can be written as</p><formula xml:id="formula_23">L(C) = C dp. (<label>15</label></formula><formula xml:id="formula_24">)</formula><p>Here, through replacing the curve C by the level set function (x, y), L(C) can be reformulated as</p><formula xml:id="formula_25">L( = 0) = |∇H((x, y))| dx dy = ((x, y))|∇(x, y)| dx dy, (<label>16</label></formula><formula xml:id="formula_26">)</formula><p>where H(z) is Heaviside function and (z) Dirac delta function, which have been described in <ref type="bibr" target="#b3">(4)</ref>. The use of length penalty term implies that the evolving curve C which minimizes the overall energy functional should be as short as possible. It imposes a penalty on the length of the curve that separates the two phases of image, i.e., foreground and background, on which the energy functional will make a transition from one of its values, c1(d1), to the other, c2(d2).</p><p>In many situations, the level set function will develop shocks, very sharp and/or flat shape during the evolution, which in turn makes further computation highly inaccurate in numerical approximations. To avoid these problems, it is necessary to reshape the level set function to a more useful form, while keeping the zero location unchanged. A common numerical scheme is to initialize the function (X, t = 0) as a signed distance function before the evolution, and then re-initialize the function (X, t) to be a signed distance function periodically during the evolution, which can be written as</p><formula xml:id="formula_27">(X, t) = ⎧ ⎪ ⎨ ⎪ ⎩ dist(X, C t ) if X is inside C t , 0, X ∈ C t , -dist(X, C t ) if X is outside C t ,<label>(17)</label></formula><p>where dist(X, C t ) is the shortest Euclidean distance of X to the points on the evolving curve C t at time t.</p><p>It is crucial to keep the evolving level set function as an approximate signed distance function during the evolution, especially in the neighborhood around the zero level set <ref type="bibr" target="#b4">[5]</ref>. The most straightforward way of implementing the re-initialization operation is to extract the zero level set and then explicitly compute the distance function from it. However, this method is generally time-consuming. To overcome this difficulty, a now widely accepted method has been proposed <ref type="bibr" target="#b38">[39]</ref> in order to re-initialize the level set function by solving the following partial difference equation:</p><formula xml:id="formula_28">* *t = sign( 0 )(1 -|∇|), (<label>18</label></formula><formula xml:id="formula_29">)</formula><p>where 0 is the function to be re-initialized, and sign( 0 ) is the sign function. When the steady state of Eq. ( <ref type="formula" target="#formula_28">18</ref>) is reached, will be a distance function with the same zero level set as 0 despite 0 is a distance function or not. This is commonly known as the standard re-initialization procedure. Another equivalent approach is to solve the following eikonal equation:</p><formula xml:id="formula_30">|∇| = 1,<label>(19)</label></formula><p>with the boundary condition = 0 on { 0 = 0}.</p><p>Re-initialization has been extensively used as a numerical remedy for maintaining stable curve evolution and ensuring desirable results in the level set methods. Unfortunately, it is obviously a disagreement between the theory of level set method and its implementation, since it has an undesirable side effect of moving the zero level set away from its original location. Moreover, it is quite complicated and time-consuming, and when and how to apply it is still a serious problem <ref type="bibr" target="#b39">[40]</ref>. Accordingly, some fast techniques <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref> were proposed for finding a solution to these problems. Among these methods, fast marching method <ref type="bibr" target="#b41">[42]</ref> is a representative and popular one. It is the optimal technique for solving the Eikonal equation F|∇| = 1, where F denotes the speed of interface. For more detailed technical description about fast marching method, readers can refer to literature <ref type="bibr" target="#b41">[42]</ref>. Though fast marching method is more efficient than traditional approach, the computational time is still large.</p><p>In this paper, we did not directly use the re-initialization step to keep the level set function as a signed distance function but add to the regularization term a penalty term as follows:</p><formula xml:id="formula_31">P() = 1 2 (|∇(x, y)| -1) 2 dx dy (<label>20</label></formula><formula xml:id="formula_32">)</formula><p>which can force the level set function to be close to a signed distance function.</p><p>Actually, this penalty term is more like a metric which characterizes how close a function is to a signed distance function. The metric plays a key role in the elimination of re-initialization in our method. To explain the effect of the penalty term P(), we give its gradient flow as follows: So, in the proposed model, the regularization term E R should be composed of two terms:</p><formula xml:id="formula_33">∇ 2 -div ∇ |∇| = div 1 - 1 |∇| ∇ . (<label>21</label></formula><formula xml:id="formula_34">E R () = • L( = 0) + P() = • ((x, y))|∇(x, y)| dx dy + 1 2 (|∇(x, y)| -1) 2 dx dy, (<label>22</label></formula><formula xml:id="formula_35">)</formula><p>where is the parameter which can control the penalization effect of length term: if is small, then smaller objects will be detected; if is larger, then larger objects are detected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Level set formulation</head><p>In the level set formulation, the curve C is represented by the zero level set of a Lipschitz function . The overall energy functional in (7) can be further described as follows:</p><formula xml:id="formula_36">E LCV (c 1 , c 2 , d 1 , d 2 , ) = • E G (c 1 , c 2 , ) + • E L (d 1 , d 2 ,</formula><p>)</p><formula xml:id="formula_37">+ E R (d 1 , d 2 , ),<label>(23)</label></formula><p>where and are two positive parameters which govern the tradeoff between the global term and the local term. In fact, and should be set according to the intensity inhomogeneity presenting in the images. For images without intensity inhomogeneity, the value of is suggested to be near or equal to that of . If images present distinct intensity inhomogeneity, the value of should be selected less than that of so as to restrict the intensity inhomogeneity. It should be noticed that the case of = 0 may be acceptable in segmenting some images. However, it is not suggested since the global term can sometimes have a restriction effect on noise and maintain the boundary details. In our experiments, we usually fixed = 1 and then dynamically adjusted the value of according to the intensity property of images.</p><p>In general, the image segmentation process can be equivalently transformed into finding a solution that minimizes the E LCV by evolving level set function . The Heaviside function H(z) and the Dirac Delta function (z) described in (4) are then applied to divide the level set function into three parts, i.e., the part inside C, the part outside C and the part on C. For practical and feasible implementation, H (z) is chosen as a non-compactly supported, smooth and strictly monotone approximation of H(z), which can be written as</p><formula xml:id="formula_38">H (z) = 1 2 1 + 2 arctan z , → 0. (<label>24</label></formula><formula xml:id="formula_39">)</formula><p>The regularized approximation (z) of Dirac delta function (z) is correspondingly computed by</p><formula xml:id="formula_40">(z) = 1 • 2 + z 2 . (<label>25</label></formula><formula xml:id="formula_41">)</formula><p>So, the overall energy functional can then be rewritten as</p><formula xml:id="formula_42">E LCV (c 1 , c 2 , d 1 , d 2 , ) = ( • |u 0 (x, y) -c 1 | 2 + • |g k * u 0 (x, y) -u 0 (x, y) -d 1 | 2 ) × H ((x, y)) dx dy + ( • |u 0 (x, y) -c 2 | 2 + • |g k * u 0 (x, y) -u 0 (x, y) -d 2 | 2 )(1 -H ((x, y))) dx dy + • ((x, y))|∇(x, y)| dx dy+ 1 2 (|∇(x, y)|-1) 2 dx dy ,<label>(26)</label></formula><p>where g k is the averaging convolution operator with k × k size window for local information detection.</p><p>Here, the gradient descent method is used to compute the minimizer of <ref type="bibr" target="#b25">(26)</ref>. For a fixed level set function , we minimize the energy functional in <ref type="bibr" target="#b25">(26)</ref> with respect to two pairs of constants: c1 and c2, d1 and d2. By calculus of variations, it can be shown that the constant functions c1(), c2(), d1() and d2() that minimize</p><formula xml:id="formula_43">E LCV (c 1 , c 2 , d 1 , d 2 ,</formula><p>) for a fixed function are given by c 1 () = u 0 (x, y)H ((x, y)) dx dy H ((x, y)) dx dy , (27a)</p><formula xml:id="formula_44">c 2 () = u 0 (x, y)(1 -H ((x, y))) dx dy (1 -H ((x, y))) dx dy , (<label>27b</label></formula><formula xml:id="formula_45">)</formula><formula xml:id="formula_46">d 1 () = (g k * u 0 (x, y) -u 0 (x, y))H ((x, y)) dx dy H ((x, y)) dx dy , (<label>27c</label></formula><formula xml:id="formula_47">)</formula><formula xml:id="formula_48">d 2 () = (g k * u 0 (x, y) -u 0 (x, y))(1 -H ((x, y))) dx dy (1 -H ((x, y))) dx dy . (<label>27d</label></formula><formula xml:id="formula_49">)</formula><p>Keeping c1, c2, d1 and d2 fixed, and minimizing the overall energy function E LCV in <ref type="bibr" target="#b25">(26)</ref> with respect to , we can deduce the associated Euler-Lagrange equation for . The minimization of ( <ref type="formula" target="#formula_42">26</ref>) can be done by introducing an artificial time variable t Ն 0, and moving in the steepest descent direction to a steady state with the initial condition defined in (28b) and boundary condition defined in (28c):</p><formula xml:id="formula_50">* *t = ()[-( (u 0 -c 1 ) 2 + (g k * u 0 (x, y) -u 0 (x, y) -d 1 ) 2 ) + ( (u 0 -c 2 ) 2 + (g k * u 0 (x, y) -u 0 (x, y) -d 2 ) 2 )] + ()div ∇ ∇ + ∇ 2 -div ∇ ∇ , (<label>28a</label></formula><formula xml:id="formula_51">) (0, x, y) = 0 (x, y) in ,<label>(28b)</label></formula><formula xml:id="formula_52">* * -→ n = 0 on * ,<label>(28c)</label></formula><p>where -→ n denotes the exterior normal to the boundary * .</p><p>In the above partial differential equation, the Neumann boundary condition in (28c) is chosen as the boundary condition. Usually, Neumann boundary condition has many advantages. First, it is easy to implement since there are no values to assign for at the boundary. Second, it implies that the solution of (26) satisfies a maximum principle. Moreover, the gaps of the curve C may appear only when advancing the zero level set which would change its topology, and cannot come from outside of because of the spurious values created by the Neumann boundary condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Termination criterion for curve evolution</head><p>Evolving curve C, or zero level set function, will gradually split according to the topological structure of objects and evolves towards the true boundaries of objects in images. When evolving curves finally arrive at the position of true boundary C * , the curves should stop evolving. Now, a problem of when and how the curves automatically stop evolving or what termination criterion is for curves evolution is arising.</p><p>It can be obviously seen that the global term and local term keep decreasing while the curve evolves towards the true boundaries of objects and the true boundary C * is the minimizer of the global term and local term, which can be written as follows:</p><formula xml:id="formula_53">inf C ( • E G (C) + • E L (C)) ≈ 0 ≈ • E G (C * ) + • E L (C * ). (<label>29</label></formula><formula xml:id="formula_54">)</formula><p>Therefore, we can approximately obtain the energy minimization value by inf</p><formula xml:id="formula_55">c 1 ,c 2 ,d1,d2,C (E LCV (c 1 , c 2 , d 1 , d 2 , C)) ≈ • L(C * ). (<label>30</label></formula><formula xml:id="formula_56">)</formula><p>Actually, (30) can be the termination criterion for curves evolution. But, it cannot be directly implemented in practice because of its approximate equal sign. In our numerical solution, we shall use another form of this termination criterion by determining the length of evolving curve L(C(t)) at each iteration. When curve reaches the true boundary, it is obvious that the variable L(C(t)) will remain almost constant. Here, we shall give the termination criterion for the curve evolution in an image as follows:</p><p>Termination criterion: If the absolute value of the change of the curve length |L(C(t))-L(C(t-1))| remains smaller than a given threshold length over a fixed threshold of iterations T it , the evolution of curves will be stopped.</p><p>The pseudocode of this termination criterion is listed as follows:</p><formula xml:id="formula_57">k = 1; ... ... if |Length(C(t)) -Length(C(t -1))| Յ length then { if k = T it then stop evolution of curve; k = k+1; } else k = 1; end If the condition |L(C(t)) -L(C(t -1)</formula><p>)| Յ length is firstly satisfied at a later stage, it is unnecessary to stop the evolution of curve immediately. Instead, we shall examine whether or not the condition is maintained over a fixed threshold of iterations T it before stopping the evolution of curve. This examination must be performed because the evolution process often slows down temporarily even before true boundary is reached. In practice, the choice of the two thresholds is flexible. Generally, we always set T it = 10 and length = 5.</p><p>Remark 1. Note that the energy functional (26) of proposed model is non-convex and sometimes it may have multiple local minima, these being properties inherited from the Mumford-Shah model. To improve the ability of curve to approach the true boundary, the local information is incorporated into the energy functional. The global term is also employed to restrain the noise and maintain the boundary details. In practice, we do not guarantee that our model can always converge to a global minimizer. Sometimes, a local minimizer may be obtained, but close to a global minimizer. In this case, the energy functional will become stationary and the proposed termination criterion can also be applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Numerical implementation of the model</head><p>The partial differential equation in the continuous domain defined in (28a) can be solved by a finite difference method in numerical scheme. All the spatial partial derivatives are approximated by the central difference and the temporal partial derivatives are approximated by the forward difference.</p><p>Then, (28a) can be discretized using the forward difference as follows:</p><formula xml:id="formula_58">n+1 i,j -n i,j t = L( n i,j ), (<label>31</label></formula><formula xml:id="formula_59">)</formula><p>where t is the time-step and L( n i,j ) is the numerical approximation of the right-hand side in (28a).</p><p>The corresponding curvature = div(∇/|∇|) in the L( n i,j ) can be discretized using a second-order central differencing scheme:</p><formula xml:id="formula_60">= div ∇ |∇| = xx 2 y -2 xy x y + yy 2 x ( 2 x + 2 y ) 3/2 , (<label>32</label></formula><formula xml:id="formula_61">)</formula><p>where x , y , xx , yy and xy are computed as follows:</p><formula xml:id="formula_62">x = 1 2h ( i+1,j -i-1,j ), y = 1 2h ( i,j+1 -i,j-1 ), xx = 1 h 2 ( i+1,j + i-1,j -2 i,j ), yy = 1 h 2 ( i,j+1 + i,j-1 -2 i,j ), xy = 1 h 2 ( i+1,j+1 -i-1,j+1 -i+1,j-1 + i-1,j-1 ), (<label>33</label></formula><formula xml:id="formula_63">)</formula><p>where h is the grid spacing. Eq. ( <ref type="formula" target="#formula_50">28a</ref>) is then implemented as follows:</p><formula xml:id="formula_64">n+1 i,j -n i,j t = ( n i,j ){-( (u i,j -c 1 ( n )) 2 + (g k * u i,j -u i,j -d 1 ( n )) 2 ) + ( (u i,j -c 2 ( n )) 2 + (g k * u i,j -u i,j -d 2 ( n )) 2 )} + [ • ( n i,j ) + ( n i+1,j + n i-1,j + n i,j+1 + n i,j-1 -4 n i,j -)],<label>(34)</label></formula><p>where and are computed according to ( <ref type="formula" target="#formula_40">25</ref>) and (32), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Texture image segmentation</head><p>Usually, the texture image segmentation algorithms include two steps: First, a texture representation is selected and corresponding texture features are extracted from initial images. Second, some objective function can be defined using the texture features, and the segmentation is formulated as an optimization or minimization problem. In this paper, the extended version of classical structure tensor was proposed to act as the texture feature and further incorporated into the LCV model for texture image segmentation.</p><p>For a scalar image I, the classical structure tensor J is obtained by Gaussian smoothing of the tensor product of the image gradient, i.e.:</p><formula xml:id="formula_65">J = K * (∇I∇I T ) = K * I 2 x K * I x I y K * I x I y K * I 2 y , (<label>35</label></formula><formula xml:id="formula_66">)</formula><p>where K is a Gaussian kernel with standard deviation , and subscripts x and y denote the partial derivatives. For vector-valued images, the following expression is employed:</p><formula xml:id="formula_67">J = K * ⎛ ⎝ n i=1 ∇I i ∇I T i ⎞ ⎠ . (<label>36</label></formula><formula xml:id="formula_68">)</formula><p>It can be seen from ( <ref type="formula" target="#formula_65">35</ref>) that the classical structure tensor yields three feature channels for each scale. The matrix representation using the image gradient allows the integration of information from a local neighborhood without considering cancellation effects. Such effects would appear if gradients with opposite orientation were integrated directly <ref type="bibr" target="#b42">[43]</ref>. Moreover, the usage of Gaussian smoothing will cause the classical structure tensor robust to noise and make the orientation estimation at certain pixel to be performed. Comparing the number of features obtained by the classical structure tensor to that of Gabor filters reveals that the degree of freedom for the orientation known from Gabor filters is replaced by the smoothed versions of the image derivatives <ref type="bibr" target="#b29">[30]</ref>. Since the image derivatives hold the whole orientation information, the components of the structure tensor are as powerful for the discrimination of textures as a whole set of Gabor filters with a fixed scale. Due to the mixed matrix component, texture discrimination of classical structure tensor is also fully rotation invariant.</p><p>However, the classical structure tensor has the disadvantage of not using any intensity information (or color information in the case of vector-valued images) at all. When the intensity (color) of texture object is different from that of background in a texture image, the introduction of intensity information will be of benefit to the texture object segmentation. Moreover, if texture images present the distinct intensity inhomogeneity as we discussed in Section 3.2, the segmentation using the classical structure tensor will also fail even if the LCV model with local term is adopted. The reason is due to the fact that the intensity information is missed of which the LCV model is strongly dependent. Therefore, we consider constructing an extended structure tensor (EST) by incorporating the intensity information into the classical structure tensor for texture image segmentation.</p><p>For a scalar image I, the extended structure tensor (EST) J E can be defined as follows:</p><formula xml:id="formula_69">J E = K * (vv T ) = ⎛ ⎝ K * I 2 x K * I x I y K * I x I K * I x I y K * I 2 y K * I y I K * I x I K * I y I K * I 2 ⎞ ⎠ , (<label>37</label></formula><formula xml:id="formula_70">)</formula><p>where v = [I x I y I] T . For vector-valued images, the following expression can be used:</p><formula xml:id="formula_71">J E = K * ⎛ ⎝ N i=1 v i v T i ⎞ ⎠ , (<label>38</label></formula><formula xml:id="formula_72">)</formula><p>where</p><formula xml:id="formula_73">v i = [I i,x I i,y I i ] T .</formula><p>Compared with the classical structure tensor, the EST yields six feature channels for each scale, with three of which containing the intensity information. After the EST is computed, the LCV model can be adopted to address texture image segmentation by replacing the original image u 0 in <ref type="bibr" target="#b27">(28)</ref> with the average of all the channels J E ,i (i = 1, 2 . . . 9) belonging to the EST J E in (37), i.e.:</p><formula xml:id="formula_74">u E = 1 9 9 i=1 J E ,i ,<label>(39)</label></formula><p>where is the standard deviation of Gaussian kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8.">Description of algorithm steps</head><p>Now, we can describe the steps of our LCV model as follows:</p><p>Step 1: Input the original image u 0 . If the image is texture image then compute the corresponding extended structure tensor J E according to <ref type="bibr" target="#b36">(37)</ref> and replace u 0 with u E in (39) (the average of nine channels of the extended structure tensor J E ).</p><p>Step 2: Set the initial curve C I in u 0 . Set the value of time-step t, the grid spacing h and in <ref type="bibr" target="#b33">(34)</ref>. In practice, t = 0.1 and h = = 1. Set the window size k of averaging convolution operator in local term. Set the values of the controlling parameter of global term, , the controlling parameter of local term, , and length controlling parameter, , in regularization term according to the following criterions:</p><p>(a) If images present the intensity homogeneity, then the value of is near or equal to that of . In practice, = = 1; (b) If images present distinct intensity inhomogeneity, then the value of should be less than that of . In practice, = 1; (c) If is small, then smaller objects will be detected; if is larger, then larger objects will be detected. Usually, is formatted by</p><formula xml:id="formula_75">= o * 255 2 , o ∈ [0, 1].</formula><p>Step 3: Evolve level set function according to <ref type="bibr" target="#b27">(28)</ref> and its numerical solution scheme described in <ref type="bibr" target="#b33">(34)</ref>.</p><p>Step 4: Extract the evolving curve C from the zero level set function.</p><p>Step 5: Judge whether the termination criterion described in Section 3.5 is satisfied or not. If yes, the algorithm is stopped; otherwise, go to Step 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results</head><p>In this Section, we shall present the experimental results of our local Chan-Vese (LCV) model on some synthetic and real images. The proposed model was implemented by Matlab 7 on a computer with Intel Core 2 Duo 2.2GHz CPU, 2G RAM, and Windows XP operating system. The processing time referred later in this section starts after choosing the initial contour. We used the same parameters of the time-step t = 0.1, the grid spacing h = 1, = 1 (for H (z) and (z)), the window size of averaging convolution operator k = 15, T it = 10 and length = 5 (to be used in the proposed termination criterion), =2 (the standard deviation of Gaussian kernel in extended structure tensor) for all the experiments in this section. It can be found that we were able to get good segmentation results on a wide range of images with these parameters.</p><p>The couple of controlling parameters of global term and local term , should be set according to the image intensity property as described in Section 3.8. Generally, we fixed = 1 and dynamically adjusted the value of . In our experiments, has two corresponding values: 0.1 and 1 for images with/without intensity inhomogeneity. The length controlling parameter also has a scaling role like . If we have to detect all or as many objects as possible and the objects of any size, then should be small. Otherwise, should be larger. In our experiments, two corresponding values of , 0.01 * 255 2 and 0.1 * 255 2 , are adopted. In conclusion, there are totally two parameters whose values need to be dynamically adjusted in our experiments, i.e., and .</p><p>We firstly considered the simplest case: segmentation of images with the intensity homogeneity. Fig. <ref type="figure" target="#fig_1">1(b)-(d)</ref> show the segmentation process of a noisy synthetic image using the proposed LCV model. The robustness property of our model is due to the usage of global term and length penalty term. It can be seen from Fig. <ref type="figure" target="#fig_1">1(a</ref>) that there are four separated shapes within the original image. To show the high efficiency of our model, the initial contour was placed at the bottom left corner unlike other methods in which the initial contour was usually placed in the center of images or touches the target objects. Afterwards, the initial contour evolves and further splits into several parts according to the topological structure of target shapes, as shown in Fig. <ref type="figure" target="#fig_1">1(c</ref>). Finally, the evolving curves stop on the true boundary of each shape after 40 iterations, as can be seen in Fig. <ref type="figure" target="#fig_1">1(d)</ref>. Since the parameter of evolution termination criterion T it = 10 is predefined before the evolution process, it is obvious that the evolving contour has already arrived at the true boundary at the 30th iteration. It should be noticed that this conclusion is suitable for all experiments using our model in this paper.</p><p>Fig. <ref type="figure" target="#fig_7">2</ref> shows the segmentation process of a real image of DNA channel using the LCV model. The objective is to extract the nuclei which appear much brighter than the background in the DNA channel, as shown in Fig. <ref type="figure" target="#fig_7">2(a)</ref>. Some nuclei are very close to each other, and traditional thresholding methods may fail to segment them. The initial contour was still placed at the bottom left corner, as shown in Fig. <ref type="figure" target="#fig_7">2(b</ref>). After 4 iterations, the evolving curves successfully approach and surround all the nuclei, as shown in Fig. <ref type="figure" target="#fig_7">2(c</ref>). It can be seen from Fig. <ref type="figure" target="#fig_7">2(d</ref>) that the majority of nuclei have been segmented after 10 iterations while two pairs of nuclei are still connected. The evolving curves continue to split and all nuclei are successfully segmented at the 25th iteration (accomplished at the 15th iteration due to T it = 10, as shown in Fig. <ref type="figure" target="#fig_7">2(e)</ref>). Here, is set to 0.01 × 255 2 since the objective is to segment those small nuclei.</p><p>In the next experiments (Figs.    inhomogeneity. Fig. <ref type="figure">3</ref> shows the segmentation results for the wellknown synthetic image using both the CV model and the proposed LCV model. It can be seen from Fig. <ref type="figure">3</ref>(a) that the intensity decreases gradually from the left to the right. The initial contour was placed at the intersectional region of high intensity area and low intensity area, as shown in Fig. <ref type="figure">3(b</ref>). The failing segmentation of this synthetic image using the CV model is illustrated in Fig. <ref type="figure">3(c)</ref>, which shows that the evolving curve of the CV model cannot pass through the intersectional region of high intensity area and low intensity area even after 100 iterations. Fig. <ref type="figure">3(d)</ref> shows the segmentation result of the LCV model where the evolving curve of the LCV model can successfully stop on the boundary of object after 19 iterations. Here, the value of the controlling parameter =0.1 is less than that of =1 to maintain a restriction effect on the intensity inhomogeneity. Fig. <ref type="figure" target="#fig_3">4</ref> shows the segmentation results for three real blood vessel images with the intensity inhomogeneity using both the CV model and the proposed LCV model. To achieve a fair comparison, we added the penalty term described in <ref type="bibr" target="#b19">(20)</ref> into the CV model to avoid the re-initialization step. In addition, the proposed termination criterion has also been applied to the CV model. It can be seen from the third column of Fig. <ref type="figure" target="#fig_3">4</ref> that the CV model failed to segment all three images with the intensity inhomogeneity as we anticipated. The reason is due to the inherent disadvantage of not using the local information. The fourth column of Fig. <ref type="figure" target="#fig_3">4</ref> shows that the proposed LCV model can successfully segment the images in the first column. It should be noticed that the iteration times will be efficiently decreased if the initial contours are placed on certain part of the objects, as shown in Fig. <ref type="figure" target="#fig_4">5</ref>.</p><p>Here, we also used the recent popular local binary fitting (LBF) model <ref type="bibr" target="#b26">[27]</ref> to segment the images in Fig. <ref type="figure" target="#fig_3">4</ref>. As we discussed in Section 1, the LBF model usually needs to perform four convolution operations at each iteration and is sensitive to the selection of governing parameters and the location of initial contour. We tried many times and selected the best governing parameters = 0.001 × 255 2 (the length controlling parameter), sigma = 5/5/3.5 (the standard deviation of Gaussian kernel for three images) and the initial contour for the LBF model. In contrast, the parameters of the LCV model are the same as the ones in Fig. <ref type="figure" target="#fig_3">4</ref>. Fig. <ref type="figure" target="#fig_4">5</ref> illustrates the segmentation results of the LBF model and the proposed LCV model with the same initial contours. Both models have succeeded in the segmentation task. Their iteration numbers and processing time for segmenting images in Fig. <ref type="figure" target="#fig_4">5</ref> are presented in Table <ref type="table" target="#tab_2">1</ref>. It can be seen from Table <ref type="table" target="#tab_2">1</ref> that the iteration number and processing time for the LCV model are both less than that of the LBF model for all three image segmentation. Note that the LCV model only needs to perform one convolution operation before level set evolution. Considering that the parameters and initial contours of the LBF model are selected elaborately, so the LCV model is proved to be more efficient in segmenting the images with the intensity inhomogeneity.</p><p>The next three experiments (Figs. <ref type="figure" target="#fig_5">6</ref><ref type="figure">7</ref><ref type="figure">8</ref>) are focused on illustrating the ability of segmenting texture images of the LCV model combined with the extended structure tensor (EST). Fig. <ref type="figure" target="#fig_5">6</ref>    segmentation process of three kinds of synthetic texture images. The first kind of image contains one texture object (the first row), the second kind of image contains three objects with the same texture (the second row), and the third kind of image contains two objects with different texture (the third row). According to the algorithm steps described in Section 3.8, the average of nine channels of the extended structure tensor (EST) is utilized for level set evolution instead of original image. Since the texture objects are usually located in the center parts of original images, the center parts of the computed averages are always in high-frequency area. Correspondingly, the boundary parts of the computed averages are in low-frequency area. Thus, the boundary parts can be firstly captured by the initial contours at the image corner. The second column shows the intermediate segmentation results for three texture images after one iteration. It can be seen that the small initial contours in the first column have quickly expanded and involve the majority of the images. After 4 or 5 iterations, the evolving curves successfully approach the true boundaries of texture objects, as shown in the third column. It can be seen from the fourth column that all texture objects are successfully segmented. Fig. <ref type="figure">7</ref> shows the segmentation result for a real giraffe image which contains nature texture produced from the upper body of the giraffe. It can be seen from Fig. <ref type="figure">7</ref>(c) that the desired upper body of giraffe was successfully segmented. Fig. <ref type="figure">8</ref> shows the segmentation results for a texture image with the intensity inhomogeneity using the LCV model combined with the classical structure tensor and the EST. First, the classical structure tensor was incorporated into the LCV model to segment this texture image. It can be seen from Fig. <ref type="figure">8(c</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original Image Initial Contour Final Contour, 29 iterations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2</head><p>The performance comparisons of proposed LCV model using the fast marching method and the penalty term in segmenting the images in Figs. <ref type="figure" target="#fig_7">2</ref> and<ref type="figure">3</ref>.  time-consuming. Therefore, the fast marching method <ref type="bibr" target="#b41">[42]</ref> was proposed for finding a solution to these problems. In this paper, we added a penalty term into the regularization term to completely avoid the re-initialization step. To further show the advantage of this penalty term, the fast marching method was also used and compared with our non-re-initialization solution scheme. Accordingly, the penalty term was removed from the energy functional and the fast marching method was adopted to re-initialize level set function to a signed distance function at every iteration. Table <ref type="table">2</ref> shows the performance comparisons of proposed LCV model using the fast marching method and the penalty term in segmenting the images in Figs. <ref type="figure" target="#fig_7">2</ref> and<ref type="figure">3</ref>. Both images were successfully segmented by the LCV model using two solution schemes. It can be seen from Table <ref type="table">2</ref> that the average computational time of fast marching method is greater than that of penalty term. In addition, the iteration number for the LCV model using fast marching method are greatly increased, especially in segmenting the larger image in Fig. <ref type="figure" target="#fig_7">2</ref>. As a result, the total processing time for the LCV model using fast marching method is obviously greater than that for the LCV model using penalty term. It can be concluded that the penalty term is a good substitute for fast marching method while solving the re-initialization problem in the proposed LCV model.</p><p>Here, we also provided more experiments on four different types of real images to further demonstrate the performance of the proposed LCV model. It should be noted that all the initial contours were placed in the background area, as shown in the second column of Fig. <ref type="figure" target="#fig_8">9</ref>. The first row of Fig. <ref type="figure" target="#fig_8">9</ref> shows the segmentation of a wrist X-ray image with obvious intensity inhomogeneity. The true boundary of the wrist is covered by certain blurry light, which will result in wrong segmentation result if only the global information is used. The successful segmentation result using the proposed LCV model is illustrated in the third image of the first row of Fig. <ref type="figure" target="#fig_8">9</ref>. The second row shows the segmentation of a real starfish image with nature texture. Thus, the LCV model combined with the EST was adopted and the successful segmentation result is shown in the third image of the second row of Fig. <ref type="figure" target="#fig_8">9</ref>. The third row shows the segmentation of a real garden image in which segmenting the fire hydrant is our objective. Obviously, the segmentation process will be influenced by the existences of wall, gate and grass if the traditional solutions are used. Although this image does not contain obvious texture, the EST containing intensity information can still be adopted for eliminating the influences of wall, gate and grass. The segmentation result in the third image of the third row shows that the LCV model combined with the EST successfully segmented the fire hydrant while the wall, the gate and the grass were not included. As mentioned above, the LCV model combined with the EST can also segment the texture image with the intensity inhomogeneity, as can be seen from the synthetic texture image segmentation in Fig. <ref type="figure">8</ref>. Next, we shall provide a real case to further validate this conclusion. The fourth row shows the segmentation of a real corpus callosum MR image with intensity inhomogeneity. The target is to segment the blurry corpus callosum region which is surrounded by the dim brain tissues. To eliminate the influences caused by both surrounding brain tissue and the intensity inhomogeneity effect, the EST was incorporated into LCV model for segmentation with the controlling parameters = 0.1 and = 1. It can be seen from the third image of the fourth row that the blurry corpus callosum region was successfully segmented. Remark 2. In general, the Courant-Friedrichs-Levy (CFL) rule will restrict the allowable step size of the partial differential equation (PDE) when the explicit numerical scheme in Section 3.6 is applied. That is, for any given grid spacing h and the velocity F, we require F • t Յ h, where t is the time-step. Thus, the CFL condition places an upper bound on the time-step and hence on the speed of curve evolution. In our experiments, we used the same evolving parameters of the time-step t = 0.1 and the grid spacing h = 1. It seems that the proposed LCV model can sometimes segment the target objects in very few iterations, especially in Figs. <ref type="figure" target="#fig_7">2</ref> and<ref type="figure" target="#fig_5">6</ref>. As we discussed in Section 3.2, the utilization of local term can significantly increase the contrast between foreground intensities and background intensities. Thus, the ability of evolving curve to approach the true boundary has also been greatly improved while compared with  traditional level set methods. Moreover, a larger window size of convolution operator k = 15 was adopted which also implicitly updates the grid spacing in the numerical solutions. As a result, the small initial contour can quickly expand and approach the true boundary even starting from the image corner, as can be seen from Fig. <ref type="figure" target="#fig_7">2(c</ref>).</p><p>For texture image segmentation, the average of nine channels of the extended structure tensor (EST) is utilized for level set evolution instead of original image. Since most texture objects are located in the center part of the original image, the center part of the computed average is in high-frequency area. Correspondingly, the boundary part of the computed average is in low-frequency area which can be firstly captured by the initial contour at the image corner. Hence, the evolving curves will expand to surround the center part of image and quickly approach the true boundaries of texture objects under the dual effect of the EST and the local term. The second to the fourth columns of Fig. <ref type="figure" target="#fig_5">6</ref> properly demonstrate this process. By incorporating the local term and the EST, our solution scheme adds some flexibility to the CFL constraint, which makes the curve evolution maintain stable and converge in fewer iterations while segmenting some ordinary images and texture images. However, it should be emphasized that the CFL rule still takes effect in our numerical scheme. It can be seen from the third and the fourth rows of Fig. <ref type="figure" target="#fig_8">9</ref> that the iteration times for two segmentations are relatively large due to the complicated background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions and future works</head><p>In this paper, we propose a new local Chan-Vese (LCV) model for image segmentation, which is based on the techniques of curve evolution, local statistical function and level set theory. The energy functional for the proposed model consists of global term, local term and regularization term. By incorporating the local image information into our model, the images with intensity inhomogeneity can be efficiently segmented. To avoid the time-consuming re-initialization step, a new penalizing energy is introduced into the regularization term. Moreover, a termination criterion based on the length of the evolving curve is proposed to ensure that the evolving curve can automatically stop on the true boundaries of objects. Particularly, by adding the intensity information into the classical structure tensor, an extended structure tensor (EST) is constructed for texture image segmentation. Combining the EST with the proposed LCV model, the texture image can be efficiently segmented no matter whether it presents intensity inhomogeneity or not. Finally, experiments on some synthetic and real images have demonstrated the desired segmentation performance of our proposed model for the (texture) images with or without intensity inhomogeneity. The comparisons with the CV model and the LBF model also show that the proposed LCV model has a much faster convergence speed and less sensitivity to the location of initial contour and the selection of governing parameters.</p><p>It should be noted that the proposed LCV model is efficient for the two-modal (phase) images, which usually generate two segments, i.e., foreground and background. As a bimodal model, it cannot simultaneously detect multiple objects in different intensities and the triple junctions. In our future work, we will extend the current LCV model by using the multi-layer idea (transformation of single phase to layer) or multiple level set functions. Further extension can be made to obtain a multimodal LCV model, so that multi-modal (phase) images and regions with triple junctions can be segmented.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>)</head><label></label><figDesc>Notice that the above gradient flow has the factor(1-(1/|∇|) which can act as the diffusion rate. If |∇| &gt; 1, the diffusion rate is positive and the effect of the penalty term is the usual diffusion, i.e. making more even and therefore reduce the gradient |∇|. If |∇| &lt; 1, the penalty term has effect of reverse diffusion and therefore increase the gradient. It can be seen that the penalty term continually adjusts the deviation of level set function from the signed distance function in the evolution process. Therefore, it can naturally and automatically force the level set function to be an approximate signed distance function during the evolution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Noisy synthetic image segmentation using the proposed LCV model: (a) original noisy image; (b) initial contour; (c) intermediate segmentation result at the 20th iteration; and (d) final segmentation result at the 40th iteration. Size = 114×112, = = 1, = 0.1 × 255 2 , and processing time = 3.1 s.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Segmentation of a real image of DNA channel using the LCV model: (a) original image; (b) initial contour; (c) intermediate segmentation result at the 4th iteration; (d) intermediate segmentation result at the 10th iteration; (e) intermediate segmentation result at the 15th iteration; and (f) final segmentation result at the 25th iteration. Size = 217×160, = = 1, = 0.01 × 255 2 , and processing time = 5.2 s.</figDesc><graphic coords="9,100.52,291.85,414.06,228.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The comparisons of the CV model and the proposed LCV model on segmenting three real blood vessel images with the intensity inhomogeneity. The first column: original images. The second column: initial contours. The third column: final segmentation results using the CV model. The fourth column: final segmentation results using the proposed LCV model. Size = 150×147, 103×131, 110×110, = 0.1 (LCV), = 1 (LCV), and = 0.01 × 255 2 (CV/LCV).</figDesc><graphic coords="10,92.60,78.85,419.86,332.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The comparisons of the LBF model and the proposed LCV model on segmenting the images in Fig. 4. The first column: initial contours. The second column: final segmentation results using the LBF model. The third column: final segmentation results using the LCV model.</figDesc><graphic coords="11,130.52,81.25,360.07,381.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Segmentation of three synthetic texture images using the LCV model combined with the EST. The first column: initial contours. The second column: intermediate segmentation result. The third column: intermediate segmentation result. The fourth column: final segmentation results. Size = 140×130, 128×128, 128×128, = = 1, and = 0.01 × 255 2 .</figDesc><graphic coords="12,53.12,81.01,498.32,374.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig. 7. Segmentation of a real giraffe image using the LCV model combined with the EST: (a) original image; (b) initial contour; and (c) final segmentation result. Size = 279×205, = = 1, and = 0.01 × 255 2 .</figDesc><graphic coords="12,92.12,538.33,420.18,98.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 2 (</head><label>2</label><figDesc>Fig. 2(a), size = 217×160 Fig. 3(a), size = 88×85 Average computational time (s)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Segmentation of four different types of real images using the LCV model. The first column: original images. The second column: initial contours. The third column: final segmentation results using the proposed LCV model with different schemes. Size = 164×323, 300×294, 255×230, 238×159, = 0.1, = 1 (the first and the fourth row), = = 1 (the second and the third row), and = 0.01 × 255 2 .</figDesc><graphic coords="14,92.12,81.49,420.18,508.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>shows the</figDesc><table><row><cell>Initial Contour</cell><cell>Final Contour, 28 iterations</cell><cell>Final Contour, 27 iterations</cell></row><row><cell>Initial Contour</cell><cell>Final Contour, 50 iterations</cell><cell>Final Contour, 29 iterations</cell></row><row><cell>Initial Contour</cell><cell>Final Contour, 59 iterations</cell><cell>Final Contour, 25 iterations</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Iteration number and processing time for the LBF model and proposed LCV model in segmenting the images in Fig.5.</figDesc><table><row><cell></cell><cell cols="2">The image from the first row</cell><cell cols="2">The image from the second row</cell><cell cols="2">The image from the third row</cell></row><row><cell></cell><cell>Iteration number</cell><cell>Processing time (s)</cell><cell>Iteration number</cell><cell>Processing time (s)</cell><cell>Iteration number</cell><cell>Processing number</cell></row><row><cell>LBF</cell><cell>28</cell><cell>4.9</cell><cell>50</cell><cell>6.8</cell><cell>59</cell><cell>7.6</cell></row><row><cell>LCV</cell><cell>27</cell><cell>2.7</cell><cell>29</cell><cell>2.4</cell><cell>25</cell><cell>2.9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>) that the LCV model</figDesc><table><row><cell>Initial Contour</cell><cell>1 iterations</cell><cell>4 iterations</cell><cell>Final Contour, 15 iterations</cell></row><row><cell>Initial Contour</cell><cell>1 iterations</cell><cell>5 iterations</cell><cell>Final Contour, 19 iterations</cell></row><row><cell>Initial Contour</cell><cell>1 iterations</cell><cell>4 iterations</cell><cell>Final Contour, 17 iterations</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by the grants of the National Science Foundation of China, Nos. 60873012, 60805021, 60705007 &amp; 30700161, the grant from the National Basic Research Program of China (973 Program), No.2007CB311002, the grants from the National High Technology Research and Development Program of China (863 Program), Nos. 2007AA01Z167, the grant of the Guide Project of Innovative Base of Chinese Academy of Sciences (CAS), No.KSCX1-YW-R-30, the grant of the Graduate Students' Scientific Innovative Project Foundation of CAS (X.-F. Wang).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary material</head><p>Supplementary data associated with this article can be found in the online version at doi:10.1016/j.patcog.2009.08.002.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Linda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>George</surname></persName>
		</author>
		<title level="m">Computer Vision</title>
		<meeting><address><addrLine>New Jersey</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Snakes: active contour models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="321" to="331" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fronts propagating with curvature-dependent speed: algorithms based on Hamilton-Jacobi formulations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Sethian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Phys</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="12" to="49" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Compactly supported radial basis functions based collocation method for level-set evolution in image segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Friboulet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Prost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1873" to="1887" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Total variation and level set based methods in image science</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Numer</title>
		<imprint>
			<biblScope unit="page" from="1" to="61" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A geometric model for active contours in image processing</title>
		<author>
			<persName><forename type="first">V</forename><surname>Caselles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Catte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dibos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Math</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Geodesic active contours</title>
		<author>
			<persName><forename type="first">V</forename><surname>Caselles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="79" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Shape modeling with front propagation: a level set approach</title>
		<author>
			<persName><forename type="first">R</forename><surname>Malladi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Sethian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="158" to="175" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Optimal approximation by piecewise smooth functions and associated variational problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Pure Appl. Math</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="577" to="685" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Active contours without edges</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="266" to="277" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Curve evolution implementation of the Mumford-Shah functional for image segmentation, denoising, interpolation, and magnification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yezzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1169" to="1186" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Geodesic active regions and level set methods for supervised texture segmentation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deriche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="223" to="247" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Image segmentation and selective smoothing by using Mumford-Shah model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Bui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1537" to="1549" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A multiphase level set framework for image segmentation using the Mumford and Shah model</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Vese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="271" to="293" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Initialization techniques for segmentation with the Chan-Vese model</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Solem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Overgaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heyden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Pattern Recognition (ICPR&apos;06)</title>
		<meeting>the 18th International Conference on Pattern Recognition (ICPR&apos;06)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="171" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An optimal initialization technique for improving the segmentation performance of Chan-Vese model</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Automation and Logistics</title>
		<meeting>the IEEE International Conference on Automation and Logistics</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="411" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A fast level set method without solving PDES</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Karl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP&apos;05)</title>
		<meeting>the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP&apos;05)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="97" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient implementation of the Chan-Vese models without solving PDEs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Birdwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Djouadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop On Multimedia Signal Processing</title>
		<meeting>the International Workshop On Multimedia Signal Processing</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="350" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Level set formulation without Reinitialization: a new variational formulation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) 2005</title>
		<meeting>the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) 2005</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="430" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A variational formulation for segmenting desired objects in color images</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vision Comput</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1414" to="1421" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Vessel extraction under non-uniform illumination: a level set approach</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="358" to="360" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the statistical interpretation of the piecewise smooth Mumford-Shah functional</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Scale Space Var</title>
		<meeting>Scale Space Var</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4485</biblScope>
			<biblScope unit="page" from="203" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Efficient segmentation of piecewise smooth images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Piovano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rousson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Papadopoulo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Scale Space Var</title>
		<meeting>Scale Space Var</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4485</biblScope>
			<biblScope unit="page" from="709" to="720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Convergence approximation to piecewise smooth medical image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rousson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Med. Imag. Comput. Comp. Assist. Interven</title>
		<imprint>
			<biblScope unit="volume">4792</biblScope>
			<biblScope unit="page" from="495" to="502" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Hybrid geodesic region-based curve evolutions for image segmentation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lankton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yezzi</surname></persName>
		</author>
		<author>
			<persName><surname>Tannenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SPIE: Medical Imagining</title>
		<meeting>the SPIE: Medical Imagining</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">6510</biblScope>
			<biblScope unit="page">65104</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Localizing region-based active contours</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lankton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tannenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2029" to="2039" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Implicit active contours driven by local binary fitting energy</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CVPR&apos;07</title>
		<meeting>the CVPR&apos;07</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Image segmentation using active contours: calculus of variations of shape gradients</title>
		<author>
			<persName><forename type="first">G</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barlaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Faugeras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jehan-Besson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research Report</title>
		<imprint>
			<date type="published" when="2002-07">July 2002</date>
		</imprint>
		<respStmt>
			<orgName>INRIA</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A level-set and gabor-based active contour algorithm for segmenting textured images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sandberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
		<idno>39</idno>
	</analytic>
	<monogr>
		<title level="j">Mathematical Department</title>
		<imprint>
			<date type="published" when="2002-07">July 2002</date>
			<pubPlace>UCLA, Los Angeles, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Active unsupervised texture segmentation on a diffusion based feature space</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rousson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deriche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;03)</title>
		<meeting>the 2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;03)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="699" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimal orientation detection of linear symmetry</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bigun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Grandlund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE First International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE First International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="433" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multidimensional orientation estimation with applications to texture analysis and optical flow</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bigun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Grandlund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wiklund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="775" to="790" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Level-set methods for tensor-valued images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Feddern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Burgeth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second IEEE Workshop on Variational, Geometric and Level Set Methods in Computer Vision</title>
		<meeting>the Second IEEE Workshop on Variational, Geometric and Level Set Methods in Computer Vision</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Tensor field segmentation using region based active contour model</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth European Conference on Computer Vision (ECCV&apos;04)</title>
		<title level="s">Springer Lecture Notes in Computer Science</title>
		<meeting>the Eighth European Conference on Computer Vision (ECCV&apos;04)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3024</biblScope>
			<biblScope unit="page" from="304" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Active contours on statistical manifolds and texture segmentation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Abott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Araman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Image Processing</title>
		<meeting>the IEEE International Conference on Image Processing</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="828" to="831" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Variable background active contour model for computer-aided delineation of nodules in thyroid ultrasound images</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Maroulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Savelonas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Iakovidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Karkanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dimitropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="537" to="543" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A review of methods for correction of intensity inhomogeneity in MRI</title>
		<author>
			<persName><forename type="first">U</forename><surname>Vovk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pernuš</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Likar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="405" to="421" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A review on MR image intensity inhomogeneity correction</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Biomed. Imaging</title>
		<imprint>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An efficient, interface preserving level set redistancing algorithm and its application to interfacial incompressible fluid flow</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sussman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fatemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1165" to="1191" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Reconciling distance functions and level sets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Faugeras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Visual Commun. Imaging Representation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="209" to="222" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A fast level set method for propagating interface</title>
		<author>
			<persName><forename type="first">D</forename><surname>Adalsteinsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Sethian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Phys</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="269" to="277" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Sethian</surname></persName>
		</author>
		<title level="m">Level Set Methods and Fast Marching Methods</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>second ed.</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Nonlinear structure tensors</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Burgeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mrázek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="55" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">About the Author-DE-SHUANG HUANG received the B.Sc., M.Sc. and Ph.D. degrees all in Electronic Engineering from Institute of Electronic Engineering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">September, 2000, he joined the Institute of Intelligent Machines, Chinese Academy of Sciences as the Recipient of</title>
		<title level="s">the M.Sc. degree in Pattern Recognition and Intelligent System from University of Science and Technology of China</title>
		<meeting><address><addrLine>Hefei, China; Hefei, China; Hefei, China; Xian, China; China; Washington DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">1999. 2005. 1986. 1989 and 1993. September 2000 to March 2001. April 2002 to June 2003. August to September 2003. October to December 2003. July to December 2004. 2006. 2009</date>
		</imprint>
		<respStmt>
			<orgName>About the Author-XIAO-FENG WANG received the B.Sc. degree in Computer and Science Technology from Anhui University ; National Defense University of Science and Technology, Changsha, China, and Xidian University ; Beijing Institute of Technology and in National Key Laboratory of Pattern Recognition, Chinese Academy of Sciences Beijing ; Research Fellow in City University of Hong Kong ; George Washington University as visiting professor ; Hong Kong Polytechnic University ; University Fellow in Hong Kong Baptist University. Dr ; Central China Normal University ; Electrical and Computer Engineering Department of Louisiana State University</orgName>
		</respStmt>
	</monogr>
	<note>majored in Computer Software Science and minored in Mathematics. She is now in pursuit for Ph.D. degree in the. Her research interests include image analysis, visual and geometric computing</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
