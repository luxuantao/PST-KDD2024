<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Online Influence Maximization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Siyu</forename><surname>Lei</surname></persName>
							<email>sylei@cs.hku.hk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Hong</orgName>
								<address>
									<addrLine>Kong Pokfulam Road</addrLine>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Silviu</forename><surname>Maniu</surname></persName>
							<email>silviu.maniu@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Noah&apos;s Ark Lab</orgName>
								<address>
									<addrLine>Huawei Science Park</addrLine>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luyi</forename><surname>Mo</surname></persName>
							<email>lymo@cs.hku.hk</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Hong</orgName>
								<address>
									<addrLine>Kong Pokfulam Road</addrLine>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Reynold</forename><surname>Cheng</surname></persName>
							<email>ckcheng@cs.hku.hk</email>
							<affiliation key="aff3">
								<orgName type="institution">University of Hong</orgName>
								<address>
									<addrLine>Kong Pokfulam Road</addrLine>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><surname>Senellart</surname></persName>
							<email>pierre@senellart.com</email>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Télécom ParisTech</orgName>
								<orgName type="institution" key="instit2">CNRS LTCI &amp; NUS</orgName>
								<orgName type="institution" key="instit3">CNRS IPAL</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Online Influence Maximization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2C4DF2ACB9CDE9BA79A12D96BE88557D</idno>
					<idno type="DOI">10.1145/2783258.2783271</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Social networks are commonly used for marketing purposes. For example, free samples of a product can be given to a few influential social network users (or seed nodes), with the hope that they will convince their friends to buy it. One way to formalize this objective is through the problem of influence maximization (or IM), whose goal is to find the best seed nodes to activate under a fixed budget, so that the number of people who get influenced in the end is maximized. Solutions to IM rely on the influence probability that a user influences another one. However, this probability information may be unavailable or incomplete.</p><p>In this paper, we study IM in the absence of complete information on influence probability. We call this problem Online Influence Maximization (OIM), since we learn influence probabilities at the same time we run influence campaigns. To solve OIM, we propose a multiple-trial approach, where (1) some seed nodes are selected based on existing influence information; (2) an influence campaign is started with these seed nodes; and (3) user feedback is used to update influence information. We adopt Explore-Exploit strategies, which can select seed nodes using either the current influence probability estimation (exploit), or the confidence bound on the estimation (explore). Any existing IM algorithm can be used in this framework. We also develop an incremental algorithm that can significantly reduce the overhead of handling user feedback information. Our experiments show that our solution is more effective than traditional IM methods on the partial information.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In recent years, there has been a lot of interest about how social network users can affect or influence others (via the so-called wordof-mouth effect). This phenomenon has been found to be useful for marketing purposes. For example, many companies have advertised their products or brands on social networks by launching influence campaigns, giving free products to a few influential individuals (seed nodes), with the hope that they can promote the products to their friends <ref type="bibr" target="#b19">[20]</ref>. The objective is to identify a set of most influential Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org. KDD'15, August 10-13, 2015, Sydney, NSW, Australia.  people, in order to attain the best marketing effect. This problem of influence maximization (IM) has attracted a lot of research interest <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b22">23]</ref>. Given a promotion budget, the goal of IM is to select the best seed nodes from an influence graph. An influence graph is essentially a graph with influence probabilities among nodes representing social network users. In the independent cascade model, for example, a graph edge e from user a to b with influence probability p implies that a has a chance p to affect the behavior of b (e.g., a convinces b to buy a movie ticket) <ref type="bibr" target="#b15">[16]</ref>. Given an influence graph, IM aims to find k seed nodes, whose expected number of influenced nodes, or influence spread, is maximized. Marketing efforts can then be focused on the k nodes (or persons). In the IM literature, these seed nodes are said to be activated <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>While existing IM algorithms effectively obtain the most influential seed nodes, they assume that the influence probability value between each pair of nodes is known. However, this assumption may not hold. Consider a marketing firm starting in a new city with some knowledge of the social network of the users in the city. The company, however, does not know how influence propagates among these users. Unless the influence probability information is known, the marketing firm cannot run an IM algorithm and decide the target users. To obtain these values, action logs, which record the social network user's past activities, can be used <ref type="bibr" target="#b10">[11]</ref>. This information may not be readily available.</p><p>Is it possible to perform IM on a social network, even if the information about influence probabilities is absent or incomplete? We call this problem Online Influence Maximization (OIM), as we aim at discovering influence probabilities at the same time we are performing influence campaigns. (We say that an IM algorithm is offline, if it assumes that the influence probability between every node pair is known in advance.) In the absence of complete influence probability information, making the best marketing effort out of a limited promotion budget can be challenging. To tackle this problem, we propose a solution based on influencing seed nodes in multiple rounds. In each round, we select some seed nodes to activate (e.g., advertising a product to a few selected users). The feedback of these users is then used to decide the seed nodes to be activated in the next round. The information about influence probabilities in the social network is learnt and refined during these campaigns.</p><p>Figure <ref type="figure" target="#fig_1">1</ref> illustrates our OIM framework. It contains multiple successive influence campaigns, or trials. A trial should fulfill one of two objectives: <ref type="bibr" target="#b0">(1)</ref> to advertise to promising nodes; and <ref type="bibr" target="#b1">(2)</ref> to improve the knowledge about influence probabilities. A trial consists of two phases: selection and action. In the selection phase, an uncertain influence graph is maintained. This graph models the uncertainty of influence probabilities among social network users, in terms of a probability distribution. A seed selection strategy, based on an existing IM solution, is then executed on this graph to produce up to k seed nodes. In the action phase, the selected seed nodes are activated in the real world (e.g., sending the advertisement message to chosen users). The actions of these users, or feedback (e.g., whether the message is further spread), is then used to update the uncertain influence graph. The iteration goes on, until the marketing budget is exhausted. In this paper, we focus on the two crucial components of the selection phase: (1) seed selection strategy; and (2) techniques for updating the uncertain influence graph. 1. Seed selection strategy. To choose seed nodes in a trial, a simple way is to make use of existing IM algorithms. Due to the lack of knowledge about influence probabilities, this approach may not be the best. We thus develop an Explore-Exploit strategy (or EE), which performs IM based on existing influence probability information:</p><p>• [Exploit] Select k seed nodes for getting the most rewarding influence spread from the influence graph, derived from the uncertain influence graph. Any state-of-the-art IM algorithms (e.g., CELF <ref type="bibr" target="#b18">[19]</ref>, DD <ref type="bibr" target="#b6">[7]</ref>, TIM and TIM+ <ref type="bibr" target="#b26">[27]</ref>) can be used; or • [Explore] Select k seed nodes based on some strategy (e.g., through estimating the confidence bound of the influence probability) to improve the knowledge about the influence graph.</p><p>In this paper, we study strategies for exploit and explore. With suitable use of strategies, EE performs better than running an existing IM algorithm on the uncertain influence graph alone.</p><p>In our OIM solution, N trials are carried out. In each trial, an existing IM algorithm may be executed. If N is large, the performance of our algorithm can be affected. The problem is aggravated if the underlying uncertain influence graph is big. For state-of-the-art IM algorithms (e.g., CELF <ref type="bibr" target="#b18">[19]</ref> and TIM+ <ref type="bibr" target="#b26">[27]</ref>), this running time is dominated by the cost of sampling the influence graph. For example, in TIM+, the sampling effort costs more than 99% of the computation time. We design an efficient solution, based on the intuition that users' feedback often only affects a small portion of the influence graph. If samples of the previous iterations are stored, it is possible to reuse them, instead of sampling the influence graph again. We examine conditions allowing a sampled graph to be effectively reused in a new trial. We propose an incremental algorithm, and present related data structures for facilitating efficient evaluation of our solution. This algorithm can support any sample-based IM algorithm running on independent cascade models. We demonstrate how to use TIM+ in this paper. 2. Updating the uncertain influence graph. As discussed before, our seed selection strategy is executed on the uncertain influence graph (Figure <ref type="figure" target="#fig_1">1</ref>). It is important that this graph accurately reflects the current knowledge about the influence among different users, so that the seed selection strategy can make the best decision. We investigate algorithms for updating this graph based on the feedback of activated users (e.g., whether they spread out an advertisement message). We examine two variants, which update the influence graph locally and globally. A local update refreshes the parameters of the influence probability distribution between two graph nodes, while a global update is applied to the parameters of the influence probability information that applies to the whole uncertain influence graph. These algorithms are developed based on classical machine learning methods (e.g, Least Squares Estimation and Maximum Likelihood).</p><p>Our solutions can be adopted by social marketers who aim to promote their products, in cases when the underlying probabilities of the influence graph are unknown. Our approach can utilize any state-of-the-art IM algorithm. We also examine how to update the uncertain influence graph effectively by machine learning methods. We develop an incremental algorithm to improve the efficiency of our solution. Our experiments demonstrate that our proposed methods can effectively and efficiently maximize influence spread.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Influence Maximization (IM). Kempe et al. <ref type="bibr" target="#b15">[16]</ref> first proposed the study of IM in social networks. They showed that finding the set of seed nodes that maximizes influence is NP-hard, and showed that the greedy algorithm has a constant approximation guarantee. However, this solution is not very fast, because thousands of samples are often required, and each sampling operation has a complexity linear to the graph size. To improve the efficiency of IM solutions, several heuristics were developed, namely Degree Discount <ref type="bibr" target="#b6">[7]</ref>, PMIA <ref type="bibr" target="#b5">[6]</ref>, IPA <ref type="bibr" target="#b16">[17]</ref>, and IRIE <ref type="bibr" target="#b14">[15]</ref>. Although these heuristics are fast, their accuracy is not theoretically guaranteed. Improved aproximation algorithms with theoretical guarantees include CELF <ref type="bibr" target="#b18">[19]</ref>, CELF++ <ref type="bibr" target="#b12">[13]</ref>, and NewGreedy <ref type="bibr" target="#b6">[7]</ref>. More recently, Borgs et al. proposed an algorithm based on reverse influence sampling, and showed that it is runtime-optimal with accuracy guarantees <ref type="bibr" target="#b3">[4]</ref>. The scalability of this solution was enhanced by Tang et al., who developed TIM and TIM+ <ref type="bibr" target="#b26">[27]</ref> to further reduce the number of samples needed.</p><p>There are also other works that address different variants of the IM problem: (1) incorporating community <ref type="bibr" target="#b27">[28]</ref> and topic <ref type="bibr" target="#b1">[2]</ref> information in the propagation process; (2) competition of different parties for influence <ref type="bibr" target="#b20">[21]</ref>; and (3) use of other influence propagation models such as linear threshold or credit distribution <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b25">26]</ref>.</p><p>Learning influence probabilities. Saito et al. <ref type="bibr" target="#b24">[25]</ref> modeled the problem of obtaining influence probabilities as an instance of likelihood maximization, and developed an expectation maximization algorithm to solve it. Given a social network and an action log (e.g., user u performs action a at time t), Goyal et al. <ref type="bibr" target="#b10">[11]</ref> developed static and time-dependent models to compute influence probabilities between a pair of social network users. These methods require the action log information of all the users involved to be known in advance; however, this information may not be available. Our framework does not require all action logs to be available. Instead, we select seed nodes in multiple advertising campaigns, so that influence maximization can be done faster. We then use users' feedback in each campaign to learn and refine influence probabilities.</p><p>Multi-armed bandits (MAB). The EE strategy in the seed selection phase of our solution is inspired by the e-greedy algorithm, which was originally developed to solve the multi-armed bandit problem (MAB) <ref type="bibr" target="#b23">[24]</ref>. In the e-greedy algorithm <ref type="bibr" target="#b21">[22]</ref>, e controls the trade-off between exploitation and exploration. Specifically, with probability 1 -e, an action is executed based on the current knowledge (i.e., exploit); with probability e, another action is performed (i.e., explore). This framework is adopted as a baseline in our solution. real world activation feedback in trial n (h i j , m i j ) number of successful and unsuccessful activations of the edge from i to j <ref type="bibr" target="#b7">[8]</ref> studies combinatorial MAB algorithms, and in particular the CUCB algorithm, which uses upper confidence bounds <ref type="bibr" target="#b2">[3]</ref> for choosing between explore and exploit. A scenario akin to the OIM problem is illustrated and it is shown that CUCB achieves a bound on the regret. However, CUCB is not applicable due to two factors. First, the activated nodes are counted multiple times leading to redundant activations and choices. Second, and most practically important, the approximation bound depends on an initialization step in which each arm (in this scenario, seed node) is tested to get an activation feedback; this is not practically feasible in cases when activation budgets are limited. Another algorithm closely related to our framework is Thompson Sampling <ref type="bibr" target="#b0">[1]</ref>, where each independent arm is simulated by a Beta distribution of successes and failures. In our scenario, the arms are the parameters of the algorithms, and defining success and failure from the result of an influence maximization step is not trivial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">INFLUENCE MAXIMIZATION: REVIEW</head><p>We now provide a review of the IM problem and its solutions. This forms the basis of the OIM problem to be studied in this paper. Table <ref type="table" target="#tab_0">1</ref> shows the notation used.</p><p>Let G = (V, E, p) be an influence graph, where v 2 V are users or nodes, and e 2 E are the links or edges between them. Each edge e = (i, j) between users i and j is associated with an influence probability p i j 2 [0, 1]. This value represents the probability that user j is activated by user i at time t + 1, given that user i is activated at time t. We also suppose that time flows in discrete, equal steps. In the IM literature, p i j is given for every i and j. Obtaining p i j requires the use of action logs <ref type="bibr" target="#b10">[11]</ref> which may not be available. In this paper, we investigate how to perform IM without knowing p i j in advance.</p><p>In the independent cascade model, at a given timestamp t, every node is in either active (influenced) or inactive state, and the state of each node can be changed from inactive to active, but not vice-versa. When a node i becomes active in step t, the influence is independently propagated at t + 1 from node i to its currently inactive neighbors with probability p i j . Node i is given one chance to activate its inactive neighbor. The process terminates when no more activations are possible. A node can be independently activated by any of its (active) incoming neighbors. Suppose that the activation process started from a set S of nodes. We call the expected number of activated nodes of S the expected influence spread, denoted s (S). Formally: DEFINITION 1. Given a weighted graph G = (V, E, p), let infl be the immediate influence operator, which is the random process that extends a set of nodes X ✓ V into a set of immediately influenced nodes infl(X), as follows:</p><formula xml:id="formula_0">Pr(v 2 infl(X)) = 8 &lt; : 1 if v 2 X; 1 ' (u,v)2E u2X (1 p uv ) otherwise.</formula><p>Given a seed set S ✓ V , we define the set of influenced nodes I(S) ✓ V as the random variable that is the fixpoint I • (S) of the following inflationary random process: 8 &gt; &gt; &lt; &gt; &gt; :</p><formula xml:id="formula_1">I 0 (S) = / 0; I 1 (S) = S; I n+2 (S) = I n+1 (S) [ infl(I n+1 (S)\I n (S)) for n &gt; 0. The influence spread s (S) is E[|I(S)|].</formula><p>Based on the above definition, <ref type="bibr" target="#b15">[16]</ref> defines the influence maximization problem (IM) as follows.</p><p>PROBLEM 1. Given a weighted graph G = (V, E, p) and a number</p><formula xml:id="formula_2">1 6 k 6 |V |, the influence maximization (IM) problem finds a set S ✓ V such that s (S) is maximal subject to |S| = k.</formula><p>As discussed in <ref type="bibr" target="#b15">[16]</ref>, evaluating the influence spread is difficult. Even when the spread values are known, obtaining an exact solution for the IM problem is computationally intractable. Next we outline the existing IM algorithms for this problem.</p><p>IM algorithms. A typical IM algorithm evaluates the score of a node based on some metric, and inserts the k best nodes, which have the highest scores, into S. For example, the degree discount (DD) heuristic <ref type="bibr" target="#b6">[7]</ref> selects the nodes with highest degree as S. Another classical example is greedy: at each step, the next best node, or the one that provides the largest marginal increase for s , is inserted into S. This is repeated until |S| = k. The greedy algorithm provides an (1 1/e)-approximate solution for the IM problem. To compute the influence spread efficiently, sampling-based algorithms with theoretical guarantees were developed. For example, CELF <ref type="bibr" target="#b18">[19]</ref> evaluates the expected spread of nodes with the seed nodes, and select the nodes with the largest marginal spread; TIM <ref type="bibr" target="#b26">[27]</ref> counts the frequencies of the nodes appearing in the reversed reachable sets, and chooses the nodes with the highest frequencies; TIM+ <ref type="bibr" target="#b26">[27]</ref> is an extension of TIM for large influence graphs.</p><p>We say that the above IM algorithms are offline, since they are executed on the influence graph once, assuming knowledge of p i j for every i and j. If these values are not known, these algorithms cannot be executed. This problem can be addressed by online IM algorithms, as we will discuss next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">MAXIMIZING INFLUENCE ONLINE</head><p>The goal of the online influence maximization (or OIM) is to perform IM without knowing influence probabilities in advance. Given a number N of advertising campaigns (or trials), and an advertising budget of k units per trial, we would like to select up to k seed nodes in each trial. These chosen nodes are then advertised or activated, and their feedback is used to decide the seed nodes in the next trial. Let us formulate the OIM problem below. PROBLEM 2. Given a weighted graph G = (V, E, p) with unknown probabilities p uv , and a budget consisting of N trials with 1 6 k 6 |V | activated nodes per trial, the online influence maximization (OIM) problem is to find for each 1 6 n 6 N a set S n of nodes, with</p><formula xml:id="formula_3">|S n | 6 k, such that E ⇥ S 16n6N I(S n ) ⇤ is maximal.</formula><p>Note that the IM problem, discussed in Section 3, is a special case of the OIM problem (by setting N = 1). Since solving the IM problem is computationally difficult, finding a solution for the OIM is also challenging. We propose a solution that consists of multiple trials. In each trial, a selection (for choosing appropriate seed nodes) and an action (for activating the seed nodes chosen) is performed (Figure <ref type="figure" target="#fig_1">1</ref>). The seed selection makes use of one of the offline IM algorithms discussed in Section 3. 1  We next present the uncertain influence graph, which captures the uncertainty of influence probabilities (Section 4.1). We then discuss our solution based on this graph in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Uncertain Influence Graph</head><p>We assume that a social network, which describes the relationships among social network users, is given. However, the exact influence probability on each edge is not known. We model this by using the uncertain influence graph, in which the influence probabilities of each edges are captured by probability density functions, or pdf (Figure <ref type="figure" target="#fig_1">1</ref>). The pdf can be refined based on the feedback returned from a trial. Since influence activations are binary random variable, we capture the uncertainty over the influence as a Beta distribution. Specifically, the random variable of the influence probability from node i to node j, P i j is modeled as a Beta distribution having probability density function:</p><formula xml:id="formula_4">f P i j (x) = x a i j 1 (1 x) b i j 1 B(a i j , b i j ) ,</formula><p>where B(a i j , b i j ) is the Beta function, acting as a normalization constant to ensure that the total probability mass is 1, and a i j and b i j are the distribution parameters. For the Beta distribution,</p><formula xml:id="formula_5">E[P i j ] = a i j a i j +b i j and s 2 [P i j ] = a i j b i j (a i j +b i j ) 2 (a i j +b i j +1</formula><p>) . An advantage of using the Beta distribution is that it is a conjugate prior for Bernoulli distributions, or more generally, binomial distributions. This allows us to compute the posterior distributions easily when new evidence is provided. Section 6 explains this in more detail.</p><p>At the time of the first trial, we assume no prior information about the influence graph, except global a and b parameters, shared by all edges, i.e., P i j ⇠ B(a, b ) 8(i, j) 2 E. These global a and b parameters represent our global prior belief of the uncertain influence graph. In the absence of any better prior, we can set a = b = 1, with B(1, 1) being the uniform distribution.</p><p>Our model can be extended to handle various prior information about the influence graph. For example, if we have individual prior knowledge (a i j , b i j ) about an edge, we can set P i j as P i j ⇠ B(a i j , b i j ). When we have access to only the mean and variance of the influence of an edge, we can derive a i j and b i j from the formulas of E[P i j ] and s 2 [P i j ] given above. For the situation in which some action logs involving the social network users are available, algorithms for learning the influence probabilities from these logs <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> can be first applied, and the estimated influence probabilities can then be used as prior knowledge for the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The OIM Framework</head><p>Algorithm 1 depicts the solution framework of the OIM problem. In this algorithm, N trials are executed. Each trial involves selecting seed nodes, activating them, and consolidating feedback from them. In each trial n (where n = 1,...,N), the following operations are performed on the uncertain influence graph G:</p><p>1. Choose (Line 5): A seed set S n is chosen from G, by using an offline IM algorithm, and strategies for handling the uncertainty of G (Section 5). 1 In this paper we assume that the advertising budget k is fixed for each trial. S n Choose(G, k) 6:</p><formula xml:id="formula_6">(A n , F n ) RealWorld(S n ) 7: A A [ A n 8: Update(G, F n ) 9: return {S n |n = 1 ...N}, A 2.</formula><p>RealWorld (Lines 6-7): The selected seeds set is tested in the real world (e.g., sending advertisement messages to selected users in the social network). The feedback information from these users is then obtained. This is a tuple (A n , F n ) comprised of: (i) the set of activated nodes A n , and (ii) the set of edge activation attempts F n , which is a list of edges having either a successful or an unsuccessful activation. 3. Update (Line 8): We refresh G based on (A n , F n ) (Section 6). One could also choose not to update G, and instead only run an offline IM based on the prior knowledge. Our experimental results show that the influence spread under our OIM framework with proper updates is better than the one without any update. Next, we investigate the design and implementation of Choose (Section 5) and Update (Section 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CHOOSING SEEDS</head><p>We now study two approaches for selecting k seed nodes in the Choose function of Algorithm 1: heuristic-based (Section 5.1) and explore-exploit strategies (Section 5.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Heuristic-Based Strategies</head><p>We first discuss two simple ways for choosing seeds from the uncertain influence graph G.</p><p>1. Random. This heuristic, which arbitrarily selects k seed nodes, is based on the fairness principle, where every user has the same chance to be activated.</p><p>2. MaxDegree. Given a node p in G, we define the out-degree of p to be the number of outgoing edges of p with non-zero influence probabilities. The out-degree of p can mean the number of friends of the social network user represented by p, or their number of followers. Intuitively, if p has a higher out-degree, it has a higher chance of influencing other users. The MaxDegree heuristic simply chooses the nodes with k highest out-degree values.</p><p>The main advantage of these two heuristics is that they are easy to implement. However, they do not make use of influence probability information effectively. In a social network, some users might be more influential than others. It may thus be better to target users with higher influence probabilities on their outgoing edges. The above heuristics also do not consider the feedback information received from the activated users, which can be useful to obtain the true values of the influence probabilities. We will examine a better seed-selection method next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Explore-Exploit Strategies</head><p>The Explore-Exploit (EE) strategy chooses seed nodes based on influence probabilities. Its main idea is to exploit, or execute an offline IM algorithm, based on the influence information currently available. Since this information may be uncertain, the seed nodes suggested by exploit may not be the best ones. We alleviate this problem by using explore operations, in order to improve the knowledge about influence probabilities. Solutions for effectively controlling explore and exploit operations have been studied in the multi-armed bandit (MAB) literature <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b23">24]</ref>. These MAB solutions inspire our development of the two seed-selection strategies, namely e-greedy and Confidence-Bound (CB). Next, we present these two solutions in detail.</p><p>1. e-greedy. In this strategy (Algorithm 2), a parameter e is used to control when to explore and when to exploit. Specifically, with probability 1 e, exploitation is carried out; otherwise, exploration is performed.</p><p>Algorithm 2 e-greedy(G, k)</p><formula xml:id="formula_7">1: Input: uncertain influence graph G = (V, E, P), budget k 2: Output: seed nodes S with |S| = k 3: sample z from Bernoulli(e) 4: if z = 0 then S Explore(G, k) 5: else S Exploit(G, k) 6: return S</formula><p>In Exploit, we execute an offline IM algorithm, given the graph information we have obtained so far. Recall that we model the influence probability p i j between nodes i and j as a probability distribution P i j . We use the mean of P i j to represent p i j , i.e., p i j = E[P i j ] = a i j a i j +b i j . A graph with the same node structure but with the p i j values on edges constitutes an influence graph G 0 , on which the offline IM algorithm is executed. Notice that when e = 0, the solution reduces to exploit-only, i.e., the IM algorithm is run on G 0 only.</p><p>The main problem of Exploit is that estimating p i j by E[P i j ] can be erroneous. For example, when P i j is a highly uncertain Beta distribution (e.g., the uniform distribution, B(1, 1)), any value in [0, 1] can be the real influence probability. Let us consider a node i that has, in reality, a high influence probability p i j on another node j. Due to the large variance in P j , its value is underestimated. This reduces the chance that Exploit chooses node i to activate; consequently, the seed nodes selected may not be the best. The Explore routine is designed to alleviate this problem. Rather than equating p i j to E[P i j ], p i j is over-estimated by using P i j 's standard deviation, or s i j , p i j = E[P i j ] + s i j .</p><p>Then an offline IM algorithm on these new values of p i j is performed. A node i that has a small chance to be chosen may now have a higher probability to be selected. Our experiments show that the use of Explore is especially useful during the first few trials of the OIM solution, since the influence probability values during that time may not be very accurate. From the feedback of activated users, we can learn more about the influence probabilities of the edges of i. We will discuss this in detail in Section 6.</p><p>This e-greedy algorithm has two problems. First, it is difficult to set an appropriate e, which may have a large impact on its effectiveness. Second, increasing p i j by s i j may not always be good. Based on these observations, we next propose an improved version of e-greedy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Confidence-Bound (CB).</head><p>The main idea of this strategy is to use a real-valued parameter q to control the value of p i j : p i j = E[P i j ] + q s i j .</p><p>(5.1)</p><p>As shown in Algorithm 3, for every edge e from node i to j, we compute its mean µ i j , variance s i j , and influence probability p i j based on q (Lines 3-6). An offline IM algorithm is then run on G 0 , the influence graph with the probabilities computed by Equation <ref type="formula">5</ref>.1 (Lines 7-8). The set S of seed nodes is then returned (Line 9).</p><p>Algorithm 3 CB(G, k)</p><p>1: Input: uncertain influence graph G = (V, E, P), budget k 2: Output: seed nodes S with |S| = k 3: for e 2 E do 4: µ i j a i j a i j +b i j</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>s i j 1 (a i j +b i j ) • r a i j b i j (a i j +b i j +1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>p i j µ i j + q s i j </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Update in the n th trial</head><p>Figure <ref type="figure">2</ref>: Updating the influence graph and q with user feedback.</p><p>Setting q . The key issue of Algorithm 3 is how to determine the value of q , so that the best S can be found. Observe that when q = 0, p i j becomes µ i j or E[P i j ], and CB reduces to Exploit of the e-greedy algorithm. On the other hand, when q = 1, p i j becomes E[P i j ] + s i j , and CB is essentially Explore. Thus, e-greedy is a special case of CB. However, CB does not restrict the value of q to zero or one. Thus, CB is more flexible and general than e-greedy.</p><p>In general, when q &gt; 0 is used, it means that CB considers the influence probabilities given by µ i j 's to be under-estimated, and it attempts to improve the activation effect by using larger values of p i j . On the contrary, if q &lt; 0, the influence probabilities are considered to be over-estimated, and CB reduces their values accordingly. As we will discuss in Section 6.3, q can be automatically adjusted based on the feedback returned by activated users. This is better than e-greedy, where the value of e is hard to set. Note that we choose to use a global q instead of a local one on each edge, to reduce the number of parameters to be optimized and to improve efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">MANAGING USER FEEDBACK</head><p>Recall from Algorithm 1 that after the seed nodes S are obtained from Choose (Line 5), they are activated in the real world. We then collect feedback from the users represented by these nodes (Lines 6-7). The feedback describes which users are influenced, and whether each activation is successful. For instances of such feedback traces, take for example Twitter and other micro-bloggin platforms. In these, the system can track actions such as likes and retweets which are reasonable indicators of influence propagation. We now explain how to use the feedback information to perform Update (Line 8), which refreshes the values of influence probabilities and q used in the CB algorithm.</p><p>Given a trial n in Algorithm 1, let A n be the set of activated nodes in that trial, and F n be the set of activation results. Specifically, F n contains tuples in the form of (i, j, a i j ), where i and j are users between which an activation was attempted; a i j = 1 if the influence was successful, and a i j = 0 otherwise. Note that (i, j) is an edge of the influence graph G. Also, F n might not contain all edges of G, since an activation might not reach every user in G.</p><p>Three kinds of updates can be performed based on A n and F n : 1. Local (Section 6.1): Update the influence probability's distribution (i.e., B(a i j , b i j )) if the edge (i.e., activation from i to j) was attempted; 2. Global (Section 6.2): Update the global prior information a and b , which are shared by all edges of G; and 3. q (Section 6.3): Update the value of q used in CB, if it is used as a seed selection strategy in Choose.</p><p>Figure <ref type="figure">2</ref> illustrates these three kinds of updates in the n-th trial. In the next sections, we discuss how to conduct these updates in detail. We remark that these update methods do not affect Random and MaxDegree, since they do not use these updated values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Updating Local ã and b</head><p>As we mentioned before, the influence probability between any two adjacent nodes i and j is modeled as a Beta distribution with parameters a i j and b i j , denoted as P i j ⇠ B(a i j , b i j ). Since the Beta distribution is a conjugate prior for the Bernoulli distribution, then, given feedback (i, j, a i j ) in F n (seen as a Bernoulli trial), we can update the distribution as follows:</p><p>1. If a i j = 1, i.e., the activation from node i to node j was successful: P i j ⇠ B(a i j + 1, b i j );</p><p>2. If a i j = 0, i.e., the activation from node i to node j failed: P i j ⇠ B(a i j , b i j + 1).</p><p>In the beginning, we have no prior information about the distribution except the global a and b , i.e., a i j = a and b i j = b . After n trials and activations, we have thus collected n pieces of feedback information. Let h i j (m i j ) be the number of successful (failed) activations for edge (i, j). Then a i j = a + h i j , b i j = b + m i j . Hence, this local update is equivalent to maintaining a distribution B(a + h i j , b + m i j ), i.e., the distributions on the edges simply count the number of successful and failed activations passing through that edge, smoothed by the prior B(a, b ).</p><p>Note that this update process corresponds exactly to the MLE approach taken by <ref type="bibr" target="#b10">[11]</ref> to learn influence probabilities from action logs, with a smoothing prior added. The important difference is that <ref type="bibr" target="#b10">[11]</ref> only conducts this estimation for edges where there is evidence, i.e., local updates. If the evidence is sparse, this can lead to a sub-optimal, and overfitting, influence graph. Global update of Beta priors, which go beyond the local feedback, can yield a better influence graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Updating Global ã and b</head><p>Local updates to the random variable P i j allows the edge influence probability distribution to be updated directly. In the first few trials, however, the real influence spread is sparse and limited, and most of the edges will not be reached by an activation. Therefore, the influence of choosing a good prior will weigh heavily on how Choose performs. Once some evidence is gathered, this prior can be refined by taking into account the feedback in a global sense, over all trials up to the current one. Next, we present two methods of updating the global a and b priors based on the feedback.</p><p>Least Squares Estimation. The first solution is to find the best fit for the a and b priors according to the real spread that we obtained from the real world test at each trial.</p><p>Let us first explain the reasoning when there is one seed node (i.e., |S n | = 1), and we fix a = 1. Let A n be the set of successful activated nodes before the n-th trial (i.e., A n = [ n 1 l=1 A l ), and s n ({i}) be the expected number of additional activated nodes (or expected additional spread) from the seed node i in the n-th trial. For S n = {s}, s n ({s}) is:</p><formula xml:id="formula_8">s n ({s}) = 1 + Â (s,i)2E i6 2An p si ⇥ s n ({i}) + Â (s,i)2E i2An p si ⇥ (s n ({i}) 1),</formula><p>which is the sum of the outgoing spreads weighted by the outgoing probabilities p si and discounted by 1 for nodes already activated along an outgoing edge. We estimate s n ({s}) by |A n | from the feedback obtained by the influence campaign. We also estimate p si = a+h si a+h si +b +m si , i.e., the mean of B(a i j , b i j ). Note that h si + m si is the total number of attempts from node s to i, which is the same for neighbors of s because every activation through s tries to activate all outgoing nodes in the independent cascade model. Thus, we use t s to denote h si + m si 8(s, i) 2 E. By further estimating s n ({i}) by an overall estimation ŝn and set a = 1, we obtain</p><formula xml:id="formula_9">|A n | = 1 + 1 b + t s + 1 Â (s,i)2E (h si + 1) ŝn Â (s,i)2E,i2A n (h si + 1) ! .</formula><p>Let o s be the outgoing degree of s, a s be the number of (previously) activated neighbors of s (i.e., a s = |{i|(s, i) 2 E ^i 2 A n }|), h s be the number of total successful activations (or hits) on outgoing edges of s, and h as be the number of total hits on edges leading to activated neighbors. The above equation is simplified to</p><formula xml:id="formula_10">(|A n | 1)b = (1 |A n |)(t s + 1) + (h s + o s ) ŝn (h as + a s ).</formula><p>We then rewrite it as the form of x n b = y n . Since this equation also applies to activations in all trials up to the current one, we use the least square estimator for linear regression without an intercept term to get an estimator for b , b = (x •ỹ) / (x •x), where x and ỹ are the vectors of values x n and y n . The same principles apply when estimating a and b simultaneously, and we omit the details here.</p><p>We estimate ŝn by the average spread of the node from the activation campaigns, i.e., ŝn = Â n l=1 |A n |/ Â n l=1 |S n |. Note that, when ŝn = 0, the equation for |A n | is exactly the degree discount estimator from the IM literature <ref type="bibr" target="#b6">[7]</ref>, and represents a lower bound on the spread from a node.</p><p>A further complication occurs when |S n | &gt; 1, which might result in an equation at least quadratic in b , due to the influence probability equations of nodes which are neighbors of more than one seed node. In this work, we simplify the estimation by assuming full independence among seed nodes, and hence replacing x n and y n by the sum over all s 2 S n .</p><p>We remark that the estimator above suffers from the reliance on the spread estimation ŝn . However, it is a good option when we cannot access the full activation feedback F n , but instead, do have the access to the set of successful activated nodes in each trial (i.e., the set A n ). This may happen in an alternate problem setting when one cannot get all the feedback information from the activated users in A n .</p><p>Maximum Likelihood Estimation. Given the feedback from trial n, we can compute the likelihood of the feedback F n given the probabilities of each edge in the feedback tuples, by assuming that they are independently activated. The likelihood depends on the successful activations (hits) and failed activations (misses) of each edges and the global prior parameters a and b :</p><formula xml:id="formula_11">L(F n ) = ' (i, j,a i j )2F n p a i j i j (1 p i j ) 1 a i j , L(F n | a, b ) = ' (i, j,a i j )2F n (a + h i j ) a i j (b + m i j ) 1 a i j a + b + h i j + m i j .</formula><p>We need to find the parameters a and b for maximizing the likelihood:</p><formula xml:id="formula_12">arg max a,b L(F n | a, b ).</formula><p>To simplify calculations, we use the usual method of taking the maximum of the log likelihood, and arrive at the optimal values by solving the equations</p><formula xml:id="formula_13">∂ log L(F n |a,b ) ∂ a = 0 and ∂ log L(F n |a,b ) ∂ b</formula><p>= 0 for a and b , respectively. This becomes:</p><formula xml:id="formula_14">Â (i, j,a i j )2F n ,a i j =1 1 a + h i j = Â (i, j,a i j )2F n ,a i j =0 1 b + m i j .</formula><p>This equation can be solved numerically by setting a and solving b . In practice, we can fix a = 1, and solve b by binary search. The full details can be found in our technical report <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Updating q</head><p>We now explain how to dynamically update the value of q used in the CB strategy (Section 5.2).</p><p>Let q = {q 1 , q 2 ,...,q q } be the q possible values of q . We also let j = {j 1 , j 2 ,...,j q }, where j j is the probability of using q j in CB. Initially, j j = 1/q for j = 1,...,q, and its value is updated based on the gain obtained in each trial. The gain is defined as</p><formula xml:id="formula_15">G n = |A n |/|V |,</formula><p>where |A n | is the real influence spread observed in each round. We then determine q by using the exponentiated gradient algorithm <ref type="bibr" target="#b4">[5]</ref>. The rationale of using this solution is that if the value of q j used in this trial results in a high gain, the corresponding j j will be increased by the algorithm, making q j more likely to be chosen in the next trial. Algorithm 4 gives the details.</p><p>Algorithm 4 ExponentiatedGradient(j, d , G n , j, w) 1: Input: j, probability distribution; d , accuracy parameter; G n , the gain obtained; j, the index of latest used q j ; w, a vector of weights; N, the number of trials. 2: Output: q 3: g q ln(q/d ) qN , t 4qg 3+g , l t 2q 4: for i = 1 to q do 5:</p><formula xml:id="formula_16">w i w i ⇥ exp ⇣ l ⇥ G n ⇥I[i= j]+g j i ⌘ 6: for i = 1 to q do 7: j i (1 t) ⇥ w i Â k j=1 w j + t ⇥ 1 q</formula><p>8: return sample from q according to j distribution Here, g and l are smoothing factors used to update weights, and I[z] is the indicator function. We compute j by normalizing vector w with regularization factor t. All the values in w are initialized with the value of 1.</p><p>In <ref type="bibr" target="#b4">[5]</ref>, it is shown that, for a choice of constant q 's, Exponenti-atedGradient can provide a regret bound on the optimal sequence of chosen q in the vector. In our case, the experimental results also show that ExponentiatedGradient is the best performing strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">INCREMENTAL SOLUTION FOR OIM</head><p>In our OIM solution, an offline IM algorithm is invoked once in every trial to select seeds. However, the state-of-the-art IM algorithms with good theoretical approximation bounds, such as CELF, TIM, and TIM+, are generally costly to run, especially for large graphs with high influence probabilities. For instance, in our experiments in DBLP, which has around two million edges, the best IM algorithm, TIM+, takes 30 minutes to select the nodes for a trial. Since an OIM solution requires multiple trials, the running time can be very high in practice. In this section, we study how to improve the scalability of the OIM solution. We use TIM+ as an example, but our approach can generally be used to handle other IM algorithms (e.g., CELF) that perform sampling on influence graphs.</p><p>Let us first explain the intuition behind our approach. We observe that the running time of TIM+ is dominated by the cost of sampling the influence graph. In our experiments, over 99% of its computation is spent in generating samples (which are random reverse reachable sets, or RR sets in short). Given a node v, the RR is the set of all nodes that can influence v. Another observation is that the size of the real-world feedback F n is relatively small compared with the number of edges in influence graph G. In DBLP, when k is set to 1 for each trial, the average size of F n is less than 1% of the total number of edges of G. Since samples are generated from G, and the user feedback only influences a small part of G, it can only affect a few samples obtained from the updated G in the next trial. Based on these observations, we develop a new method to save the sampling effort, based on reusing samples of previous trials. We call this the incremental algorithm of OIM.</p><p>Here we give an outline of this approach; the details can be found in <ref type="bibr" target="#b17">[18]</ref>. The algorithm stores the samples generated during the TIM+ computation in previous trials in a data structure. In a new trial, when TIM+ requires a new sample, instead of immediately sampling G, we first randomly select a stored sample from the data structure, and check whether this sample can be reused. If this is the case, the selected sample will be returned; otherwise, a new sample will be generated according to the current G and stored in the data structure. Next, we discuss how to determine whether a sample can be reused.</p><p>Intuitively, if G remains the same (or only deviates little), the occurrence probability of a sample is only slightly affected. Hence, reusing a randomly selected sample will not incur much error. Recall that in our OIM framework, only the update component might affect the estimation of the influence graph. Therefore, we only need to check whether the updates affect G or the samples significantly, in order to determine whether a sample can be reused. Suppose s is the sample to be checked. In TIM+, s is a random RR set. We design three checks corresponding to three updates in Section 6. <ref type="bibr">[1.</ref> Local check] If all edges that point to a node in s are not affected by local updates, local check is passed. [2. Global check] If the prior of generating s (denoted by a t , b t ) is close to the current prior, global check is passed. The check is controlled by a threshold t, i.e., the condition is | a t a t +b t a a+b | &lt; t. [3. q check] If q and the standard deviation of the global prior when generating s (denoted by q t , s t ) is similar to the current values, q check is passed, i.e., |q t s t q s| &lt; t.</p><p>We remark that with our checking mechanism, conducting checks on a sample is about d times faster than sampling a new one, where d is the average in-degree for a node. As shown by our experiments, this incremental approach can significantly save the computation effort of our OIM solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">EXPERIMENTAL EVALUATION</head><p>Setup. We developed a "real-world simulator" to mimic the user feedback process of Figure <ref type="figure" target="#fig_1">1</ref>. This simulator first uses a real social network to obtain a graph G. It then associates an influence probability to each edge in G, where p i j = 1/d j , with d j the in-degree of node j. This setting of influence probability values is adopted in previous works <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b26">27]</ref>.  When the chosen seed nodes are tested on whether they can influence other nodes, the simulator runs a single independent cascade simulation on G, and obtains feedback information F n , in a form of (i, j, a i j ) and A n , the set of successfully activated nodes. We measure the effectiveness of an OIM solution by its influence spread in the real world, after N trials, as the total number of successfully activated nodes in these trials, i.e, | [ N n=1 A n |. We repeat each solution 10 times and report the average.</p><p>Datasets. We have studied several real social network datasets. We have used NETHEPT and NETPHY are collaboration networks, obtained from arXiv.org in the High Energy Physics Theory and Physics domains, respectively. We have also used the DBLP graph, which is an academic collaboration network. In these datasets, nodes represent authors, and edges representing co-authorship. These datasets are commonly used in the literature of influence maximization <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b26">27]</ref>. Table <ref type="table" target="#tab_2">2</ref> shows the details of these datasets.</p><p>Options for OIM algorithm. We have evaluated several possible options for the seed selection and graph update components for our OIM solution:</p><p>[Choosing seeds] In our experiments, we compare the algorithms using combinations of the above two components. Note that Random and MaxDegree do not rely on the influence probability of the edges, and they are not combined with update methods. When a particular EE strategy is adopted, the update method would be specified, for instance, CB+MLE means that we use CB with MLE update. By default, we use MLE for updating the graph. Furthermore, if the EE strategy is used in choosing seeds, we use CB by default.</p><p>When an IM algorithm is invoked in an EE strategy, we use TIM+ since it is the state-of-art influence maximization algorithm. We also compare the incremental approach with the non-incremental one for EE strategy. For example, we denote the incremental version for CB as CB-INC.</p><p>Parameters. By default, the global prior is set to be B <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b18">19)</ref>, q = { 1, 0, 1} in CB, e = 0.1 in e-greedy, and t = 0.02 in the incremental approach.</p><p>Our algorithms, implemented in C++, are conducted on a Linux machine with a 3.40 GHz Octo-Core Intel(R) processor and 16GB of memory. Next, we focus on NETPHY, and evaluate different combinations of the algorithms in our OIM framework. We summarize our results for other datasets in Section 8.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Results on NetPHY</head><p>Heuristic-based v.s. Explore-Exploit. We first fix the total budget and verify how the OIM algorithms perform with different number of trials. We set Budget = 50, and vary k in {1, 5, 10, 25, 50}. By varying k, we essentially vary the total budget. For example, with k = 5, 50 units of budget is invested over N = 10 trials. Figure <ref type="figure" target="#fig_3">3a</ref> shows our results. Since Random only has influence spread less than 200 on average, we do not plot it. We observe that the spread of MaxDegree does not change much since it does not depend on the real-world feedback. For CB, its spread increases when k decreases and it is better than MaxDegree when k 6 10 (or N 5). Specifically, when k = 1, CB is about 35% better than MaxDegree. The reason is that, for CB, a smaller k indicates more chances to get real-world feedback, and thus, more chances to learn the real influence graph, which leads to a better result. Moreover, when k = 50, all budget is invested once, which can be regarded as an offline solution, and produces the worst result for CB. This further indicates the effectiveness of our OIM framework. For CB-INC, it performs close to CB with only a small discount (around 5% for different k) on the spread. It supports our claim that the incremental approach can perform without incurring much error.</p><p>We next fix k and compare different algorithms in Figure <ref type="figure" target="#fig_3">3b</ref>. The results are consistent with our previous findings that CB outperforms other variants. CB-INC produces similar results with CB. We observe that the gap between CB and MaxDegree increases with N and k. For example, at N = 50, CB is about 20% better than MaxDegree when k = 5, and the percentage grows to 45% when k = 25. The reason is that larger k and larger N give more chances for CB to learn the real influence graph. We also plot the result for TIM+ when the real influence probability is known, denoted as Real. This can be seen as an oracle, serving as a reference for other algorithms. We find that CB performs close to Real, and its discount on the spread decreases with N. For example, when k = 5, the discount decreases from 30% at N = 10 to 13% at N = 50. This indicates that, with more real-world feedback, the learned graph for CB is closer to the real graph, and thus, leads to a closer result to Real. Explore-Exploit Strategies. We compare three versions of the EE strategies for different k in Figure <ref type="figure">4</ref>. We observe that Exploit is the worst, since it may suffer from the wrong prediction of the influence probabilities and does not explore other potential high influencing nodes. CB is the best, especially, for small k. When k = 5, N = 50, CB is about 20% and 32% better than e-greedy and Exploit, respectively. The reason is that for a smaller k, fewer feedback tuples are returned in one trial, which makes the learned influence graph converge to the real graph slower. Hence, the effect of exploration is strengthened, which is more favorable to CB. We have also conducted experiments for e-greedy by varying e. We observe that its performance is sensitive to e and e = 0.1 is the best one in our results, but it is still worse than CB in all cases.</p><p>Updating the uncertain influence graph. In Figure <ref type="figure" target="#fig_4">5a</ref>, we compare different updating methods for the uncertain influence graph. Although NO makes use of the prior knowledge about the influence graph to select seeds, it still performs worse than other update options. LOC is slightly better, but still worse than MLE and LSE, since it does not employ any global update and it suffers from the sparseness of the activations. MLE is the best (about 25% better than LSE and 40% better than LOC), which is consistent with the fact that MLE makes use of the full feedback to update the graph while LSE only utilizes the set of successfully activated nodes.</p><p>We also test the updating methods with different priors (Figure <ref type="figure" target="#fig_4">5b</ref>) to check whether they are sensitive to the prior. We observe that while LOC and NO fluctuate a lot with different priors, MLE and LSE's performance is very stable. In fact, during different runs of MLE and LSE with different priors, the global b values all converge to around 27. This supports the fact that the global updating techniques are Even an inexact choice of prior will be generally fixed, minimizing the impact on performance.</p><p>Efficiency. In Figure <ref type="figure" target="#fig_5">6a</ref>, we illustrate the cumulative running time for running N trials for different algorithms. Random and MaxDegree are most efficient as they do not rely on any influence evaluation. With the help of incremental approach, CB-INC runs significantly faster than CB, and for the case where N &gt; 10, it achieves about 10 times speedup. For instance, at N = 50, CB-INC reduces the running time by 88%, compared to CB. This is intuitive, as in the first few trials the graph is more uncertain, and the updates affect the samples a lot. However, when N &gt; 10, we observe that the global priors become more stable, leading to a high ratio of re-using samples (e.g., the ratio is about 80% to 99% when N &gt; 10). Moreover, the average in-degree of NETPHY is 12.46, making the time of generating a new sample about an order of magnitude slower than re-using a sample. These two factors together make CB-INC have a much more efficient performance than CB.</p><p>We then show the efficiency results by fixing Budget = 50 and varying k in Figure <ref type="figure" target="#fig_5">6b</ref>. The running time of MaxDegree and Random is stable for various k, while CB and CB-INC show a decline on efficiency when k decreases. This is because a smaller k indicates that more trials are required to invest all budget, and so, TIM+ should be executed more often, for a general decrease in efficiency. Another observation is that the improvement of CB-INC over CB increases with k. This further strengthens the utility of using CB-INC in practice. Figure <ref type="figure" target="#fig_5">6b</ref> and Figure <ref type="figure" target="#fig_3">3a</ref> together show a tradeoff of setting k: a smaller k leads to a better performance in spread but worse performance in efficiency. We suggest to set a small k to ensure the algorithm's better performance in spread. The value of k will depend on how much total time that the user can afford.</p><p>Effect of t. We also verify the effect of t in the incremental approach by varying t from 0.01 to 0.03 and fixing k = 1, Budget = 50. We compare them with CB, the non-incremental algorithm. First, a smaller t gives better results in terms of influence spread. For instance, it leads to 3%, 5%, 15% discount in spread compared with CB for t = 0.01, 0.02, 0.03, respectively. However, a smaller t leads to a slowdown in efficiency since it has a stricter requirement in global check. For example, the running time for t = 0.01 is about 28% slower than the one for t = 0.02 and 38% worse than the one for t = 0.03.</p><p>Discussion. The OIM framework is highly effective in maximizing influence when the real influence probabilities are unknown. In this framework, MLE is the best updating method. Moreover, CB and CB-INC consistently outperform other algorithms. By using CB-INC, we can also significantly improve the efficiency of CB, with only a small discount in influence spread.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">CONCLUSIONS</head><p>In this paper, we examine how to perform influence maximization when influence probabilities may not be known in advance. We develop a new solution, where IM is performed in multiple trials, and we have proposed explore-exploit strategies for this problem. We showed experimentally that explore-exploit based on the uncertainty in the graph performs well. We also proposed novel methods to update the knowledge of the graph based on the feedback received from the real world, and showed experimentally that they are effective in longer campaigns. Even when the influence probabilities are not known in advance, the influence spread of our solution is close to the spread using the real influence graph, especially when the number of trials increases.</p><p>In the future, we will examine the scenario where budgets are different in each trial. We will extend our solution to handle other complex situations (e.g., the change of influence probability values over time), consider IM methods (e.g., <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b1">[2]</ref>) that utilize community and topic information, and other influence propagation models, such as linear threshold or credit distribution <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b25">26]</ref>. Another direction is to increase the scalability of our methods; this may require distributed algorithm, such as distributed sampling.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>c 2015 ACM. ISBN 978-1-4503-3664-2/15/08 ...$15.00. DOI: http://dx.doi.org/10.1145/2783258.2783271.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The OIM framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1 1 : 4 :</head><label>114</label><figDesc>Framework(G, k, N) Input: # trials N, budget k, uncertain influence graph G 2: Output: seed nodes S n (n = 1 ...N), activation results A 3: A / 0 for n = 1 to N do 5:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Heuristic-based v.s. Explore-Exploit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 4: Explore-exploit strategies</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Cumulative running time</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 7: Effectiveness on other datasets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 and</head><label>7</label><figDesc>Figure 7 and Figure 8 show representative results for NETHEPT and DBLP. These results are consistent with the ones for NETPHY, where CB and CB-INC are close to the oracle (Real), and better than heuristic-based algorithms in maximizing influence spread. For efficiency, CB-INC significantly reduces the running time of CB, especially for a large dataset DBLP. For instance, at k = 1, N = 50, CB-INC saves 16 hours compared with CB which costs 19 hours in total to get the result for DBLP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Symbols used in this paper.</figDesc><table><row><cell>symbol</cell><cell>description</cell></row><row><cell>G V E p i j P i j N k S s (S) (a, b ) A n F n</cell><cell>influence graph set of users (nodes) of G set of edges of G influence probability from i to j (fixed value) influence probability from i to j (random variable) number of trials budget for each trial set of seed nodes expected influence spread global prior for the beta distribution set of successfully activated nodes in trial n</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">: Datasets</cell><cell></cell></row><row><cell>Dataset</cell><cell cols="3">NETHEPT NETPHY DBLP</cell></row><row><cell># of Nodes</cell><cell>15K</cell><cell>37K</cell><cell>655K</cell></row><row><cell># of Edges</cell><cell>59K</cell><cell>231K</cell><cell>2.1M</cell></row><row><cell>avg. degree</cell><cell>7.73</cell><cell>12.46</cell><cell>6.1</cell></row><row><cell>max. degree</cell><cell>341</cell><cell>286</cell><cell>588</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. Siyu Lei, Silviu Maniu, Luyi Mo, and Reynold Cheng were supported by University of Hong Kong (201311159095 and 201411159171). We thank the reviewers for their comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Analysis of thompson sampling for the multi-armed bandit problem</title>
		<author>
			<persName><forename type="first">S</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLT</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Online topic-aware influence maximization queries</title>
		<author>
			<persName><forename type="first">C</forename><surname>Aslay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bonchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Baeza-Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using confidence bounds for exploitation-exploration trade-offs</title>
		<author>
			<persName><forename type="first">P</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="397" to="422" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Maximizing social influence in nearly optimal time</title>
		<author>
			<persName><forename type="first">C</forename><surname>Borgs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bratbar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lucier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SODA</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lugosi</surname></persName>
		</author>
		<title level="m">Prediction, Learning, and Games</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Scalable influence maximization for prevalent viral marketing in large-scale social networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Efficient influence maximization in social networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Combinatorial multi-armed bandit: General framework and applications</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Scalable influence maximization in social networks under the linear threshold model</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mining the network value of customers</title>
		<author>
			<persName><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning influence probabilities in social networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bonchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Lakshmanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A data-based approach to social influence maximization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bonchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Lakshmanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Celf++: Optimizing the greedy algorithm for influence maximization in social networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Lakshmanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Exploring social influence via posterior effect of word-of-mouth recommendations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-Q</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Irie: Scalable and robust influence maximization in social networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Maximizing the spread of influence through a social network</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kempe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tardos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scalable and parallelizable processing of influence maximization for large-scale social networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Online influence maximization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maniu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Senellart</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1056.01188</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>extended version</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cost-effective outbreak detection in networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanbriesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Glance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On brands and word of mouth</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Lovett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shachar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Research</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bonchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Lakshmanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The bang for the buck: Fair competitive viral marketing from the host perspective</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Reinforcement Learning: An Introduction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mining knowledge-sharing sites for viral marketing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Some aspects of the sequential design of experiments</title>
		<author>
			<persName><forename type="first">H</forename><surname>Robbins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bull. Amer. Math. Soc</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Prediction of information diffusion probabilities for independent cascade model</title>
		<author>
			<persName><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kimura</surname></persName>
		</author>
		<editor>KES</editor>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">How to win friends and influence people, truthfully: influence maximization mechanisms for social networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Influence maximization: Near-optimal time complexity meets practical efficiency</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Community-based greedy algorithm for mining top-k influential nodes in mobile social networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
