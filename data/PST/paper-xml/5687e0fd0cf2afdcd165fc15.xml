<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Survey and Evaluation of FPGA High-Level Synthesis Tools</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Razvan</forename><surname>Nane</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vlad-Mihai</forename><forename type="middle">M</forename><surname>Sima</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Christian</forename><surname>Pilato</surname></persName>
						</author>
						<author>
							<persName><forename type="first">F</forename><surname>Ferrandi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">J</forename><surname>Choi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">B</forename><surname>Fort</surname></persName>
						</author>
						<author>
							<persName><forename type="first">A</forename><surname>Canis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">H</forename><surname>Hsiao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">S</forename><surname>Brown</surname></persName>
						</author>
						<author>
							<persName><forename type="first">J</forename><surname>Anderson</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Delft University of Technol</orgName>
								<address>
									<country>The Netherlands. C</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Pilato was with Politecnico di Milano</orgName>
								<address>
									<settlement>Italy</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Columbia University</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Politecnico di Milano</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">are with University of Toronto</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Survey and Evaluation of FPGA High-Level Synthesis Tools</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">33E6C2C0DA145DE6C2B00A24F2E8C231</idno>
					<idno type="DOI">10.1109/TCAD.2015.2513673</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCAD.2015.2513673, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>High-Level Synthesis</term>
					<term>Survey</term>
					<term>Evaluation</term>
					<term>Comparison</term>
					<term>FPGA</term>
					<term>DWARV</term>
					<term>LegUp</term>
					<term>Bambu</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>High-level synthesis (HLS) is increasingly popular for the design of high-performance and energy-efficient heterogeneous systems, shortening time-to-market and addressing today's system complexity. HLS allows designers to work at a higher-level of abstraction by using a software program to specify the hardware functionality. Additionally, HLS is particularly interesting for designing FPGA circuits, where hardware implementations can be easily refined and replaced in the target device. Recent years have seen much activity in the HLS research community, with a plethora of HLS tool offerings, from both industry and academia. All these tools may have different input languages, perform different internal optimizations, and produce results of different quality, even for the very same input description. Hence, it is challenging to compare their performance and understand which is the best for the hardware to be implemented. We present a comprehensive analysis of recent HLS tools, as well as overview the areas of active interest in the HLS research community. We also present a first-published methodology to evaluate different HLS tools. We use our methodology to compare one commercial and three academic tools on a common set of C benchmarks, aiming at performing an in-depth evaluation in terms of performance and use of resources.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Clock frequency scaling in processors stalled in the middle of the last decade, and in recent years, an alternative approach for high-throughput and energy-efficient processing is based on heterogeneity, where designers integrate software processors and application-specific customized hardware for acceleration, each tailored towards specific tasks <ref type="bibr">[1]</ref>. Although specialized hardware has the potential to provide huge acceleration at a fraction of a processor's energy, the main drawback is related to its design. On one hand, describing these components in a hardware description language (HDL) (e.g. VHDL or Verilog) allows the designer to adopt existing tools for RTL and logic synthesis into the target technology. On the other hand, this requires the designer to specify functionality at a low level of abstraction, where cycle-by-cycle behavior is completely specified. The use of such languages requires advanced hardware expertise, besides being cumbersome to develop in. This leads to longer development times that can critically impact the time-to-market.</p><p>An interesting solution to realize such heterogeneity and, at the same time, address the time-to-market problem is the combination of reconfigurable hardware architectures, such as field-programmable gate arrays (FPGAs) and high-level synthesis (HLS) tools <ref type="bibr" target="#b3">[2]</ref>. FPGAs are integrated circuits that can be configured by the end user to implement digital circuits. Most FPGAs are also reconfigurable, allowing a relatively quick refinement and optimization of a hardware design with no additional manufacturing costs. The designer can modify the HDL description of the components and then use an FPGA vendor toolchain for the synthesis of the bitstream to configure the FPGA. HLS tools start from a high-level software programmable language (HLL) (e.g. C, C++, SystemC) to automatically produce a circuit specification in HDL that performs the same function. HLS offers benefits to software engineers, enabling them to reap some of the speed and energy benefits of hardware, without actually having to build up hardware expertise. HLS also offers benefits to hardware engineers, by allowing them to design systems faster at a highlevel abstraction and rapidly explore the design space. This is crucial in the design of complex systems <ref type="bibr" target="#b4">[3]</ref> and especially suitable for FPGA design where many alternative implementations can be easily generated, deployed onto the target device, and compared. Recent developments in the FPGA industry, such as Microsoft's application of FPGAs in Bing search acceleration <ref type="bibr" target="#b5">[4]</ref>, and the forthcoming acquisition of Altera by Intel, further underscore the need for using FPGAs as computing platforms with high-level software-amenable design methodologies. HLS has also been recently applied to a variety of applications (e.g. medical imaging, convolutional neural networks, machine learning), with significant benefits in terms of performance and energy consumption <ref type="bibr" target="#b6">[5]</ref>.</p><p>Although HLS tools seem to efficiently mitigate the problem of creating the hardware description, automatically generating hardware from software is not easy and a wide range of different approaches have been developed. One approach is to adapt the high-level language to a specific application domain (e.g. dataflow languages for describing streaming applications). These HLS tools can leverage dedicated optimizations or micro-architectural solutions for the specific domain. However, the algorithm designer, who is usually a software engineer, has to understand how to properly update the code. This approach is usually time consuming and error prone. For this reason, some HLS tools offer complete support for a standard high-level language, such as C, giving complete freedom to the algorithm designer. Understanding the current HLS research directions, the different HLS tools available and their capabilities is a difficult challenge, and a thoughtful analysis is lacking in the literature to cover all these aspects. For example, <ref type="bibr" target="#b7">[6]</ref> was a small survey of existing HLS tools with a static comparison (on criteria such as the documentation available or the learning curve) of their features and user experience. However, the tools have not been applied to benchmarks, nor were the results produced by the tools compared. Indeed, given an application to be implemented as a hardware accelerator, it is crucial to understand which HLS tool better fits the characteristics of the algorithm. For this reason, we believe that it is important to have a comprehensive survey of recent HLS tools, research directions, as well as a systematic method to evaluate different tools on the same benchmarks in order to analyze the results.</p><p>In this paper, we present a thorough analysis of HLS tools, current HLS research thrusts, as well as a detailed way to evaluate different state-of-the-art tools (both academic and commercial) on performance and resource usage. The three academic tools considered are DWARV <ref type="bibr" target="#b8">[7]</ref>, BAMBU <ref type="bibr" target="#b9">[8]</ref> and LEGUP <ref type="bibr" target="#b10">[9]</ref> -tools under active development in three institutions and whose developers are co-authoring this paper. The contributions of this work are:</p><p>• A thorough evaluation of past and present HLS tools (Section II). • A description of HLS optimizations and problems wherein active research is underway (Section III). • The first-published comprehensive in-depth evaluation (Section IV) and discussion (Section V) of selected commercial and academic HLS tools in terms of performance and area metrics. This analysis shows that industry and academia are closely progressing together towards efficient methods to automatically design application-specific customized hardware accelerators. However, several research challenges remain open.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. OVERVIEW OF HIGH-LEVEL SYNTHESIS TOOLS</head><p>In this section, we present an overview of academic and commercial HLS tools. The presentation will be done according to a classification of the design input language as shown in Fig. <ref type="figure">1</ref>. We distinguish between two major categories, namely tools that accept domain-specific languages (DSLs) and tools that are based on general-purpose programmable languages (GPLs). DSLs are split into new languages invented specially for a particular tool-flow and GPL-based dialects, which are languages based on a GPL (e.g. C) extended with specific constructs to convey specific hardware information to the tool. Under each category, the corresponding tools are listed in green, red or blue fonts, where green represents the tool being in use, red implies the tool is abandoned and blue implies N/A, meaning that no information is currently known about its status. Furthermore, the bullet type, defined in the figure's legend, denotes the target application domain for which the tool can be used. Finally, tool names which are underlined in the figure mean that the tool also supports SystemC as input. Using DSLs or SystemC raises challenges for adoption of HLS by software developers. In this section, due to space limitations, we describe only the unique features of each tool. For general information (e.g. target application domain, support for floating/fixed-point arithmetic, automatic testbench generation), the reader is referred to Table <ref type="table">I</ref>. We first introduce the academic HLS tools evaluated in this study, before moving onto highlight features of other HLS tools available in the community (either commercial or academic).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Academic HLS Tools Evaluated in This Study</head><p>DWARV <ref type="bibr" target="#b8">[7]</ref> is an academic HLS compiler developed at Delft University of Technology. The tool is based on the CoSy commercial compiler infrastructure <ref type="bibr" target="#b11">[10]</ref> developed by ACE. The characteristics of DWARV are directly related to the advantages of using CoSy, which are its modular and robust back-end, and that is easily extensible with new optimizations.</p><p>BAMBU <ref type="bibr" target="#b9">[8]</ref> is an academic HLS tool developed at Politecnico di Milano and first released in 2012. BAMBU is able to generate different pareto-optimal implementations to trade-off latency and resource requirements, and to support hardware/software partitioning for designing complex heterogeneous platforms. Its modular organization allows the evaluation of new algorithms, architectures, or synthesis methods. BAMBU leverages the GCC compiler's many compiler-based optimizations and implements a novel memory architecture to efficiently support complex constructs of the C language (e.g., function calls, pointers, multi-dimensional arrays, structs) <ref type="bibr" target="#b12">[11]</ref>. It is also able to support different data types, including floating-point arithmetic, in order to generate optimized microarchitectures.</p><p>LEGUP <ref type="bibr" target="#b10">[9]</ref> is a research compiler developed at the University of Toronto, first released in 2011 and currently on its forth public release. It accepts a C-language program as input and operates in one of two ways: 1) it synthesizes the entire C program to hardware, or 2) it synthesizes the program to a hybrid system comprising a processor (a MIPS soft processor or ARM) and one or more hardware accelerators. In the latter flow, the user designates which C functions to implement as accelerators. Communication between the MIPS/ARM and accelerators is through Altera's memory-mapped on-chip bus interface (LEGUP is designed specifically to target a variety of Altera FPGA families). For hardware synthesis, most of the C language is supported, with the exception of dynamic memory allocation and recursion. LEGUP is built within the open-source LLVM compiler framework <ref type="bibr" target="#b13">[12]</ref>. Compared to other HLS tools, LEGUP has several unique features. registers on some paths permitted more than a single cycle to complete, generating constraints for the back-end of the toolflow accordingly.</p><p>B. Other HLS Tools CyberWorkBench (CWB) <ref type="bibr" target="#b14">[13]</ref> is a set of synthesis, verification and simulation tools intended for system-level design. The tool input is the Behavioral Description Language (BDL), i.e. a superset of the C language extended with constructs to express hardware concepts. Examples of such constructs are user-defined bitwidth for variables, synchronization, explicit clock boundaries specification, and concurrency.</p><p>Bluespec Compiler (BSC) [14] is a tool that uses Bluespec System Verilog (BSV) as the design language. BSV is a high-level functional HDL based on Verilog and inspired by Haskell, where modules are implemented as a set of rules using Verilog syntax. The rules are called Guarded Atomic Actions and express behaviour in the form of concurrently cooperating FSMs <ref type="bibr" target="#b15">[15]</ref>. Using this language, and implicitly the BSC tool, requires developers with specific expertise.</p><p>PipeRench <ref type="bibr" target="#b16">[16]</ref> was an early reconfigurable computing project. The PipeRench compiler was intended solely for generating reconfigurable pipelines in stream-based media applications. The source language is a dataflow intermediate language, which is a single-assignment language with C operators. The output of the tool is a bitstream to configure the reconfigurable pipeline in the target circuit.</p><p>HercuLeS <ref type="bibr" target="#b17">[17]</ref> is a compiler that uses an NAC (N-address code) IR (intermediate representation), which is a new typedassembly language created by a front-end available through GCC Gimple. The work deals only with complete applications targeting FPGAs.</p><p>CoDeveloper <ref type="bibr" target="#b18">[18]</ref> is the HLS design environment provided by Impulse Accelerated Technologies. Impulse-C is based on a C-language subset to which it adds communicating sequential processes (CSP)-style extensions. These extensions are required for parallel programming of mixed processor and FPGA platforms. Because the basic principle of the CSP programming model consists of processes that have to be independently synchronized and streams for inter-process communication, the application domain is limited primarily to image processing and streaming applications.</p><p>DK Design Suite <ref type="bibr" target="#b19">[19]</ref> uses Handel-C as the design language, which is based on a rich subset of the C language extended with hardware-specific language constructs. The user however needs to specify timing requirements, and to describe the parallelization and synchronization segments in the code explicitly. In addition, the data mapping to different memories has to be manually performed. Because of these language additions, the user needs advanced hardware knowledge.</p><p>Single-Assignment C (SA-C) <ref type="bibr" target="#b20">[20]</ref> is a compiler that uses a C language variant in which variables can be set only once. This work provided the inspiration for the later ROCCC compiler. The language introduces new syntactical constructs that require application rewriting.</p><p>The Garp <ref type="bibr" target="#b21">[21]</ref> project's main goal was to accelerate loops of general-purpose software applications. It accepts C as input and generates hardware code for the loop.</p><p>The Napa-C <ref type="bibr" target="#b22">[22]</ref> project was one of the first to consider high-level compilation for systems which contain both a microprocessor and reconfigurable logic. The NAPA C compiler, implemented in SUIF and targeting National Semiconductor's NAPA1000 chip, performed semantic analysis of the pragmaannotated program and co-synthesized a conventional program executable for the processor, and a configuration bit stream.</p><p>In eXCite <ref type="bibr" target="#b23">[23]</ref>, communication channels have to be inserted manually to describe the communication between the software and hardware. These channels can be streaming, blocking or indexed (e.g. for handling arrays). Different types of communication between the software and hardware parts (e.g. streaming, shared memory) are possible.</p><p>The ROCCC <ref type="bibr" target="#b24">[24]</ref> project focused mainly on the parallelization of heavy-compute-density applications having little control. This restricts its application domain to streaming applications, and it means that the input C is limited to a subset of the C language. For example, only perfectly nested loops with fixed stride, operating on integer arrays are allowed.</p><p>Catapult-C <ref type="bibr" target="#b25">[25]</ref> is a commercial high-level synthesis tool initially oriented towards the ASIC hardware developer, however, it now targets both FPGAs and ASICs. It offers flexibility in choosing the target technology, external libraries, setting the design clock frequency, mapping function parameters to either register, RAM, ROM or streaming interfaces.</p><p>C-to-Silicon (CtoS) <ref type="bibr" target="#b26">[26]</ref>, offered by Cadence, offers support for both control-and dataflow applications. Since it accepts SystemC as input, it is possible to accurately specify different interface types, from simple function array parameters to cycle-accurate transmission protocols.</p><p>SPARK <ref type="bibr" target="#b27">[27]</ref> was targeted to multimedia and image processing applications along with control-intensive microprocessor functional blocks. The compiler generated synthesizable VHDL that could be mapped to both ASICs or FPGAs.</p><p>The C to Hardware Compiler <ref type="bibr" target="#b28">[28]</ref> generates hardware to be offloaded onto a Application Specific Processor (ASP) core, for which verification has to be done manually by loading and executing the generated design on an Altium Desktop NanoBoard NB2DSK01.</p><p>A distinct feature of the GAUT <ref type="bibr" target="#b29">[29]</ref> project is that besides the processing accelerator, it can generate both communication and memory units. A testbench is also automatically generated to apply stimuli to the design and to analyze the results for validation purposes. Fixed-point arithmetic is supported through Mentor Graphics Algorithmic C class library.</p><p>Trident <ref type="bibr" target="#b30">[30]</ref> is a compiler that is an offshoot of an earlier project called Sea Cucumber <ref type="bibr" target="#b31">[31]</ref>. It generates VHDL-based accelerators for scientific applications operating on floatingpoint data starting from a C-language program. Its strength is in allowing users to select floating-point operators from a variety of standard libraries, such as FPLibrary and Quixilica, or to import their own. C2H [32] was an HLS tool offered by Altera Corporation since 2006. The tool is technology dependent, generating accelerators that can only communicate via an Altera Avalon bus with an Altera NIOS II configurable soft processor. Furthermore, using this tool required advanced hardware design knowledge in order to configure and connect the accelerators to the rest of the system -tasks performed in Altera's development environment.</p><p>Synphony C <ref type="bibr" target="#b32">[33]</ref>, formerly PICO <ref type="bibr" target="#b33">[34]</ref>, is an HLS tool for hardware DSP design offered by Synopsys. The tool can support both streaming and memory interfaces and allows for performance-related optimizations to be fine-tuned (e.g. loop unrolling, loop pipelining). Floating point operations are not permitted, but the programmer can use fixed-point arithmetic.</p><p>Comparison results published by BDTi <ref type="bibr" target="#b34">[35]</ref> showed that performance and area metrics for Synphony-produced circuits are comparable with those obtained with AutoESL (the product that become Vivado HLS when acquired by <ref type="bibr">Xilinx)</ref>.</p><p>The goal of the MATCH [36] software system was to translate and map MATLAB code to heterogeneous computing platforms for signal and image processing applications. The MATCH technology was later transferred to a startup company, AccelChip <ref type="bibr" target="#b35">[37]</ref>, bought in 2006 by Xilinx but discontinued in 2010. The tool was one of the few on the market that started from a MATLAB input description to generate VHDL or Verilog. Key features of the product were automation conversion of floating point to fixed point.</p><p>The CHiMPS compiler <ref type="bibr" target="#b36">[38]</ref> targets applications for highperformance. The distinctive feature of CHiMPS is its manycache, which is a hardware model that adapts the hundreds of small, independent FPGA memories to the specific memory needs of an application. This allows for many simultaneous memory operations per clock cycle to boost performance.</p><p>DEFACTO <ref type="bibr" target="#b37">[39]</ref> is one of the early design environments that proposed hardware/software co-design solutions as an answer to increasing demands for computational power. DEFACTO is composed of a series of tools such as a profiler, partitioner and software and hardware compilers to perform fast design space exploration given a set of design constraints.</p><p>MaxCompiler <ref type="bibr" target="#b38">[40]</ref> is a data-flow specific HLS tool. The compiler accepts MaxJ, a Java-based language, as input and generates synthesizable code for the hardware data-flow engines provided by Maxeler's hardware platform.</p><p>The Kiwi <ref type="bibr" target="#b39">[41]</ref> programming library and its associated synthesis system generates FPGA co-processors (in Verilog) from C# programs. Kiwi allows the programmer to use parallel constructs such as events, monitors and threads, which are closer to hardware concepts than classical software constructs.</p><p>Sea Cucumber <ref type="bibr" target="#b31">[31]</ref> is a Java-based compiler that generates EDIF netlists and adopts the standard Java thread model, augmented with a communication model based on CSP.</p><p>Cynthesizer <ref type="bibr" target="#b40">[42]</ref>, recently acquired by Cadence, includes formal verification between RTL and gates, power analysis, and several optimizations, such as support for floating-point operations with IEEE-754 single/double precision.</p><p>Vivado HLS <ref type="bibr" target="#b41">[43]</ref>, formerly AutoPilot <ref type="bibr" target="#b42">[44]</ref>, was developed initially by AutoESL until it was acquired by Xilinx in 2011. The new improved product, which is based on LLVM, was released early 2013, and includes a complete design environment with abundant features to fine-tune the generation process from HLL to HDL. C, C++ and SystemC are accepted as input, and hardware modules are generated in VHDL, Verilog and SystemC. During the compilation process, it is possible to apply different optimizations, such as operation chaining, loop pipelining, and loop unrolling. Furthermore, different parameter mappings to memory can be specified. Streaming or shared memory type interfaces are both supported to simplify accelerator integration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. HIGH-LEVEL SYNTHESIS (HLS) OPTIMIZATIONS</head><p>HLS tools feature several optimizations to improve the performance of the accelerators. Some of them are borrowed from the compiler community, while others are specific for hardware design. In this section, we discuss these HLS optimizations, which are also current research trends for the HLS community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Operation Chaining</head><p>Operation chaining is an optimization that performs operation scheduling within the target clock period. This requires the designer to "chain" two combinational operators together in a single cycle in a way that false paths are avoided <ref type="bibr" target="#b45">[46]</ref>. Concretely, if two operations are dependent in the data-flow graph and they can both complete execution in a time smaller than the target clock period, then they can be scheduled in the same cycle; otherwise at least two cycles are needed to finish execution, along with a register for the intermediate result. Generally, chaining reduces the number of cycles in the schedule, improving performance and reducing the global number of registers in the circuit. However, this is highly technology dependent and requires an accurate characterization of the resource library (see Section III-E).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Bitwidth Analysis and Optimization</head><p>Bitwidth optimization is a transformation that aims to reduce the number of bits required by datapath operators. This is a very important optimization because it impacts all non-functional requirements (e.g. performance, area, power) of a design, without affecting its behavior. Differently from GPP compilers, which are designed to target a processor with a fixed-sized datapath (usually 32 or 64 bits), a hardware compiler can exploit specialization by generating custom-size operators (i.e. functional units) and registers. As a direct consequence, we can select the minimal number of bits required for an operation and/or storage of the specific algorithm, which in turns leads to minimal space used for registers, smaller functional units that translate into less area, less power, and shorter critical paths. However, this analysis cannot be usually completely automated since it often requires specific knowledge of the algorithm and the input datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Memory Space Allocation</head><p>FPGAs contain multiple memory banks in the form of distributed block RAMs (BRAMs) across the device. This allows the designer to partition and map software data structures onto dedicated BRAMs in order to implement fast memory accesses at low cost. As a result, the scheduler can perform multiple memory operations in one cycle once it is able to statically determine that they access different memories in the same cycle without contention. This feature is similar to the allocation of different memory spaces used in the embedded systems domain. Using multiple BRAMs increases the available parallelism. On the other hand, these memory elements have a limited number of memory ports and the customization of memory accesses may require the creation of an efficient multi-bank architecture to avoid limiting the performance <ref type="bibr" target="#b46">[47]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Loop Optimizations</head><p>Hardware acceleration is particularly important for algorithms with compute-intensive loops. Loop pipelining is a key performance optimization for loops implemented in hardware. This optimization exploits loop-level parallelism by allowing a loop iteration to start before the completion of its predecessor, provided that data dependences are satisfied. The concept is related to software pipelining <ref type="bibr" target="#b47">[48]</ref>, which has widely been applied in VLIW processors. A key concept in loop pipelining is the initiation interval (II), which is the number of clock cycles between successive loop iterations. For high throughput, it is desirable that II be as small as possible, ideally one, which implies that a new loop iteration is started every cycle. Achieving the minimum II for a given design can be impeded by two factors: 1) resource constraints, and 2) loopcarried dependencies. Regarding resource constraints, consider a scenario where a loop body contains 3 load operations, and 1 store operation. In this case, achieving an II less than two is impossible if the memory has two ports, since each loop iteration has 4 memory operations. For this reason, loop optimizations are frequently combined with multi-bank architecture to fully exploit the parallelism <ref type="bibr" target="#b46">[47]</ref>. With respect to loop-carried dependencies, if a loop iteration depends on a result computed in a prior iteration, that data dependency may restrict the ability to reduce II, as it may be necessary to delay commencing an iteration until its dependent data has been computed.</p><p>For example, DWARV leverages CoSy to implement loop pipelining. The heuristic applied is based on swing modulo scheduling <ref type="bibr" target="#b48">[49]</ref>, which considers operation latencies between loop instructions to move conflicting instructions and reduce the II. However, due to the high availability of resources in FPGAs, the loop pipelining algorithm for hardware generation can be relaxed. This can be accomplished by fixing the II to a desired value, i.e. based on a required design throughput, and then generating enough hardware (e.g. registers) to accommodate the particular II.</p><p>Recent research has focused on loop pipelining for nested loops. Consider, for example, a doubly-nested loop whose outermost loop (with induction variable i) iterates 100 times, and whose innermost one (with induction variable j) iterates up to i times. The iteration space traversed by i and j can be viewed as a polyhedron (in this case, a triangle) and analytically analyzed with the polyhedral model <ref type="bibr" target="#b49">[50]</ref>. Applying loop transformations (e.g. exchanging the outer and inner loop) result in different polyhedra, and potentially different IIs. Polyhedral-based optimizations have been applied to synthesize memory architectures <ref type="bibr" target="#b50">[51]</ref>, improve throughput <ref type="bibr" target="#b51">[52]</ref>, and optimize resource usage <ref type="bibr" target="#b52">[53]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Hardware Resource library</head><p>In the process of HLS, in order to generate an efficient implementation that meets timing requirements while minimizing the use of resources, it is essential to determine how to implement each operation. Specifically, the front-end phase first inspects the given behavioral specification and identifies operations characteristics, such as the type of each operation (e.g. arithmetic or non-arithmetic), its operand types (e.g. integer, float), and its bit-width. At this stage, some operations may benefit from specific optimizations. For example, multiplications or divisions by a constant are typically transformed into operations that use only shifts and adds <ref type="bibr" target="#b53">[54]</ref>, <ref type="bibr" target="#b54">[55]</ref> in order to improve area and timing. All these characteristics are then used during the module allocation phase, where the resulting operations are associated with functional units contained in the resource library <ref type="bibr" target="#b45">[46]</ref>. This heavily impacts the use of resources and the timing of the resulting circuit. Hence, the proper composition of such a library and its characterization is crucial for efficient HLS.</p><p>The library of functional units can be quite rich and may contain several implementations for each single operation. On one hand, the library usually includes resources that are specific for the technology provider (e.g. the FPGA vendor). Some of these resources may leverage vendor-specific intrinsics or IP generators. In this case the module allocation will exploit resources that have been explicitly tailored and optimized for the specific target. This is usually adopted by HLS tools that are specific for some FPGA vendors (e.g. <ref type="bibr" target="#b41">[43]</ref>). The library may also contain resources that are expressed as templates in a standard hardware description language (i.e. Verilog or VHDL). These templates can be retargeted and customized based on characteristics of the target technology, like in FloPoCo <ref type="bibr" target="#b55">[56]</ref>. In this case, the underlying logic synthesis tool can determine which is the best architecture to implement each function. For example, multipliers can be mapped either on dedicated DSP blocks or implemented with LUTs.</p><p>To perform aggressive optimizations, each component of the library needs to be annotated with information useful during the entire HLS process, such as resource occupation and latency for executing the operations. There are several approaches for library characterization. The first approach performs a rapid logic synthesis during the scheduling and binding of the operations to determine the most suitable candidate resources, like in Cadence's C-to-Silicon <ref type="bibr" target="#b56">[57]</ref>. However, this approach has a high cost in terms of computation time, especially when the HLS is repeatedly performed for the same target. An alternative approach is to pre-characterize all resources in advance, as done in BAMBU <ref type="bibr" target="#b9">[8]</ref>. The performance estimation starts with a generic template of the functional unit, which can be parametric with respect to bitwidths and pipeline stages. Latency and resource occupation are then obtained by synthesizing each configuration and storing the results in the library. Mathematical models can be built on top of these actual synthesis values <ref type="bibr" target="#b57">[58]</ref>, <ref type="bibr" target="#b58">[59]</ref>. Additionally, this information can also be coupled with delays obtained after the place-and-route phase. This may improve the maximum frequency and the design latency and it makes the HLS results more predictable <ref type="bibr" target="#b59">[60]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Speculation and Code Motion</head><p>Most HLS scheduling techniques can extract parallelism only within the same control region (i.e. the same CDFG basic block). This can limit the performance of the resulting accelerator, especially in control-intensive designs. Speculation is a code-motion technique that allows operations to be moved along their execution traces, possibly anticipating them before the conditional constructs that control their execution <ref type="bibr" target="#b60">[61]</ref>, <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b62">[63]</ref>, <ref type="bibr" target="#b63">[64]</ref>. A software compiler is less likely to use this technique since, in a sequential machine, they may delay the overall execution with computations that are unnecessary in certain cases. In hardware, however, speculated operations can often be executed in parallel with the rest of the operations. Their results simply will be simply maintained or discarded based on later-computed branch outcomes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Exploiting Spatial Parallelism</head><p>A primary mechanism through which hardware may provide higher speed than a software implementation is by instantiating multiple hardware units that execute concurrently (spatial parallelism). HLS tools can extract fine-grained instructionlevel parallelism by analyzing data dependencies and looplevel parallelism via loop pipelining. It is nevertheless difficult to automatically extract large amounts of coarse-grained parallelism, as the challenges therein are akin to those faced by an auto-parallelizing software compiler. A question that arises, therefore, is how to specify hardware parallelism to an HLS tool whose input is a software programming language. With many HLS tools, a designer synthesizes an accelerator and then manually writes RTL that instantiates multiple instances of the synthesized core, steering input/output data to/from each, accordingly. However, this approach is error prone and requires hardware expertise. An alternative approach is to support the synthesis of software parallelization paradigms.</p><p>LEGUP supports the HLS of pthreads and OpenMP <ref type="bibr" target="#b64">[65]</ref>, which are two standard ways of expressing parallelism in C programs, widely used by software engineers. The general idea is to synthesize parallel software threads into an equal number of parallel-operating hardware units. With pthreads, a user can express both task and data-level spatial parallelism. In the former, each hardware unit may be performing a different function, and in the latter, multiple hardware units perform the same function on different portions of an input dataset. LEGUP also supports the synthesis of two standard pthreads synchronization constructions: mutexes and barriers. With OpenMP, the authors have focused on supporting the aspects of the standard that target loop parallelization, e.g. an N -iteration loop with no loop-carried dependencies can be split into pieces that are executed in parallel by concurrently operating hardware units. An interesting aspect of LEGUP is the support for nested parallelism: threads forking threads. Here, the threads initially forked within a program may themselves fork other threads, or contain OpenMP parallelization constructs. A limitation of the LEGUP work is that the number of parallel hardware units instantiated must exactly match the number of software threads forked since in hardware there is no support for context switching.</p><p>Altera has taken an different approach with their OpenCL SDK <ref type="bibr" target="#b65">[66]</ref>, which supports HLS of OpenCL programs. The OpenCL language is a variant of C and is heavily used for parallel programming of graphics processing units (GPUs). With OpenCL, one generally launches hundreds or thousands of threads that are relatively fine-grained, for example, each computing a vector dot product, or even an individual scalar multiplication. Altera synthesizes OpenCL into a deeply pipelined FPGA circuit that connects to an x86-based host processor over PCIe. The support for OpenCL HLS allows Altera to compete directly with GPU vendors, who have been gaining traction in the high-performance computing market.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. If-Conversion</head><p>If-conversion <ref type="bibr" target="#b66">[67]</ref> is a well-known software transformation that enables predicated execution, i.e. instructions are executed only when its predicate or guard evaluates to true. The main objective of this transformation is to schedule in parallel instructions from disjoint execution paths created by selective statements (e.g. if statements). The goals are two fold. First, it increases the number of parallel operations. Second, it facilitates pipelining by removing control dependencies within the loop, which may shorten the loop body schedule. In software, this leads to a 34% performance improvement, on average <ref type="bibr" target="#b67">[68]</ref>. However, if-conversion should be enabled only when the branches have a balanced number of cycles required to complete execution. When this is not the case, predicated execution incurs a slowdown in execution time because, if the shorter branch is taken, useless instructions belonging to the longer unselected branch will need to be checked before executing useful instructions can be resumed. Therefore, different algorithms have been proposed to decide when it is beneficial to apply if-conversion and when the typical conditional jump approach should be followed. For example, in <ref type="bibr" target="#b68">[69]</ref>, a generic model to select the fastest implementation for if-then-else statements is proposed. This selection is done according to the number of implicated if-statements, as well as the balance characteristics. The approach for selecting if-conversion on a case-by-case basis changes for hardware compilers generating an FPGA hardware circuit. This is because resources can be allocated as-needed (subject to area or power constraints), and therefore, we can schedule branches in a manner that does not affect the branch-minimal schedule. Data and control instructions can be executed in parallel and we can insert "jumps" to the end of the if-statement to short-cut the execution of (useless) longer branch instructions when a shorter path is taken. This was demonstrated in <ref type="bibr" target="#b69">[70]</ref> (incorporated in DWARV), which proposed a lightweight if-conversion scheme adapted for hardware generation. Furthermore, the work showed that such a lightweight predicative scheme is beneficial for hardware compilers, with performance always at least as good as when no if-conversion is enabled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EVALUATION OF HIGH-LEVEL SYNTHESIS TOOLS</head><p>In this section, we define a common environment to evaluate four HLS tools, i.e. one commercial and three academic: DWARV, BAMBU, and LEGUP. With LEGUP we target the fastest speedgrade of the Altera Stratix V family <ref type="bibr" target="#b70">[71]</ref>, while with the other tools we target the fastest speedgrade of the Xilinx Virtex-7 family <ref type="bibr" target="#b71">[72]</ref>. Both Stratix V and Virtex-7 are 28nm state-of-the-art high-performance FPGAs fabricated by TSMC. The primary combinational logic element in both architectures is a dual-output 6-input look-up-table (LUT).</p><p>Three metrics are used to evaluate circuit performance: maximum frequency (FMax in MHz), cycle latency (i.e. the number of clock cycles needed for a benchmark to complete the computation), and wall-clock time (minimum clock period × cycle latency). Clock period (and the corresponding FMax) is extracted from post-routing static timing analysis. Cycle latency is evaluated by simulating the resulting RTL circuits using ModelSim (discussed further below). We do not include the evaluations the HLS tool execution times as this time is negligible in comparison with the synthesis, mapping, placement and routing time.</p><p>To evaluate area, we consider logic, DSP and memory usage. For logic area, in Xilinx devices, we report the total number of fracturable 6-LUTs, each of which can be used to implement any single function of up to 6 variables, or any two functions that together use at most 5 distinct variables. For Altera, we report the total number of used adaptive logic modules (ALMs), each of which contains one fracturable 6-LUT, that can implement any single function of up to 6 variables, any two 4-variable functions, a 5-and 3-variable function, and several other dual-function combinations. With respect to DSP usage, we consider the DSP units in Altera and Xilinx devices to be roughly equivalent (Xilinx devices contain hardened 25 × 18 multipliers, whereas Altera devices contain hardened 18×18 multipliers). For memory, we report the total number of dedicated blocks used (e.g. BRAMs), which are equivalent to 18Kb in Virtex-7 and 20Kb in Stratix V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Potential Sources of Inaccuracy</head><p>Although we have endeavored to make the comparison between tools as fair as possible, we discuss potential sources of inaccuracy to better understand the results. First, the evaluated HLS tools are built within different compilers (e.g. BAMBU is built within GCC, LEGUP within LLVM, and DWARV within CoSy), and target different FPGA devices. It is thus impossible to perfectly isolate variations in circuit area and speed attributable to the HLS tools versus other criteria. Each compiler framework has a different set of optimizations that execute before HLS, with potentially considerable impact on HLS results. Likewise, we expect that Altera's RTL and logic synthesis, placement and routing, are different than those within Xilinx's tool. Moreover, while the chosen Virtex-7 and Stratix V are fabricated in the same TSMC process, there are differences in the FPGA architecture itself. For example, as mentioned above, the fracturable 6-LUTs in Altera FPGAs are more flexible than the fracturable 6-LUTs in Xilinx FPGAs, owing to the Altera ALMs having more inputs. This may vary the final resource requirements for the accelerators. Finally, although we have selected the fastest speedgrade for each vendor's device, we cannot be sure whether the fraction of die binned in Xilinx's fastest speedgrade is the same as that for Altera because this information is kept proprietary by the vendors.</p><p>Other differences relate to tool assumptions, e.g. about memory implementation. For each benchmark kernel, some data is kept local to the kernel (i.e. in BRAMs instantiated within the module), whereas other data is considered "global", kept outside the kernel and accessed via a memory controller. As an example, in LEGUP, a data is considered local when, at compile time, is proven to solely be accessed within the kernel (e.g. an array declared within the kernel itself and used as a scratch pad). The various tools evaluated do not necessarily make the same decisions regarding which data is kept local versus global. The performance and area numbers reported reflect the kernel itself and do not include the global memory. The rationale behind this decision is to focus on the results on the HLS-generated portion of the circuit, rather than on the integration with the rest of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Benchmark Overview</head><p>The synthesized benchmark kernels are listed in Table <ref type="table">where</ref> we mention in the second and third columns the application domain of the corresponding kernel, as well as its source. Most of the kernels have been extracted from the C-language CHStone benchmark suite <ref type="bibr" target="#b72">[73]</ref>, with the remainder being from DWARV and BAMBU. The selected functions originate from different application domains, which are control-flow, as well as data-flow dominated as we aim at evaluating generic (nonapplication-specific) HLS tools.</p><p>An important aspect of the benchmarks used in this study is that input and golden output vectors are available for each program. Hence, it is possible to "execute" each benchmark with the built-in input vectors, both in software and also in HLS-generated RTL using ModelSim. The RTL simulation permits extraction of the total cycle count, as well as enables functional correctness checking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. HLS Evaluation</head><p>We performed two sets of experiments to evaluate the compilers. In the first experiment, we executed each tool in a TABLE III: Optimizations Used (Letter in () Refers to Subsection in Section III). v: USED; x: UNUSED.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HLS Tool</head><p>Compiler Framework Target FPGA OC</p><formula xml:id="formula_0">(A) BA(B) MS(C) LO(D) HwRL(E) Sp(F) SP(G) IC(H) LEGUP LLVM Altera v v v v x x v v BAMBU GCC Xilinx v v v x v v x v DWARV CoSy Xilinx v v v v x x x v Commercial Unknown Xilinx v v v v v v v v</formula><p>"push-button" manner using all of its default settings, which we refer to as standard-optimization. The first experiment thus represents what a user would see running the HLS tools "out of the box". We used the following default target frequencies: 250 MHz for BAMBU, 150 MHz for DWARV, and 200 MHz for LEGUP. For the commercial tool, we decided to use a default frequency of 400 MHz. In the second experiment, we manually optimized the programs and constraints for the specific tools (by using compiler flags and code annotations to enable various optimizations) to generate performanceoptimized implementations. Table <ref type="table" target="#tab_1">III</ref> lists for each tool the optimizations enabled in this second experiment. As we do not have access to the source of the commercial tool, its list is based on the observations done on the available options and on the inspection of the generated code. The last four columns of Table <ref type="table" target="#tab_1">II</ref> show the HLS target frequencies used for the optimized experiment. It should be noted that there is no strict correlation between these and the actual post place and route frequencies obtained after implementing the designs (shown in tables IV and V) due to the actual vendor-provided back-end tools that perform the actual mapping, placing and routing steps. This is explained by the inherently approximate timing models for computing in HLS. The target frequency used as input to the HLS tools should be regarded only as an indication of how much operation chaining can be performed. As a rule of thumb, in order to implement a design at some frequency, one should target a higher frequency in HLS.</p><p>Table <ref type="table">IV</ref> shows performance metrics (e.g. number of cycles, maximum frequency after place &amp; route, and wall-clock time) obtained in the standard-optimization scenario, while Table <ref type="table">V</ref> shows the same performance metrics obtained in the performance-optimized scenario. The ERR entries denote errors that prevented us from obtaining complete results for the corresponding benchmarks (e.g. compiler segmentation error). Observe that geometric mean data is included at the bottom of the rows. Two rows of geomean are shown: the first includes only those benchmarks for which all tools were successful; the second includes all benchmarks, and is shown for BAMBU and LEGUP. In the standard-optimization results in Table <ref type="table">IV</ref>, we see that the commercial tool is able to achieve the highest F max; BAMBU implementations have the lowest cycle latencies; and BAMBU and LEGUP deliver roughly the same (and lowest) average wall-clock time. However, we also observe that no single tool delivers superior results for all benchmarks. For example, while DWARV does not provide the lowest wall-clock time on average, it produced the best results (among the academic tools) for several benchmarks, including aes decrypt and bellmanford.</p><p>For the performance-optimized results in Table <ref type="table">V</ref>, a key takeaway is that performance is drastically improved when the constraints and source code input to the HLS tools are tuned. For the commercial tool, geomean wall-clock time is reduced from 37.1 to 19.9µs (1.9×) in the optimized results. For BAMBU, DWARV and LEGUP, the wall-clock time reductions in the optimized flow are 1.6×, 1.7× and 2×, respectively, on average (comparing values in the GEOMEAN row of the table ). It is interesting that, for all the tools, the average performance improvements in the optimized flow were roughly the same. From this, we conclude that one can expect ∼1.6-2× performance improvement, on average, from tuning code and constraints provided to HLS. We also observe that, from the performance angle, the academic tools are comparable to the commercial tool. BAMBU and LEGUP, in particular, deliver superior wall-clock time to commercial, on average.</p><p>For completeness, the area-related metrics are shown in tables VI and VII for the standard and optimized flows, respectively. Comparisons between LEGUP and the other tools are more difficult in this case, owing to architectural differences between Stratix V and Virtex-7. Among the flows that target Xilinx, the commercial HLS tool delivers considerably more compact implementations than the academic tools (much smaller LUT consumption) since we anticipate it implements more technology-oriented optimizations. For all flows (including LEGUP), we observe that, in the performanceoptimized flow, more resources are used to improve effectively performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. DISCUSSON FROM THE TOOL PERSPECTIVE</head><p>In this section, we describe the results for the academic HLS tools from a tool-specific viewpoint and highlight techniques used to improve performance in each tool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Bambu</head><p>BAMBU leverages GCC to perform classical code optimizations, such as loop unrolling, constant propagation, etc. To simplify the use of the tool for software designers, its interface has been designed such that the designer can use the same compilation flags and directives that would be given to GCC. In the standard-optimization case, the compiler optimization level passed to GCC is -O3, without any modifications to the source code of the benchmarks. In the performance-optimized study, the source code was modified only in case of sobel, where we used the same version modified by the LEGUP team. Loop unrolling was used for adpcm, matrix and sha. On three benchmarks (gsm, matrix and sobel), GCC vectorization produced a better wall-time, while function inlining was useful for gsm, dfadd, dfsin, aes encrypt and decrypt.</p><p>BAMBU's front-end phase implements also operation transformations that are specific for HLS, e.g. by transforming  multiplications and divisions which are usually very expensive in hardware. BAMBU maps 64-bit divisions onto a C library function implementing the Newton-Raphson algorithm for the integer division. This leads to a higher number of DSPs required by dfdiv and dfsin in the standard-optimzation case. BAMBU also supports floating-point operations since it interfaces with FloPoCo library <ref type="bibr" target="#b55">[56]</ref>.</p><p>All functional units are pre-characterized for multiple combinations of target devices, bit-widths and pipeline stages. Hence, BAMBU implements a technology-aware scheduler to perform aggressive operation chaining and code motion. This reduces the total number of clock cycles, while respecting the given timing constraint. Trimming of the address bus was useful for bellmanford, matrix, satd, and sobel.</p><p>Finally, BAMBU adopts a novel architecture for memory accesses <ref type="bibr" target="#b12">[11]</ref>. Specifically, BAMBU builds a hierarchical datapath directly connected to a dual-port BRAM whenever a local aggregated or a global scalar/aggregate data type is used by the kernel and whenever the accesses can be determined at compile time. In this case, multiple memory accesses can be performed in parallel. Otherwise, the memories are interconnected so that it is also possible to support dynamic resolution of the addresses. Indeed, the same memory infrastructure can be natively connected to external components (e.g. a local scratch-pad memory or cache) or directly to the bus to access off-chip memory. Finally, if the kernel has pointers as parameters, it assumes that the objects referred are allocated on dual-port BRAMs.</p><p>The optimized results obtained for blowfish and jpeg are the same obtained in the first study since we were not able to identify different options to improve the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. DWARV</head><p>Since DWARV is based on CoSy <ref type="bibr" target="#b11">[10]</ref>, one of the main advantages is its flexibility to easily exploit standard and custom optimizations. The framework contains 255 transformations and optimizations passes available in the form of stand-alone engines. For the standard-evaluation experiment, the most important optimizations that DWARV uses are if-conversion, operation chaining, multiple memories and a simple (i.e. analysis based only on standard integer types) bit-width analysis. For the performance-optimized runs, pragmas were added to enable loop unrolling. However, not all framework optimizations are yet fully integrated in the HLS flow. One of the DWARV restrictions is that it does not support global variables. As a result, the CHStone benchmarks, which rely heavily on global variables, had to be rewritten to transform global variables to function parameters passed by reference. Besides the effort needed to rewrite code accessing global memory, some global optimizations across functions are not considered. Another limitation is a mismatch between the clock period targeted by operation-chaining and the selection of IP cores in the target technology (e.g. for a divider unit), which are not (re)generated on request based on a target frequency. Operation chaining is set to a specific target frequency for each benchmark (as shown in Table <ref type="table" target="#tab_1">II</ref>). However this can differ significantly from that achievable within the instantiated IP cores available in DWARV's IP library, as shown for example in the dfxxx kernels. DWARV targets mostly small and medium size kernels. It thus generates a central FSM and always maps local arrays to distributed logic. This is a problem for large kernels such as the jpeg benchmark, which could not be mapped in the available area on the target platform. Another minor limitation is the transformation -in the compiler backend -of switch constructs to if-else constructs. Generating lower-level switch constructs would improve the aes, mips, jpeg kernels, that contain multiple switch statements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. LegUp</head><p>Several methods exist for optimizing LEGUP-produced circuits: automatic LLVM compiler optimizations <ref type="bibr" target="#b13">[12]</ref>, userdefined directives for activating various hardware specific features, and source code modifications. Since LEGUP is built within LLVM, users can utilize LLVM optimization passes with minimal effort. In the context of hardware circuits, for the performance-optimized runs, function inlining and loop unrolling provided benefits across multiple benchmarks. Function inlining allows the hardware scheduler to exploit more instruction-level parallelism and simplify the FSM. Similarly, loop unrolling exposes more parallelism across loop iterations. The performance boost associated with inlining and unrolling generally comes at the cost of increased area.</p><p>LEGUP also offers many hardware optimizations that users can activate by means of tcl directives, such as activating loop pipelining or changing the target clock period. Loop pipelining allows consecutive iterations of a loop to begin execution before the previous iteration has completed, reducing the overall number of clock cycles. Longer clock periods permit more chaining, reducing cycle latency. If the reduction in cycle latency does not exceed the amount by which the clock period lengthens, wall-clock time will be also improved.</p><p>Manual source code modifications can be made to assist LEGUP in inferring parallelism within the program. One such modification is to convert single-threaded execution to multithreaded execution using pthreads/OpenMP, whereby LEGUP synthesizes the multiple parallel threads into parallel hardware accelerators. This optimization was applied for all of the df benchmarks. In the df benchmarks, a set of inputs is applied to a kernel in a data-parallel fashion -there are no dependencies between the inputs. Such a situation is particularly desirable for LEGUP's multi-threading synthesis: multiple identical hardware kernels are instantiated, each operating in parallel on disjoint subsets of the input data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUDING REMARKS</head><p>To the authors' knowledge, this paper represents the first broad evaluation of several HLS tools. We presented an extensive survey and categorization for past and present hardware compilers. We then described the optimizations on which recent and ongoing research in the HLS community is focussed. We experimentally evaluated three academic HLS tools, BAMBU, DWARV and LEGUP, against a commercial tool. The methodology aims at providing a fair comparison of tools, even if they are built within different compiler frameworks and target different FPGA families. The results shows that each HLS tool can significantly improve the performance with benchmark-specific optimizations and constraints. However, software engineers need to take into account that optimizations that are necessary to realize high performance in hardware (e.g. enabling loop pipelining, removing control flow, etc.) differ significantly from software-oriented ones (e.g. data re-organization for cache locality).</p><p>Overall, the performance results showed that academic and commercial HLS tools are not drastically far apart in terms of quality, and that no single tool producted the best results for all benchmarks. Obviously, despite this, it should nevertheless be noted that the commercial compiler supports more features, allowing multiple input and output languages, the customization of the generated kernels in terms of interface types, memory bank usage, throughput, etc., while at the same time also being more robust than the academic tools.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>Benchmark Characteristics &amp; Target Frequencies for Optimized Flow (MHz).</figDesc><table><row><cell>Benchmark</cell><cell>Domain</cell><cell cols="5">Source BAMBU DWARV LEGUP Commercial</cell></row><row><cell>adpcm encode</cell><cell>Comm</cell><cell cols="2">CHStone 333</cell><cell>150</cell><cell>333</cell><cell>400</cell></row><row><cell>aes encrypt</cell><cell>Encrypt</cell><cell cols="2">CHStone 250</cell><cell>200</cell><cell>333</cell><cell>363</cell></row><row><cell>aes decrypt</cell><cell>Encrypt</cell><cell cols="2">CHStone 250</cell><cell>200</cell><cell>1000</cell><cell>312</cell></row><row><cell>gsm</cell><cell>Comm</cell><cell cols="2">CHStone 200</cell><cell>150</cell><cell>333</cell><cell>400</cell></row><row><cell>sha</cell><cell>Encrypt</cell><cell cols="2">CHStone 200</cell><cell>200</cell><cell>333</cell><cell>400</cell></row><row><cell>blowfish</cell><cell>Encrypt</cell><cell cols="2">CHStone 250</cell><cell>200</cell><cell>200</cell><cell>400</cell></row><row><cell>dfadd</cell><cell>Arith</cell><cell cols="2">CHStone 250</cell><cell>200</cell><cell>333</cell><cell>400</cell></row><row><cell>dfdiv</cell><cell>Arith</cell><cell cols="2">CHStone 250</cell><cell>150</cell><cell>200</cell><cell>400</cell></row><row><cell>dfmul</cell><cell>Arith</cell><cell cols="2">CHStone 250</cell><cell>150</cell><cell>200</cell><cell>400</cell></row><row><cell>dfsin</cell><cell>Arith</cell><cell cols="2">CHStone 250</cell><cell>100</cell><cell>200</cell><cell>303</cell></row><row><cell>jpeg</cell><cell>Media</cell><cell cols="2">CHStone 250</cell><cell>N/A</cell><cell>1000</cell><cell>400</cell></row><row><cell>mips</cell><cell>Compute</cell><cell cols="2">CHStone 400</cell><cell>300</cell><cell>200</cell><cell>400</cell></row><row><cell>motion</cell><cell>Media</cell><cell cols="2">CHStone 250</cell><cell>150</cell><cell>200</cell><cell>ERR</cell></row><row><cell>satd</cell><cell>Compute</cell><cell cols="2">DWARV 455</cell><cell>100</cell><cell>100</cell><cell>400</cell></row><row><cell>sobel</cell><cell>Media</cell><cell cols="2">DWARV 500</cell><cell>300</cell><cell>1000</cell><cell>285</cell></row><row><cell>bellmanford</cell><cell>Compute</cell><cell cols="2">DWARV 500</cell><cell>300</cell><cell>333</cell><cell>400</cell></row><row><cell>matrix</cell><cell>Arith</cell><cell>Bambu</cell><cell>250</cell><cell>300</cell><cell>250</cell><cell>400</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE VI :</head><label>VI</label><figDesc>Standard-Optimization Area Results.</figDesc><table><row><cell></cell><cell>Commercial</cell><cell></cell><cell></cell><cell>BAMBU</cell><cell></cell><cell></cell><cell>DWARV</cell><cell></cell><cell></cell><cell>LEGUP</cell><cell></cell></row><row><cell cols="12">Benchmark LUTp BRAMB18 DSP48s LUTp BRAMB18 DSP48s LUTp BRAMB18 DSP48s ALMs M20K DSPs</cell></row><row><cell>adpcm encode 4319</cell><cell>0</cell><cell>68</cell><cell>19931</cell><cell>52</cell><cell>64</cell><cell>5626</cell><cell>18</cell><cell>6</cell><cell>2490</cell><cell>0</cell><cell>43</cell></row><row><cell>aes encrypt 5802</cell><cell>6</cell><cell>1</cell><cell>8485</cell><cell>4</cell><cell>0</cell><cell>15699</cell><cell>16</cell><cell>3</cell><cell>4263</cell><cell>8</cell><cell>0</cell></row><row><cell>aes decrypt 6098</cell><cell>4</cell><cell>1</cell><cell>8747</cell><cell>4</cell><cell>1</cell><cell>12733</cell><cell>16</cell><cell>3</cell><cell>4297</cell><cell>14</cell><cell>0</cell></row><row><cell>gsm 5271</cell><cell>8</cell><cell>49</cell><cell>11864</cell><cell>10</cell><cell>75</cell><cell>6442</cell><cell>0</cell><cell>8</cell><cell>4311</cell><cell>1</cell><cell>51</cell></row><row><cell>sha 2161</cell><cell>16</cell><cell>0</cell><cell>4213</cell><cell>12</cell><cell>0</cell><cell>10012</cell><cell>0</cell><cell>0</cell><cell>6398</cell><cell>26</cell><cell>0</cell></row><row><cell>blowfish 2226</cell><cell>0</cell><cell>0</cell><cell>6837</cell><cell>0</cell><cell>0</cell><cell>7739</cell><cell>0</cell><cell>0</cell><cell>1679</cell><cell>0</cell><cell>0</cell></row><row><cell>dfadd 7409</cell><cell>0</cell><cell>0</cell><cell>7250</cell><cell>0</cell><cell>0</cell><cell>7334</cell><cell>0</cell><cell>0</cell><cell>2812</cell><cell>1</cell><cell>0</cell></row><row><cell>dfdiv 15107</cell><cell>0</cell><cell>24</cell><cell>11757</cell><cell>0</cell><cell>24</cell><cell>13934</cell><cell>1</cell><cell>40</cell><cell>4679</cell><cell>4</cell><cell>42</cell></row><row><cell>dfmul 3070</cell><cell>0</cell><cell>16</cell><cell>3430</cell><cell>0</cell><cell>16</cell><cell>14157</cell><cell>1</cell><cell>40</cell><cell>1464</cell><cell>1</cell><cell>28</cell></row><row><cell>dfsin 22719</cell><cell>0</cell><cell>43</cell><cell>21892</cell><cell>0</cell><cell>59</cell><cell>30616</cell><cell>43</cell><cell>43</cell><cell>9099</cell><cell>3</cell><cell>72</cell></row><row><cell>jpeg 16192</cell><cell>25</cell><cell>1</cell><cell>46757</cell><cell>154</cell><cell>26</cell><cell>ERR</cell><cell>ERR</cell><cell>ERR</cell><cell>16276</cell><cell>41</cell><cell>85</cell></row><row><cell>mips 1963</cell><cell>3</cell><cell>8</cell><cell>2501</cell><cell>0</cell><cell>8</cell><cell>3904</cell><cell>3</cell><cell>20</cell><cell>1319</cell><cell>0</cell><cell>15</cell></row><row><cell>motion ERR</cell><cell>ERR</cell><cell>ERR</cell><cell>2776</cell><cell>2</cell><cell>0</cell><cell>45826</cell><cell>6</cell><cell>0</cell><cell>6788</cell><cell>0</cell><cell>0</cell></row><row><cell>satd 790</cell><cell>0</cell><cell>0</cell><cell>4425</cell><cell>0</cell><cell>0</cell><cell>1411</cell><cell>0</cell><cell>0</cell><cell>2004</cell><cell>0</cell><cell>0</cell></row><row><cell>sobel 792</cell><cell>0</cell><cell>6</cell><cell>3106</cell><cell>0</cell><cell>28</cell><cell>1160</cell><cell>0</cell><cell>12</cell><cell>1241</cell><cell>0</cell><cell>36</cell></row><row><cell>bellmanford 485</cell><cell>0</cell><cell>0</cell><cell>1046</cell><cell>0</cell><cell>0</cell><cell>633</cell><cell>0</cell><cell>0</cell><cell>493</cell><cell>0</cell><cell>0</cell></row><row><cell>matrix 175</cell><cell>0</cell><cell>3</cell><cell>551</cell><cell>0</cell><cell>3</cell><cell>471</cell><cell>0</cell><cell>3</cell><cell>225</cell><cell>0</cell><cell>2</cell></row><row><cell>GEOMEAN 2711.75</cell><cell>1.84</cell><cell cols="2">4.57 5253.60</cell><cell>2.15</cell><cell cols="2">5.30 5148.72</cell><cell>2.43</cell><cell cols="4">4.88 2197.66 2.01 5.67</cell></row><row><cell>GEOMEAN (ALL)</cell><cell></cell><cell></cell><cell>5754.49</cell><cell>2.76</cell><cell>5.28</cell><cell></cell><cell></cell><cell></cell><cell cols="3">2641.94 2.30 6.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE VII :</head><label>VII</label><figDesc>Performance-Optimized Area Results.</figDesc><table><row><cell></cell><cell>Commercial</cell><cell></cell><cell></cell><cell>BAMBU</cell><cell></cell><cell></cell><cell>DWARV</cell><cell></cell><cell></cell><cell>LEGUP</cell><cell></cell></row><row><cell cols="12">Benchmark LUTp BRAMB18 DSP48s LUTp BRAMB18 DSP48s LUTp BRAMB18 DSP48s ALMs M20K DSPs</cell></row><row><cell>adpcm encode 5325</cell><cell>0</cell><cell>116</cell><cell>10546</cell><cell>2</cell><cell>81</cell><cell>13416</cell><cell>0</cell><cell>6</cell><cell>2903</cell><cell>0</cell><cell>57</cell></row><row><cell>aes encrypt 5798</cell><cell>6</cell><cell>1</cell><cell>9793</cell><cell>2</cell><cell>1</cell><cell>15699</cell><cell>16</cell><cell>3</cell><cell>3199</cell><cell>0</cell><cell>0</cell></row><row><cell>aes decrypt 6370</cell><cell>4</cell><cell>1</cell><cell>12927</cell><cell>2</cell><cell>3</cell><cell>12733</cell><cell>16</cell><cell>3</cell><cell>4894</cell><cell>18</cell><cell>0</cell></row><row><cell>gsm 8970</cell><cell>11</cell><cell>49</cell><cell>29646</cell><cell>16</cell><cell>316</cell><cell>6442</cell><cell>0</cell><cell>8</cell><cell>3442</cell><cell>3</cell><cell>59</cell></row><row><cell>sha 13105</cell><cell>16</cell><cell>0</cell><cell>14819</cell><cell>12</cell><cell>0</cell><cell>10012</cell><cell>0</cell><cell>0</cell><cell>28289</cell><cell>12</cell><cell>0</cell></row><row><cell>blowfish 3433</cell><cell>0</cell><cell>0</cell><cell>6799</cell><cell>0</cell><cell>0</cell><cell>7739</cell><cell>0</cell><cell>0</cell><cell>1648</cell><cell>0</cell><cell>0</cell></row><row><cell>dfadd 7409</cell><cell>0</cell><cell>0</cell><cell>6413</cell><cell>0</cell><cell>0</cell><cell>7334</cell><cell>0</cell><cell>0</cell><cell>3506</cell><cell>0</cell><cell>0</cell></row><row><cell>dfdiv 15107</cell><cell>0</cell><cell>24</cell><cell>7673</cell><cell>1</cell><cell>76</cell><cell>16209</cell><cell>1</cell><cell>40</cell><cell>16895</cell><cell>9</cell><cell>126</cell></row><row><cell>dfmul 3070</cell><cell>0</cell><cell>16</cell><cell>3001</cell><cell>0</cell><cell>16</cell><cell>14157</cell><cell>1</cell><cell>40</cell><cell>1866</cell><cell>0</cell><cell>28</cell></row><row><cell>dfsin 22719</cell><cell>0</cell><cell>43</cell><cell>21538</cell><cell>1</cell><cell>111</cell><cell>30616</cell><cell>43</cell><cell>43</cell><cell>10857</cell><cell>3</cell><cell>72</cell></row><row><cell>jpeg 16099</cell><cell>25</cell><cell>1</cell><cell>46757</cell><cell>154</cell><cell>26</cell><cell>ERR</cell><cell>ERR</cell><cell>ERR</cell><cell>16669</cell><cell>41</cell><cell>85</cell></row><row><cell>mips 1963</cell><cell>3</cell><cell>8</cell><cell>2305</cell><cell>0</cell><cell>8</cell><cell>3904</cell><cell>3</cell><cell>20</cell><cell>1319</cell><cell>0</cell><cell>15</cell></row><row><cell>motion ERR</cell><cell>ERR</cell><cell>ERR</cell><cell>2678</cell><cell>1</cell><cell>0</cell><cell>49414</cell><cell>6</cell><cell>0</cell><cell>6788</cell><cell>0</cell><cell>0</cell></row><row><cell>satd 1704</cell><cell>0</cell><cell>0</cell><cell>2447</cell><cell>2</cell><cell>0</cell><cell>3037</cell><cell>0</cell><cell>0</cell><cell>1959</cell><cell>0</cell><cell>0</cell></row><row><cell>sobel 1015</cell><cell>0</cell><cell>3</cell><cell>722</cell><cell>0</cell><cell>0</cell><cell>2877</cell><cell>0</cell><cell>3</cell><cell>698</cell><cell>0</cell><cell>0</cell></row><row><cell>bellmanford 1127</cell><cell>0</cell><cell>0</cell><cell>717</cell><cell>0</cell><cell>0</cell><cell>633</cell><cell>0</cell><cell>0</cell><cell>528</cell><cell>1</cell><cell>0</cell></row><row><cell>matrix 3406</cell><cell>0</cell><cell>96</cell><cell>10531</cell><cell>0</cell><cell>384</cell><cell>7110</cell><cell>0</cell><cell>3</cell><cell>3747</cell><cell>0</cell><cell>68</cell></row><row><cell>GEOMEAN 4575.89</cell><cell>1.88</cell><cell cols="2">5.70 5925.67</cell><cell>1.71</cell><cell cols="2">7.95 7384.52</cell><cell>2.00</cell><cell cols="4">4.45 3159.64 1.92 6.25</cell></row><row><cell>GEOMEAN (ALL)</cell><cell></cell><cell></cell><cell>6385.85</cell><cell>2.16</cell><cell>7.54</cell><cell></cell><cell></cell><cell></cell><cell cols="3">3644.68 2.21 6.54</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>TCAD, VOL. X, NO. Y, DECEMBER 2015</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Commercial BAMBU DWARV LEGUP Benchmark Cycles Fmax Wall-clock Cycles Fmax Wall-clock Cycles Fmax Wall-clock Cycles Fmax Wall-clock adpcm encode 27250 281 96</title>
		<author>
			<persName><surname>Table Iv</surname></persName>
		</author>
		<idno>87 11179 232 48.14 24454 183 133.67 7883 245 32.12 aes encrypt 3976 345 11.54 1574 252 6.25 5135 201 25.60 1564 395 3.96 aes decrypt 5461 322 16.95 2766 260 10.64 2579 255 10.11 7367 313 23.56 gsm 5244 347 15.12 2805 200 14.01 6866 186 36.90 3966 273 14.52 sha 197867 327 605.08 111762</idno>
		<imprint>
			<biblScope unit="page">259</biblScope>
		</imprint>
	</monogr>
	<note>Standard-Optimization Performance Results</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Commercial BAMBU DWARV LEGUP Benchmark Cycles Fmax Wall-clock Cycles Fmax Wall-clock Cycles Fmax Wall-clock Cycles Fmax Wall-clock adpcm encode 12350 281 43</title>
		<author>
			<persName><surname>Table V</surname></persName>
		</author>
		<idno>90 7077 258 27.40 9122 148 61.47 6635 348 19.06 aes encrypt 3735 331 11.29 1485 249 5.96 3282 250 13.13 1191 408 2.92 aes decrypt 3923 307 12.77 2585 254 10.17 2579 255 10.11 4847 319 15.19 gsm 3584 347 10.34 2128 180 11.83 7308 333 21.92 1931 262 7.36 sha 124339 329 377.87 51399 203 253.35 71163 253</idno>
	</analytic>
	<monogr>
		<title level="m">Fmax is Reported in MHz</title>
		<imprint>
			<publisher>Performance-Optimized Results</publisher>
		</imprint>
	</monogr>
	<note>Wall-clock in µs</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Borkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Chien</surname></persName>
		</author>
		<title level="m">The Future of Microprocessors. Communications of the ACM</title>
		<imprint>
			<date type="published" when="2011-05">May 2011</date>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="67" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">High-Level Synthesis: from Algorithm to Digital Circuit</title>
		<author>
			<persName><forename type="first">P</forename><surname>Coussy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Morawiec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Compositional System-Level Design Exploration with Planning of High-level Synthesis</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Petracca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Carloni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM DATE</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="641" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Reconfigurable Fabric for Accelerating Large-Scale Datacenter Services</title>
		<author>
			<persName><forename type="first">A</forename><surname>Putnam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Caulfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM ISCA</title>
		<imprint>
			<biblScope unit="page" from="13" to="24" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM FPGA</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="161" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">An Overview of Todays High-Level Synthesis Tools. In Design Automation for Embedded Systems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Meeus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Van Beeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Goedem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Meel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stroobandt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="31" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A CoSy-based C-to-VHDL Hardware Compiler</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V.-M</forename><surname>Sima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Olivier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Meeuws</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yankova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bertels</surname></persName>
		</author>
		<idno>DWARV 2.0</idno>
	</analytic>
	<monogr>
		<title level="m">FPL</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="619" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Bambu: A Modular Framework for the High Level Synthesis of Memory-intensive Applications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Pilato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ferrandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FPL</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">LegUp: High-Level Synthesis for FPGA-based Processor/Accelerator Systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Canis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aldham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kammoona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Czajkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM FPGA</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="33" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">ACE-Associated Compiler Experts. CoSy</orgName>
		</author>
		<ptr target="http://www.ace.nl" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Design Methodology to Implement Memory Accesses in High-Level Synthesis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Pilato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ferrandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sciuto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM CODES+ISSS</title>
		<imprint>
			<biblScope unit="page" from="49" to="58" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">LLVM: A Compilation Framework for Lifelong Program Analysis &amp; Transformation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lattner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Adve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM CGO</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="75" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">C-based SoC Design Flow and EDA Tools: An ASIC and System Vendor Perspective</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wakabayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Okamoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE TCAD</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1507" to="1522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bluespec System Verilog: Efficient, Correct RTL from High-Level Specifications</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nikhil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM MEMOCODE</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="69" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">PipeRench: A Reconfigurable Architecture and Compiler</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schmit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Budiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cadambi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Reed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="70" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automated Synthesis of FSMD-Based Accelerators for Hardware Compilation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kavvadias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Masselos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ASAP</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="157" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<ptr target="http://www.impulseaccelerated.com/productsuniversal.htm" />
		<title level="m">Impulse Accelerated Technologies. Impulse CoDeveloper C-to-FPGA Tools</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">DK Design Suite: Handel-C to FPGA for Algorithm Design</title>
		<author>
			<persName><forename type="first">Mentor</forename><surname>Graphics</surname></persName>
		</author>
		<ptr target="http://www.mentor.com/products/fpga/handel-c/dk-design-suite" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">High-Level Language Abstraction for Reconfigurable Computing</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Najjar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bohm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Draper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hammes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rinker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Beveridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chawathe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="63" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The Garp Architecture and C Compiler</title>
		<author>
			<persName><forename type="first">T</forename><surname>Callahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wawrzynek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="62" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">NAPA C: Compiling for a Hybrid RISC/F-PGA Architecture</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Gokhale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE FCCM</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="126" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">eXCite: C to RTL Behavioral Synthesis</title>
		<author>
			<orgName type="collaboration">Y Explorations.</orgName>
		</author>
		<ptr target="http://www.yxi.com/products.php" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Designing Modular Hardware Accelerators in C with ROCCC 2.0</title>
		<author>
			<persName><forename type="first">J</forename><surname>Villarreal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Najjar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Halstead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE FCCM</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="127" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Catapult: Product Family Overview</title>
		<ptr target="http://calypto.com/en/products/catapult/overview" />
		<imprint/>
		<respStmt>
			<orgName>Calypto Design Systems</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">C-to-Silicon Compiler</title>
		<ptr target="http://www.cadence.com/products/sd/siliconcompiler/pages/default.aspx" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">SPARK: A High-Level Synthesis Framework for Applying Parallelizing Compiler Transformations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nicolau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLSI Design</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="461" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Altium Designer: A Unified Solution</title>
		<author>
			<persName><surname>Altium</surname></persName>
		</author>
		<ptr target="http://www.altium.com/en/products/altium-designer" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">GAUT -High-Level Synthesis Tool from C to RTL</title>
		<ptr target="http://hls-labsticc.univ-ubs.fr/" />
		<imprint/>
		<respStmt>
			<orgName>Universite de Bretagne-Sud</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Trident: From High-Level Language to Hardware Circuitry</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Tripp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Gokhale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="28" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sea Cucumber: A Synthesizing Compiler for FPGAs</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Tripp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hutchings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FPL</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="875" to="885" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName><surname>Synopsys</surname></persName>
		</author>
		<author>
			<persName><surname>Synphony</surname></persName>
		</author>
		<author>
			<persName><surname>Compiler</surname></persName>
		</author>
		<ptr target="https://www.synopsys.com/Tools/Implementation/RTLSynthesis/Pp./SynphonyC-Compiler.aspx" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sivaraman. PICO (Program In, Chip Out): Automatically Designing Custom Computers</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kathail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Aditya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schreiber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cronquist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="39" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">BDTI High-Level Synthesis Tool Certification Program Results</title>
		<author>
			<persName><surname>Bdti</surname></persName>
		</author>
		<ptr target="http://www.bdti.com/Resources/BenchmarkResults/HLSTCP" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">AccelDSP Synthesis Tool</title>
		<author>
			<persName><surname>Xilinx</surname></persName>
		</author>
		<ptr target="http://www.xilinx.com/tools/acceldsp.htm" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">CHiMPS: A C-Level Compilation Flow for Hybrid CPU-FPGA Architectures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Putnam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dellinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Eggers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FPL</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="173" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">DEFACTO: A Design Environment for Adaptive Computing Technology</title>
		<author>
			<persName><forename type="first">Kiran</forename><surname>Bondalapati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Diniz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Granacki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heidi</forename><surname>Ziegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE RAW</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Maxeler</forename><surname>Technologies</surname></persName>
		</author>
		<author>
			<persName><surname>Maxcompiler</surname></persName>
		</author>
		<ptr target="https://www.maxeler.com/products/software/maxcompiler/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Kiwi: Synthesis of FPGA Circuits from Parallel Programs</title>
		<author>
			<persName><forename type="first">David</forename><surname>Greaves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satnam</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE FCCM</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title/>
		<ptr target="http://www.forteds.com/products/cynthesizer.asp" />
	</analytic>
	<monogr>
		<title level="j">Forte Design Systems. Cynthesizer</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Vivado Design Suite -VivadoHLS</title>
		<ptr target="http://www.xilinx.com/products/design-tools/vivado/index.htm" />
		<imprint>
			<publisher>Xilinx Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">High-Level Synthesis for FPGAs: From Prototyping to Deployment</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Neuendorffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Noguera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vissers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE TCAD</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="473" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">GCC2Verilog Compiler for Complete Translation of C Programming Language into</title>
		<author>
			<persName><forename type="first">Giang</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thi</forename><surname>Huong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seon</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Hdl</forename><surname>Verilog</surname></persName>
		</author>
		<title level="m">ETRI Journal</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="731" to="740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">L</forename><surname>Stok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Path Synthesis. Integration</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="71" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">System-Level Memory Optimization for High-Level Synthesis of Componentbased SoCs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Pilato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mantovani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Di</forename><surname>Guglielmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carloni</surname></persName>
		</author>
		<idno>IEEE CODES+ISSS</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Iterative Modulo Scheduling: An Algorithm for Software Pipelining Loops</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Rau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM MICRO</title>
		<imprint>
			<biblScope unit="page" from="63" to="74" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Swing Modulo Scheduling: A Lifetime-Sensitive Approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Llosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonzlez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ayguad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM PACT</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The Polyhedral Model Is More Widely Applicable Than You Think</title>
		<author>
			<persName><forename type="first">M</forename><surname>Benabderrahmane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pouchet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bastoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Compiler Construction</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="208" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Theory and Algorithm for Generalized Memory Partitioning in High-Level Synthesis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM FPGA</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="199" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Improving Polyhedral Code Generation for High-Level Synthesis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pouchet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
		<idno>IEEE CODES+ISSS</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Combining Computation and Communication Optimizations in System Synthesis for Streaming Applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM FPGA</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="213" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Multiplication by Rational Constants</title>
		<author>
			<persName><forename type="first">F</forename><surname>De Dinechin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TCAS II: Express Briefs</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="98" to="102" />
			<date type="published" when="2012-02">Feb 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Multiple Constant Multiplication with Ternary Adders</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kumm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hardieck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Willkomm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meyer-Baese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FPL</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Designing Custom Arithmetic Data Paths with FloPoCo</title>
		<author>
			<persName><forename type="first">F</forename><surname>De Dinechin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pasca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Design Test of Computers</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="18" to="27" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Exploiting Area/Delay Tradeoffs in High-Level Synthesis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kondratyev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lavagno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM DATE</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1024" to="1029" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Macro-Models for High Level Area and Power Estimation on Fpgas</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE GLSVLSI</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="162" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Balanced Scheduling and Operation Chaining in High-Level Synthesis for FPGA Designs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zaretsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ISQED</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="595" to="601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Fast and Effective Placement and Routing Directed High-Level Synthesis for FPGAs</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Gurumani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rupnow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM FPGA</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Incorporating Speculative Execution into Scheduling of Control-Flow Intensive Behavioral Descriptions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lakshminarayana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM DAC</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="108" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Conditional Speculation and Its Effects on Performance and Area for High-Level Synthesis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Savoiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nicolau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM ISSS</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="171" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Using Speculative Computation and Parallelizing Techniques to Improve Scheduling of Control Based Designs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cordone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ferrandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Santambrogio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Palermo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sciuto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM ASP-DAC</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="898" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A Gradual Scheduling Framework for Problem Size Reduction and Cross Basic Block Parallelism Exploitation in High-Level Synthesis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM ASP-DAC</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="780" to="786" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">From Software Threads to Parallel Hardware in High-Level Synthesis for FPGAs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE FPT</title>
		<imprint>
			<date type="published" when="2013-12">Dec. 2013</date>
			<biblScope unit="page" from="270" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Harnessing the Power of FPGAs Using Altera&apos;s OpenCL Compiler</title>
		<author>
			<persName><forename type="first">D</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Czajkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM FPGA</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="5" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Characterizing the Impact of Predicated Execution on Branch Prediction</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mahlke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Hank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Bringmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gyllenhaal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W-M</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE MICRO</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="217" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">The Benefit of Predicated Execution for Software Pipelining</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Warter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Lavery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-M</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hawaii International Conference on System Sciences</title>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Retargetable Code Optimization for Predicated Execution</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hohenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leupers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ascheid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Meyr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM DATE</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1492" to="1497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A Lightweight Speculative and Predicative Scheme for Hardware Execution</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V.-M</forename><surname>Sima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bertels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ReConFig</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName><forename type="first">Altera</forename><surname>Corp</surname></persName>
		</author>
		<title level="m">Stratix V FPGA Data Sheet</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m">Virtex-7 FPGA Data Sheet</title>
		<imprint>
			<publisher>Xilinx Inc</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Proposal and Quantitative Analysis of the CHStone Benchmark Program Suite for Practical C-based High-Level Synthesis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tomiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Honda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Takada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Processing</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="242" to="254" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
