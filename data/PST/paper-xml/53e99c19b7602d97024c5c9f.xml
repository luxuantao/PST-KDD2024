<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Composite Templates for Cloth Modeling and Sketching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hong</forename><surname>Chen</surname></persName>
							<email>hchen@stat.ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Departments of Statistics and Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Zi</roleName><forename type="first">Zi</forename><forename type="middle">Jian</forename><surname>Xu</surname></persName>
							<email>zjxu@stat.ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Departments of Statistics and Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departments of Statistics and Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Song</forename><forename type="middle">Chun</forename><surname>Zhu</surname></persName>
							<email>sczhu@stat.ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Departments of Statistics and Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Composite Templates for Cloth Modeling and Sketching</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5369B99E7738898888F1D37868356CDB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Cloth modeling and recognition is an important and challenging problem in both vision and graphics tasks, such as dressed human recognition and tracking, human sketch and portrait. In this paper, we present a context sensitive grammar in an And-Or graph representation which will produce a large set of composite graphical templates to account for the wide variabilities of cloth configurations, such as T-shirts, jackets, etc. In a supervised learning phase, we ask an artist to draw sketches on a set of dressed people, and we decompose the sketches into categories of cloth and body components: collars, shoulders, cuff, hands, pants, shoes etc. Each component has a number of distinct subtemplates (sub-graphs). These sub-templates serve as leafnodes in a big And-Or graph where an And-node represents a decomposition of the graph into sub-configurations with Markov relations for context and constraints (soft or hard), and an Or-node is a switch for choosing one out of a set of alternative And-nodes (sub-configurations) -similar to a node in stochastic context free grammar (SCFG). This representation integrates the SCFG for structural variability and the Markov (graphical) model for context. An algorithm which integrates the bottom-up proposals and the topdown information is proposed to infer the composite cloth template from the image.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">. Introduction</head><p>Modeling human clothes is an important and challenging problem in many vision tasks that involve recognition of dressed people in natural environments, such as detecting <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b10">11]</ref>, tracking <ref type="bibr" target="#b4">[5]</ref>, surveillance, HCI, identification, human sketch and portrait for graphics rendering <ref type="bibr" target="#b1">[2]</ref> etc. Despite intensive studies on the problems of "look at people" in the past decade, there is, to our best knowledge, no good model dedicated to realistic cloth modeling and recognition. The closest work that we can find are silhouette, contour, blob and region representations <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b3">4]</ref>. In graphics, physical based models <ref type="bibr" target="#b7">[8]</ref> are mostly used to create realistic visual effects of drapery and animation. Such models involve a large amount of polygons (mesh) and are very expensive. They do not account for the wide variability of cloth designs and are less relevant for the vision tasks mentioned above.</p><p>There are three major challenges in cloth representations.</p><p>1. Geometric deformations: clothes do not have static form and are very flexible.</p><p>2. Photometric variabilities: large variety of colors, shading effects, and textures.</p><p>3. Topological configurations: a combinatorial number of cloth designs -T-shirts, jackets, pockets, zips, suits, sweaters, coats where cloth components may be reconfigured and combined to yield new styles.</p><p>In this paper, we present a parsimonious yet expressive representation for clothes, motivated by the success of two sketch based methods. (i) Artists can draw concise sketches of clothes and human body that capture the most essential perceptual information <ref type="bibr" target="#b6">[7]</ref>. (ii) The recent primal sketch model <ref type="bibr" target="#b2">[3]</ref> -an attributed graph representation with a dictionary of image primitives aligned through landmarks -can reconstruct generic images with almost no perceptual distortions. We adopt a sketch graph representation like the primal sketch. Each stroke (long curves) of the sketch may correspond to (a) folds of clothes, (b) sewing lines, (c) occluding boundaries, and (d) shape outlines.</p><p>The geometric deformations of clothes are accounted for by the flexibility of the sketch graphs, and the photometric variabilities are accounted for by the rich image primitives whose parameters control the photometric variations. In the rest of the paper, we focus mostly on the study of topological configurations -a central theme in this paper, which has not been studied in the vision literature.</p><p>In a supervised learning phase, we collect a set of human images and sketches drawn by an artist. An example is shown in Fig 2 .a-b. We remove one layer of the strokes that corresponds to shading folds and textures (Fig. <ref type="figure" target="#fig_1">2</ref>.c). The remaining graph (Fig. <ref type="figure" target="#fig_1">2</ref>.d) is decomposed into a number of subgraphs for cloth components (Fig. <ref type="figure" target="#fig_1">2</ref>.e). All subgraphs across the dataset, together with their neighborhood, are grouped into categories for collars, shoulders, cuff, hands, pants, shoes and each has a number of possible structures (See Fig. <ref type="figure" target="#fig_2">4</ref>). These subgraphs have "bonds" that tell them who to link with to compose bigger structures (see Fig. <ref type="figure">6</ref>), and they are combined using the context information to form a wide variety of cloth configurations. For example, Fig. <ref type="figure">5</ref> shows three novel upper cloth configurations using some sub-templates in Fig. <ref type="figure" target="#fig_2">4</ref>.</p><p>A crucial technique problem is: how can these components be composed into valid clothes? What are the rigorous mathematical models to govern the computation?</p><p>To account for the topological configurations, we build an And-Or graph, which is widely used in AI search <ref type="bibr" target="#b8">[9]</ref>, as an overall representation of clothes. An example is illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. The And-Or graph is also used in the previous work <ref type="bibr" target="#b15">[16]</ref> to present an attributed grammar in a generic rectangle parsing problem. The And-Or graph for clothes are quite different and more complicated. Each terminal (leaf) node (squares 1 -11) represents a component or sub-templates. Different sub-templates in the same category are represented by distinct leaves. The non-terminal nodes are divided into And-nodes whose children must be chosen jointly and Or-nodes of which only one child can be selected to express the alternative components. Intuitively, an And-node expands the configuration and an Or-node is a switch between alternative sub-configurations. The And-Or graph should be distinguished from a tree because the graph has horizontal edges (dashed) to specify the spatial relations and constraints among the components. A specific cloth configuration, say a jacket, corresponds to a subset of the And-Or graph (see the dark nodes and arrows). Thus one And-Or graph is like a "mother template" which produces a set of valid cloth configurations -"composite templates". A composite template is made of a set of leaf nodes (subtemplates). For example, leaf nodes <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10)</ref> in Fig. <ref type="figure" target="#fig_0">1</ref> form a composite template. The spatial relations between the chosen leaf nodes are inherited from the And-Or graph. For example, the relation between nodes 1 and 6 is inherited from nodes B and C in Fig. <ref type="figure" target="#fig_0">1</ref>, and the relation between nodes 6 and 8 is inherited from nodes N and O. These relations help to link the subgraphs (components) together to form a valid representation. In fact, the And-Or graph embodies a context-sensitive grammar which can generate a rich set of composite templates to account for the variabilities of clothes. It is a novel representational scheme that has not been studied yet in the vision literature. We will define a probability model on the context sensitive grammar in later section.</p><p>In a computing and recognition phase, we first activate some sub-templates in a bottom-up step. For example, we can detect the face and skin color to locate the coarse position of some components, which help to predict the positions of other components by context. Then a top-down step is activated to match some sub-templates in various categories to the edge maps. The matched graphs are deformed through diffusion to the exact boundaries in the image. Overall computation follows the Bayesian inference.</p><p>The context sensitive grammar and composite graphical template is a general modeling framework. We used cloth modeling and recognition as an example. This framework is applicable to many other classes of objects, especially classes where object instances have wide variabilities in their configurations, such as cars/van/truck, buildings, furniture and scene settings.</p><p>The paper is organized as follows. We first present the And-Or graph theory in Section 2 and a probabilistic context sensitive grammar model in Section 3 to set the theoretical foundation. Then we show the cloth model in Section 4 as an example, and briefly discuss the inference algorithm in 5. Some results are presented in Section 6 which is followed by a discussion on future work in Section 7. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a). input image (b). artist sketch (c). folds/textures (d). structures (e). decomposition</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">. Composite graphical templates</head><p>Graphical templates are widely used in computer vision to model objects which have geometric deformation and photometric variabilities. A lot of object classes, such as clothes, have different topological configurations which cannot be modelled by a single graphical template. We propose to use a composite template to accommodate the topological variabilities, and we use the And-or graph as the overall representation of these composite graphical templates. The And-Or graph is a 5-tuple explained below.</p><formula xml:id="formula_0">G and-or =&lt; N = U ∪ V, T, Σ, R, A &gt; .</formula><p>(1)</p><p>1. Non-terminal nodes N includes a set of And-nodes</p><formula xml:id="formula_1">U = {u 1 , ..., u m(U ) )} and a set of Or-nodes V = {v 1 , ..., v m(V )</formula><p>}. An And-node u ∈ U represents a graph template which is composed of a set of sub-templates with certain relations r 1 , ..., r k ∈ R shown by the dashed horizontal lines in Fig. <ref type="figure" target="#fig_0">1</ref>. An Or-node v ∈ V is a switch pointing to a number (≥ 1) of alternative sub-configurations. We define a switch variable ω(v) for v ∈ V , that takes an integer value as an index to the chosen node. ω(v) = ∅ if v is not used in the final chosen configuration.</p><p>2. Terminal nodes T = {t 1 , ..., t m (T )} is a set of subtemplates g i representing object components for clothes, such as collars, pockets, hands, etc, as shown in Fig. <ref type="figure">3</ref>.</p><p>Each g i is a sketch graph where the sketch contours (strokes) are divided into many short segments and are connected by junctions. Both short segments and junctions are represented as vertices in g i . Endpoints are 1-degree vertices, segments in the middle of contours are 2-degree vertices, and junctions have 3-4 degrees. Each vertex corresponds to an image primitive <ref type="bibr" target="#b2">[3]</ref>, such as step edge, bar, ridge, etc. We denote by x a vertex in g i , f an edge in g i , and Λ i the image domain covered by g i ,</p><formula xml:id="formula_2">g i = ({x i1 , ..., x ik(i) }, {f mn =&lt; x im , x in &gt;}, Λ i ). (2)</formula><p>3. Configurations Σ is a finite set of valid composite templates,</p><formula xml:id="formula_3">Σ = {G j = (g j,1 , ..., g j,m(j) ) : j = 1, 2, ..., M }. (3)</formula><p>Each graph G ∈ Σ is a specific configuration for the object, such as a suit, a jacket or a T-shirt. For example G = (1, 6, 8, 10) is a configuration in Fig. <ref type="figure" target="#fig_0">1</ref> (bottom). The spatial relations/constraints between these leaves are inherited from their parents in the graphs. For example, the relation between node 6 and node 8 are inherited from nodes N and O. The And-Or graph in Fig. <ref type="figure" target="#fig_0">1</ref> contains a combinatorial number of valid configurations, e.g. <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10)</ref>, <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b10">11)</ref>, <ref type="bibr" target="#b1">(2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9)</ref>, ...} (4)</p><formula xml:id="formula_4">Σ = {</formula><p>The number of nodes may vary as well as the graphical structures. Fig. <ref type="figure">5</ref> shows three novel upper cloth configurations generated by the And-Or graph of clothes.</p><p>4. R is a set of relations between Or-nodes or subgraphs.</p><formula xml:id="formula_5">R = {r ij =&lt; v i , v j &gt;: v i , v j ∈ V }. (<label>5</label></formula><formula xml:id="formula_6">)</formula><p>Figure <ref type="figure">3</ref>. The And-Or graph for arms.</p><p>These relations become the pair-cliques in the composite graphical template. When a node v i is split later, the relation r ij will be split as well. For example, in Fig. <ref type="figure" target="#fig_0">1</ref> node C is split into two leaf nodes 6 and 8, then the relation &lt; B, C &gt; is split into two subsets between 1-6 and 1-8,</p><formula xml:id="formula_7">&lt; B, C &gt;=&lt; 1, 6 &gt; ∪ &lt; 1, 8 &gt; . (<label>6</label></formula><formula xml:id="formula_8">)</formula><p>5. Attributes A is a set of photometric and geometric transforms applied to the sub-templates g i on the leaf nodes t i ∈ T, i = 1, ..., m(T ).</p><formula xml:id="formula_9">A = {(A pho i , A geo i ) : i = 1, 2, ..., m(T )}.<label>(7)</label></formula><p>The photometric attributes A pho i is a vector -the type of intensity/color profiles and their contrasts -for the primitives of the vertices x i1 , ..., x ik(i) in sub-graph g i . The geometric transforms include affine transform A i = (T x, T y, s, θ) for the whole subgraph g i and warping (deformation or displacement) (ξ ij , η ij ) for each vertex.</p><formula xml:id="formula_10">A geo i = (A i , (ξ i1 , η i1 ), ..., (ξ in(i) , η ik(i) )).<label>(8)</label></formula><p>The photometric and geometrical transforms, together with the topological variations construct a very rich set of composite (attributed) templates, and the graph matching algorithm in later section will be defined on the photometric, geometric, and topological distances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">. Context sensitive grammar models</head><p>Stochastic context free grammars (SCFG) were introduced to vision in <ref type="bibr" target="#b0">(Fu, 1981)</ref> <ref type="bibr" target="#b0">[1]</ref>, and are equivalent to the Markov tree model. Such grammar models suffer a major problem that they cannot pass global and context information among nodes. For example, they cannot put a constraint that a face consists of 2 (not 3 or 4) nearly symmetric eyes. The context information is best described by graphic templates <ref type="bibr">(Yuille 1991)</ref> <ref type="bibr" target="#b12">[13]</ref> and Markov random fields (MRF) on graphs. But a fixed template cannot account for the structural variabilities. The And-Or graphs integrate both representations.</p><p>The And-Or graph presented in the previous section is a combination of a Markov tree and Markov random fields. Each And-node is a graphic (MRF) template model, and each Or-node is a switch node in the Markov tree (SCFG). As a matter of fact, each And-Or graph G =&lt; U ∪ V, T, Σ, R, A &gt; is a context sensitive grammar <ref type="bibr" target="#b9">[10]</ref> where T is the vocabulary, U and V are two types of production rules (U for graph expansion with relation R and V for graph switches), Σ is a language (sentences) generated by these rules, and A is the photometric and geometric attributes associated with the vocabulary. It can generate a large set of configurations (sentences) like the SCFG, and at the same time each configuration G ∈ Σ carries the context and Markov constraints (soft or hard) in a graphic model.</p><p>The context sensitive grammar will be useful for many vision tasks. Cloth modeling in the this paper is just one example. In the following, we define a probabilistic model p on top of the composite graphical templates Σ for modeling and inference.</p><p>Let G ∈ Σ(G) be a composite template. It has the following constituents.</p><p>1.</p><p>V (G) = {v 1 , ..., v m } is a set of Or-nodes (switches) that are used in configuring G. For instance, V (G) = {B, C, D, N, O} in Fig. <ref type="figure" target="#fig_0">1</ref> for the configuration G =(1,6,8,10).</p><p>2. T (G) = {t 1 , ..., t n } is the leaf nodes in configuration G, such as <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10)</ref> in Fig. <ref type="figure" target="#fig_0">1</ref> . Each is a subgraph g i (t i ), i = 1, 2, ..., n.</p><p>3. R(G) = {r i,j =&lt; g i , g j &gt;} is the set of relations defined on terminal sub-templates inherited from the And-Or graph G. Each is a pair-clique and g i and g j are both terminal node in the And-Or graph.</p><p>4. S(G) is the photometric and geometric transforms applied to the subgraphs g i , i = 1, 2, .., n.</p><p>The probability for G is</p><formula xml:id="formula_11">p(G; G) = 1 Z(G) exp{-E(G)}<label>(9)</label></formula><formula xml:id="formula_12">E(G) = v∈V E v (ω(v))+ t i ∈T (G) E(g i )+ r i,j ∈R(G) E(g(v i ), g(v j )).</formula><p>(10) The first term in the energy E is the same as the SCFG. It assigns different weights to the switch variables ω(v) at the or-nodes v, and each accounts for how frequently an And-node appears. Removing the 2nd and 3rd terms, this reduces to a SCFG.</p><p>The second and third terms are typical singleton and pair-clique energy defined on the graph G after the switch variables are decided. The second term is the prior model of the geometric and photometric transformations applied to the sub-template. The third term models the compatibility constraint, such as the spatial constraint between subtemplates. We will give the detailed energy of cloth modelling in following section.</p><p>In the above model, the partition function is related to the and-Or graph G and is common to all graph configurations in Σ(G).</p><formula xml:id="formula_13">Z(G) = G∈Σ(G) exp{-E(G)}. (<label>11</label></formula><formula xml:id="formula_14">)</formula><p>Because of a common Z, we no longer need to worry about computing the partition function or ratio when we switch between different configurations G ↔ G in the inference phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">. Composite models of clothes</head><p>We take 50 training images of college students sitting in a high chair with good light conditions and uniform background to exclude occlusions and bad illuminations. Gesture, illuminations and background clutter are other difficult problems that are beyond the scope of this paper. This paper is focused on modeling the variability of cloth configurations. An artist is paid (in hourly rate) to draw the sketches in Adobe illustrator. She is asked to make the sketches as consistent as possible across the training images.</p><p>As Fig. <ref type="figure" target="#fig_1">2</ref> shows, we first manually separate a layer of sketches corresponding to shading folds and textures (e.g. shoe lace, text printed on T-shirt). Then we decompose the remaining structures (Fig. <ref type="figure" target="#fig_1">2</ref>.d) into a number of subtemplates: hair, face, collar, shoulder, upper and lower arms, cuff, hands, pants, shoes, and pocket. Fig. <ref type="figure" target="#fig_2">4</ref> shows some examples for each category.</p><p>With these categories, we construct an And-Or graph to account for the variability of configurations. For an example, we shown the And-Or graph of arms in Fig. <ref type="figure">3</ref>. Intuitively, the And-Or graph is like a "mother template" which can produce a large set of configurations, three of which are shown in Fig. <ref type="figure">5</ref>.</p><p>For each terminal node, we assume uniform probability for choosing the primitives and intensity profile and put a Thin Plate Spline (TPS) model to regularize the warping (deformation controlled by the warping on the vertices) (ξ, η) of subgraphs g i on domain Λ i . Therefore, the singleton E(g i ) in Eqn.10 is defined by,</p><formula xml:id="formula_15">E(g i ) = Λi ξ 2 xx + ξ 2 xy + ξ 2 yy + η 2 xx + η 2 xy + η 2 yy dxdy. (<label>12</label></formula><formula xml:id="formula_16">)</formula><p>We define a set of "bonds" for each sub-template. They are used to link the corresponding "bonds" in neighbor parts, such as the torso and upper arm or the upper arm and the forearm. Let's denote the set of all connection of "bonds" between sub-template g i and g j as B i,j . Then, the pair-clique term is defined as</p><formula xml:id="formula_17">E(g i , g j ) = d(A i , A j ) + &lt;β ik ,β jl &gt;∈Bi,j d(x(β ik ), x(β jl )).</formula><p>, where the first term is used to enforce consistence of the affine transforms of the two sub-templates.</p><formula xml:id="formula_18">d(A i , A j ) = λ s (log(s i /s j )-α s ) 2 +λ θ sin((θ i -θ j -α θ )/2) 2 .</formula><p>,where s, θ are the affine transformation parameters for each part, and λ s , α s , λ θ , α θ are learned parameters.</p><p>The second term is used to enforce the corresponding "bonds" between neighboring parts, which are connected with each other.</p><p>The likelihoods are models from sub-template g i with domain Λ i to the image patch I Λ i . The likelihood model is</p><formula xml:id="formula_19">p(I Λ |G; ∆) = gi∈T (G) p(I Λi |g i ; ∆ i ),<label>(13)</label></formula><p>where ∆ = {∆ 1 , ..., ∆ N } is the set of all image primitives <ref type="bibr" target="#b2">[3]</ref> associated with the templates. Within each domain Λ i , some pixels are covered by the image primitives (for vertices) and the remaining part are filled in by MRF models as in the primal sketch <ref type="bibr" target="#b2">[3]</ref>. People who are not familiar with the primal sketch should think of it like inpainting. The background, which is not covered by our templates, is modeled as uniform Gaussian noise. For each template, we will record the following attributes: (a) the type of boundary, (b) ownership (which side owns an occluding boundary), (c) the intensity profiles and types of image primitives, (d) region model (illustrated by a-b-c in Fig. <ref type="figure">6</ref>). Since the likelihood model for graphical templates are straightforward, we choose not to unfold its details due to space limits. The parameters in the above models are learned independently from the set of training examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">. Bottom-up and top-down inference</head><p>Given the prior model with all the descriptions G and the generative likelihood model, the objective of the inference algorithm is to compute the best graph configuration G ∈ Σ(G) for a test image I,</p><formula xml:id="formula_20">G * = arg max G∈Σ(G) p(I Λ |G; ∆)p(G). (<label>14</label></formula><formula xml:id="formula_21">)</formula><p>The inference is done in a spirit similar to the DDMCMC image parsing <ref type="bibr" target="#b11">[12]</ref> which combine the bottom-up and topdown computation.</p><p>Bottom-up data driven proposals (discriminative tests) are designed for all nodes in the And-Or graph. Some nodes are more informative and thus can be detected more reliably, such as the face. Other nodes are less informative. For instance, the elbow is hard to infer when the arm is straight. It is also desirable to infer the nodes from coarse-to-fine. For example, the leaf nodes have many sub-templates which should be activated after their positions are located (predicted) from the parent nodes in the higher level of the And-Or graph. We carefully design the order of the bottomup and top-down computation so that the more informative nodes are proposed and inferred earlier, and they in turn generate useful top-down/context information for computing the other less informative nodes. Fig. <ref type="figure" target="#fig_4">7</ref> shows an example of our bottom-up and top-down inference. We do face detection as shown in Fig. <ref type="figure" target="#fig_4">7</ref>.(c). To locate the torso, we use an ASM (Active Shape Model) <ref type="bibr" target="#b16">[17]</ref> type of model. We define a common shape template for the key points of the torso as the red points in Fig. <ref type="figure" target="#fig_4">7</ref>.(c). We apply PCA to the shape and model the prior of shape as a Gaussian distribution in the reduced dimension. With the position of the face, and the relative position model of torso and face, we randomly sample some shapes to use as the initialization of the ASM searching algorithm. Using the same method, we build shape models for upper arms and forearms. Note in Fig. <ref type="figure">3</ref>, there are two distinct configurations of the forearms. We use a mixture model for the two distinct configurations of forearms: separated or crossed. After locating these body parts with bottom-up methods, we obtain an overall proposal for body parts as shown in Fig. <ref type="figure" target="#fig_4">7(c</ref>). The face rectangle is used as the initialization of the skin region, and combined with the results of mean shift clustering, we get the skin region as in Fig. <ref type="figure" target="#fig_4">7.(d)</ref>.</p><p>With the coarse positions of the human parts, we start the top-down graph matching process. Each non-terminal node at the bottom of the And-Or graph has a number of leaf nodes (see Fig. <ref type="figure">3</ref>) which correspond to a set of subtemplates (subgraphs). Each sub-template is a subgraph with photometric and geometric transformation parameters. Deformable Template matching is well studied, especially with good initialization. For each candidate sub-template, we match it to the image with the thin-plate spline prior (defined in the prior terms in eqn.( <ref type="formula" target="#formula_15">12</ref>)) with iterated closest point algorithm (TPS-ICP) <ref type="bibr" target="#b13">[14]</ref>. The best matched subtemplate is selected by comparing the posterior probability. Although the TPS-ICP algorithm is a locally optimal algorithm, the likelihood models with region information in the sub-templates are quite robust. An example of the fitting result is shown in Fig. <ref type="figure" target="#fig_4">7</ref>.(e).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">. Experiments</head><p>We applied our algorithms to two sets of images. One set is in Fig. <ref type="figure" target="#fig_5">8</ref>, and another set is in Fig. <ref type="figure" target="#fig_6">9</ref>. For each testing image, as in Fig. <ref type="figure" target="#fig_4">7</ref>, we first infer the body gesture at the parts layer, then infer the composite graphical template. As we can see, the whole hand is represented by one or two subtemplates. We are not computing the fingers individually which seems an impractical task. In case a hand in the test image has a different configuration from the sub-templates in our training set, we choose the closest match. It is interesting to observe that human vision is apparently not very sensitive to subtle differences.</p><p>As shown in Fig. <ref type="figure" target="#fig_5">8</ref> and Fig. <ref type="figure" target="#fig_6">9</ref>, these graphical sketches are quite nice for they are generated from the artist's templates. One can use such results in many applications, such as cartoon animation, human portraits, and video communication in narrow band devices.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">. Discussion</head><p>The main contribution of this paper is the And-Or graph representation as a rigorous matching model for generating a set of composite graphical templates in a principled way, in contrast of the graphical (MRF) models/template of fixed structure widely used in the literature. This representation embodies the context sensitive grammar model which was never used in the vision literature before, despite the fact that people have long desired such a model. We used cloth modeling and recognition as an example, however the framework is generally applicable to many other classes of objects, especially classes where object instances have wide variabilities in their configurations.</p><p>Due to space limit, we cannot unfold many details on graph matching and the likelihood models, which are, in our opinion, straightforward and not new in this paper. We refer to the literature for existing work on graph matching and primal sketch <ref type="bibr" target="#b2">[3]</ref> for likelihood models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. An illustration of the And-Or graph representation. The dark arrows and shaded nodes represent a composition of 4 leaf nodes (1,6,8,10) each being a sub-template. This generates a composite graphical template (at the bottom) representing the specific cloth configuration with the spatial relations (context) inherited from the And-Or graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. An example of training the model. (a) Cloth image, (b) artist's sketch, (c) a layer of sketches for shading folds and texture (e.g. shoe lace, text on shirt etc), (d) remaining sketch graph for structures and sewing lines, (e) decomposed from (d) to sub-templates for components.</figDesc><graphic coords="3,47.34,74.16,98.02,195.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The categories for cloth components and each category consists of a set of sub-templates used as leaf nodes in the And-Or graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .Figure 6 .</head><label>56</label><figDesc>Figure 5. Three novel configurations composed of 6,5,7 subtemplates in the categories respectively. The bonds are shown by the red dots.</figDesc><graphic coords="6,107.05,217.71,126.94,104.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Running example. (a) input image, (b) Canny edge map, (c) bottom-up detection of face and body parts, (d) skin color detection by mean-shift clustering in color space, (e) results of top-down matching.</figDesc><graphic coords="7,237.94,47.58,136.40,182.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Some recognition results of upper body with clothes. The input images are shown in the first row. The third row shows the composite graphical templates inferred from the images. For comparison, the results of a canny edge detector are shown in the middle row.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. More recognition results of upper body with clothes. The results are the composite graphical templates inferred from the images.</figDesc><graphic coords="8,52.81,72.01,489.65,214.50" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work is supported by grants ONR N-0014-05-1-0543, NSF IIS-0413214 and Kodak Fellowship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Fu</surname></persName>
		</author>
		<title level="m">Syntactic Pattern Recognition and Applications</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Example-Based Composite Sketching of Human Portraits</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Shum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Salesin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Int&apos;l Symp. NPAR</title>
		<meeting>3rd Int&apos;l Symp. NPAR</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="95" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A mathematical theory for primal sketch and sketchability</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Probabilistic methods for finding people</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">68</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Human upper body pose estimation in static images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<title level="m">Dressed Human Modeling, Detection, and Parts Localization</title>
		<imprint>
			<date type="published" when="2001-07">July, 2001</date>
		</imprint>
		<respStmt>
			<orgName>CMU</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D Dissertation</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The Natural Way to Draw</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nicolaides</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1941">1941</date>
			<publisher>Houghton Mifflin Co. Boston</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Computer Graphics Techniques for Modeling Cloth</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="28" to="42" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Heuristics: Intelligent Search Strategies for Computer Problem Solving</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A parsing algorithm for context sensitive graph grammars</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rekers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schürr</surname></persName>
		</author>
		<idno>TR-95-05</idno>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>Leiden Univ</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to parse pictures of people</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ronfard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Image parsing: unifying segmentation, detection, and recognition</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">W</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Feature extraction from faces using deformable templates</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hallinan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="99" to="111" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A new algorithm for non-rigid point matching</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning to estimate human pose with data-driven belief propagation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Buttom-up/Top-down image parsing by attribute graph grammar</title>
		<author>
			<persName><forename type="first">F</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Statistical models of appearance for computer vision</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Univ. of Manchester, U.K.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
