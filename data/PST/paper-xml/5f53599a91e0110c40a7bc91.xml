<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LEARNING FROM PROTEIN STRUCTURE WITH GEO-METRIC VECTOR PERCEPTRONS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<title level="a" type="main">LEARNING FROM PROTEIN STRUCTURE WITH GEO-METRIC VECTOR PERCEPTRONS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning on 3D structures of large biomolecules is emerging as a distinct area in machine learning, but there has yet to emerge a unifying network architecture that simultaneously leverages the geometric and relational aspects of the problem domain. To address this gap, we introduce geometric vector perceptrons, which extend standard dense layers to operate on collections of Euclidean vectors. Graph neural networks equipped with such layers are able to perform both geometric and relational reasoning on efficient representations of macromolecules. We demonstrate our approach on two important problems in learning from protein structure: model quality assessment and computational protein design. Our approach improves over existing classes of architectures on both problems, including state-ofthe-art convolutional neural networks and graph neural networks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Many efforts in structural biology aim to predict, or derive insights from, the structure of a macromolecule (such as a protein, RNA, or DNA), represented as a set of positions associated with atoms or groups of atoms in 3D Euclidean space. These problems can often be framed as functions mapping the input domain of structures to some property of interest-for example, predicting the quality of a structural model or determining whether two molecules will bind. Thanks to their importance and difficulty, such problems, which we broadly refer to as learning from structure, have recently developed into an exciting and promising application area for deep learning <ref type="bibr" target="#b11">(Graves et al., 2020;</ref><ref type="bibr" target="#b16">Ingraham et al., 2019;</ref><ref type="bibr" target="#b24">Pereira et al., 2016;</ref><ref type="bibr" target="#b29">Townshend et al., 2019;</ref><ref type="bibr" target="#b33">Won et al., 2019)</ref>. Successful applications of deep learning are often driven by techniques that leverage the problem structure of the domain-for example, convolutions in computer vision <ref type="bibr" target="#b6">(Cohen &amp; Shashua, 2017)</ref> and attention in natural language processing <ref type="bibr" target="#b31">(Vaswani et al., 2017)</ref>. What are the relevant considerations in the domain of learning from structure? Using proteins as the most common example, we have on the one hand the arrangement and orientation of the amino acids in space, which govern the dynamics and function of the molecule <ref type="bibr" target="#b3">(Berg et al., 2002)</ref>. On the other hand, proteins also possess relational structure in terms of their amino-acid sequence and the residue-residue interactions that mediate the aforementioned protein properties <ref type="bibr" target="#b13">(Hammes-Schiffer &amp; Benkovic, 2006)</ref>. We refer to these as the geometric and relational aspects of the problem domain, respectively.</p><p>Recent state-of-the-art methods for learning from structure are successful by leveraging one of these two aspects. Commonly, such methods either employ graph neural networks (GNNs), which are expressive in terms of relational reasoning <ref type="bibr" target="#b2">(Battaglia et al., 2018)</ref>, or convolutional neural networks (CNNs), which operate directly on the geometry of the structure. Here, we present a unifying architecture that bridges these two families of methods to leverage both aspects of the problem domain.</p><p>We do so by introducing geometric vector perceptrons (GVPs), a drop-in replacement for standard multi-layer perceptrons (MLPs) in aggregation and feed-forward layers of GNNs. GVPs operate directly on both scalar and geometric features-features that transform as a vector under a rotation of spatial coordinates. GVPs therefore allow for the embedding of geometric information at nodes and edges without reducing such information to scalars that may not fully capture complex geometry. We postulate that our approach makes it easier for a GNN to learn functions whose significant features are both geometric and relational.</p><p>Our method (GVP-GNN) can be applied to any problem where the input domain is a structure of a single macromolecule or of molecules bound to one another. In this work, we specifically demonstrate our approach on two problems connected to protein structure: model quality assessment and computational protein design. Model quality assessment (MQA) aims to select the best structural model of a protein from a large pool of candidate structures and is a crucial step in protein structure prediction <ref type="bibr" target="#b5">(Cheng et al., 2019)</ref>. Computational protein design (CPD) is the conceptual inverse of structure prediction, aiming to infer an amino acid sequence that will fold into a given structure. Our method outperforms existing methods on both tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>ML methods for learning from protein structure largely fall into one of three types, operating on sequential, voxelized, or graph-structured representations of proteins. We briefly discuss each type and introduce state-of-the-art examples for MQA and CPD to set the stage for our experiments later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sequential representations</head><p>In traditional models of learning from protein structure, each amino acid is represented as a feature vector using hand-crafted representations of the 3D structural environment. These representations include residue contacts <ref type="bibr" target="#b22">(Olechnovič &amp; Venclovas, 2017)</ref>, orientations or positions collectively projected to local coordinates <ref type="bibr" target="#b17">(Karasikov et al., 2019)</ref>, physicsinspired energy terms <ref type="bibr" target="#b21">(O'Connell et al., 2018;</ref><ref type="bibr" target="#b30">Uziela et al., 2017)</ref>, or context-free grammars of protein topology <ref type="bibr" target="#b12">(Greener et al., 2018)</ref>. The structure is then viewed as a sequence or collection of such features which can be fed into a 1D convolutional network, RNN, or dense feedforward network. Although these methods only indirectly represent the full 3D structure of the protein, a number of them, such as ProQ4 <ref type="bibr" target="#b15">(Hurtado et al., 2018)</ref>, VoroMQA <ref type="bibr" target="#b22">(Olechnovič &amp; Venclovas, 2017)</ref>, and SBROD <ref type="bibr" target="#b17">(Karasikov et al., 2019)</ref>, are competitive in assessments of MQA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Voxelized representations</head><p>In lieu of hand-crafted representations of structure, 3D convolutional neural networks (CNNs) can operate directly on the positions of atoms in space, encoded as occupancy maps in a voxelized 3D volume. The hierarchical convolutions of such networks are easily compatible with the detection of structural motifs, binding pockets, and the specific shapes of other important structural features, leveraging the geometric aspect of the domain. The MQA methods 3DCNN <ref type="bibr" target="#b9">(Derevyanko et al., 2018)</ref> and Ornate <ref type="bibr" target="#b23">(Pagès et al., 2019)</ref> and a number of CPD methods <ref type="bibr" target="#b0">(Anand et al., 2020;</ref><ref type="bibr" target="#b35">Zhang et al., 2019;</ref><ref type="bibr" target="#b26">Shroff et al., 2019)</ref> exemplify the power of this approach.</p><p>Graph-structured representations A protein structure can also be represented as a proximity graph over amino acid nodes, reducing the challenge of representing a collective structural neighborhood in a single feature vector to that of representing individual edges. Graph neural networks (GNNs) can then perform complex relational reasoning over structures <ref type="bibr" target="#b2">(Battaglia et al., 2018)</ref>-for example, identifying key relationships among amino acids, or flexible structural motifs described as a connectivity pattern rather than a rigid shape. Recent state-of-the-art GNNs include GraphQA <ref type="bibr" target="#b1">(Baldassarre et al., 2020)</ref> on MQA, Structured Transformer <ref type="bibr" target="#b16">(Ingraham et al., 2019)</ref> on CPD, and ProteinSolver <ref type="bibr" target="#b27">(Strokach et al., 2020)</ref> on CPD and mutation stability prediction. These methods vary in their representation of geometry: while some, such as GraphQA and ProteinSolver, represent edges as a function of their length, others, such as Structured Transformer, indirectly encode the 3D geometry of the proximity graph in terms of relative orientations and other scalar features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>Our architecture seeks to combine the strengths of CNN and GNN methods in learning from biomolecular structure by improving the latter's ability to reason geometrically. The GNNs described in the previous section encode the 3D geometry of the protein by encoding vector features (such as node orientations and edge directions) in terms of rotation-invariant scalars, often by defining a local coordinate system at each node. We instead propose that these features be directly represented as geometric vectors-features in R 3 which transform appropriately under a change of spatial coordinates-at all steps of graph propagation.</p><p>This conceptual shift has two important ramifications. First, the input representation is more efficient: instead of encoding the orientation of a node by its relative orientation with all of its neighbors, we only have to represent one absolute orientation per node. Second, it standardizes a global coordinate system across the entire structure, which allows geometric features to be directly propagated without transforming between local coordinates. For example, representations of arbitrary positions in space-including points that are not themselves nodes-can be easily propagated across the graph by Euclidean vector addition. We postulate this allows the GNN to more easily access global geometric properties of the structure. The key challenge with this representation, however, is to perform graph propagation in a way that simultaneously preserves the full expressive power of the original GNN while maintaining the rotation invariance provided by the scalar representations. We do so by introducing a new module, the geometric vector perceptron, to replace dense layers in a GNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">GEOMETRIC VECTOR PERCEPTRONS</head><p>The geometric vector perceptron is a simple module for learning vector-valued and scalar-valued functions over geometric vectors and scalars. That is, given a tuple (s, V) of scalar features s ∈ R n and vector features V ∈ R ν×3 , we compute new features (s , V ) ∈ R m × R µ×3 . The computation is formally described in Algorithm 1 and illustrated in Figure <ref type="figure">1A</ref>.</p><p>At its core, the GVP consists of two separate linear transformations W m , W h for the scalar and vector features, followed by nonlinearities σ, σ + . However, before the scalar features are transformed, we concatenate the L 2 norm of the transformed vector features V h ; this allows us to extract rotation-invariant information from the input vectors V. An additional linear transformation W µ is inserted just before the vector nonlinearity to control the output dimensionality independently of the number of norms extracted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Geometric vector perceptron</head><p>Input: Scalar and vector features (s, V) ∈ R n × R ν×3 . Output: Scalar and vector features</p><formula xml:id="formula_0">(s , V ) ∈ R m × R µ×3 . h ← max (ν, µ) GVP: V h ← W h V ∈ R h×3 V µ ← W µ V h ∈ R µ×3 s h ← V h 2 (row-wise) ∈ R h v µ ← V µ 2 (row-wise) ∈ R µ s h+n ← concat (s h , s) ∈ R h+n s m ← W m s h+n + b ∈ R m s ← σ (s m ) ∈ R m V ← σ + (v µ ) V µ , (row-wise multiplication) ∈ R µ×3 return (s , V )</formula><p>The GVP is conceptually simple, yet provably possesses the desired properties of invariance/equivariance and expressiveness. First, the vector and scalar outputs of the GVP are equivariant and invariant, respectively, with respect to an arbitrary composition R of rotations and reflections in 3D Euclidean space -i.e., if GVP(s,</p><formula xml:id="formula_1">V) = (s , V ) then GVP(s, R(V)) = (s , R(V ))</formula><p>(1) This is due to the fact that the only operations on vector-valued inputs are scalar multiplication, linear combination, and the L 2 norm. <ref type="foot" target="#foot_0">1</ref> We include a formal proof in Appendix A.</p><p>In addition, a GVP can approximate any continuous rotation-and reflection-invariant scalar-valued function of V. More precisely, let G s be a GVP defined with n, µ = 0-that is, the part of a GVP that transforms vector features to scalar features. Then G s is able to -approximate any function F : R ν×3 → R that is invariant with respect to rotations and reflections in 3D under mild assumptions. Theorem. Let R describe an arbitrary rotation and/or reflection in R 3 . For ν ≥ 3 let Ω ν ⊂ R ν×3 be the set of all V = [v 1 , . . . , v ν ]</p><p>T ∈ R ν×3 such that v 1 , v 2 , v 3 are linearly independent and 0 &lt; ||v i || 2 ≤ b for all i and some finite b &gt; 0. Then for any continuous F : Ω ν → R such that F (R(V)) = F (V) and for any &gt; 0, there exists a form f (</p><formula xml:id="formula_2">V) = w T G s (V) such that |F (V) − f (V)| &lt; for all V ∈ Ω ν .</formula><p>Figure <ref type="figure">1</ref>: (A) Schematic of the geometric vector perceptron illustrating Algorithm 1. Given a tuple of scalar and vector input features (s, V), the perceptron computes an updated tuple (s , V ). s is a function of both s and V. (B) Illustration of the structure-based prediction tasks. In model quality assessment (top), the goal is to predict a quality score given the 3D structure of a candidate model. Individual atoms are represented as colored spheres. The quality score measures the accuracy of a candidate structure with respect to an experimentally determined structure (shown in gray). In computational protein design (bottom), the goal is to predict an amino acid sequence that would fold into a given protein backbone structure.</p><p>We include a formal proof in Appendix A. As a corollary, a GVP with nonzero n, µ is also able to approximate similarly-defined functions over the full input domain R n × R ν×3 .</p><p>In addition to the GVP layer itself, we use a version of dropout that drops entire vector channels at random (as opposed to coordinates within vector channels). We also introduce layer normalization for the vector features as</p><formula xml:id="formula_3">V ← V/ 1 ν V 2 2 ∈ R ν×3<label>(2)</label></formula><p>That is, we scale the row vectors of V such that their root-mean-square norm is one. This vector layer norm has no trainable parameters, but we continue to use normal layer normalization on scalar channels with trainable parameters γ, β.</p><p>We study our hypothesis that GVPs augment the geometric reasoning ability of GNNs on a synthetic dataset (Appendix B). The synthetic dataset allows us to control the function underlying the groundtruth label in order to explicitly separate geometric and relational aspects in different tasks. The GVP-augmented GNN (or GVP-GNN) matches a CNN on a geometric task and a standard GNN on a relational task. However, when we combine the two tasks in one objective, the GVP-GNN does significantly better than either a GNN or a CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">REPRESENTATIONS OF PROTEINS</head><p>The main empirical validation of our architecture is its performance on two real-world tasks: model quality assessment (MQA) and computational protein design (CPD). These tasks, as illustrated in Figure <ref type="figure">1B</ref> and described in detail in Section 4, are complementary in that one (MQA) predicts a global property and the other (CPD) predicts a property for each amino acid.</p><p>We represent a protein structure input as a proximity graph with a minimal number of scalar and vector features to fully specify the 3D structure of the molecule. A protein structure is a sequence of amino acids, where each amino acid consists of four backbone atoms<ref type="foot" target="#foot_1">2</ref> and a set of sidechain atoms located in 3D Euclidean space. Here we represent only the backbone because our MQA benchmark corresponds to the assessment of backbone structure. In CPD, the sidechains are by definition unknown.</p><p>Let X i be the position of atom X in the ith amino acid (e.g. N i is the position of the nitrogen atom in the ith amino acid). We represent backbone structure as a graph G = (V, E) where each node v i ∈ V corresponds to an amino acid and has embedding h</p><formula xml:id="formula_4">(i)</formula><p>v with the following features:</p><p>• Scalar features {sin, cos} • {φ, ψ, ω}, where φ, ψ, ω are the dihedral angles computed from C i−1 , N i , Cα i , C i , and N i+1 . • The forward and reverse unit vectors in the directions of Cα i+1 − Cα i and Cα i−1 − Cα i , respectively. • The unit vector in the imputed direction of Cβ i − Cα i .<ref type="foot" target="#foot_2">3</ref> This is computed by assuming tetrahedral geometry and normalizing</p><formula xml:id="formula_5">1 3 (n × c)/||n × c|| 2 − 2 3 (n + c)/||n + c|| 2</formula><p>where n = N i − Cα i and c = C i − Cα i . This vector, along with the forward and reverse unit vectors, unambiguously define the orientation of each amino acid residue. • A one-hot representation of amino acid identity, when available.</p><p>The set of edges is E = {e i→j } i =j for all i, j where v i is among the k = 30 nearest neighbors of v j as measured by the distance between their Cα atoms. Each edge has an embedding h (i→j) e with the following features:</p><p>• The unit vector in the direction of Cα i − Cα j .</p><p>• The encoding of the distance ||Cα i − Cα j || 2 in terms of Gaussian radial basis functions. <ref type="foot" target="#foot_3">4</ref>• A sinusoidal encoding of i − j as described in <ref type="bibr" target="#b31">Vaswani et al. (2017)</ref>, representing distance along the backbone.</p><p>In our notation, each feature vector h is a concatenation of scalar and vector features as described above. Collectively, these features are sufficient for a complete description of the protein backbone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">NETWORK ARCHITECTURE</head><p>Our architecture (GVP-GNN) leverages message passing <ref type="bibr" target="#b10">(Gilmer et al., 2017)</ref> in which messages from neighboring nodes and edges are used to update node embeddings at each graph propagation step. More explicitly, the architecture takes as input the protein graph defined above and performs graph propagation steps according to:</p><formula xml:id="formula_6">h (i→j) m := g concat h (i) v , h (i→j) e (3) h (j) v ← LayerNorm   h (j) v + 1 k Dropout   i:ei→j ∈E h (i→j) m     (4)</formula><p>Here, g is a sequence of three GVPs, h</p><p>v and h</p><formula xml:id="formula_8">(i→j) e</formula><p>are the embeddings of the node i and edge (i → j) as above, and h (i→j) m represents the message passed from node i to node j. k is the number of incoming messages, which is equal to k unless the protein contains fewer than k amino acid residues. Between graph propagation steps, we also use a feed-forward point-wise layer to update the node embeddings at all nodes j:</p><formula xml:id="formula_9">h (j) v ← LayerNorm h (j) v + Dropout g h (j) v (5)</formula><p>where g is a sequence of two GVPs. These graph propagation and feed-forward steps update the vector features at each node in addition to its scalar features.</p><p>In model quality assessment, we use three graph propagation steps and perform regression against the true quality score of a candidate structure, a global scalar property. To obtain a single global representation, we apply a node-wise GVP to reduce all node embeddings to scalars. We then average the representations across all nodes and apply a final dense feed-forward network to output the network's prediction.</p><p>In computational protein design, the network learns a generative model over the space of protein sequences conditioned on the given backbone structure. Following <ref type="bibr" target="#b16">Ingraham et al. (2019)</ref>, we frame this as an autoregressive task and use a masked encoder-decoder architecture to capture the joint distribution over all positions: for each i, the network models the distribution at i based on the complete structure graph, as well as the sequence information at positions j &lt; i. The encoder first performs three graph propagation steps on the structural information only. Then, sequence information is added to the graph, and the decoder performs three further graph propagation steps where incoming messages h (i→j) m for i ≥ j are computed only with the encoder embeddings. Finally, we use one last GVP with 20-way scalar softmax output to predict the probability of the amino acids.</p><p>Further details regarding training and hyperparameters can be found in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DATASET AND EVALUATION</head><p>In this section, we set up the background and methodology for benchmarking the architecture on model quality assessment and protein design.</p><p>Model quality assessment Model quality assessment aims to select the best structural model of a protein from a large pool of candidate structures. <ref type="foot" target="#foot_4">5</ref> The performance of different MQA methods is evaluated every two years in the community-wide Critical Assessment of Structure Prediction (CASP) <ref type="bibr" target="#b5">(Cheng et al., 2019)</ref>. For a number of recently solved but unreleased structures, called targets, structure generation programs produce a large number of candidate structures. MQA methods are evaluated by how well they predict the GDT-TS score of a candidate structure compared to the experimentally solved structure for that target. GDT-TS is a scalar measure of how similar two protein backbones are after global alignment <ref type="bibr" target="#b34">(Zemla et al., 2001)</ref>.</p><p>In addition to accurately predicting the absolute quality of a candidate structure, a good MQA method should also be able to accurately assess the relative model qualities among a pool of candidates for a given target so that the best ones can be selected, perhaps for further refinement. Therefore, MQA methods are commonly evaluated on two metrics: a global correlation between the predicted and ground truth scores, pooled across all targets, and the average per-target correlation among only the candidate structures for a specific target <ref type="bibr">(Cao &amp; Cheng, 2016;</ref><ref type="bibr" target="#b9">Derevyanko et al., 2018;</ref><ref type="bibr" target="#b23">Pagès et al., 2019)</ref>. We follow this convention in our experiments.</p><p>We train and validate on 79200 candidate structures for 528 targets submitted to CASP 5-10. We then test GVP-GNN on two MQA datasets. First, we score 20880 stage 1 and stage 2 candidate structures from CASP 11 (84 targets) and 12 (40 targets). This benchmark was first established by <ref type="bibr" target="#b17">Karasikov et al. (2019)</ref> and has been used by many recently published methods. However, to compare with a larger number of methods on more recent structural data, we also score 1472 stage 2 candidate structures from all 20 publicly available targets in CASP 13. We add the CASP 11-12 structures to our training set to evaluate on CASP 13. Further details can be found in Appendix C.</p><p>Protein design Computational protein design is the conceptual inverse of structure prediction, aiming to infer an amino acid sequence that will fold into a given structure. In comparison to model quality assessment, computational protein design is more difficult to unambiguously benchmark, as some structures may correspond to a large space of sequences and others may correspond to none at all. Therefore, the proxy metric of native sequence recovery-splitting the set of all known native structures in the PDB and attempting to design the sequences corresponding to held-out structuresis typically used to benchmark CPD models <ref type="bibr" target="#b20">(Li et al., 2014;</ref><ref type="bibr" target="#b21">O'Connell et al., 2018;</ref><ref type="bibr" target="#b32">Wang et al., 2018)</ref>. Drawing an analogy between sequence design and language modelling, Ingraham et al. ( <ref type="formula">2019</ref>) also evaluate the model perplexity on held-out native sequences. Both metrics rest on the implicit assumption that native sequences are optimized for their structures <ref type="bibr" target="#b19">(Kuhlman &amp; Baker, 2000)</ref> and should be assigned high probabilities.</p><p>Table <ref type="table">1</ref>: Comparison with state-of-the-art methods on CASP 11 and 12 in terms of global (Glob) and mean per-target (Per) Pearson correlation coefficients (higher is better). Each method is classified as one of the three types discussed in Section 2. ProQ3D is set aside as the only method which additionally uses non-structure information. The top performing structure-only method for each metric is in bold, as is the top performing-method overall (if different We also report results on TS50, an older test set of 50 native structures first introduced by <ref type="bibr" target="#b20">Li et al. (2014)</ref>. The smaller size of this benchmark also allows a comparison to the computationally expensive physics-based calculations of the fixbb protocol in Rosetta, a software suite well-established in the structural biology community <ref type="bibr" target="#b8">(Das &amp; Baker, 2008)</ref>. No canonical training and validation sets exist for TS50. In order to evaluate on TS50, we remove sequences with more than 30% similarity with any structure in TS50 from the CATH 4.2 training and validation sets and retrain our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>Model quality assessment We compare GVP-GNN against state-of-the-art methods on the CASP 11-12 test set in Table <ref type="table">1</ref>. These include the CNN methods 3DCNN <ref type="bibr" target="#b9">(Derevyanko et al., 2018)</ref> and Ornate <ref type="bibr" target="#b23">(Pagès et al., 2019)</ref>, the GNN method GraphQA <ref type="bibr" target="#b1">(Baldassarre et al., 2020)</ref>, and three methods that use sequential representations-VoroMQA <ref type="bibr" target="#b22">(Olechnovič &amp; Venclovas, 2017)</ref>, SBROD <ref type="bibr" target="#b17">(Karasikov et al., 2019)</ref>, and ProQ3D <ref type="bibr" target="#b30">(Uziela et al., 2017)</ref>. All of these methods learn solely from protein structure,<ref type="foot" target="#foot_5">6</ref> with the exception of ProQ3D, which in addition uses sequence profiles based on alignments, which are not always available. We include ProQ3D because it is an improved version of the best single-model method in CASP 11 and CASP 12 <ref type="bibr" target="#b30">(Uziela et al., 2017)</ref>. GVP-GNN outperforms all other structural methods in both global and per-target correlation, and even performs better than ProQ3D on all but one benchmark.</p><p>We also evaluate DimeNet, a recent 3D-aware GNN architecture which achieves state-of-the-art on many small-molecule tasks <ref type="bibr" target="#b18">(Klicpera et al., 2019)</ref>, on CASP 11-12. DimeNet differs from GVP-GNN in that it uses relative edge orientations to indirectly encode geometry into its messagepassing operations. While this paradigm appears well-suited for the domain of learning from small molecules, DimeNet does not outperform any of the models in Table <ref type="table">1</ref> on model quality assessment.</p><p>See Appendix E for detailed results and discussion.</p><p>We compare GVP-GNN with all 23 single-structure MQA methods participating in CASP 13 for which complete predictions are available. Seven of these methods were highlighted as bestperforming by the CASP organizers in <ref type="bibr" target="#b5">Cheng et al. (2019)</ref> and are shown along with GVP-GNN Finally, because our architecture updates vector features along with scalar features at each node embedding, it is possible to visualize learned vector features in the intermediate layers of the trained MQA network. We show and discuss the interpretability of such features in Appendix F.</p><p>Protein design GVP-GNN achieves state-of-the-art performance on CATH 4.2, representing a substantial improvement both in terms of perplexity and sequence recovery over Structured Transformer <ref type="bibr" target="#b16">(Ingraham et al., 2019)</ref>, a GNN method which was trained using the same training and validation sets (Table <ref type="table" target="#tab_3">3</ref>). Following <ref type="bibr" target="#b16">Ingraham et al. (2019)</ref>, we report evaluation on short (100 or fewer amino acid residues) and single-chain subsets of the CATH 4.2 test set, containing 94 and 103 proteins, respectively, in addition to the full test set. Although Structured Transformer leverages an attention mechanism on top of a graph-structured representation of proteins, the authors note in ablation studies that removing attention appeared to increase performance. We therefore retrain and compare against a version of Structured Transformer with the attention layers replaced with standard graph propagation operations (Structured GNN). Our method also improves upon this model.</p><p>On the smaller test set TS50, we achieve 44.9% recovery compared to Rosetta's 30% and outperform methods based on each of the three classes of structural representations. Overall, we place 2nd out of 9 methods in terms of recovery (see Appendix E). However, the results for this test set should be taken with a grain of salt, given that the different methods did not use canonical training datasets.</p><p>Ablation studies The methods we have compared against include a number of GNNs (GraphQA, Structured Transformer/GNN, ProteinSolver). We train a number of ablated models for MQA and CPD to identify the aspects of the GVP which most contribute to our performance improvement over these GNNs (Table <ref type="table" target="#tab_4">4</ref>). Replacing the GVP with a vanilla MLP layer or propagating only scalar features both remove direct access to geometric information, forcing the model to learn scalarvalued, indirect representations of geometry. These modifications result in considerable decreases in performance, underscoring the importance of direct access to geometric information. Propagating only the vector features results in an even larger decrease as it both eliminates important scalar input features (such as torsion angles and amino acid identity) and the part of the GVP with approximation guarantees. Therefore, the dual scalar/vector design of the GVP is essential: without either, the best ablated model only matches GraphQA on MQA and falls short of Structured GNN on CPD. Finally, eliminating the second vector transformation W µ results in a slight decrease in performance. Therefore, all architectural elements contributed to our improvement over state-of-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this work, we developed the first architecture designed specifically for learning on dual relational and geometric representations of 3D macromolecular structure. At its core, our method, GVP-GNN, augments graph neural networks with computationally simple layers that perform expressive geometric reasoning over Euclidean vector features. Our method possesses desirable theoretical properties and empirically outperforms existing architectures on learning quality scores and sequence designs, respectively, from protein structure.</p><p>In further work, we hope to apply our architecture to other important structural biology problem areas, including protein complexes, RNA structure, and protein-ligand interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A PROPERTIES OF GEOMETRIC VECTOR PERCEPTRONS A.1 EQUIVARIANCE AND INVARIANCE</head><p>The vector and scalar outputs of the GVP are equivariant and invariant, respectively, with respect to an arbitrary composition of rotations and reflections in 3D Euclidean space described by R i.e.,</p><formula xml:id="formula_10">GVP((s, R(V))) = (s , R(V ))</formula><p>Proof. We can write the transformation described by R as multiplying V with a unitary matrix U ∈ R 3×3 from the right. The L 2 -norm, scalar multiplications, and nonlinearities are defined rowwise as in Algorithm 1. We consider scalar and vector outputs separately. The scalar output, as a function of the inputs, is</p><formula xml:id="formula_11">s = σ W m W h V 2 s + b Since W h VU 2 = W h V 2 , we conclude s is invariant.</formula><p>Similarly the vector output is</p><formula xml:id="formula_12">V = σ + W µ W h V 2 W µ W h V</formula><p>The row-wise scaling can also be viewed as left-multiplication by a diagonal matrix D. Since</p><formula xml:id="formula_13">W µ W h V 2 = W µ W h VU 2 , D is invariant. Since DW µ W h (VU) = (DW µ W h V) U</formula><p>we conclude that V is equivariant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 THE ABILITY TO APPROXIMATE ROTATION-INVARIANT FUNCTIONS</head><p>The GVP inherits an analogue of the Universal Approximation property <ref type="bibr" target="#b7">Cybenko (1989)</ref> of standard dense layers. If R describes an arbitrary rotation or reflection in 3D Euclidean space, <ref type="foot" target="#foot_8">9</ref> we show that a GVP can approximate arbitrary scalar-valued functions invariant under R and defined over Ω ν ⊂ R ν×3 , the bounded subset of R ν×3 whose elements can be canonically oriented based on three linearly independent vector entries. Without loss of generality, we assume the first three vector entries can be used.</p><p>The machinery corresponding to such approximations corresponds to a GVP G s with only vector inputs, only scalar outputs, and a sigmoidal nonlinearity σ; followed by a dense layer. This can also be viewed as the sequence of matrix multiplication with W h , taking the L 2 -norm, and a dense network with one hidden layer. Such machinery can be extracted from any two consecutive GVPs (assuming a sigmoidal σ).</p><p>Theorem. Let R describe an arbitrary rotation and/or reflection in</p><formula xml:id="formula_14">R 3 . For ν ≥ 3 let Ω ν ⊂ R ν×3 be the set of all V = [v 1 , . . . , v ν ] T ∈ R ν×3 such that v 1 , v 2 , v<label>3</label></formula><p>are linearly independent and 0 &lt; v i 2 ≤ b for all i and some finite b &gt; 0. Then for any continuous</p><formula xml:id="formula_15">F : Ω ν → R such that F (R(V)) = F (V) and for any &gt; 0, there exists a form f (V) = w T G s (V) such that |F (V) − f (V)| &lt; for all V ∈ Ω.</formula><p>Proof. The idea is to write F as a composition F = F •ω and ω = h•y. We show that multiplication with W h and and taking the L 2 -norm can compute y, and that the dense network with one hidden layer can approximate F • h.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Call an element</head><formula xml:id="formula_16">V ∈ Ω ν oriented if v 1 = x 1 e x , v 2 =</formula><p>x 2 e x + y 2 e y , and v 3 = x 3 e x + y 3 e y + z 3 e z , with x 1 , y 2 , z 3 &gt; 0. Define ω : Ω ν → R 3ν−3 to be the orientation function that orients its input and then extracts the vector of 3ν − 3 coefficients, [x 1 , x 2 , y 2 , x 3 , y 3 , z 3 , . . . , x i , y i , z i , . . .] T . These elements can be written as</p><formula xml:id="formula_17">x 1 = v 1 2 x i = v i • v 1 /x 1 , i ≥ 2 y 2 = v 2 2 2 − x 2 2 y i = (v i • v 2 − x i x 2 )/y 2 , i ≥ 3 z 3 = v 3 2 2 − x 2 3 − y 2 3 z i = (v i • v 3 − x i x 3 − y i y 3 )/z 3 , i ≥ 4</formula><p>and are invariant under rotation and reflection, because they are defined using only the norms and inner products of the v i . Then</p><formula xml:id="formula_18">F = F • ω, where F : [−b, b] 3ν−3 → R.</formula><p>The key insight is that if we construct W h such that the rows of W h V are the original vectors v i , ∀i and all differences v i − v j , ∀i, j ≤ min(i, 3), then we can compute ω(V) from the row-wise norms of</p><formula xml:id="formula_19">W h V. That is, ω = h • y where y = y(V) = . 2 (W h V) ∈ R 4ν−6</formula><p>and h is an application of the cosine law. The GVP precisely computes y as an intermediate step:</p><formula xml:id="formula_20">G s (V) = σ (W m y + b). It remains to show that there exists a form f (y) = w T [σ (W h y + b)] that -approximates F • h : [−2b, 2b] 4ν−6 → R.</formula><p>Up to a translation and uniform scaling of the hypercube, this is the result of the Universal Approximation Theorem <ref type="bibr" target="#b7">(Cybenko, 1989)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B SYNTHETIC TASKS</head><p>We perform controlled experiments on a synthetic dataset in order to analyze the benefits of the GVP architecture and determine if it indeed improves the geometric and joint geometric-relational reasoning abilities of GNNs.</p><p>Dataset The synthetic dataset is designed to mimic the essential qualities of the domain of protein structures. Each "structure" consists of n = 100 random points in R 3 , distributed uniformly in the ball of radius r = 10, with the constraint that no two points are less than distance d = 2 apart. Each position is also associated with a random unit vector (a "sidechain") to endow it with an orientation. Three points are randomly chosen and are labelled as "special"; these will be used to define the learning tasks. We generate 20k "structures" and split them 80% train : 10% validation : 10% test.</p><p>In the voxelized representation of a data point, the volume is voxelized into unit cubes. Each point is partitioned into a neighborhood of eight voxels by trilinear interpolation, such that exact coordinate information is retained. Separate channels are used for the special and non-special points. The "sidechains" are represented with a set of n = 100 points located at the ends of the unit vectors and mapped into a third channel.</p><p>In the graph-structured representation of a data point, a proximity graph is drawn with k = 10 nearest neighbors. Each node is labelled with a one-hot encoding of its type ("special" or "nonspecial") and each edge with its Euclidean length. In the vanilla GNN, orientation information is encoded by additionally including all three dot products in each edge embedding. In the GVP-GNN, each node embedding contains the node's "sidechain" vector, and each edge embedding contains a unit vector indicating the direction of the edge.</p><p>A link to our synthetic dataset can be found here: https://drive.google.com/drive/ folders/1XuCyPFTM2Ro9kfCP_tWOF1uwBB-Hn3LH</p><p>Tasks We identify two regression tasks to exemplify geometric and relational reasoning, respectively. In the "Off-center" task, the network predicts the distance from the centroid of the three special points to the centroid of the entire structure. In the "Perimeter" task, the network predicts the perimeter of the triangle defined by the three special points. We characterize the former as primarily geometric, as it requires reasoning about global properties of the 3D shape, in particular points in space that are not themselves nodes, and the latter as primarily relational, as it involves distances between three specific pairs of nodes. Finally, to represent a problem with geometric and relational aspects, in the "Combined" task we attempt to predict the difference of the (normalized) off-center and perimeter objectives.</p><p>Models We train a 3-layer shallow CNN and a 3-layer GNN with a single-layer feed-forward network. These are compared against a GVP-GNN that is otherwise identical to the standard GNN. To reflect the spirit of the synthetic experiment, all models have the same intermediate dimensionality of 32 (4 vector and 20 scalar channels in the GVP-GNN), we use the same training procedure for all models, and no hyperparameter tuning or architecture search is performed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The results of the synthetic experiments are shown in Table <ref type="table">5</ref>. The vanilla GNN significantly outperforms the CNN on the perimeter task, while the CNN significantly outperforms the GNN on the off-center task, supporting our conceptual framework of the relative strengths of the two architectures. However, the GVP-GNN matches (and even outperforms) the CNN on the geometric task while maintaining the GNN's performance on the relational task. It additionally significantly outperforms both models on the combined task. On the basis of these results, the GVP appears successful in combining the strengths of the CNN and GNN into a single architecture.</p><p>Table <ref type="table">5</ref>: Performance of the three compared model architectures on the off-center (geometric), perimeter (relational), and combined objectives. The MSE losses are standardized such that predicting a constant value (i.e. the mean) would result in unit loss. Results are reported as the mean ± S.D. over k = 5 random splits, where the best of three random seeds is taken for each split.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Parameters </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C DATASETS</head><p>Model quality assessment For training and validation, we use 528 targets from CASP 5-10 and 150 candidate structures per target. These targets are partitioned at random into 480 training targets and 48 validation targets. We include native structures for training and validation to make use of the greatest range of GDT-TS scores. We do not include native structures for testing in order to mimic CASP and real-world applications and because other methods were not tested on native structures.</p><p>In the CASP assessments, stage 1 refers to a set of 20 candidate structures per target and stage 2 to a set of 150 candidate structures per target (5 from each structure prediction server). Both sets are pre-designated by the CASP organizers.</p><p>There has been slight inconsistency in the literature with regards to the exact composition of the CASP 11 and 12 test sets. We use the list established by <ref type="bibr" target="#b17">Karasikov et al. (2019)</ref> because nearly all recent methods have been benchmarked on this set at some point. For the CASP 13 test set, we include all stage 2 candidate structures for which the ground-truth GDT-TS is available and for which the mapping between candidate structure names and IDs is provided, enabling the candidate structure set to be matched with predictions from methods which officially participated in CASP 13. There are 1472 such candidate structures in total for 20 targets: T0950, T0951, T0953s1, T0953s2, T0954, T0955, T0957s1, T0957s2, T0958, T0960, T0963, T0966, T0968s1, T0968s2, T1003, T1005, T1008, T1009, T1011, and T1016. This information is obtained from the CASP download center as described by <ref type="bibr" target="#b1">Baldassarre et al. (2020)</ref>. The exact numbers of targets and structures in each set can be found in Table <ref type="table" target="#tab_6">6</ref>.</p><p>Protein design As described in the main text, we use the CATH 4.2 dataset and splits as curated by <ref type="bibr" target="#b16">Ingraham et al. (2019)</ref> and the TS50 test set as curated by <ref type="bibr" target="#b20">Li et al. (2014)</ref>. To evaluate on TS50, we remove sequences with more than 30% similarity as computed by PSIBLAST to any protein in TS50 from CATH 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D TRAINING AND HYPERPARAMETERS</head><p>To train the MQA model to perform regression against the model quality score, we use a sum of an absolute loss and a pairwise loss. That is, for each training step we intake pairs i, j where i, j are </p><formula xml:id="formula_21">L = H(y (i) − ŷ(i) ) + H(y (j) − ŷ(j) ) + H (y (i) − y (j) ) − (ŷ (i) − ŷ(j) )<label>(6)</label></formula><p>where H is the Huber loss. When reshuffling at the beginning of each epoch, we also randomly pair up the candidate structures for each target. Interestingly, adding the pairwise term also improves global correlation, likely because the much larger number of possible pairs makes it more difficult to overfit.</p><p>To train the CPD model to perform classification / discrete generative modelling, we use the crossentropy / negative log likelihood loss. We also experimented with label smoothing, but this did not improve performance.</p><p>For both the MQA and CPD model, we use node and hidden embeddings with 16 vector and 100 scalar channels and edge embeddings with 1 vector and 32 scalar channels. The input node and edge features are first transformed by a sequence of GVPs to these dimensionalities before graph propagation. In all training runs, we use the Adam optimizer to perform mini-batch gradient descent. Batches are constructed by grouping structures of similar size to have a maximum of 1800 residues per batch for CPD and 3000 residues per batch for MQA. We also tune the following hyperparameters over a total of 70 training runs:</p><p>• Learning rate in the range of 10 −4 to 10 −3</p><p>• Dropout probability in the range of 10 −4 to 10 −1</p><p>• Number of graph propagation layers in the range of 3 to 6</p><p>• Relative weight of the MQA pairwise loss in the range of 0 to 2 All models are implemented in TensorFlow 2.1 and trained for a maximum of 100 epochs. This takes around two days for both models on a single Titan X GPU. However, we note that the GPU memory, not compute power, is the bottleneck when training, based on the the average volatile GPU usage. We therefore anticipate that the runtime can be further optimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E ADDITIONAL RESULTS</head><p>E.1 DIMENET ON MQA DimeNet <ref type="bibr" target="#b18">(Klicpera et al., 2019</ref>) is a recent GNN architecture designed to incorporate the 3D geometry of small molecule graphs by updating edge embeddings with incoming messages from neighboring edges, where the relative orientation of each edge is encoded in a local spherical Bessel basis. DimeNet and our architecture are similar in that both seek to leverage geometric aspects of a problem domain on top of graph-structured representations. However, unlike our architecture, it specifically updates edge embeddings and must represent each pair of neighboring edges, and therefore does not scale well to large protein structure graphs. In evaluating DimeNet on MQA, we could only extend the distance cutoff to 7.5 angstroms, while 30 neighbors corresponds to roughly 13 angstroms. DimeNet does not perform comparably to our model, or to previous GNNs designed for learning from structure such as GraphQA. (Table <ref type="table" target="#tab_7">7</ref>). We report results for all 23 single-structure methods assessed in CASP 13 for which scores on all 20 targets are available (Table <ref type="table" target="#tab_8">8</ref>). The following 7 methods were excluded because they do not report results for some targets: LamoureuxLab, SBROD-server, SBROD, 3DCNN, MESHI-server, SBROD-plus, FALCON-QA, and Grudinin. We do include comparisons with LamoureuxLab (previously 3DCNN), 3DCNN (previously Ornate), and SBROD on CASP 11-12. All of the methods highlighted as top-performing by the CASP organizers in <ref type="bibr" target="#b5">Cheng et al. (2019)</ref> are in our comparison for CASP 13. All predictions were obtained from the CASP download center as described by <ref type="bibr" target="#b1">Baldassarre et al. (2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 CPD: RESULTS ON TS50 TEST SET</head><p>We compare against a number of recent CPD methods on the TS50 test set in Table <ref type="table">9</ref>. These include two CNNs (ProDCoNN and DenseCPD), a distance-map method (SBROF), and sequential representation methods <ref type="bibr">(Wang's model and SPIN2)</ref>. We also evaluate the GNN ProteinSolver on TS50 by sampling 100 sequences with temperature 1 (the default setting) for each structure using the public web server. No canonical training and validation sets exist for TS50. Therefore, in order to evaluate on TS50, we remove sequences with more than 30% similarity from the CATH 4.2 training and validation sets and retrain our model. We outperform all other methods with the exception of DenseCPD, a CNN method with canonical orientations. Interestingly, DenseCPD leverages the same underlying representation as ProDCoNN, yet achieves remarkably better performance. The main difference between the two methods is that ProDCoNN has 4 convolutional layers and DenseCPD has 21 layers organized into dense residual blocks.</p><p>Table <ref type="table">9</ref>: Sequence recovery on TS50. Recovery for GVP-GNN and ProteinSolver is a median over all proteins of the mean recovery of 100 designs per protein; recovery for other methods, which model residues independently, is just classification accuracy. GVP-GNN is the second bestperforming method, behind the CNN method DenseCPD. There is no canonical training and validation set for methods evaluated on TS50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Recovery % GVP-GNN 44.9 DenseCPD <ref type="bibr" target="#b25">(Qi &amp; Zhang, 2020)</ref> 50.7 ProDCoNN <ref type="bibr" target="#b35">(Zhang et al., 2019)</ref> 40.7 SBROF <ref type="bibr" target="#b4">(Chen et al., 2019)</ref> 39.2 SPIN2 <ref type="bibr" target="#b21">(O'Connell et al., 2018)</ref> 33.6 Wang's model <ref type="bibr" target="#b32">(Wang et al., 2018)</ref> 33.0 ProteinSolver <ref type="bibr" target="#b27">(Strokach et al., 2020)</ref> 30.8 SPIN <ref type="bibr" target="#b20">(Li et al., 2014)</ref> 30.3 Rosetta 30.0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F VISUALIZATION AND INTERPRETATION OF LEARNED FEATURES</head><p>The geometric vector perceptron updates the vector features, in addition to scalar features, at node embeddings during graph propagation. Therefore, while the input vector channels represent the forward and reverse directions at each amino acid, the intermediate layers represent learned vector features. Could some of these features correspond to interpretable properties of the structure? Among a total of 64 intermediate vector channels learned by the MQA model, a few appeared visually interpretable and are shown on selected structures in Figure <ref type="figure" target="#fig_0">2</ref>. We caution against generalizing from the necessarily small number of images that could be manually inspected, but find these preliminary visualizations intriguing. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Four different learned vector channels of the MQA model are visualized on four separate structures. The backbone is represented as a chain of points, and each vector is rooted at the position of the amino acid node to which it belongs. From left to right: the vectors appear to A) point in the direction of motion that would make the protein more compact; B) point along the central axis of the alpha helix; C) point outwards from the structure; and D) point inwards into the structure.</figDesc><graphic url="image-2.png" coords="17,108.00,573.69,395.99,82.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>). GVP-GNN generally improves over all other methods.To best approximate real-world applications that may require design of novel structures, the heldout evaluation set should bear minimal similarity to the training structures. We use the CATH 4.2 dataset curated by<ref type="bibr" target="#b16">Ingraham et al. (2019)</ref> in which all available structures with 40% nonredudancy are partitioned by their CATH (class, architecture, topology/fold, homologous superfamily) classification. The canonical training, validation, and test splits consist of 18204, 608, and 1120 structures, respectively.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">CASP 11</cell><cell cols="2">CASP 12</cell></row><row><cell></cell><cell></cell><cell>Stage 1</cell><cell>Stage 2</cell><cell>Stage 1</cell><cell>Stage 2</cell></row><row><cell>Method</cell><cell cols="2">Type Glob Per</cell><cell>Glob Per</cell><cell>Glob Per</cell><cell>Glob Per</cell></row><row><cell cols="3">GVP-GNN GNN 0.84 0.66</cell><cell>0.87 0.45</cell><cell>0.79 0.73</cell><cell>0.82 0.62</cell></row><row><cell>3DCNN</cell><cell cols="2">CNN 0.59 0.52</cell><cell>0.64 0.40</cell><cell>0.49 0.44</cell><cell>0.61 0.51</cell></row><row><cell>Ornate</cell><cell cols="2">CNN 0.64 0.47</cell><cell>0.63 0.39</cell><cell>0.55 0.57</cell><cell>0.67 0.49</cell></row><row><cell>GraphQA</cell><cell cols="2">GNN 0.83 0.63</cell><cell>0.82 0.38</cell><cell>0.72 0.68</cell><cell>0.81 0.61</cell></row><row><cell cols="2">VoroMQA Seq</cell><cell>0.69 0.62</cell><cell>0.65 0.42</cell><cell>0.46 0.61</cell><cell>0.61 0.56</cell></row><row><cell>SBROD</cell><cell>Seq</cell><cell>0.58 0.65</cell><cell>0.55 0.43</cell><cell>0.37 0.64</cell><cell>0.47 0.61</cell></row><row><cell>ProQ3D</cell><cell>Seq</cell><cell>0.80 0.69</cell><cell>0.77 0.44</cell><cell>0.67 0.71</cell><cell>0.81 0.60</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance of GVP-GNN and the seven top-performing single-structure methods from CASP 13 on the 20 publicly available CASP 13 targets, in terms of global and per-target Pearson correlation. The methods above the line use only structural features, while those below the line also leverage sequence alignment-based profiles. As before, the top structure-only method is in bold, as is the top method overall (if different). GVP-GNN is the top-performing structure-only method and the top method overall in terms of global correlation.</figDesc><table><row><cell>Method</cell><cell cols="2">Global Per-target</cell></row><row><cell>GVP-GNN</cell><cell>0.888</cell><cell>0.671</cell></row><row><cell>SASHAN</cell><cell>0.840</cell><cell>0.633</cell></row><row><cell>FaeNNz</cell><cell>0.810</cell><cell>0.650</cell></row><row><cell>VoroMQA-A</cell><cell>0.744</cell><cell>0.595</cell></row><row><cell>VoroMQA-B</cell><cell>0.726</cell><cell>0.586</cell></row><row><cell>ProQ3D</cell><cell>0.847</cell><cell>0.660</cell></row><row><cell cols="2">MULTICOM-NOVEL 0.652</cell><cell>0.551</cell></row><row><cell>ProQ4</cell><cell>0.604</cell><cell>0.691</cell></row><row><cell>in</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>These include four methods learning solely from structural features and three also using sequence profiles. SASHAN learns a linear model over secondary structure and contact-based features<ref type="bibr" target="#b5">(Cheng et al., 2019)</ref>. FaeNNz 7<ref type="bibr" target="#b28">(Studer et al., 2020)</ref>, ProQ3D<ref type="bibr" target="#b30">(Uziela et al., 2017)</ref>, and VoroMQA</figDesc><table /><note>8<ref type="bibr" target="#b22">(Olechnovič &amp; Venclovas, 2017</ref>) learn a multi-layer perceptron or statistical potential on top of such structural features. Finally, MULTICOM-NOVEL<ref type="bibr" target="#b14">(Hou et al., 2019)</ref> and ProQ4<ref type="bibr" target="#b15">(Hurtado et al., 2018)</ref> employ one-dimensional deep convolutional networks on top of sequential representations. GVP-GNN outperforms all methods in terms of global correlation and outperforms all structure-only methods in per-target correlation (see Appendix E for more details). Because of the small size of the available CASP 13 dataset, we emphasize that these results, although promising, should be considered preliminary until experimental structures of further targets from CASP 13 become publicly available.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Performance on the CATH 4.2 test set and its short and single-chain subsets in terms of per-residue perplexity (lower is better) and recovery (higher is better). Recovery is reported as the median over all structures of the mean recovery of 100 sequences per structure. GVP-GNN performs better than Structured Transformer and a variant of it, Structured GNN, in which we replaced the attention mechanisms with standard graph propagation operations (see main text).</figDesc><table><row><cell>Perplexity</cell><cell>Recovery %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Performance of ablated models and other state-of-the-art GNNs (Structured GNN for CPD; GraphQA for MQA) compared to the unmodified GVP-GNN on both tasks. Metrics for MQA are reported as global and mean per-target Pearson correlations. CPD perplexity and recovery are defined in the same way as in Table3.</figDesc><table><row><cell></cell><cell></cell><cell>MQA</cell><cell></cell><cell></cell><cell>CPD</cell><cell></cell></row><row><cell></cell><cell cols="2">CASP 11 Stage 2</cell><cell cols="2">CASP 12 Stage 2</cell><cell cols="2">CATH4.2 All</cell></row><row><cell>Modification</cell><cell cols="2">Global Per-target</cell><cell cols="2">Global Per-target</cell><cell cols="2">Perplexity Recovery</cell></row><row><cell>None</cell><cell>0.87</cell><cell>0.45</cell><cell>0.82</cell><cell>0.62</cell><cell>5.29</cell><cell>40.2</cell></row><row><cell>MLP layer</cell><cell>0.84</cell><cell>0.36</cell><cell>0.79</cell><cell>0.59</cell><cell>7.76</cell><cell>30.6</cell></row><row><cell>Only scalars</cell><cell>0.84</cell><cell>0.38</cell><cell>0.83</cell><cell>0.59</cell><cell>7.31</cell><cell>32.4</cell></row><row><cell>Only vectors</cell><cell>0.56</cell><cell>0.16</cell><cell>0.57</cell><cell>0.39</cell><cell>11.05</cell><cell>23.2</cell></row><row><cell>No W µ</cell><cell>0.86</cell><cell>0.41</cell><cell>0.81</cell><cell>0.60</cell><cell>5.85</cell><cell>37.1</cell></row><row><cell>GraphQA</cell><cell>0.82</cell><cell>0.38</cell><cell>0.81</cell><cell>0.61</cell><cell>-</cell><cell>-</cell></row><row><cell>Structured GNN</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>6.55</cell><cell>37.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>: MQA datasets</cell><cell></cell></row><row><cell>Dataset</cell><cell cols="3"># Targets # Structures Includes natives?</cell></row><row><cell>Training</cell><cell>480</cell><cell>72000</cell><cell>Yes</cell></row><row><cell>Validation</cell><cell>48</cell><cell>7200</cell><cell>Yes</cell></row><row><cell>CASP 11 stage 1</cell><cell>84</cell><cell>1680</cell><cell>No</cell></row><row><cell>CASP 11 stage 2</cell><cell>83</cell><cell>12450</cell><cell>No</cell></row><row><cell>CASP 12 stage 1</cell><cell>40</cell><cell>800</cell><cell>No</cell></row><row><cell>CASP 12 stage 2</cell><cell>40</cell><cell>5950</cell><cell>No</cell></row><row><cell>CASP 13 stage 2</cell><cell>20</cell><cell>1472</cell><cell>No</cell></row><row><cell cols="3">candidate structures for the same target and compute</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Comparison of our GVP architecture, DimeNet, and the GraphQA, another GNN-based MQA method, on CASP 11-12. As in the main text, the global and mean per-target Pearson correlations are shown. DimeNet does not perform comparably to either GVP-GNN or GraphQA.</figDesc><table><row><cell></cell><cell cols="2">CASP 11 Stage 2</cell><cell cols="2">CASP 12 Stage 2</cell></row><row><cell>Method</cell><cell cols="2">Global Per-target</cell><cell cols="2">Global Per-target</cell></row><row><cell>GVP-GNN</cell><cell>0.87</cell><cell>0.45</cell><cell>0.82</cell><cell>0.62</cell></row><row><cell>GraphQA</cell><cell>0.82</cell><cell>0.38</cell><cell>0.81</cell><cell>0.61</cell></row><row><cell>DimeNet</cell><cell>0.61</cell><cell>0.30</cell><cell>0.62</cell><cell>0.47</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Comparison of GVP-GNN against all 23 available single-structure MQA methods in CASP 13 sorted by global correlation. The total number of predictions is shown, which may be less than 1472 even though they include all 20 targets. GVP-GNN is the best-performing method in terms of global correlation. In terms of per-target correlation, GVP-GNN outperforms all other structure-only methods and also all methods using sequence profiles except for ProQ4 and two ProQ3D variants.</figDesc><table><row><cell>Method</cell><cell cols="4">Global Per-target Predictions Structure only?</cell></row><row><cell>GVP-GNN</cell><cell>0.888</cell><cell>0.671</cell><cell>1472</cell><cell>Yes</cell></row><row><cell>ProQ3D</cell><cell>0.847</cell><cell>0.660</cell><cell>1467</cell><cell>No</cell></row><row><cell>SASHAN</cell><cell>0.840</cell><cell>0.633</cell><cell>1472</cell><cell>Yes</cell></row><row><cell>MESHI-corr-server</cell><cell>0.838</cell><cell>0.651</cell><cell>1472</cell><cell>Yes</cell></row><row><cell>ProQ3</cell><cell>0.822</cell><cell>0.576</cell><cell>1468</cell><cell>No</cell></row><row><cell>MESHI</cell><cell>0.813</cell><cell>0.666</cell><cell>1472</cell><cell>Yes</cell></row><row><cell>MESHI-enrich-server</cell><cell>0.813</cell><cell>0.666</cell><cell>1472</cell><cell>Yes</cell></row><row><cell>FaeNNz</cell><cell>0.810</cell><cell>0.650</cell><cell>1472</cell><cell>Yes</cell></row><row><cell>ProQ3D-CAD</cell><cell>0.803</cell><cell>0.673</cell><cell>1468</cell><cell>No</cell></row><row><cell>ProQ3D-lDDT</cell><cell>0.803</cell><cell>0.687</cell><cell>1467</cell><cell>No</cell></row><row><cell>ProQ2</cell><cell>0.802</cell><cell>0.577</cell><cell>1472</cell><cell>No</cell></row><row><cell>ProQ3D-TM</cell><cell>0.791</cell><cell>0.654</cell><cell>1467</cell><cell>No</cell></row><row><cell>MASS1</cell><cell>0.776</cell><cell>0.582</cell><cell>1472</cell><cell>Yes</cell></row><row><cell>VoroMQA-A</cell><cell>0.744</cell><cell>0.595</cell><cell>1472</cell><cell>Yes</cell></row><row><cell>VoroMQA-B</cell><cell>0.726</cell><cell>0.586</cell><cell>1472</cell><cell>Yes</cell></row><row><cell>MASS2</cell><cell>0.689</cell><cell>0.584</cell><cell>1472</cell><cell>Yes</cell></row><row><cell cols="2">MULTICOM-NOVEL 0.652</cell><cell>0.551</cell><cell>1472</cell><cell>No</cell></row><row><cell>ProQ4</cell><cell>0.604</cell><cell>0.691</cell><cell>1472</cell><cell>No</cell></row><row><cell>PLU-AngularQA</cell><cell>0.577</cell><cell>0.460</cell><cell>1472</cell><cell>Yes</cell></row><row><cell>Bhattacharya-Server</cell><cell>0.577</cell><cell>0.501</cell><cell>1452</cell><cell>No</cell></row><row><cell>Bhattacharya-SingQ</cell><cell>0.498</cell><cell>0.525</cell><cell>1452</cell><cell>No</cell></row><row><cell>Kiharalab</cell><cell>0.375</cell><cell>0.565</cell><cell>1472</cell><cell>No</cell></row><row><cell>PLU-TopQA</cell><cell>0.239</cell><cell>0.049</cell><cell>1472</cell><cell>Yes</cell></row><row><cell>Jagodzinski-Cao-QA</cell><cell>0.180</cell><cell>0.341</cell><cell>1472</cell><cell>Yes</cell></row><row><cell cols="2">E.2 MQA: RESULTS ON CASP 13</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">The nonlinearity σ + is a scaling by σ + applied to the L2 norm.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Cα, C, N, and O. The alpha carbon Cα is the central carbon atom in each amino acid residue.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">Cβ is the second carbon from the carboxyl carbon C.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">We use 16 Gaussian radial basis functions with centers evenly spaced between 0 and 20 angstroms.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">We refer to models of protein structure as "structural models" or "candidate structures" to avoid confusion with the term "model" as used in the ML community.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">There are two versions of GraphQA; we compare against the one using only structure information.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6">FaeNNz is also known as QMEANDisCo</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7">VoroMQA-A and VoroMQA-B are the same except that the former relaxes the sidechains before scoring.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8">More precisely, if R describes a unitary transformation.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Protein sequence design with a learned potential</title>
		<author>
			<persName><forename type="first">Namrata</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raphael</forename><forename type="middle">Ryuichi</forename><surname>Eguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Derry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><forename type="middle">B</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Possu</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">GraphQA: protein model quality assessment using graph convolutional networks</title>
		<author>
			<persName><forename type="first">Federico</forename><surname>Baldassarre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">Menndez</forename><surname>Hurtado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arne</forename><surname>Elofsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hossein</forename><surname>Azizpour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Relational inductive biases, deep learning, and graph networks</title>
		<author>
			<persName><forename type="first">Jessica</forename><forename type="middle">B</forename><surname>Peter W Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alvaro</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinicius</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Zambaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><surname>Faulkner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01261</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Renzhi Cao and Jianlin Cheng. Protein single-model quality assessment by feature-based probability density functions</title>
		<author>
			<persName><forename type="first">Jeremy</forename><forename type="middle">M</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">L</forename><surname>Tymoczko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lubert</forename><surname>Stryer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Biochemistry</surname></persName>
		</author>
		<author>
			<persName><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><surname>Company</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">23990</biblScope>
			<date type="published" when="2002">2002. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">To improve protein sequence profile prediction through image captioning on pairwise residue distance map</title>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zifeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutian</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huiying</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuedong</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Information and Modeling</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Estimation of model accuracy in casp13</title>
		<author>
			<persName><forename type="first">Jianlin</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myong-Ho</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arne</forename><surname>Elofsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun-Sop</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><forename type="middle">J</forename><surname>Maghrabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mcguffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kliment</forename><surname>Menéndez-Hurtado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torsten</forename><surname>Olechnovič</surname></persName>
		</author>
		<author>
			<persName><surname>Schwede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins: Structure, Function, and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1361" to="1377" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Inductive bias of deep convolutional networks through pooling geometry</title>
		<author>
			<persName><forename type="first">Nadav</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amnon</forename><surname>Shashua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Approximation by superpositions of a sigmoidal function</title>
		<author>
			<persName><forename type="first">George</forename><surname>Cybenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematics of control, signals and systems</title>
				<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="303" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Macromolecular modeling with rosetta</title>
		<author>
			<persName><forename type="first">Rhiju</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Biochem</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="363" to="382" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep convolutional networks for quality assessment of protein folds</title>
		<author>
			<persName><forename type="first">Georgy</forename><surname>Derevyanko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergei</forename><surname>Grudinin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lamoureux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="4046" to="4053" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">F</forename><surname>Samuel S Schoenholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
				<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A review of deep learning methods for antibodies</title>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Byerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduardo</forename><surname>Priego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naren</forename><surname>Makkapati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vince</forename><surname>Parish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brenda</forename><surname>Medellin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monica</forename><surname>Berrondo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Antibodies</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Design of metalloproteins and novel protein folds using variational autoencoders</title>
		<author>
			<persName><forename type="first">Lewis</forename><surname>Joe G Greener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">T</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Relating protein motion to catalysis</title>
		<author>
			<persName><forename type="first">Sharon</forename><surname>Hammes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Schiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">J</forename><surname>Benkovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Biochem</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="519" to="541" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep convolutional neural networks for predicting the quality of single protein structural models</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renzhi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianlin</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<biblScope unit="page">590620</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Deep transfer learning in the assessment of the quality of protein models</title>
		<author>
			<persName><forename type="first">David Menéndez</forename><surname>Hurtado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karolis</forename><surname>Uziela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arne</forename><surname>Elofsson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.06281</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generative models for graphbased protein design</title>
		<author>
			<persName><forename type="first">John</forename><surname>Ingraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="15794" to="15805" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Smooth orientation-dependent scoring function for coarse-grained protein quality assessment</title>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Karasikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Pagès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergei</forename><surname>Grudinin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="2801" to="2808" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Directional message passing for molecular graphs</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Klicpera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janek</forename><surname>Groß</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Native protein sequences are close to optimal for their structures</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Kuhlman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page" from="10383" to="10388" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Direct prediction of profiles of sequences compatible with a protein structure by neural networks with fragment-based local and energy-based nonlocal profiles</title>
		<author>
			<persName><forename type="first">Zhixiu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuedong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eshel</forename><surname>Faraggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoqi</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins: Structure, Function, and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2565" to="2573" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Spin2: Predicting sequence profiles from protein structures using deep neural networks</title>
		<author>
			<persName><forename type="first">O'</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhixiu</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rhys</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Heffernan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuldip</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdollah</forename><surname>Paliwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuedong</forename><surname>Dehzangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins: Structure, Function, and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="629" to="633" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Voromqa: Assessment of protein structure quality using interatomic contact areas</title>
		<author>
			<persName><forename type="first">Kliment</forename><surname>Olechnovič</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Česlovas</forename><surname>Venclovas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins: Structure, Function, and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1131" to="1145" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Protein model quality assessment using 3d oriented convolutional neural networks</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Pagès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoit</forename><surname>Charmettant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergei</forename><surname>Grudinin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="3313" to="3319" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Boosting dockingbased virtual screening with deep learning</title>
		<author>
			<persName><forename type="first">Cruz</forename><surname>Janaina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ernesto</forename><forename type="middle">Raul</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cicero Nogueira Dos</forename><surname>Caffarena</surname></persName>
		</author>
		<author>
			<persName><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2495" to="2506" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Densecpd: Improving the accuracy of neural-network-based computational protein sequence design with densenet</title>
		<author>
			<persName><forename type="first">Yifei</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John Zh</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Information and Modeling</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1245" to="1252" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A structure-based deep learning framework for protein engineering</title>
		<author>
			<persName><forename type="first">Raghav</forename><surname>Shroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Austin</forename><forename type="middle">W</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barrett</forename><forename type="middle">R</forename><surname>Morrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">J</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isaac</forename><surname>Donnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Gollihar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">D</forename><surname>Ellington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Thyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<biblScope unit="page">833905</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fast and flexible protein design using deep graph neural networks</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Strokach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Becerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carles</forename><surname>Corbi-Verge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Perez-Riba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">M</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell Systems</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="402" to="411" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Studer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Rempfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Waterhouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafal</forename><surname>Gumienny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juergen</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torsten</forename><surname>Schwede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Qmeandiscodistance constraints applied on model quality estimation. Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1765" to="1771" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">End-to-end learning on 3d protein structure for interface prediction</title>
		<author>
			<persName><forename type="first">Raphael</forename><surname>Townshend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patricia</forename><surname>Suriana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ron</forename><surname>Dror</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="15616" to="15625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Proq3d: improved model quality assessments using deep learning</title>
		<author>
			<persName><forename type="first">Karolis</forename><surname>Uziela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">Menéndez</forename><surname>Hurtado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanjiang</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Björn</forename><surname>Wallner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arne</forename><surname>Elofsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1578" to="1580" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Computational protein design with deep learning neural networks</title>
		<author>
			<persName><forename type="first">Jingxue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huali</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">Zh</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifei</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Assessment of protein model structure accuracy estimation in casp13: Challenges in the era of deep learning</title>
		<author>
			<persName><forename type="first">Jonghun</forename><surname>Won</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minkyung</forename><surname>Baek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bohdan</forename><surname>Monastyrskyy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Kryshtafovych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaok</forename><surname>Seok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins: Structure, Function, and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1351" to="1360" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Processing and evaluation of predictions in casp4</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Zemla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Česlovas</forename><surname>Venclovas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Moult</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krzysztof</forename><surname>Fidelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins: Structure, Function, and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">S5</biblScope>
			<biblScope unit="page" from="13" to="21" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Prodconn: Protein design using a convolutional neural network</title>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chun-Chao</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuwen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinfeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins: Structure, Function, and Bioinformatics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
