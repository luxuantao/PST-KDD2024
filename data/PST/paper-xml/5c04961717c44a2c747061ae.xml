<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Binary Dragonfly Optimization for Feature Selection using Time-Varying Transfer functions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-08-04">August 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Majdi</forename><surname>Mafarja</surname></persName>
							<email>mmafarja@birzeit.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Birzeit University</orgName>
								<address>
									<settlement>Birzeit</settlement>
									<country key="PS">Palestine</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ibrahim</forename><surname>Aljarah</surname></persName>
							<email>i.aljarah@ju.edu.jo</email>
							<affiliation key="aff1">
								<orgName type="department">King Abdullah II School for Information Technology</orgName>
								<orgName type="institution">The University of Jordan</orgName>
								<address>
									<settlement>Amman</settlement>
									<country key="JO">Jordan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ali</forename><forename type="middle">Asghar</forename><surname>Heidari</surname></persName>
							<email>as_heidari@ut.ac.ir</email>
							<affiliation key="aff2">
								<orgName type="department">School of Surveying and Geospatial Engineering</orgName>
								<orgName type="institution">University of Tehran</orgName>
								<address>
									<settlement>Tehran</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hossam</forename><surname>Faris</surname></persName>
							<email>hossam.faris@ju.edu.jo</email>
							<affiliation key="aff1">
								<orgName type="department">King Abdullah II School for Information Technology</orgName>
								<orgName type="institution">The University of Jordan</orgName>
								<address>
									<settlement>Amman</settlement>
									<country key="JO">Jordan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Philippe</forename><surname>Fournier-Viger</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">School of Natural Sciences and Humanities</orgName>
								<orgName type="institution" key="instit1">Harbin Institute of Technology (Shenzhen)</orgName>
								<orgName type="institution" key="instit2">HIT Campus</orgName>
								<address>
									<settlement>Xili, Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaodong</forename><surname>Li</surname></persName>
							<email>xiaodong.li@rmit.edu.au</email>
							<affiliation key="aff4">
								<orgName type="department">School of Science</orgName>
								<orgName type="institution">RMIT University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Seyedali</forename><surname>Mirjalili</surname></persName>
							<email>seyedali.mirjalili@griffithuni.edu.au</email>
							<affiliation key="aff5">
								<orgName type="department">Institute of Integrated and Intelligent Systems</orgName>
								<orgName type="institution">Griffith University</orgName>
								<address>
									<postCode>4111</postCode>
									<settlement>Nathan, Brisbane</settlement>
									<region>QLD</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Binary Dragonfly Optimization for Feature Selection using Time-Varying Transfer functions</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-08-04">August 4, 2018</date>
						</imprint>
					</monogr>
					<idno type="MD5">EE06EA9F84E5083950C0C4D0ECBA2299</idno>
					<idno type="DOI">10.1016/j.knosys.2018.08.003</idno>
					<note type="submission">Received date: 28 December 2017 Revised date: 31 July 2018 Accepted date: 4 August 2018 Preprint submitted to Knowledge-based systems</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Knowledge-Based Systems Feature Selection</term>
					<term>Optimization</term>
					<term>Binary Dragonfly Algorithm</term>
					<term>classification</term>
					<term>Transfer Functions</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Dragonfly Algorithm (DA) is a recently proposed heuristic search algorithm that was shown to have excellent performance for numerous optimization problems. In this paper, a wrapper-feature selection algorithm is proposed based on the Binary Dragonfly Algorithm (BDA). The key component of the BDA is the transfer function that maps a continuous search space to a discrete search space. In this study, eight transfer functions, categorized into two families (S-shaped and V-shaped functions) are integrated into the BDA and evaluated using eighteen benchmark datasets obtained from the UCI data repository. The main contribution of this paper is the proposal of time-varying S-shaped and V-shaped transfer functions to leverage the impact of the step vector on balancing exploration and exploitation. During the early stages of the optimization process, the probability of changing the position of an element is high, which facilitates the exploration of new solutions starting from the initial population. On the other hand, the probability of changing the position of an element becomes lower towards the end of the optimization process. This behavior is obtained by considering the current iteration number as a parameter of transfer functions. The performance of the proposed approaches is compared with that of other state-of-art approaches including the DA, binary grey wolf optimizer (bGWO), binary gravitational search algorithm (BGSA), binary bat algorithm (BBA), particle swarm optimization (PSO), and genetic algorithm in terms of classification accuracy, sensitivity, specificity, area under the curve, and number of selected attributes. Results show that the time-varying S-shaped BDA approach outperforms compared approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>• Eight time varying S-shaped and V-shaped transfer functions are proposed.</p><p>• The leverage of using time-varying transfer functions on exploration and exploitation behaviors is investigated.</p><p>• Extensive tests are made to assess the proposed algorithms on the datasets to prove their merits In the past decades, metaheuristic and evolutionary algorithms were shown to be very successful for solving various optimization problems <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref>. The Dragonfly Algorithm (DA) is a recent metaheuristic, which is inspired by the behavior of dragonflies <ref type="bibr" target="#b5">[6]</ref>. The DA can be regarded as a recently successful algorithm that can outperform other well-regarded optimizers. The DA has been applied to several real-world problems such as economic emission dispatch in power systems <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, simulation building <ref type="bibr" target="#b8">[9]</ref>, wireless node localization in computer networks <ref type="bibr" target="#b9">[10]</ref> and machine learning <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. The DA has shown an excellent performance for several continuous, discrete, single-objective and multi-objective optimization problems compared to several state-of-the-art metaheuristic and evolutionary algorithms such as Particle Swarm Optimization (PSO) and Differential Evolution (DE).</p><p>Up to 2018, several works have utilized the DA or improved its performance to tackle practical tasks such as photovoltaic systems <ref type="bibr" target="#b12">[13]</ref>, extension of RFID network lifetime <ref type="bibr" target="#b13">[14]</ref>, 0-1 knapsack problems <ref type="bibr" target="#b14">[15]</ref>, and economic emission dispatch problem <ref type="bibr" target="#b15">[16]</ref>. In 2017, KS and Murugan <ref type="bibr" target="#b16">[17]</ref> proposed a memory-based hybrid DA that integrates concepts of PSO for dealing with global optimization cases. Song and Li <ref type="bibr" target="#b17">[18]</ref> proposed a modified DA with elite opposition learning for global optimization.</p><p>Recently, a binary version of the DA called BDA was proposed by Mirjalili <ref type="bibr" target="#b5">[6]</ref>, which applies a transfer function (TF) to map a continuous search space to a discrete one. The potential of BDA was initially evaluated on some feature selection problems and results have shown that this method has acceptable performance <ref type="bibr" target="#b18">[19]</ref>.</p><p>In general, a TF must map a continuous search space to a discrete space. In this regard, selecting a suitable TF is an important decision for improving the performance of binary velocity-based algorithms (e.g. PSO and DA) <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>. Using TFs is recommended in several works due to several reasons <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">22]</ref>. Firstly, TFs are algorithm independent and do not impact the search behavior of an algorithm. Secondly, the computational complexity of the algorithm does not change since the TF is calculated for each solution during each iteration. Thirdly, exploration and exploitation can be boosted when using a TF. The core drawback of a TF comes from the nature of this component. Transfer functions map velocity to probability. Hence, an algorithm should have a velocity vector. In other words, it is not a generic operator that can be used for all optimization algorithms. The other drawback of typically employed TFs within binary optimizers (e.g. the sigmoid, tangent and log-sigmoid functions <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b22">23]</ref>) is that they do not adapt exploration and exploitation in an evolutionary way during the search for solutions. They calculate the probability of changing the value of parameters in a non-adaptive way.</p><p>The operators of population-based algorithms are the only components that guide exploration and exploitation. Improving the performance of any population-based optimizer such as the DA requires to select an appropriate balance between exploration (diversification) and exploitation (intensification). Generally speaking, exploration is more important</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>than intensification during the early stages of the selection process, to explore promising regions of the feature space. But during the later stages, exploitation becomes more important because we need to increase the probability of discovering better solutions, close to those found in the previous phases. To solve challenging and high-dimensional problems, where a good balance between exploration and exploitation is required, hybrid methods can be developed. However, such techniques normally increase the computational cost of the whole optimization process.</p><p>Based on the aforementioned observations and since DA utilizes velocity vectors for updating solutions, the main contribution of this paper is to propose several time-varying TFs for the DA for binary tasks. This work demonstrates and argues that how a TF can be utilized to fine-tune and control the exploration and exploitation behavior of an optimizer is important. In other words, a TF can play a key role in tuning the exploration and exploitation phases of an optimizer rather than just converting a continuous search space to a binary one.</p><p>Based on this idea, this study proposes the use of a controlling parameter that has a gradually decreasing influence over the course of iterations, and that idea is applied to BDA. To assess the performance of BDA, this paper considers the task of feature selection, as it is a fundamental binary optimization problem that is challenging and high-dimensional, and has many applications.</p><p>This work proposes a wrapper feature selection approach that utilizes the recent BDA as a search strategy and the K-Nearest Neighborhood (KNN) classifier as an evaluator. The main aim of this study is to propose and investigate the effects of eight time-dependent TFs on the efficiency of BDA. Moreover, the results from the eight proposed approaches are compared with the original DA and some other state-of-the-art algorithms.</p><p>The contributions of this research can be summarized as follows:</p><p>• Several binary variants of the DA are proposed.</p><p>• This paper investigates the exploration and exploitation behavior of BDA with existing TFs and identifies their possible negative effects on the balance between exploration and exploitation.</p><p>• Various time-dependent S-shaped and V-shaped TFs are proposed to effectively overcome the drawbacks of existing TFs, and provide a stable balance between exploration and exploitation in BDA.</p><p>• The improved searching capabilities of the proposed time-dependent variants of the BDA is evaluated on several well-regarded feature selection datasets, and excellent results are obtained.</p><p>The rest of the paper is organized as follows. A theoretical background about feature selection is presented and related work is reviewed in Section 2. Section 3 describes the DA. Section 4 introduces the BDA. Section 5 presents the proposed approach. Experimental results and discussion are presented in Section 6, and finally, a conclusion is drawn and opportunities for future work are discussed in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background on feature selection</head><p>Feature selection (FS) plays an important role in various machine learning and data mining tasks such as object-based image classification <ref type="bibr" target="#b23">[24]</ref>, prediction of groundwater nitrate pollution <ref type="bibr" target="#b24">[25]</ref>, intrusion detection <ref type="bibr" target="#b25">[26]</ref>, automatic satire and irony detection <ref type="bibr" target="#b26">[27]</ref>, music streaming recommendation <ref type="bibr" target="#b27">[28]</ref>, spam detection <ref type="bibr" target="#b28">[29]</ref>, financial distress prediction <ref type="bibr" target="#b29">[30]</ref>, and classification <ref type="bibr" target="#b30">[31]</ref>. Bolón-Canedo et al. <ref type="bibr" target="#b31">[32]</ref> discussed challenges of FS in the context of big data. FS aims at improving classification accuracy by eliminating redundant, irrelevant, and noisy data from a dataset. According to Liu and Motoda <ref type="bibr" target="#b32">[33]</ref>, FS algorithms can be classified based on two main criteria: their subset evaluation procedure and their searching procedure. In terms of the former, FS methods are categorized as filters and wrappers <ref type="bibr" target="#b32">[33]</ref>. Wrapper approaches utilizes a learning algorithm (e.g. classifier) to evaluate feature subsets, while filters evaluate a feature subset using the data itself (e.g. using a measure such as the information gain) <ref type="bibr" target="#b33">[34]</ref>.</p><p>Finding an optimal subset of features for FS problems is challenging due to the large number of possible combinations. A naive approach to solve a FS problem is to apply a brute-force search and generate all possible subsets of features to find the best one. If the original dataset contains k features, then there are 2 k -1 subsets to be generated and evaluated.</p><p>Due to the exponential complexity of this approach, it is impractical when N is very large. A more practical solution to solve FS problems is to utilize a heuristic search <ref type="bibr" target="#b34">[35]</ref>. As the name suggests, the search is guided using heuristic information collected during the optimization process. Although heuristic search techniques do not guarantee finding the best subset of features, they can generally produce an acceptable solution quickly <ref type="bibr" target="#b35">[36]</ref>.</p><p>Metaheuristics are general purpose algorithms, which have been readily applied to a wide range of problems <ref type="bibr" target="#b35">[36]</ref>. Nature-inspired algorithms are mostly metaheuristics and mimic the social and biological behaviors of creatures in nature. Various nature-inspired algorithms have been utilized to tackle the FS problem in the literature such as GA <ref type="bibr" target="#b36">[37]</ref>, PSO <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref>, Ant Colony Optimization (ACO) <ref type="bibr" target="#b41">[42]</ref>, DE <ref type="bibr" target="#b42">[43]</ref>, Bacterial Foraging Optimization (BFO) <ref type="bibr" target="#b43">[44]</ref>, and Artificial Bee Colony (ABC) <ref type="bibr" target="#b44">[45]</ref>.</p><p>Recently, new nature-inspired algorithms have been proposed and have shown improved results for the FS problems. For instance, an Ant Lion Optimizer (ALO) <ref type="bibr" target="#b45">[46]</ref>, which mimics the hunting behavior of antlions, has been employed as a wrapper FS method <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref>. Grey Wolf Optimizer (GWO) is another recent algorithm <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref> that has been successfully employed for solving feature selection problems <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b52">53]</ref>. Moth-Flame Optimizer (MFO) <ref type="bibr" target="#b53">[54]</ref> is an algorithm that mimics the navigation method of moths and has been applied to the FS problem by Zawbaa et al. <ref type="bibr" target="#b54">[55]</ref>. Multi-Verse Optimizer (MVO) is another recent example of metaheuristics that was applied in combination with classifiers to some FS problems Faris et al. <ref type="bibr" target="#b55">[56]</ref>.</p><p>Mafarja and Abdullah <ref type="bibr" target="#b56">[57]</ref> proposed a mimetic filter FS approach that combines the capability of Simulated Annealing (SA) as a local search algorithm with a GA.</p><p>In subsequent work in <ref type="bibr" target="#b57">[58]</ref>, SA was hybridized with the Whale Optimization Algorithm (WOA) to form a wrapper FS approach. WOA was also recently used as a wrapper FS approach in <ref type="bibr" target="#b58">[59]</ref>. In that approach, evolutionary operators (i.e., crossover, mutation</p><formula xml:id="formula_0">A C C E P T E D M A N U S C R I P T</formula><p>and selection) were employed to enhance both the exploration and exploitation capabilities of the WOA. The reported results revealed the benefits of combining those operators with WOA. In <ref type="bibr" target="#b47">[48]</ref>, the performance of the Ant Lion Optimizer (ALO) algorithm with eight different TFs was investigated. Another study Faris et al. <ref type="bibr" target="#b59">[60]</ref> proposed a novel FS approach based on a recent metaheuristic algorithm called Multi-Verse Optimizer (MVO). In 2018, Mafarja et al. <ref type="bibr" target="#b60">[61]</ref> proposed an improved grasshopper optimization algorithm (GOA) with new evolutionary-based operators, which is called GOA-EPD, to develop an efficient wrapper FS method. Salp Swarm Algorithm (SSA) is another recent metaheuristic that has been used in a wrapper FS method in <ref type="bibr" target="#b61">[62]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Overview of the Dragonfly Algorithm</head><p>The Dragonfly Algorithm is a recently proposed swarm-based algorithm <ref type="bibr" target="#b5">[6]</ref>. The DA mimics the hunting and migration mechanisms of idealized dragonflies. The hunting mechanism is called static swarm (feeding), in which the dragonflies fly in small groups over a small area to search for food sources. The migration mechanism is called dynamic swarm (migratory). In this phase, the dragonflies fly along one direction in larger groups so that the swarm migrates. Static and dynamic swarms are illustrated in Fig 1 . Similarly to other nature-inspired algorithms, the DA consists of two phases: exploration, inspired by the static swarming behavior, and exploitation, inspired by the dynamic swarming behavior.  To model the swarming behavior of dragonflies, five individual behaviors are utilized as follows. In the following equations, X represents the position of the current search agent, X j represents the j-th neighbor of the X search agent, and N is the neighborhood size <ref type="bibr" target="#b62">[63]</ref>:</p><p>• Separation is a mechanism that a search agent applies to stay away from other</p><formula xml:id="formula_1">A C C E P T E D M A N U S C R I P T</formula><p>neighboring search agents. This behavior is mathematically modeled as Eq. ( <ref type="formula" target="#formula_2">1</ref>):</p><formula xml:id="formula_2">S i = - N j=1 X -X i<label>(1)</label></formula><p>• Alignment indicates how an individual matches its velocity with the velocity of other neighboring individuals. This behavior is mathematically modeled as Eq. ( <ref type="formula" target="#formula_3">2</ref>):</p><formula xml:id="formula_3">A i = N j=1 V j N<label>(2)</label></formula><p>where V j represents the velocity of the j-th neighbor.</p><p>• Cohesion refers to the tendency of individuals to fly towards the neighboring center of mass. This behavior is mathematically modeled as Eq. ( <ref type="formula" target="#formula_4">3</ref>):</p><formula xml:id="formula_4">C i = N j=1 x j N -X<label>(3)</label></formula><p>• Attraction refers to the tendency of individuals to fly towards the food source. The attraction between the food source and the i th solution is mathematically modeled as Eq. ( <ref type="formula" target="#formula_5">4</ref>):</p><formula xml:id="formula_5">F i = F loc -X<label>(4)</label></formula><p>where F loc represents the position of the food source.</p><p>• Distraction refers to the tendency of individuals to fly away from an enemy. The distraction between the enemy and the i th solution is mathematically modeled as Eq. ( <ref type="formula" target="#formula_6">5</ref>):</p><formula xml:id="formula_6">E i = E loc + X<label>(5)</label></formula><p>where E loc represents the enemy's position.</p><p>In the DA, the food source fitness and location are supposed to be updated using the best candidate (search agent) so far. In addition, the fitness and location of the enemy should be updated using the worst candidate. This causes convergence towards promising areas and divergence outwards non-promising regions of the search space.</p><p>Based on the framework of the PSO algorithm, the DA uses two vectors to update the position of a dragonfly: the step vector (∆X) that is similar to the velocity vector in PSO and the position vector. The step vector represents the dragonflies' movement direction. The step vector is modeled as Eq. ( <ref type="formula" target="#formula_7">6</ref>):</p><formula xml:id="formula_7">∆X t+1 = (sS i + aA i + cC i + f F i + eE i ) + wX t<label>(6)</label></formula><p>where s, w, a, c, f , and e represent the weights of the separation S i , alignment</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>A i , cohesion C i , attraction towards the food source F i , and distraction from the enemy E i of the i-th individual's respectively. These weights enable the DA to achieve different exploration and intensification behaviors during optimization. An extensive analysis of the effect of those parameters on the DA and their values can be found in <ref type="bibr" target="#b5">[6]</ref>.</p><p>The position of an individual is updated as in Eq. ( <ref type="formula" target="#formula_8">7</ref>):</p><formula xml:id="formula_8">X t+1 = X t + ∆X t+1 (<label>7</label></formula><formula xml:id="formula_9">)</formula><p>where t is the current iteration.</p><p>Algorithm 1 shows the pseudocode of the DA. The algorithm starts by creating a random initial population. The positions and step vectors of dragonflies are randomly defined. In each iteration, the algorithm repeatedly executes the following steps until a termination criterion is satisfied. Firstly, each individual in the population is evaluated using a fitness function. Secondly, the main coefficients are updated. Thirdly, the separation (S), alignment (A), and cohesion (C), food source (F ) and enemy (E) are updated using Eqs. 1 to 5. Finally, the step vectors and the position are updated using Eqs 6 and Eq. 7, respectively.</p><p>Finally, the best solution found so far is returned. In a binary optimization problem, the search space is considered as a hypercube, where an individual can change its position from one location to another by changing one or more bits of its position vector x = {x 1 , x 2 , ..., x d }. Since the original DA was designed for handling continuous optimization problems, the position of an individual is updated by adding the current position vector to the step vector. However, this mechanism cannot be used to handle a binary optimization problem such as feature selection. According to a previous study Mirjalili and Lewis <ref type="bibr" target="#b19">[20]</ref>, employing a transfer function is an effective and convenient way of converting a continuous algorithm into a binary one. Transfer functions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T are categorized in two families according to their shapes: S-shaped and V-shaped. Fig. <ref type="figure" target="#fig_5">2</ref> depicts these two families of transfer functions.  Generally speaking, transfer functions are used to generate the probability of changing a position's elements to 0 or 1 based on the value of the step vector (velocity) of the i th search agent in the d th dimension in the current iteration (t) as an input parameter. In a previous study <ref type="bibr" target="#b5">[6]</ref>, the transfer function of Eq. (8 was employed to calculate the probability of changing the continuous positions to binary.</p><formula xml:id="formula_10">T (v i d (t)) = |(v i d (t))/ 1 + (v i d (t)) 2 |<label>(8)</label></formula><p>The result T (v i k (t)), obtained from Eq. ( <ref type="formula" target="#formula_10">8</ref>) is then used to convert the i-th element of the position vector to 0 or 1 according to Eq. 9</p><formula xml:id="formula_11">X(t + 1) = ¬X t r &lt; T (v i k (t)) X t r ≥ T (v i k (t))<label>(9)</label></formula><p>where r is a random number in the [0,1] interval. The step vector indicates the momentum of the current individual and defines the magnitude of movement. A lower step vector value indicates that the individual is very close to the best solution and needs to move in smaller steps (exploitation). In contrast, if the step vector value is large, the search agent is far from the best solution so far and requires abrupt changes (exploration) <ref type="bibr" target="#b63">[64]</ref>. In a binary algorithm, where one uses the step vector to calculate the probability of changing positions, TFs significantly impact the balance between exploration and exploitation. If the transfer function does not change, probability will be calculated in the same manner throughout the optimization process.</p><p>Changing the TF has the potential to leverage the impact of the step vector on position updates for exploring and exploiting the search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">The proposed approach</head><p>The first TF Eq. ( <ref type="formula">10</ref>) was proposed by <ref type="bibr">Kennedy and Eberhart [38]</ref>. This function belongs to the S-shaped family. <ref type="bibr" target="#b9">(10)</ref> where v i k (t) represents the step vector of the i-th search agent at the t-th iteration in the k-th dimension.</p><formula xml:id="formula_12">T (v k i (t)) = 1 1 + e -v k i (t)</formula><p>Each element of the vector representing the current individual will be changed according to Eq. 11 based on the probability value T (v i k (t)) obtained from Eq. 10.</p><formula xml:id="formula_13">x k i (t + 1) = 1 rand &lt; T (v k i (t + 1)) 0 rand ≥ T (v k i (t + 1))<label>(11)</label></formula><p>An extensive study of the influence of TFs on the efficiency and final results of binary PSO was recently presented in <ref type="bibr" target="#b21">[22]</ref>. The study evaluated three classes of TFs including S-shaped, V-shaped and linear normalized TFs.</p><p>By observing the sigmoid function in Eq. 10, it can be seen that the current version of this function does not provide a good balance between exploration and exploitation, where the exploration rate should be more than the exploitation rate at the beginning of the optimization process. Thus, some promising areas inside the search space may remain unexplored. As a result, there is a high possibility that the optimizer will get trapped in local optima (LO). A similar phenomenon can also be observed during the exploitation stage.</p><p>Inspecting the ordinary TFs (see Fig. <ref type="figure" target="#fig_5">2</ref>), it can be seen that with the small absolute values of inputs, the probability of flipping an element in the dth dimension of a solution is high, while with the large absolute values of inputs the flipping probability is low. Therefore, to better explore the search space at the early stages of the optimization process, a small absolute value of step vector (close to zero) is preferable. On the other hand, to better exploit the search space in the final stages of the optimization process, a large absolute value of step vector is preferable. With the current form of the sigmoid function, a high flipping probability is produced when a low probability is required.</p><p>As a result, there is a high probability that the optimizer will oversight good solutions in the neighborhood of the solutions that have been found during the exploration phase. All these issues are caused by the fact that a TF cannot map step vector values to appropriate probability values without changing its shape during the optimization process.</p><p>Another TF that belongs to the V-shaped family (V T 1 ) is represented in Eq. 12:</p><formula xml:id="formula_14">T (∆x) = 1 -2 1+e -2x x ≤ 0 2 1+e -2x -1 x &gt; 0<label>(12)</label></formula><p>The position of the current search agent is changed in Eq. ( <ref type="formula" target="#formula_15">13</ref>) according to the probability value T (v i k (t)) obtained from Eq. 12.</p><p>A</p><formula xml:id="formula_15">C C E P T E D M A N U S C R I P T X k+1 id =    0 r ≤ T (∆x t+1 )and∆x t+1 ≤ 0 1 r ≤ T (∆x t+1 )and∆x t+1 ≥ 0 X k id r &gt; T (∆x t+1 )<label>(13)</label></formula><p>where r is a random number in the [0,1] interval.</p><p>After examining V T 1 , one can see that the algorithm still suffers from biased stability between the exploration and exploitation phases due to problems similar to those of the S-shaped function. Inspired by <ref type="bibr" target="#b21">[22]</ref>, an effective strategy to mitigate this problem in the BDA is to update the S-shaped TF in Eq. 10 and design a new model of TFs as shown in Eq. 14. In the proposed TFs, a time-varying scheme is employed to achieve a better balance between exploration and exploitation.</p><formula xml:id="formula_16">T (v k i (t), τ ) = 1 1 + e -v k i (t) τ (<label>14</label></formula><formula xml:id="formula_17">)</formula><p>where τ is a time-varying variable that starts with an initial value and gradually decreases over iterations as shown in Eq. 15.</p><formula xml:id="formula_18">τ = 1 - t T τ max + t T τ min<label>(15)</label></formula><p>where τ min and τ max are the min and max values of the control parameter τ , T represents the maximum number of iterations and t k+1 represents the current iteration.</p><p>The key fact about the newly proposed time-dependent TF is that its value can be linearly increased as the step vector of search agents increases. During early stages (when τ = τ max ), the probability of changing the position's element is higher, which provides higher exploration capacities for the initial population. On the other hand, the probability of changing the position's element becomes very low once τ = τ min , which provides steadier exploitation inclinations in latter stages of the run.</p><p>In previous work <ref type="bibr" target="#b21">[22]</ref>, only one TF was employed and tested on the 0-1 knapsack problem, which was the improved sigmoid function. Authors of that study stated that the V-shaped TF suffers from the same problem as the S-shaped TF, but they did not study the possibility of adaptively updating this function over the iterations. In this work, the original TF is modified by adding a time-varying parameter as shown in Eq. 16. The proposed TF satisfies the design considerations mentioned in <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b19">20]</ref>.</p><formula xml:id="formula_19">T (∆x, τ ) = 1 -2 1+e -2x τ x ≤ 0 2 1+e -2x τ -1 x &gt; 0<label>(16)</label></formula><p>In this work, seven new TFs manipulating the coefficient of x are introduced. Table <ref type="table">1</ref> contains the mathematical formulations of the TFs proposed in this research. Figure <ref type="figure" target="#fig_7">3</ref> and Figure <ref type="figure" target="#fig_9">4</ref> show the behaviors of the proposed time-dependent TFs.</p><p>Algorithm 2 shows the pseudocode of BDA. The algorithm starts by creating a random initial population; the position and step vectors of dragonflies are randomly defined. In each iteration, the algorithm repeatedly executes the following steps until a termination    </p><formula xml:id="formula_20">A C C E P T E D M A N U S C R I P T Table 1: T V S -shaped and T V V -shaped transfer functions T V S family T V V family Name Transfer function Name Transfer function T V S1 T (x, τ ) = 1 1+e -2x τ T V V 1 T (x, τ ) = 1 -2 1+e -2x τ x ≤ 0 2 1+e -2x τ -1 x &gt; 0 T V S2 T (x, τ ) = 1 1+e -x τ T V V 2 T (x, τ ) = 1 -2 1+e -x τ x ≤ 0 2 1+e -x τ -1 x &gt; 0 T V S3 T (x, τ ) = 1 1+e -x 2τ T V V 3 T (x, τ ) = 1 -2 1+e -x 2τ x ≤ 0 2 1+e -x 2τ -1 x &gt; 0 T V S4 T (x, τ ) = 1 1+e -x 3τ T V V 4 T (x, τ ) = 1 -2 1+e -x 3τ x ≤ 0 2 1+e -x 3τ -1 x &gt; 0 -4 -3 -2 -1 0 1 2<label>3</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D</head><formula xml:id="formula_21">M A N U S C R I P T -4 -3 -2 -1 0 1 2 3 4 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 x Probability (a) T V V 1 -4 -3 -2 -1 0 1 2 3 4 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 x Probability (b) T V V 2 -4 -3 -2 -1 0 1 2<label>3</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>criterion is satisfied. Firstly, each individual in the population is evaluated using a fitness function. Secondly, the main coefficients are updated. Thirdly, the separation (S), alignment (A), and cohesion (C), food source (F ) and enemy (E) are calculated using Eqs. 1 to 5. Finally, the step vectors, transfer and the position are updated using Eqs 6, 10, and 11.</p><p>Note that adding the time-varying S-shaped and V-shaped TFs does not change the computational complexity of the DA since this component is run only once for each solution and in each iteration. Therefore, the computational complexity of binary DA is of O(tnd) where t is the number of iterations, n shows the number of solutions, and d indicates the number of dimensions (variables). This complexity is identical to those of other comparative algorithms in this work: PSO, bGWO, GA, BGSA, and BBA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Pseudocode of the BDA algorithm</head><p>Initialize the population</p><formula xml:id="formula_22">X i (i = 1, 2, . . . , n) Initialize ∆X i (i = 1, 2, . . . , n)</formula><p>Set τ max and τ min Initialize τ using Eq. 15 while (end condition is not satisfied) do Evaluate each dragonfly Update (F ) and (E) Update the main coefficients (i., e., w, s, a, c, f, ande) Calculate S, A, C, F , and E (using Eqs. (1 to 5)) Update step vectors using Eq. ( <ref type="formula" target="#formula_7">6</ref>) Calculate T (∆X) using an equation from Table <ref type="table">1</ref> Update X t+1 using Eq. 11 or Eq. 13 Return the best solution</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">BDA for feature selection</head><p>Feature selection is considered as a binary optimization problem, where solutions are restricted to binary values. Therefore, the binary version of the DA could be employed to solve this problem. In this work, a vector of zeros and ones is used to represent a solution to a FS problem, where a zero indicates that the corresponding feature is not selected and a one indicates that the corresponding feature is selected. The length of the solution vector is equal to the number of features in the original dataset. In this work, eight wrapper feature selection approaches using the BDA are proposed. Each approach utilizes a transfer function to convert a continuous value to a binary value. The KNN classifier <ref type="bibr" target="#b64">[65]</ref> evaluates the selected feature subsets. The fitness function considers classification accuracy and the number of selected features, which fulfill the consideration that FS is a multi-objective problem. The objective function is presented in Eq. 17:</p><formula xml:id="formula_23">↓ F itness = αγ R (D) + β |C| |N | (17) A C C E P T E D M A N U S C R I P T</formula><p>where γ R (D) represents the classification error rate, while |C| is the number of selected features and |N | is the total number of features in the original dataset, α and β are two parameters corresponding to the importance of classification quality and subset length, α is in the [0,1] interval and β =(1 -α) is adapted from <ref type="bibr" target="#b58">[59]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experimental evaluation and discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Experimental setup</head><p>The proposed approaches were tested on eighteen feature selection datasets obtained from the UCI data repository <ref type="bibr" target="#b65">[66]</ref>. Table <ref type="table" target="#tab_1">2</ref> shows characteristics of these datasets. The datasets belong to different fields (e.g. biology, politics, games, physics, and chemistry) and are of different sizes. The diversity of the selected datasets facilitates benchmarking of the proposed approaches from different perspectives. In the proposed approach, to validate the optimality of the results, the hold-out strategy was used, where each dataset is randomly divided into two parts; training and testing, where 80% of each dataset is used for training and the remaining 20% is for testing purposes <ref type="bibr" target="#b58">[59]</ref>. All experiments were repeated for 30 independent times to obtain statistically meaningful results. Furthermore, each algorithm was implemented using MATLAB 2013 and was run on an Intel Core i5 machine, 2.2 GHz CPU and 4 GB of RAM. 6.2. Parameter tuning BDA is a metaheuristic algorithm that is highly dependent on the parameter values when searching for the optimal solutions. Setting the suitable parameter values requires an extra effort since it depends on the problem being solved. To determine the most suitable values of the proposed approaches, the following empirical studies were conducted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>The parameters that were included in these studies are population size, max number of iterations, α and β (in the fitness function), the number of nearest neighbors (k) in the k-NN classifier. In all initial empirical studies, the Leukemia dataset was used because it revealed more sensitivity compared to other datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Assessment of the impact of population size and number of iterations</head><p>Table <ref type="table" target="#tab_2">3</ref> compares the performance of the optimizer as it is monitored for slight adjustments in the parameter values. As it can be interpreted from Table <ref type="table" target="#tab_2">3</ref>, for a population size of 10 and 100 iterations, the optimizer can obtain the best results in terms of classification accuracy, and is very competitive in terms of selection ratio and time. 6.4. Assessment of the impact of α and β on the fitness function FS problems cover two contradictory objectives (i.e., classification accuracy (maximization) and selection ration (minimization)) in the optimization process. In the fitness function (see Eq. 17), those two objectives are presented, and two values (α and β) were used to represent their weights for the user. That is, α determines the weight of classification accuracy, while β corresponds to the weight of the features reduction rate. In this section, an initial empirical study is presented to assess the influence of both α and β on the performance of the BDA optimizer. Different values for α and β were used to measure the classification accuracy and selection ration. The leukemia dataset was used in all experiments in this section due to its sensitivity in comparison with other datasets. Table <ref type="table" target="#tab_3">4</ref> shows the classification accuracy and selection ration with different combinations of α and β values. Inspecting the results in Table <ref type="table" target="#tab_3">4</ref>, it can be seen that accuracy rate and the selection ration are changing with the different values of α and β. That is to say, when increasing alpha, the classification accuracy increases and the selection ratio decreases.</p><p>To make fair comparisons with the results obtained in previous works, we set α = 0.99 and β = 0.01 which are commonly used values in the literature <ref type="bibr" target="#b54">[55]</ref>.</p><p>In the experiments, the K-NN classifier (with K = 5 <ref type="bibr" target="#b58">[59]</ref>), with the Euclidean distance metric, was used to evaluate the feature subsets.</p><p>The parameters setting of the algorithms are outlined in Table <ref type="table" target="#tab_4">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.">Results and discussion</head><p>To study the influence of the newly proposed time-dependent TFs on the performance of the BDA, this paper provides a comparison of the results obtained by BDA with eight static TFs and BDA, and those obtained by BDA with eight time-dependent TFs. The best reported approaches were then compared with state-of-the-art FS methods using two phases. In the first phase, we implemented three recent FS techniques (i.e. BGSA, BBA, and bGWO) and compared them with the proposed approaches. Then in the second phase we used some previously published results of some well-known algorithms (GA, PSO, and GWO). The comparisons are done using the following criteria:</p><p>• The mean classification accuracy was obtained from 30 runs. For each run, the accuracy of the best solution is considered.</p><p>• The average selection size from 30 runs. In each run, the cardinality of the best solution is considered.</p><p>• The average of the best fitness values obtained from each approach are reported.</p><p>• Statistical standard deviation (STD) is reported for all approaches to indicate the stability and robustness of the optimizer.</p><p>• Wilcoxon signed-rank test to assess the significance of the results obtained from the proposed approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>• Specificity, Sensitivity, and Area Under the ROC Curve (AUC) <ref type="bibr" target="#b66">[67]</ref> for binary datasets for each approach are reported.</p><p>Note that in the following tables, the best results are highlighted in bold.</p><p>The classification accuracy obtained from the approaches that are based on S-shaped TFs are reported in Table <ref type="table" target="#tab_5">6</ref>, followed by the results of the approaches based on the Vshaped TFs in Table <ref type="table" target="#tab_6">7</ref>. We named the approaches with the static TFs as S1 to S4 for the S-shaped TFs, and V1 to V4 for the V-shaped TFs. Similarly, the time dependent TFs are named as T V S1 to T V S4 for the S-shaped functions and</p><formula xml:id="formula_24">T V V 1 to T V V 4 for the V-shaped TFs.</formula><p>In general, it is observed that the BDA with time-dependent TFs (T V -T F s) perform better than those with fixed TFs. In Table <ref type="table" target="#tab_5">6</ref>, it is observed that T V S1 provided the best results on 50% of the datasets, and on three datasets it provided the same results as S1.</p><p>In the case of T V S2 , the traditional TFs approach performs better than the TV approach, however, it can be found that T V S3 obtained the best results for eight datasets and is competitive with S3 for five datasets, while S3 obtained the best results for only five datasets. S4 and T V S4 obtained the same results. The results in Table <ref type="table" target="#tab_5">6</ref> show that TV approaches are robust since they have the smallest standard deviation.</p><p>By observing the results of Table <ref type="table" target="#tab_6">7</ref>, it is obvious that TV performs well compared to traditional TFs based approaches. An exception is the case of V2 and T V V 2 that obtained nearly the same results, while T V V 1 , T V V 3 and T V V 4 obtained the best results for 70%, 72% and 77% of the datasets, respectively. The time TV-TFs with V-shaped functions highly improved the performance of the BDA. This is because a good balance is achieved between exploration and exploitation. The robustness of TV-BDA approaches is also observed as they obtained smaller values in terms of standard deviation.</p><p>In Tables <ref type="table" target="#tab_7">8</ref> and<ref type="table">9</ref>, the ratio of kept feature to the total number of features using the BDA that utilize the traditional TFs and TV-BDA are reported. Once again, the TV-BDA outperforms TF-BDA approaches on the majority of the datasets. In particular, T V S1 selected the minimal number features for 10 datasets and was competitive with other approaches on the two other datasets.</p><p>The same observation can be made when studying the behaviors of T V S2 , T V S3 , and T V S4 , which achieved the best performance on 12, 13 and 11 datasets, respectively. Since the main objective of FS is to minimize the number of selected features without decreasing the classification accuracy as much as possible, we can say that S-shaped TV-BDA approaches showed good performance since they obtained comparative classification accuracy using a smaller number of features. The same observation can be made from Table <ref type="table">9</ref>, where TV-BDA approaches obtained comparative performance in terms of number of selected features, while the classification accuracy of those approaches is much better than TF-BDA approaches.</p><p>From Table <ref type="table" target="#tab_9">10</ref>, it is found that the S-shaped TV-BDA optimizers are better than TF-BDA in terms of fitness measures. T V S1 obtained the best fitness value on 50% of the datasets, and on two datasets it obtained the same results as S1. In the case of T V S3 and T V S4 , it can be detected that they obtained the best results for 67% and 55% of the datasets, respectively.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmark</head><formula xml:id="formula_25">Measure V1 T V V 1 V2 T V V 2 V3 T V V 3 V4 T V V</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Table <ref type="table">9</ref>: Comparison between the original V-shaped transfer functions and time dependent variants in terms of minimum number of selected features </p><formula xml:id="formula_26">Benchmark Measure V1 T V V 1 V2 T V V 2 V3 T V V 3 V4 T V V</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Given that TV-BDA approaches have the lowest standard deviation as presented in Table <ref type="table" target="#tab_10">11</ref>, TV-based approaches can be considered as more robust than approaches based on traditional TFs. According to results of Table <ref type="table" target="#tab_10">11</ref>, V-shaped TV-BDA approaches outperform traditional V-shaped approaches for most datasets, where T V V 1 outperformed V1 on 72% of the datasets, and T V V 1 , and T V V 1 are better for 72% and 77% of the datasets, respectively.</p><p>These results indicate how important is the role of the TF in BDA, since by selecting a suitable function, the performance of the BDA can be remarkably increased. Moreover, it is clear that adapting the behavior of the TF through the optimization process has a major influence on improving the performance of the BDA. Furthermore, the good performance of the BDA highlights its ability at searching the feature space for the most informative features and avoid premature convergence that may be caused by falling in local optima.</p><p>In addition, the improved potential to balance between exploration and exploitation throughout iterations is another reason for the BDA's superiority. Since the only modification is the replacement of the traditional TFs with the TV-TFs, these results show that the adaptive control of the TFs can significantly improve the search ability of the BDA. Overall, we can say that T V S3 is the best approach when compared with S-shaped approaches, while T V V 4 ) is the best among the V-shaped approaches. In the next subsection, we assess the performance of those two approaches by comparing their performances with other well-known state-of-the-art FS algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6.">Comparison with other metaheuristic based approaches</head><p>After analyzing the results of the proposed approaches, this section presents a comparison between the best two approaches proposed in this work (T V S3 and T V V 4 ) and the most popular metaheuristics-based feature selection algorithms (BGWO, BGSA, BPSO, BBA, and GA).</p><p>The performance of T V S3 and T V V 4 is compared in terms of average accuracy and standard deviation. As per results in Table <ref type="table" target="#tab_12">12</ref>, T V S3 performs better than T V V 4 . It obtained the best results for 78% of the datasets. Moreover, we can observe that the performance of the proposed T V S3 approach is better than all the other algorithms for all datasets in terms of classification accuracy. Figure <ref type="figure">5</ref> compares T V S3 , T V V 4 and other approaches in terms of classification accuracy. Based on reduction rates presented in Table <ref type="table" target="#tab_13">13</ref>, it is observed that T V S3 outperforms other algorithms for 10 out of 18 datasets, while the BBA and the BGSA obtained the best results for seven datasets and one dataset, respectively. The obtained reduction rates are represented in Fig. <ref type="figure">6</ref>. Table <ref type="table" target="#tab_14">14</ref> shows the superiority of T V S3 , where the reported fitness combines both classification accuracy and reduction rate, and showed that T V S3 had the best values for 14 out of 18 datasets.    Table <ref type="table" target="#tab_15">15</ref> reports the results of the best BDA V-shaped and BDA S-shaped timedependent variants versus others algorithms for the specificity metric. Results of Table <ref type="table" target="#tab_15">15</ref> show that the proposed BDA-based techniques can outperform all other methods for that metric. For 69.23% of the datasets, the T V V 4 variant performs best, while for the rest of the cases; T V S3 has better results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><formula xml:id="formula_27">Benchmark Measure V1 T V V 1 V2 T V V 2 V3 T V V 3 V4 T V V</formula><p>Table <ref type="table" target="#tab_16">16</ref> compares the best BDA V-shaped and BDA S-shaped time-dependent variants and others optimizers for the sensitivity metric. From Table <ref type="table" target="#tab_16">16</ref>, we see that the proposed BDA-based techniques can outperform other competitors according to the sensitivity measure. For 61.53% of the datasets, the T V V 4 variant demonstrates satisfactory performance. But T V S3 has better performance for the rest of the cases except for SpectEW, where the BGSA has the highest sensitivity.</p><p>Table <ref type="table" target="#tab_17">17</ref> compares results of the best BDA V-shaped and BDA S-shaped time-varying variants with others optimizers for the AUC metric. It is observed that the proposed      The results thus far compared the average performance, STD, best and worst performance of algorithms for 30 runs. To judge whether results are significant or not, the Wilcoxon statistical test with 5% significance was conducted <ref type="bibr" target="#b67">[68]</ref>. The p-values of the Wilcoxon test based on fitness values are reported in Table <ref type="table" target="#tab_7">18</ref>. Such statistical tests consider all runs and can verify that the observed differences and improvements are significantly meaningful. Table <ref type="table" target="#tab_7">18</ref> shows that the superiority of T V S3 over bGWO, BGSA, and BBA is statistically significant for all cases. In addition, the observed differences between T V S3 and T V V 4 are statistically significant for most cases.</p><formula xml:id="formula_28">A C C E P T E D M A N U S C R I P T</formula><p>The p-values of the Wilcoxon test according to the number of features are shown in Table <ref type="table" target="#tab_18">19</ref>. As per results in Table <ref type="table" target="#tab_18">19</ref>, the observed differences between the T V V 4 and T V S3 techniques are statistically meaningful for all problems. Based on Tables <ref type="table" target="#tab_13">13</ref> and<ref type="table" target="#tab_18">19</ref>, it can be detected that BBA optimizer has obtained better results for several problems but the observed differences are not statistically significant. Hence, it is not significantly better    other approaches for several datasets. The golden areas indicates rates in the [60% 80%] interval. It can be observed that the proposed approaches (T V S3 and T V V 4 ) have smaller golden areas, which visually shows the result improvement. By reconsidering all the presented results, we can summarize observations. Timevarying TFs can effectively improve the BDA to generally deliver improved results compared to the versions based on traditional TFs. The dynamic nature of TV-based functions can assist the proposed binary optimizer to search the global feature space in a time-aware manner that focus around more promising neighborhood solutions when it is necessary. However, the current non-time-varying nature of TFs cannot adapt the exploration behavior at the beginning of the optimization process when it is required to deal with challenging feature spaces. Thus, it was seen that some promising regions inside the feature space remained unexplored or are not explored enough. This shows the significant role of dynamically-varying TFs to enhance the exploration and exploitation trends of the BDA. The dynamic behavior of proper TFs has mitigated the immature convergence and stagnation behaviors of the basic BDA with non-dynamic TFs. The reason is that in the case of stagnation, the proposed BDA can change its transfer function in the next iterations to avoid LO and it has thus an increased chance of escaping from them by fine-tuning its exploration and exploitation behaviors for the rest of the steps.</p><p>The key reason behind all observations is the benefits provided using TV-based TFs in efficiently balancing exploration and exploitation. Changing the shape of TF proportionally to the iteration counter (time dimension) allows the algorithm to leverage the impact of solid TFs on exploration and exploitation by using more varied searching patterns. Different shapes of TFs have varied the probability values that directly translate to the way that the BDA provides diversity or intensity around candidate features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Another main observation was that S-shaped functions outperform V-shaped functions. This is due to the mechanism that each family uses to update the position. When using an S-shaped TFs, the position will be updated using Eq. 11, in which the search agents are required to change the values of 1 to 0 if the step vector level is high. In contrast, the updating rules in the V-shaped TFs are different. The search agents will not be forced to take the values of 0 or 1, but they encourage search agents to stay in their current positions when their step vector values are low or switch to their complements when the step vector values are high. This can significantly degrade exploration of a metaheuristic algorithm.</p><p>According to the no free lunch (NFL) theorems <ref type="bibr" target="#b68">[69]</ref>, we cannot propose a universal best optimizer or feature selection approach. Hence, the proposed wrapper techniques follow the NFL rule.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8.">Results of algorithms on high-dimensional small instances datasets</head><p>In some fields such as the medical and biological studies, it is a hard task to get new instances frequently, since some experiments may take a long time to be reproduced. However, it is well-known that in such fields the number of features to be assessed are very huge, e,g., a dataset may contain thousands or even millions of features. In this case, a dataset may contain a large number of features while the number of instances is relatively very small.</p><p>For FS methods, it is a big challenge to deal with datasets that contain a large number of features, or a few number of instances due to two main reasons: the low number of instances (examples) is insufficient to train the learning model, and the large number of features increases the search space where the heuristic approach cannot explore most target regions <ref type="bibr" target="#b69">[70]</ref>.</p><p>In the previous sections, the reported results revealed the capabilities of the proposed approach in dealing with several datasets (with features from 9 to 325) with much success. In this subsection, new experiments are conducted using three well-known medical datasets <ref type="bibr" target="#b70">[71]</ref>.</p><p>The datasets are listed in Table <ref type="table" target="#tab_19">21</ref>. As can be seen in Table <ref type="table" target="#tab_19">21</ref>, three multi-class datasets with a huge number of features and a few number of samples are adopted. In this section, we are interested to compare the best approaches among the proposed ones (i.e., T V S3 and T V V 4 ) against other methods (i.e., bGWO, BGSA and BBA) in terms of classification accuracy and fitness values, which both AVG and STD values are reported in Tables <ref type="table" target="#tab_20">22</ref> and<ref type="table" target="#tab_21">23</ref>. Note that the tabulated results for each algorithm are the average of 30 independent runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Inspecting the results in Table <ref type="table" target="#tab_20">22</ref>, we can observe that T V V 4 has obtained the best classification accuracy result among all approaches in one dataset (namely: SRBCT) out of three, while the T V S3 approach achieved the best results on two datasets (Brain_Tumor2 and 9_Tumor). It is worth mentioning that the difference between the accuracy obtained by T V S3 and the other approaches varies from 15% to 26% on the Brain_Tumor2. Moreover, on the 9_Tumor, T V S3 is better than bGWO by 17%, and bGSA by 4%, but BBA has attained a very low classification accuracy. T V V 4 is still better than other approaches with lower difference in classification accuracy.</p><p>From Table <ref type="table" target="#tab_20">22</ref>, the STD values of the proposed approaches are low which indicates how much the values are close to the mean value. This indicates the satisfactory stability of the proposed approach and its capabilities in searching the promising regions of the search space. Boxplots of accuracy results are also shown in Fig. <ref type="figure" target="#fig_15">10</ref>.    <ref type="table" target="#tab_21">23</ref> compares the fitness values and the associated STD values for T V S3 and T V V 4 versus other algorithms. From Table <ref type="table" target="#tab_21">23</ref>, it is clear that both approaches (T V S3 and T V V 4 ) obtained the best fitness values with very competitive STD values over all datasets. The number of selected features for all approaches are presented in Table <ref type="table" target="#tab_22">24</ref>. The results shows that bGWO obtained the smallest number of features but it obtained much lower classification accuracy than the proposed approaches. This can be seen in the fitness values</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>(that merge both classification accuracy and the number of selected features), where bGWO obtained the worst fitness values compared to proposed approaches. Although BBA obtained the lowest number of features in one dataset, it has a very low classification rate. The p-values of the Wilcoxon test are tabulated in Table <ref type="table" target="#tab_23">25</ref>. These values can verify that the observed differences and improvements are significantly meaningful for all cases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion and future directions</head><p>In this paper, the performance of the DA was improved using different TFs to convert the step vector from continuous to a binary space. Eight different transfer functions that belong to two groups (S-shaped and V-shaped) were employed to investigate their</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T effectiveness on the basic BDA. The main contribution was the proposal of time-varying S-shaped and V-shaped transfer functions to leverage the impact of the step vector on balancing the exploration and exploitation behavior. A set of well-known FS datasets from the UCI data repository were used to evaluate the proposed approach, and the results were compared with the results from other state-of-the-art algorithms. The experimental results showed the superior performance for the time-varying S-shaped BDA approaches compared with other investigated approaches. The discussions and the extensive analyses of the results revealed that time-varying transfer functions can be utilized as an effective way of improving the exploration and exploitation behavior of the BDA for feature selection tasks.</p><p>This research opens several research directions for future work in the fields of optimization, metaheuristics, feature selection and applications of these disciplines. As future directions, we think that proposing several new time-dependent TFs is highly beneficial to develop enhanced binary optimizers, and may change the direction of research in the binary optimization field. As a next step, developing new versions of DA by proposing new operators in binary space can also be an interesting research direction. Finally, the proposed binary BDA approaches can be applied as preprocessing step of many pattern recognition, machine learning and feature selection tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Acknowledgements</head><p>We acknowledge the valuable comments of anonymous reviewers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>•</head><label></label><figDesc>Novel feature selection approaches based on Binary Dragonfly Algorithm (BDA) are proposed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Static and dynamic swarming behaviors of dragonflies when foraging (each geometric figure represents a class of search agents)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Transfer functions families (a) S-shaped and (b) V-shaped<ref type="bibr" target="#b19">[20]</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Demonstration of the time-varying S-shaped TFs when τ max =4 and τ min =0.01 during 100 iterations with time step 2. Note that more vertical curves belong to the lower values of τ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Demonstration of the time-varying V-shaped TFs when τ max =4 and τ min =0.01 during 100 iterations with time step 2. Note that more vertical curves belong to the lower values of τ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Figure 5: Comparison of T V V 4 and T V S3 versus other optimizers based on accuracy metric</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Boxplots of accuracy results for BDA V-shaped and BDA S-shaped time dependent variants versus other competitors on Breastcancer, BreastEW, Exactly, Exactly2, HeartEW, Lymphography, Mof-n, penglungEW, and SonarEW datasets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Boxplots of accuracy results for BDA V-shaped and BDA S-shaped time dependent variants versus other competitors on SpectEW, CongressEW, IonosphereEW, KrvskpEW, Tic-tac-toe, Vote, WaveformEW, WineEW, and Zoo datasets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Boxplots of accuracy results for BDA V-shaped and BDA S-shaped time dependent variants versus other optimizers on Brain_Tumor2, SRBCT, and 9_Tumors datasets Table23compares the fitness values and the associated STD values for T V S3 and T V V 4 versus other algorithms. From Table23, it is clear that both approaches (T V S3 and T V V 4 ) obtained the best fitness values with very competitive STD values over all datasets. The number of selected features for all approaches are presented in Table24. The results shows that bGWO obtained the smallest number of features but it obtained much lower classification accuracy than the proposed approaches. This can be seen in the fitness values</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="39,105.11,439.79,360.91,228.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Details of datasets</figDesc><table><row><cell>Dataset Breastcancer BreastEW Exactly Exactly2 HeartEW Lymphography 18 No. of Attributes No. of Objects No. of Classes 9 699 2 30 569 2 13 1000 2 13 1000 2 13 270 2 148 4 M-of-n 13 1000 2 PenglungEW 325 73 7 SonarEW 60 208 2 SpectEW 22 267 2 CongressEW 16 435 2 IonosphereEW 34 351 2 KrvskpEW 36 3196 2 Tic-tac-toe 9 958 2 Vote 16 300 2 WaveformEW 40 5000 3 WineEW 13 178 3 Zoo 16 101 7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Average accuracy, selection ration and time results, when using different combinations of population sizes and number of iterations for the Leukemia dataset.</figDesc><table><row><cell cols="5">Pop Size Max Iterations Accuracy Selection Ration Time</cell></row><row><cell>10</cell><cell>100</cell><cell>1</cell><cell>0.485</cell><cell>212.11</cell></row><row><cell>20</cell><cell>100</cell><cell>0.938</cell><cell>0.481</cell><cell>455.18</cell></row><row><cell>30</cell><cell>100</cell><cell>1</cell><cell>0.474</cell><cell>698.32</cell></row><row><cell>50</cell><cell>100</cell><cell>1</cell><cell>0.473</cell><cell>1262.41</cell></row><row><cell>10</cell><cell>150</cell><cell>1</cell><cell>0.477</cell><cell>318.44</cell></row><row><cell>20</cell><cell>150</cell><cell>0.933</cell><cell>0.477</cell><cell>685.21</cell></row><row><cell>30</cell><cell>150</cell><cell>0.933</cell><cell>0.472</cell><cell>697.86</cell></row><row><cell>50</cell><cell>150</cell><cell>0.916</cell><cell>0.481</cell><cell>1891.88</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Impact of α and β on the accuracy and selection ration results for the Leukemia dataset.</figDesc><table><row><cell cols="5">Alpha Beta Accuracy Selection Ration Time</cell></row><row><cell>0.5</cell><cell>0.5</cell><cell>0.956</cell><cell>0.476</cell><cell>212.21</cell></row><row><cell>0.7</cell><cell>0.3</cell><cell>0.967</cell><cell>0.474</cell><cell>212.30</cell></row><row><cell>0.9</cell><cell>0.1</cell><cell>0.936</cell><cell>0.477</cell><cell>212.15</cell></row><row><cell>0.99</cell><cell cols="2">0.01 1</cell><cell>0.471</cell><cell>211.91</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>The parameter settings</figDesc><table><row><cell>Parameter</cell><cell>Value</cell></row><row><cell cols="2">Population size Number of iterations Dimension Number of runs for each technique 30 10 100 Number of features α in fitness function 0.99 β in fitness function 0.01 a in GWO [2 0] Q min Frequency minimum in BA 0 Q max Frequency maximum in BA 2 A Loudness in BA 0.5 r Pulse rate in BA 0.5 G 0 in GSA 100 α in GSA 20</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Comparison between the original S-shaped transfer functions and time dependent variants in terms of accuracy</figDesc><table><row><cell>Benchmark</cell><cell cols="2">Measure S1</cell><cell>T V S1</cell><cell>S2</cell><cell>T V S2</cell><cell>S3</cell><cell>T V S3</cell><cell>S4</cell><cell>T V S4</cell></row><row><cell>Breastcancer</cell><cell>AVG STD</cell><cell cols="8">0.9643 0.9786 0.9714 0.9852 0.9929 0.9929 0.9786 0.9786 0.0000 0.0000 0.0000 0.0018 0.0000 0.0000 0.0000 0.0000</cell></row><row><cell>BreastEW</cell><cell>AVG STD</cell><cell cols="8">0.9839 0.9716 0.9889 0.9769 0.9822 0.9792 0.9564 0.9936 0.0052 0.0072 0.0039 0.0075 0.0028 0.0049 0.0059 0.0056</cell></row><row><cell>Exactly</cell><cell>AVG STD</cell><cell cols="8">1.0000 1.0000 1.0000 0.9902 1.0000 1.0000 0.9998 1.0000 0.0000 0.0000 0.0000 0.0539 0.0000 0.0000 0.0009 0.0000</cell></row><row><cell>Exactly2</cell><cell>AVG STD</cell><cell cols="8">0.7922 0.7892 0.7952 0.7630 0.7983 0.7725 0.7658 0.7508 0.0141 0.0099 0.0100 0.0060 0.0040 0.0222 0.0116 0.0057</cell></row><row><cell>HeartEW</cell><cell>AVG STD</cell><cell cols="8">0.9154 0.9377 0.8691 0.8679 0.8846 0.8759 0.8759 0.9080 0.0173 0.0091 0.0047 0.0193 0.0080 0.0139 0.0170 0.0191</cell></row><row><cell>Lymphography</cell><cell>AVG STD</cell><cell cols="8">0.9440 0.9667 0.9510 0.9608 0.9844 0.9922 0.9822 0.9889 0.0218 0.0000 0.0168 0.0215 0.0169 0.0143 0.0169 0.0183</cell></row><row><cell>M-of-n</cell><cell>AVG STD</cell><cell cols="8">1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000</cell></row><row><cell>penglungEW</cell><cell>AVG STD</cell><cell cols="8">1.0000 0.9044 1.0000 1.0000 0.9289 1.0000 0.9889 0.9600 0.0000 0.0336 0.0000 0.0000 0.0169 0.0000 0.0253 0.0332</cell></row><row><cell>SonarEW</cell><cell>AVG STD</cell><cell cols="8">0.9825 0.9992 1.0000 1.0000 0.9683 0.9841 0.9865 0.9651 0.0165 0.0043 0.0000 0.0000 0.0144 0.0114 0.0135 0.0136</cell></row><row><cell>SpectEW</cell><cell>AVG STD</cell><cell cols="8">0.8685 0.9352 0.9049 0.8617 0.9228 0.8519 0.8741 0.8438 0.0141 0.0117 0.0064 0.0094 0.0120 0.0109 0.0123 0.0093</cell></row><row><cell>CongressEW</cell><cell>AVG STD</cell><cell cols="8">0.9820 0.9977 0.9885 0.9502 0.9966 0.9866 0.9766 0.9751 0.0065 0.0047 0.0000 0.0063 0.0061 0.0044 0.0021 0.0044</cell></row><row><cell>IonosphereEW</cell><cell>AVG STD</cell><cell cols="8">0.9634 0.9535 0.9582 0.9347 0.9728 0.9911 0.9639 0.9075 0.0102 0.0092 0.0094 0.0094 0.0051 0.0094 0.0096 0.0121</cell></row><row><cell>KrvskpEW</cell><cell>AVG STD</cell><cell cols="8">0.9853 0.9858 0.9842 0.9912 0.9787 0.9794 0.9754 0.9840 0.0030 0.0020 0.0031 0.0029 0.0048 0.0031 0.0040 0.0032</cell></row><row><cell>Tic-tac-toe</cell><cell>AVG STD</cell><cell cols="8">0.8431 0.8267 0.8594 0.8333 0.8323 0.8469 0.8490 0.8290 0.0018 0.0049 0.0000 0.0000 0.0021 0.0064 0.0000 0.0099</cell></row><row><cell>Vote</cell><cell>AVG STD</cell><cell cols="8">0.9739 0.9694 0.9828 0.9850 0.9667 0.9894 0.9783 0.9994 0.0084 0.0077 0.0030 0.0067 0.0000 0.0082 0.0078 0.0030</cell></row><row><cell>WaveformEW</cell><cell>AVG STD</cell><cell cols="8">0.7544 0.7630 0.7581 0.7733 0.7542 0.7580 0.7534 0.7621 0.0078 0.0064 0.0074 0.0086 0.0078 0.0066 0.0058 0.0077</cell></row><row><cell>WineEW</cell><cell>AVG STD</cell><cell cols="8">1.0000 0.9750 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 0.0000 0.0085 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000</cell></row><row><cell>Zoo</cell><cell>AVG STD</cell><cell cols="8">1.0000 1.0000 0.9524 1.0000 1.0000 1.0000 1.0000 1.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000</cell></row><row><cell>Ranking</cell><cell>W|T|L</cell><cell>7|3|8</cell><cell>8|3|7</cell><cell>8|4|6</cell><cell>6|4|8</cell><cell>5|5|8</cell><cell>8|5|5</cell><cell>7|4|7</cell><cell>7|4|7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Comparison between the original V-shaped transfer functions and time dependent variants in terms of accuracy results</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 :</head><label>8</label><figDesc><ref type="bibr" target="#b3">4</ref> Comparison between the original S-shaped transfer functions and time dependent variants in terms of minimum number of selected features</figDesc><table><row><cell>Breastcancer</cell><cell>AVG STD</cell><cell cols="8">0.9786 0.9671 0.9805 0.9781 0.9569 0.9895 0.9619 0.9771 0.0050 0.0036 0.0032 0.0072 0.0083 0.0070 0.0057 0.0047</cell></row><row><cell>BreastEW</cell><cell>AVG STD</cell><cell cols="8">0.9465 0.9582 0.9816 0.9658 0.9520 0.9801 0.9494 0.9740 0.0146 0.0121 0.0070 0.0093 0.0091 0.0065 0.0119 0.0096</cell></row><row><cell>Exactly</cell><cell>AVG STD</cell><cell cols="8">0.8847 0.8605 0.9075 0.8947 0.9093 0.9137 0.8838 0.9290 0.0860 0.0971 0.0891 0.0814 0.0873 0.0841 0.1051 0.0551</cell></row><row><cell>Exactly2</cell><cell>AVG STD</cell><cell cols="8">0.7230 0.7428 0.7190 0.7595 0.6985 0.7358 0.7417 0.7257 0.0216 0.0214 0.0195 0.0166 0.0209 0.0216 0.0167 0.0200</cell></row><row><cell>HeartEW</cell><cell>AVG STD</cell><cell cols="8">0.8463 0.8617 0.8525 0.8525 0.7926 0.8321 0.8148 0.8858 0.0234 0.0251 0.0269 0.0250 0.0235 0.0153 0.0188 0.0327</cell></row><row><cell>Lymphography</cell><cell>AVG STD</cell><cell cols="8">0.8877 0.8967 0.8673 0.7956 0.8744 0.9121 0.8611 0.8950 0.0296 0.0308 0.0309 0.0287 0.0243 0.0268 0.0264 0.0321</cell></row><row><cell>M-of-n</cell><cell>AVG STD</cell><cell cols="8">0.9493 0.9523 0.9518 0.9450 0.9673 0.9578 0.9463 0.9732 0.0383 0.0473 0.0373 0.0435 0.0301 0.0405 0.0557 0.0275</cell></row><row><cell>penglungEW</cell><cell>AVG STD</cell><cell cols="8">0.8733 0.9333 0.9778 0.9556 1.0000 0.9222 0.9333 0.8067 0.0203 0.0000 0.0320 0.0320 0.0000 0.0466 0.0000 0.0441</cell></row><row><cell>SonarEW</cell><cell>AVG STD</cell><cell cols="8">0.9476 0.9214 0.9595 0.9587 0.9659 0.9563 0.9722 0.9952 0.0229 0.0251 0.0243 0.0216 0.0162 0.0251 0.0199 0.0097</cell></row><row><cell>SpectEW</cell><cell>AVG STD</cell><cell cols="8">0.8580 0.8599 0.8525 0.8099 0.7796 0.8198 0.8969 0.8765 0.0235 0.0232 0.0165 0.0279 0.0171 0.0168 0.0256 0.0164</cell></row><row><cell>CongressEW</cell><cell>AVG STD</cell><cell cols="8">0.9521 0.9586 0.9548 0.9713 0.9678 0.9705 0.9686 0.9950 0.0091 0.0119 0.0113 0.0108 0.0093 0.0130 0.0074 0.0072</cell></row><row><cell>IonosphereEW</cell><cell>AVG STD</cell><cell cols="8">0.9535 0.9437 0.9582 0.9779 0.9042 0.9700 0.9131 0.9249 0.0182 0.0133 0.0120 0.0096 0.0186 0.0121 0.0129 0.0130</cell></row><row><cell>KrvskpEW</cell><cell>AVG STD</cell><cell cols="8">0.9620 0.9664 0.9666 0.9581 0.9649 0.9733 0.9658 0.9705 0.0100 0.0105 0.0082 0.0120 0.0119 0.0079 0.0163 0.0088</cell></row><row><cell>Tic-tac-toe</cell><cell>AVG STD</cell><cell cols="8">0.8153 0.8227 0.7939 0.8021 0.8347 0.8017 0.7915 0.8215 0.0320 0.0238 0.0171 0.0269 0.0208 0.0225 0.0209 0.0196</cell></row><row><cell>Vote</cell><cell>AVG STD</cell><cell cols="8">0.9489 0.9544 0.9361 0.9733 0.9594 0.9683 0.9733 0.9617 0.0131 0.0175 0.0146 0.0155 0.0129 0.0119 0.0136 0.0089</cell></row><row><cell>WaveformEW</cell><cell>AVG STD</cell><cell cols="8">0.7382 0.7456 0.7493 0.7554 0.7404 0.7496 0.7433 0.7488 0.0111 0.0098 0.0105 0.0113 0.0089 0.0100 0.0125 0.0097</cell></row><row><cell>WineEW</cell><cell>AVG STD</cell><cell cols="8">0.9769 0.9537 0.9778 0.9778 0.9981 1.0000 0.9991 0.9991 0.0105 0.0234 0.0153 0.0170 0.0070 0.0000 0.0051 0.0051</cell></row><row><cell>Zoo</cell><cell>AVG STD</cell><cell cols="8">1.0000 1.0000 0.9555 0.9984 0.9921 0.9825 0.9524 0.9825 0.0000 0.0000 0.0121 0.0087 0.0181 0.0233 0.0354 0.0233</cell></row><row><cell>Ranking</cell><cell>W|T|L</cell><cell>5|1|12</cell><cell>12|1|5</cell><cell>10|0|8</cell><cell>8|0|10</cell><cell>5|0|13</cell><cell>13|0|5</cell><cell>4|1|13</cell><cell>13|1|4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc><ref type="bibr" target="#b3">4</ref> </figDesc><table><row><cell>Breastcancer</cell><cell>AVG STD</cell><cell>5.23 1.30</cell><cell>5.63 1.30</cell><cell>4.60 0.93</cell><cell>5.23 0.77</cell><cell>4.77 0.97</cell><cell>5.27 0.74</cell><cell>5.47 1.43</cell><cell>5.37 0.81</cell></row><row><cell>BreastEW</cell><cell>AVG STD</cell><cell>16.50 2.89</cell><cell cols="2">18.17 17.87 3.03 2.64</cell><cell cols="2">18.43 16.17 3.57 2.64</cell><cell cols="2">17.50 16.77 2.56 2.19</cell><cell>16.37 2.47</cell></row><row><cell>Exactly</cell><cell>AVG STD</cell><cell>9.10 1.32</cell><cell>9.33 1.30</cell><cell>8.90 2.09</cell><cell>9.43 1.45</cell><cell>8.90 1.30</cell><cell cols="2">8.87 8.60 1.14 1.16</cell><cell>8.97 0.93</cell></row><row><cell>Exactly2</cell><cell>AVG STD</cell><cell>8.87 1.43</cell><cell cols="2">6.90 8.87 3.01 2.70</cell><cell>5.53 2.57</cell><cell>7.37 2.59</cell><cell>9.27 2.29</cell><cell>8.57 1.70</cell><cell>9.67 1.37</cell></row><row><cell>HeartEW</cell><cell>AVG STD</cell><cell>7.53 2.10</cell><cell>7.73 1.68</cell><cell>8.70 1.84</cell><cell>7.87 1.68</cell><cell>7.47 1.83</cell><cell>9.73 1.48</cell><cell>7.87 1.50</cell><cell>9.07 1.53</cell></row><row><cell>Lymphography</cell><cell>AVG STD</cell><cell>11.77 2.56</cell><cell cols="2">13.00 10.30 2.13 2.72</cell><cell cols="2">11.20 11.33 2.20 1.75</cell><cell cols="2">10.47 11.03 1.72 2.24</cell><cell>10.80 1.73</cell></row><row><cell>M-of-n</cell><cell>AVG STD</cell><cell>9.57 1.65</cell><cell cols="2">8.93 9.37 1.46 1.16</cell><cell>9.20 1.10</cell><cell>8.60 0.77</cell><cell>8.63 1.10</cell><cell>8.50 1.41</cell><cell>8.43 1.14</cell></row><row><cell>penglungEW</cell><cell>AVG STD</cell><cell cols="8">151.90 155.50 171.83 161.57 156.03 174.20 152.17 165.40 9.90 8.01 24.62 15.75 7.81 19.05 6.12 15.90</cell></row><row><cell>SonarEW</cell><cell>AVG STD</cell><cell>35.53 4.59</cell><cell cols="2">37.07 35.47 4.62 4.15</cell><cell cols="2">34.37 33.63 5.18 3.97</cell><cell cols="2">35.97 33.07 4.19 2.89</cell><cell>35.33 4.88</cell></row><row><cell>SpectEW</cell><cell>AVG STD</cell><cell>12.53 2.52</cell><cell cols="2">12.33 12.63 2.45 2.30</cell><cell cols="2">11.73 10.63 2.33 2.98</cell><cell cols="2">13.60 12.77 2.99 2.13</cell><cell>11.20 1.67</cell></row><row><cell>CongressEW</cell><cell>AVG STD</cell><cell>8.63 1.40</cell><cell>9.40 2.62</cell><cell>9.17 1.72</cell><cell>8.87 1.61</cell><cell>9.30 1.62</cell><cell cols="2">8.60 9.07 2.11 1.78</cell><cell>7.10 1.95</cell></row><row><cell>IonosphereEW</cell><cell>AVG STD</cell><cell>18.73 3.90</cell><cell cols="2">19.40 20.67 2.65 3.09</cell><cell cols="2">18.57 18.23 3.54 3.07</cell><cell cols="2">18.37 18.13 2.93 2.27</cell><cell>17.53 3.18</cell></row><row><cell>KrvskpEW</cell><cell>AVG STD</cell><cell>27.10 2.25</cell><cell cols="2">26.93 26.53 2.05 2.49</cell><cell cols="2">26.63 26.40 3.36 2.16</cell><cell cols="2">26.30 25.20 2.81 3.07</cell><cell>25.13 2.60</cell></row><row><cell>Tic-tac-toe</cell><cell>AVG STD</cell><cell>7.33 1.30</cell><cell cols="2">6.70 6.87 1.24 0.90</cell><cell>7.10 1.16</cell><cell>7.30 0.92</cell><cell cols="2">6.40 6.30 1.07 0.70</cell><cell>6.53 0.57</cell></row><row><cell>Vote</cell><cell>AVG STD</cell><cell>9.80 2.04</cell><cell cols="2">8.37 8.63 1.63 1.88</cell><cell cols="2">10.23 7.83 2.27 1.46</cell><cell cols="2">7.10 7.40 2.04 1.81</cell><cell>8.47 2.01</cell></row><row><cell>WaveformEW</cell><cell>AVG STD</cell><cell>30.43 3.88</cell><cell cols="2">30.90 30.57 4.00 3.11</cell><cell cols="2">29.37 28.80 3.05 3.94</cell><cell cols="2">29.07 27.03 3.32 4.42</cell><cell>30.57 3.86</cell></row><row><cell>WineEW Zoo</cell><cell>AVG STD AVG STD</cell><cell>8.20 1.69 7.17 1.32</cell><cell cols="2">7.37 7.00 1.52 0.87 5.60 7.57 1.30 1.33</cell><cell>7.57 1.63 8.67 1.52</cell><cell>7.50 1.17 9.20 1.99</cell><cell cols="2">7.40 7.10 1.45 1.77 9.03 8.43 1.90 1.57</cell><cell>6.67 1.37 8.47 1.36</cell></row><row><cell>Ranking</cell><cell>W|T|L</cell><cell cols="3">10|0|8 8|0|10 9|0|9</cell><cell>9|0|9</cell><cell>9|0|9</cell><cell>9|0|9</cell><cell cols="2">8|0|10 10|0|8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 10 :</head><label>10</label><figDesc>Comparison between the original transfer S-shaped functions and time dependent S-shaped variants in terms of best fitness values</figDesc><table><row><cell>Benchmark</cell><cell cols="2">Measure S1</cell><cell>T V S1</cell><cell>S2</cell><cell>T V S2</cell><cell>S3</cell><cell>T V S3</cell><cell>S4</cell><cell>T V S4</cell></row><row><cell>Breastcancer</cell><cell>AVG STD</cell><cell cols="8">0.0420 0.0290 0.0338 0.0201 0.0126 0.0126 0.0257 0.0257 0.0000 0.0000 0.0000 0.0015 0.0000 0.0000 0.0000 0.0000</cell></row><row><cell>BreastEW</cell><cell>AVG STD</cell><cell cols="8">0.0202 0.0323 0.0155 0.0267 0.0220 0.0244 0.0475 0.0108 0.0049 0.0070 0.0038 0.0074 0.0028 0.0048 0.0056 0.0053</cell></row><row><cell>Exactly</cell><cell>AVG STD</cell><cell cols="8">0.0046 0.0046 0.0046 0.0143 0.0047 0.0046 0.0050 0.0046 0.0000 0.0000 0.0001 0.0532 0.0003 0.0000 0.0011 0.0000</cell></row><row><cell>Exactly2</cell><cell>AVG STD</cell><cell cols="8">0.2121 0.2151 0.2077 0.2415 0.2015 0.2307 0.2357 0.2535 0.0141 0.0099 0.0081 0.0058 0.0030 0.0202 0.0084 0.0048</cell></row><row><cell>HeartEW</cell><cell>AVG STD</cell><cell cols="8">0.0875 0.0673 0.1346 0.1353 0.1194 0.1273 0.1278 0.0962 0.0171 0.0083 0.0052 0.0187 0.0078 0.0143 0.0166 0.0177</cell></row><row><cell>Lymphography</cell><cell>AVG STD</cell><cell cols="8">0.0598 0.0363 0.0530 0.0431 0.0203 0.0123 0.0212 0.0150 0.0214 0.0008 0.0162 0.0210 0.0165 0.0133 0.0165 0.0180</cell></row><row><cell>M-of-n</cell><cell>AVG STD</cell><cell cols="8">0.0046 0.0046 0.0046 0.0046 0.0047 0.0046 0.0048 0.0046 0.0000 0.0000 0.0000 0.0000 0.0003 0.0001 0.0003 0.0000</cell></row><row><cell>penglungEW</cell><cell>AVG STD</cell><cell cols="8">0.0039 0.0983 0.0040 0.0036 0.0749 0.0037 0.0155 0.0438 0.0001 0.0331 0.0002 0.0001 0.0166 0.0001 0.0248 0.0327</cell></row><row><cell>SonarEW</cell><cell>AVG STD</cell><cell cols="8">0.0225 0.0054 0.0045 0.0038 0.0361 0.0200 0.0180 0.0388 0.0157 0.0042 0.0004 0.0004 0.0141 0.0111 0.0131 0.0133</cell></row><row><cell>SpectEW</cell><cell>AVG STD</cell><cell cols="8">0.1338 0.0680 0.0983 0.1412 0.0804 0.1498 0.1290 0.1580 0.0134 0.0118 0.0065 0.0086 0.0116 0.0100 0.0118 0.0085</cell></row><row><cell>CongressEW</cell><cell>AVG STD</cell><cell cols="8">0.0217 0.0051 0.0127 0.0536 0.0068 0.0167 0.0272 0.0282 0.0064 0.0041 0.0002 0.0058 0.0059 0.0040 0.0017 0.0044</cell></row><row><cell>IonosphereEW</cell><cell>AVG STD</cell><cell cols="8">0.0402 0.0497 0.0454 0.0683 0.0312 0.0122 0.0399 0.0951 0.0102 0.0093 0.0093 0.0093 0.0049 0.0095 0.0093 0.0120</cell></row><row><cell>KrvskpEW</cell><cell>AVG STD</cell><cell cols="8">0.0208 0.0195 0.0216 0.0146 0.0274 0.0262 0.0304 0.0216 0.0028 0.0022 0.0031 0.0030 0.0046 0.0033 0.0039 0.0031</cell></row><row><cell>Tic-tac-toe</cell><cell>AVG STD</cell><cell cols="8">0.1627 0.1792 0.1470 0.1717 0.1729 0.1594 0.1573 0.1767 0.0006 0.0046 0.0000 0.0000 0.0025 0.0063 0.0000 0.0089</cell></row><row><cell>Vote</cell><cell>AVG STD</cell><cell cols="8">0.0284 0.0336 0.0210 0.0185 0.0360 0.0126 0.0249 0.0042 0.0083 0.0070 0.0027 0.0066 0.0011 0.0073 0.0069 0.0031</cell></row><row><cell>WaveformEW</cell><cell>AVG STD</cell><cell cols="8">0.2496 0.2409 0.2455 0.2308 0.2492 0.2453 0.2500 0.2408 0.0077 0.0069 0.0074 0.0084 0.0075 0.0070 0.0059 0.0077</cell></row><row><cell>WineEW</cell><cell>AVG STD</cell><cell cols="8">0.0039 0.0282 0.0026 0.0033 0.0035 0.0027 0.0037 0.0030 0.0002 0.0083 0.0007 0.0004 0.0004 0.0005 0.0005 0.0005</cell></row><row><cell>Zoo</cell><cell>AVG STD</cell><cell cols="8">0.0030 0.0017 0.0510 0.0024 0.0021 0.0028 0.0011 0.0020 0.0004 0.0004 0.0002 0.0005 0.0003 0.0003 0.0004 0.0002</cell></row><row><cell>Ranking</cell><cell>W|T|L</cell><cell>7|2|9</cell><cell>9|2|7</cell><cell>9|1|8</cell><cell>8|1|9</cell><cell cols="2">6|1|11 11|1|6</cell><cell>8|1|9</cell><cell>9|1|8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 11 :</head><label>11</label><figDesc>Comparison between the original transfer V-shaped functions and time-dependent V-shaped variants in terms of best fitness values</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc><ref type="bibr" target="#b3">4</ref> </figDesc><table><row><cell>Breastcancer</cell><cell>AVG STD</cell><cell cols="2">0.0270 0.0388 0.0244 0.0275 0.0480 0.0162 0.0438 0.0286 0.0052 0.0040 0.0031 0.0067 0.0081 0.0072 0.0060 0.0048</cell></row><row><cell>BreastEW</cell><cell>AVG STD</cell><cell cols="2">0.0585 0.0475 0.0242 0.0400 0.0529 0.0255 0.0557 0.0312 0.0147 0.0120 0.0071 0.0090 0.0091 0.0063 0.0117 0.0092</cell></row><row><cell>Exactly</cell><cell>AVG STD</cell><cell cols="2">0.1212 0.1453 0.0984 0.1115 0.0966 0.0923 0.1216 0.0772 0.0861 0.0966 0.0886 0.0814 0.0868 0.0840 0.1045 0.0553</cell></row><row><cell>Exactly2</cell><cell>AVG STD</cell><cell cols="2">0.2810 0.2599 0.2850 0.2424 0.3042 0.2687 0.2623 0.2790 0.0213 0.0208 0.0190 0.0173 0.0202 0.0209 0.0165 0.0195</cell></row><row><cell>HeartEW</cell><cell>AVG STD</cell><cell cols="2">0.1580 0.1428 0.1527 0.1521 0.2111 0.1737 0.1894 0.1200 0.0237 0.0247 0.0260 0.0251 0.0227 0.0147 0.0188 0.0315</cell></row><row><cell>Lymphography</cell><cell>AVG STD</cell><cell cols="2">0.1178 0.1095 0.1371 0.2086 0.1306 0.0928 0.1436 0.1099 0.0290 0.0303 0.0303 0.0287 0.0238 0.0268 0.0260 0.0314</cell></row><row><cell>M-of-n</cell><cell>AVG STD</cell><cell cols="2">0.0575 0.0541 0.0549 0.0615 0.0390 0.0484 0.0597 0.0331 0.0390 0.0479 0.0377 0.0438 0.0302 0.0408 0.0557 0.0280</cell></row><row><cell>penglungEW</cell><cell>AVG STD</cell><cell cols="2">0.1301 0.0708 0.0273 0.0490 0.0048 0.0824 0.0707 0.1965 0.0199 0.0002 0.0314 0.0313 0.0002 0.0460 0.0002 0.0435</cell></row><row><cell>SonarEW</cell><cell>AVG STD</cell><cell cols="2">0.0578 0.0840 0.0460 0.0466 0.0394 0.0492 0.0330 0.0106 0.0228 0.0248 0.0242 0.0213 0.0157 0.0245 0.0198 0.0096</cell></row><row><cell>SpectEW</cell><cell>AVG STD</cell><cell cols="2">0.1463 0.1443 0.1518 0.1936 0.2230 0.1846 0.1079 0.1273 0.0229 0.0233 0.0167 0.0282 0.0171 0.0167 0.0254 0.0162</cell></row><row><cell>CongressEW</cell><cell>AVG STD</cell><cell cols="2">0.0528 0.0468 0.0505 0.0340 0.0377 0.0346 0.0368 0.0094 0.0092 0.0113 0.0111 0.0102 0.0089 0.0131 0.0074 0.0078</cell></row><row><cell>IonosphereEW</cell><cell>AVG STD</cell><cell cols="2">0.0515 0.0615 0.0474 0.0273 0.1002 0.0351 0.0913 0.0795 0.0183 0.0133 0.0120 0.0097 0.0185 0.0122 0.0130 0.0131</cell></row><row><cell>KrvskpEW</cell><cell>AVG STD</cell><cell cols="2">0.0451 0.0407 0.0404 0.0489 0.0421 0.0338 0.0408 0.0362 0.0101 0.0105 0.0082 0.0120 0.0119 0.0078 0.0161 0.0089</cell></row><row><cell>Tic-tac-toe</cell><cell>AVG STD</cell><cell cols="2">0.1910 0.1829 0.2116 0.2038 0.1717 0.2034 0.2134 0.1839 0.0316 0.0237 0.0172 0.0273 0.0211 0.0227 0.0212 0.0194</cell></row><row><cell>Vote</cell><cell>AVG STD</cell><cell cols="2">0.0567 0.0503 0.0686 0.0328 0.0450 0.0358 0.0310 0.0432 0.0133 0.0177 0.0142 0.0150 0.0130 0.0119 0.0138 0.0086</cell></row><row><cell>WaveformEW</cell><cell>AVG STD</cell><cell cols="2">0.2668 0.2596 0.2558 0.2495 0.2642 0.2552 0.2609 0.2563 0.0108 0.0097 0.0107 0.0112 0.0089 0.0100 0.0125 0.0096</cell></row><row><cell>WineEW</cell><cell>AVG STD</cell><cell cols="2">0.0292 0.0515 0.0274 0.0278 0.0076 0.0057 0.0064 0.0060 0.0111 0.0229 0.0150 0.0161 0.0067 0.0011 0.0046 0.0052</cell></row><row><cell>Zoo</cell><cell>AVG STD</cell><cell cols="2">0.0045 0.0035 0.0488 0.0070 0.0136 0.0229 0.0524 0.0226 0.0008 0.0008 0.0121 0.0087 0.0172 0.0222 0.0346 0.0224</cell></row><row><cell>Ranking</cell><cell>W|T|L</cell><cell>5|0|13 13|0|5 10|0|8 8|0|10</cell><cell>5|0|13 13|0|5 4|0|14 14|0|4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 12 :</head><label>12</label><figDesc>Comparison between the best BDA V-shaped and BDA S-shaped time dependent variants and other meta-heuristics in term of accuracy</figDesc><table><row><cell>Benchmark</cell><cell>Measure</cell><cell cols="2">BDA T V V 4 T V S3</cell><cell>bGWO BGSA BBA</cell></row><row><cell>Breastcancer</cell><cell>AVG STD</cell><cell cols="3">0.9771 0.9929 0.9779 0.9481 0.9321 0.0047 0.0000 0.0103 0.0203 0.0513</cell></row><row><cell>BreastEW</cell><cell>AVG STD</cell><cell cols="3">0.9740 0.9792 0.9231 0.9284 0.9129 0.0096 0.0049 0.0152 0.0140 0.0349</cell></row><row><cell>Exactly</cell><cell>AVG STD</cell><cell cols="3">0.9290 1.0000 0.8345 0.7323 0.6015 0.0551 0.0000 0.0773 0.1244 0.0555</cell></row><row><cell>Exactly2</cell><cell>AVG STD</cell><cell cols="3">0.7257 0.7725 0.6740 0.6438 0.6830 0.0200 0.0222 0.0405 0.0407 0.0400</cell></row><row><cell>HeartEW</cell><cell>AVG STD</cell><cell cols="3">0.8858 0.8759 0.7883 0.7698 0.7284 0.0327 0.0139 0.0391 0.0664 0.0606</cell></row><row><cell>Lymphography</cell><cell>AVG STD</cell><cell cols="3">0.8950 0.9922 0.8422 0.8642 0.6894 0.0321 0.0143 0.0567 0.0805 0.1033</cell></row><row><cell>M-of-n</cell><cell>AVG STD</cell><cell cols="3">0.9732 1.0000 0.9130 0.8268 0.7155 0.0275 0.0000 0.0517 0.0608 0.0832</cell></row><row><cell>penglungEW</cell><cell>AVG STD</cell><cell cols="3">0.8067 1.0000 0.8689 0.9493 0.8156 0.0441 0.0000 0.0122 0.0543 0.0545</cell></row><row><cell>SonarEW</cell><cell>AVG STD</cell><cell cols="3">0.9952 0.9841 0.8865 0.8651 0.8143 0.0097 0.0114 0.0404 0.0465 0.0588</cell></row><row><cell>SpectEW</cell><cell>AVG STD</cell><cell cols="3">0.8765 0.8519 0.8179 0.7846 0.7556 0.0164 0.0109 0.0288 0.0342 0.0393</cell></row><row><cell>CongressEW</cell><cell>AVG STD</cell><cell cols="3">0.9950 0.9866 0.9502 0.9425 0.8686 0.0072 0.0044 0.0469 0.0260 0.0803</cell></row><row><cell>IonosphereEW</cell><cell>AVG STD</cell><cell cols="3">0.9249 0.9911 0.8911 0.8685 0.8662 0.0130 0.0094 0.0251 0.0257 0.0271</cell></row><row><cell>KrvskpEW</cell><cell>AVG STD</cell><cell cols="3">0.9705 0.9794 0.9346 0.8978 0.7898 0.0088 0.0031 0.0190 0.0526 0.0896</cell></row><row><cell>Tic-tac-toe</cell><cell>AVG STD</cell><cell cols="3">0.8215 0.8469 0.8057 0.7611 0.6578 0.0196 0.0064 0.0287 0.0380 0.0805</cell></row><row><cell>Vote</cell><cell>AVG STD</cell><cell cols="3">0.9617 0.9894 0.9394 0.9433 0.8556 0.0089 0.0082 0.0208 0.0246 0.1016</cell></row><row><cell>WaveformEW</cell><cell>AVG STD</cell><cell cols="3">0.7488 0.7580 0.7050 0.6971 0.6592 0.0097 0.0066 0.0154 0.0205 0.0460</cell></row><row><cell>WineEW</cell><cell>AVG STD</cell><cell cols="3">0.9991 1.0000 0.9380 0.9759 0.8380 0.0051 0.0000 0.0362 0.0348 0.1305</cell></row><row><cell>Zoo</cell><cell>AVG STD</cell><cell cols="3">0.9825 1.0000 0.9930 0.9952 0.8667 0.0233 0.0000 0.0229 0.0148 0.1142</cell></row><row><cell>Ranking</cell><cell>W|T|L</cell><cell>4|0|14</cell><cell>14|0|4</cell><cell>0|0|18 0|0|18 0|0|18</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 13 :</head><label>13</label><figDesc>Comparison between the best BDA V-shaped and BDA S-shaped time dependent variants and other meta-heuristics in terms of minimum number of features</figDesc><table><row><cell>Benchmark</cell><cell>Measure</cell><cell>T V V 4</cell><cell cols="2">BDA T V S3</cell><cell cols="3">bGWO BGSA BBA</cell></row><row><cell>Breastcancer</cell><cell>AVG STD</cell><cell>5.37 0.81</cell><cell></cell><cell>5.00 0.00</cell><cell>6.40 1.75</cell><cell>4.47 1.01</cell><cell>4.10 1.27</cell></row><row><cell>BreastEW</cell><cell>AVG STD</cell><cell cols="2">16.37 2.47</cell><cell>11.50 2.15</cell><cell>21.57 4.80</cell><cell>14.93 2.00</cell><cell>11.77 3.94</cell></row><row><cell>Exactly</cell><cell>AVG STD</cell><cell>8.97 0.93</cell><cell></cell><cell>6.00 0.00</cell><cell>10.70 2.02</cell><cell>7.67 1.49</cell><cell>5.23 2.25</cell></row><row><cell>Exactly2</cell><cell>AVG STD</cell><cell>9.67 1.37</cell><cell></cell><cell>7.10 2.72</cell><cell>6.97 2.74</cell><cell>6.13 2.08</cell><cell>5.77 1.57</cell></row><row><cell>HeartEW</cell><cell>AVG STD</cell><cell>9.07 1.53</cell><cell></cell><cell>5.77 1.50</cell><cell>9.70 1.99</cell><cell>6.63 1.94</cell><cell>5.07 1.70</cell></row><row><cell>Lymphography</cell><cell>AVG STD</cell><cell cols="2">10.80 1.73</cell><cell>8.23 2.73</cell><cell>10.60 2.63</cell><cell>9.00 2.18</cell><cell>6.87 1.96</cell></row><row><cell>M-of-n</cell><cell>AVG STD</cell><cell>8.43 1.14</cell><cell></cell><cell>6.03 0.18</cell><cell>10.43 1.45</cell><cell>8.20 1.16</cell><cell>5.73 1.82</cell></row><row><cell>penglungEW</cell><cell>AVG STD</cell><cell cols="6">165.40 121.17 152.33 145.10 126.47 15.90 4.71 7.00 4.88 15.62</cell></row><row><cell>SonarEW</cell><cell>AVG STD</cell><cell cols="2">35.33 4.88</cell><cell>25.57 3.35</cell><cell>34.87 7.81</cell><cell cols="2">27.07 23.53 3.64 5.15</cell></row><row><cell>SpectEW</cell><cell>AVG STD</cell><cell cols="2">11.20 1.67</cell><cell>6.83 2.56</cell><cell>13.77 2.93</cell><cell>9.77 2.30</cell><cell>8.73 2.29</cell></row><row><cell>CongressEW</cell><cell>AVG STD</cell><cell>7.10 1.95</cell><cell></cell><cell>5.53 2.29</cell><cell>10.00 1.88</cell><cell>7.00 1.91</cell><cell>5.70 2.18</cell></row><row><cell>IonosphereEW</cell><cell>AVG STD</cell><cell cols="2">17.53 3.18</cell><cell>11.47 1.89</cell><cell>16.17 2.35</cell><cell>14.90 2.89</cell><cell>12.30 3.40</cell></row><row><cell>KrvskpEW</cell><cell>AVG STD</cell><cell cols="2">25.13 2.60</cell><cell>20.67 2.32</cell><cell>30.90 2.93</cell><cell cols="2">19.73 14.97 2.36 2.88</cell></row><row><cell>Tic-tac-toe</cell><cell>AVG STD</cell><cell>6.53 0.57</cell><cell></cell><cell>7.00 0.00</cell><cell>8.30 1.24</cell><cell>5.60 0.97</cell><cell>4.30 1.70</cell></row><row><cell>Vote</cell><cell>AVG STD</cell><cell>8.47 2.01</cell><cell></cell><cell>3.37 1.43</cell><cell>8.63 2.63</cell><cell>7.37 1.67</cell><cell>6.10 2.14</cell></row><row><cell>WaveformEW</cell><cell>AVG STD</cell><cell cols="2">30.57 3.86</cell><cell>23.00 3.18</cell><cell>34.07 4.48</cell><cell cols="2">21.60 16.23 3.69 4.08</cell></row><row><cell>WineEW</cell><cell>AVG STD</cell><cell>6.67 1.37</cell><cell></cell><cell>3.57 0.63</cell><cell>7.37 1.67</cell><cell>6.57 1.36</cell><cell>4.87 1.87</cell></row><row><cell>Zoo</cell><cell>AVG STD</cell><cell>8.47 1.36</cell><cell></cell><cell>4.43 0.50</cell><cell>7.37 1.63</cell><cell>6.97 1.25</cell><cell>6.43 1.83</cell></row><row><cell>Ranking</cell><cell>W|T|L</cell><cell cols="3">0|0|18 8|0|10</cell><cell cols="3">0|0|18 0|0|18 10|0|8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 14 :</head><label>14</label><figDesc>Comparison between the best BDA V-shaped and BDA S-shaped time dependent variants and other meta-heuristics in terms of fitness results</figDesc><table><row><cell>Benchmark</cell><cell>Measure</cell><cell cols="2">BDA T V V 4 T V S3</cell><cell>bGWO BGSA BBA</cell></row><row><cell>Breastcancer</cell><cell>AVG STD</cell><cell cols="3">0.0286 0.0126 0.0155 0.0273 0.0361 0.0048 0.0000 0.0023 0.0068 0.0050</cell></row><row><cell>BreastEW</cell><cell>AVG STD</cell><cell cols="3">0.0312 0.0244 0.0428 0.0390 0.0358 0.0092 0.0048 0.0066 0.0100 0.0087</cell></row><row><cell>Exactly</cell><cell>AVG STD</cell><cell cols="3">0.0772 0.0046 0.1851 0.2532 0.3028 0.0553 0.0000 0.0515 0.0944 0.1080</cell></row><row><cell>Exactly2</cell><cell>AVG STD</cell><cell cols="3">0.2790 0.2307 0.2489 0.2876 0.2499 0.0195 0.0202 0.0136 0.0137 0.0151</cell></row><row><cell>HeartEW</cell><cell>AVG STD</cell><cell cols="3">0.1200 0.1273 0.1285 0.1369 0.1613 0.0315 0.0143 0.0258 0.0299 0.0230</cell></row><row><cell>Lymphography</cell><cell>AVG STD</cell><cell cols="3">0.1099 0.0123 0.0832 0.0813 0.1622 0.0314 0.0133 0.0346 0.0329 0.0526</cell></row><row><cell>M-of-n</cell><cell>AVG STD</cell><cell cols="3">0.0331 0.0046 0.0874 0.1652 0.1653 0.0280 0.0001 0.0387 0.0413 0.0438</cell></row><row><cell>penglungEW</cell><cell>AVG STD</cell><cell cols="3">0.1965 0.0037 0.1257 0.0045 0.1317 0.0435 0.0001 0.0249 0.0002 0.0384</cell></row><row><cell>SonarEW</cell><cell>AVG STD</cell><cell cols="3">0.0106 0.0200 0.1041 0.0816 0.1099 0.0096 0.0111 0.0205 0.0232 0.0300</cell></row><row><cell>SpectEW</cell><cell>AVG STD</cell><cell cols="3">0.1273 0.1498 0.1434 0.1532 0.1427 0.0162 0.0100 0.0162 0.0176 0.0208</cell></row><row><cell>CongressEW</cell><cell>AVG STD</cell><cell cols="3">0.0094 0.0167 0.0283 0.0324 0.0702 0.0078 0.0040 0.0101 0.0134 0.0149</cell></row><row><cell>IonosphereEW</cell><cell>AVG STD</cell><cell cols="3">0.0795 0.0122 0.0988 0.1272 0.1237 0.0131 0.0095 0.0128 0.0108 0.0186</cell></row><row><cell>KrvskpEW</cell><cell>AVG STD</cell><cell cols="3">0.0362 0.0262 0.0514 0.0994 0.0933 0.0089 0.0033 0.0089 0.0488 0.0394</cell></row><row><cell>Tic-tac-toe</cell><cell>AVG STD</cell><cell cols="3">0.1839 0.1594 0.1767 0.2318 0.2319 0.0194 0.0063 0.0081 0.0243 0.0218</cell></row><row><cell>Vote</cell><cell>AVG STD</cell><cell cols="3">0.0432 0.0126 0.0476 0.0385 0.0627 0.0086 0.0073 0.0088 0.0090 0.0175</cell></row><row><cell>WaveformEW</cell><cell>AVG STD</cell><cell cols="3">0.2563 0.2453 0.2373 0.2514 0.2508 0.0096 0.0070 0.0080 0.0133 0.0164</cell></row><row><cell>WineEW</cell><cell>AVG STD</cell><cell cols="3">0.0060 0.0027 0.0446 0.0091 0.0255 0.0052 0.0005 0.0169 0.0117 0.0171</cell></row><row><cell>Zoo</cell><cell>AVG STD</cell><cell cols="3">0.0226 0.0028 0.0066 0.0046 0.0521 0.0224 0.0003 0.0095 0.0008 0.0320</cell></row><row><cell>Ranking</cell><cell>W|T|L</cell><cell>4|0|14</cell><cell>14|0|4</cell><cell>0|0|18 0|0|18 0|0|18</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 15 :</head><label>15</label><figDesc>Comparison between the best BDA V-shaped and BDA S-shaped time-dependent variants and other meta-heuristics in term of specificity.</figDesc><table><row><cell>Benchmark</cell><cell>Measure</cell><cell cols="2">BDA T V V 4 T V S3</cell><cell>bGWO BGSA BBA</cell></row><row><cell>Breastcancer</cell><cell>AVG STD</cell><cell cols="3">0.9540 1.0000 0.9689 0.8935 0.9091 0.0190 0.0000 0.0184 0.0460 0.1239</cell></row><row><cell>BreastEW</cell><cell>AVG STD</cell><cell cols="3">0.9595 0.9470 0.9304 0.8959 0.8535 0.0189 0.0065 0.0191 0.0314 0.0868</cell></row><row><cell>Exactly</cell><cell>AVG STD</cell><cell cols="3">0.8821 1.0000 0.7478 0.5164 0.3320 0.1081 0.0000 0.1313 0.2363 0.1571</cell></row><row><cell>Exactly2</cell><cell>AVG STD</cell><cell cols="3">0.4284 0.3296 0.2950 0.3176 0.2370 0.0868 0.1692 0.1076 0.0907 0.1135</cell></row><row><cell>HeartEW</cell><cell>AVG STD</cell><cell cols="3">0.8606 0.8122 0.7460 0.8238 0.7333 0.0506 0.0185 0.0539 0.1017 0.1028</cell></row><row><cell>M-of-n</cell><cell>AVG STD</cell><cell cols="3">0.9705 1.0000 0.9213 0.8818 0.7940 0.0299 0.0000 0.0482 0.0524 0.0918</cell></row><row><cell>SonarEW</cell><cell>AVG STD</cell><cell cols="3">1.0000 0.9949 0.9517 0.8580 0.8236 0.0000 0.0133 0.0404 0.0653 0.0779</cell></row><row><cell>SpectEW</cell><cell>AVG STD</cell><cell cols="3">0.9356 0.9667 0.8894 0.8148 0.9397 0.0229 0.0307 0.0453 0.0651 0.0458</cell></row><row><cell>CongressEW</cell><cell>AVG STD</cell><cell cols="3">0.9941 0.9977 0.9441 0.9422 0.8204 0.0120 0.0087 0.1123 0.0503 0.1182</cell></row><row><cell>IonosphereEW</cell><cell>AVG STD</cell><cell cols="3">0.8396 0.9769 0.7667 0.7529 0.7027 0.0281 0.0259 0.0571 0.0521 0.0601</cell></row><row><cell>KrvskpEW</cell><cell>AVG STD</cell><cell cols="3">0.9649 0.9732 0.9240 0.8904 0.7775 0.0115 0.0053 0.0200 0.0522 0.1083</cell></row><row><cell>Tic-tac-toe</cell><cell>AVG STD</cell><cell cols="3">0.6781 0.7738 0.6628 0.6348 0.5068 0.0325 0.0329 0.0469 0.0767 0.1147</cell></row><row><cell>Vote</cell><cell>AVG STD</cell><cell cols="3">0.9496 0.9838 0.9260 0.9504 0.8514 0.0163 0.0126 0.0283 0.0164 0.0695</cell></row><row><cell>Ranking</cell><cell>W|T|L</cell><cell>4|0|9</cell><cell>9|0|4</cell><cell>0|0|13 0|0|13 0|0|13</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 16 :</head><label>16</label><figDesc>Comparison between the best BDA V-shaped and BDA S-shaped time-dependent variants and other meta-heuristics in term of Sensitivity.BDA-based approaches beat other optimizers for all cases. For 69.23% of test cases, T V V 4 provides the highest AUC rates. It is also observed that T V S3 outperforms other methods for the other problems.</figDesc><table><row><cell>Benchmark</cell><cell>Measure</cell><cell cols="2">BDA T V V 4 T V S3</cell><cell cols="2">bGWO BGSA</cell><cell>BBA</cell></row><row><cell>Breastcancer</cell><cell>AVG STD</cell><cell cols="5">0.9900 0.9886 0.9819 0.9707 0.9471 0.0094 0.0000 0.0134 0.0166 0.0185</cell></row><row><cell>BreastEW</cell><cell>AVG STD</cell><cell cols="5">0.9824 0.9960 0.9184 0.9528 0.9425 0.0146 0.0071 0.0259 0.0214 0.0288</cell></row><row><cell>Exactly</cell><cell>AVG STD</cell><cell cols="5">0.9472 1.0000 0.8782 0.8316 0.7632 0.0389 0.0000 0.0606 0.0820 0.0652</cell></row><row><cell>Exactly2</cell><cell>AVG STD</cell><cell cols="5">0.8356 0.9322 0.7904 0.7676 0.8125 0.0240 0.0344 0.0606 0.0732 0.0698</cell></row><row><cell>HeartEW</cell><cell>AVG STD</cell><cell cols="5">0.9031 0.9556 0.8373 0.7354 0.7253 0.0388 0.0463 0.0481 0.1034 0.0827</cell></row><row><cell>M-of-n</cell><cell>AVG STD</cell><cell cols="5">0.9784 1.0000 0.8991 0.7390 0.5900 0.0283 0.0000 0.0668 0.0856 0.1536</cell></row><row><cell>SonarEW</cell><cell>AVG STD</cell><cell cols="5">0.9905 0.9667 0.8273 0.8778 0.8019 0.0194 0.0317 0.0613 0.0744 0.0739</cell></row><row><cell>SpectEW</cell><cell>AVG STD</cell><cell cols="5">0.5815 0.2778 0.5033 0.6333 0.1111 0.0997 0.1974 0.1066 0.2920 0.1185</cell></row><row><cell>CongressEW</cell><cell>AVG STD</cell><cell cols="5">0.9956 0.9810 0.9541 0.9428 0.9026 0.0081 0.0053 0.0292 0.0315 0.0800</cell></row><row><cell>IonosphereEW</cell><cell>AVG STD</cell><cell cols="5">0.9949 0.9993 0.9630 0.9484 0.9551 0.0124 0.0041 0.0229 0.0273 0.0279</cell></row><row><cell>KrvskpEW</cell><cell>AVG STD</cell><cell cols="5">0.9762 0.9853 0.9448 0.9058 0.8014 0.0097 0.0048 0.0199 0.0626 0.0868</cell></row><row><cell>Tic-tac-toe</cell><cell>AVG STD</cell><cell cols="5">0.8984 0.8843 0.8723 0.8304 0.7425 0.0298 0.0072 0.0290 0.0460 0.1050</cell></row><row><cell>Vote</cell><cell>AVG STD</cell><cell cols="5">0.9922 1.0000 0.9684 0.9302 0.8623 0.0255 0.0000 0.0528 0.0748 0.1787</cell></row><row><cell>Ranking</cell><cell>W|T|L</cell><cell>4|0|9</cell><cell>8|0|5</cell><cell>0|0|13</cell><cell cols="2">1|0|12 0|0|13</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 17 :</head><label>17</label><figDesc>Comparison between the best BDA V-shaped and BDA S-shaped time dependent variants and other meta-heuristics in term of AUC.</figDesc><table><row><cell>Benchmark</cell><cell>Measure</cell><cell cols="2">BDA T V V 4 T V S3</cell><cell>bGWO BGSA BBA</cell></row><row><cell>Breastcancer</cell><cell>AVG STD</cell><cell cols="3">0.9720 0.9943 0.9754 0.9321 0.9281 0.0069 0.0000 0.0108 0.0266 0.0637</cell></row><row><cell>BreastEW</cell><cell>AVG STD</cell><cell cols="3">0.9710 0.9715 0.9244 0.9244 0.8980 0.0100 0.0044 0.0136 0.0150 0.0459</cell></row><row><cell>Exactly</cell><cell>AVG STD</cell><cell cols="3">0.9147 1.0000 0.8130 0.6740 0.5476 0.0704 0.0000 0.0890 0.1533 0.0710</cell></row><row><cell>Exactly2</cell><cell>AVG STD</cell><cell cols="3">0.6320 0.6309 0.5427 0.5426 0.5248 0.0381 0.0685 0.0471 0.0340 0.0400</cell></row><row><cell>HeartEW</cell><cell>AVG STD</cell><cell cols="3">0.8819 0.8839 0.7917 0.7796 0.7293 0.0337 0.0168 0.0387 0.0637 0.0620</cell></row><row><cell>M-of-n</cell><cell>AVG STD</cell><cell cols="3">0.9744 1.0000 0.9102 0.8104 0.6920 0.0270 0.0000 0.0539 0.0646 0.0908</cell></row><row><cell>SonarEW</cell><cell>AVG STD</cell><cell cols="3">0.9952 0.9808 0.8895 0.8679 0.8127 0.0097 0.0144 0.0397 0.0460 0.0580</cell></row><row><cell>SpectEW</cell><cell>AVG STD</cell><cell cols="3">0.7585 0.6222 0.6964 0.7241 0.5254 0.0441 0.0840 0.0427 0.1222 0.0586</cell></row><row><cell>CongressEW</cell><cell>AVG STD</cell><cell cols="3">0.9949 0.9894 0.9491 0.9425 0.8615 0.0076 0.0049 0.0576 0.0282 0.0837</cell></row><row><cell>IonosphereEW</cell><cell>AVG STD</cell><cell cols="3">0.9172 0.9881 0.8648 0.8506 0.8289 0.0141 0.0128 0.0304 0.0285 0.0325</cell></row><row><cell>KrvskpEW</cell><cell>AVG STD</cell><cell cols="3">0.9705 0.9792 0.9344 0.8981 0.7894 0.0088 0.0031 0.0190 0.0529 0.0900</cell></row><row><cell>Tic-tac-toe</cell><cell>AVG STD</cell><cell cols="3">0.7883 0.8290 0.7676 0.7326 0.6247 0.0188 0.0128 0.0317 0.0425 0.0796</cell></row><row><cell>Vote</cell><cell>AVG STD</cell><cell cols="3">0.9709 0.9919 0.9472 0.9403 0.8568 0.0098 0.0063 0.0253 0.0354 0.1150</cell></row><row><cell>Ranking</cell><cell>W|T|L</cell><cell>4|0|9</cell><cell>9|0|4</cell><cell>0|0|13 0|0|13 0|0|13</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 19 :</head><label>19</label><figDesc>p-values of the Wilcoxon test for the number of features obtained by T V S3 versus other algorithms (p ≥ 0.05 are underlined).</figDesc><table><row><cell>Datasets Breast Cancer 1.19E-02 9.76E-06 6.24E-03 2.26E-05 T V V 4 bGWO BGSA BBA BreastEW 5.48E-09 6.51E-09 3.23E-07 5.61E-01 Exactly 8.53E-13 2.46E-11 1.09E-07 7.61E-03 Exactly2 2.75E-04 8.15E-01 2.74E-01 2.01E-01 HeartEW 9.14E-09 4.29E-09 5.81E-02 1.62E-01 Lymphography 4.84E-05 1.41E-03 4.49E-01 2.91E-03 M-of-n 1.75E-12 1.46E-12 7.38E-12 2.86E-01 penglungEW 2.94E-11 2.90E-11 2.88E-11 1.90E-02 SonarEW 1.00E-08 1.16E-07 9.60E-02 1.75E-01 SpectEW 8.73E-09 6.41E-10 2.87E-05 7.07E-03 CongressEW 8.51E-03 8.44E-09 1.89E-02 6.42E-01 IonosphereEW 8.26E-10 1.84E-09 1.41E-05 3.10E-01 KrvskpEW 9.42E-08 3.37E-11 1.35E-01 3.42E-09 Tic-tac-toe 5.80E-05 4.93E-07 3.18E-09 3.71E-10 Vote 1.05E-10 7.56E-10 9.94E-10 2.31E-06 WaveformEW 1.03E-08 4.30E-10 1.26E-01 7.84E-08 WineEW 9.47E-11 2.50E-11 3.07E-11 2.49E-03 Zoo 1.22E-11 2.31E-09 3.10E-10 5.55E-06</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 21 :</head><label>21</label><figDesc>Details of high-dimensional small instances datasets<ref type="bibr" target="#b70">[71]</ref> </figDesc><table><row><cell>Dataset Brain_Tumor2 10367 No. of Attributes No. of Objects No. of Classes 50 4 SRBCT 2308 83 4 9_Tumors 5726 60 9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 22 :</head><label>22</label><figDesc>Comparison between the best BDA V-shaped and BDA S-shaped time dependent variants and other meta-heuristics in term of accuracy</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Benchmark</cell><cell>Measure</cell><cell>BDA TVV4 TVS3</cell><cell>bGWO BGSA BBA</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Brain_Tumor2</cell><cell>AVG STD</cell><cell>0.6000 0.7100 0.5600 0.5133 0.4500 0.0000 0.0305 0.0498 0.0346 0.0572</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>SRBCT</cell><cell></cell><cell>AVG STD</cell><cell>0.9020 0.8275 0.8882 0.9000 0.8667 0.0520 0.0435 0.0357 0.0441 0.0265</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">9_Tumors</cell><cell>AVG STD</cell><cell>0.5028 0.5611 0.3917 0.5228 0.1033 0.0152 0.0375 0.0543 0.0285 0.0394</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Classification accuracy</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>TVS3</cell><cell>TVV4</cell><cell>BGWO Algorithms</cell><cell>BGSA</cell><cell>BBA</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 23 :</head><label>23</label><figDesc>Comparison between the best BDA V-shaped and BDA S-shaped time dependent variants and other meta-heuristics in term of fitness results</figDesc><table><row><cell>Benchmark</cell><cell>Measure</cell><cell>BDA TVV4 TVS3</cell><cell>bGWO BGSA BBA</cell></row><row><cell>Brain_Tumor2</cell><cell>AVG STD</cell><cell cols="2">0.4010 0.2920 0.4560 0.3018 0.3414 0.0000 0.0302 0.0495 0.0000 0.0493</cell></row><row><cell>SRBCT</cell><cell>AVG STD</cell><cell cols="2">0.0224 0.0535 0.1297 0.0608 0.0609 0.0271 0.0220 0.0309 0.0106 0.0106</cell></row><row><cell>9_Tumors</cell><cell>AVG STD</cell><cell cols="2">0.4970 0.4393 0.5633 0.4564 0.7948 0.0151 0.0371 0.0416 0.0337 0.0278</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 24 :</head><label>24</label><figDesc>Comparison between the best BDA V-shaped and BDA S-shaped time dependent variants and other meta-heuristics in terms of minimum number of features</figDesc><table><row><cell>Benchmark</cell><cell>Measure</cell><cell>BDA TVV4 TVS3</cell><cell>bGWO</cell><cell>BGSA</cell><cell>BBA</cell></row><row><cell>Brain_Tumor2</cell><cell>AVG STD</cell><cell cols="3">5134.23 5121.43 4150.90 4932.43 40.78 33.11 509.29 24.48</cell><cell>4992.90 60.39</cell></row><row><cell>SRBCT</cell><cell>AVG STD</cell><cell>1135.63 1135.57 29.31 18.78</cell><cell cols="2">907.90 1047.23 78.88 12.20</cell><cell>1068.33 15.37</cell></row><row><cell>9_Tumors</cell><cell>AVG STD</cell><cell>2715.17 2758.03 17.20 36.38</cell><cell cols="3">2914.27 2859.13 2318.67 300.60 40.62 186.95</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 25 :</head><label>25</label><figDesc>p-values of the Wilcoxon test for the fitness results of T V V 4 versus other algorithms</figDesc><table><row><cell>T V S3 Brain_Tumor2 1.57E-10 9.96E-08 2.79E-11 2.84E-11 bGWO BGSA BBA SRBCT 8.48E-06 6.70E-06 1.91E-03 3.46E-09 9_Tumors 4.39E-05 2.91E-11 4.44E-04 2.99E-11</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>than BDA-based versions. On the other hand, referring to Tables <ref type="table">12</ref> and<ref type="table">18</ref>, we see that both variants of BDA can outperform BBA in term of accuracy for all problems and all differences are statistically significant. Boxplots of accuracy results for BDA V-shaped and BDA S-shaped time dependent variants versus other competitors on the compared datasets are shown in Figs. <ref type="figure">7</ref> and<ref type="figure">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7.">Comparison with other meta-heuristics</head><p>This section compares the proposed TV-BDA approaches with popular FS methods proposed in previous studies in terms of classification accuracy rates. The results of T V S3 and T V V 4 are compared with the results of GA and PSO from <ref type="bibr" target="#b41">[42]</ref> and the results of the bGWO1, bGWO2, GA, and PSO from <ref type="bibr" target="#b52">[53]</ref> in Table <ref type="table">20</ref>. It is worth mentioning that the results of the first GA and PSO versions where executed using the source code from the authors in <ref type="bibr" target="#b41">[42]</ref>, while the results of bGWO1, bGWO2, GA, and PSO where obtained from the paper <ref type="bibr" target="#b52">[53]</ref>, where the same datasets are used.</p><p>In table 20, the substantial superiority of the proposed approaches is observed, where T V S3 is capable of revealing the best results for fourteen datasets, and T V V 4 has discovered the best results for four datasets. These results show again how TV-TFs influences the effectiveness and results of the BDA by enhancing its exploration and exploitation capabilities, to find the most informative features that provides the maximum classification accuracy for different datasets in different dimensions. The key reason for this excellent performance is that the proposed time-varying transfer mechanisms can provide more variety for exploration and exploitation, which leads to improved classification rates. The results are also visually compared in Fig. <ref type="figure">9</ref>. It can be seen that the classification rates of T V S3 and T V V 4 are relatively higher (shown using darker colors) than those attained by  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Improving extreme learning machine by competitive swarm optimization and its application for medical diagnosis problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eshtay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Obeid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="134" to="152" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A survey on evolutionary algorithms dynamics and its complexity-mutual relations, past, present and future</title>
		<author>
			<persName><forename type="first">I</forename><surname>Zelinka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2" to="14" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Gaussian bare-bones water cycle algorithm for optimal reactive power dispatch in electrical power systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Abbaspour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Jordehi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="657" to="671" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An efficient chaotic water cycle algorithm for optimization tasks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Abbaspour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Jordehi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="57" to="85" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An efficient hybrid multilayer perceptron neural network with grasshopper optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Computing</title>
		<imprint>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dragonfly algorithm: a new meta-heuristic optimization technique for solving single-objective, discrete, and multi-objective problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1053" to="1073" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Price penalty factors based approach for combined economic emission dispatch problem solution using dragonfly algorithm</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Bhesdadiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Pandya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">N</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jangir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jangir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 International Conference on Energy Efficient Technologies for Sustainability</title>
		<imprint>
			<biblScope unit="page" from="436" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generation dispatch of combined solar thermal systems using dragonfly algorithm</title>
		<author>
			<persName><forename type="first">V</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sreejith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="59" to="80" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A performance comparison of multiobjective optimization algorithms for solving nearly-zero-energy-building design problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hamdy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L M</forename><surname>Hensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Energy and Buildings</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="57" to="71" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Range based wireless node localization using dragonfly algorithm</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Daely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ubiquitous and Future Networks (ICUFN)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1012" to="1015" />
		</imprint>
	</monogr>
	<note>Eighth International Conference on</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Bio-inspired optimization for feature set dimensionality reduction</title>
		<author>
			<persName><forename type="first">E</forename><surname>Elhariri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>El-Bendary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassanien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Computational Tools for Engineering Applications (ACTEA), 2016 3rd International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="184" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A hybrid dragonfly algorithm with extreme learning machine for prediction</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Salam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Zawbaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Emary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K A</forename><surname>Ghany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 International Symposium on INnovations in Intelligent SysTems and Applications (INISTA)</title>
		<imprint>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dragonfly algorithm based global maximum power point tracker for photovoltaic systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Manickam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Ganesan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference in Swarm Intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="211" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Energy efficient cluster based protocol to extend the rfid network lifetime using dragonfly algorithm</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communication and Signal Processing (ICCSP), 2016 International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="530" to="0534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Solving 0-1 knapsack problems by binary dragonfly algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abdel-Basset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="491" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Price penalty factors based approach for combined economic emission dispatch problem solution using dragonfly algorithm</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bhesdadiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Pandya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">N</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jangir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jangir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="436" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Memory based hybrid dragonfly algorithm for numerical optimization problems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Ks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Murugan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="63" to="78" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Elite opposition learning and exponential function steps-based dragonfly algorithm for global optimization, in: Information and Automation (ICIA)</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="1178" to="1183" />
			<date type="published" when="2017">2017</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Binary dragonfly algorithm for feature selection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eleyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Jaber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hammouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New Trends in Computing Sciences (ICTCS), 2017 International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="12" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">S-shaped versus v-shaped transfer functions for binary particle swarm optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A modified binary particle swarm optimization for knapsack problems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deep</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="page" from="11042" to="11061" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A time-varying transfer function for balancing the exploration and exploitation ability of a binary pso</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="182" to="196" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A novel probability binary particle swarm optimization algorithm and its application</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of software</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="28" to="35" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A novel wrapper approach for feature selection in object-based image classification using polygon-based cross-validation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="409" to="413" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Feature selection approaches for predictive modelling of groundwater nitrate pollution: An evaluation of filters, embedded and wrapper methods</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rodriguez-Galiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luque-Espinar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chica-Olmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science of The Total Environment</title>
		<imprint>
			<biblScope unit="volume">624</biblScope>
			<biblScope unit="page" from="661" to="672" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">An improved nsga-iii algorithm for feature selection used in intrusion detection, Knowledge-Based Systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ming</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="74" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A novel automatic satire and irony detection using ensembled feature selection and data mining</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ravi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="15" to="33" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A smartphone-based activity-aware system for music streaming recommendation</title>
		<author>
			<persName><forename type="first">W.-P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="70" to="82" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Binary pso with mutation operator for feature selection using decision tree applied to spam detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="22" to="31" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The effect of feature selection on financial distress prediction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="289" to="297" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The impact of preprocessing on data mining: An evaluation of classifier sensitivity in direct marketing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Crone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lessmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stahlbock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="781" to="800" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Recent advances and emerging challenges of feature selection in the context of big data</title>
		<author>
			<persName><forename type="first">V</forename><surname>Bolón-Canedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sánchez-Maroño</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alonso-Betanzos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="33" to="45" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Feature Selection for Knowledge Discovery and Data Mining</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Motoda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Boston</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">WrapperâĂŞfilter feature selection algorithm using a memetic framework</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="70" to="76" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence and Feature Selection: Rough and Fuzzy Approaches</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Wiley-IEEE Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Talbi</surname></persName>
		</author>
		<title level="m">Metaheuristics From design to implementation</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A new local search based hybrid genetic algorithm for feature selection</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Kabir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shahjahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murase</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="2914" to="2928" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A discrete binary version of the particle swarm algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="4104" to="4108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">A Hybrid Approach Based on Particle Swarm Optimization and Random Forests for E-Mail Spam Filtering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Al-Shboul</surname></persName>
		</author>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="498" to="508" />
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Feature selection using binary particle swarm optimization with time varying inertia weight strategies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jarrar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abusnaina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2nd International Conference on Future Networks &amp; Distributed Systems</title>
		<meeting><address><addrLine>Amman, Jordan</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Rank based binary particle swarm optimisation for feature selection in classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Sabar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Nezamabadi-pour, An advanced aco algorithm for feature subset selection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kashef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="page" from="271" to="279" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A hybrid approach of differential evolution and artificial bee colony for feature selection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zorarpacı</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Özel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="91" to="103" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A novel bacterial foraging optimization algorithm for feature selection</title>
		<author>
			<persName><forename type="first">Y.-P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-F</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-T</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">An idea based on honey bee swarm for numerical optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Erciyes university, engineering faculty, computer engineering department</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report-tr06</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The ant lion optimizer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="80" to="98" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Hybrid binary ant lion optimizer with rough set and approximate entropy reducts for feature selection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Computing</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">S-shaped vs. v-shaped transfer functions for ant lion optimization algorithm in feature selection problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eleyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Abdullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Future Networks and Distributed Systems</title>
		<meeting>the International Conference on Future Networks and Distributed Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Grey wolf optimizer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="46" to="61" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">An efficient modified grey wolf optimizer with lévy flight for optimization tasks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pahlavani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="115" to="134" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Enhanced chaotic grey wolf optimizer for realworld optimization problems: A comparative study</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Abbaspour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Research on Emergent Applications of Optimization Algorithms</title>
		<imprint>
			<publisher>IGI Global</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="693" to="727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Feature subset selection approach by gray-wolf optimization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Emary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Zawbaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Grosan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassenian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Afro-European Conference for Industrial Advancement</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Binary grey wolf optimization approaches for feature selection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Emary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Zawbaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassanien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="371" to="381" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Moth-flame optimization algorithm: A novel nature-inspired heuristic paradigm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="228" to="249" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Feature selection approach based on moth-flame optimization algorithm</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Zawbaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Emary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sharawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation (CEC)</title>
		<imprint>
			<biblScope unit="page" from="4612" to="4617" />
			<date type="published" when="2016">2016</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
	<note>IEEE Congress on</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">A multi-verse optimizer approach for feature selection and optimizing svm parameters based on a robust system architecture</title>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hassonah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Al-Zoubi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Neural Computing and Applications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Investigating memetic algorithm in solving rough set attribute reduction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Abdullah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Applications in Technology</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="195" to="202" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Hybrid whale optimization algorithm with simulated annealing for feature selection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">260</biblScope>
			<biblScope unit="page" from="302" to="312" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Whale optimization approaches for wrapper feature selection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="441" to="453" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">A multi-verse optimizer approach for feature selection and optimizing svm parameters based on a robust system architecture</title>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hassonah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Al-Zoubi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Neural Computing and Applications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Evolutionary population dynamics and grasshopper optimization approaches for feature selection problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Hammouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Zoubi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page" from="25" to="45" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Asynchronous accelerating multi-leader salp chains for feature selection</title>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Flocks, herds and schools: A distributed behavioral model</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Reynolds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGGRAPH computer graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="25" to="34" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Binary optimization using hybrid particle swarm optimization and gravitational search algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D S</forename><surname>Coelho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">An introduction to kernel and nearest-neighbor nonparametric regression</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Altman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="175" to="185" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">UCI machine learning repository</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lichman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Optimizing the learning process of feedforward neural networks using lightning search algorithm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Al-Madi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Artificial Intelligence Tools</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">1650033</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A practical tutorial on the use of nonparametric statistical tests as a methodology for comparing evolutionary and swarm intelligence algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Derrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3" to="18" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Understanding machine learning: From theory to algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Feature selection for high-dimensional data</title>
		<author>
			<persName><forename type="first">V</forename><surname>Bolón-Canedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sánchez-Maroño</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alonso-Betanzos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">A comprehensive evaluation of multicategory classification methods for microarray gene expression cancer diagnosis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Statnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Aliferis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tsamardinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="631" to="643" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
