<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Itemset mining: A constraint programming perspective</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011-05-11">11 May 2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Tias</forename><surname>Guns</surname></persName>
							<email>tias.guns@cs.kuleuven.be</email>
							<affiliation key="aff0">
								<orgName type="institution">Katholieke Universiteit Leuven</orgName>
								<address>
									<addrLine>Celestijnenlaan 200A</addrLine>
									<postCode>3001</postCode>
									<settlement>Leuven</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Siegfried</forename><surname>Nijssen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Katholieke Universiteit Leuven</orgName>
								<address>
									<addrLine>Celestijnenlaan 200A</addrLine>
									<postCode>3001</postCode>
									<settlement>Leuven</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luc</forename><surname>De Raedt</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Katholieke Universiteit Leuven</orgName>
								<address>
									<addrLine>Celestijnenlaan 200A</addrLine>
									<postCode>3001</postCode>
									<settlement>Leuven</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Itemset mining: A constraint programming perspective</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2011-05-11">11 May 2011</date>
						</imprint>
					</monogr>
					<idno type="MD5">277EE8AD4AF8A15F61C7647F98EC0FF7</idno>
					<idno type="DOI">10.1016/j.artint.2011.05.002</idno>
					<note type="submission">Received 31 May 2010 Received in revised form 5 May 2011 Accepted 6 May 2011</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Data mining Itemset mining Constraint programming</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The field of data mining has become accustomed to specifying constraints on patterns of interest. A large number of systems and techniques has been developed for solving such constraint-based mining problems, especially for mining itemsets. The approach taken in the field of data mining contrasts with the constraint programming principles developed within the artificial intelligence community. While most data mining research focuses on algorithmic issues and aims at developing highly optimized and scalable implementations that are tailored towards specific tasks, constraint programming employs a more declarative approach. The emphasis lies on developing high-level modeling languages and general solvers that specify what the problem is, rather than outlining how a solution should be computed, yet are powerful enough to be used across a wide variety of applications and application domains. This paper contributes a declarative constraint programming approach to data mining. More specifically, we show that it is possible to employ off-the-shelf constraint programming techniques for modeling and solving a wide variety of constraint-based itemset mining tasks, such as frequent, closed, discriminative, and cost-based itemset mining. In particular, we develop a basic constraint programming model for specifying frequent itemsets and show that this model can easily be extended to realize the other settings. This contrasts with typical procedural data mining systems where the underlying procedures need to be modified in order to accommodate new types of constraint, or novel combinations thereof. Even though the performance of state-of-the-art data mining systems outperforms that of the constraint programming approach on some standard tasks, we also show that there exist problems where the constraint programming approach leads to significant performance improvements over state-of-the-art methods in data mining and as well as to new insights into the underlying data mining problems. Many such insights can be obtained by relating the underlying search algorithms of data mining and constraint programming systems to one another. We discuss a number of interesting new research questions and challenges raised by the declarative constraint programming approach to data mining.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Itemset mining is probably the best studied problem in the data mining literature. Originally applied in a supermarket setting, it involved finding frequent itemsets, that is, sets of items that are frequently bought together in transactions of customers <ref type="bibr" target="#b0">[1]</ref>. The introduction of a wide variety of other constraints and a range of algorithms for solving these constraintbased itemset mining problems <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b8">9]</ref> has enabled the application of itemset mining to numerous other problems, ranging from web mining to bioinformatics <ref type="bibr" target="#b30">[31]</ref>; for instance, whereas early itemset mining algorithms focused on finding itemsets in unsupervised, sparse data, nowadays closed itemset mining algorithms enable the application of itemset mining on dense data <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b42">43]</ref>, while discriminative itemset mining algorithms allow for their application on supervised data <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b12">13]</ref>. This progress has resulted in many effective and scalable itemset mining systems and algorithms, usually optimized to specific tasks and constraints. This procedural and algorithmic focus can make it non-trivial to extend such systems to accommodate new constraints or combinations thereof. The need to allow user-specified combinations of constraints is recognized in the data mining community, as witnessed by the development of a theoretical framework based on (anti-)monotonicity <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b10">11]</ref> and systems such as ConQueSt <ref type="bibr" target="#b8">[9]</ref>, MusicDFS <ref type="bibr" target="#b49">[50]</ref> and Molfea <ref type="bibr" target="#b17">[18]</ref>. These systems support a predefined number of (anti-)monotonicity based constraints, making them well suited for a number of typical data mining tasks.</p><p>These approaches contrast with those of constraint programming. Constraint programming is a general declarative methodology for solving constraint satisfaction problems, meaning that constraint programs specify what the problem is, rather than outline how the solution should be computed; it does not focus on a particular application. Constraint programming systems provide declarative modeling languages in which many types of constraints can be expressed and combined; they often support a much wider range of constraints than more specialized systems such as satisfiability (SAT) and integer linear programming (ILP) solvers <ref type="bibr" target="#b9">[10]</ref>. To realize this, the model is separated as much as possible from the solver. In the past two decades, constraint programming has developed expressive high-level modeling languages as well as solvers that are powerful enough to be used across a wide variety of applications and domains such as scheduling and planning <ref type="bibr" target="#b44">[45]</ref>.</p><p>The question that arises in this context is whether these constraint programming principles can also be applied to itemset mining. As compared to the more traditional constraint-based mining approach, this approach would specify data mining models using general and declarative constraint satisfaction primitives, instead of specialized primitives; this should make it easy to incorporate new constraints and combinations thereof as -in principle -only the model needs to be extended to specify the problem and general purpose solvers can be used for computing solutions.</p><p>The contribution of this article is that we answer the above question positively by showing that the general, off-the-shelf constraint programming methodology can indeed be applied to the specific problems of constraint-based itemset mining. <ref type="foot" target="#foot_0">1</ref>We show how a wide variety of itemset mining problems (such as frequent, closed and cost-based) can be modeled in a constraint programming language and that general purpose out-of-the-box constraint programming systems can effectively deal with these problems.</p><p>While frequent, closed and cost-based itemset mining are ideal cases, for which the existing constraint programming modeling language used suffices to tackle the problems, this cannot be expected in all cases. Indeed, in our formulation of discriminative itemset mining, we introduce a novel primitive by means of a global constraint. This is common practice in constraint programming, and the identification and study of global constraints that can effectively solve specific subproblems has become a branch of research on its own <ref type="bibr" target="#b5">[6]</ref>. Here, we have exploited the ability of constraint programming to serve as an integration platform, allowing for the free combination of new primitives with existing ones. This property allows to find closed discriminative itemsets effectively, as well as discriminative patterns adhering to any other constraint(s). Furthermore, casting the problem within a constraint programming setting also provides us with new insights in how to solve discriminative pattern mining problems that lead to important performance improvements over state-of-the-art discriminative data mining systems.</p><p>A final contribution is that we compare the resulting declarative constraint programming framework to well-known state-of-the-art algorithms in data mining. It should be realized that any such comparison is difficult to perform; this already holds when comparing different data mining (resp. constraint programming) systems to one another. In our comparison we focus on high-level concepts rather than on specific implementation issues. Nevertheless, we demonstrate the feasibility of our approach using our CP4IM implementation that employs the state-of-the-art constraint programming library Gecode <ref type="bibr" target="#b46">[47]</ref>, which was developed for solving general constraint satisfaction problems. While our analysis reveals some weaknesses when applying this particular library to some itemset mining problem, it also reveals that Gecode can already outperform state-of-the-art data mining systems on some tasks. Although outside the scope of the present paper, it is an interesting topic of ongoing research <ref type="bibr" target="#b36">[37]</ref> to optimize constraint programming systems for use in data mining.</p><p>The article is organized as follows. Section 2 provides an introduction to the main principles of constraint programming. Section 3 introduces the basic problem of frequent itemset mining and discusses how this problem can be addressed using constraint programming techniques. The following sections then show how alternative itemset mining constraints and problems can be dealt with using constraint programming: Section 4 studies closed itemset mining, Section 5 considers discriminative itemset mining, and Section 6 shows that the typical monotonicity-based problems studied in the literature can also be addressed in the constraint programming framework. We also study in these sections how the search of the constraint programming approach compares to that of the more specialized approaches. The CP4IM approach is then evaluated in Section 7, which provides an overview of the choices made when modeling frequent itemset mining in a concrete constraint programming system and compares the performance of this constraint programming system to specialized data mining systems. Finally, Section 8 concludes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Constraint programming</head><p>In this section we provide a brief summary of the most common approach to constraint programming. More details can be found in text books <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b2">3]</ref>; we focus on high-level principles and omit implementation issues.</p><p>Constraint programming (CP) is a declarative programming paradigm: the user specifies a problem in terms of its constraints, and the system is responsible for finding solutions that adhere to the constraints. The class of problems that constraint programming systems focus on are constraint satisfaction problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 1 (Constraint Satisfaction Problem (CSP)).</head><p>A CSP P = (V, D, C) is specified by</p><p>• a finite set of variables V;</p><p>• an initial domain D, which maps every variable v ∈ V to a set of possible values D(v); • a finite set of constraints C.</p><p>A variable x ∈ V is called fixed if |D(x)| = 1; a domain D is fixed if all its variables are fixed, ∀x ∈ V: |D(x)| = 1. A domain D is called stronger than domain D if D (x) ⊆ D(x) for all x ∈ V; a domain is false if there exists an x ∈ V such that D(x) = ∅. A constraint C (x 1 , . . . , x k ) ∈ C is an arbitrary boolean function on variables {x 1 , . . . , x k } ⊆ V.</p><p>A solution to a CSP is a fixed domain D stronger than the initial domain D that satisfies all constraints. Abusing notation for a fixed domain, we must have that ∀C(x 1 , . . . , x k ) ∈ C: C (D (x 1 ), . . . , D (x k )) = true.</p><p>A distinguishing feature of CP is that it does not focus on a specific set of constraint types. Instead it provides general principles for solving problems with any type of variable or constraint. This sets it apart from satisfiability (SAT) solving, which focuses mainly on boolean formulas, and from integer linear programming (ILP), which focuses on linear constraints on integer variables.</p><p>Example 1. Assume we have four people that we want to allocate to two offices, and that every person has a list of other people that he does not want to share an office with. Furthermore, every person has identified rooms he does not want to occupy. We can represent an instance of this problem with four variables which represent the persons, and inequality constraints which encode the room-sharing constraints:</p><formula xml:id="formula_0">D(x 1 ) = D(x 2 ) = D(x 3 ) = D(x 4 ) = {1, 2}, C = {x 1 = 2, x 1 = x 2 , x 3 = x 4 }.</formula><p>The simplest algorithm to solve CSPs enumerates all possible fixed domains, and evaluates all constraints on each of these domains; clearly this approach is inefficient. Most CP systems perform a more intelligent type of depth-first search, as given in Algorithm 1 <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b44">45]</ref>:</p><formula xml:id="formula_1">Algorithm 1 Constraint-Search(D) 1: D := propagate(D) 2: if D is a false domain then 3: return 4: end if 5: if ∃x ∈ V: |D(x)| &gt; 1 then 6: x := arg min x∈V,D(x)&gt;1 f (x) 7: for all d ∈ D(x) do 8: Constraint-Search(D ∪ {x → {d}}) 9:</formula><p>end for 10: else 11:</p><p>Output solution 12: end if Other search strategies have been investigated as well <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b43">44]</ref>, but we restrict ourselves here to the most common case. In each node of the search tree the algorithm branches by restricting the domain of one of the variables not yet fixed (line 7 in Algorithm 1). It backtracks when a violation of a constraint is found (line 2). The search is further optimized by carefully choosing the variable that is fixed next (line 6); here a function f (x) ranks variables, for instance, by determining which variable is involved in the highest number of constraints.</p><p>The main concept used to speed up the search is constraint propagation (line 1). Propagation reduces the domains of variables such that the domain remains locally consistent. One can define many types of local consistencies, such as node consistency, arc consistency and path consistency; see <ref type="bibr" target="#b44">[45]</ref>. In general, in a locally consistent domain, a value d does not occur in the domain of a variable x if it can be determined that there is no solution D in which D (x) = {d}. The main motivation for maintaining local consistencies is to ensure that the backtracking search does not unnecessarily branch over such values, thereby significantly speeding up the search.</p><p>To maintain local consistencies, propagators or propagation rules are used. Each constraint is implemented by a propagator. Such a propagator is activated when the domain of one of the variables of the constraint changes. A propagator takes the domain as input and outputs a failed domain in case the constraint can no longer be satisfied, i.e. if there exists no fixed D stronger than D with C D (x 1 ), . . . , D (x k ) = true.</p><p>(1)</p><p>When possible, the propagator will remove values from the domain that can never satisfy the constraint, giving as output a stronger, locally consistent domain. More formally, a value c should be removed from the domain of a variable x if there is no fixed D stronger than D with D (x) = c and C D (x 1 ), . . . , D (x k ) = true.</p><p>(2) This is referred to as propagation; propagation ensures domain consistency. The repeated application of propagators can lead to increasingly stronger domains. Propagators are repeatedly applied until a fixed point is reached in which the domain does not change any more.</p><p>Consider the constraint x 1 = x 2 , the corresponding propagator is given in Algorithm 2:</p><formula xml:id="formula_2">Algorithm 2 Conceptual propagator for x 1 = x 2 1: if |D(x 1 )| = 1 then 2: D(x 2 ) = D(x 2 ) \ D(x 1 ) 3: end if 4: if |D(x 2 )| = 1 then 5: D(x 1 ) = D(x 1 ) \ D(x 2 ) 6: end if</formula><p>The propagator can only propagate when x 1 or x 2 is fixed (lines 1 and 4). If one of them is, its value is removed from the domain of the other variable (lines 2 and 5). In this propagator there is no need to explicitly check whether the constraint is violated, as a violation results in an empty and thus false domain in line 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 2 (Example 1 continued).</head><p>The initial domain of this problem is not consistent: the constraint x 1 = 2 cannot be satisfied when D(x 1 ) = {2} so value 2 is removed from the domain of x 1 . Subsequently, the propagator for the constraint x 1 = x 2 is activated, which removes value 1 from D(x 2 ). At this point, we obtain a fixed point with D(x 1 ) = {1}, D(x 2 ) = {2}, D(x 3 ) = D(x 4 ) = {1, 2}. Persons 1 and 2 have now each been allocated to an office, and two rooms are possible for persons 3 and 4. The search branches over x 3 and for each branch, constraint x 3 = x 4 is propagated; a fixed point is then reached in which every variable is fixed, and a solution is found.</p><p>In the above example for every variable its entire domain D(x) is maintained. In constraint programming many types of consistency and algorithms for maintaining consistency have been studied. A popular type of consistency is bound consistency. In this case, for each variable only a lower-and an upper-bound on the values in its domain is maintained. A propagator will try to narrow the domain of a variable to that range of values for which it still believes a solution can be found, but does not maintain consistency for individual values. To formulate itemset mining problems as constraint programming models, we mostly use variables with binary domains, i.e. D(x) = {0, 1} with x ∈ V. For such variables there is no difference between bound and domain consistency.</p><p>Furthermore, we make extensive use of two types of constraints over boolean variables, namely the summation constraint, Eq. ( <ref type="formula" target="#formula_3">3</ref>), and reified summation constraint, Eq. ( <ref type="formula">6</ref>), which are introduced below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Summation constraint</head><p>Given a set of variables V ⊆ V and weights w x for each variable x ∈ V , the general form of the summation constraint is:</p><formula xml:id="formula_3">x∈V w x x θ. (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>The first task of the propagator is to discover as early as possible whether the constraint is violated. To this aim, the propagator needs to determine whether the upper-bound of the sum is still above the required threshold; filling in the constraint of Eq. ( <ref type="formula">1</ref>), this means we need to check whether:</p><formula xml:id="formula_5">max fixed D stronger than D x∈V w x D (x) θ. (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>A more intelligent method to evaluate this property works as follows. We denote the maximum value of a variable x by</p><p>x max = max d∈D(x) d, and the minimum value by x min = min d∈D(x) d. Denoting the set of variables with a positive, respectively negative, weight by</p><formula xml:id="formula_7">V + = {x ∈ V | w x 0} and V -= {x ∈ V | w x &lt; 0}</formula><p>, the bounds of the sum are now defined as:</p><formula xml:id="formula_8">max x∈V w x x = x∈V + w x x max + x∈V - w x x min , min x∈V w x x = x∈V + w x x min + x∈V - w x x max .</formula><p>These bounds allow one to determine whether an inequality constraint x∈V w x x θ can still be satisfied.</p><p>The second task of the propagator is to maintain the bounds of the variables in the constraint, which in this case are the variables in V . In general, for every variable x ∈ V , we need to update xmin to the lowest value c for which there exists a domain D with fixed D stronger than D, D (x) = c and x∈V w x D (x) θ.</p><p>(</p><formula xml:id="formula_9">)<label>5</label></formula><p>Also this can be computed efficiently; essentially, for binary variables x ∈ V we can update all domains as follows:</p><formula xml:id="formula_10">• D(x) ← D(x) \ {0} if w x ∈ V + and θ max( x∈V w x x) &lt; θ + w x ; • D(x) ← D(x) \ {1} if w x ∈ V -and θ max( x∈V w x x) &lt; θ -w x .</formula><p>Example 3. Let us illustrate the propagation of the summation constraint. Given</p><formula xml:id="formula_11">D(x 1 ) = {1}, D(x 2 ) = D(x 3 ) = {0, 1}, D(x 1 ) = {1}, D(x 2 ) = D(x 3 ) = {0, 1}, 2 * x 1 + 4 * x 2 + 8 * x 3 7;</formula><p>the propagator determines that the constraint can never be satisfied if x 3 is false, so D(x 3 ) = {1}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Reified summation constraint</head><p>The second type of constraints we will use extensively is the reified summation constraint. Reified constraints are a common construct in constraint programming <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b53">54]</ref>. Essentially, a reified constraint binds the truth value of a constraint C to a binary variable b: b ↔ C .</p><p>In principle, C can be any boolean constraint. In this article, C will usually be a constraint on a sum. In this case we speak of a reified summation constraint: b ↔ x∈V w x x θ. <ref type="bibr" target="#b5">(6)</ref> This constraint states that b is true if and only if the weighted sum of the variables in V is higher than θ . The most important constraint propagation that occurs for this constraint is the one that updates the domain of variable b. Essentially, the domain of this variable is updated as follows:</p><formula xml:id="formula_12">• D(b) ← D(b) \ {1} if max( x∈V w x x) &lt; θ; • D(b) ← D(b) \ {0} if min( x∈V w x x) θ .</formula><p>In addition, in some constraint programming systems, constraint propagators can also simplify constraints. In this case, if D(b) = {1}, the reified constraint can be simplified to the constraint x∈V w x x θ ; if D(b) = {0}, the simplified constraint becomes x∈V w x x &lt; θ.</p><p>Many different constraint programming systems exist. They differ in the types of variables they support, the constraints they implement, the way backtracking is handled and the data structures that are used to store constraints and propagators. Furthermore, in some systems constraints are specified in logic (for instance, in the constraint logic programming system ECLiPSe <ref type="bibr" target="#b2">[3]</ref>), while in others the declarative primitives are embedded in an imperative programming language. An example of the latter is Gecode <ref type="bibr" target="#b46">[47]</ref>, which we use in the experimental section of this article. </p><formula xml:id="formula_13">Tid A B C D E 1 0 1 0 0 0 2 0 0 0 0 1 3 1 0 1 0 0 4 1 0 0 0 1 5 0 1 1 0 0 6 0 0 0 1 1 7 0 0 1 1 1 8 1 1 1 0 0 9 1 1 0 0 1 10 1 1 1 0 1</formula><p>Fig. <ref type="figure">1</ref>. A small example of an itemset database, in multiset notation (left) and in binary matrix notation (right).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Frequent itemset mining</head><p>Now that we have introduced the key concepts underlying constraint programming (CP), we study various itemset mining problems within this framework. We start with frequent itemset mining in the present section, and then discuss closed, discriminative and cost-based itemset mining in the following sections. For every problem, we provide a formal definition, then introduce a constraint programming model that shows how the itemset mining problem can be formalized as a CP problem, and then compare the search strategy obtained by the constraint programming approach to that of existing itemset mining algorithms.</p><p>We start with the problem of frequent itemset mining and we formulate two CP models for this case. The difference between the initial model and the improved one is that the later uses the notion of reified constraints, which yields better propagation as shown by an analysis of the resulting search strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem definition</head><p>The problem of frequent itemset mining was proposed in 1993 by Agrawal et al. <ref type="bibr" target="#b0">[1]</ref>. Given is a database with a set of transactions. 2 Let I = {1, . . . ,m} be a set of items and A = {1, . . . ,n} be a set of transaction identifiers. An itemset database D is as a binary matrix of size n × m with D ti ∈ {0, 1}, or, equivalently, a multi-set of itemsets I ⊆ I, such that D = (t, I) t ∈ A, I ⊆ I, ∀i ∈ I: D ti = 1 .</p><p>A small example of an itemset database is given in Fig. <ref type="figure">1</ref>, where for convenience every item is represented as a letter.</p><p>There are many databases that can be converted into an itemset database. The traditional example is a supermarket database, in which each transaction corresponds to a customer and every item in the transaction to a product bought by the customer. Attribute-value tables can be converted into an itemset database as well. For categorical data, every attributevalue pair corresponds to an item and every row is converted into a transaction.</p><p>The coverage ϕ D (I) of an itemset I consists of all transactions in which the itemset occurs:</p><formula xml:id="formula_14">ϕ D (I) = {t ∈ A | ∀i ∈ I: D ti = 1}.</formula><p>The support of an itemset I , which is denoted as support D (I), is the size of the coverage: support D (I) = ϕ D (I) .</p><p>In the example database we have ϕ D ({D, E}) = {T 6 , T 7 } and support D ({D, E}) = |{T 6 , T 7 }| = 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2 (Frequent itemset mining).</head><p>Given an itemset database D and a threshold θ , the frequent itemset mining problem consists of computing the set</p><formula xml:id="formula_15">I I ⊆ I, support D (I) θ .</formula><p>The threshold θ is called the minimum support threshold. An itemset with support D (I) θ is called a frequent itemset.</p><p>Note that we are interested in finding all itemsets satisfying the frequency constraint. The subset relation between itemsets defines a partial order. This is illustrated in Fig. <ref type="figure" target="#fig_0">2</ref> for the example database of Fig. <ref type="figure">1</ref>; the frequent itemsets are visualized in a Hasse diagram: a line is drawn between two itemsets I 1 and</p><formula xml:id="formula_16">I 2 iff I 1 ⊂ I 2 and |I 2 | = |I 1 | + 1.</formula><p>By changing the support threshold, an analyst can influence the number of patterns that is returned by the data mining system: the lower the support threshold, the larger the number of frequent patterns. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Initial constraint programming model</head><p>Our model of the frequent itemset mining problem in constraint programming is based on the observation that we can formalize the frequent itemset mining problem also as finding the set:</p><formula xml:id="formula_17">(I, T ) I ⊆ I, T ⊆ A, T = ϕ D (I), |T | θ .</formula><p>Here we make the set of transactions T = ϕ D (I) explicit. This yields the same solutions as the original problem because the set of transactions T is completely determined by the itemset I . We will refer to T = ϕ D (I) as the coverage constraint while |T | θ expresses a support constraint.</p><p>To model this formalization in CP, we need to represent the set of items I and the set of transactions T . In our model we use a boolean variable I i for every individual item i; furthermore we use a boolean variable T t for every transaction t.</p><p>An itemset I is represented by setting I i = 1 for all i ∈ I and I i = 0 for all i / ∈ I . The variables T t represent the transactions that are covered by the itemset, i.e. T = ϕ(I); T t = 1 iff t ∈ ϕ(I). One assignment of values to all I i and T t corresponds to one itemset and its corresponding transaction set. We now show that the coverage constraint can be formulated as follows.</p><p>Property 1 (Coverage constraint). Given a database D, an itemset I and a transaction set T , then</p><formula xml:id="formula_18">T = ϕ D (I) ⇐⇒ ∀t ∈ A: T t = 1 ↔ i∈I I i (1 -D ti ) = 0 , (<label>7</label></formula><formula xml:id="formula_19">)</formula><p>or equivalently,</p><formula xml:id="formula_20">T = ϕ D (I) ⇐⇒ ∀t ∈ A: T t = 1 ↔ i∈I D ti = 1 ∨ I i = 0 , (<label>8</label></formula><formula xml:id="formula_21">)</formula><p>where I i , T t ∈ {0, 1} and I i = 1 iff i ∈ I and T t = 1 iff t ∈ T .</p><p>Proof. Essentially, the constraint states that for one transaction t, all items i should either be included in the transaction (D ti = 1) or not be included in the itemset (I i = 0):</p><formula xml:id="formula_22">T = ϕ D (I) = {t ∈ A | ∀i ∈ I: D ti = 1} ⇐⇒ ∀t ∈ A: T t = 1 ↔ ∀i ∈ I: D ti = 1 ⇐⇒ ∀t ∈ A: T t = 1 ↔ ∀i ∈ I: 1 -D ti = 0 ⇐⇒ ∀t ∈ A: T t = 1 ↔ i∈I I i (1 -D ti ) = 0.</formula><p>The representation as a clause in Eq. ( <ref type="formula" target="#formula_20">8</ref>) follows from this. 2</p><p>It is quite common in constraint programming to encounter different ways to model the same problem or even the same conceptual constraint, as above. How propagation is implemented for these constraints can change from solver to solver. For example, watched literals could be used for the clause constraint, leading to different runtime and memory characteristics compared to a setting where no watched literals are used. We defer the study of such characteristics to Section 7.</p><p>Under the coverage constraint, a transaction variable will only be true if the corresponding transaction covers the itemset.</p><p>Counting the frequency of the itemset can now be achieved by counting the number of transactions for which T t = 1.</p><p>Property 2 (Frequency constraint). Given a database D, a transaction set T and a threshold θ , then</p><formula xml:id="formula_23">|T | θ ⇐⇒ t∈A T t θ, (<label>9</label></formula><formula xml:id="formula_24">)</formula><p>where T t ∈ {0, 1} and T t = 1 iff t ∈ T .</p><p>We can now model the frequent itemset mining problem as a combination of the coverage constraint <ref type="bibr" target="#b6">(7)</ref> and the frequency constraint <ref type="bibr" target="#b8">(9)</ref>. To illustrate this, we provide an example of our model in the Essence' language in Algorithm 3:  <ref type="formula" target="#formula_18">7</ref>)) 8: forall t: int(1..NrT). 9: Essence' is a solver-independent modeling language; it was developed to support intuitive modeling, abstracting away from the underlying solver technology <ref type="bibr" target="#b21">[22]</ref>.</p><formula xml:id="formula_25">Trans[t]</formula><p>We will now study how a constraint programming solver will search for the solutions given the above model. A first observation is that the set of transactions is completely determined by the itemset, so we need only to search over the item variables.</p><p>When an item variable is set (D(I i ) = {1}) by the search, only the constraints that contain this item will be activated.</p><p>In other words, the frequency constraint will not be activated, but every coverage constraint that contains this item will be. A coverage constraint is a reified summation constraint, for which the propagator was explained in Section 2. In summary, when an item variable is set, the following propagation is possible for the coverage constraint:</p><formula xml:id="formula_26">• if for some t: i∈I (1 -D ti ) * I min i &gt; 0 then remove 1 from D(T t ); • if for some t: i∈I (1 -D ti ) * I max i = 0 then remove 0 from D(T t ).</formula><p>Once the domain of a variable T t is changed, the support constraint will be activated. The support constraint is a summation constraint, which will check whether:</p><formula xml:id="formula_27">t∈A T max t θ.</formula><p>If this constraint fails, we do not need to branch further and we can backtrack.</p><p>Example 4. Fig. <ref type="figure" target="#fig_1">3</ref>(a) shows part of a search tree for a small example with a minimum frequency threshold of 2. Essentially, the search first tries to add an item to an itemset and after backtracking it will only consider itemsets not including it. After a search step (indicated in green), the propagators are activated. The coverage propagators can set transactions to 0 or 1, while the frequency constraint can cause failure when the desired frequency can no longer be obtained (indicated by a red cross in the two left-most branches). Observe that in the example we branched on item 2 first. This follows the generic 'most constrained' variable order heuristic, which branches over the variable contained in most constraints first (remember that the coverage constraints are posted on items that have a 0 in the matrix). If item 1 would be branched over first, the search tree would be larger, as both branches would have to determine separately that I 2 = 1 does not result in a frequent itemset. An experimental investigation of different branching heuristics is done in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Improved model</head><p>Inspired by observations in traditional itemset mining algorithms, we propose an alternative model that substantially reduces the size of the search tree by introducing fine-grained constraints. The main observation is that we can formulate the frequency constraint on each item individually:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Property 3 (Reified frequency constraint). Given a database D, an itemset I = ∅ and a transaction set T , such that</head><formula xml:id="formula_28">T = ϕ D (I), then |T | θ ⇐⇒ ∀i ∈ I : I i = 1 → t∈A T t D ti θ, (<label>10</label></formula><formula xml:id="formula_29">)</formula><formula xml:id="formula_30">where I i , T t ∈ {0, 1} and I i = 1 iff i ∈ I and T t = 1 iff t ∈ T .</formula><p>Proof. We observe that we can rewrite ϕ D (I) as follows:</p><formula xml:id="formula_31">ϕ D (I) = {t ∈ A | ∀i ∈ I: D ti = 1} = i∈I ϕ D {i} .</formula><p>Using this observation, it follows that:</p><formula xml:id="formula_32">|T | θ ⇐⇒ j∈I ϕ D { j} θ ⇐⇒ ∀i ∈ I: ϕ D {i} ∩ j∈I ϕ D { j} θ ⇐⇒ ∀i ∈ I: ϕ D {i} ∩ T θ ⇐⇒ ∀i ∈ I: I i = 1 → t∈A T t D ti θ. 2</formula><p>The improved model consists of the coverage constraint (Eq. ( <ref type="formula" target="#formula_18">7</ref>)) and the newly introduced reified frequency constraint (Eq. ( <ref type="formula" target="#formula_28">10</ref>)). This model is equivalent to the original model, and also finds all frequent itemsets.</p><p>The reified frequency constraint is posted on every item separately, resulting in more fine-grained search-propagation interactions. Essentially, the reified frequency constraint performs a kind of look-ahead; for each item, a propagator will check whether that item is still frequent given the current itemset. If it is not, it will be removed from further consideration, as its inclusion would make the itemset infrequent. In summary, the main additional propagation allowed by the reified constraint is the following:</p><formula xml:id="formula_33">• if for some i: t∈A D ti * T max t &lt; θ then remove 1 from D(I i ), i.e. I i = 0.</formula><p>Example 5. Fig. <ref type="figure" target="#fig_1">3</ref> shows the search trees of both the original non-reified model as well as the improved model using the reified frequency constraint.</p><p>In the original model (Fig. <ref type="figure" target="#fig_3">3(a)</ref>), the search branches over I 2 = 1, after which the propagation detects that this makes the itemset infrequent and fails (left-most branch). In the reified model (Fig. <ref type="figure" target="#fig_3">3(b)</ref>) the reified frequency propagator for I 2 detects that this item is infrequent. When evaluating the sum (0</p><formula xml:id="formula_34">* T max 1 + 1 * T max 2 + 0 * T max</formula><p>3 ), it is easy to see that the maximum is 1 &lt; 2, leading to I 2 = 0 (second level). The same situation occurs for I 3 near the bottom of the figure. This time, the propagator takes into account that at this point T 3 = 0 and hence T max</p><formula xml:id="formula_35">3 = 0.</formula><p>The reified propagations avoid creating branches that can only fail. In fact, using the reified model, the search becomes failure-free: every branch will lead to a solution, namely a frequent itemset. This comes at the cost of a larger number of propagations. In Section 7 we experimentally investigate the difference in efficiency between the two formulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Comparison</head><p>Let us now study how the proposed CP-based approach compares to traditional itemset mining algorithms. In order to understand this relationship, let us first provide a short introduction to these traditional algorithms.</p><p>The most important property exploited in traditional algorithms is anti-monotonicity.</p><p>Definition 3 (Anti-monotonic constraints). Assume given two itemsets I 1 and I 2 , and a predicate p(I, D) expressing a constraint that itemset I should satisfy on database D. Then the constraint is anti-monotonic iff</p><formula xml:id="formula_36">∀I 1 ⊆ I 2 : p(I 2 , D) ⇒ p(I 1 , D).</formula><p>Indeed, if an itemset I 2 is frequent, any itemset I 1 ⊆ I 2 is also frequent, as it must be included in at least the same transactions as I 2 . This property allows one to develop search algorithms that do not need to consider all possible itemsets.</p><p>Essentially, no itemset I 2 ⊃ I 1 needs to be considered any more once it has been found that I 1 is infrequent.</p><p>Starting a search from the empty itemset, there are many ways in which one could traverse the search space, the most important ones being breadth-first search and depth-first search. Initial algorithms for itemset mining were mostly breadthfirst search algorithms, of which the Apriori algorithm is the main representative <ref type="bibr" target="#b1">[2]</ref>. However, more recent algorithms mostly use depth-first search. Given that most CP systems also perform depth-first search, the similarities between CP and depth-first itemset mining algorithms are much larger than between CP and breadth-first mining algorithms. An outline of a general depth-first frequent itemset mining algorithm is given in Algorithm 4. The main observations are the following:</p><p>• if an item is infrequent in a database, we can remove the corresponding column from the database, as no itemset will contain this item and hence the column is redundant;</p><p>• once an item is added to an itemset, all transactions not containing this item become irrelevant for the search tree below this itemset; hence we can remove the corresponding row from the database.</p><p>The resulting database, which contains a smaller number of transactions having a smaller number of items, is often called a projected database. Hence, every time that we add an item to an itemset, we determine which items and transactions become irrelevant, and continue the search for the resulting database, which only contains frequent items and transactions covered by the current itemset. Important benefits are that the search procedure will never try to add items once they have been found to be infrequent; transactions no longer relevant can similarly be ignored.</p><p>Please note the following detail: in the projected database, we only include items which are strictly higher in order than the highest item currently in the itemset. The reason for this is that we wish to avoid that the same itemset is found multiple times; for instance, we wish to find itemset {1, 2} only as a child of itemset {1} and not also as a child of itemset {2}. -only items in D i that are frequent and higher than i in chosen order R 7:</p><formula xml:id="formula_37">F := F ∪ Depth-First-Search(I ∪ {i}, D i );</formula><p>8: end for 9: return F An important choice in this general algorithm is how the projected databases are stored. A very large number of strategies have been explored, among which tid-lists and FP-trees <ref type="bibr" target="#b29">[30]</ref>. Tid-lists are most relevant here, as they compare best to strategies chosen in CP systems. Given an item i, its tid-list in a database D is ϕ D ({i}). We can store this list as a list of integers <ref type="bibr" target="#b55">[56]</ref>, a binary vector, or using variations of run-length encoding <ref type="bibr" target="#b48">[49]</ref>. The projected database of a given itemset I is thus the set</p><formula xml:id="formula_38">i, ϕ D I ∪ {i} ϕ D I ∪ {i} θ .</formula><p>The interesting property of tid-lists is that they can easily be updated incrementally: if we wish to obtain a tid-list for item j in the projected database of itemset {i}, this can be obtained by computing ϕ D ({i}) ∩ ϕ D ({ j}), where D is the original database; for instance, in the case bit vectors are used this is a binary AND operation, which most CPUs evaluate efficiently. The most well-known algorithm using this approach is the Eclat algorithm <ref type="bibr" target="#b55">[56]</ref>.</p><p>An example of a depth-first search tree is given in Fig. <ref type="figure" target="#fig_4">4</ref>, using the same database as in Fig. <ref type="figure" target="#fig_1">3</ref>; we represent the projected database using tid-lists. The order of the items is assumed to be the usual order between integers. In the initial projected database, item 2 does not occur as it is not frequent. Each child of the root corresponds to an itemset with one item. The search tree for depth-first frequent itemset miners, for the same example as in Fig. <ref type="figure" target="#fig_1">3</ref>, where the items are ordered by the natural order on integers. Each itemset has a corresponding projected database containing only frequent items higher than the items chosen so far. For instance, the projected database for itemset {4} is empty as items 1 and 3 are lower than 4; the database of {1} does not contain item i 3 as {1, 3} is not frequent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.">Comparison with search using the CP model</head><p>We now compare the above descriptions of itemset mining algorithms and constraint programming systems. Necessarily we need to restrict this discussion to a comparison of high-level principles; a detailed comparison of both approaches is not possible without studying the data structures of specific constraint programming systems in detail, which we consider to be out of the scope of this article; see <ref type="bibr" target="#b36">[37]</ref> for a first attempt in that direction.</p><p>We first consider the differences in the search trees when using our CP model as compared to traditional mining algorithms. These differences can be understood by comparing the trees in Figs. <ref type="figure" target="#fig_3">3</ref> and<ref type="figure" target="#fig_4">4</ref>. In depth-first itemset mining, each node in the search tree corresponds to an itemset. Search proceeds by adding items to it; nodes in the search tree can have an arbitrary number of children. In CP, each node in the search tree corresponds to a domain, which in our model represents a choice for possible values of items and transactions. Search proceeds by restricting the domain of a variable. The resulting search tree is always binary, as every item is represented by a boolean variable that can either be true or false (include or exclude the item).</p><p>We can identify the following relationship between nodes in the search tree of a CP system and nodes in the search tree of itemset miners. Denoting by D(I i ) the domain of item variable I i in the state of the CP system, we can map each state to an itemset as follows:</p><formula xml:id="formula_39">i ∈ I D(I i ) = {1} .</formula><p>Essentially, in CP some branches in the search tree correspond to an assignment D(I i ) = {0} for an item i (i.e. the item i is removed from consideration). All nodes across a path of such branches are collapsed in one node of the search tree of the itemset miner, turning the binary tree in an n-ary tree.</p><p>Even though it might seem that this different perception of the search tree leads to a higher memory use in CP systems, this is not necessarily the case. If the search tree is traversed in the order indicated in Fig. <ref type="figure" target="#fig_3">3(b</ref>), once we have assigned value D(I 1 ) = {0} and generated the corresponding child node, we no longer need to store the original domain D with D(I 1 ) = {0, 1}. The reason is that there are no further children to generate for this original node in the search tree; if the search returns to this node, we can immediately backtrack further to its parent (if any). Hence, additional memory only needs to be consumed by branches corresponding to D(I i ) = {1} assignments. This implies that in practice the efficiency depends on the implementation of the CP system; it does not depend on the theoretically different shape of the search tree.</p><p>In more detail these are the possible domains for the variables representing items during the search of the CP system:</p><p>• D(I i ) = {0, 1}: this represents an item that can still be added to the itemset, but that currently is not included; in traditional itemset mining algorithms, these are the items included in the projected database;</p><p>• D(I i ) = {0}: this represents an item that will not be added to the itemset. In the case of traditional itemset mining algorithms, these are items that are neither part of the projected database nor part of the current itemset;</p><p>• D(I i ) = {1}: this represents an item that will be part of all itemsets deeper down the search tree; in the case of traditional algorithms, this item is part of the itemset represented in the search tree node.</p><p>Similarly, we have the transaction variables:</p><p>• D(T t ) = {0, 1}: this represents a transaction that is covered by the current itemset (since 1 is still part of its domain), but may still be removed from the coverage later on; in traditional algorithms, this transaction is part of the projected database;</p><p>• D(T t ) = {0}: this represents a transaction that is not covered by the current itemset; in traditional algorithms, this transaction is not part of the projected database;</p><p>• D(T t ) = {1}: this represents a transaction that is covered by the current itemset and that will be covered by all itemsets deeper down the search tree, as the transaction contains all items that can still be added to the itemset; in traditional itemset mining algorithms, this transaction is part of the projected database.</p><p>A second difference is hence which information is available about transactions during the search. In our CP formalization, we distinguish transactions with domain D(T t ) = {0, 1} and D(T t ) = {1}. Frequent itemset mining algorithms do not make this distinction. This difference allows one to determine when transactions are unavoidable: A transaction becomes unavoidable</p><formula xml:id="formula_40">(D(T t ) = {1}) if all remaining items (1 ∈ D(I i ))</formula><p>are included in it; the propagation to detect this occurs in branches where items are removed from consideration. Such branches are not present in the itemset mining algorithms; avoiding this propagation could be important in the development of new constraint programming systems. Thirdly, to evaluate the constraints, CP systems store constraints or propagators during the search. Essentially, to every node in the search tree a state is associated that reflects active constraints, propagators and variables. Such a state corresponds to the concept of a projected database in itemset mining algorithms. The data structures for storing and maintaining propagators in CP systems and in itemset mining algorithms are however often very different. For example, in itemset mining efficient data representations such as tid-lists and fp-trees have been developed; CP systems use data structures for storing both propagators and constraints, which may be redundant in this problem setting. For instance, while in depth-first itemset mining, a popular approach is to store a tid-list in an integer array, CP systems may use both an array to store the indexes of variables in a constraint, and use an array to store a list of constraints watching a variable. Resolving these differences however requires a closer study of particular constraint programming systems, which is outside the scope of this paper.</p><p>Overall, this comparison shows that there are many high-level similarities between itemset mining and constraint programming systems, but that in many cases one can also expect lower-level differences. Our experiments will show that these low-level differences can have a significant practical impact, and hence that an interesting direction for future research is to bridge the gap between these systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Closed itemset mining</head><p>Even though the frequency constraint can be used to limit the number of patterns, the constraint is often not restrictive enough to find useful patterns. A high support threshold usually has as effect that only well-known itemsets are found; for a low threshold the number of patterns is often too large. To alleviate this problem, many additional types of constraints have been introduced. In this and the following sections, we will study how three further representative types of constraints can be formalized as constraint programming problems. Closed itemset mining aims at avoiding redundant itemsets, discriminative itemset mining wants to find itemsets that discriminate two classes of transactions, and cost-based constraints are representative for a fairly general class of constraints in the monotonicity framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Problem definition</head><p>Condensed representations aim at avoiding redundant itemsets, which are itemsets whose necessary presence in the full solution set may be derived from other itemsets found by the algorithm. The closedness constraint is a typical constraint that is used to find such a condensed representation <ref type="bibr" target="#b39">[40]</ref>. We now introduce the closedness constraint more formally.</p><p>One way to interpret itemsets, is by seeing them as rectangles of ones in a binary matrix. For instance, in our example database of Fig. <ref type="figure">1</ref> on page 1956, for itemset {D} we have corresponding transactions {T 6 , T 7 }. The itemset {D} and the transaction set {T 6 , T 7 } select a submatrix which can be seen as a rectangle in the matrix. Observe that due to the way that we calculate the set of transactions from the set of items, we cannot add a transaction to the set of transactions without including a zero element in the rectangle. However, this is not the case for the columns. In this case, we have ϕ({D}) = ϕ({D, E}) = {T 6 , T 7 }; we can add item E and still obtain a rectangle containing only ones. Closed itemset mining can be seen as the problem of finding maximal rectangles of ones in the matrix. An essential property of 'maximal' rectangles is that if we consider its transactions, we can derive the corresponding set of items: the largest itemset shared by all transactions must define all columns included in the rectangle. This leads us to the following definition of closed itemset mining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4 (Frequent closed itemset mining).</head><p>Given a database D, let ψ D (T ) be defined as</p><formula xml:id="formula_41">ψ D (T ) = {i ∈ I | ∀t ∈ T : D ti = 1}.</formula><p>Given a threshold θ , the frequent closed itemsets are the itemsets in</p><formula xml:id="formula_42">I I ⊆ I, support D (I) θ, ψ D ϕ D (I) = I .</formula><p>Given an itemset I , the itemset ψ D (ϕ D (I)) is called the closure of I . Closed itemsets are those which equal their closure.</p><p>If an itemset is not equal to its closure, this means that we can add an item to the itemset without changing its support. Closed itemsets for our example database are highlighted in black in Fig. <ref type="figure" target="#fig_0">2</ref>.</p><p>The idea behind closed itemsets has also been studied in other communities; closed itemset mining is in particular closely related to the problem of finding formal concepts in formal contexts <ref type="bibr" target="#b23">[24]</ref>. Essentially, formal concepts can be thought of as closed itemsets that are found without applying a support threshold. In formal concept analysis, the operators ϕ and ψ are called Galois operators. These operators define a Galois connection between the partial orders for itemsets and transaction sets, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Constraint programming model</head><p>Compared to frequent itemset mining, the additional constraint that we need to express is the closedness constraint. We can deal with this constraint in a similar way as with the coverage constraint. Assuming that T represents the set of transactions covered by an itemset I , the constraint that we need to check is the following: <ref type="bibr" target="#b10">(11)</ref> as in this case ψ D (ϕ D (I)) = I . This leads to the following constraint in the CP model, which should be posted together with the constraints in Eqs. ( <ref type="formula" target="#formula_18">7</ref>) and <ref type="bibr" target="#b9">(10)</ref>.</p><formula xml:id="formula_43">ψ D (T ) = I,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Property 4 (Closure constraint). Given a database D, an itemset I and a transaction set T , then</head><formula xml:id="formula_44">I = ψ D (T ) ⇐⇒ ∀i ∈ I: I i = 1 ↔ t∈A T t (1 -D ti ) = 0 , (<label>12</label></formula><formula xml:id="formula_45">)</formula><p>where I i , T t ∈ {0, 1} and</p><formula xml:id="formula_46">I i = 1 iff i ∈ I and T t = 1 iff t ∈ T .</formula><p>The proof is similar to the proof for the coverage constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison</head><p>Several classes of algorithms have been proposed for closed itemset mining, each being either an extension of a breadthfirst algorithm such as Apriori, or a depth-first algorithm, operating on tid-lists or fp-trees. We limit ourselves here to depth-first mining algorithms once more.</p><p>Initial algorithms for mining closed itemsets were based on a repository in which closed itemsets were stored. The search is performed by a depth-first frequent itemset miner which is modified as follows:</p><p>• when it is found that all transactions in a projected database contain the same item, this item is immediately added to the itemset as without it the itemset cannot be closed;</p><p>• for each itemset I 1 found in this way, it is checked in the repository whether an itemset I 2 ⊇ I 1 has been found earlier which has the same support; if not, the itemset is stored in the repository and the search continues; otherwise the closed supersets, starting with I 2 , have already been found earlier as children of I 2 so this branch of the search tree is pruned.</p><p>The first modification only checks items that are in the projected database, which are by construction items i &gt; max(I) that are higher in the lexicographic order. The repository is needed to check whether there is no superset with an additional item i &lt; max(I); this is what the second modification does. With an appropriate search order only closed itemsets are stored <ref type="bibr" target="#b42">[43]</ref>.</p><p>This procedure works well if the number of closed sets is small and the database is large. When the number of closed itemsets is large storing itemsets and searching in them can be costly. The LCM algorithm addresses this problem <ref type="bibr" target="#b50">[51]</ref>. In this algorithm also for the items i &lt; max(I) it is checked in the data whether they should be part of the closure, even though the depth-first search procedure does not recurse on such items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Constraint propagation</head><p>The additional constraint <ref type="bibr" target="#b11">(12)</ref> for closed itemset mining is similar to the coverage constraint and hence its propagation is also similar. When all remaining transactions (i.e. those for which 1 ∈ D(T t )) contain a certain item, the propagator will:</p><p>• change the domain of the item i to Hence, in this case we do not have failure-free search; if the closure constraint requires the inclusion of an item in the closure that cannot be included, the search will backtrack. Overall this behavior is very similar to that of the LCM algorithm: essentially we are performing a backtracking search without storing solutions, in which items in the closure are immediately added and some branches are pruned as they fail to satisfy an order constraint. The main difference between LCM and the CP system is as in the previous section: other data structures are used and the search tree is differently organized.</p><formula xml:id="formula_47">D(I i ) = {1} if 1 ∈ D(I i ); • fail if 1 / ∈ D(I i ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discriminative itemset mining</head><p>Itemset mining was initially motivated by the need to find rules, namely association rules. However, in the problem settings discussed till now, no rules were found; instead we only found conditions and no consequents. In this section we study the discovery of rules in a special type of transactional data, namely, data in which every transaction is labeled with a (binary) class label. The task is here to find itemsets that allow one to discriminate the transactions belonging to one class from those belonging to the other class. As it turns out, integrating this constraint efficiently in constraint programming requires the addition of a new primitive to the constraint programming system that we used till now. On the one hand this shows the limits of the declarative approach presented till now; on the other hand, our results demonstrate the feasibility of adding new data mining primitives as global constraints. Furthermore, as we will see, the application of the CP principles in the development of a new constraint propagator turns out to be crucial in improving the performance of existing mining systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Problem definition</head><p>To illustrate the problem of discriminative itemset mining, consider the database given in Fig. <ref type="figure">5</ref>. We are interested in finding itemsets that discriminate transactions in different classes from one another. In the example database, for instance, the itemset {B, C } almost only occurs in the positive examples, and hence can be thought to discriminate positive transactions from negative ones, leading to the rule {B, C } → +.</p><p>Whereas we will refer to this mining problem here as the problem of discriminative itemset mining <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b20">21]</ref>, it is also known under many other names, such as correlated itemset mining <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b38">39]</ref>, interesting itemset mining <ref type="bibr" target="#b4">[5]</ref>, contrast set mining <ref type="bibr" target="#b3">[4]</ref>, emerging itemset mining <ref type="bibr" target="#b19">[20]</ref> and subgroup discovery <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b27">28]</ref>. The problem is also highly related to that of rule learning in machine learning <ref type="bibr" target="#b22">[23]</ref>. The key difference is that rule learning in machine learning usually uses heuristic techniques, while in itemset mining typically exhaustive techniques are used to find the global optimum.</p><p>Even though in the general case a target attribute may have multiple values, we will restrict ourselves to the case where the target attribute has two values: positive and negative. We refer to the part of the database for which the target attribute is positive as D + , and the part for which the target attribute is negative as D -. The set of transactions identifiers appearing in the corresponding parts is indicated by A + and A -. We define the stamp point of an itemset I as σ (I) =</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(|support D + (I)|, |support D -(I)|).</head><p>Hence the stamp point of an itemset is a vector (p, n) where p is the frequency of this itemset in D + and n is the frequency of this itemset in D -. Given these numbers, we can compute a discrimination score f (p, n). For itemsets, the stamp point σ (I) = (p, n) is used to calculate the score f (σ (I)), written f (I) in short. Examples of discrimination measures f include χ 2 , information gain, Gini index, Fisher score and others. For example χ 2 is a wellknown measure of correlation in statistics:</p><formula xml:id="formula_48">χ 2 (p, n) = (p -(p+n) |D| • |D + |) 2 (p+n) |D| • |D + | + (n -(p+n) |D| • |D -|) 2 (p+n) |D| • |D -| + (|D + | -p -|D|-(p+n) |D| • |D + |) 2 |D|-(p+n) |D| • |D + | + (|D -| -n -|D|-(p+n) |D| • |D -|) 2 |D|-(p+n) |D| • |D -| (<label>13</label></formula><formula xml:id="formula_49">)</formula><p>where it is assumed that 0/0 = 0. An illustration of this measure is given in Fig. <ref type="figure" target="#fig_6">6</ref>. The domain of stamp points [0, Essentially, we are interested in finding itemsets which are as close as possible to the maxima in one of the opposite corners; the χ 2 measure scores higher the closer we are to these maxima.</p><formula xml:id="formula_50">|D + |] × [0, |D -|] is often called PN-space.</formula><p>A discrimination measure can be used in a constraint in several ways. We will limit ourselves to the following two cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 5 (Discriminative itemset mining).</head><p>Given a database D, a discrimination measure f and a parameter θ , the discriminative itemset mining problem is that of finding all itemsets in In other words, the set of k patterns that score highest according to the discrimination measure. For k = 1 this corresponds to finding arg max I⊆I f (I).</p><formula xml:id="formula_51">I I ⊆ I, f (I) θ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Constraint programming model</head><p>The discrimination constraint can be expressed in a straightforward way. In addition to the variables T t and I i we introduce two new variables p and n, calculated as follows:</p><formula xml:id="formula_52">p = t∈A + T t , n = t∈A - T t . (<label>14</label></formula><formula xml:id="formula_53">)</formula><p>Remember that A + and A -represent the set of transaction identifiers in the positive database D + and negative database D -respectively. The discrimination constraint is now expressed as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Property 5 (Discrimination constraint). Given a database D, a transaction set T , a discrimination measure f and a threshold θ , an</head><formula xml:id="formula_54">itemset is discriminative iff f (p, n) θ,</formula><p>where p and n are defined as described in Eq. <ref type="bibr" target="#b13">(14)</ref>.</p><p>Such a constraint could be readily expressed in CP systems; essentially, a discrimination measure such as χ 2 is composed of a large number of mathematical operations on the variables p, n, |A -| and |A + |. By carefully decomposing the measure into simple operations using intermediate variables, CP systems may be able to maintain bound consistency. This approach would however be cumbersome (for instance, in the case of the χ 2 function we would need to rewrite the formula to take care of the division by zero) and it is not guaranteed that rewriting its formula leads to an efficient computation strategy for all discrimination measures. Hence, we propose a more robust approach here, which requires the addition of a new constraint in a CP system to enable the maintenance of tighter bounds for discrimination measures with 'nice' properties. Adding specialized global constraints is common practice in CP <ref type="bibr" target="#b44">[45]</ref> and hence well supported in systems such as Gecode. The main observation that we use in this case is that many discrimination measures, such as χ 2 , are zero on the diagonal and convex (ZDC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 7. A scoring function f is zero diagonal convex (ZDC) if it has the following two properties:</head><p>• the function reaches its minimum in all stamp points on the diagonal in PN-space, i.e., ∀0 α 1:</p><formula xml:id="formula_55">f α A + , α A -= 0;</formula><p>• the function is convex, i.e., for every pair of stamp points σ = σ it holds that ∀0 α 1:</p><formula xml:id="formula_56">f ασ + (1 -α)σ α f (σ ) + (1 -α) f σ .</formula><p>Theorem 1. Fisher score, information gain, Gini index, and χ 2 are ZDC measures.</p><p>Definitions, as well as independent, alternative proofs of this theorem, can be found in <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35]</ref>. The plot of χ 2 in Fig. <ref type="figure" target="#fig_6">6</ref> illustrates these two properties: the function is zero on the diagonal and convex. For a ZDC measure the following can be proved.</p><p>Theorem 2 (Maximum for ZDC measures). Let f be a ZDC measure and 0 p 1 p 2 and 0 n 1 n 2 . Then max</p><formula xml:id="formula_57">(σ 1 ,σ 2 )∈[p 1 ,p 2 ]×[n 1 ,n 2 ] f (σ 1 , σ 2 ) = max f (p 1 , n 2 ), f (p 2 , n 1 ) .</formula><p>Proof. The proof is similar to that of <ref type="bibr" target="#b34">[35]</ref>. First, we observe that the function is convex. Hence, we know that the maximum in a space [p </p><formula xml:id="formula_58">( |A + | |A -| n 1 , n 1 ) on the diagonal that f ( |A + | |A -| n 1 , n 1 ) = 0.</formula><p>Due to the convexity we know then that f</p><formula xml:id="formula_59">( |A + | |A -| n 1 , n 1 ) = 0 f (p 1 , n 1 ) f (p 2 , n 1 ). Similarly, we can show that if (p 1 , n 1 ) is above the diagonal that f (p 1 , n 1 ) f (p 1 , n 2 ); that f (p 2 , n 2 ) f (p 2 , n 1 ) if (p 2 , n 2 ) is below the diagonal; and that f (p 2 , n 2 ) f (p 1 , n 2 ) if (p 2 , n 2 ) is above the diagonal. 2</formula><p>The bound states that to find the highest possible score in a rectangle of points, it suffices to check two corners of the rectangle. This is illustrated in Fig. <ref type="figure" target="#fig_8">7</ref>, where a rectangle [p 1 , p 2 ] × [n 1 , n 2 ] is highlighted; the maximum on a ZDC measure is reached in one of the two corners (p 2 , n 1 ) and (p 1 , n 2 ). This property can be used to implement a propagator for a discrimination constraint.</p><p>Similar to the model for standard frequent itemset mining, we can improve the model by posting the discrimination constraint on each item individually, leading to the reified discrimination constraint: ∀i ∈ I :</p><formula xml:id="formula_60">I i = 1 → f t∈A + T t D ti , t∈A - T t D ti θ. (<label>15</label></formula><formula xml:id="formula_61">)</formula><p>Our CP model of discriminative itemset mining is a combination of this constraint and the coverage constraint in Eq. ( <ref type="formula" target="#formula_18">7</ref>).</p><p>The propagator for the above constraint is obtained by applying Theorem 2 (see Algorithm 5).</p><p>To understand this propagator, consider the example in Fig. <ref type="figure" target="#fig_8">7</ref>, where we have marked the curve f (p, n) = θ for a particular value of θ . Due to the convexity of the function f , stamp points for which f (p, n) θ can be found in the Algorithm 5 Conceptual propagator for</p><formula xml:id="formula_62">I i = 1 → f ( t∈A + T t D ti , t∈A -T t D ti ) θ 1: if D(I i ) = {1} then 2: post constraint f ( t∈A + T t D ti , t∈A -T t D ti ) θ 3: else 4: upper = max{ f ( t∈A + T max t D ti , t∈A -T min t D ti ), 5: f ( t∈A + T min t D ti , t∈A -T max t D ti )} 6:</formula><p>if upper &lt; θ then 7:  ; this can easily be checked by the propagator by determining that f (p 1 , n 2 ) &lt; θ and f (p 2 , n 1 ) &lt; θ.</p><formula xml:id="formula_63">D(I i ) = D(I i ) \ {1}</formula><formula xml:id="formula_64">(p, n) ∈ [p 1 , p 2 ] × [n 1 , n 2 ], where p 1 = t∈A + T min t D ti , p 2 = t∈A + T max t D ti , n 1 = t∈A -T min t D ti and n 2 = t∈A -T max t D ti , satisfies f (p, n) θ in the figure</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Comparison</head><p>Traditional discriminative itemset mining algorithms essentially proceed by updating frequent itemset mining algorithms such that a different anti-monotonic constraint is used during the search. This constraint is based on the derivation of an upper-bound on the discrimination measure <ref type="bibr" target="#b34">[35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 8 (Upper-bound). Given a function f (p, n), function g(p, n) is an upper-bound for f iff ∀p, n: f (p, n) g(p, n).</head><p>In the case of itemsets it is said that the upper-bound is anti-monotonic, if the constraint g(I) θ is anti-monotonic.</p><p>The following upper-bound was presented by Morishita and Sese for ZDC measures <ref type="bibr" target="#b34">[35]</ref>.</p><p>Theorem 3 (Upper-bound for ZDC measures). Let f (p, n) be a ZDC measure, then g(p, n) = max( f (p, 0), f (0, n)) is an upper-bound for f (p, n) and g(I) θ is an anti-monotonic constraint.</p><p>Proof. The fact that this function is an upper-bound follows from Theorem 2, where we take p 1 = n 1 = 0, p 2 = σ 1 (I) and n 2 = σ 2 (I). The anti-monotonicity follows from the fact that f (p, 0) and f (0, n) are monotonically increasing functions in p and n, respectively. p and n represent the support of the itemset in the positive and negative databases D + and D - respectively, which are anti-monotonic as well. 2</p><p>The bound is illustrated in Fig. <ref type="figure">8</ref>. Given the threshold θ in this figure, the itemset I with stamp point (p, n) = σ (I) will not be pruned, as at least one of f (p, 0) or f (0, n) has a discrimination score that exceeds the threshold θ . This bound is used in an updated frequent itemset miner, of which the main differences are:</p><p>• we need to be able to compute the support in the two classes of data separately. This can be achieved both using tid-list and fp-trees;</p><p>• to prune items from the projected database, instead of a support constraint, a constraint on the upper-bound of the discrimination score is used: a subtree of the search tree is pruned iff g(I) &lt; θ, where θ is the threshold on the score (or the score of the kth best itemset found so far in top-k mining).</p><p>In case we do not wish to find all discriminative patterns with a score above θ , but instead the top-k patterns with the highest discriminative score, a branch-and-bound search strategy can be employed. In top -1 branch-and-bound search, the bound on the discrimination score f (p, n) is increased as patterns with a higher score are found. For topk branch-andbound search, the bound is set to that of the kth pattern. In step 1 we have itemset {2}; we find out that itemset {2, 6} cannot reach the desired score and hence item 6 is excluded from consideration. As a result, some transactions may become unavoidable. Consequently, itemset {2, 4} may now be known not to reach the threshold and item {4} is excluded from consideration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1.">Constraint propagation</head><p>Intuitively, when we compare Figs. <ref type="figure" target="#fig_8">7</ref> and<ref type="figure">8</ref>, we can see that the search would continue for the itemset in Fig. <ref type="figure">8</ref> because the maximum reachable score is measured in the points (p 2 , 0) and (0, n 2 ), for which the score is above the threshold θ . On the other hand the search would stop in Fig. <ref type="figure" target="#fig_8">7</ref> because the maximum the itemset can reach is measured in (p 2 , n ) 1 , 2 ), for which the score is below the threshold. The difference is that in Fig. <ref type="figure" target="#fig_8">7 p</ref>  Using the reified discrimination constraint leads to fine-grained interaction between search and propagation similar to the reified frequency constraint in Section 3.3; Excluding an item from the itemset by reducing its domain to D(I i ) = {0}, can lead to the following propagation loop:</p><p>1. Some transactions become unavoidable and are changed to D(T t ) = {1}.</p><p>2. D(T t ) having changed, the reified discrimination constraints are checked; possibly a constraint detects that some item can no longer be included in the itemset and the item's domain is reduced to D(I i ) = {0}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Return to step 1.</head><p>This propagation loop is illustrated in Fig. <ref type="figure" target="#fig_9">9</ref>. It is absent in traditional discriminative itemset miners, which use the more simple bound g(I). We will experimentally verify whether it is beneficial to perform the additional proposed propagation in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Itemset mining with costs</head><p>In cases where the mining process still yields a very large set of patterns, additional constraints can reduce the number of patterns. Several papers have studied alternative constraints to the support constraint, which has lead to the concepts of monotonic, anti-monotonic and convertible anti-monotonic constraints. The prime example on which these concepts have been illustrated both in theory and in practice are constraints in which a cost, or weight, is associated with every item. In this section, we review these constraints and then show how they can be handled in the constraint programming approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Problem definition</head><p>Essentially, every item i now has an associated weight c(i), often called the cost<ref type="foot" target="#foot_4">3</ref> of the item. Let us now define the total cost of an itemset as</p><formula xml:id="formula_65">c(I) = i∈I c(i).</formula><p>Then we may be interested in finding itemsets for which we have a high total cost <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b8">9]</ref>. Definition 9 (Frequent itemset mining with minimum total cost). Given a database D and two parameters θ and γ , the frequent itemset mining problem under a minimum cost constraint is the problem of finding the itemsets in</p><formula xml:id="formula_66">I I ⊆ I, support D (I) θ, c(I) γ .</formula><p>Similarly, we can mine under maximum cost constraints and average cost constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 10 (Frequent itemset mining with maximum total cost).</head><p>Given a database D and two parameters θ and γ , the frequent itemset mining problem under a maximum cost constraint is the problem of finding the itemsets in</p><formula xml:id="formula_67">I I ⊆ I, support D (I) θ, c(I) γ .</formula><p>Definition 11 (Frequent itemset mining with minimum average cost). Given a database D and two parameters θ and γ , the frequent itemset mining problem under a minimum average cost constraint is the problem of finding the itemsets in</p><formula xml:id="formula_68">I I ⊆ I, support D (I) θ, c(I)/|I| γ .</formula><p>Please note that a special case of cost-based itemset mining is achieved when c(i) = 1 for all i. These constraints are usually referred to as size constraints. A minimum size constraint is similar to a minimum support constraint: one is defined on the items, the other on the transactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Constraint programming model</head><p>In analogy to the support constraint, cost constraints can be expressed in two ways, non-reified and reified, and can be added to the usual support and coverage constraints in the CP model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Property 6 (Non-reified minimum and maximum total cost constraint). Given a database D, an itemset I and a threshold</head><formula xml:id="formula_69">γ , then c(I) ≶ γ ⇐⇒ i∈I I i c(i) ≶ γ , (<label>16</label></formula><formula xml:id="formula_70">)</formula><p>where ≶∈ {&lt;, , , &gt;}, I i ∈ {0, 1} and I i = 1 iff i ∈ I. Property 7 (Reified minimum and maximum total cost constraint). Given a database D, an itemset I and a threshold γ , if</p><formula xml:id="formula_71">support D (I) 1 then c(I) ≶ γ ⇐⇒ T t = 1 → i∈I I i D ti c(i) ≶ γ , (<label>17</label></formula><formula xml:id="formula_72">)</formula><p>where ≶∈ {&lt;, , , &gt;},</p><formula xml:id="formula_73">I i ∈ {0, 1}, I i = 1 iff i ∈ I and T t = 1 iff t ∈ T .</formula><p>Proof. This follows from the assumption that also the coverage constraint should hold; hence if T t = 1 we know that for all i with I i = 1 we must have D ti = 1. Because support D (I) 1, we know that there is at least one transaction for which T t = 1. 2</p><p>Average cost constraints can be expressed by allowing for negative coefficients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Property 8 (Non-reified minimum and maximum average cost constraint). Given a database D, an itemset I and a transaction set T , then c(I)/|I|</head><formula xml:id="formula_74">≶ γ ⇐⇒ i∈I I i c(i) -γ ≶ 0 , (<label>18</label></formula><formula xml:id="formula_75">)</formula><p>where ≶∈ {&lt;, , =, =, , &gt;}, I i ∈ {0, <ref type="figure">1}</ref> and<ref type="figure">I</ref> </p><formula xml:id="formula_76">i = 1 iff i ∈ I.</formula><p>Proof. This follows from the following observation:</p><formula xml:id="formula_77">c(I)/|I| ≶ γ ⇔ c(I) ≶ γ |I| ⇔ c(I) -γ |I| ≶ 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>The reified average cost constraints are obtained in a similar way as the reified total cost constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Comparison</head><p>All specialized algorithms for mining under cost constraints exploit that these constraints have properties similar to anti-monotonicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 12 (Monotonic constraints).</head><p>Assume given two itemsets I 1 and I 2 , and a predicate p(I, D) expressing a constraint. Then the constraint is monotonic iff ∀I 1 ⊆ I 2 : p(I 1 , D) ⇒ p(I 2 , D).</p><p>Examples are maximum support and minimum cost constraints. Different approaches have been proposed for dealing with monotonic constraints in the literature. We will discuss these approaches separately, at the same time pointing out the relation to our models in CP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1.">Minimum total cost constraint: simple approach</head><p>The simplest depth-first algorithms developed in the data mining community for dealing with monotonic constraints are based on the observation that supersets of itemsets satisfying the constraint also satisfy the constraint. Hence, during the depth-first search procedure, we do not need to check the monotonic constraint for children of itemsets satisfying the monotonic constraint <ref type="bibr" target="#b40">[41]</ref>. To emulate this behavior in CP, we would only check the satisfiability of the monotone constraint, and refrain from possibly propagating over variables. This would result in branches of the search tree being cut when they can no longer satisfy the constraint; the constraint would be disabled once it can no longer be violated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2.">Minimum total cost constraint: DualMiner/non-reified</head><p>More advanced is the specialized DualMiner algorithm <ref type="bibr" target="#b10">[11]</ref>. DualMiner associates a triplet (I in , I check , I out ) with every node in the depth-first search tree of an itemset miner. Element I in represents the itemset to which the node in the search tree corresponds; I check and I out provide additional information about the search node. Items in I check are currently not included in the itemset, but may be added in itemsets deeper down the search tree; these items are part of the projected database. For items in I out it is clear that they can no longer be added to any itemset deeper down the search tree. Adding an item of I check to I in leads to a branch in the search tree. An iterative procedure is applied to determine a final triplet (I in , I check , I out ) for the new search node, and to determine whether the recursion should continue:</p><p>• it is checked whether the set I in satisfies all anti-monotonic constraints. If not, stop;</p><p>• it is checked which individual items in I check can be added to I in and satisfy the anti-monotonic constraints. Only those that do satisfy the constraints are kept in I check , others are moved to I out ;</p><p>• it is checked whether the set I in ∪ I check satisfies the monotonic constraints. If not, stop. Every item i ∈ I check for which itemset (I in ∪ I check )\{i} does not satisfy the monotonic constraints, is added to I in . (For instance, if the total cost is too low without a certain item, we have to include this item in the itemset.) Finally, the procedure is iterated again to determine whether I in still satisfies the anti-monotonic constraints.</p><p>If the loop reaches a fixed point and items are still left in I check the search continues, unless it also appears that I in ∪ I check satisfies the anti-monotonic constraints and I in satisfies the monotonic constraints; in this case the sets I check ⊆ I ⊆ I in ∪ I check could immediately be listed.</p><p>A similar search procedure is obtained when the cost constraints are formulated in a non-reified way in the CP system. As pointed out earlier, a non-reified minimum or maximum cost constraint takes the following form:</p><formula xml:id="formula_78">i I i c(I) ≶ γ .</formula><p>Propagation for this constraint is of the following kind:</p><p>• if according to current domains the constraint can only be satisfied when the CP system includes (minimum cost constraint) or excludes (maximum cost constraint) an item, then the system does so; this corresponds to moving an item to the I in or I out set in DualMiner;</p><p>• if according to current domains the constraint can no longer be satisfied, backtrack;</p><p>• if according to current domains the constraint will always be satisfied the constraint is removed from the constraint store.</p><p>Hence, the overall search strategy for the non-reified constraint is similar to that of DualMiner. There are also some differences. DualMiner does not aim at finding the transaction set for every itemset. If it finds that I in satisfies the monotonic constraint and I in ∪ I check satisfies the anti-monotonic constraint, it does not continue searching, and outputs the corresponding range of itemsets explicitly or implicitly. The CP system will continue enumerating all itemsets in the range in order to find the corresponding transaction sets explicitly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.3.">Minimum total cost constraint: FP-Bonsai/reified</head><p>In the FP-Bonsai algorithm <ref type="bibr" target="#b7">[8]</ref>, the idea of iteration till a fixed point is reached was extended to monotonic constraints. The main observation on which this algorithm is based is that a transaction which does not satisfy the minimum cost constraints, will never contain an itemset that satisfies the minimum cost constraint. Hence, we can remove such transactions from consideration. This may reduce the support of items in the projected database and result in the removal of more items from the database. The reduction in size of some transactions may trigger a new step of propagation.</p><p>If we consider the reified minimum cost constraint,</p><formula xml:id="formula_79">T t = 1 → i I i c(I)D ti γ ,</formula><p>we can observe a similar propagation. Propagation essentially removes a transaction from consideration when the constraint can no longer be satisfied on the transaction. The removal of this transaction may affect the support of some items, requiring the propagators for the support constraints to be re-evaluated.</p><p>Note that the reified constraint is less useful for a maximum total cost constraint, c(I) γ . Essentially, for every transaction only items already included in the itemset can be considered. If the sum of these items is to large, the transaction is removed from consideration. This would happen for all transactions separately, leading to a failed branch. Overall, the propagation is expensive to evaluate (as it needs to be done for each transaction) and not as effective as the non-reified propagator which can also prune items from consideration instead of only failing.</p><p>Thus the reified and non-reified form are complementary to each other. We can obtain both types of propagation by posting constraints of both types in a CP system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.4.">Minimum and maximum average cost constraints.</head><p>Average cost constraints are neither monotonic nor anti-monotonic. Still, they have a property that is related to that of monotonic and anti-monotonic constraints.</p><p>Definition 13 (Convertible anti-monotonic constraints). Assume given two itemsets I 1 and I 2 , a predicate p(I, D) expressing a constraint, and an order &lt; between items. Then the constraint is convertible anti-monotonic for this order iff ∀I 1 ⊆ I 2 , min(I 2 \ I 1 ) max(I 1 ) : p(I 2 , D) ⇒ p(I 1 , D).</p><p>For example, if the items are ordered according to increasing cost c(I), when adding items that are more expensive than the current items, the average cost can only increase. For a decreasing order in item cost, the minimum average cost constraint is convertible anti-monotonic. Different orderings will not result in anti-monotonic behavior, i.e. if after adding expensive items an item with a low cost would be added, the average cost would go down. Note that a conjunction of maximum and minimum cost constraints is hence not convertible anti-monotonic, as we would need opposing orders for each of the two constraints.</p><p>Essentially our formalization in CP of average cost constraints is very similar to that of total cost constraints, the main difference being that negative costs are allowed. Consequently, depending on the constraint (minimum or maximum) and the weight (positive or negative) either the maximum value in the domain or the minimum value in the domain is used in the propagator. In the non-reified form, we obtain propagation towards the items; in the reified form towards the transactions.</p><p>This search strategy is fundamentally different from the search strategy used in specialized mining systems, in which the property is used that one average cost constraint is convertible anti-monotonic. Whereas in specialized systems the combination of multiple convertible constraints poses problems, in the CP-based approach this combination is straightforward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.5.">Conclusions</head><p>Interestingly, when comparing models in CP and algorithms proposed in the data mining community, we can see that there are many similarities between these approaches. The different approaches can be distinguished based on whether they represent a reified or an non-reified constraint. The main advantage of the constraint programming approach is that these approaches can also easily be combined. This advantage is also evident when combining convertible constraints; specialized algorithms can only optimize on one such constraint at the same time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Experiments</head><p>In previous sections we concentrated on the conceptual differences between traditional algorithms for itemset mining and constraint programming; we showed that itemset mining can be modeled in constraint programming. In the present section, we first consider several choices that have to be made when implementing itemset mining in a constraint programming framework and evaluate their influence on the performance of the mining process. More specifically, we answer the following two questions about such choices: QA What is the difference in performance between using reified versus non-reified constraints of itemset mining? QB What is the effect of the different variable orderings on the performance of itemset mining?</p><p>Further (more technical and system dependent) choices made in our implementation are explained in Appendix A for completeness and reproducibility. All used implementations are also available on our website: http://dtai.cs.kuleuven.be/CP4IM/. We use the best approach resulting from the above experiments to experimentally compare our constraint programming framework CP4IM to state-of-the-art itemset mining systems. More specifically, our comparative experiments focus on answering the following questions:</p><p>Q1 What is the difference in performance of CP4IM for frequent itemset mining and traditional algorithms? Q2 What is the difference in performance of CP4IM for closed itemset mining and traditional algorithms? Q3 Is the additional propagation in CP4IM for discriminative itemset mining beneficial? If so, how much? Q4 Is the alternative approach for dealing with convertible constraints in CP4IM beneficial? If so, how much?</p><p>We ran experiments on PCs with Intel Core 2 Duo E6600 processors and 4 GB of RAM, running Ubuntu Linux. The experiments are conducted using the Gecode constraint programming system <ref type="bibr" target="#b24">[25]</ref>. Gecode <ref type="foot" target="#foot_5">4</ref> is an open source constraint programming system which is representative for the current state-of-the-art of efficient constraint programming.</p><p>The starting point for our experiments was Gecode version 2.2.0. In the course of our experiments we tried several formulations and implemented alternative propagators, explained in detail in Appendix A, some of which are now included in Gecode by default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Data sets</head><p>In our experiments we used data from the UCI Machine Learning repository. <ref type="foot" target="#foot_6">5</ref> To deal with missing values we preprocessed each dataset in the same way as <ref type="bibr" target="#b15">[16]</ref>: we first eliminated all attributes having more than 10% of missing values and then removed all examples (transactions) for which the remaining attributes still had missing values. Numerical attributes were binarized by using unsupervised discretization with 4 equal-frequency bins; each item for an attribute corresponds to a threshold between two bins. These preprocessed datasets can be downloaded from our website. <ref type="foot" target="#foot_7">6</ref> The datasets and their basic properties can be found in Table <ref type="table" target="#tab_5">1</ref>. The density is the relative amount of ones in the matrix. In many itemset problems, a higher density indicates that the dataset is more difficult to mine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Alternative itemset miners</head><p>We used the following state-of-the-art specialized algorithms, for which implementations are freely available, as the basis for our comparative evaluation:</p><p>LCM LCM <ref type="bibr" target="#b50">[51]</ref> is a specialized frequent closed itemset mining algorithm based on tid-lists; Eclat Eclat <ref type="bibr" target="#b55">[56]</ref> is a specialized depth-first frequent itemset mining based on tid-lists; Patternist Patternist <ref type="bibr" target="#b8">[9]</ref> is a specialized breadth-first algorithm for mining under monotonic and anti-monotonic constraints; DDPMine DDPMine <ref type="bibr" target="#b12">[13]</ref> is a specialized depth-first closed discriminative itemset mining algorithm based on fp-trees and a repository of closed itemsets; it uses a less tight bound than the bound summarized in Section 5 <ref type="bibr" target="#b37">[38]</ref>.</p><p>Note that in our experiments we are not using all algorithms discussed in previous sections. The reason is that we preferred to use algorithms for which comparable implementations by the original authors were freely available (i.e. executable on the same Linux machine).</p><p>Table <ref type="table">2</ref> provides an overview of the different tasks that these data mining systems support. The LCM and Eclat algorithms have been upgraded by their original authors to support respectively frequent itemset mining and closed itemset mining too. Patternist is a constraint-based mining algorithm which has been carefully designed to make maximal use of monotone In Fig. <ref type="figure">11</ref> the runtime of all mining algorithms is shown for the problem of closed itemset mining. Again, run time is correlated with the number of patterns found. The difference between CP4IM and the other miners is smaller in this experiment. We argued in the previous section that the CP system behaves similar to the LCM system. Indeed, our experiments on both the mushroom and letter data set show that this is the case; in one case even outperforming the Eclat system, which as not originally developed for closed itemset mining.</p><p>It should be noted that on sparse data, such as mushroom, the difference in performance between Gecode and specialized systems is larger than on dense data, such as the letter data. This can be explained by the inefficient representation of sparse data in Gecode; on dense data, as compared to Eclat, this inefficient representation is compensated by more effective propagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.7.">Q3: discriminative closed itemset mining</head><p>In this experiment we compare several approaches for finding the most discriminative itemset, given labeled data. Results are shown in Table <ref type="table" target="#tab_6">5</ref>. As in this setting we do not have to determine a threshold parameter, we perform experiments on a larger number of datasets. The missing values of the datasets were preprocessed in the same way as in previous experiments. However, the numerical attributes were binarized using unsupervised discretization with 7 binary split points (8 equal-frequency bins). This enforces a language bias on the patterns that is closer to that of rule learning and subgroup discovery systems <ref type="bibr" target="#b27">[28]</ref>. In case of a non-binary class label, the largest class was labeled positive and the others negative. The properties of the datasets are summarized in Table <ref type="table" target="#tab_6">5</ref>; note the higher density of the datasets than in the previous experiments, resulting from the discretization procedure.</p><p>We report two types of experiments with CP4IM: using the propagator introduced in Section 5.2 (CP4IM(4)) and using a propagator that mimics the propagation occurring in the specialized discriminative itemset miner introduced in <ref type="bibr" target="#b34">[35]</ref> (CP4IM(2)). Furthermore, we also apply the LCM algorithm; in <ref type="bibr" target="#b37">[38]</ref> it was shown that for well-chosen support thresholds, the resulting set of frequent itemsets is guaranteed to contain all itemsets exceeding a correlation threshold. We use the correlation threshold of the best pattern (found using our algorithm) to compute a support threshold according to this method and run LCM with this support threshold. Note that by providing LCM knowledge about the best pattern to be found, the comparison is unfair to the advantage of LCM.</p><p>For experiments marked by "&gt;" in our table no solution was found within 900 seconds. In experiments marked by "-" the repository of closed itemsets runs out of memory. The experiment shows that CP4IM(4) consistently outperforms existing data mining systems, where in most cases this increased performance can be attributed to the improved propagation that was revealed in CP4IM(4).</p><p>It can be noted that on one dataset, the mushroom dataset, the new propagator takes slightly more time. Our hypothesis is that this is related to the low density of the data, for which 4-bound pruning can be less effective when there is no structure in the data which would lead to unavoidable transactions. To test this hypothesis, we performed additional experiments in which we gradually sparsified two dense datasets, given in Fig. <ref type="figure" target="#fig_0">12</ref>. The sparsification was performed by randomly removing items uniformly from the transaction database, until a predefined sparsity threshold was reached. Averaging runtimes over 10 different samples for each setting, we ran our CP4IM system using three different propagators: CP4IM(4) and CP4IM(2), as explained above, and CP4IM(1) which uses the simple frequency based propagator used in <ref type="bibr" target="#b13">[14]</ref>. The experiments show that when the density is decreased, and hence the sampling removes structure from the data, the advantage of the more advanced pruning method over the more simple ones disappears. However, within the CP framework the 4-bound method is often better and at worse equivalent to the 2-and 1-bound pruning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.8.">Q4: cost-based itemset mining</head><p>In this experiment we determine how CP4IM compares with other systems when additional cost constraints are employed. Results for two settings are given in Fig. <ref type="figure" target="#fig_3">13</ref>, where our system is indicated by FIM_CP. In the first experiment we employed a (monotonic) minimum size constraint in addition to a minimum frequency constraint; in the second a (convertible) maximum average cost constraint. The results are positive: even though for small minimum size constraints the brute force mining algorithms, such as LCM, outperform CP4IM, CP4IM does search very effectively when this constraint selects a small number of very large itemsets (30 items or more); in extreme cases CP4IM finishes within seconds while other algorithms do not finish within our cut-off time of 30 minutes. Patternist, being a breadth-first algorithm, was unable to finish some of these experiments due to memory problems. This indicates that CP4IM is a competitive system when the constraints require the discovery of a small number of very large itemsets. The results for convertible constraints are particularly promising, as we did not optimize the item order in any of our experiments, as is usually done when dealing with convertible constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusions</head><p>We started this paper by raising the question as to whether constraint programming can be used for solving itemset mining problems in a declarative way. Our results show that the answer to this question is indeed positive and that the use of constraint programming offers several advantages as well as new insights. Perhaps the more important advantage is that constraint programming systems are general purpose systems supporting many different types of constraints. In this regard, we showed that it is possible to incorporate many well-known constraints, such as cost constraints, closedness or discriminative measures as defined above, as well as their combinations in the constraint programming system. The advantage of the resulting declarative approach to data mining is that it is easy to extend or change in order to accommodate new constraints, and that all constraints can automatically be combined with one another. Furthermore, a detailed analysis of the solution strategy of constraint programming systems showed that there are many similarities between these systems and specialized itemset mining systems. Therefore, the constraint programming system arguably generalizes these systems, not only from a theoretical perspective but also from a practical one. This was confirmed in our experiments: for problems such as frequent and closed itemset mining, for which fast implementation contests were organized, these specialized systems usually outperform CP4IM; however the runtime behavior of our constraint programming approach is similar to that of the specialized systems. The potential of the CP approach from a performance perspective was demonstrated on the problem of discriminative itemset mining. We showed that by rigorously using the principles of constraint programming, more effective propagation is obtained than in alternative state-of-the-art data mining algorithms. This confirms that it is also useful in an itemset mining context to take propagation as a guiding principle. In this regard, it might be interesting to investigate the use of alternative search strategies that have been developed in the constraint programming community <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b43">44]</ref>.</p><p>Continuing this research, we are currently studying the application of our approach to problems arising in bioinformatics. For instance, itemset mining has commonly been applied to the analysis of microarray data; our hope is that constraint programming may offer a more general and more flexible approach to analyze such data. Whereas the above work is still restricted to the discovery of patterns in binary data, the use of constraint programming in other pattern mining related problems is also a promising direction of future research. A problem closely related to pattern mining is that of pattern set mining <ref type="bibr" target="#b18">[19]</ref>, where one does not only impose constraints on individual patterns, but also on the overall set of patterns constituting a solution <ref type="bibr" target="#b28">[29]</ref>. Constraints that can be imposed include, for instance, the requirement that patterns do not overlap too much, or that they cover the complete set of transactions together. Another related problem is that of finding patterns in continuous data. This requirement is in particular relevant to deal with problems in bioinformatics. Likewise, there are many approaches to mining structured data, such as sequences, trees and graphs. It is an interesting open question as to whether it is possible to represent such problems using constraint programming too. One of the challenges here is that such structured data can no longer be represented using a fixed number of features or variables.</p><p>In addition to pattern mining, other areas of machine learning and data mining may also profit from a closer study of constraint programming techniques. One such area is statistical machine learning, where problems are typically formulated using mathematical programming. Recently some results in the use of other types of solvers have already been obtained for certain probabilistic models <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b14">15]</ref>. In these approaches, however, Integer Linear Programming (ILP) or satisfiability (SAT) solvers were used. CP solvers address a more general class of problems than ILP and SAT solvers, but this generality sometimes comes at a computational cost. Current developments in CP that aim at combining ILP and SAT with CP may also help in addressing these machine learning problems.</p><p>Other topics of interest are constraint-based clustering and constraint-based classifier induction. In constraint-based clustering the challenge is to cluster examples when additional knowledge is available about these examples, for instance, prohibiting certain examples from being clustered together (so-called cannot-link constraints). Similarly, in constraint-based classifier induction, one may wish to find a decision tree that satisfies size and cost-constraints. A first study on the application of CP on this problem was recently performed by Bessiere, Hebrard, and O'Sullivan <ref type="bibr" target="#b6">[7]</ref>. In data mining, the relationship between itemset mining and constraint-based decision tree learning was studied <ref type="bibr" target="#b35">[36]</ref>. It is an open question as to whether this relation can also be exploited in a constraint programming setting.</p><p>Whereas the previous cases study how data mining could profit from constraint programming, the opposite direction is also a topic of interest: how can constraint programming systems be extended using techniques from data mining? For example, in constraint programming systems the data is typically spread over the constraints, and possibly multiple times in different ways. In contrast, in data mining the data is typically centrally accessed, allowing the use of different matrix representations.</p><p>To summarize, we believe that the further integration of machine learning, data mining and constraint programming may be beneficial for all these areas. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Booleans vs integers</head><p>Finite domain integer solvers can choose to represent a boolean as an integer with a domain of {0, 1}, or to implement a specific boolean variable. An essential constraint in our models is the reified summation constraint. Such a sum can be expressed both on boolean and integer variables, but the reification variable always has a boolean domain. Using boolean variables should be equally or more efficient than integer variables, especially since in our model, the integer variables need to be 'channeled' to boolean variables for use in the reification part. However, in our experiments (Table <ref type="table">A</ref>.6) the model using booleans was slower than the one using integers. The reason is that a given reified summation constraint on booleans B i and boolean variable C , i B i v ↔ C was decomposed into two constraints: S = i B i and S v ↔ C , where S is an additional integer variable; separate propagators were used for both constraints. For integers on the other hand, a single propagator was available. Our experiments show that decomposing a reified sum constraints over booleans into a sum of booleans and reifying the integer variable is not beneficial.</p><p>We implemented a dedicated propagator for a reified sum of boolean variables constraint, which includes an optimization inspired by SAT solvers <ref type="bibr" target="#b25">[26]</ref>. A propagator is said to watch the variables on which it depends. A propagator is activated when the domain of one of its watched variables changes. To improve efficiency, the number of watched variables should not be larger than necessary. Assume we have a sum n i=1 B i v ↔ C , where all B i and C are boolean variables, then it is sufficient to watch max(v, nv + 1) (arbitrary) variables B i not fixed yet: the propagator can not succeed (v variables true) or fail (nv + 1 variables false) without assigning at least one of the watched variables. In Table A.7 we compare the formulation of the basic frequent itemset mining problem using integers and channeling, to using boolean variables and the new dedicated propagator. The peak amount of memory needed when using only booleans is naturally lower. The amount of propagations is also decreased significantly, leading to lower runtimes for all but one dataset. Hence it is overall recommended to use boolean variables with dedicated propagators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Coverage constraint: propagators versus advisers</head><p>When a variable's domain changes, the propagators that watch this variable can be called with different amounts of information. To adopt the terminology of the Gecode system, we differentiate between classic 'propagators' and 'advisers':</p><p>• propagators: when the domain of at least one variable changes, the entire propagator is activated and re-evaluated;</p><p>• advisers: when the domain of a variable changes, an adviser is activated and informed of the new domain of this variable. When the adviser detects that propagation can happen, it will activate the propagator.</p><p>Both techniques have their advantages and disadvantages: classic propagators are conceptually simpler but need to iterate over all its variables when activated; advisers are more fine-grained but require more bookkeeping. We implemented the coverage constraint using both techniques, and compare them in Table A.8. Using advisers requires more memory but reduces the overall amount of propagations, the runtimes also decrease.  As we pointed out in Property 1, Eqs. ( <ref type="formula" target="#formula_18">7</ref>) and ( <ref type="formula" target="#formula_20">8</ref>), on page 1957, the coverage constraint can be expressed in two equivalent ways: using reified sums or using reified clauses. Both options are evaluated in Table A.8. Overall, we find that the formulation using clauses performs best.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Value ordering</head><p>For boolean decision variables, two value ordering heuristics are meaningful: selecting the minimum value (0) or selecting the maximum value (1) first. A comparison can be found in Table <ref type="table">A</ref>.9, where the maximum degree variable ordering is used.</p><p>The results are surprising: using the maximum value heuristic leads to more propagation and longer run times. This is counter-intuitive: the search tree is equally large in both cases and because the complete tree is searched, the total amount of propagation should be identical too. The explanation can be found in how the Gecode system stores intermediate states during the search. Gecode uses a technique called copying and recomputation <ref type="bibr" target="#b45">[46]</ref>. In this technique, some nodes, but not necessarily all nodes, in the depth-first search tree are copied and stored. To backtrack, one retrieves the latest copied node and recomputes the propagations using the assignments leading to the desired node. This can save memory consumption and runtime for large problems <ref type="bibr" target="#b45">[46]</ref>. The amount of copying/recomputation is set by the copy distance parameter. In Gecode, the default is 8, meaning that a new copy is made every 8 nodes.</p><p>When we consider a search tree using the minimum value first heuristic for our models (see <ref type="bibr">Fig. A.14)</ref>, we see that all variables are set to zero first, creating one long branch. The copied nodes in this branch are reused throughout the rest of the search. When using the maximum value heuristic, more propagation is possible and shorter branches are explored first. Consequently, less nodes are copied, and a lot of recomputation needs to be done in each of the short branches. In our experiments this results in increased overhead.</p><p>Table <ref type="table">A</ref>.10 compares two values of the copy distance parameter, and how this influences the value ordering heuristic. With a distance of 0, every node in the search tree is copied. This results in a smaller amount of propagation compared to a distance of 8, independent of the value ordering heuristic used. Interestingly, the amount of runtime is also decreased compared to a larger copy distance. Using the maximum value first heuristic is about as fast as the minimum value heuristic,</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. A visualization of the search space for the database of Fig. 1; frequent itemsets for θ = 2 are highlighted. Frequent closed itemsets are highlighted black; non-closed frequent itemsets are grey.</figDesc><graphic coords="7,38.21,54.49,463.68,229.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 3</head><label>3</label><figDesc>Fim_cp's frequent itemset mining model, in Essence' 1: given NrT, NrI : int 2: given TDB : matrix indexed by [int(1..NrT),int(1..NrI)] of int(0..1) 3: given Freq : int 4: find Items : matrix indexed by [int(1..NrI)] of bool 5: find Trans : matrix indexed by [int(1..NrT)] of bool 6: such that 7: $ Coverage Constraint (Eq. (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>&lt;=&gt; ((sum i: int(1..NrI). (1-TDB[t,i]) * Items[i]) &lt;= 0), 10: $ Frequency Constraint (Eq. (9)) 11: (sum t: int(1..NrT). Trans[t]) &gt;= Freq.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Search-propagation interaction of the non-reified frequent itemset model (left) and the reified frequent itemset model (right). A propagation step is colored in blue, a search step in green. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 4</head><label>4</label><figDesc>Depth-First-Search (Itemset I , Database D) 1: F := {I} 2: determine a total order R on the items in D 3: for all items i occurring in D do 4: create from D projected database D i , containing: 5:-only transactions in D that contain i 6:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.4. The search tree for depth-first frequent itemset miners, for the same example as in Fig.3, where the items are ordered by the natural order on integers. Each itemset has a corresponding projected database containing only frequent items higher than the items chosen so far. For instance,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Left: Plot of the χ 2 measure and a threshold at χ 2 = 20. Right: isometric of the threshold in PN space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Definition 6 (</head><label>6</label><figDesc>Top-k discriminative itemset mining). Given a database D, a discrimination measure f and a value k, the top-k discriminative itemset mining problem is the problem of finding the first k elements of the list [I 1 , I 2 , . . . , I n ] consisting of all itemsets I ⊆ I downward sorted by their f (I) values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Illustration of a rectangle of stamp points in PN space; within the rectangle [p 1 , p 2 ] × [n 1 , n 2 ], a ZDC measure reaches its highest value in one of the two highlighted stamp points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. Illustration of the possible propagation for discriminative itemset mining; this propagation loop was not yet studied in specialized itemset mining algorithms. In step 1 we have itemset {2}; we find out that itemset {2, 6} cannot reach the desired score and hence item 6 is excluded from consideration. As a result, some transactions may become unavoidable. Consequently, itemset {2, 4} may now be known not to reach the threshold and item {4} is</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 . 13 .</head><label>1213</label><figDesc>Fig. 12. Correlated itemset mining when sparsifying the data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. A. 14 .</head><label>14</label><figDesc>Fig. A.14. Search tree for the first 35 variables of the mushroom dataset. Every blue circle is a branchpoint over an item, every green diamond is a solution. A branch to the left assigned 0 to the item of that branchpoint, a branch to the right assigned 1. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)</figDesc><graphic coords="30,42.51,273.97,463.68,72.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Stamp points (p 2 , 0) and (0, n 2 ) are upper bounds for the itemset I with (p 2 , n 2 ) = σ (I). lower-right and upper-left corner. None of the stamp points in</figDesc><table><row><cell>8:</cell><cell>end if</cell></row><row><cell cols="2">9: end if</cell></row><row><cell></cell><cell>Fig. 8.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc><ref type="bibr" target="#b0">1</ref> and n 1 are taken into account, which is the number of unavoidable transactions. As outlined on page 1963, unavoidable transactions are transactions for which min D(T t ) = 1. So instead of having to use the upper-bound of Theorem 3, which does not take unavoidable transactions into account, we can use Theorem 2, which offers a much tighter bound, especially in the case of many unavoidable transactions.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 1</head><label>1</label><figDesc>Properties of the datasets used.</figDesc><table><row><cell>Dataset</cell><cell># transactions</cell><cell># items</cell><cell>Density</cell><cell>10% freq</cell><cell># solutions (10% freq)</cell></row><row><cell>1. Soybean</cell><cell>630</cell><cell>59</cell><cell>0.25</cell><cell>63</cell><cell>12 754</cell></row><row><cell>2. Splice-1</cell><cell>3190</cell><cell>290</cell><cell>0.21</cell><cell>319</cell><cell>1963</cell></row><row><cell>3. Anneal</cell><cell>812</cell><cell>41</cell><cell>0.43</cell><cell>81</cell><cell>1 891 712</cell></row><row><cell>4. Mushroom</cell><cell>8124</cell><cell>119</cell><cell>0.19</cell><cell>812</cell><cell>574 514</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5</head><label>5</label><figDesc>Statistics of UCI datasets, and runtimes, in seconds, of two CP models and other systems.</figDesc><table><row><cell>Name</cell><cell>Dense</cell><cell>Trans</cell><cell>Item</cell><cell>CP4IM(4)</cell><cell>CP4IM(2)</cell><cell>ddpmine [14]</cell><cell>lcm [51]</cell></row><row><cell>Anneal</cell><cell>0.45</cell><cell>812</cell><cell>93</cell><cell>0.22</cell><cell>24.09</cell><cell>22.46</cell><cell>7.92</cell></row><row><cell>Australian-cr</cell><cell>0.41</cell><cell>653</cell><cell>125</cell><cell>0.30</cell><cell>0.63</cell><cell>3.40</cell><cell>1.22</cell></row><row><cell>Breast-wisc</cell><cell>0.50</cell><cell>683</cell><cell>120</cell><cell>0.28</cell><cell>13.66</cell><cell>96.75</cell><cell>27.49</cell></row><row><cell>Diabetes</cell><cell>0.50</cell><cell>768</cell><cell>112</cell><cell>2.45</cell><cell>128.04</cell><cell>-</cell><cell>697.12</cell></row><row><cell>German-cr</cell><cell>0.34</cell><cell>1000</cell><cell>112</cell><cell>2.39</cell><cell>66.79</cell><cell>-</cell><cell>30.84</cell></row><row><cell>Heart-clevel</cell><cell>0.47</cell><cell>296</cell><cell>95</cell><cell>0.19</cell><cell>2.15</cell><cell>9.49</cell><cell>2.87</cell></row><row><cell>Hypothyroid</cell><cell>0.49</cell><cell>3247</cell><cell>88</cell><cell>0.71</cell><cell>10.91</cell><cell>-</cell><cell>&gt;</cell></row><row><cell>Ionosphere</cell><cell>0.50</cell><cell>351</cell><cell>445</cell><cell>1.44</cell><cell>&gt;</cell><cell>-</cell><cell>&gt;</cell></row><row><cell>kr-vs-kp</cell><cell>0.49</cell><cell>3196</cell><cell>73</cell><cell>0.92</cell><cell>46.20</cell><cell>125.60</cell><cell>25.62</cell></row><row><cell>Letter</cell><cell>0.50</cell><cell>20 000</cell><cell>224</cell><cell>52.66</cell><cell>&gt;</cell><cell>-</cell><cell>&gt;</cell></row><row><cell>Mushroom</cell><cell>0.18</cell><cell>8124</cell><cell>119</cell><cell>14.11</cell><cell>13.48</cell><cell>0.09</cell><cell>0.03</cell></row><row><cell>Pendigits</cell><cell>0.50</cell><cell>7494</cell><cell>216</cell><cell>3.68</cell><cell>&gt;</cell><cell>-</cell><cell>&gt;</cell></row><row><cell>Primary-tum</cell><cell>0.48</cell><cell>336</cell><cell>31</cell><cell>0.03</cell><cell>0.13</cell><cell>0.26</cell><cell>0.08</cell></row><row><cell>Segment</cell><cell>0.50</cell><cell>2310</cell><cell>235</cell><cell>1.45</cell><cell>&gt;</cell><cell>-</cell><cell>&gt;</cell></row><row><cell>Soybean</cell><cell>0.32</cell><cell>630</cell><cell>50</cell><cell>0.05</cell><cell>0.07</cell><cell>0.05</cell><cell>0.02</cell></row><row><cell>Splice-1</cell><cell>0.21</cell><cell>3190</cell><cell>287</cell><cell>30.41</cell><cell>31.11</cell><cell>1.86</cell><cell>0.02</cell></row><row><cell>Vehicle</cell><cell>0.50</cell><cell>846</cell><cell>252</cell><cell>0.85</cell><cell>&gt;</cell><cell>-</cell><cell>&gt;</cell></row><row><cell>Yeast</cell><cell>0.49</cell><cell>1484</cell><cell>89</cell><cell>5.67</cell><cell>781.63</cell><cell>-</cell><cell>185.28</cell></row><row><cell cols="2">7.6. Q2: closed itemset mining</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table A . 6</head><label>A6</label><figDesc>Comparison in propagations, peak memory and time (in seconds) of using boolean variables and their respective constraints versus using integer variables and constraints.</figDesc><table><row><cell>Dataset</cell><cell>Original boolean</cell><cell></cell><cell></cell><cell>Integers</cell><cell></cell><cell></cell><cell>Gain</cell></row><row><cell></cell><cell>Peak mem.</cell><cell># props</cell><cell>Time</cell><cell>Peak mem.</cell><cell># props</cell><cell>Time</cell><cell></cell></row><row><cell>1. Soybean</cell><cell>2820</cell><cell>5 909 592</cell><cell>1.4</cell><cell>2436</cell><cell>1 839 932</cell><cell>0.8</cell><cell>1 . 7</cell></row><row><cell>2. Splice-1</cell><cell>147 280</cell><cell>23 708 807</cell><cell>129</cell><cell>142 032</cell><cell>9 072 323</cell><cell>57</cell><cell>2.3</cell></row><row><cell>3. Anneal</cell><cell>3140</cell><cell>1 121 904 924</cell><cell>279</cell><cell>2564</cell><cell>273 248 618</cell><cell>136</cell><cell>2.1</cell></row><row><cell>4. Mushroom</cell><cell>45 636</cell><cell>2 989 128 466</cell><cell>1447</cell><cell>39 940</cell><cell>862 480 847</cell><cell>508</cell><cell>2.9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table A . 7</head><label>A7</label><figDesc>Comparison in propagations, peak memory and time (in seconds) of the channeled integer formulation of the base model and the boolean formulation with the dedicated propagator.</figDesc><table><row><cell>Dataset</cell><cell>Integers</cell><cell></cell><cell></cell><cell>Dedicated boolean</cell><cell></cell><cell></cell><cell>Gain</cell></row><row><cell></cell><cell>Peak mem.</cell><cell># props</cell><cell>Time</cell><cell>Peak mem.</cell><cell># props</cell><cell>Time</cell><cell></cell></row><row><cell>1. Soybean</cell><cell>2436</cell><cell>1 839 932</cell><cell>0.8</cell><cell>1796</cell><cell>1 058 238</cell><cell>0.5</cell><cell>1 . 6</cell></row><row><cell>2. Splice-1</cell><cell>142 032</cell><cell>9 072 323</cell><cell>57</cell><cell>123 279</cell><cell>6 098 820</cell><cell>68</cell><cell>0.8</cell></row><row><cell>3. Anneal</cell><cell>2564</cell><cell>273 248 618</cell><cell>136</cell><cell>2500</cell><cell>121 495 848</cell><cell>74</cell><cell>1.8</cell></row><row><cell>4. Mushroom</cell><cell>39 940</cell><cell>862 480 847</cell><cell>508</cell><cell>30 852</cell><cell>520 928 196</cell><cell>387</cell><cell>1.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table A . 8</head><label>A8</label><figDesc>Comparison in propagations, peak memory and time (in seconds) of formulating the coverage constraints using: the new reified sum constraint, the advisor version of the new reified sum constraint and the clause constraint.</figDesc><table><row><cell></cell><cell>Boolean sum</cell><cell></cell><cell></cell><cell cols="2">Boolean sum, advisers</cell><cell></cell><cell>Clause, advisers</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Mem.</cell><cell># props</cell><cell>Time</cell><cell>Mem.</cell><cell># props</cell><cell>Time</cell><cell>Mem.</cell><cell># props</cell><cell>Time</cell></row><row><cell>1</cell><cell>1796</cell><cell>1 058 238</cell><cell>0.5</cell><cell>2500</cell><cell>799 791</cell><cell>0.5</cell><cell>1860</cell><cell>799 791</cell><cell>0.5</cell></row><row><cell>2</cell><cell>123 279</cell><cell>6 098 820</cell><cell>68</cell><cell>237 071</cell><cell>3 188 139</cell><cell>54</cell><cell>124 431</cell><cell>3 188 139</cell><cell>49</cell></row><row><cell>3</cell><cell>2500</cell><cell>121 495 848</cell><cell>74</cell><cell>2500</cell><cell>121 495 848</cell><cell>73</cell><cell>2116</cell><cell>121 495 848</cell><cell>73</cell></row><row><cell>4</cell><cell>30 852</cell><cell>520 928 196</cell><cell>387</cell><cell>47 172</cell><cell>344 377 153</cell><cell>372</cell><cell>31 236</cell><cell>344 377 153</cell><cell>365</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table A . 9</head><label>A9</label><figDesc>Comparison of peak memory, propagations and time (in seconds) using the minimum or maximum value ordering heuristics on the frequent itemset mining problem.</figDesc><table><row><cell>Dataset</cell><cell>Minimum value</cell><cell></cell><cell></cell><cell>Maximum value</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Mem.</cell><cell>Props.</cell><cell>Time</cell><cell>Mem.</cell><cell>Props.</cell><cell>Time</cell></row><row><cell>1. Soybean</cell><cell>1860</cell><cell>137 666</cell><cell>0.2</cell><cell>899</cell><cell>217 802</cell><cell>0.3</cell></row><row><cell>2. Splice-1</cell><cell>122 511</cell><cell>2 602 069</cell><cell>41</cell><cell>16 328</cell><cell>4 961 137</cell><cell>109</cell></row><row><cell>3. Anneal</cell><cell>1796</cell><cell>577 719</cell><cell>18</cell><cell>1412</cell><cell>726 308</cell><cell>18</cell></row><row><cell>4. Mushroom</cell><cell>26 244</cell><cell>6 232 932</cell><cell>48</cell><cell>20 229</cell><cell>9 989 882</cell><cell>63</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We studied this problem in two conference papers<ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b37">38]</ref> and brought it to the attention of the AI community<ref type="bibr" target="#b16">[17]</ref>. This article extends these earlier papers with proofs, experiments and comprehensive comparisons with related work in the literature.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>* x 1 + 4 * x 2 + 8 * x</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>3;    we know that at least one of x 2 and x 3 must have value 1, but we cannot conclude that either one of these variables is certainly zero or one. The propagator does not change any domains. On the other hand, given</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_3"><p>Itemset mining was first applied in a supermarket setting; the terminology still reflects this.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_4"><p>This terminology is again from the supermarket setting, where the cost of an item could be its price or profit.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_5"><p>http://www.gecode.org/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_6"><p>http://archive.ics.uci.edu/ml/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_7"><p>http://dtai.cs.kuleuven.be/CP4IM/.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by a Postdoc and a project grant from the Research Foundation-Flanders, project "Principles of Patternset Mining" as well as a grant from the Institute for the Promotion and Innovation through Science and Technology in Flanders (IWT-Vlaanderen).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>and convertible constraints during the search. Our CP4IM system is the only system that supports all of these constraints as well as combinations of these constraints. Furthermore, thanks to the use of a declarative constraint programming system it can easily be extended with further types of constraints. This is what we regard as the major of advantage of the constraint programming methodology. It is also interesting to contrast this approach with that taken by the alternative, more procedural systems, which were typically designed to cope with a single constraint family and were later upgraded to deal with other ones too. This upgrade usually involves changing the algorithm dramatically and hard-coding the new constraint in it. In contrast, in CP one might need to add a new propagator (as we have done for the discrimination constraint), but the corresponding constraint can freely be used and combined with any other current and future constraint in the system. This is essentially the difference between a declarative and a procedural approach. On the other hand, generality and flexibility also may have a price in terms of performance. Therefore, we do not expect CP4IM to perform well on each task, but we would hope its performance is competitive when averaging over a number of tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">QA: non-reified vs reified</head><p>In Section 3.3 we argued that using reified frequency constraints for the standard frequent itemset mining problem can lead to more propagation. Table <ref type="table">3</ref> shows a comparison between running the CP model with non-reified and reified frequency constraints. Two datasets were used, each with three different frequency thresholds. For the reasonably small anneal dataset, it can be noted that the non-reified version needs a bit less memory and propagation, but at the cost of some failed branches in the search tree. This leads to a small increase in run time. For the bigger mushroom dataset however, the difference is larger. For higher minimum frequency thresholds the reified pruning becomes stronger while for the non-reified formulation the cost of a failed branch increases, leading to a larger difference in runtime. In general we have observed that using the reified frequency constraints often leads to better performance, especially for larger datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.">QB: variable ordering</head><p>In constraint programming it is known that the order in which the variables are searched over can have a large impact on the size of the search tree, and hence the efficiency of the search. This has received a lot less attention in the itemset mining community, except in algorithms like fp-growth where a good ordering is needed to keep the fp-tree size down.</p><p>We consider three possible variable ordering strategies, for the standard frequent itemset mining problem:</p><p>arbitrary: the input order of variables is used; minimum degree: the variable occurring in the smallest number of propagators; maximum degree: the variable occurring in the largest number of propagators.</p><p>The comparison of the three variable orderings can be found in Table <ref type="table">4</ref>. The experiments show that choosing the variable with maximum degree leads to a large reduction in the number of propagations and runtime. The maximum degree heuris-  tic corresponds to choosing the item with the lowest frequency, as this item occurs in the coverage constraint (Eq. ( <ref type="formula">7</ref>)) of most transactions. In other words, the most efficient variable ordering strategy is a fail-first strategy that explores the most unlikely branches of the search tree first. Such a conclusion is not surprising in the constraint programming community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.">Q1: frequent itemset mining</head><p>A comparison of specialized frequent itemset miners and CP4IM is provided in Fig. <ref type="figure">10</ref> for a representative number of datasets. In this figure we show run times for different support thresholds as it was previously found that the differences between systems can highly depend on this constraint <ref type="bibr" target="#b26">[27]</ref>.</p><p>The run time of all systems is correlated to the number of patterns found (the red line). Our CP4IM model implemented in Gecode, indicated by FIM_CP, is significantly slower than the other depth-first miners, but shows similar behavior. This indicates that indeed its search strategy is similar, but the use of alternative data structures and other overhead in the constraint programming system introduces a lot of overhead for standard frequent itemset mining. It is remarkable that CP4IM compares well to the breadth-first Patternist system, which does not use the concept of projected databases as pervasively as other systems; the compact representations developed in the specialized itemset miners for projected databases indeed explain the performance difference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Improved solving, continued</head><p>In Section 7 we empirically studied the effect of non-reified versus reified formulations and of different variable ordering heuristics. In this appendix we include some additional findings, as we have experienced that making the right low-level decisions is necessary to be competitive with the highly optimized itemset mining implementations. We start by studying the differences between using boolean variables and integers with a domain of {0, 1}. We continue by studying two implementation alternatives for an essential constraint shared by all models: the coverage constraint. We end with a comparison of different value ordering heuristics; to explain and improve the results we have to provide some additional details about the Gecode system.</p><p>Apart from Gecode specific remarks, which are applicable only to solvers that do copying and cloning, the results presented in this appendix are also valid and applicable to other solvers. In fact, parts of the work studied here are now by default in the aforementioned Gecode system. but needs significantly less memory. For our application it is thus faster and less memory intensive to clone every node in the search tree and choose the maximum value first.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5. Summary</head><p>An overview of the relative improvements of each step can be found in Fig. <ref type="bibr">A.15</ref>. Overall, we see that even though our initial model -using reified constraints -could be specified straightforwardly, the scalability of the approach is highly depended on making the right low-level decisions, as discussed in this section. Only this modeling process as a whole can make the CP-based approach competitive with current specialized systems for constraint-based itemset mining.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mining association rules between sets of items in large databases</title>
		<author>
			<persName><forename type="first">Tomasz</forename><surname>Rakesh Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><forename type="middle">N</forename><surname>Imielinski</surname></persName>
		</author>
		<author>
			<persName><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="207" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast discovery of association rules</title>
		<author>
			<persName><forename type="first">Hiekki</forename><surname>Rakesh Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramakrishnan</forename><surname>Mannila</surname></persName>
		</author>
		<author>
			<persName><surname>Srikant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Inkeri</forename><surname>Hannu Toivonen</surname></persName>
		</author>
		<author>
			<persName><surname>Verkamo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Knowledge Discovery and Data Mining</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="307" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Krzysztof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Apt</surname></persName>
		</author>
		<author>
			<persName><surname>Wallace</surname></persName>
		</author>
		<title level="m">Constraint Logic Programming Using Eclipse</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Detecting change in categorical data: mining contrast sets</title>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">D</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Fifth International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="302" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Constraint-based rule mining in large, dense databases</title>
		<author>
			<persName><forename type="first">Roberto</forename><forename type="middle">J</forename><surname>Bayardo</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitrios</forename><surname>Rakesh Agrawal</surname></persName>
		</author>
		<author>
			<persName><surname>Gunopulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2/3</biblScope>
			<biblScope unit="page" from="217" to="240" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Global constraint catalogue: past, present and future</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Beldiceanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mats</forename><surname>Carlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophie</forename><surname>Demassey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Petit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Constraints</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="21" to="62" />
			<date type="published" when="2007-03">March 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Minimising decision tree size as combinatorial optimisation, in: Principles and Practice of Constraint Programming</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Bessiere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Hebrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName><surname>Sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">5732</biblScope>
			<biblScope unit="page" from="173" to="187" />
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">FP-bonsai: the art of growing and pruning small fp-trees</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Bonchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Goethals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Knowledge Discovery and Data Mining</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3056</biblScope>
			<biblScope unit="page" from="155" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Extending the state-of-the-art of constraint-based pattern discovery</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Bonchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Lucchese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data and Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="377" to="399" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Constraint satisfaction problems: algorithms and applications</title>
		<author>
			<persName><forename type="first">Sally</forename><forename type="middle">C</forename><surname>Brailsford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">N</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbara</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="557" to="581" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">DualMiner: a dual-pruning algorithm for itemsets with constraints</title>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Bucila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Kifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="241" to="272" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning and inference with constraints</title>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lev-Arie</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Rizzolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Third AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1513" to="1518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Discriminative frequent pattern analysis for effective classification</title>
		<author>
			<persName><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Xifeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chih-Wei</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Data Engineering</title>
		<meeting>the 23rd International Conference on Data Engineering</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="716" to="725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Direct discriminative pattern mining for effective classification</title>
		<author>
			<persName><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Xifeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Data Engineering</title>
		<meeting>the 24th International Conference on Data Engineering</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="169" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bayesian network learning by compiling to weighted max-sat</title>
		<author>
			<persName><forename type="first">James</forename><surname>Cussens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Conference in Uncertainty in Artificial Intelligence</title>
		<meeting>the 24th Conference in Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Constraint programming for itemset mining</title>
		<author>
			<persName><forename type="first">Luc</forename><surname>De Raedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tias</forename><surname>Guns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siegfried</forename><surname>Nijssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>eeding of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="204" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Constraint programming for data mining and machine learning</title>
		<author>
			<persName><forename type="first">Luc</forename><surname>De Raedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tias</forename><surname>Guns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siegfried</forename><surname>Nijssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Fourth AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1513" to="1518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The levelwise version space algorithm and its application to molecular fragment finding</title>
		<author>
			<persName><forename type="first">Luc</forename><surname>De Raedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Kramer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Seventeenth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="853" to="862" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Constraint-based pattern set mining</title>
		<author>
			<persName><forename type="first">Luc</forename><surname>De Raedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albrecht</forename><surname>Zimmermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh SIAM International Conference on Data Mining</title>
		<meeting>the Seventh SIAM International Conference on Data Mining</meeting>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Efficient mining of emerging patterns: discovering trends and differences</title>
		<author>
			<persName><forename type="first">Guozhu</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Fifth International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Direct mining of discriminative and essential frequent patterns via model-based search tree</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Xifeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Verscheure</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="230" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The design of essence: a constraint language for specifying combinatorial problems</title>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">M</forename><surname>Frisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Grum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Jefferson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernadette</forename><forename type="middle">Martínez</forename><surname>Hernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Miguel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 20th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="80" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">ROC &apos;n&apos; rule learning -towards a better understanding of covering algorithms</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Fürnkranz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">A</forename><surname>Flach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="77" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
	</analytic>
	<monogr>
		<title level="m">Formal Concept Analysis, Foundations and Applications</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Bernhard</forename><surname>Ganter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Gerd</forename><surname>Stumme</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rudolf</forename><surname>Wille</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3626</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Gecode</forename><surname>Team</surname></persName>
		</author>
		<ptr target="http://www.gecode.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">MINION: a fast scalable constraint solver</title>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">P</forename><surname>Gent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Jefferson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Miguel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 17th European Conference on Artificial Intelligence</title>
		<meeting>eeding of the 17th European Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="98" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Bart</forename><surname>Goethals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
		<title level="m">Advances in frequent itemset mining implementations: report on FIMI&apos;03</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="109" to="117" />
		</imprint>
	</monogr>
	<note>SIGKDD Explorations Newsletter</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Tight optimistic estimates for fast subgroup discovery</title>
		<author>
			<persName><forename type="first">Henrik</forename><surname>Grosskreutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Rüping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Wrobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5211</biblScope>
			<biblScope unit="page" from="440" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Luc De Raedt, k-Pattern set mining under constraints</title>
		<author>
			<persName><forename type="first">Tias</forename><surname>Guns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siegfried</forename><surname>Nijssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CW Reports CW</title>
		<imprint>
			<biblScope unit="volume">596</biblScope>
			<date type="published" when="2010-10">October 2010</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, K.U. Leuven</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Mining frequent patterns without candidate generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Frequent pattern mining: current status and future directions</title>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="86" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">APRIORI-SD: adapting association rule learning to subgroup discovery</title>
		<author>
			<persName><forename type="first">Branko</forename><surname>Kavsek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nada</forename><surname>Lavrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Jovanoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Intelligent Data Analysis</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2810</biblScope>
			<biblScope unit="page" from="230" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Levelwise search and borders of theories in knowledge discovery</title>
		<author>
			<persName><forename type="first">Heikki</forename><surname>Mannila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannu</forename><surname>Toivonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="241" to="258" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Algorithms for mining association rules for binary segmentations of huge categorical databases</title>
		<author>
			<persName><forename type="first">Yasuhiko</forename><surname>Morimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Takeshi</forename><surname>Fukuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hirofumi</forename><surname>Matsuzawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Takeshi</forename><surname>Tokuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunikazu</forename><surname>Yoda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 24rd International Conference on Very Large Data Bases</title>
		<meeting>24rd International Conference on Very Large Data Bases</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="380" to="391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Traversing itemset lattice with statistical metric pruning</title>
		<author>
			<persName><forename type="first">Shinichi</forename><surname>Morishita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Sese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems</title>
		<meeting>the Nineteenth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="226" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Optimal constraint-based decision tree induction from itemset lattices</title>
		<author>
			<persName><forename type="first">Siegfried</forename><surname>Nijssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Élisa</forename><surname>Fromont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="51" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Integrating constraint programming and itemset mining</title>
		<author>
			<persName><forename type="first">Siegfried</forename><surname>Nijssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tias</forename><surname>Guns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6322</biblScope>
			<biblScope unit="page" from="467" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Luc De Raedt, Correlated itemset mining in ROC space: a constraint programming approach</title>
		<author>
			<persName><forename type="first">Siegfried</forename><surname>Nijssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tias</forename><surname>Guns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="647" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Knowledge Discovery in Inductive Databases</title>
		<author>
			<persName><forename type="first">Siegfried</forename><surname>Nijssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joost</surname></persName>
		</author>
		<author>
			<persName><surname>Kok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">3933</biblScope>
			<biblScope unit="page" from="165" to="187" />
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>Multi-class correlated pattern mining</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Discovering frequent closed itemsets for association rules</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Pasquier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yves</forename><surname>Bastide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafik</forename><surname>Taouil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lotfi</forename><surname>Lakhal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Database Theory</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">1540</biblScope>
			<biblScope unit="page" from="398" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Can we push more constraints into frequent pattern mining</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="350" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mining frequent item sets with convertible constraints</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Laks</surname></persName>
		</author>
		<author>
			<persName><surname>Lakshmanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Data Engineering</title>
		<meeting>the IEEE International Conference on Data Engineering</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="433" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Closet: an efficient algorithm for mining frequent closed itemsets</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Runying</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="page" from="21" to="30" />
			<date type="published" when="2000">2000</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Search procedures and parallelism in constraint programming, in: Principles and Practice of Constraint Programming</title>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Perron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">1713</biblScope>
			<biblScope unit="page" from="346" to="360" />
			<date type="published" when="1999">1999</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Handbook of Constraint Programming (Foundations of Artificial Intelligence)</title>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Van Beek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toby</forename><surname>Walsh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Elsevier Science Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Programming Constraint Services: High-Level Programming of Standard and New Constraint Services</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Schulte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">2302</biblScope>
			<date type="published" when="2002">2002</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Efficient constraint propagation engines</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Schulte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Stuckey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Programming Languages and Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="43" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Answering the most correlated n association rules efficiently</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Sese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shinichi</forename><surname>Morishita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Principles of Data Mining and Knowledge Discovery</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2431</biblScope>
			<biblScope unit="page" from="410" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Turbo-charging vertical mining of large databases</title>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Shenoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayant</forename><forename type="middle">R</forename><surname>Haritsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sudarshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Bhalotia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mayank</forename><surname>Bawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shah</forename><surname>Devavrat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2000 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="22" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">An efficient framework for mining flexible constraints</title>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Soulet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Crømilleux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Knowledge Discovery and Data Mining</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3518</biblScope>
			<biblScope unit="page" from="43" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">3: collaboration of array, bitmap and prefix tree for frequent itemset mining</title>
		<author>
			<persName><forename type="first">Takeaki</forename><surname>Uno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masashi</forename><surname>Kiyomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroki</forename><surname>Arimura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lcm</forename><surname>Ver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Workshop on Open Source Data Mining</title>
		<meeting>the 1st International Workshop on Open Source Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="77" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Van Hentenryck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yves</forename><surname>Deville</surname></persName>
		</author>
		<title level="m">The Cardinality Operator: A New Logical Connective for Constraint Logic Programming</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="383" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Search and strategies in OPL</title>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Van Hentenryck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Perron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Francois</forename><surname>Puget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transations Computational Logic</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="285" to="320" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Yves Deville, Design, implementation, and evaluation of the constraint language cc(FD)</title>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Van Hentenryck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><forename type="middle">A</forename><surname>Saraswat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Logic Programming</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="139" to="164" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">An algorithm for multi-relational discovery of subgroups</title>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Wrobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Principles of Data Mining and Knowledge Discovery</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">1263</biblScope>
			<biblScope unit="page" from="78" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Fast vertical mining using diffsets</title>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Javeed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaki</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Karam</forename><surname>Gouda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="326" to="335" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
