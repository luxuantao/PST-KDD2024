<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">OneEE: A One-Stage Framework for Fast Overlapping and Nested Event Extraction</title>
				<funder ref="#_NKdJXF9">
					<orgName type="full">Center for Artificial Intelligence</orgName>
				</funder>
				<funder ref="#_fbyWpd4">
					<orgName type="full">Youth Fund for Humanities and Social Science Research of Ministry of Education of China</orgName>
				</funder>
				<funder ref="#_M4Kxjbp">
					<orgName type="full">Research Foundation of Ministry of Education of China</orgName>
				</funder>
				<funder>
					<orgName type="full">Sao Paulo Research Foundation</orgName>
				</funder>
				<funder ref="#_8fERUR4">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_66qEFBM">
					<orgName type="full">FAPESP</orgName>
				</funder>
				<funder>
					<orgName type="full">IBM Corporation</orgName>
				</funder>
				<funder ref="#_7DgZ84Q">
					<orgName type="full">General Project of Natural Science Foundation of Hubei Province</orgName>
				</funder>
				<funder ref="#_HWDW4ZS">
					<orgName type="full">National Key Research and Development Program of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hu</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">School of Cyber Science and Engineering</orgName>
								<orgName type="laboratory">Key Laboratory of Aerospace Information Security and Trusted Computing</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">The codes at https://github.com/Cao-Hu</orgName>
								<address>
									<country>OneEE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jingye</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">School of Cyber Science and Engineering</orgName>
								<orgName type="laboratory">Key Laboratory of Aerospace Information Security and Trusted Computing</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">The codes at https://github.com/Cao-Hu</orgName>
								<address>
									<country>OneEE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fangfang</forename><surname>Su</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">School of Cyber Science and Engineering</orgName>
								<orgName type="laboratory">Key Laboratory of Aerospace Information Security and Trusted Computing</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">The codes at https://github.com/Cao-Hu</orgName>
								<address>
									<country>OneEE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fei</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>Fei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">School of Cyber Science and Engineering</orgName>
								<orgName type="laboratory">Key Laboratory of Aerospace Information Security and Trusted Computing</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">The codes at https://github.com/Cao-Hu</orgName>
								<address>
									<country>OneEE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shengqiong</forename><surname>Wu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bobo</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">School of Cyber Science and Engineering</orgName>
								<orgName type="laboratory">Key Laboratory of Aerospace Information Security and Trusted Computing</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">The codes at https://github.com/Cao-Hu</orgName>
								<address>
									<country>OneEE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liang</forename><surname>Zhao</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computing and Mathematics</orgName>
								<orgName type="institution">University of S?o Paulo</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Donghong</forename><surname>Ji</surname></persName>
							<email>dhji@whu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">School of Cyber Science and Engineering</orgName>
								<orgName type="laboratory">Key Laboratory of Aerospace Information Security and Trusted Computing</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">The codes at https://github.com/Cao-Hu</orgName>
								<address>
									<country>OneEE</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">OneEE: A One-Stage Framework for Fast Overlapping and Nested Event Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Event extraction (EE) is an essential task of information extraction, which aims to extract structured event information from unstructured text. Most prior work focuses on extracting flat events while neglecting overlapped or nested ones. A few models for overlapped and nested EE includes several successive stages to extract event triggers and arguments, which suffer from error propagation. Therefore, we design a simple yet effective tagging scheme and model to formulate EE as word-word relation recognition, called OneEE. The relations between trigger or argument words are simultaneously recognized in one stage with parallel grid tagging, thus yielding a very fast event extraction speed. The model is equipped with an adaptive event fusion module to generate event-aware representations and a distance-aware predictor to integrate relative distance information for word-word relation recognition, which are empirically demonstrated to be effective mechanisms. Experiments on 3 overlapped and nested EE benchmarks, namely FewFC, Genia11, and Genia13, show that OneEE achieves the stateof-the-art (SoTA) results. Moreover, the inference speed of OneEE is faster than those of baselines in the same condition, and can be further substantially improved since it supports parallel inference. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Event Extraction (EE) is a fundamental yet challenging task in information extraction research <ref type="bibr" target="#b23">(Miwa and Bansal, 2016;</ref><ref type="bibr" target="#b12">Katiyar and Cardie, 2016;</ref><ref type="bibr">Fei et al., 2020b;</ref><ref type="bibr">Li et al., 2021b;</ref><ref type="bibr">Fei et al., 2022a)</ref>. EE facilitates the development of practical applications such as knowledge graph construction <ref type="bibr">(Wei et al., 2019b;</ref><ref type="bibr" target="#b0">Bosselut et al., 2021)</ref>, biological process analysis <ref type="bibr" target="#b24">(Miwa et al., 2013)</ref>, and financial market surveillance <ref type="bibr" target="#b27">(Nuij et al., 2013)</ref>. The goal of EE  is to recognize event triggers as well as the associated arguments from texts. As an example, Figure <ref type="figure" target="#fig_0">1</ref>(a) illustrates a Share Reduction event including a trigger "reduced" and a subject argument "Wang Yawei".</p><p>Traditional methods for EE <ref type="bibr" target="#b20">(Li et al., 2013;</ref><ref type="bibr" target="#b1">Chen et al., 2015;</ref><ref type="bibr" target="#b25">Nguyen et al., 2016;</ref><ref type="bibr" target="#b21">Liu et al., 2018;</ref><ref type="bibr" target="#b26">Nguyen and Nguyen, 2019)</ref> regard event extraction as a sequence labeling task, assuming that event mentions do not overlap with each other. However, they neglect complicated irregular EE scenarios (i.e., overlapped and nested EE) <ref type="bibr">(Fei et al., 2020a</ref><ref type="bibr">(Fei et al., , 2021a))</ref>. As exemplified in Figure <ref type="figure" target="#fig_0">1(b)</ref>, there are two overlapped events, Investment, and Share Transfer, which share the same trigger word "acquired" and the argument words "Guangzhou Securities". Figure <ref type="figure" target="#fig_0">1</ref>(c) illustrates an example of nested events where the event Gene Citic Securities acquired 100% equity of Guangzhou Securities  We formalize the overlapping and nested EE as wordword relation recognition, where S-T and S-A denote the relations between the head and tail boundary words of a trigger or argument, and R-S, R-O, R-T, and R-P denote the relations between the trigger word and the argument words with the roles "subject", "object", "target" and "proportion".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-T S-A</head><formula xml:id="formula_0">S-A R-S R-S R-O R-O<label>(</label></formula><p>Expression is the Theme argument of another event Positive Regulation.</p><p>Prior studies for overlapped and nested EE <ref type="bibr" target="#b38">(Yang et al., 2019;</ref><ref type="bibr" target="#b16">Li et al., 2020)</ref> employ pipeline-based methods that extract event triggers and arguments in several successive stages. Recently, the state-ofthe-art model <ref type="bibr" target="#b29">Sheng et al. (2021)</ref> also uses such a method that consecutively performs event type detection, trigger extraction, and argument extraction. The main problem with such a method is that the latter stage relies on the former stage, which inherently brings the error propagation problem.</p><p>To address the above issue, we present a novel tagging scheme that transforms overlapping and nested EE into word-word relation recognition. As shown in Figure <ref type="figure" target="#fig_2">2</ref>, we design two types of relations, including the span relation (S-* ) and role relation (R-* ). S-* handles trigger and argument identification, denoting whether two words are the head-tail boundary of a trigger (T) or argument (A). R-* addresses argument role classification, indicating whether the argument plays the " * " role in the event.</p><p>Based on this scheme, we further propose a onestage event extraction model, OneEE, which mainly includes three parts. First, it adopts BERT <ref type="bibr" target="#b2">(Devlin et al., 2019)</ref> as the encoder to get contextualized word representations. Afterward, an adaptive event fusion layer composed of an attention module and two gate fusion modules are used to obtain eventaware contextual representations for each event type. In the prediction layer, we parallelly predict the span and role relations between each pair of words by calculating distance-aware scores. Finally, event triggers, arguments, and their roles can be decoded out using these relation labels in one stage without error propagation.</p><p>We evaluate OneEE on 3 overlapped and nested EE datasets (FewFC <ref type="bibr" target="#b40">(Zhou et al., 2021)</ref>, Genia11 <ref type="bibr" target="#b13">(Kim et al., 2011), and</ref><ref type="bibr">Genia13 (Kim et al., 2013)</ref>), and conduct extensive experiments and analyses. Our contributions can be summarized as follows:</p><p>? We design a new tagging scheme that casts event extraction as a word-word relation recognition task, providing a novel and simple solution for overlapped and nested EE.</p><p>? We propose OneEE, a one-stage model that effectively extracts word-word relations in parallel for overlapped and nested EE.</p><p>? We further present an adaptive event fusion layer to obtain event-aware contextual representations and effectively integrate event information.</p><p>? OneEE outperforms the SoTA model with regard to both the performance and inference speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Event Extraction</head><p>Information extraction is one of the key research track in natural language processing <ref type="bibr" target="#b23">(Miwa and Bansal, 2016;</ref><ref type="bibr">Fei et al., 2021c)</ref>, among which the event extraction is the most complicated task <ref type="bibr" target="#b1">(Chen et al., 2015;</ref><ref type="bibr">Fei et al., 2022c)</ref>. Traditional EE (i.e., flat or regular EE) <ref type="bibr" target="#b20">(Li et al., 2013;</ref><ref type="bibr" target="#b25">Nguyen et al., 2016;</ref><ref type="bibr" target="#b21">Liu et al., 2018;</ref><ref type="bibr" target="#b28">Sha et al., 2018;</ref><ref type="bibr" target="#b26">Nguyen and Nguyen, 2019)</ref> formulates EE into a sequence labeling task, assigning each token with a label (e.g., BIO tagging scheme). For example, <ref type="bibr" target="#b25">Nguyen et al. (2016)</ref> uses two bidirectional RNNs to get richer representation which is then utilized to predict event triggers and argument roles jointly. <ref type="bibr" target="#b21">Liu et al. (2018)</ref> jointly extracts multiple event triggers and arguments by introducing attention-based GCN to model the dependency graph information <ref type="bibr">(Fei et al., 2021b;</ref><ref type="bibr">Li et al., 2021a;</ref><ref type="bibr">Fei et al., 2022b)</ref>. However, their underlying assumption that event mentions do not overlap with each other is not always valid. Irregular EE (i.e., overlapped and nested EE) has not received much attention, which is more challenging and realistic.</p><p>Existing methods for overlapped and nested EE <ref type="bibr" target="#b38">(Yang et al., 2019;</ref><ref type="bibr" target="#b16">Li et al., 2020)</ref> perform event extraction in a pipeline manner with several steps. To solve the argument overlap, <ref type="bibr" target="#b38">Yang et al. (2019)</ref> adopts multiple sets of binary classifiers where BERT S-A</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-T S-A</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-A</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-A</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-T S-A</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-A</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Span Head</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R-S R-S R-P R-T R-T R-S R-S R-P R-T R-T</head><p>Span Tail </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Tagging-based Information Extraction</head><p>Tagging scheme in the field of information extraction has been extensively investigated. Traditional sequence labeling approaches tagging each token once (e.g., BIO) is hard to tackle irregular information extraction (e.g., overlapped NER). Several researchers <ref type="bibr" target="#b39">(Zheng et al., 2017)</ref> extend the BIO label scheme to adapt to more complex scenarios. However, they suffer from the label ambiguity problem due to limited flexibility. Recently, the grid tagging scheme is used in a lot of information extraction tasks, such as opinion mining <ref type="bibr" target="#b37">(Wu et al., 2020)</ref>, relation extraction <ref type="bibr" target="#b33">(Wang et al., 2020)</ref>, and named entity recognition <ref type="bibr" target="#b34">(Wang et al., 2021)</ref>, due to its characteristic of presenting relations between word pairs. For example, TPLinker <ref type="bibr" target="#b33">(Wang et al., 2020)</ref> realizes one-stage joint relation extraction without a gap between training and inference by tagging token pairs with link labels. Inspired by these works, we design our tagging scheme to address overlapping and nested EE, which predicts relations between trigger or argument words parallelly in one stage. Also it is noteworthy explicitly that this work inherits the recent success of the idea of wordword relation detection, as in <ref type="bibr" target="#b18">Li et al. (2022)</ref>. <ref type="bibr" target="#b18">Li et al. (2022)</ref> propose to unify all the NER (including the flat, nested and discontinuous mentions) with a word-word modeling based on the grid tagging scheme. This work however differs from <ref type="bibr" target="#b18">Li et al. (2022)</ref> in two folds. First, we extend the idea of the word-word tagging from NER to EE successfully, where we re-design two relation types for the nested and overlapped events. Second, from the modeling perspective, we devise an adaptive event fusion layer to fully support the one-stage (end-toend) complex event detection, which greatly helps avoid error propagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>The goal of event extraction includes extracting event triggers and their arguments. We can formalize overlapping and nested EE as follows: given an input sentence consisting of N tokens or words X = {x 1 , x 2 , . . . , x N } and event type e ? E, the task aims to extract the span relations S and the role relations R between each token pair (x i , x j ), where E denotes the event type collection, S and R are pre-defined tags. These relations can be explained below, and we also give an example as demonstrated in Figure <ref type="figure" target="#fig_2">2</ref> for better understanding.</p><p>? S: the span relation indicates that x i and x j are the starting and ending token of the extracted trigger span S-T or argument span S-A, where 1 ? i ? j ? N . ? R: the role relation indicates that the argument with x j acts the certain role R-* of the event with the trigger containing x i , where 1 ? i, j ? N . * indicates the role type. ? NONE, indicating that the word pair does not have any relation defined in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Framework</head><p>The architecture of our model is illustrated in Figure <ref type="figure">3</ref>, which mainly consists of three components. First, the widely-used pre-trained language model, BERT <ref type="bibr" target="#b2">(Devlin et al., 2019)</ref>, is used as the encoder to yield contextualized word representations from the input sentences. Then, an adaptive event fusion layer consisting of an attention module and two gate modules is used to integrate the target event type embedding into contextual representations. Afterward, a prediction layer is employed to jointly extract the span relations and the role relations between word pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Encoder Layer</head><p>We leverage BERT as the encoder for our model since it has been demonstrated to be one of the SoTA models for representation learning in EE.</p><p>Given an input sentence X = {x 1 , x 2 , . . . , x N }, we convert each token x i into word pieces and then feed them into a pre-trained BERT module. After the BERT calculation, each sentential word may involve vectorial representations of several pieces.</p><p>Here we employ max pooling to produce word representations H = {h 1 , h 2 , ..., h N } ? R N ?d h based on the word piece representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Adaptive Event Fusion Layer</head><p>Since the goal of our framework is to predict the relations between word pairs for the target event type e t , it is important to generate event-aware representations. Therefore, to fuse the event information and contextual information provided by the encoder, we design an adaptive fusion layer. As shown in Figure <ref type="figure">3</ref>, it consists of an attention module, modeling the interaction among events and obtaining the global event information, and two gate fusion modules for integrating the global and target event information with contextualized word representations.</p><p>Attention Mechanism Motivated by the selfattention in Transformer <ref type="bibr" target="#b32">(Vaswani et al., 2017;</ref><ref type="bibr">Wei et al., 2019a)</ref>, we first introduce an attention mechanism, of which input consists of queries, keys, and values. The output is computed as a weighted sum of the values, where the weight assigned to each value is the dot product of the query with the corresponding key. The attention mechanism can be formulated as:</p><formula xml:id="formula_1">Attention(Q, K, V ) = softmax( QK ? ? d h )V ,</formula><p>(1) where ? d h is a scaling factor, Q, K and V are query, key and value tensors, represented by Eq. 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gate Fusion Mechanism</head><p>We design a gate fusion mechanism to integrate two kinds of features and filter the unnecessary information. The gate vector g is produced by a fully-connection layer with the sigmoid function, which can adaptively control the flow of the input:</p><formula xml:id="formula_2">Gate(p, q) = g ? p + (1 -g) ? q , (2) g = ?(W g [p; q] + b g ) ,<label>(3)</label></formula><p>where p and q are input vectors, represented by Eq. 5 and Eq. 6. ?(?) is a sigmoid activation function, ? and [; ] denote element-wise product and concatenation operations, respectively. W g and b g are trainable parameters.</p><p>We leverage the attention mechanism to obtain the global event embeddings for each contextualized word representation. Given a set of randomly initialized event type embeddings E = {e 1 , e 2 , . . . , e M } ? R M ?d h , where M is the number of event types, the calculation can be formulated as:</p><formula xml:id="formula_3">E g = Attention(W q H, W k E, W v E) , (4)</formula><p>where E g is the output of the attention mechanism, W q , W k and W v are learnable parameters.</p><p>To encode global event information into word representations, we adopt a gate module to fuse the contextual word representations and global event representations. After that, we employ another gate mechanism to integrate the target event type embedding and the output of the last gate module. the overall process can be formulated as:</p><formula xml:id="formula_4">H g = Gate(H, E g ) , (<label>5</label></formula><formula xml:id="formula_5">) V t = Gate(H g , e t ) ,<label>(6)</label></formula><p>where e t ? E denotes the target event type embedding, V t = {v 1 , v 2 , ..., v N } ? R N ?d h is the final event-aware word representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Joint Prediction Layer</head><p>After the adaptive event fusion layer, we obtain the event-aware word representations V t , which are used to jointly predict the span and role relations between each pair of words. For each word pair (w i , w j ), we calculate a score to measure the possibility of them for the relation s ? S and r ? R.</p><p>Distance-aware Score To integrate relative distance information and word pair representations, we introduce a distance-aware score function. For two vectors p i and p j from a sequence of representations, we combine them with corresponding position embeddings from <ref type="bibr" target="#b30">Su et al. (2021)</ref>, and then calculate the score by the dot product of them:</p><formula xml:id="formula_6">Score(p i , p j ) = (R i p i ) ? (R j p j ) = p ? i R j-i p j ,<label>(7)</label></formula><p>where R i and R j are position embeddings of p i and p j , R j-i = R ? i R j . Thus, we can obtain the span score c s ij and the role score c r ij of the word pair (w i , w j ) for target event type t:</p><formula xml:id="formula_7">c s ij = Score(W s1 v t i , W s2 v t j ) ,<label>(8)</label></formula><formula xml:id="formula_8">c r ij = Score(W r1 v t i , W r2 v t j ) ,<label>(9)</label></formula><p>where W s1 , W s2 , W r1 and W r2 denote parameters. v t i and v t j are from Eq. 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Training Details</head><p>For the score c ? ij , where ? denotes the relation s or r, our training target is to minimize a variant of circle loss <ref type="bibr" target="#b31">(Sun et al., 2020)</ref> which extends softmax cross-entropy loss to figure out multi-label classification problem. In addition, we introduce a threshold score ?, noting that the scores of the pairs with relation are larger than ?, and the other pairs are less than it. The loss function can be formulated as:</p><formula xml:id="formula_9">L ? = log(e ? + (i,j)?? ? e -c ? ij )+log(e ? + (i,j) / ?? ? e c ? ij ) ,<label>(10)</label></formula><p>where ? ? denotes the pair set of relation ?, ? is set to zero.</p><p>Finally, we enumerate all event types in the selected event type set E ? and get the total loss:</p><formula xml:id="formula_10">L = t?E ? ( s?S L s + r?R L r ) ,<label>(11)</label></formula><p>where S ? is a subset sampled from S, we detail the sampling strategy in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Inference</head><p>During the inference period, our model is able to extract all events by parallelly injecting their event type embeddings to the adaptive event fusion layer. As shown in Figure <ref type="figure">4</ref>, once all the tags of a certain event type are predicted by our model in one stage, the overall decoding process can be summarized as four steps: First, we get starting and ending indices of the trigger or argument. Second, we obtain the trigger and argument spans.<ref type="foot" target="#foot_0">2</ref> Third, we match the trigger and arguments according to the R-* relations. Finally, the event type is assigned to this event structure. Specially, we repeat the above four steps for each event type.</p><p>5 Experiments Settings</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>As shown in Table <ref type="table" target="#tab_2">1</ref>, we follow previous work <ref type="bibr" target="#b29">(Sheng et al., 2021)</ref>, adopting FewFC <ref type="bibr" target="#b40">(Zhou et al., 2021)</ref>, a Chinese financial event extraction benchmark for overlapped EE. FewFC annotates 10 event types and 18 argument role classes with about 22% sentences containing overlapped events. We also experiment on two biomedical datasets for nested EE, namely Genia11 <ref type="bibr" target="#b13">(Kim et al., 2011)</ref> and Ge-nia13 <ref type="bibr" target="#b14">(Kim et al., 2013)</ref>, with around 18% sentences containing nested events. Genia11 annotates 9 event types and 10 argument role classes while the figures for Genia13 are 13 and 7. We split the train/dev/test as 8.0:1.0:1.0 for both of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Implementation Details</head><p>We employ the Chinese Bert-base model for FewFC and BioBERT <ref type="bibr" target="#b15">(Lee et al., 2020)</ref> for Ge- nia11 and Genia13. We adopt AdamW <ref type="bibr" target="#b22">(Loshchilov and Hutter, 2019)</ref> optimizer with the learning rate of 2e -5 for BERT and 1e -3 for the other modules. The batch size is 8 and the hidden size d h is 768. We train our model with epochs on FewFC and Genia11 and 30 epochs on Genia13. All the hyper-parameters are tuned on the development set.</p><p>All the event type embeddings are trained from scratch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation Metrics</head><p>For evaluation, we follow the traditional criteria of previous work <ref type="bibr" target="#b1">(Chen et al., 2015;</ref><ref type="bibr" target="#b3">Du and Cardie, 2020;</ref><ref type="bibr" target="#b29">Sheng et al., 2021)</ref>. 1) Trigger Identification (TI): A trigger is correctly identified if the predicted trigger span matches with a golden label; 2) Trigger Classification (TC): A trigger is correctly classified if it is correctly identified and assigned to the right type; 3) Argument Identification (AI): An argument is correctly identified if its event type is correctly recognized and the predicted argument span matches with a golden label; 4) Argument Classification (AC): An argument is correctly classified if it is correctly identified and the predicted role matches any of the golden labels. We report Precision (P), Recall (R), and F measure (F1) for each of the four metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Baselines</head><p>Sequence Labeling Methods for Flat EE These methods cast the EE task into a sequence labeling task by assigning each token a label. BERTsoftmax uses BERT to get feature representations for classifying triggers and arguments. BERT-CRF adds the CRF layer on BERT to capture label dependencies. BERT-CRF-joint extends the BIO tagging scheme to joint labels of type and role as B/I/O-type-role, inspired by joint extraction of entity and relation <ref type="bibr" target="#b39">(Zheng et al., 2017)</ref>. All these methods are incapable to solve the overlapping problem due to label conflicts.</p><p>Multi-stage Methods for Overlapped and Nested EE These methods perform EE in several stages. PLMEE <ref type="bibr" target="#b38">(Yang et al., 2019)</ref> solves the argument overlap problem by extracting rolespecific argument according to the trigger predicted by the trigger extractor in a pipeline manner. CasEE <ref type="bibr" target="#b29">(Sheng et al., 2021)</ref> sequentially performs type&amp;trigger&amp;argument extractions, where the overlapped targets are separately extracted conditioned on former predictions and all subtasks are jointly learned.</p><p>6 Experimental Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Results of All EE</head><p>Table <ref type="table" target="#tab_3">2</ref> reports the result of all methods on the overlapped EE dataset, FewFC, while Table <ref type="table">3</ref> reports the results of the nested EE datasets, Genia11 and Genia13. We can observe that: 1) Our method significantly outperforms all other methods and achieves the state-of-the-art F1 score on all three datasets.</p><p>2) In comparison with sequence labeling methods, our model achieves better recall and F1 scores. Specifically, our model outperforms BERT-CRFjoint by 11.7% and 6.3% in recall and the F1 score of AC on the FewFC dataset and achieves a substantial improvement of 4.4% in F1 score of AC on two Genia datasets averagely. It shows the effectiveness of our model on overlapped and nested EE since the sequence labeling methods can only solve flat EE.</p><p>3) In comparison with multi-stage methods, our model also improves the performance on the F1 score considerably. Our model outperforms the TI(%) TC(%) AI(%) AC(%)  state-of-the-art model, CasEE, by 2.1% in the F1 score of TC on three datasets averagely. We consider this is because that the event feature is well learned by our adaptive event fusion module. Especially, our model improves 3.4% on AI and 1.6% on AC over CasEE on an average of three datasets. The results reveal the superiority of our one-stage framework which elegantly realizes overlapped and nested event extraction without error propagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results of Overlapped and Nested EE</head><p>To evaluate the effectiveness of our proposed model in recognizing overlapping and nested event mentions, we further report the results on sentences containing at least one overlapping event in FewFC and sentences containing at least one nested event in Genia11, respectively. Figure <ref type="figure" target="#fig_3">5</ref> illustrates the results of TC and AC on overlapping and nested sentences in testing. It shows that our method outperforms other methods on overlapping and nested sentences. The reasons are mainly two-fold: 1) We solve all the overlapping patterns while BERT-CRF-joint could not handle overlapped and nested EE and PLMEE only solve the argument overlap. 2) Our one-stage model outperforms CasEE because we effectively learn event-aware representations and extract wordword relations in parallel, while CasEE performs in three sequential steps with error propagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Effects of the Modules in the Fusion Layer</head><p>To verify the effectiveness of each component, we conduct ablation studies on the FewFC dataset, as shown in Table <ref type="table" target="#tab_5">4</ref>. First, without the attention mechanism, we observe slight performance drops. By replacing the gate mechanism with an addition operation, the performance also decreases to a small degree. Furthermore, a significant drop can be found when the adaptive event fusion layer is substituted by addition, which indicates the usefulness of event representation and context. Finally, removing the position embeddings results in a remarkable drop on all F1 scores, especially 1.6% in the F1 score of AC, which suggests that the information of positions is essential to recognize word-word relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Effect of the Distance-aware Tag Prediction</head><p>In this section, we investigate the effect of position embeddings for the prediction layer of OneEE. We divide the arguments in the test set of FewFC into 6 groups according to their distance from corresponding triggers and report the recall scores of the model with and without position embeddings. As shown in Figure <ref type="figure">6</ref>, the AC recall declines as the distance between trigger and argument in an event go up. This indicates that it is more difficult for the model to detect roles correctly if the distance is longer in an event. Furthermore, the model with position embeddings outperforms another one without position embeddings, revealing that the relative distance information is beneficial for event extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Parameter Number &amp; Efficiency Comparisons</head><p>Table <ref type="table" target="#tab_6">5</ref> lists the stage numbers, parameter numbers, and inference speeds of two baselines and our model. For a fair comparison, all of these models are implemented using PyTorch and tested using the NVIDIA RTX 3090 GPU, where the batch size is set as 1. As seen, PLMEE has 2 times as many parameters as the other two models, due to the utilization of two BERT-based modules for each stage. Moreover, the inference speed of our model is about 3 times faster than that of PLMEE <ref type="bibr" target="#b38">(Yang et al., 2019)</ref> and 0.3 times faster than that of CasEE <ref type="bibr" target="#b29">(Sheng et al., 2021)</ref>, which verifies the efficiency of our model. Last but not least, when the batch size is set as 8, the inference speed of our model is 9.4 times as fast as that of PLMEE, which also demonstrates the advantage of our model, that is, it supports parallel inference. In one word, our model leverages fewer parameters but achieves better performance and faster inference speed.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Analysis of 4 Role Label Strategies</head><p>In this section, we investigate the effect of the role strategies for AC performance. As shown in Figure <ref type="figure" target="#fig_4">7</ref>, we introduce 4 different strategies to predict the role relation between trigger and argument: the role labels only exist in 1) trigger and argument head pairs (TH-AH), 2) trigger word and argument head pairs (TW-AH), 3) trigger head and argument word pairs (TH-AW), and 4) trigger and argument word pairs (TW-AW). The results of our model with 4 strategies are demonstrated in Figure <ref type="figure" target="#fig_6">8</ref>. We can learn that TW-AW achieves the best results against all other strategies on both FewFC and Genia11 datasets. It is largely due to that its labels are denser than other strategies. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">Analysis of the Event Number</head><p>We further investigate the effect of the event number for EE, and the results are shown in Figure <ref type="figure" target="#fig_7">9</ref>. We can observe that BERT-CRF-joint, PLMEE, and CasEE achieve similar performances on singleevent sentences, while CasEE outperforms PLMEE and BERT-CRF-joint on the sentences with multiple events. Most importantly, our system achieves the best results against all other baselines for different event numbers, indicating the advances of our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we propose a novel one-stage framework based on word-word relation recognition to address overlapped and nested EE concurrently. The relations between word pairs are pre-defined as the word-word relations within a trigger or argument and cross a trigger-argument pair. Moreover, we propose an efficient model that consists of an adaptive event fusion layer for integrating the target event representation, and a distance-aware prediction layer for identifying all kinds of relations jointly. Experimental results show that our proposed model achieves new SoTA results on three datasets and faster speed than the SoTA model. Through ablation studies, we find that the adaptive event fusion layer and distance-aware prediction layer are effective in improving the model performance. In future work, we will extend our method to other structured prediction tasks, such as structured sentiment analysis and overlapped entity relation extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Parallel Training with Sampling</head><p>We parallelly inject multiple target event type embeddings at the adaptive event fusion layer during training period, which results in huge computation resources. To this end, we use a subset E ? to replace E for each sample, where the number of E ? is K. It consists of one positive event type (the event type annotated in the sample) and K -1 negative event types selected randomly from the event types that does not appear in the sample. In other words, we inject K different event type embeddings into the gate module of Eq. 6 simultaneously. If there is no positive event type in the sample, we will select K negative event types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Decoding for Nested EE</head><p>HU induced a dose-dependent stimulation of c-jun synthesis. In the manuscript, we have already shown the decoding process of our model for overlapped EE in Section 4.5. Due to page limitation, we show an example of nested in Figure <ref type="figure" target="#fig_8">10</ref>(a). We also demonstrate its decoding process in Figure <ref type="figure" target="#fig_8">10(b)</ref>, which is the same as the overlapped EE decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Event: Positive Regulation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Analysis of the Event Sampling Number</head><p>To further analyze the effect of sampling number K and the sampling strategy, we also evaluate our model with positive and negative sampling and  random sampling and compare them with different sampling numbers. Figure <ref type="figure" target="#fig_10">11</ref> shows the TC F1 change trend as the number of sampling increases. As seen, both two models with 6 event type samplings achieve the best performance, compared with the other sampling numbers. Specifically, our model with one positive sampling and K -1 negative samplings outperforms the model with K randomly selected samplings when K is less than 7, which demonstrates that our sampling strategy is helpful for the model training.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples of three kinds of events, including a flat event (a), overlapped events (b), and nested events (c). Different event mentions are denoted in distinct colors. Triggers are marked with red boxes while arguments are underlined.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Two examples to illustrate our tagging scheme. We formalize the overlapping and nested EE as wordword relation recognition, where S-T and S-A denote the relations between the head and tail boundary words of a trigger or argument, and R-S, R-O, R-T, and R-P denote the relations between the trigger word and the argument words with the roles "subject", "object", "target" and "proportion".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Results for overlapped trigger (a) and argument (b) extraction on FewFC, and nested trigger (c), and argument (d) extraction on Genia11. Note that only the sentences that contain at least one such event are used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Four kinds of role label strategies. The goal is to predict the relation between trigger head and argument head (a), trigger word and argument head (b), trigger head and argument word (c), and trigger word and argument word (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Results of AC with different role label strategies on FewFC (a) and Genia11 (b) datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Results of different event numbers on FewFC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Example of nested event (a) and its decoding process (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Results on different sampling numbers of random sampling, and positive and negative sampling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Wang Yawei reduced shares in Sanju environmental protection.</head><label></label><figDesc></figDesc><table><row><cell cols="2">Event: Share Reduction</cell><cell></cell></row><row><cell>subject</cell><cell>trigger</cell><cell>object</cell></row><row><cell>Event: Investment</cell><cell></cell><cell></cell></row><row><cell></cell><cell>trigger</cell><cell></cell></row><row><cell cols="2">subject</cell><cell>object</cell></row><row><cell cols="2">Event: Share Transfer</cell><cell></cell></row></table><note><p>Citic Securities acquired 100% equity of Guangzhou Securities.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>... Encoder Layer Adaptive Event Fusion Layer Joint Prediction Layer</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>Target Event Type Embedding</cell><cell></cell></row><row><cell>Citic</cell><cell></cell><cell>...</cell><cell>Argument</cell></row><row><cell>Securities</cell><cell cols="2">Global Event Attention</cell><cell></cell></row><row><cell>acquired</cell><cell></cell><cell>Gate</cell><cell></cell></row><row><cell>100% equity</cell><cell>...</cell><cell>...</cell><cell>Trigger</cell></row><row><cell>of</cell><cell></cell><cell>Gate</cell><cell></cell></row><row><cell>Guangzhou</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Securities</cell><cell></cell><cell>Trigger/Argument Span Prediction</cell><cell>Trigger-Argument Role Prediction</cell></row><row><cell cols="4">Figure 3: The architecture of our framework. Given a target event type embedding e t of type t (e.g., transfer share),</cell></row><row><cell cols="4">the goal of our framework is to identify its triggers, arguments, and corresponding roles in the input sentence.</cell></row><row><cell cols="3">each severs for a role to detect the role-specific</cell><cell></cell></row><row><cell cols="3">argument spans but fails in solving trigger over-</cell><cell></cell></row><row><cell cols="3">lap. Except for pipeline methods, the latest attempt</cell><cell></cell></row><row><cell cols="3">dealing with overlapped EE is Sheng et al. (2021)</cell><cell></cell></row><row><cell cols="3">in a joint framework with cascade decoding. They</cell><cell></cell></row><row><cell cols="3">are the first to simultaneously tackle all the over-</cell><cell></cell></row><row><cell cols="3">lapping patterns. Sheng et al. (2021) sequentially</cell><cell></cell></row><row><cell cols="3">performs type detection, trigger extraction, and ar-</cell><cell></cell></row><row><cell cols="3">gument extraction, where the overlapped targets</cell><cell></cell></row><row><cell cols="3">are extracted separately conditioned on the specific</cell><cell></cell></row><row><cell cols="3">former prediction. Nevertheless, most of the multi-</cell><cell></cell></row><row><cell cols="3">stage methods suffer from error propagation.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the datasets. "Ovlp." and "Nest." denote the sentences with overlapped and nested events, respectively.</figDesc><table><row><cell cols="2">Transfer Share</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>S-A</cell><cell></cell><cell>S-T</cell><cell cols="2">S-A</cell><cell></cell><cell></cell><cell>S-A</cell></row><row><cell cols="9">Citic Securities acquired 100% equity of Guangzhou Securities</cell></row><row><cell>1</cell><cell>2</cell><cell>3</cell><cell cols="2">4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell></row><row><cell cols="2">8 Securities 8 Securities 3 acquired 1 Citic 2 Securities 4 100% 7 Guangzhou 3 acquired 1 Citic 2 Securities 4 100% 7 Guangzhou</cell><cell cols="2">8 Securities 8 Securities 8 Securities 1 Citic 1 Citic 1 Citic 2 Securities 2 Securities 2 Securities 4 100% 4 100% 4 100% 7 Guangzhou 7 Guangzhou 7 Guangzhou</cell><cell>R-S R-S R-S R-P R-P R-P R-T R-T R-T</cell><cell cols="2">3 acquired 3 acquired 3 acquired</cell><cell cols="2">Event Type: Transfer Share Trigger: acquired Argument: Subject: Citic Securities Proportion: 100% Securities Target: Guangzhou</cell></row><row><cell cols="9">Figure 4: A decoding case of our system with four steps.</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">#Ovlp. #Nest. #Sent. #Events</cell></row><row><cell></cell><cell></cell><cell>train</cell><cell cols="2">1,560</cell><cell>-</cell><cell></cell><cell>7,185</cell><cell>10,227</cell></row><row><cell>FewFC</cell><cell></cell><cell>dev</cell><cell>205</cell><cell></cell><cell>-</cell><cell></cell><cell>899</cell><cell>1,281</cell></row><row><cell></cell><cell></cell><cell>test</cell><cell>210</cell><cell></cell><cell>-</cell><cell></cell><cell>898</cell><cell>1,332</cell></row><row><cell></cell><cell></cell><cell>train</cell><cell>954</cell><cell></cell><cell cols="2">1,628</cell><cell>8,730</cell><cell>6,401</cell></row><row><cell>Genia11</cell><cell></cell><cell>dev</cell><cell>121</cell><cell></cell><cell>199</cell><cell></cell><cell>1,091</cell><cell>824</cell></row><row><cell></cell><cell></cell><cell>test</cell><cell>125</cell><cell></cell><cell>197</cell><cell></cell><cell>1,092</cell><cell>775</cell></row><row><cell></cell><cell></cell><cell>train</cell><cell>347</cell><cell></cell><cell>784</cell><cell></cell><cell>4,000</cell><cell>2,743</cell></row><row><cell>Genia13</cell><cell></cell><cell>dev</cell><cell>44</cell><cell></cell><cell>100</cell><cell></cell><cell>500</cell><cell>352</cell></row><row><cell></cell><cell></cell><cell>test</cell><cell>42</cell><cell></cell><cell>88</cell><cell></cell><cell>500</cell><cell>320</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Results for extracting all kinds of events on FewFC, where TI, TC, AI, AC denote trigger identification, trigger classification, argument identification, and argument classification, respectively. We run our model for 5 times with different random seeds and report the median values.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>TI(%)</cell><cell></cell><cell></cell><cell>TC(%)</cell><cell></cell><cell></cell><cell>AI(%)</cell><cell></cell><cell></cell><cell>AC(%)</cell></row><row><cell></cell><cell></cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell></cell><cell>BERT-softmax</cell><cell cols="11">89.8 79.0 84.0 80.2 61.8 69.8 74.6 62.8 68.2 72.5 60.2 65.8</cell></row><row><cell>Flat EE</cell><cell>BERT-CRF</cell><cell cols="11">90.8 80.8 85.5 81.7 63.6 71.5 75.1 64.3 69.3 72.9 61.8 66.9</cell></row><row><cell></cell><cell cols="12">BERT-CRF-joint 89.5 79.8 84.4 80.7 63.0 70.8 76.1 63.5 69.2 74.2 61.2 67.1</cell></row><row><cell>Ovlp. &amp; Nest. EE</cell><cell>PLMEE MQAEE CasEE</cell><cell cols="11">83.7 85.8 84.7 75.6 74.5 75.1 74.3 67.3 70.6 72.5 65.5 68.8 89.1 85.5 87.4 79.7 76.1 77.8 70.3 68.3 69.3 68.2 66.5 67.3 89.4 87.7 88.6 77.9 78.5 78.2 72.8 73.1 72.9 71.3 71.5 71.4</cell></row><row><cell>Ours</cell><cell>OneEE</cell><cell cols="11">88.7 88.7 88.7 79.1 80.3 79.7 75.4 77.0 76.2 74.0 72.9 73.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Ablation studies using FewFC.</figDesc><table><row><cell></cell><cell cols="4">TI(%) TC(%) AI(%) AC(%)</cell></row><row><cell>OneEE</cell><cell>88.7</cell><cell>79.7</cell><cell>76.2</cell><cell>73.4</cell></row><row><cell>w/o Attention</cell><cell>88.3</cell><cell>79.5</cell><cell>75.9</cell><cell>72.8</cell></row><row><cell>w/o Gate</cell><cell>88.4</cell><cell>79.3</cell><cell>75.3</cell><cell>72.6</cell></row><row><cell>w/o Fusion Layer</cell><cell>88.0</cell><cell>78.7</cell><cell>75.2</cell><cell>72.2</cell></row><row><cell>w/o Position Emb.</cell><cell>88.1</cell><cell>78.7</cell><cell>74.1</cell><cell>71.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Parameter number and inference speed comparisons on FewFC. All models are tested with batch size 1, ? denotes that the model is tested with batch size 8. The ratio denotes the multiple of the speed increase with regard to PLMEE.</figDesc><table><row><cell></cell><cell>75</cell><cell></cell><cell></cell><cell></cell></row><row><cell>AC Recall (%)</cell><cell>65 70</cell><cell cols="2">OneEE w/o Pos. OneEE</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="4">1-10 11-20 21-30 31-40 41-50 &gt;50</cell></row><row><cell></cell><cell></cell><cell cols="4">Distances Between Triggers and Arguments</cell></row><row><cell cols="6">Figure 6: FewFC results of extracting triggers and argu-</cell></row><row><cell cols="6">ments with different distances. The red line denotes that</cell></row><row><cell cols="6">position embeddings are used while the blue line not.</cell></row><row><cell cols="2">Model</cell><cell cols="4">Stage #Param. Speed (sent/s) Ratio</cell></row><row><cell cols="2">PLMEE</cell><cell>Two</cell><cell>204.6M</cell><cell>19.8</cell><cell>?1.0</cell></row><row><cell cols="2">CasEE</cell><cell cols="2">Three 120.7M</cell><cell>62.3</cell><cell>?3.1</cell></row><row><cell cols="2">OneEE</cell><cell>One</cell><cell>114.2M</cell><cell>79.4</cell><cell>?4.0</cell></row><row><cell cols="2">OneEE  ?</cell><cell>One</cell><cell>114.2M</cell><cell>186.5</cell><cell>?9.4</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Note that if two pairs with the same span relation clash in the boundaries, the pair with higher score will be selected.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work is supported by the <rs type="funder">National Natural Science Foundation of China</rs> (No. <rs type="grantNumber">62176187</rs>), the <rs type="funder">National Key Research and Development Program of China</rs> (No. <rs type="grantNumber">2017YFC1200500</rs>), the <rs type="funder">Research Foundation of Ministry of Education of China</rs> (No. <rs type="grantNumber">18JZD015</rs>), the <rs type="funder">Youth Fund for Humanities and Social Science Research of Ministry of Education of China</rs> (No. <rs type="grantNumber">22YJCZH064</rs>), the <rs type="funder">General Project of Natural Science Foundation of Hubei Province</rs> (No.<rs type="grantNumber">2021CFB385</rs>). L Zhao would like to thank the support from <rs type="funder">Center for Artificial Intelligence</rs> (<rs type="grantNumber">C4AI-USP</rs>), the <rs type="funder">Sao Paulo Research Foundation</rs> (<rs type="funder">FAPESP</rs> grant #<rs type="grantNumber">2019/07665-4</rs>), the <rs type="funder">IBM Corporation</rs>, and <rs type="person">China Branch</rs> of <rs type="affiliation">BRICS Institute of Future Networks</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_8fERUR4">
					<idno type="grant-number">62176187</idno>
				</org>
				<org type="funding" xml:id="_HWDW4ZS">
					<idno type="grant-number">2017YFC1200500</idno>
				</org>
				<org type="funding" xml:id="_M4Kxjbp">
					<idno type="grant-number">18JZD015</idno>
				</org>
				<org type="funding" xml:id="_fbyWpd4">
					<idno type="grant-number">22YJCZH064</idno>
				</org>
				<org type="funding" xml:id="_7DgZ84Q">
					<idno type="grant-number">2021CFB385</idno>
				</org>
				<org type="funding" xml:id="_NKdJXF9">
					<idno type="grant-number">C4AI-USP</idno>
				</org>
				<org type="funding" xml:id="_66qEFBM">
					<idno type="grant-number">2019/07665-4</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dynamic neuro-symbolic knowledge graph construction for zero-shot commonsense question answering</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Le Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4923" to="4931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Event extraction via dynamic multipooling convolutional neural networks</title>
		<author>
			<persName><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="167" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Event extraction by answering (almost) natural questions</title>
		<author>
			<persName><forename type="first">Xinya</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="671" to="683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">2021a. Rethinking boundaries: Endto-end recognition of discontinuous mentions with pointer networks</title>
		<author>
			<persName><forename type="first">Donghong</forename><surname>Hao Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bobo</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yijiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yafeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="page" from="12785" to="12793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">2021b. Encoder-decoder based unified semantic role labeling with label-aware syntax</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Hao Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bobo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="page" from="12794" to="12802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">2022a. Global inference with explicit syntactic and discourse structures for dialogue-level relation extraction</title>
		<author>
			<persName><forename type="first">Jingye</forename><surname>Hao Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengqiong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenliang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI</title>
		<meeting>the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI</meeting>
		<imprint>
			<biblScope unit="page" from="4082" to="4088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Boundaries and edges rethinking: An end-to-end neural model for overlapping entity relation extraction</title>
		<author>
			<persName><forename type="first">Yafeng</forename><surname>Hao Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghong</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">102311</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Matching structure for dual learning</title>
		<author>
			<persName><forename type="first">Shengqiong</forename><surname>Hao Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yafeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meishan</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning, ICML</title>
		<meeting>the International Conference on Machine Learning, ICML</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6373" to="6391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Yafeng Ren, and Donghong Ji. 2022c. Conversational semantic role labeling with predicate-oriented latent graph</title>
		<author>
			<persName><forename type="first">Shengqiong</forename><surname>Hao Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meishan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI</title>
		<meeting>the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI</meeting>
		<imprint>
			<biblScope unit="page" from="4089" to="4095" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cross-lingual semantic role labeling with highquality translated training corpus</title>
		<author>
			<persName><forename type="first">Meishan</forename><surname>Hao Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7014" to="7026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">2021c. End-to-end semantic role labeling with neural transition-based model</title>
		<author>
			<persName><forename type="first">Meishan</forename><surname>Hao Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bobo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="page" from="12803" to="12811" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Investigating LSTMs for joint extraction of opinion entities and relations</title>
		<author>
			<persName><forename type="first">Arzoo</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="919" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Overview of genia event task in bionlp shared task 2011</title>
		<author>
			<persName><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toshihisa</forename><surname>Takagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akinori</forename><surname>Yonezawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of BioNLP shared task 2011 workshop</title>
		<meeting>BioNLP shared task 2011 workshop</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="7" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The genia event extraction shared task, 2013 edition-overview</title>
		<author>
			<persName><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yamamoto</forename><surname>Yasunori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the BioNLP Shared Task 2013 Workshop</title>
		<meeting>the BioNLP Shared Task 2013 Workshop</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="8" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Biobert: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wonjin</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghyeon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunkyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">So</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1234" to="1240" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Event extraction as multi-turn question answering</title>
		<author>
			<persName><forename type="first">Fayuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yajuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (Fingdings)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (Fingdings)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="829" to="838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">2021a. A span-based model for joint overlapped and discontinuous named entity recognition</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghong</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<biblScope unit="page" from="4814" to="4828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unified named entity recognition as wordword relation classification</title>
		<author>
			<persName><forename type="first">Jingye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengqiong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10965" to="10973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Yafeng Ren, and Donghong Ji. 2021b. MRN: A locally and globally mention-based reasoning network for document-level relation extraction</title>
		<author>
			<persName><forename type="first">Jingye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<biblScope unit="page" from="1359" to="1370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Joint event extraction via structured prediction with global features</title>
		<author>
			<persName><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Jointly multiple events extraction via attention-based graph information aggregation</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhunchen</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">He-Yan</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1247" to="1256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">End-to-end relation extraction using LSTMs on sequences and tree structures</title>
		<author>
			<persName><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1105" to="1116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A method for integrating and ranking the evidence for biochemical pathways by mining reactions from text</title>
		<author>
			<persName><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafal</forename><surname>Rak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Rowley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><forename type="middle">B</forename><surname>Kell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="44" to="52" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Joint event extraction via recurrent neural networks</title>
		<author>
			<persName><forename type="first">Thien</forename><surname>Huu Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the North American Chapter</title>
		<meeting>the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="300" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">One for all: Neural joint modeling of entities and events</title>
		<author>
			<persName><forename type="first">Minh</forename><surname>Trung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thien</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><surname>Huu Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6851" to="6858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An automated framework for incorporating news into stock trading strategies</title>
		<author>
			<persName><forename type="first">Wijnand</forename><surname>Nuij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viorel</forename><surname>Milea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederik</forename><surname>Hogenboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Flavius</forename><surname>Frasincar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uzay</forename><surname>Kaymak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TKDE</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="823" to="835" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Jointly extracting event triggers and arguments by dependency-bridge rnn and tensor-based argument interaction</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5916" to="5923" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Casee: A joint learning framework with cascade decoding for overlapping event extraction</title>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Hei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingwen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongbo</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (Findings)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (Findings)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="164" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Roformer: Enhanced transformer with rotary position embedding</title>
		<author>
			<persName><forename type="first">Jianlin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengfeng</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunfeng</forename><surname>Liu</surname></persName>
		</author>
		<idno>CoRR, abs/2104.09864</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Circle loss: A unified perspective of pair similarity optimization</title>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changmao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongdao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6397" to="6406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NeurIPS</title>
		<meeting>of NeurIPS</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Tplinker: Single-stage joint extraction of entities and relations through token pair linking</title>
		<author>
			<persName><forename type="first">Yucheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yueyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingwen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongsong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Limin</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Linguistics</title>
		<meeting>the International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1572" to="1582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Discontinuous named entity recognition as maximal clique discovery</title>
		<author>
			<persName><forename type="first">Yucheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongsong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingwen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Limin</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="764" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Neural multimodal cooperative learning toward micro-video understanding</title>
		<author>
			<persName><forename type="first">Yinwei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weili</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Mmgcn: Multi-modal graph convolution network for personalized recommendation of micro-video</title>
		<author>
			<persName><forename type="first">Yinwei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richang</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Multimedia</title>
		<meeting>the 27th ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1437" to="1445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Grid tagging scheme for end-to-end fine-grained opinion extraction</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengcan</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (Findings)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (Findings)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2576" to="2585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Exploring pre-trained language models for event extraction and generation</title>
		<author>
			<persName><forename type="first">Sen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linbo</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhigang</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5284" to="5294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Joint extraction of entities and relations based on a novel tagging scheme</title>
		<author>
			<persName><forename type="first">Suncong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexing</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1227" to="1236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">What the role is vs. what plays the role: Semi-supervised event argument extraction via dual question answering</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiexin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinlong</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="14638" to="14646" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
