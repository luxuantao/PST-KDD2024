<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scalable Effort Hardware Design: Exploiting Algorithmic Resilience for Energy Efficiency</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Vinay</forename><forename type="middle">K</forename><surname>Chippa</surname></persName>
							<email>vchipp@purdue.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Purdue University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Debabrata</forename><surname>Mohapatra</surname></persName>
							<email>dmohapat@purdue.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Purdue University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anand</forename><surname>Raghunathan</surname></persName>
							<email>raghunathan@purdue.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Purdue University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kaushik</forename><surname>Roy</surname></persName>
							<email>kaushik@purdue.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Purdue University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Srimat</forename><forename type="middle">T</forename><surname>Chakradhar</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Systems Architecture Department</orgName>
								<orgName type="institution">NEC Laboratories America</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Scalable Effort Hardware Design: Exploiting Algorithmic Resilience for Energy Efficiency</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EA64A5376D9F314F14A34C30BB95338D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>VLSI (Very large scale integration) Scalable Effort</term>
					<term>Approximate Computing</term>
					<term>Low Power Design</term>
					<term>Support Vector Machines</term>
					<term>Recognition</term>
					<term>Mining</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Algorithms from several interesting application domains exhibit the property of inherent resilience to "errors" from extrinsic or intrinsic sources, offering entirely new avenues for performance and power optimization by relaxing the conventional requirement of exact (numerical or Boolean) equivalence between the specification and hardware implementation.</p><p>We propose scalable effort hardware design as an approach to tap the reservoir of algorithmic resilience and translate it into highly efficient hardware implementations The basic tenet of the scalable effort design approach is to identify mechanisms at each level of design abstraction (circuit, architecture and algorithm) that can be used to vary the computational effort expended towards generation of the correct (exact) result, and expose them as control knobs in the implementation. These scaling mechanisms can be utilized to achieve improved energy efficiency while maintaining an acceptable (and often, near identical) level of quality of the overall result. A second major tenet of the scalable effort design approach is that fully exploiting the potential of algorithmic resilience requires synergistic cross-layer optimization of scaling mechanisms identified at different levels of design abstraction.</p><p>We have implemented an energy-efficient SVM classification chip based on the proposed scalable effort design approach. We present results from post-layout simulations and demonstrate that scalable effort hardware can achieve large energy reductions (1.2X-2.2X with no impact on classification accuracy, and 2.2X-4.1X with modest reductions in accuracy) across various sets. Our results also establish that cross-layer optimization leads to much improved energy vs. quality tradeoffs compared to each of the individual techniques.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Several application domains that are of growing interest in general-purpose and embedded computing, such as Recognition and Data Mining <ref type="bibr" target="#b1">[1]</ref>, exhibit the interesting property of high inherent algorithmic resilience to "errors" from both extrinsic and intrinsic sources. This resilience can be attributed to several factors <ref type="bibr" target="#b2">[2]</ref>. These algorithms are designed to process large amounts of input data that has significant redundancy and may frequently contain significant imperfections or noise. The algorithms themselves are often statistical and aggregative, implying that errors can easily get averaged down or averaged out. The algorithms typically use iterative, successive refinement techniques, which imparts them with a self-healing nature since subsequent iterations may correct errors introduced in previous iterations. Frequently, these algorithms do not have a single golden result; instead, they may produce any one of multiple solutions that are equally acceptable (e.g., a training algorithm that is fed the same data set in a different order may produce a different but equivalent model). Finally, the usage model of these algorithms is such that the user is conditioned to accept less-than-perfect results (even the best known algorithm does not achieve 100% accuracy).</p><p>Hardware implementations of inherently resilient algorithms offer entirely new avenues for performance and power optimization by relaxing the conventional requirement of exact (numerical or Boolean) equivalence between the specification and implementation. While several approaches to leveraging algorithmic resilience in both software and hardware implementations have been recently proposed and shown significant promise <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b4">4,</ref><ref type="bibr" target="#b5">5,</ref><ref type="bibr" target="#b6">6,</ref><ref type="bibr" target="#b7">7]</ref>, we believe that fully exploiting the "reservoir of resilience" requires a systematic design approach.</p><p>In this work we propose one such systematic approach wherein the notion of scalable effort is embodied into the design process at different layers (or levels of abstraction). We demonstrate this approach through the design of an energyefficient scalable-effort hardware implementation for Support Vector Machines, a popular Machine Learning algorithm. Scalable effort hardware design involves (i) identifying mechanisms at each level of abstraction that can be used to vary the effort expended by the hardware in order to accurately implement the computations in the algorithm, and (ii) exposing them as control knobs that can be used (after fabrication) to achieve energy efficiency while maintaining acceptable overall quality of the result. At the circuit-level, we utilize voltage over-scaling as a mechanism to control the effort expended in order to correctly compute the outputs of computational blocks within the clock period, thereby trading accuracy of the result for the energy consumed to compute it. At the architecture level, we utilize dynamic precision control as the mechanism to vary the computational effort expended. Finally, at the algorithm level, we utilize significance-driven algorithmic truncation in order to achieve an energy vs. accuracy tradeoff. While each of these knobs has significant and interesting effects, we demonstrate that much greater gains can be achieved by synergistically co-optimizing across the different levels.</p><p>We have implemented an energy-efficient SVM classification chip based on the scalable effort design approach. We present a wide range of experimental results from post-layout simulations, demonstrating that scalable effort design achieves significant reductions in energy compared to conventional implementations (1.2X-2X with no loss in classification accuracy, and 2.2X-4.1X with a moderate loss in classification accuracy). We also establish the benefits of a layered approach to scalable effort design and and cross-layer optimization of the control knobs that govern the efficiency vs. accuracy tradeoff. We believe that the proposed approach has potential to significantly extend the performance and energy-efficiency of hardware implementations of algorithms in various existing and emerging application domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">MOTIVATION</head><p>The motivation for our work stems from the observation that algorithms in application domains such as recognition and mining possess a very high degree of resilience to "errors" from both extrinsic and intrinsic sources. The above observation naturally leads to the question of whether the hardware implementations of these algorithms need to be "perfect"? Specifically, do the hardware implementations of these algorithms need to maintain exact (numerical or Boolean) equivalence to their specification? We suggest that the answer to these questions is no, and address the problem of how to utilize the inherent algorithmic resilience so as to achieve maximum savings in energy consumption.</p><p>In order to empirically illustrate the algorithmic resilience described above, we consider Support Vector Machines <ref type="bibr" target="#b8">[8]</ref>, one of the most popularly used Machine Learning algorithms. We focus on SVM-based classification of handwritten digit images from the MNIST database <ref type="bibr">[9]</ref>. The SVM classification almost entirely consists of dot-product computations, which can be expressed as MAC operations. In order to emulate the effect of an "imperfect" hardware implementation, we injected random errors in the outputs of each of the MAC operations performed in the SVM classification algorithm<ref type="foot" target="#foot_0">1</ref> and evaluated the impact on the classification accuracy. The results are presented in Figure <ref type="figure" target="#fig_1">1</ref>. The x-axis represents the rate of error injection, and the different curves correspond to different experiments where the errors were restricted to different ranges of least significant bits (within the accumulated result of each MAC operation). It can be seen that, when errors are injected in the 15 LSBs (even with a 100% probability), they do not have any impact on the final classification accuracy. Similarly injecting errors with probabilities of 10 -6 in upto 28 of the 32 bits has negligible impact on classification accuracy. These results suggest that hardware design techniques that trade off the accuracy of the computations for energy savings are worth investigating.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RELATED WORK</head><p>A significant body of previous work shares the philosophy of exploiting the inherent resilience of algorithms in certain application domains to achieve various benefits. In this section, we acknowledge and describe the closely related efforts that have inspired our own, and place our contributions in their context.</p><p>The use of imperfect or unreliable components in computing has a long history and can be traced back to the work of Von Neumann <ref type="bibr" target="#b10">[10]</ref>, which proposed a model for computation using unreliable components. In his work on adaptive computers <ref type="bibr" target="#b11">[11]</ref>, Breuer proposed graceful degradation as a mechanism to deal with component failures. Over two decades later, the use of imprecise computation was explored to achieve improved performance in the context of real-time systems <ref type="bibr" target="#b12">[12]</ref>.</p><p>ANT (Algorithmic Noise Tolerance) <ref type="bibr" target="#b5">[5]</ref> was one of the earliest proposals to leverage the inherent error resilience of algorithms in the context of hardware implementation, and aimed to achieve both energy efficiency and tolerance to deep submicron noise. Subsequent efforts proposed variants of this basic approach, and applied it to signal, image, and video processing algorithms <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b15">15]</ref>.</p><p>The concept of Probabilistic CMOS or PCMOS, wherein each transistor and logic gate displays a probabilistic rather than deterministic behavior, was proposed as an energyefficient alternative to traditional always-correct computational models <ref type="bibr" target="#b16">[16]</ref>. This has led to a significant body of research on probabilistic and approximate computation, which is summarized in <ref type="bibr" target="#b4">[4]</ref>.</p><p>The concept of utilizing the inherent resilience of multimedia applications to tolerate defects and improve fabrication yields was proposed in <ref type="bibr" target="#b17">[17]</ref>, and led to new approaches to manufacturing test <ref type="bibr" target="#b18">[18]</ref>.</p><p>Other recent efforts have exploited algorithmic error resilience for process variation tolerance and low power design through the use of design techniques such as significance driven computation <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b19">19]</ref>.</p><p>ERSA (Error Resilient System Architecture) <ref type="bibr" target="#b7">[7]</ref> is a programmable multi-core architecture for deeply scaled technologies with unreliable components, that combines one reliable processor core with a large number of unreliable cores. ERSA exploits the inherent error resilience of probabilistic applications, which overlap with the domains considered in our work.</p><p>We have used Support Vector Machines <ref type="bibr" target="#b8">[8]</ref>, one of the most widely used machine learning algorithms, as a vehicle to demonstrate our concepts. Various hardware implementations of Support Vector Machines <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b21">21]</ref> have been optimized for either performance or area, but the error resiliency of the algorithm has not been fully explored.</p><p>The term scalable effort was inspired by the work on best effort computing <ref type="bibr" target="#b2">[2]</ref>, where error resiliency has been used to achieve parallel scalability of software implementations on multi-core computing platforms <ref type="bibr" target="#b3">[3]</ref>. Furthermore, the basic SVM architecture used in our work was inspired by the MAPLE parallel architecture <ref type="bibr" target="#b22">[22]</ref>, where an array of variable precision processing elements were utilized to achieve high performance with relatively low power consumption.</p><p>The primary contribution of this work is a systematic design approach for hardware implementation of algorithms that exhibit high levels of inherent resilience. Unlike previous efforts that only focus on one dimension (e.g., voltage overscaling), the scalable effort approach espouses synergistic scaling along multiple dimensions that correspond to different levels of design abstraction (circuit, micro-architecture, and algorithm). This leads to higher energy savings through better utilization of the reservoir of algorithmic resilience, as borne out by the experimental results presented in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">BACKGROUND</head><p>Support Vector Machines (SVMs), a family of algorithms for supervised learning, are widely used for applications 556 33.3 that require classification (where data must be classified into a number of pre-determined categories) and regression (where a model is built to capture the relationship between a dependent variable and one or more independent variables) <ref type="foot" target="#foot_1">2</ref> . In classification, given a labeled training data set (each data point is a multi-dimensional vector of features), the SVM training algorithm is used to generate a hyperplane in the feature space that distinguishes the classes with maximal separation (see Figure <ref type="figure" target="#fig_2">2</ref>). The hyperplane is fully specified by a subset of the training data that are called the support vectors. Once the hyperplane is generated, any unlabeled datum can be assigned a label based on it's position relative to the hyperplane. Generation of the hyperplane from the labeled data is called training and assigning a label to a new data point is called testing <ref type="foot" target="#foot_2">3</ref> .</p><p>The computation performed for classifying a new unlabeled data point is given by Label = sign(</p><formula xml:id="formula_0">N X i=1 Kernel( x. svi) * αi * yi -b)<label>(1)</label></formula><p>where x is a vector representing the data to be classified, svi is the i-th support vector, b is the offset and αi and yi are the Lagrangian coefficient (computed during training) and the label of the i-th support vector, respectively. Kernel is a non-linear function that greatly enhances the capability of SVMs by enabling the construction of non-linear classifiers. svi, αi and b values are generated by the SVM training algorithm, details of which can be found in <ref type="bibr" target="#b8">[8]</ref>. SVMs are used in a wide range of applications involving image and video analysis (e.g., face or object detection, handwriting recognition, content-based image retrieval, speech recognition), and have demonstrated great promise in several other application domains [23].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">SCALABLE EFFORT HARDWARE FOR SVM CLASSIFICATION</head><p>In this section, we describe the scalable effort design approach and illustrate it through application to SVM classification. In a broad sense, scalable effort hardware provides mechanisms to modulate the effort expended in performing the computations that constitute the algorithm. The specific definition of effort varies depending on the level of design abstraction at which it is modulated. We next briefly describe the overall design of the SVM classification chip and detail how the principles of scalable effort design were applied at the circuit, architecture, and algorithm levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Overview</head><p>Figure <ref type="figure" target="#fig_3">3</ref> presents a dedicated hardware architecture for SVM classification. We used a systolic array architecture (similar to <ref type="bibr" target="#b22">[22]</ref>) to implement the computation of dot products between support vectors and test vectors, which dominates the workload of SVM classification. From Equation  The architecture consists of two arrays of FIFOs from which data is streamed to a 2-dimensional array of MAC units. The support vectors and test vectors are pushed into their respective FIFO's. Support vectors are streamed from top to bottom, and test vectors are streamed from left to right, through the MAC array. Each MAC unit computes the dot product between a unique (support vector, test vector) pair by processing one dimension per cycle in the nominal case and accumulating the result. Once the dot product operation is complete, the dot product values are read out in a raster scan order by the host processor, which takes this data and performs the remaining computation required to compute the label.</p><p>We would like to mention that our focus in this work is not on the base architecture itself; rather, we focus on the application of scalable effort at different levels of abstraction to this architecture. The effort expended by the SVM classification hardware can be scaled at the circuit, architecture, and algorithm levels. The proposed design has provisions to scale the effort at all these levels, each of which is described in detail in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Algorithm Level Scaling</head><p>At the algorithm level, we identify parameters that control the amount of computation performed and vary them to tradeoff decreased computational complexity for the quality of the result. Rather than indiscriminately eliminate computations, we prioritize computations based on their likely impact on the quality of the result to achieve a better tradeoff.</p><p>In the case of Support Vector Machines, our analysis in Section 5.1 shows that the complexity depends upon both N and d, i.e., the number of support vectors and the number of features per vector. Figure <ref type="figure" target="#fig_4">4</ref> depicts the dot product operations involved in SVM classification in matrix form and illustrates how the scaling is performed along these two dimensions. In order to achieve the best accuracy vs. energy tradeoff, support vectors are considered in the order of their significance. One way of quantifying the significance of sup-557 33.3 port vectors is based on the values of αi (Lagrangian coefficients that are computed during training). This approach can be further extended using the concept of RSVMs <ref type="bibr" target="#b23">[24]</ref>, where training is adapted to generate support vector sets of different sizes, from which we choose during testing. If the features are arranged in the order of their importance, the dot product can be computed in that order and the computation can be stopped at any point to get an approximate output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Architecture Level Scaling</head><p>At the architecture level, we scale effort by scaling the precision with which the variables of the algorithm are represented and the corresponding operations are performed. The variables can be the inputs of the algorithm, like the test vectors and α, or they can be the intermediate values like outputs of the multiplier and the accumulator. The number of bits needed to represent variables varies from data set to data set. In context of SVM's, the effect of precision scaling has been studied in <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b22">22]</ref>. In this section, we explain different methods of realizing precision scaling. However our focus is on translating precision scaling into energy efficiency, and combining this with other scalable effort mechanisms to maximize the overall energy efficiency of the SVM computation. The simplest approach to precision scaling at the architecture level is to utilize only a sub-set of the data path and shut down the rest for energy efficiency. While this approach saves energy, the hardware that is shut down is unutilized. Whenever possible, it is preferable to pack multiple data points into a single word and use the same hardware to process multiple data at the same time (similar to SIMD instructions in modern processors), simultaneously increasing the overall throughput and energy efficiency of the system. Multi-precision operation can be achieved in two ways -with segmented units that incur some hardware overhead, or through suitable data packing with padding (at virtually no hardware overhead).</p><p>Figure <ref type="figure" target="#fig_5">5</ref>(a) shows the block diagram of a segmented MAC unit that supports multi-precision operation. In this case, the multiplier needs to be able to operate differently for different precision levels. For an architecture supporting 24 bit input data, we can pack one 16 bit, three 8 bit or six 4 bit data types into a single input. We improve the throughput in this case at the cost of some hardware overhead.</p><p>Figure <ref type="figure" target="#fig_5">5</ref>(b) shows the block diagram of a MAC unit implementing padding, which requires only minimal amount of control logic on top of the regular MAC. Multiple data are packed into a single word with sufficient padding of '0's, such that the middle bits of the multiplier output are 0 and the accumulator never sees carry propagation across the boundaries separating the distinct results in the output. In other words, the guard bits ensure that the two MAC operations do not interfere with each other. For a data path that supports 24-bit input words, we can pack one 16 bit, two 8 bit or two 4 bit data. In this case, we are under-utilizing the hardware (due to the padding bits) but require almost no hardware overhead.</p><p>In both the aforementioned methods, there are cases where we will not utilize the hardware completely and it would be advantageous to shut down the parts of the circuit that are not being used. Therefore, we have implemented power gating, where we connect groups of bit lines of the data path to different voltage domains, each of which can be turned off independently using sleep transistors. Figure <ref type="figure" target="#fig_5">5(c</ref>) illustrates this concept.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Circuit Level Scaling</head><p>At the circuit level, scalable effort is synonymous with voltage over-scaling. Voltage over-scaling differs from traditional voltage scaling in that we do not scale the clock frequency, thereby intentionally causing the critical paths to violate the clock period. We do not have to take strict corrective measures to preserve the accuracy of computation as the applications that we consider are inherently error resilient. Such implementations can be categorized under the approximate arithmetic paradigm which is an active area of research <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b6">6,</ref><ref type="bibr" target="#b13">13]</ref>. In order to perform approximate computing at the circuit level, we visualize computations in terms of "meta" operations, which in the case of SVM is the dot product. Scalable effort at the circuit level essentially translates into a dot product value whose accuracy scales with the degree of voltage over-scaling. While any given implementation can be subject to voltage over-scaling, appropriate design techniques need to be used in order to obtain a better energy vs. accuracy tradeoff.  Figure <ref type="figure" target="#fig_7">6</ref> shows the design of a voltage scalable MAC for dot product computation. At an atomic level the MAC unit consists of partial product generator followed by a merge adder and an accumulator. In order to implement a scalable effort MAC, we apply a segmentation based technique to the adders in the MAC hardware. The technique involves segmenting the adder into smaller bit width adders. The point of segmentation can be adaptively controlled based on the de-gree of voltage scaling. This serves two primary purposes: a) reduces critical path of the adder, allowing aggressive voltage scaling at the cost of approximation and b) prevents harmful glitch propagation across the adder from arbitrarily corrupting the MSB bits. However, application of the standalone segmentation technique incurs significant error in the dot product due to its accumulative nature over multiple cycles. We address this issue by introducing a low overhead correction circuit that keeps track of the carries across sections of the segmented adder that have been ignored in each cycle by means of small bit width counters. In the event of overflow in any one of the carry counters, a correction term is added to adjust the accumulator value based on these counter outputs. It is to be noted that even though this adds few extra cycles to the dot product computation, it can be ignored for practical purposes since the feature size of data (number of MAC cycles for one dot product computation) is typically large. The scalable effort MAC incorporating segmentation with error correction scheme incurs roughly 25% area overhead. However, this area overhead, due to the MAC, is significantly amortized over the entire SVM design and can be considered negligible. Another important design issue is determining the group size k during segmentation. Higher degree of segmentation (higher k) implies greater opportunity for VOS due to critical path reduction, at the expense of greater area and power overhead due to the carry correction counters. Hence, a judicious approach needs to be taken while determining the group size during segmentation. In our design k=n/4 was used to achieve a balanced tradeoff between the degree of VOS and the overhead incurred.</p><p>Techniques such as segmentation augmented by correction term addition are independent of the underlying adder and multiplier architectures and hence can be applied to other algorithms involving these basic arithmetic operations. Moreover, the proposed segmentation technique is distinct from pure truncation in the sense that we utilize all the input bits in computing the result as opposed to discarding some of them, thereby achieving higher accuracy. In order to demonstrate the proposed design approach, we realised a scalable effort hardware implementation of SVM classification, and evaluated it for energy consumption and accuracy on various data sets. We have implemented the full layout in two different process technologies -IBM 90nm and 45nm. The 45nm technology implementation has been taped out but the chips are not available as of this time, hence we present results based on post-layout simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPERIMENTAL METHODOLOGY</head><p>The layout of the hardware is presented in figure <ref type="figure" target="#fig_8">7</ref>. The design flow used for our implementation consists of Synopsys Design Compiler <ref type="bibr" target="#b24">[25]</ref> for logic synthesis and Cadence SOC Encounter [26] for physical design. The parasitics annotated net list extracted from the layout was used for power simulations using the Synopsys Nanosim <ref type="bibr" target="#b25">[27]</ref> switch-level simulator.</p><p>Since circuit level simulations for large data sets and numerous combinations of circuit, micro-architecture, and algorithmic scaling "levels" requires unacceptable simulation times, we used software simulations (on large traces) to obtain classification accuracy and hardware simulations (for smaller representative traces) to obtain energy values.</p><p>We used the MILDE framework from NEC Labs, Princeton to perform software simulations <ref type="bibr" target="#b26">[28]</ref>. The data sets used for validation are explained in detail in Table <ref type="table" target="#tab_1">1</ref>. Reflecting the effects of the different scaling mechanisms in the software simulations required us to perform careful modeling as explained below. To obtain the accuracy values for different voltage levels, we characterized the MAC for different voltage levels to construct functional models, and used these functional models in software. These models break down the MAC operation into the bit-level and reflect the impact of segmentation and limited carry propagation on the computed result. To obtain accuracy values of the algorithm for different precision levels, the LSB bits of the variables in the software were truncated before/after the appropriate computations. For algorithm level scaling, The SVM implementation in MiLDe was modified to consider only Support Vectors with α values greater than a pre-specified threshold during classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">RESULTS</head><p>In this section, we present results that demonstrate the potential of scalable effort hardware design. Scalable effort hardware can be characterized by the energy vs. accuracy trade off curve that it can achieve. We first report the overall energy savings that were obtained through scalable-effort hardware at different levels of accuracy. Next, we compare the cross-layer optimization of scaling mechanisms vs. the application of individual techniques. Figure <ref type="figure" target="#fig_9">8</ref> shows the normalized energy consumption at different accuracy levels for several data sets. Energy is normalized to the base case in which no scaling techniques are applied <ref type="foot" target="#foot_3">4</ref> . We are able to obtain 1.2X-2.2X energy savings without any significant loss of accuracy. If a minimal loss of 5% in classification accuracy is acceptable, energy savings of 1.6X-3X are possible. For moderate accuracy loss of 15%, the energy savings grow to 2.2X-4.1X.</p><p>Figure <ref type="figure">9</ref> illustrates the benefits of cross layer optimization in scalable effort design. Significantly improved energy vs. quality trade offs were obtained by utilizing the optimal combinations of all the scaling mechanisms as compared  to the application of individual scaling techniques. Figure <ref type="figure">9</ref> shows the tradeoffs for the MNIST data set. To evaluate a qualitatively different data set, we also obtained accuracy vs. energy trade offs for the artificially generated Checkerboard data set and present the results in Figure <ref type="figure" target="#fig_11">10</ref>. These results reinforce our initial claim that cross layer optimization has considerably greater potential to tap into the reservoir of algorithmic resilience and can achieve significantly improved energy-accuracy trade offs over uni-dimensional approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">SUMMARY AND CONCLUSIONS</head><p>We presented a new systematic approach based on the concept of scalable effort hardware, for the design of efficient hardware implementations for algorithms that demonstrate inherent error resilience. Scalable effort design is based on the identification of mechanisms at each level of design abstraction (circuit, architecture and algorithm) that can be used to vary the computational effort expended towards generation of the correct (exact) result. These mechanisms can be utilized to achieve improved energy efficiency (or performance) while maintaining an acceptable level of quality of the overall result. While each of these knobs has significant impact, we demonstrated that much greater gains can be achieved through synergistic cross-layer optimization.</p><p>Although we have focused on a representative and popular Machine Learning algorithm, namely Support Vector Machines, we believe that the proposed concepts are general and can be applied to realize high-performance or energyefficient implementations of a wide range of Recognition and Data Mining algorithms. Our focus on these application domains is fueled by our belief that the constituent algorithms have unsurpassed levels of algorithmic error resilience. However, the property of error resilience (and therefore our design approach) also applies to traditional application domains such as DSP and multi-media (image/audio/video) process-ing, which have largely been the focus of related work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The accuracy of SVM classification for handwritten digit recognition in the presence of errors in the computations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustration of SVMbased classification (Source: Wikipedia)</figDesc><graphic coords="3,70.02,99.02,111.40,119.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Block diagram of SVM architecture we can see that with N support vectors and a feature size of d, classifying a single data point will require N • d + 2N multiplications, N •d-N +1 additions and N kernel function computations. Of these, N • d multiplications and N • d -N additions are due to the dot product of the test vector with the support vectors.The architecture consists of two arrays of FIFOs from which data is streamed to a 2-dimensional array of MAC units. The support vectors and test vectors are pushed into their respective FIFO's. Support vectors are streamed from top to bottom, and test vectors are streamed from left to right, through the MAC array. Each MAC unit computes the dot product between a unique (support vector, test vector) pair by processing one dimension per cycle in the nominal case and accumulating the result. Once the dot product operation is complete, the dot product values are read out in a raster scan order by the host processor, which takes this data and performs the remaining computation required to compute the label.We would like to mention that our focus in this work is not on the base architecture itself; rather, we focus on the application of scalable effort at different levels of abstraction to this architecture. The effort expended by the SVM classification hardware can be scaled at the circuit, architecture, and algorithm levels. The proposed design has provisions to scale the effort at all these levels, each of which is described in detail in the following subsections.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: SVM classification in matrix form and illustration of algorithmic scaling When we scale the number of support vectors, we are basically reducing the number of dot product computations per classification. We can also cut down the number of MAC operations per dot product, e.g., scaling the dimensionality of the vectors. Generally, different features (or dimensions) have very different effects on the accuracy of classification.If the features are arranged in the order of their importance, the dot product can be computed in that order and the computation can be stopped at any point to get an approximate output.</figDesc><graphic coords="4,93.37,127.39,206.13,72.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: (a) Data packing without zero padding. (b) Data packing with zero padding. (c) Power gating</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: (a) Scalable MAC circuit. (b) Correction term based implementation. (c) Segmented ImplementationFigure6shows the design of a voltage scalable MAC for dot product computation. At an atomic level the MAC unit consists of partial product generator followed by a merge adder and an accumulator. In order to implement a scalable effort MAC, we apply a segmentation based technique to the adders in the MAC hardware. The technique involves segmenting the adder into smaller bit width adders. The point of segmentation can be adaptively controlled based on the de-</figDesc><graphic coords="4,314.68,484.57,73.99,116.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Scalable-effort SVM classifier</figDesc><graphic coords="5,69.17,420.73,112.81,137.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Normalized energy consumption vs accuracy loss for different data sets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>5 Figure 9 :</head><label>59</label><figDesc>Figure 9: Energy vs accuracy for different levels of scaling(MNIST data set)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Energy vs accuracy for different levels of scaling (Checkerboard data set)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1,   </figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Host Processor</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Scaling levels</cell></row><row><cell>Memory</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Bus Interface</cell><cell>Level: Algorithm</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Scaling: Number of</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Support Vectors and</cell></row><row><cell>FIFO control Block</cell><cell>FIFO</cell><cell>FIFO</cell><cell>Support Vectors</cell><cell>FIFO</cell><cell>Number of Features Changes: Amount of data fed to MAC</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>array</cell></row><row><cell>FIFO</cell><cell>MAC</cell><cell>MAC</cell><cell></cell><cell>MAC</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Level: Architecture</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Scaling: Number of</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>bits in datapath</cell></row><row><cell>FIFO</cell><cell>MAC</cell><cell>MAC</cell><cell>. . . .</cell><cell>MAC</cell><cell>Changes: MAC and FIFOs</cell></row><row><cell>Test Vector FIFOs</cell><cell>. . . .</cell><cell cols="2">Systolic Array Architecture</cell><cell>. . . .</cell><cell>Level: Circuit</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Scaling: Voltage</cell></row><row><cell>FIFO</cell><cell>MAC</cell><cell>MAC</cell><cell>. . . .</cell><cell>MAC</cell><cell>Changes: Design</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MACs to be</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>scalable under VOS</cell></row></table><note><p>. . . .</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Data sets used for our evaluations</figDesc><table><row><cell>Data set</cell><cell>Source</cell><cell cols="2">Features Classes</cell></row><row><cell>Adult</cell><cell cols="2">UCI database 14</cell><cell>2</cell></row><row><cell>MNIST</cell><cell>NEC MiLDe</cell><cell>784</cell><cell>10</cell></row><row><cell>NORB</cell><cell>NEC MiLDe</cell><cell>5184</cell><cell>5</cell></row><row><cell cols="2">Checkerboard Artificial</cell><cell>2</cell><cell>2</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>As explained in Section 5.1, the SVM classification almost entirely consists of dot-product computations, which can be expressed as MAC operations.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We focus on classification, however the proposed concepts apply to SVM based regression as well.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Although we only demonstrate our ideas for SVM testing, the core computation in training is essentially the same and the proposed concepts apply to training as well.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Note that the base case was well-optimized -clocked at close to the critical path, and the data path was configured to operate at the minimum precision dictated by the input data set.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>33.3</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgment: The authors would like to thank Patrick Ndai for his inputs on circuit-level scaling, and Igor Durdanovic for his help with the MiLDe software and data sets.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A platform 2015 workload model recognition, mining and synthesis moves computers to the era of tera</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dubey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>White paper, Intel Corp</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Best-effort Computing: Re-thinking Parallel Software and Hardware</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Chakradhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM/IEEE Design Automation Conf</title>
		<meeting>ACM/IEEE Design Automation Conf</meeting>
		<imprint>
			<date type="published" when="2010-06">June 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Best-effort parallel execution framework for recognition and mining applications. Parallel and Distributed Processing Symposium, International</title>
		<author>
			<persName><forename type="first">Jiayuan</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srimat</forename><surname>Chakradhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Raghunathan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sustaining moore&apos;s law in embedded computing through probabilistic and approximate design: retrospects and prospects</title>
		<author>
			<persName><forename type="first">Krishna</forename><forename type="middle">V</forename><surname>Palem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Compilers, Architecture and Synthesis for Embedded Systems</title>
		<meeting>Int. Conf. on Compilers, Architecture and Synthesis for Embedded Systems</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Energy-efficient signal processing via algorithmic noise-tolerance</title>
		<author>
			<persName><forename type="first">Rajamohana</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naresh</forename><forename type="middle">R</forename><surname>Shanbhag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. on Low Power Electronics and Design</title>
		<meeting>Int. Symp. on Low Power Electronics and Design</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="30" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Significance driven computation: A voltage-scalable, variation-aware, quality-tuning motion estimator</title>
		<author>
			<persName><forename type="first">Debabrata</forename><surname>Mohapatra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Karakonstantis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaushik</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. Low Power Electronics and Design</title>
		<meeting>Int. Symp. Low Power Electronics and Design</meeting>
		<imprint>
			<date type="published" when="2009-08">Aug. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Error resilient system architecture (ERSA) for probabilistic applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hankins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adl</forename><forename type="middle">A</forename><surname>Tabatabai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd Wkshp. on System Effects of Logic Soft Errors (SELSE)</title>
		<imprint>
			<date type="published" when="2007-04">April 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The nature of statistical learning theory</title>
		<author>
			<persName><forename type="first">Vladimir</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Springer-Verlag New York, Inc</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The mnist database of handwritten digits</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Probabilistic logics and the synthesis of reliable organisms from unreliable components</title>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Von</forename><surname>Neumann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adaptive computers</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Breuer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Control</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="402" to="422" />
			<date type="published" when="1967-10">October 1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Imprecise results: Utilizing partial computations in real-time systems</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Real-Time Systems Symposium</title>
		<meeting>IEEE Real-Time Systems Symposium</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reliable and energy-efficient digital signal processing</title>
		<author>
			<persName><forename type="first">Naresh</forename><surname>Shanbhag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Design Automation Conference</title>
		<meeting>Design Automation Conference</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="830" to="835" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A low-power digital filter IC via soft DSP</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Shanbhag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Custom Integrated Circuits</title>
		<meeting>IEEE Conf. Custom Integrated Circuits</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="309" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Error-resilient motion estimation architecture</title>
		<author>
			<persName><forename type="first">Vishnu</forename><surname>Girish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naresh</forename><forename type="middle">R</forename><surname>Varatkar</surname></persName>
		</author>
		<author>
			<persName><surname>Shanbhag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. VLSI Systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1399" to="1412" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Energy aware algorithm design via probabilistic computing: From algorithms and models to Moore&apos;s law and novel (semiconductor) devices</title>
		<author>
			<persName><forename type="first">Krishna</forename><forename type="middle">V</forename><surname>Palem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Compilers, Architecture and Synthesis for Embedded Systems</title>
		<meeting>Int. Conf. on Compilers, Architecture and Synthesis for Embedded Systems</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="113" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-media applications and imprecise computation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Breuer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Euromicro Conf. on Digital System Design</title>
		<meeting>8th Euromicro Conf. on Digital System Design</meeting>
		<imprint>
			<date type="published" when="2005-08-03">Aug.-3 Sept. 2005</date>
			<biblScope unit="page" from="2" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An error rate based test methodology to support error-tolerance. Reliability</title>
		<author>
			<persName><forename type="first">Tong-Yu</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuen-Jong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Breuer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="204" to="214" />
			<date type="published" when="2008-03">March 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Process variation tolerant low power DCT architecture</title>
		<author>
			<persName><forename type="first">Nilanjan</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Karakonstantis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaushik</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Design, Automation, and Test Europe</title>
		<meeting>Design, Automation, and Test Europe</meeting>
		<imprint>
			<date type="published" when="2007-04">April 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A hardware-friendly support vector machine for embedded automotive applications</title>
		<author>
			<persName><forename type="first">D</forename><surname>Anguita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pischiutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ridella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Joint Conference on Neural Networks</title>
		<meeting>International Joint Conference on Neural Networks</meeting>
		<imprint>
			<date type="published" when="2007-08">Aug. 2007</date>
			<biblScope unit="page" from="1360" to="1364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Embedded support vector machine : Architectural enhancements and evaluation</title>
		<author>
			<persName><forename type="first">Soumyajit</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monu</forename><surname>Kedia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niket</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anupam</forename><surname>Basu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. VLSI Design</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="685" to="690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Srihari</forename><surname>Cadambi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Durdanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Venkata</forename><surname>Jakkula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Murugan</forename><surname>Sankaradass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Cosatto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srimat</forename><surname>Chakradhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans</forename><forename type="middle">Peter</forename><surname>Graf</surname></persName>
		</author>
		<title level="m">A massively parallel FPGA-based coprocessor for support vector machines. IEEE Symp. Field-Programmable Custom Computing Machines</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">RSVM: Reduced support vector machines</title>
		<author>
			<persName><forename type="first">Olvi</forename><forename type="middle">L</forename><surname>Yuh Jye Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Mangasarian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="0" to="07" />
		</imprint>
		<respStmt>
			<orgName>Data Mining Institute, Computer Sciences Department, University of Wisconsin</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Design compiler</title>
		<imprint>
			<publisher>Synopsys Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Nanosim. Synopsys Inc</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><surname>Milde</surname></persName>
		</author>
		<ptr target="www.nec-labs.com" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
