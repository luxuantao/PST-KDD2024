<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Importance-Driven Volume Rendering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ivan</forename><surname>Viola</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Graphics and Algorithms</orgName>
								<orgName type="institution">Vienna University of Technology</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Armin</forename><surname>Kanitsar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Graphics and Algorithms</orgName>
								<orgName type="institution">Vienna University of Technology</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Meister</forename><forename type="middle">Eduard</forename><surname>Gröller</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Graphics and Algorithms</orgName>
								<orgName type="institution">Vienna University of Technology</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Importance-Driven Volume Rendering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">15BEA82DE457F8B2C02AA14C3C3577B7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>view-dependent visualization</term>
					<term>volume rendering</term>
					<term>focus+context techniques</term>
					<term>level-of-detail techniques</term>
					<term>nonphotorealistic techniques</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper introduces importance-driven volume rendering as a novel technique for automatic focus and context display of volumetric data. It is a generalization of cut-away views, which -depending on the viewpoint -remove or suppress less important parts of a scene to reveal more important underlying information. We automatize and apply this idea to volumetric data.</p><p>Each part of the volumetric data is assigned an object importance which encodes visibility priority. It determines which structures should be readily discernable and which structures are less important. In those image regions, where an object occludes more important structures it is displayed more sparsely than in those areas where no occlusion occurs. Thus the objects of interest are clearly visible. For each object several representations, i.e., levels of sparseness, are specified. The display of an individual object may incorporate different levels of sparseness. The goal is to emphasize important structures and to maximize the information content in the final image. This paper also discusses several possible schemes for level of sparseness specification and different ways how object importance can be composed to determine the final appearance of a particular object.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The importance of volumetric visualization in medical applications has been increasing significantly over the last years. In the future three dimensional visualization will be an essential tool for medical diagnosis. As the amount of data keeps increasing -due to the rapid development of high precision imaging modalities -the need for emphasizing important structures is given.</p><p>Various medical applications exist where the size of the structures of interest is comparably small in relation to the overall data. Examples are examinations of tumors in the kidneys, lesions inside the liver and findings of lung nodules. In addition to that performing diagnostic findings is a complex task. Different features and properties of the anatomical issues have to be taken into account.</p><p>Especially not only the size and the shape of pathologies are of interest, but also their spatial position and vicinity to other anatomical structures. Hence, from a computer science point of view we are dealing with a focus and context task.</p><p>The investigation of liver lesions illustrates the medical requirements on the applied visualization method. Radiologists need to see the tumor from several directions in order to estimate the shape of the lesion. Computer aided diagnosis tools provide precise information about the size calculated from volumetric segmentation. The exact spatial position of arteries in close vicinity is very important in order to determine which liver segments to remove in a possible subsequent surgical treatment. Therefore it is necessary to visualize three different structures: the tumor, the vessel tree of the liver, and -of course -the liver (the liver parenchyma).</p><p>Visualizing these structures simultaneously -probably also including parts of the surrounding anatomy for orientation purposes -results in objects occluding each other. Known methods classify objects within the dataset independently from the viewpoint. This limits viewpoint positions and viewing angles to a range, where the important structures are not occluded by other objects. Using clipping geometries to reveal important inner structures eliminates less important objects also in those viewing situations where it would not be necessary. The application of different optical properties and rendering techniques (i.e. silhouette rendering) eases the problem only to a certain degree. From certain viewpoints several objects of less importance may overlap and largely obscure important features. Furthermore the fine-tuning of these rendering parameters is a time consuming process not suitable for rapid clinical use.</p><p>Here comes importance-driven volume rendering into play. The tumor and the vascular tree in close vicinity are the most important objects, the liver tissue and the surrounding anatomy (bones, aorta, skin) are of lower importance but still helpful for orientation purposes. Similar to anatomical drawings the interesting structure are clearly visible from other positions and different viewing angles, the occluding objects are represented more sparsely or suppressed totally.</p><p>The main contribution of this paper is importance-driven volume rendering as a model for automatic focus and context rendering. The proposed method overcomes the problem of occlusion within the volume, which happens when using any kind of viewindependent classification. As opposed to previous approaches the optical properties of the proposed technique are not constant for the entire object. Depending on the viewing situation the level of sparseness varies dynamically. In order to visually emphasize features with the highest importance, objects between these features and the viewpoint are rendered very sparsely. Interesting objects are represented more densely to see most of the detail. Irrespective of the viewpoint there is always a clear view on the most important structures. On the other hand if no occlusion occurs, even the less important objects can be rendered densely. This enables an automatic generation of images with maximal visual information.</p><p>In figure <ref type="figure" target="#fig_1">2</ref> an anatomical illustration of the human abdomen <ref type="bibr" target="#b11">[12]</ref> and a result of our technique is presented. In this case the internal structures are classified with a high importance value so that structures between the viewpoint and the important values are simply cut away automatically.  The paper is organized as follows: section 2 describes previous work related to importance-driven volume rendering. Section 3 explains the basic idea of the proposed model. Section 4 discusses the principal components of the model and depicts their impact on the resulting visualization. In section 5 we show the applicability of the model to examples from medical visualization. Finally we draw conclusions, summarize the paper in section 6 and propose future work in this field in section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Scientific work related to our model can be divided into several categories. We will first discuss methods that use advanced transfer function specification for feature enhancement and use semi-automatic transfer function specification. These classification methods are viewpoint-independent. Our work on the other hand enables automatic focus+context visualization, where the information about the viewpoint is taken into account. We therefore point out some previous focus+context approaches. Afterwards we review various rendering techniques that are interesting for the level of sparseness specification. Finally we shortly mention other graphics research fields, where importance information is a significant factor of the method.</p><p>Feature Classification: The most typical feature classification in volume visualization is the transfer function specification that maps sample density values to optical properties, i.e., color and opacity. These are composited using one of the known volume rendering techniques to produce the final colors on a two-dimensional image. Transfer functions with density as single input parameter are also denoted as one-dimensional transfer functions. There has also been a lot of research on multi-dimensional transfer functions. The basic idea is to incorporate first, and second derivatives of the density into the transfer function design <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17]</ref>. It is possible to assign optical properties based on gradient and curvature values, so that for example object boundaries are classified differently from homogeneous regions. Taking into account first and second derivatives allows also the semi-automatic generation of transfer functions <ref type="bibr" target="#b15">[16]</ref>.</p><p>Focus+Context Rendering: A lot of work has been done in the field of focus+context visualization. Viewpoint-dependent distortion of three-dimensional data <ref type="bibr" target="#b1">[2]</ref> for example highlights data by dedicating more space to it. Distortions are applied to abstract graphs in order to clearly see interesting graph nodes. An interesting idea is also to include a focal point into the transfer-function specification <ref type="bibr" target="#b27">[28]</ref>. This allows to change the optical properties according to the distance to the focal point. Using this technique several expressive focus+context effects can be achieved. Distancebased transfer functions consider the observer's focal point only, the transfer function is constant for different viewpoint settings. Gaze-directed volume rendering takes the observer's viewing direction into account <ref type="bibr" target="#b18">[19]</ref>. The information about the gaze direction enables to display the volume dataset in different resolutions. The focal region is represented in full resolution, while the other parts are rendered in lower resolution.</p><p>Sparse Representation: The graphics community has been inspired by artists to reduce a visual representation just to show features of interest. This is in contrast to traditional photorealistic approaches. Non-photorealistic methods show features in a sparse way exploiting human imagination. The display of contours is a popular method to represent context information in volume visualization contours <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7]</ref>. Outlines are often sufficient to roughly understand the shape and can be combined with other rendering techniques like direct volume rendering or maximum intensity projection <ref type="bibr" target="#b9">[10]</ref>. To make a contour representation more dense suggestive contours can be introduced <ref type="bibr" target="#b4">[5]</ref>. Additionally to real contours also contours from further virtual viewpoints close to the current view are being rendered. Also pen-and-ink techniques convey good shape information. Pen-and-ink styles in combination with traditional volume rendering have already been applied for fo-cus+context rendering in volume visualization <ref type="bibr" target="#b25">[26]</ref>. This is up to a certain degree similar to combining curvature-directed strokes with iso-surface rendering <ref type="bibr" target="#b12">[13]</ref>. This approach was proposed for rendering structures that are completely enclosed by other objects. The interior structures are rendered fully opaque, while the enclosing objects are represented by a set of curvature-directed lines. The vis-ibility of inner structures can also be modified by dynamic changes in transparency of the outer shape. Dynamic transparency is already used in user interface design <ref type="bibr" target="#b8">[9]</ref>.</p><p>Cut-Away Views: Cut-away illustrations are another way to represent nested objects. The popularity of this technique is demonstrated by the fact that it can be found in almost all books with technical or medical illustrations. Volume cutting is a research area with high potential <ref type="bibr" target="#b21">[22]</ref>. Diepstraten et al. <ref type="bibr" target="#b5">[6]</ref> describe how various cut-away techniques can be achieved automatically. Streamarrows were presented by Löffelmann et al. <ref type="bibr" target="#b19">[20]</ref> for visualizing complex dynamical systems. They use arrows as a basic element for cutting the stream surface. This allows to see through the surface and perceive other surfaces or structures behind.</p><p>Importance-Driven Rendering: Importance as a rendering parameter has already been investigated in other graphics fields. In global illumination the term importance is used quite often. Importance sampling for example is a popular method to accelerate convergence of Monte-Carlo integration by faster reducing the variance. The basic idea is based on distributing sample points nonuniformly <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b13">14]</ref>. This idea of has been recently researched also for volume rendering <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b3">4]</ref>. In radiosity importance can also encode the potential visibility of surfaces <ref type="bibr" target="#b22">[23]</ref> or the prominence of a patch as a light source. Importance is also proposed as an additional user-defined parameter for halftoning as well <ref type="bibr" target="#b23">[24]</ref>. All these methods employ importance in different contexts and meanings. But all of them use importance as an additional dimension to improve the behavior of traditional approaches. In the following we discuss how importance is applicable also for volume rendering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">IMPORTANCE-DRIVEN VOLUME RENDERING</head><p>In volume visualization we are often dealing with the problem that interesting structures are partly or completely occluded by surrounding tissue. This is hard to resolve by traditional viewindependent approaches, such as transfer function specification. We propose a viewpoint-dependent model that removes unwanted occlusions automatically and maximizes the information content of the final image.</p><p>Traditionally objects within the volume dataset are classified by optical properties like color and opacity. We additionally assign objects another dimension, which describes their importance. Importance encodes which objects are the most interesting ones and have the highest priority to be clearly visible. Each object is therefore weighted by a positive scalar value called object importance. During the rendering stage, the model evaluates the visibility of each object according to its importance. If the less important objects are occluding features that are more interesting, the less important ones are rendered more sparsely. This means that they are more transparent for example. If the same object does not cause any unwanted occlusions in other regions of the image, it is rendered more densely, e.g., opaque, in order to see its features more clearly. On one hand this allows to see all interesting structures no matter if they are occluded or not, and on the other hand the less important parts are still visible as much as possible. Instead of using constant optical characteristics, which are independent from the viewpoint, we use several levels of sparseness for each object. This means that not a single optical characteristic is assigned, but several characteristics with smooth transitions inbetween. These multiple levels of sparseness allow the object to continuously change it's visual appearance from a very dense representation to a very sparse one. Which level of sparseness will be chosen is dependent on the importance of the particular object and the importance of hidden objects behind. The level of sparseness thus may continuously vary within a single object. Also depending on the viewpoint the same part of an object may be represented with different levels of sparseness. To determine the sparseness level for each object or parts thereof the rendering pipeline requires an additional step, which we call importance compositing. This step evaluates the occlusion, takes the importance factor of each object into account and assigns to each object particular levels of sparseness. The final synthesis results in images with maximal visual information with respect to the predefined object importance.</p><p>Importance-driven volume rendering is controlled by the following three already shortly mentioned components:</p><p>Object importance describes the visibility priority of each object within the volume dataset. It is a positive scalar value, which is constant for the whole object.</p><p>Levels of sparseness are various different representations of a particular object from the most dense to the most sparse one. Sparseness is defined in terms of how much the display of an object takes up screen estate. For an iso-surface a point-cloud or wireframe display is a very sparse representation. The display of filled opaque polygons is a very dense representation of the same isosurface. In case of volumetric data each sample within the volume is classified to have a color and opacity. These are in direct volume rendering (DVR) composited together to synthesize the final image. The sparseness can in this case modulate the opacity of object samples so that the most interesting samples are opaque while other samples are more transparent. This is a simple and straightforward example of levels of sparseness. More elaborate schemes are discussed in section 4.2.</p><p>Importance Compositing is an additional rendering step that assigns to each part of an object a specific level of sparseness. A very simple importance compositing scheme is maximum importance projection (MImP). For each image area only the object with highest importance is visible. The remaining objects are shown with the highest level of sparseness, i.e., fully transparent. This results in cut-out views of important structures. As another example, we can perform importance compositing in a similar way as compositing of color and opacity in the traditional DVR approach. Instead of compositing optical properties, the object importance values are accumulated. We will discuss different compositing modes in section 4.1.</p><p>The interrelationship between the above mentioned components is depicted in figure <ref type="figure" target="#fig_2">4</ref>. The importance compositing is done similar to the DVR approach. For each ray the compositing evaluates object occlusions. It assigns the corresponding level of sparseness to each object. Object importance is presented in the sense that it is mapped to object visibility in the result image. This causes different rendering settings for the context object 0 in the area of the image which is covered by the focus object 1. The difference between traditional volume rendering and importance-driven volume rendering is clearly visible in figure <ref type="figure" target="#fig_3">3</ref>. In traditional approach it is necessary to reduce the opacity of occluding objects globally. Importancedriven rendering assigns higher sparseness factor only on the area where occlusion occurs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">IMPORTANCE AND SPARSENESS FACTORS</head><p>In the previous section we have explained the basic idea of importance-driven volume rendering and its components. For the moment we assume that object importance is just a scalar value. Therefore in this chapter we concentrate on the two remaining components, i.e., importance compositing and levels of sparseness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Importance Compositing</head><p>Importance compositing is an additional pass added to the traditional volume-rendering pipeline. It determines the level of sparseness for each object or a part thereof in order to preserve important features. There are many possibilities conceivable how to perform importance compositing. In the following we will discuss two  simple methods of importance compositing which are derived from compositing optical properties through ray casting of volume data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Maximum Importance Projection</head><p>Maximum Intensity Projection (MIP) <ref type="bibr" target="#b20">[21]</ref> is a simple and fast volume rendering approach. It is applicable for sparse data where important information has high intensity values like contrast-media enhanced blood vessels. With MIP compositing reduces to selecting the highest intensity value along a ray. Intensities are encoded as grey values to produce the final image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analogous to Maximum Intensity Projection we propose Maximum Importance Projection (MImP).</head><p>For each ray the object with highest importance along the ray is determined. This object is displayed densely. All the remaining objects along the ray are displayed with the highest level of sparseness, i.e., fully transparent.</p><p>With MImP structures are either rendered using the most dense representation or they are not rendered at all.</p><p>With Maximum Intensity Projection the spatial arrangement of structures is not readily apparent. MImP has a similar problem which we alleviate as follows. The footprint of an object denotes the image area covered by the object after projection. With MImP the footprint is exactly the image region where only the object is visible. One can consider MImP as a cut-away view, where the space in front of the most important object is simply clipped. The clipping object is a translational sweep with the footprint as cross section (general cylinder). One can now modify this cylinder to obtain a clipping frustum. This is achieved by scaling up the footprint during the translational sweep towards the viewer. This produces a countersink clipping geometry. The countersink geometry, i.e., the entry points, are computed from the footprint of the focus object. The term footprint denotes the projection of the object on the image plane. The footprint contains depth information of the "last-hit" sample for each ray along the viewing direction. This is the base for performing the cut-out. Furthermore we need to enlarge the footprint to build the conical shape. This is possible to realize using 2D image processing on the depth image, where the intensity encodes the depth of the entry point. The depth-footprint is processed by a 2D chamfer distance transform <ref type="bibr" target="#b0">[1]</ref>. The highest depth value of the footprint is calculated. The depth buffer of new entry points that contribute to the countersink e i are calculated from highest depth value e max , slope of the countersink s c and distance value at pixel i d i as shown in equation 1.</p><formula xml:id="formula_0">e i = e max -d i * s c<label>(1)</label></formula><p>To simulate the cut-out it is necessary to change the gradient value at the entry points that contribute to the countersink effect. Two components of the gradient are estimated from the gradient information of the 2D distance field. The "z" component is constant, i.e, the slope factor frustum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Average Importance Compositing</head><p>The second approach of importance compositing takes into account all the objects along a ray. The influence of an individual object is hereby independent from the number of ray samples within the object. Each object o has an importance value I o . Ray r is intersected by n r objects. The level of sparseness S o of a particular object o at ray r is equal to the fraction of its own importance and the sum of the importance of all the intersected objects:</p><formula xml:id="formula_1">S o = I o ∑ n r i=1 I i (2)</formula><p>Average importance compositing does not completely remove the less important objects as with MImP. The sparseness factors are estimated according to the given importance. This allows a very sparse representation of the occluding object maybe just to see its high curvature areas and the important object behind it.</p><p>The compositing can be evaluated using the footprint image of each object. Then for each image region we get the sparseness factors for all objects. To achieve smooth transitions, we use the distance transform of each footprint. Figure <ref type="figure" target="#fig_7">6</ref> gives an example of average importance compositing. ensured.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Levels of Sparseness</head><p>Different levels of sparseness schemes are finally compared in fig- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Color and Opacity Modulation</head><p>A direct control of optical properties is the first approach to modify the visual prominence of a particular object. With increasing sparseness the object becomes more transparent in order to show the more important underlying data. This approach is widely used in transfer function specification.</p><p>Interesting results can be achieved by controlling the color values with the level of sparseness factor, independently from the opacity factor. The color is a very important visual cue used in visualization from its very beginning. Highly saturated colors are attracting the observer's focus more than colors close to gray. The level of sparseness can be therefore expressed also in the amount of saturation of the color. Changing only the saturation, however, does not increase the visibility of occluded objects. Therefore it is necessary to change the color and opacity values at the same time. Different visual appearance within the same object can cause misinterpretations. Therefore smooth transitions between different levels of sparseness have to be applied. The smooth modulation of the optical properties is shown in figure <ref type="figure" target="#fig_6">7</ref>(top).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Screen-Door Transparency</head><p>Screen-door transparency is a well-known strategy to simulate transparency. The semi-transparent view of an object behind a screen-door is simulated as follows. A screen-door consists of a mesh and holes inbetween. The mesh fully occludes the object behind, whereas it is fully visible through the holes. From a certain distance holes and mesh blend together to produce a semitransparent view. We use an analogue idea to define levels of sparseness. The volumetric dataset consists of voxels. The level of sparseness estimates which voxels should be rendered and which not. The distribution of visible voxels is uniform and is forming a wireframe-like structure. The impact of increasing sparseness is shown in figure <ref type="figure" target="#fig_6">7</ref>(middle).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Volume Thinning</head><p>Voxels of an object are sorted according to two sorting keys. The first sorting key is gradient magnitude, the second sorting key is curvature magnitude of the iso-surface through the voxel. Reducing the sparseness factor according to gradient magnitude has the effect that the volume is continuously reduced to fewer and fewer strong iso-surfaces. As soon as only few iso-surfaces remain the reduction proceeds according to curvature magnitude. This has the effect that the iso-surfaces gradually dissolve and in the end (most sparse representation) only few high curvature lines (ridge, valley lines) remain. Figure <ref type="figure" target="#fig_6">7</ref>(bottom) shows the first part of volume thinning, the reduction of the volume into iso-surfaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>We have tested our method on three datasets. The Leopard Gecko dataset is of resolution 512 × 512 × 87. The Monster Study dataset has been downsampled to the half of its full resolution, i.e., 256 × 256 × 610. Both datasets are using pre-segmented objects. The Monster Study has all important organs pre-segmented. Therefore it is a good dataset for automatic generation of medical illustrations.</p><p>The performance of the current implementation is not interactive. The goal of the implementation was to verify the proof of concept rather than performance optimizations. The model was integrated into the J-Vision <ref type="bibr" target="#b14">[15]</ref> medical workstation.</p><p>To fully appreciate the strengths of importance-driven volume rendering viewpoint changes are essential. This is best illustrated with animation sequences which are available at http://www.cg.tuwien.ac.at/research/vis/adapt/2004 idvr/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">SUMMARY AND CONCLUSIONS</head><p>In this paper we have proposed a view-dependent model for automatic focus+context volume visualization. It introduces new factor to the traditional volume rendering pipeline, i.e., the importance dimension. According to the importance and viewpoint settings a each object is rendered in order to maximize the visual information. This method allows to see structures within the volume as dense as possible. The sparse representation is chosen only if other, more important structures are occluded.</p><p>We have discussed three different schemes for levels of sparseness. This factor controls the optical properties or the amount of visible elements of the volume. Smooth opacity change works well in combination with desaturation. The amount of visible volume elements can be distributed uniformly over the whole volume, or the first-and second-order derivatives can be used for visibility distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">FUTURE WORK</head><p>The paper opens a lot of opportunities for possible research areas. We assume that the objects within the volume data are presegmented and the importance is assigned manually by the user. An open issue here is, how to do the feature selection and importance assignment automatically. Various automatic feature detection approaches can be integrated into the model to select the important features without additional user interaction. Another idea can be to assign the importance values according to closeness to one or several focal points, similarly to distance transfer functions <ref type="bibr" target="#b27">[28]</ref>. The importance dimension controls in this case the transition from one level of sparseness to another.</p><p>The paper has presented various levels of sparseness schemes. The continuous transition from dense to sparse representations for volumetric data is a wide area for research. In polygonal rendering levels of sparseness are widely used. The most sparse representation is a set of points, another representation is wireframe display, and most dense display is surface representation. Volume graphics does not have such variety, which shows the need for research in this area.</p><p>The third factor of importance-driven volume rendering is importance compositing. The paper presents simple compositing schemes derived from ray-casting approaches. The next step are compositing schemes that incorporate first-and second order derivatives to preserve object boundaries. These parts are then considered as more important and a more dense representation is estimated.</p><p>The conical MImP is a compositing scheme that uses the cut-out illustration technique to improve perception of the spatial relationship. More elaborate approaches for intelligent automatic cut-out generation are to be researched more intensively.</p><p>Each viewpoint contains a fraction of the whole information encoded in the data set. How to estimate this fraction and how to automatically determine optimal viewpoints <ref type="bibr" target="#b26">[27]</ref> is another, not yet researched, area for volume data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison between artistic medical illustration of the abdomen (a) and our method (b). Illustration image is courtesy to Howell MediGraphics.</figDesc><graphic coords="2,182.30,414.16,113.30,152.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Stages of the importance-driven volume rendering pipeline in contrast to traditional volume rendering.</figDesc><graphic coords="4,59.06,358.88,235.20,65.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Comparison between traditional volume rendering (top) and importance-driven volume rendering (bottom).</figDesc><graphic coords="4,59.06,427.76,235.20,65.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 (</head><label>5</label><figDesc>top) illustrates the difference between a cylindrical and a conical MImP in 2D. Figure 5(bottom) shows images to compare both approaches. The conical MImP is easily realized during the ray traversal by changing the starting point during ray traversal for those rays intersecting the side faces of the clipping frustum.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Maximum Importance Projection. Cylindrical MImP (left) and conical MImP with different slope factors (center and right).</figDesc><graphic coords="5,59.06,143.09,241.08,105.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>ure 7 .</head><label>7</label><figDesc>The Figure shows the Leopard Gecko dataset where the inner part was pre-segmented. The series of images illustrate the transition from the most dense to the most sparse representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Average importance compositing: The average compositing is shown in combination with optical properties modulation.</figDesc><graphic coords="5,318.02,54.18,241.37,188.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Changing levels of sparseness. First row: opacity modulation and color saturation modulation. Second row: screen-door transparency. Third row: volume thinning. Each row displays levels of sparseness with factors 0.75, 0.5, and 0.25.</figDesc><graphic coords="6,62.18,213.12,155.90,71.51" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">ACKNOWLEDGMENTS</head><p>The work presented in this publication has been funded by the ADAPT project (FFF-804544).</p><p>ADAPT is supported by Tiani Medgraph, Vienna (http://www.tiani.com), and the Forschungsförderungsfonds für die gewerbliche Wirtschaft, Austria. See http://www.cg.tuwien.ac.at/research/vis/adapt for further information on this project.</p><p>The authors would like to thank Stefan Bruckner and Sören Grimm for providing the software ray-caster. The Monster Study dataset is courtesy of Tiani Medgraph and the Leopard Gecko is courtesy of University of Veterinary Medicine Vienna.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Distance transformations in digital images</title>
		<author>
			<persName><forename type="first">G</forename><surname>Borgefors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="344" to="371" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Distortion viewing techniques for 3-dimensional data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S T</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Cowperthwaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Fracchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Symposium on Information Visualization &apos;96</title>
		<meeting>IEEE Symposium on Information Visualization &apos;96</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="46" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast visualization of object contours by non-photorealistic volume rendering</title>
		<author>
			<persName><forename type="first">B</forename><surname>Csébfalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>König</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Procceedings of EUROGRAPHICS &apos;01</title>
		<meeting>ceedings of EUROGRAPHICS &apos;01</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="452" to="460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Monte carlo volume rendering</title>
		<author>
			<persName><forename type="first">B</forename><surname>Csébfalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Szirmay-Kalos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization&apos;03</title>
		<meeting>IEEE Visualization&apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="449" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Suggestive contours for conveying shape</title>
		<author>
			<persName><forename type="first">D</forename><surname>Decarlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Santella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIG-GRAPH &apos;03</title>
		<meeting>ACM SIG-GRAPH &apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="848" to="855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Interactive cutaway illustrations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Diepstraten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Procceedings of EUROGRAPHICS &apos;03</title>
		<meeting>ceedings of EUROGRAPHICS &apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="523" to="532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Volume illustration: non-photorealistic rendering of volume models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rheingans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization &apos;00</title>
		<meeting>IEEE Visualization &apos;00</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="195" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">VOlume doTS as a point-based representation of volumetric data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">To appear in Proceedings of EUROGRAPHICS &apos;04</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The effects of dynamic transparency on targeting performance</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dyck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ch</forename><surname>Fedak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Graphics Interface &apos;03</title>
		<meeting>Graphics Interface &apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Two-level volume rendering-fusing mip and dvr</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bischi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization &apos;00</title>
		<meeting>IEEE Visualization &apos;00</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Curvature-based transfer functions for direct volume rendering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hlad Ůvka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>König</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SCCG &apos;00</title>
		<meeting>SCCG &apos;00</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="58" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<ptr target="http://www.medigraphics.com/" />
		<title level="m">Howell MediGraphics web site</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Illustrating transparent surfaces with curvature-directed strokes</title>
		<author>
			<persName><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization &apos;96</title>
		<meeting>IEEE Visualization &apos;96</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Importance driven path tracing using the photon map</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Wann</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Rendering Techniques &apos;95</title>
		<meeting>Rendering Techniques &apos;95</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="326" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Vision medical workstation</title>
		<author>
			<persName><forename type="first">J-</forename></persName>
		</author>
		<ptr target="http://www.tiani.com/" />
	</analytic>
	<monogr>
		<title level="m">Tiani MedGraph web site</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semi-automatic generation of transfer functions for direct volume rendering</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Durkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Symposium on Volume Visualization &apos;98</title>
		<meeting>IEEE Symposium on Volume Visualization &apos;98</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Interactive volume rendering using multi-dimensional transfer functions and direct manipulation widgets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ch</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization &apos;01</title>
		<meeting>IEEE Visualization &apos;01</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="255" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Display of surfaces from volume data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Gaze-directed volume rendering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Whitaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Symposium on Interactive 3D Graphics &apos;90</title>
		<meeting>Symposium on Interactive 3D Graphics &apos;90</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="217" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Hierarchical streamarrows for the visualization of dynamical systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Löffelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics Workshop on Visualization in Scientific Computing &apos;97</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="155" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Interactive high-quality maximum intensity projection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EUROGRAPHICS &apos;00</title>
		<meeting>EUROGRAPHICS &apos;00</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="341" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Towards realistic visualization for surgery rehearsal</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pflesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Tiede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Höhne</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An importance-driven radiosity algorithm</title>
		<author>
			<persName><forename type="first">B</forename><surname>Smits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Arvo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Salesin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH &apos;92</title>
		<meeting>ACM SIGGRAPH &apos;92</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="273" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Importance driven halftoning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buchanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EUROGRAPHICS &apos;98</title>
		<meeting>EUROGRAPHICS &apos;98</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="207" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Importance driven quasi-random walk solution of the rendering equation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Szirmay-Kalos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Csébfalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Werner</forename><surname>Purgathofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WSCG &apos;98</title>
		<meeting>WSCG &apos;98</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="379" to="385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pen-and-ink rendering in volume visualisation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Treavett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization &apos;00</title>
		<meeting>IEEE Visualization &apos;00</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="203" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Viewpoint selection using viewpoint entropy</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of VMV &apos;01</title>
		<meeting>VMV &apos;01</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="273" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Distance transfer function based rendering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Döring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toennies</surname></persName>
		</author>
		<idno>TR-ISGBV-04-01</idno>
		<imprint>
			<date type="published" when="2004">2004</date>
			<pubPlace>Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Institute for Simulation and Graphics, University of Magdeburg</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
