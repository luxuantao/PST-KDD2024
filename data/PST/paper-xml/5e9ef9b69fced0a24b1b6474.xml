<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adversarial Attacks on Graph Neural Networks via Node Injections: A Hierarchical Reinforcement Learning Approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yiwei</forename><surname>Sun</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xianfeng</forename><surname>Tang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tsung-Yu</forename><surname>Hsieh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vasant</forename><surname>Honavar</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">The Pennsylvania State University University Park</orgName>
								<address>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">The Pennsylvania State University University Park</orgName>
								<address>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">The Pennsylvania State University University Park</orgName>
								<address>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">The Pennsylvania State University University Park</orgName>
								<address>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">The Pennsylvania State University University Park</orgName>
								<address>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Adversarial Attacks on Graph Neural Networks via Node Injections: A Hierarchical Reinforcement Learning Approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3366423.3380149</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Adversarial Attack</term>
					<term>Graph Poisoning</term>
					<term>Reinforcement learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph Neural Networks (GNN) offer the powerful approach to node classification in complex networks across many domains including social media, E-commerce, and FinTech. However, recent studies show that GNNs are vulnerable to attacks aimed at adversely impacting their node classification performance. Existing studies of adversarial attacks on GNN focus primarily on manipulating the connectivity between existing nodes, a task that requires greater effort on the part of the attacker in real-world applications. In contrast, it is much more expedient on the part of the attacker to inject adversarial nodes, e.g., fake profiles with forged links, into existing graphs so as to reduce the performance of the GNN in classifying existing nodes.</p><p>Hence, we consider a novel form of node injection poisoning attacks on graph data. We model the key steps of a node injection attack, e.g., establishing links between the injected adversarial nodes and other nodes, choosing the label of an injected node, etc. by a Markov Decision Process. We propose a novel reinforcement learning method for Node Injection Poisoning Attacks (NIPA), to sequentially modify the labels and links of the injected nodes, without changing the connectivity between existing nodes. Specifically, we introduce a hierarchical Q-learning network to manipulate the labels of the adversarial nodes and their links with other nodes in the graph, and design an appropriate reward function to guide the reinforcement learning agent to reduce the node classification performance of GNN. The results of the experiments show that NIPA is consistently more effective than the baseline node injection attack methods for poisoning graph data on three benchmark datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Graphs, where nodes and their attributes denote real-world entities (e.g., individuals) and links encode relationships (e.g., friendship) between entities, are ubiquitous in many application domains, including social media <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50]</ref>, e-commerce <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b46">47]</ref>, and FinTech <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b32">33]</ref>. Many real-wold applications are involve classifying the nodes in graph data based on the attributes of the nodes, and their connectivity and attributes of the nodes that are connected to them in the graph. Thus, revealing a user's level of risk in financial platform such as AliPay<ref type="foot" target="#foot_0">1</ref> can be formulated as a node classification problem <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b40">41]</ref>. Graph Neural Networks (GNNs) <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">26]</ref>, currently offer the state-of-the art approach to node classification in graph-structured data.</p><p>However, recent studies <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b50">51]</ref> show that GNNs are vulnerable to poisoning attacks which add perturbation to the training graph. Since GNNs are trained based on node attributes and the link structure in the graph, an adversary can attack the GNNs by poisoning the graph data used for training. For example, Nettack <ref type="bibr" target="#b50">[51]</ref> shows that by adding the adversarial perturbations on the node's attributes and the graph structure, classification accuracy of graph convolution network significantly drops. However, the success of such attack strategy requires that the adversary is able to control these nodes and manipulate its connectivity. In other words, poisoning the real-world graphs such as Facebook and twitter require breaching the security of the database that stores the graph data, or manipulating the requisite members into adding or deleting their links to other selected members. Consequently, such attack strategy is expensive and usually requires more budgets for the adversary to execute without being caught.</p><p>Thus, we need a more efficient way to poison the graphs to increase the node misclassification rate of GNNs without changing the link structure between the existing nodes in the graph. Injecting fake nodes (users) to social networks with carefully crafted node labels and connecting them to carefully chosen existing nodes offers a promising approach to accomplishing this objective. For example, in the financial platform, there is significant financial incentives for adversaries to attack the GNNs and manipulate the risks level of the real users. However, it is impossible for an attacker to breach the database. In contrast, an attacker could easily sign up fake accounts, create the social identity of the profiles and send friendship requests to the real members. And as the social users always want to have the social influence <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b30">31]</ref>, they tend to accept the friendship requests from the others. With some of the real users accept the friendship from the attacker, the fake accounts are connected to the real users and thus such social network is poisoned. Once the GNNs are trained on the corrupted graph, the propagation of the fake information will misclassify the predicted level of risks on real users. Such node injection poisoning attacks are easier and less expensive to execute compared to those that require manipulating the links between existing nodes in the graph. Though promising, the work on such attacks are limited.</p><p>Therefore, in this paper, we investigate a novel problem of graph poisoning attack by node injection. In essence, we are faced with two challenges: (i) How to mathematically model and effectively establish links between an injected adversarial (fake) node to existing nodes in the original graph or to other injected adversarial nodes. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, both the attackers in (b) and (c) want to inject two fake nodes into the clean graph in (a). Obviously, the "smart attacker" who carefully designs the links and labels of the dashed line injected nodes could better poison the clean graph than the "dummy attack" who establish the links and generate the labels at random; and (ii) How to efficiently solve the optimization problem as the graph is discrete and highly-nonlinear. In an attempt to solve these two challenges, we propose a novel framework named NIPA, to perform the Node Injection Poisoning Attack. As sequentially adding the adversarial connections and designing adversarial labels of the injected fake nodes could be naturally formulated as the Markov decision process (MDP), NIPA adopts Qlearning algorithms, which have shown great successes for solving such problems <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b42">43]</ref>. The adopt of Q-learning also naturally solves the challenge of discrete optimization as now we concert the discrete edge adding process as actions in reinforcement learning framework. To reduce the searching space, NIPA adopt a hierarchical Q-learning network to decompose the actions. To cope with the graph highly-nonlinearity, NIPA comprises of deep Q network and GNN based state representation method. These components could learn the semantic structure of the graph and convert the discrete graph structure to latent representations. The key contributions of the paper are as follows:</p><p>• We study a novel graph node injection attack problem to adversely impact the accuracy of graph neural networks without manipulating the link structure of the original graph.  The rest of the paper is organized as follows: Section 2 reviews the related work on adversarial attacks and reinforcement learning on graph data; Section 3 formally defines the non-target-specific node injection poisoning attack problem. Section 4 presents NIPA, our proposed solution; Section 5 describes our experimental results; section 6 concludes with a summary and an outline of promising directions for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our study falls in the general area of data poisoning attacks on machine learning <ref type="bibr" target="#b3">[4]</ref>, that aim to corrupt the data so as to adversely impact the performance of the predictive model that is trained on the data. Such attacks have been extensively studied in the case of non graph-structured data in supervised <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b28">29]</ref> and reinforcement <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b24">25]</ref> learning. Specifically, recent work has shown that deep neural networks are particularly vulnerable to data poisoning attacks <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b36">37]</ref>. However, little attention has been given to understanding how to poisoning the graph structured data. In this paper, our focus is on such attacks on classifiers trained on graph-structured data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Adversarial Attacks on GNN</head><p>The previous works <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b36">37]</ref> have shown the intriguing properties of neural networks as they are "vulnerable to adversarial examples" in computer vision domain. For example, in <ref type="bibr" target="#b18">[19]</ref>, the authors show that some deep models are not resistant to adversarial perturbation and propose the Fast Gradient Sign Method (FGSM) to generate the adversarial image samples to attack such models. Not only in computer vision domain, recently such "intriguing properties" have been observed in various domain including from text mining <ref type="bibr" target="#b7">[8]</ref> to data mining <ref type="bibr" target="#b19">[20]</ref>.</p><p>Recent work has also highlighted the vulnerability of graph neural networks to adversarial attacks <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b50">51]</ref>. As already noted, such attacks can be (i) node specific, as in the case of a target evasion attack <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b50">51]</ref> that is designed to ensure that the GNNs are fooled into misclassifying a specific node; or (ii) nontarget <ref type="bibr" target="#b11">[12]</ref>, as in the case of attacks that aim to reduce the accuracy of node classification across a graph. As shown by <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b50">51]</ref>, both node specific and non-target attacks can be executed by selectively adding adversarial edges or removing existing edges between the existing nodes in the graph so as to reduce the accuracy of the resulting graph neural networks.</p><p>Nettack <ref type="bibr" target="#b50">[51]</ref> is one of the first methods that perturbs the graph data to perform poisoning/training-time attack on GCN <ref type="bibr" target="#b22">[23]</ref> model. RL-S2V <ref type="bibr" target="#b11">[12]</ref> adopts reinforcement learning for evasion/testing-time attack on graph data. Different from previous methods, <ref type="bibr" target="#b9">[10]</ref> and <ref type="bibr" target="#b43">[44]</ref> focus on poison attack by gradient information. <ref type="bibr" target="#b9">[10]</ref> attacks the graph in embedding space by iteratively modifying the connections of nodes with maximum absolute gradient. <ref type="bibr" target="#b43">[44]</ref> proposes to attack the graph structured data by use the integrated gradients approximating the gradients computed by the model and performs perturbation on data by flipping the binary value. <ref type="bibr" target="#b51">[52]</ref> modifies the training data and performs poisoning attacks via meta-learning. <ref type="bibr" target="#b38">[39]</ref> formulates adversarial attacks on graph as the optimization problem and adopts several approximation techniques such as projected gradient descent to solve it.</p><p>Though these graph adversarial attacks are effective, they focus on manipulating links among existing nodes in a graph, which are impractical as these nodes/individuals are not controlled by the attacker. Our framework is inherently different from existing work. Instead of manipulating links among existing nodes, our framework NIPA injects fake nodes into the graph, and carefully designed links of fake nodes and its label to poison the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Reinforcement Learning in Graph</head><p>Reinforcement learning(RL) has achieved significant successes in solving challenging problems from different domains such as continuous robotics control <ref type="bibr" target="#b33">[34]</ref>, playing games <ref type="bibr" target="#b29">[30]</ref>, code retrieval <ref type="bibr" target="#b45">[46]</ref>. However, there has been little previous work exploring the capability reinforcement learning in graph mining domain.</p><p>More recently, reinforcement learning has begun to find applications that involve graph data. For example, NerveNet <ref type="bibr" target="#b41">[42]</ref> learns policy network for the robotics control with Graph Neural Network as the body of a robot is represented as a graph. Graph Convolutional Policy Network (GCPN) <ref type="bibr" target="#b47">[48]</ref> adopts reinforcement learning in chemistry and molecular graph mining. The reinforcement learning agent is trained on the chemistry aware graph environment and learns to generate molecular graph. <ref type="bibr" target="#b13">[14]</ref> is another work which defines chemical molecular reaction environment and trains the reinforcement learning agent for predicting products of the chemical reaction.</p><p>The most similar work to ours is RL-S2V <ref type="bibr" target="#b11">[12]</ref> which adopts reinforcement learning method for target evasion attack on graph by manipulating the links among existing nodes. However, there are several main differences between RL-S2V and our proposed model: <ref type="bibr" target="#b0">(1)</ref> the two works research on different attacking scenario as we focus on non-targeted poison attack while RL-S2V performs target evasion attack; (2) the reinforcement learning agents have different tasks: the agent in RL-S2V learns to attack the specific nodes in the graph via modifying the inner-structure of the original graph and our proposed agent generates the adversarial connections and design the labels for the injected fake nodes in stead; (3) we design different reward functions to steer the agent. Here we explore the usage of reinforcement learning model in novel non-target poison attacking scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">NODE INJECTION POISONING ATTACKS ON GRAPH DATA</head><p>In this section, we formally define the problem we target and provide its object functions. We begin by introducing the definition of semi-supervised node classification as we aim to poison the graph for manipulating label classification of graph classifiers. Note that the proposed framework is a general framework which can also be used to poison the graph for other tasks. We leave other tasks as future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>Definition 3.1. (Semi-Supervised Node Classification) Let G = (V , E, X ) be an attributed graph, where V = {v 1 , . . . v n } denotes the node set, E ⊆ V × V means the edge set and X represents the nodes features. T = {v t 1 , . . . , v t n } is the labeled node set and U = {v u 1 , . . . , v u n } is the unlabeled node set with T ∪ U = V . Semi-supervised node classification task aims at correctly labeling the unlabeled nodes in U with the graph classifier C.</p><p>In semi-supervised node classification task, the graph classifier C(G) which learns the mapping V → L aims to correctly assign the label to node v j ∈ U with aggregating the structure and feature information. The classifier C is parameterized by θ and we denote the classifier as C θ . For simplicity of notations, we use C θ (G) i as the classier prediction on v i and T i as the ground truth label of v i . In the training process, we aim to learn the optimal classifier C with the corresponding parameter θ L defined as following:</p><formula xml:id="formula_0">θ L = arg min θ v i ∈T L(T i , C θ (G) i )<label>(1)</label></formula><p>where L is the loss function such as cross entropy. To attack the classifier, there are mainly two attacking settings including poisoning/training-time attack and evasion/testing-time attack. In poisoning attacks, the classifier C uses the poisoned graph for training while in evasion attack, adversarial examples are included in testing samples after C is trained on clean graph. In this paper, we focus on non-targeted graph poisoning attack problem where the attacker A poisons the graph before training time to reduce the performance of graph classifier C over unlabeled node set U. Definition 3.2. (Graph Non-Targeted Poisoning Attack) Given the attributed graph G = (V , E, X ), the labeled node set T , the unlabeled node set U and the graph classifier C, the attacker A aims to modify the graph G within a budget ∆ to reduce the accuracy of classifier C on U.</p><p>As the attacking process is supposed to be unnoticeable, the number of allowed modifications of attacker A on G is constrained by the budget ∆. Based on the problem, we propose the node injection poisoning method to inject a set of adversarial nodes V A into the node set V to perform graph non-targeted poisoning attack. Definition 3.3. (Node Injection Poisoning Attack) Given the clean graph G = (V , E, X ), the attacker A injects the adversarial node set V A with its adversarial features X A and labels T A into the clean node set V . After injecting V A , the attack A creates adversarial edges</p><formula xml:id="formula_1">E A ⊆ V A ×V A ∪V A ×V to poison G. G ′ = (V ′ , E ′ , X ′ ) is the poisoned graph where V ′ = V ∪V A , E ′ = E∪E A , X ′ = X ⊕X A with ⊕ is append operator and T ′ is the labeled set with T ′ = T ∪ T A .</formula><p>In the poisoning attack, the graph classifier is trained on poisoned graph G ′ .</p><p>With the above definitions and notations, the objective function for the non-targeted node injection poisoning attack is defined as: max</p><formula xml:id="formula_2">E A , T A v j ∈U 1(U j C θ L (G ′ ) j )<label>(2)</label></formula><formula xml:id="formula_3">s.t . θ L = arg min θ v i ∈ T ′ L(T ′ i , C θ (G ′ ) i )<label>(3)</label></formula><formula xml:id="formula_4">|E A | ≤ ∆<label>(4)</label></formula><p>Here 1(s) is the indicator function with 1(s) = 1 if s is true and 0 otherwise, and U j represents the label of the unlabeled node v j . If the attacker has the ground truth for the unlabeled data (unlabel is to end-user in this case), then U is ground truth label. The attacker maximizes the prediction error for the unlabeled nodes in U as in Eq. ( <ref type="formula" target="#formula_2">2</ref>), subject to two constraints. The constrain (3) enforces the classifier is learned from the poisoned graph G ′ . and constrain (4) restricts the modifications of adversarial edges by the attacker in the budget ∆. However, if attacker doesn't have the access to the ground true, the attacker could not directly use object function in Eq.( <ref type="formula" target="#formula_2">2</ref>). Two alternative solutions are suggested according to <ref type="bibr" target="#b51">[52]</ref>: one is to maximize the loss on the labeled (training) nodes; the other is to adopt self-learning, i.e. use these predicted labels and compute the loss of a model on the unlabeled nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph Convolution Network</head><p>In this paper, we use the Graph Convolution Network (GCN) <ref type="bibr" target="#b22">[23]</ref> as our graph classifier C to illustrate our framework as it is one kind of widely adopted graph neural networks for node classification task. In the convolutional layer of GCN, it explores the topological structure in spectral space and aggregates attribute information from the neighbor nodes followed by the non-linear transformation such as ReLU. The equation for a two-layer GCN is defined as:</p><formula xml:id="formula_5">f (A, X ) = softmax( Â ReLU ( ÂXW (0) )W (1) )<label>(5)</label></formula><p>where Â = D− 1 2 Ã D− 1 2 denotes the normalized adjacency matrix, Ã = A + I N denotes adding the identity matrix I N to the adjacent matrix A. D is the diagonal matrix with on-diagonal element as Dii = j Ãij . W (0) and W (1) are the weights of first and second layer of GCN, respectively. ReLU(0, a) = max(0, a) is adopted. The loss function L in GCN is cross entropy.</p><p>The notations we use throughout the paper are summarized in Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PROPOSED FRAMEWORK</head><p>To perform the non-target node injecting poisoning attack, we propose to solve the optimization problem in Eq.( <ref type="formula" target="#formula_2">2</ref>) via deep reinforcement learning. Compared with directly optimizing the adjacency matrix with traditional matrix optimization techniques, the advantages of adopting deep reinforcement learning are two folds: (i) Adding edges and designing labels of fake nodes are naturally sequential decision making process. Thus, deep reinforcement learning is a good fit for the problem <ref type="bibr" target="#b35">[36]</ref>; (ii) The underlying structures of graphs are usually highly nonlinear <ref type="bibr" target="#b39">[40]</ref>, which adds</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1: Notations and Explanations</head><p>Notation Explanation Policy of state to action distribution Q = {Q (1) , Q (2) , Q (3) } Hierarchical action-value functions l a (1) t Labels of fake node a (1) t at time t the non-linearity to the decision making process. The deep nonlinear neural networks of the Q network could better capture the graph non-linearity and learn the semantic meaning of the graph for making better decisions.</p><formula xml:id="formula_6">V A Adversarial node set V ′ Poisoned node set, V ∪ V A E A Adversarial Edge set E ′ Poisoned Edge set, E ∪ E A T Labeled node sets U Unlabeled node set, V \ T G ′ Poisoned graph $ C θ C θ (G ′ ) Prediction of classifier C on G ′ L Label sets ∆ Poisoning budget G ′ t Poisoned</formula><p>An illustration of the proposed framework is shown in Figure <ref type="figure" target="#fig_2">2</ref>. The key idea of our proposed framework is to train the deep reinforcement learning agent which could iteratively perform actions to poison the graph. The actions includes adding adversarial edges and modifying the labels of injected nodes. More specifically, the agent needs to firstly pick one node from injected nodes set V A and select another node from poisoned node set V ′ to add the adversarial edge, and modify the label of the injected nodes to attack the classifier C. We design reinforcement learning environment and reward according to the optimization function to achieve this.</p><p>Next, we describe the details of the proposed method and present the reinforcement learning environment design, the deep Q network used to estimate the policy and the training algorithm of the proposed NIPA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Attacking Environment</head><p>We model the proposed poisoning attack procedure as a Finite Horizon Markov Decision Process (S, A, P, R, γ ). The definition of the MDP contains state space S, action set A, transition probability P, reward R, discount factor γ .    which is extremely expensive especially in large graphs. Thus, we adopt hierarchical action to decompose such action and reduce the action space to enable efficient exploration inspired by previous work <ref type="bibr" target="#b11">[12]</ref>. As shown in Figure <ref type="figure" target="#fig_2">2</ref>, in NIPA, at time t, the agent first performs an action a t , the agent connects these two selected nodes to forge the adversarial edge as the dashed line in the Figure <ref type="figure" target="#fig_2">2</ref>. Finally, the agent designs the label of the selected fake node through action a </p><formula xml:id="formula_7">) … … … … … … 𝑎 $ (,) ~𝞹(𝑠 $ ) … … … … … … 𝑎 $ (4) ~𝞹(𝑠 $ , 𝑎 $ (,) ) 𝑉 𝑉 𝑉 action 𝑎 $ = (𝑎 $ (,) , 𝑎 $ (4) , 𝑎 $ (') ) state 𝑠 $6, … … … … … … GCN 𝑪 𝑺 𝑎 $ (,) 𝑎 $ (4) 𝑎 $ (') reward 𝑟 $ (𝑠 $ , 𝑎 $ ) 𝑒 𝐺 $ / 𝑒(𝑣 1 2 (3) ) 𝑒(𝑣</formula><formula xml:id="formula_8">t , a (2) t , a (3) t ), the action space is reduced from O(|V A | * |V ′ | * |L|) to O(|V A | + |V ′ | + |L|).</formula><p>With the hierarchy action a = (a (1) , a (2) , a (3) ), the trajectory of the proposed MDP is (s 0 , a</p><formula xml:id="formula_9">(1) 0 , a (2) 0 , a (3) 0 , r 0 , s 1 , . . . , s T −1 , a<label>(1)</label></formula><formula xml:id="formula_10">T −1 , a<label>(2)</label></formula><p>T −1 , a</p><p>T −1 , r T −1 , s T ). 4.1.3 Policy network. As both of previous work <ref type="bibr" target="#b11">[12]</ref> and our preliminary experiments show that Q-learning works more stable than other policy optimization methods such as Advantage Actor Critic, we focus on modeling policy network with Q-learning. Q-learning finds a policy that is optimal in the sense that it maximizes the expected value of the total reward over any and all successive steps, starting from the current state. Q-learning is an off-policy optimization which fits the Bellman optimality equation as:</p><formula xml:id="formula_12">Q * (s t , a t ) = r (s t , a t ) + γ max a ′ t Q * (s t +1 , a ′ )<label>(6)</label></formula><p>The greedy policy to select the action a t with respect to Q * is:</p><formula xml:id="formula_13">a t = π (s t ) = arg max a Q * (s t , a)<label>(7)</label></formula><p>As we explain in the above subsection that performing one poisoning action requires searching in O(|V A | * |V ′ | * |L|) space and we perform hierarchical actions other than one action, we cannot directly follow the policy network in Eq.( <ref type="formula" target="#formula_12">6</ref>) and Eq. <ref type="bibr" target="#b6">(7)</ref>. Here, we adopt hierarchical Q function for the actions and we propose the hierarchical framework which integrates three DQNs. The details of the proposed DQNs are presented in following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Reward.</head><p>As the RL agent is trained to enforce the misclassification of the graph classifier C, we need to design the reward accordingly to guide the agent. The reasons why we need to design novel reward function other than using the widely adopted binary sparse rewards are two folds: (1) as our trajectory in the attacking environment is usually long, we need the intermediate rewards which give feedback to the RL agent on how to improve its performance on each state; (2) different from the target attack that we know whether the attack on one targeted node is success or not, we perform the non-target attack over graph thus accuracy is not binary. To tackle theses two challenges, we design the reward of the current state and actions for the agent is designed according to the poisoning objective function shown in Eq. <ref type="bibr" target="#b1">(2)</ref>. For each state s t , we firstly define the attack success rate A t as:</p><formula xml:id="formula_14">A t = v j ∈T 1(T j C θ S (G ′ t ) j )/|V |<label>(8)</label></formula><p>θ S = arg min</p><formula xml:id="formula_15">θ v i ∈ T ′ L(T ′ i , C θ (G ′ ) i )<label>(9)</label></formula><p>Here T is the training set used to compute the reward as we discussed for the Eq.( <ref type="formula" target="#formula_2">2</ref>). Note that the C θ S is not the graph classifier C that evaluates the final classification accuracy by end-user. As the attacker usually doesn't know the model that end-user is using, it represents the simulated graph classifier designed by attacker to acquire the state and actions reward. However, directly using the success rate A t as the reward would increase the instability of training process since the accuracy might not differ a lot for two consecutive state. In this case, we design the guiding binary reward r t to be one if the action a t = (a</p><p>t , a</p><p>t , a</p><p>t ) could reduce the accuracy of attacker's simulated graph classifier C θ S at time t, and to be negative one vice versa. The proposed guiding reward r t is defined as follows:</p><formula xml:id="formula_19">r t (s t , a (1) t , a (2) t , a (3) t ) = 1; if A t +1 &gt; A t −1; otherwise. (<label>10</label></formula><formula xml:id="formula_20">)</formula><p>Our preliminary experimental results show that such guiding reward is effective in our case.</p><p>4.1.5 Terminal. In the poisoning attacking problem, the number of allowed adding adversarial edges is constrained by the budget ∆ for the unnoticeable consideration. So in the poisoning reinforcement learning environment, once the agent adds budget number of edges (T = ∆), it stops taking actions. In terminal state s T , the poisoned graph G ′ contains T more adversarial edges compared to the clean graph G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">State Representation</head><p>As mentioned above, the state s t contains the poisoned graph G ′ t and injected nodes labels T A t at time t. It is important to explore the high nonlinear structure of the state as the Q function is scoring the nodes in the poisoned graph G ′ t . As shown in Figure <ref type="figure" target="#fig_2">2</ref>, NIPA represents the state s t by the e(G ′ t ) and e(T A t ) via graph embedding and label embedding methods. Here, in details, to represent the non-Euclidean structure of the poisoned graph G ′ t with vector e(G ′ t ), the latent embedding e(v i ) of the each node v i in G ′ t is firstly learned by struct2vec <ref type="bibr" target="#b10">[11]</ref> using the discriminative information. Then the state vector representation e(G ′ t ) is obtained by aggregating the embedding of nodes as:</p><formula xml:id="formula_21">e(G ′ t ) = v i ∈V ′ e(v i )/|V ′ |<label>(11)</label></formula><p>To represent the label of the injected fake nodes, we use the two layer neural networks to encode the one-hot embedding of the nodes labels T A t as:</p><formula xml:id="formula_22">e(T A t ) = σ (W (2) l (σ (W (1) l z A t + b 1 ) + b 2 )<label>(12)</label></formula><p>Here, z A t represents the one-hot embedding of the labels T A t , σ is the non-linear activation function and {W</p><p>(1)</p><formula xml:id="formula_23">l ,W<label>(2)</label></formula><p>l , b 1 , b 2 } are the parameters of neural networks.</p><p>Actually, more complex graph embedding and label embedding methods could replace the adopted modules outlined here and we leave exploring feasible graph embedding and label embedding methods as a future direction. Note that for the notation compact and consistency consideration, e(s) represents embedding of the state, and e(v a ) and e(T a ) are the embeddings of the node selected by action a and label selected by action a respectively in the following paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Hierarchical Q Network</head><p>In Q learning process, given the state s t and action a t , the actionvalue function Q(s t , a t ) is supposed to give the scores of current state and selected actions to steer the RL agent. However, as the action a is decomposed into three hierarchical actions {a (1) , a (2) , a (3) } for the efficiency searching consideration, it would be hard to directly design the Q(s t , a</p><formula xml:id="formula_24">(1) t , a (2) t , a<label>(3)</label></formula><p>t ) and apply one policy network to select hierarchical actions.</p><p>To overcome this problem, we adopt hierarchical deep Q networks Q = {Q (1) , Q (2) , Q (3) } which integrates three DQNs to model the Q values over the actions. Figure <ref type="figure" target="#fig_2">2</ref> illustrates the selection of action a t = {a (1)</p><formula xml:id="formula_25">t , a (2) t , a<label>(3)</label></formula><p>t )} at time t performed by our proposed NIPA. After obtaining the state representations e(s t ), the first DQN Q (1) guides the policy to pick a node from injected node set V A ;</p><p>Based on a (1) t , the second DQN Q (2) learns the policy to pick the second node from the node set V ′ , which completes an edge injection by connecting the two nodes; The third DQN Q (3) learns the policy to design the label of the first selected injected fake node.</p><p>The agent firstly selects one node from the injected node set V A and calculate the Q value based on the action-value function Q (1)  as:</p><formula xml:id="formula_26">Q (1) (s t , a<label>(1)</label></formula><formula xml:id="formula_27">t ; θ (1) ) = W (1) 1 σ (W (1) 2 [e(s t ) ∥ e(v a (1) t )])<label>(13)</label></formula><p>where θ (1) = {W</p><p>(1)</p><formula xml:id="formula_28">1 ,W<label>(1)</label></formula><p>2 } represents the trainable weights of the first DQN and ∥ is the concatenation operation. The action-value function Q (1) estimates the Q value of each injected fake node given the state representation s t and action embedding e(v a (1) t ).</p><p>The greedy policy which selects the action a</p><p>(1) t based on optimal action-value function Q (1) * in Eq.( <ref type="formula" target="#formula_27">13</ref>) is defined as follows:</p><formula xml:id="formula_29">a (1) t = π (s t ) = arg max a ∈V A Q (1) (s t , a; θ (1) );<label>(14)</label></formula><p>With the first action a</p><p>(1)</p><p>t selected, the agent picks the second action a</p><p>(2) t hierarchically based on Q (2) as:</p><formula xml:id="formula_30">Q (2) (s t , a (1) t , a (2) t ; θ (2) ) = W (2) 1 σ (W (2) 2 [e(s t ) ∥ e(v a (1) t ) ∥ e(v a (2) t )]) (15) where θ (2) = {W (2) 1 ,W (2)</formula><p>2 } is the trainable weights. The action value function Q (2) scores the second nodes based on the state s t , and the selected action a</p><p>(1) t . The greedy policy to make the second action a</p><p>(2) t with the optimal Q (2) * in Eq.( <ref type="formula">15</ref>) is defined as follows:</p><formula xml:id="formula_31">a (2) t = π (s t , a (1) t ) = arg max a ∈V ′ Q (2) (s t , a<label>(1)</label></formula><p>t , a; θ (2) ); <ref type="bibr" target="#b15">(16)</ref> Note that the agent only modifies the label of the selected injected fake node a (1) t , thus the action-value function for the third action is not directly related to the action a</p><p>(2) t . The action-value function Q (3) which scores the injected fake node label designing is defined as follows:</p><formula xml:id="formula_32">Q (3) (s t , a (1) t , a (3) t ; θ (3) ) = W (3) 1 σ (W (3) 2 [e(s t ) ∥ e(v a (1) t ) ∥ e(T a (3) t )]) (17) In Eq.(17), θ (3) = {W (3) 1 ,W<label>(3)</label></formula><p>2 } represents the trainable weights in Q (3) . The action value function Q (3) models the score of changing the label of the injected node a</p><p>(1)</p><p>t . The greedy policy to such action is defined as follows:</p><formula xml:id="formula_33">a (3) t = π (s t , a (1) t ) = arg max a ∈L Q (3) (s t , a<label>(1)</label></formula><p>t , a; θ (3) ); <ref type="bibr" target="#b17">(18)</ref> With the proposed hierarchical deep Q networks Q = {Q (1) , Q (2) , Q (3) } in Eq.( <ref type="formula" target="#formula_27">13</ref>), Eq.( <ref type="formula">15</ref>) and Eq.( <ref type="formula">17</ref>), NIPA integrates hierarchical actionvalue functions to model the Q values over the hierarchical actions a = {a (1) , a (2) , a (3) }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Training Algorithm</head><p>To train the proposed hierarchical DQNs Q = {Q (1) , Q (2) , Q (3) } and the parameters in states representation methods, we adopt the experience replay technique with a certain size memory buffer M <ref type="bibr" target="#b29">[30]</ref>. The high level idea to use the experience replay is to reduce bias caused by correlation between samples. We simulate the selection process to generate training data and store them in memory buffer M. During training, a batch of experience (s, a, s ′ ) where a = {a (1) , a (2) , a (3) } is drawn uniformly at random from the stored memory buffer M. The Q-learning loss function is defined as:</p><formula xml:id="formula_34">E (s,a,s ′ )∼M [(r + γ max a ′ Q(s ′ , a ′ |θ − ) − Q(s, a|θ )) 2 ] (<label>19</label></formula><formula xml:id="formula_35">)</formula><p>where Q represents the target action-value function and its parameters θ − are updated with θ every C steps. To improve the stability of the algorithm, we clip the error term between −1 and +1. The agent adopts ϵ-greedy policy that select a random action with probability ϵ. The overall training framework is summarized in Algorithm 1.</p><p>In the proposed model, we use two layer multi-layer perceptrons to implement all the trainable parameters θ in action-value functions Q = {Q (1) , Q (2) , Q (3) } and structure2vec. Actually, more complex deep neural networks could replace the models outlined here. We leave exploring feasible deep neural networks as a future direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we introduce the experiment setting including baseline datasets and comparing poisoning attack methods. Moreover, we conduct experiments and present results to answer the following research questions:</p><p>• (RQ1) Can the NIPA effectively poison the graph data and attack the GCN via node injection? • (RQ2) Whether the poisoned graph remains the key statistics after the poison attack? • (RQ3) How the proposed framework performances under different scenarios?</p><p>Next, we first introduce the experimental settings followed by experimental results to answer the three questions. Compute reward r t according to Eq.( <ref type="formula" target="#formula_14">8</ref>) and Eq.( <ref type="formula" target="#formula_19">10</ref>);</p><formula xml:id="formula_36">12 Set s t +1 = {s t , a<label>(1) t , a (2) t , a (3)</label></formula><formula xml:id="formula_37">t }; 13 Update edges as E A t +1 ← E A ∪ (a (1) t , a<label>(2)</label></formula><p>t ) and labels as l a (1)  We conduct experiments on three widely used benchmark datasets for node classification, which include CORA-ML <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b27">28]</ref>, CITESEER <ref type="bibr" target="#b16">[17]</ref> and DBLP <ref type="bibr" target="#b31">[32]</ref>. Following <ref type="bibr" target="#b51">[52]</ref>, we only consider the largest connected component (LCC) of each graph data. The statistics of the datasets with the LCC are summarized in Table <ref type="table" target="#tab_6">2</ref>. For each dataset, we randomly split the nodes into (20%) labeled nodes for training procedure and (80%) unlabeled nodes as test set to evaluate the model. The labeled nodes are further equally split into training and validation sets. We perform the random split five times and report averaged results. </p><formula xml:id="formula_38">t +1 ← a (3) t ; 14 Store {s t , a<label>(1) t , a (2) t , a (3)</label></formula><p>5.1.2 Baseline Methods. Though there are several adversarial attack algorithms on graphs such as Nettack <ref type="bibr" target="#b50">[51]</ref> and RL-S2v <ref type="bibr" target="#b11">[12]</ref>, most of them are developed for manipulating links among existing nodes in graph, which cannot be easily modified in our attacking setting for node injection attack. Thus, we don't compare with them. Since node injection attack on graphs is a novel task, there are very few baselines that we can compare with. We select following four baselines, with two from classical graph generation models, one by applying the technique of fast gradient attack and a variant of NIPA.</p><p>• Random Attack <ref type="bibr" target="#b14">[15]</ref>: The attacker A first adds adversarial edges between the injected nodes according to classic Erdős-Rényi model G(V A , p), where the probability p = 2|E | |V | 2 is the average degree of the clean graph G(V , E) to make sure the density of the injected graph G A is similar to the clean graph. The attacker then randomly add adversarial edges connecting the injected graph G A and clean graph G until the budget ∆ is used ups.</p><p>• Preferential attack <ref type="bibr" target="#b1">[2]</ref>: The attacker A iteratively adds the adversarial edges according to preferential attachment mechanism. The probability of connecting the injected node v i ∈ V A to the other node v j ∈ |V ∪ V A | is proportional to the node degrees. The number of adversarial edges is constrained by the budget ∆. • Fast Gradient Attack (FGA) <ref type="bibr" target="#b9">[10]</ref>: FGA is a gradient based method which is designed to attack the graph data by perturbing the gradients. In FGA, the attacker A removes/adds the adversarial edges guided by edge gradient. • NIPA-w/o: This is a variant of the proposed framework NIPA where we don't optimize w.r.t the label of fake nodes, i.e., the labels of the fake nodes are randomly assigned.</p><p>The Fast Gradient Attack (FGA) <ref type="bibr" target="#b9">[10]</ref> is not directly applicable in node injection poisoning setting, since the injected nodes are isolated at the beginning and would be filtered out by graph classifier. Here we modify the FGA for fair comparison. The FGA method is performed on the graph poisoned by preferential attack. After calculating the gradient ∇ i j L GC N with v i ∈ V A and v j ∈ V ′ , the attack A adding/remove the adversarial edges between (v i , v j ) according to the largest positive/negative gradient. The attack only add and remove one feasible adversarial edge are each iteration so that the number of the adversarial edges is still constrained by budget ∆. The attacker is allowed to perform 20*∆ times modifications in total suggested by <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Attack Performance Comparison</head><p>To answer RQ1, we evaluate how the node classification accuracy degrades on the poisoned graph compared with the performance on the clean graph. The larger decrease the performance is on the poisoned graph, the more effective the attack is. To compare the decrease the of different models, we firstly show the node classification results on clean graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Node Classification on Clean</head><p>Graph. As the Nettack <ref type="bibr" target="#b50">[51]</ref> points out that "poisoning attacks are in general harder and match better the transductive learning scenario", we follow the same poisoning transductive setting in this paper. The parameters of GCN are trained according to Eq. ( <ref type="formula" target="#formula_0">1</ref>). We report the averaged node classification accuracy over five runs in Table <ref type="table">.</ref> 3 to present the GCN node classification accuracy on clean graph. Note that if the poisoning nodes are injected with the budget ∆ = 0, such isolated nodes would be filtered out by GCN and the classification results remain the same as in Table <ref type="table">.</ref> 3. We will evaluate how effective the attack is when the injected nodes can have different number of degrees in Section 5.4.1. To have comprehensive comparisons of the methods, we vary r as r = {0.01, 0.02, 0.05, 0.10}. We don't set r &gt; 0.10 since we believe that too much injected nodes could be easily noticed in real-world scenarios. For the same unnoticeable consideration, the feature of the injected nodes is designed to be similar to that of the clean node features. For each injected node, we calculate the mean of the features as X and apply the Gaussian noise N (0, 1) on the averaged features X . The features of the injected node are similar to the features in clean graph. We leave the generation of node features as future work. As the other baselines method could not modifies the adversarial labels of the injected nodes, we also provide the variant model NIPA-w/o which doesn't manipulate the adversarial labels for fair comparison. The adversarial labels are randomly generated within |L| for the baseline methods. In both NIPA and NIPA-w/o, we set the discount factor γ = 0.9 and the injected nodes V A are only appear in training phase in all of the methods. The averaged results with standard deviation for all methods are reported in Table <ref type="table" target="#tab_8">4</ref>. From Table <ref type="table" target="#tab_7">3</ref> and 4, we make the following observations</p><p>• In all attacking methods, more injected nodes could better reduce the node classification accuracy, which satisfy our expectation; • Compared with Random and Preferential attack, FGA is relatively more effective in attacking the graph, though the performance gap is marginal. This is because random attack and preferential attack don't learn information from the clean graph and just insert fake nodes following predefined In particular, both FGA and NIPA are optimization based approach while NIPA significantly outperforms FGA, which implies the effectiveness of the proposed framework by designing hierarchical deep reinformcent learning to solve the decision making optimization problem; and • NIPA out performances NIPA-w/o, which shows the necessity of optimizing w.r.t to labels for node injection attack.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Key Statistics of the Poisoned Graphs</head><p>To answer RQ2, we analyze several key statistics of the poisoned graphs, which helps us to understand the attacking behaviors. One desired property of the poisoning graph is that the poisoned graph has similar graph statistics to the clean graph. Here, we adopt the important graph statistics as that used in <ref type="bibr" target="#b5">[6]</ref> to measure the poisoned graphs for the three datasets. More specifically, we presents the Gini coefficient, characteristic path length, distribution entropy, power law exponent and numbers of triangle counts to carefully analysis the poisoned graph statistics such as graph distribution and graph density. The detailed equations and descriptions could be found <ref type="bibr" target="#b5">[6]</ref>. The results are reported in Table <ref type="table" target="#tab_9">5</ref>. It could be concluded from the graph statistics that</p><p>• Poisoned graph has very similar graph distribution to the clean graph. For example, the similar exponent of the power law distribution in graph indicates that the poisoned graph and the clean graph shares the similar distribution; • More injected nodes would make the poisoning attack process noticeable. The results show that with the increase of r , the poisoned graph becomes more and more diverse from the origin graph. • The number of triangles increases, which shows that the attack not just simply connect fake nodes to other nodes, but also connect in a way to form triangles so each connection could affects more nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Attack Effects Under Different Scenarios</head><p>In this subsection, we conduct experiments to answer RQ3, i.e., how effective the attack by NIPA is under different scenarios. We carefully study the effective of different parameters to NIPA. The experiment results with injected node ratio r = 0.01 and r = 0.02 on CITESEER and CORA-ML are shown in Fig. <ref type="figure" target="#fig_7">3</ref>(a) and Fig. <ref type="figure" target="#fig_7">3(b)</ref>, respectively. From the figures, we observe that as the increase of the average degree of the injected nodes, the node classification accuracy decrease sharply. Such observation satisfies our expectation because the more links a fake node can have, the more likely it can propagate the adversarial information and poison the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Sparsity of the Origin Graph.</head><p>We further investigate how the proposed framework works under different sparsity of the network. Without loss of generality, we set average degree of injected node as the average degree of the real node. To simulate the sparsity of the network, we randomly remove S p = {0, 10%, . . . , 90%} edges from the original graph and perform NIPA on the modified graph. The results with injected node ratio r = 0.01 and r = 0.02 on CITSEER and CORA-ML are shown in Fig. <ref type="figure" target="#fig_1">4</ref>(a) and Fig. <ref type="figure" target="#fig_1">4</ref>(b) respectively.</p><p>The results show that as the graph becomes more spare, the proposed framework is more effective in attacking the graph. This is because as the graph becomes more sparse, each node in the clean graph has less neighbors, which makes the it easier for fake nodes to change the labels of unlabeled nodes.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we study a novel problem of non-target graph poisoning attack via node injection. We propose a deep reinforcement learning based method named NIPA to solve the node injection poisoning attack task. NIPA simulates the attack process and sequentially adds the adversarial edges and designs labels for the injected fake nodes. Specifically, we adopt hierarchy deep Q networks to efficiently reduce the action spaces and use GNN based graph state representation method to cope with the graph topology. Experimental results of poisoning graph convolutional network on node classification demonstrate the effectiveness of the proposed framework for poisoning the graph. The poisoned graph has very similar properties as the original clean graph such as gini coefficient and distribution entropy. Further experiments are conducted to understand how the proposed framework works under different scenarios such as very sparse graph. There are several interesting directions that need further investigation. First, we have used the mean of node features corrupted by Gaussian noise to set the features of fake nodes. It would be interesting to explore variants of NIPA that optimize the features of fake nodes to maximize the effectiveness of NIPA. Second, we have used a 2-layer graph neural networks to encode the states of the hierarchical deep Q learner. It would be interesting to explore more complex deep neural networks for this task. Moreover, it would be interesting to explore extensions of NIPA for carrying out node poisoning attacks on more complex graphs, e.g., heterogeneous graphs, multi-modal graphs, and dynamic graphs. Last, but not the least, it would be interesting to explore variants of NIPA that use more sophisticated optimization methods for reinforcement learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a) is the toy graph where the color of a node represents its label; (b) shows the node injection poisoning attack performed by a naive attacker; (c) shows the node injection poisoning attack performed by a smart attacker using a smart strategy. The injected nodes are circled with dashed line.</figDesc><graphic url="image-1.png" coords="2,403.58,93.67,72.02,58.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>4</head><label>4</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An overview of the Proposed Framework NIPA for Node Injection Attack on Graphs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( 1 )</head><label>1</label><figDesc>t to select one injected node from V A . The agent then picks another node from the whole node set V ′ via action a</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>17</head><label></label><figDesc>Every C steps update θ − = θ ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>5. 4 . 1</head><label>41</label><figDesc>Average Degrees of Injected Nodes. As we discussed that the budget ∆ = r * |V | * deg(v A ) is essential to the poisoning attack, we investigate the node classification accuracy by varying the average degree of injected nodes as deg(v A ) = {3, . . . 10}. We don't set deg(v A ) &gt; 10 since injecting 'celebrate' or 'hub' nodes into the network is not common in graph poisoning attack.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Node classification performance on (a) CITESEER and (b) CORA-ML by varying average node degree of injected nodes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Node classification performance on (a) CITESEER and (b) CORA-ML with varying graph sparsity</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>.1.1 State. The state s t contains the intermediate poisoned graph G ′ t and labels information T A t of the injected nodes at the time t. To capture the highly non-linear information and the non-Euclidean structure of the poisoned graph G ′ t , we embed G ′ t as e(G ′ t ) with aggregating the graph structure information via designed graph neural networks. e(T A t ) encodes the adversarial label information L A t with neural networks. The details of the state representation is described in following subsection. Since in the injection poisoning</figDesc><table><row><cell></cell><cell>RL Agent</cell></row><row><cell></cell><cell>𝑒 𝐺 $ / 𝑒(𝑣 1 2 (3)</cell></row><row><cell></cell><cell>𝑎 $ (') ~𝞹(𝑠 $ , 𝑎 $ , )</cell></row><row><cell>𝑉</cell><cell>𝑉</cell></row><row><cell>state 𝑠 $</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Algorithm 1: The training algorithm of framework NIPA Input: clean graph G(V , E, X ), labeled node set T , budget ∆, number of injected nodes |V A |, training iteration K Output: G ′ (V ′ , E ′ , X ′ ) and L A 1 Initialize action-value function Q with random parameters θ ;</figDesc><table><row><cell>6</cell><cell>while t ≤ ∆ do</cell><cell></cell></row><row><cell>7</cell><cell cols="2">Compute state representation according to Eq.(11)</cell></row><row><cell></cell><cell>and Eq.(12);</cell><cell></cell></row><row><cell>8 9 10</cell><cell>With probability ϵ select a random action a otherwise select a (1) t based on Eq.(14); With probability ϵ select a random action a otherwise select a (2) t based on Eq.(16); With probability ϵ select a random action a otherwise select a (3) t based on Eq.(18);</cell><cell>(1) t , (2) t , (3) t ,</cell></row><row><cell>11</cell><cell></cell><cell></cell></row></table><note>2 Set target function Q with parameters θ − = θ ; 3 Initialize replay memory buffer M; 4 Randomly assign Adversarial label L A ; 5 while episode ≤ K do</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 :</head><label>2</label><figDesc>Statistics of benchmark datasets</figDesc><table><row><cell>Datasets</cell><cell>N LCC</cell><cell>E LCC</cell><cell>|L|</cell></row><row><cell>CITESEER</cell><cell>2,110</cell><cell>3,757</cell><cell>6</cell></row><row><cell>CORA-ML</cell><cell>2,810</cell><cell>7,981</cell><cell>7</cell></row><row><cell>PUBMED</cell><cell>19,717</cell><cell>44,324</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Node classification results on clean graph Node Classification on Poisoned Graph. In poisoning attacking process, the attacking budget ∆ which controls the number of added adversarial edges is one important factor. On the one hand, if the budget is limited, eg., ∆ &lt; |V A |, then at least |V A | − ∆ injected nodes are isolated. Clearly, isolated nodes have no effect on the label prediction as they are not really injected into the environment. On the other hand, if the budget is large, the density of the injected graph is different from the clean graph and such injected nodes might be detected by the defense methods. Here, to make the poisoned graph has the similar density with the clean graph and simulates the real world poisoning attacking scenario, we set ∆ = r * |V | * deд(V ) where r is the injected nodes ratio compared to the clean graph and deд(V ) is the average degree of the clean graph G. The injected nodes number is |V A | = r * |V |.</figDesc><table><row><cell>Dataset</cell><cell>CITESEER</cell><cell>CORA-ML</cell><cell>Pubmed</cell></row><row><cell cols="4">Clean data 0.7730 ± 0.0059 0.8538 ± 0.0038 0.8555 ± 0.0010</cell></row><row><cell>5.2.2</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Classification results after adversarial attack on graphs The proposed framework outperforms the other methods.</figDesc><table><row><cell>Dataset</cell><cell>Methods</cell><cell>r = 0.01</cell><cell>r = 0.02</cell><cell>r = 0.05</cell><cell>r = 0.10</cell></row><row><cell></cell><cell>Random</cell><cell>0.7582 ± 0.0082</cell><cell>0.7532 ± 0.0130</cell><cell>0.7447 ± 0.0033</cell><cell>0.7147 ± 0.0122</cell></row><row><cell></cell><cell>Preferrential</cell><cell>0.7578 ± 0.0060</cell><cell>0.7232 ± 0.0679</cell><cell>0.7156 ± 0.0344</cell><cell>0.6814 ± 0.0131</cell></row><row><cell>CITESEER</cell><cell>FGA</cell><cell>0.7129 ± 0.0159</cell><cell>0.7117 ± 0.0052</cell><cell>0.7103 ± 0.0214</cell><cell>0.6688 ± 0.0075</cell></row><row><cell></cell><cell>NIPA-wo(ours)</cell><cell>0.7190 ± 0.0209</cell><cell>0.6914 ± 0.0227</cell><cell>0.6778 ± 0.0162</cell><cell>0.6301 ± 0.0182</cell></row><row><cell></cell><cell>NIPA (ours)</cell><cell>0.7010 ± 0.0123</cell><cell>0.6812 ± 0.0313</cell><cell>0.6626 ± 0.0276</cell><cell>0.6202 ± 0.0263</cell></row><row><cell></cell><cell>Random</cell><cell>0.8401 ± 0.0226</cell><cell>0.8356 ± 0.0078</cell><cell>0.8203 ± 0.0091</cell><cell>0.7564 ± 0.0192</cell></row><row><cell></cell><cell>Preferrential</cell><cell>0.8272 ± 0.0486</cell><cell>0.8380 ± 0.0086</cell><cell>0.8038 ± 0.0129</cell><cell>0.7738 ± 0.0151</cell></row><row><cell>CORA-ML</cell><cell>FGA</cell><cell>0.8205 ± 0.0044</cell><cell>0.8146 ± 0.0041</cell><cell>0.7945 ± 0.0117</cell><cell>0.7623 ± 0.0079</cell></row><row><cell></cell><cell>NIPA-w/o (ours)</cell><cell>0.8042 ± 0.0190</cell><cell>0.7948 ± 0.0197</cell><cell>0.7631 ± 0.0412</cell><cell>0.7206 ± 0.0381</cell></row><row><cell></cell><cell>NIPA (ours)</cell><cell>0.7902 ± 0.0219</cell><cell>0.7842 ± 0.0193</cell><cell>0.7461 ± 0.0276</cell><cell>0.6981 ± 0.0314</cell></row><row><cell></cell><cell>Random</cell><cell>0.8491 ± 0.0030</cell><cell>0.8388 ± 0.0035</cell><cell>0.8145 ± 0.0076</cell><cell>0.7702 ± 0.0126</cell></row><row><cell></cell><cell>Preferrential</cell><cell>0.8487 ± 0.0024</cell><cell>0.8445 ± 0.0035</cell><cell>0.8133 ± 0.0099</cell><cell>0.7621 ± 0.0096</cell></row><row><cell>PUMBED</cell><cell>FGA</cell><cell>0.8420 ± 0.0182</cell><cell>0.8312 ± 0.0148</cell><cell>0.8100 ± 0.0217</cell><cell>0.7549 ± 0.0091</cell></row><row><cell></cell><cell>NIPA-w/o(ours)</cell><cell>0.8412 ± 0.0301</cell><cell>0.8164 ± 0.0209</cell><cell>0.7714 ± 0.0195</cell><cell>0.7042 ± 0.0810</cell></row><row><cell></cell><cell>NIPA (ours)</cell><cell>0.8242 ± 0.0140</cell><cell>0.8096 ± 0.0155</cell><cell>0.7646 ± 0.0065</cell><cell>0.6901 ± 0.0203</cell></row><row><cell cols="3">rule. Thus, both of the methods are not as effective as FGA</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">which tries to inject nodes through a way to decrease the</cell><cell></cell><cell></cell><cell></cell></row><row><cell>performance;</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>•</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Statistics of the clean graph (r = 0.00) and the graphs poisoned by NIPA averaged over 5 runs.</figDesc><table><row><cell>Dataset</cell><cell>r</cell><cell cols="4">Gini Coefficient Characteristic Path Length Distribution Entropy Power Law Exp. Triangle Count</cell></row><row><cell></cell><cell cols="2">0.00 0.4265 ± 0.0000</cell><cell>9.3105 ± 0.0000</cell><cell>0.9542 ± 0.0000</cell><cell>2.0584 ± 0.0000</cell><cell>1083.0 ± 0.0</cell></row><row><cell></cell><cell cols="2">0.01 0.4270 ± 0.0012</cell><cell>8.3825 ± 0.3554</cell><cell>0.9543 ± 0.0001</cell><cell>2.0296 ± 0.0024</cell><cell>1091.2 ± 6.6</cell></row><row><cell cols="3">CITESEER 0.02 0.4346 ± 0.0007</cell><cell>8.3988 ± 0.2485</cell><cell>0.9529 ± 0.0005</cell><cell>2.0161 ± 0.0007</cell><cell>1149.8 ± 32.4</cell></row><row><cell></cell><cell cols="2">0.05 0.4581 ± 0.0026</cell><cell>8.0907 ± 0.7710</cell><cell>0.9426 ± 0.0009</cell><cell>1.9869 ± 0.0073</cell><cell>1174.2 ± 42.8</cell></row><row><cell></cell><cell cols="2">0.10 0.4866 ± 0.0025</cell><cell>7.3692 ± 0.6818</cell><cell>0.9279 ± 0.0012</cell><cell>1.9407 ± 0.0088</cell><cell>1213.6 ± 61.8</cell></row><row><cell></cell><cell cols="2">0.00 0.3966 ± 0.0000</cell><cell>6.3110 ± 0.0000</cell><cell>0.9559 ± 0.0000</cell><cell>1.8853 ± 0.0000</cell><cell>1558.0 ± 0.0</cell></row><row><cell></cell><cell cols="2">0.01 0.4040 ± 0.0007</cell><cell>6.0576 ± 0.1616</cell><cell>0.9549 ± 0.0004</cell><cell>1.8684 ± 0.0016</cell><cell>1566.2 ± 7.4</cell></row><row><cell cols="3">CORA-ML 0.02 0.4075 ± 0.0002</cell><cell>6.1847 ± 0.1085</cell><cell>0.9539 ± 0.0002</cell><cell>1.8646 ± 0.0006</cell><cell>1592.0 ± 17.4</cell></row><row><cell></cell><cell cols="2">0.05 0.4267 ± 0.0014</cell><cell>5.8165 ± 0.1018</cell><cell>0.9458 ± 0.0009</cell><cell>1.8429 ± 0.0027</cell><cell>1603.8 ± 12.8</cell></row><row><cell></cell><cell cols="2">0.10 0.4625 ± 0.0005</cell><cell>6.1397 ± 0.0080</cell><cell>0.9261 ± 0.0007</cell><cell>1.8399 ± 0.0017</cell><cell>1612.4 ± 22.2</cell></row><row><cell></cell><cell cols="2">0.00 0.6037 ± 0.0000</cell><cell>6.3369 ± 0.0000</cell><cell>0.9268 ± 0.0000</cell><cell>2.1759 ± 0.0000</cell><cell>12520.0 ± 0.0</cell></row><row><cell></cell><cell cols="2">0.01 0.6076 ± 0.0005</cell><cell>6.3303 ± 0.0065</cell><cell>0.9253 ± 0.0004</cell><cell>2.1562 ± 0.0013</cell><cell>12570.8 ± 29.2</cell></row><row><cell cols="3">PUBMED 0.02 0.6130 ± 0.0006</cell><cell>6.3184 ± 0.0046</cell><cell>0.9213 ± 0.0004</cell><cell>2.1417 ± 0.0009 13783.4 ± 101.8</cell></row><row><cell></cell><cell cols="2">0.05 0.6037 ± 0.0000</cell><cell>6.3371 ± 0.0007</cell><cell>0.9268 ± 0.0000</cell><cell>2.1759 ± 0.0001 14206.6 ± 152.8</cell></row><row><cell></cell><cell cols="2">0.10 0.6035 ± 0.0003</cell><cell>6.2417 ± 0.1911</cell><cell>0.9263 ± 0.0010</cell><cell>2.1686 ± 0.0141 14912.0 ± 306.8</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://intl.alipay.com/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was funded in part by the NIH NCATS grant UL1 TR002014 and by NSF grants 1518732, 1640834, and 1636795, the Edward Frymoyer Endowed Professorship at Pennsylvania State University and the Sudha Murty Distinguished Visiting Chair in Neurocomputing and Data Science funded by the Pratiksha Trust at the Indian Institute of Science (both held by Vasant Honavar) and by Samsung GRO Award #225003 to Suhang Wang and Vasant Honavar.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An introduction to social network data analytics</title>
		<author>
			<persName><forename type="first">C</forename><surname>Charu</surname></persName>
		</author>
		<author>
			<persName><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Social network data analytics</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Emergence of scaling in random networks</title>
		<author>
			<persName><forename type="first">Albert-László</forename><surname>Barabási</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Réka</forename><surname>Albert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">science</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="page" from="509" to="512" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Poisoning attacks against support vector machines</title>
		<author>
			<persName><forename type="first">Battista</forename><surname>Biggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blaine</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pavel</forename><surname>Laskov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">29th Int&apos;l Conf. on Machine Learning (ICML)</title>
				<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Wild patterns: Ten years after the rise of adversarial machine learning</title>
		<author>
			<persName><forename type="first">Battista</forename><surname>Biggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Roli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="317" to="331" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking</title>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=r1ZdKJ-0W" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Shchur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.00816</idno>
		<title level="m">Netgan: Generating graphs via random walks</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Real-time bidding by reinforcement learning in display advertising</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kan</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kleanthis</forename><surname>Malialis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Defeng</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM International Conference on Web Search and Data Mining</title>
				<meeting>the Tenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="661" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Audio adversarial examples: Targeted attacks on speech-to-text</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Security and Privacy Workshops (SPW). IEEE</title>
		<imprint>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Narcissism on Facebook: Self-promotional and anti-social behavior</title>
		<author>
			<persName><forename type="first">J</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Personality and individual differences</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="482" to="486" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Jinyin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangyang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Xuan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.02797</idno>
		<title level="m">Fast gradient attack on network embedding</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Discriminative embeddings of latent variable models for structured data</title>
		<author>
			<persName><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2702" to="2711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.02371</idno>
		<title level="m">Adversarial attack on graph structured data</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName><forename type="first">Michaël</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Graph transformation policy network for chemical reaction prediction</title>
		<author>
			<persName><forename type="first">Kien</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Truyen</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Svetha</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="750" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On the evolution of random graphs</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Erdős</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alfréd</forename><surname>Rényi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Publ. Math. Inst. Hung. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="17" to="60" />
			<date type="published" when="1960">1960. 1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Graph Neural Networks for Social Recommendation</title>
		<author>
			<persName><forename type="first">Wenqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="417" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">CiteSeer: An Automatic Citation Indexing System</title>
		<author>
			<persName><forename type="first">Lee</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><forename type="middle">D</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM DL</title>
				<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Adam</forename><surname>Gleave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Kant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cody</forename><surname>Wild</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Russell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.10615</idno>
		<title level="m">Adversarial Policies: Attacking Deep Reinforcement Learning</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Securing the Deep Fraud Detector in Large-Scale E-Commerce Platform via Adversarial Machine Learning Approach</title>
		<author>
			<persName><forename type="first">Qingyu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengrui</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengchen</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="616" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Detecting overlapping communities from local spectral subspaces</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Bindel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Hopcroft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Data Mining</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="769" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adversarial attacks on stochastic bandits</title>
		<author>
			<persName><forename type="first">Kwang-Sung</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3640" to="3649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Heterogeneous graph neural networks for malicious account detection</title>
		<author>
			<persName><forename type="first">Ziqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaochao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinxing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management</title>
				<meeting>the 27th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2077" to="2085" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Data poisoning attacks in contextual bandits</title>
		<author>
			<persName><forename type="first">Yuzhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kwang-Sung</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Decision and Game Theory for Security</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="186" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Graph convolutional networks with eigenpooling</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charu</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="723" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Attacking graph convolutional networks via rewiring</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.03750</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automating the construction of internet portals with machine learning</title>
		<author>
			<persName><forename type="first">Andrew Kachites</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamal</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Rennie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristie</forename><surname>Seymore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="127" to="163" />
			<date type="published" when="2000">2000. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Using Machine Teaching to Identify Optimal Training-Set Attacks on Machine Learners</title>
		<author>
			<persName><forename type="first">Shike</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 29th AAAI Conference on Artificial Intelligence</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><forename type="middle">K</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Ostrovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="page">529</biblScope>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Friendship selection in the social internet of things: challenges and possible strategies</title>
		<author>
			<persName><forename type="first">Michele</forename><surname>Nitti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luigi</forename><surname>Atzori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irena</forename><forename type="middle">Pletikosa</forename><surname>Cvijikj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of things journal</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="240" to="247" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Triparty deep network representation</title>
		<author>
			<persName><forename type="first">Jia</forename><surname>Shirui Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingquan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Network</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Puschmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fintech. Business &amp; Information Systems Engineering</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="69" to="76" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Trust region policy optimization</title>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Moritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1889" to="1897" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsung-Yu</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianfeng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasant</forename><surname>Honavar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.01084</idno>
		<title level="m">Megan: A generative adversarial network for multi-view network embedding</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6199</idno>
		<title level="m">Intriguing properties of neural networks</title>
				<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Transferring Robustness for Graph Neural Network Against Poisoning Attacks</title>
		<author>
			<persName><forename type="first">Xianfeng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yandong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaxiu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasenjit</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Internatioal Conference on Web Search and Data Mining (WSDM)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Attacking Graph-based Classification via Manipulating the Graph Structure</title>
		<author>
			<persName><forename type="first">Binghui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Zhenqiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gong</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Computer and Communications Security (CCS)</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Structural deep network embedding</title>
		<author>
			<persName><forename type="first">Daixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1225" to="1234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">FdGars: Fraudster Detection via Graph Convolutional Networks in Online App Review System</title>
		<author>
			<persName><forename type="first">Jianyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Xion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of The 2019 World Wide Web Conference</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="310" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Nervenet: Learning structured policy with graph neural networks</title>
		<author>
			<persName><forename type="first">Tingwu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Reinforcement learning to rank with Markov decision process</title>
		<author>
			<persName><forename type="first">Zeng</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="945" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Adversarial Examples on Graph Data: Deep Insights into Attack and Defense</title>
		<author>
			<persName><forename type="first">Huijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuriy</forename><surname>Tyshetskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Docherty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liming</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Joint Conference on Artificial Intelligence</title>
				<meeting>the 28th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Han</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haochen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debayan</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anil</forename><surname>Jain</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.08072</idno>
		<title level="m">Adversarial attacks and defenses in images, graphs and text: A review</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning</title>
		<author>
			<persName><forename type="first">Ziyu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayavardhan</forename><surname>Reddy Peddamail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2203" to="2214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pong</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="974" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Graph convolutional policy network for goal-directed molecular graph generation</title>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="6410" to="6421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Representation learning for large-scale dynamic networks</title>
		<author>
			<persName><forename type="first">Yanwei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaxiu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongjian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianfeng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhui</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Database Systems for Advanced Applications</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="526" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Your Style Your Identity: Leveraging Writing and Photography Styles for Drug Trafficker Identification in Darknet Markets over Attributed Heterogeneous Information Network</title>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shifu</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanfang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiabin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3448" to="3454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Adversarial Attacks on Neural Networks for Graph Data</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Akbarnejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2847" to="2856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Adversarial Attacks on Graph Neural Networks via Meta Learning</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
