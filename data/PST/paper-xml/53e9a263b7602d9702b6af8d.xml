<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Yahoo! Music Recommendations: Modeling Music Ratings with Temporal Dynamics and Item Taxonomy</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Gideon</forename><surname>Dror</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Yahoo! Research Haifa</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Noam</forename><surname>Koenigstein</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Electrical Eng</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Yahoo! Research Haifa</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Yahoo! Music Recommendations: Modeling Music Ratings with Temporal Dynamics and Item Taxonomy</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3D53FD821C0884CB505432ECC85E670B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.2.8 [Database Applications]: Data Mining recommender systems</term>
					<term>collaborative filtering</term>
					<term>matrix factorization</term>
					<term>yahoo! music</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the past decade large scale recommendation datasets were published and extensively studied. In this work we describe a detailed analysis of a sparse, large scale dataset, specifically designed to push the envelope of recommender system models. The Yahoo! Music dataset consists of more than a million users, 600 thousand musical items and more than 250 million ratings, collected over a decade. It is characterized by three unique features: First, rated items are multi-typed, including tracks, albums, artists and genres; Second, items are arranged within a four level taxonomy, proving itself effective in coping with a severe sparsity problem that originates from the unusually large number of items (compared to, e.g., movie ratings datasets). Finally, fine resolution timestamps associated with the ratings enable a comprehensive temporal and session analysis. We further present a matrix factorization model exploiting the special characteristics of this dataset. In particular, the model incorporates a rich bias model with terms that capture information from the taxonomy of items and different temporal dynamics of music ratings. To gain additional insights of its properties, we organized the KddCup-2011 competition about this dataset. As the competition drew thousands of participants, we expect the dataset to attract considerable research activity in the future.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>People have been fascinated by music since the dawn of humanity. A wide variety of music genres and styles has evolved, reflecting diversity in personalities, cultures and age groups. It comes as no surprise that human tastes in music are remarkably diverse, as nicely exhibited by the famous quotation: "We don't like their sound, and guitar music is on the way out" (Decca Recording Co. rejecting the <ref type="bibr">Beatles, 1962)</ref>.</p><p>Yahoo! Music has amassed billions of user ratings for musical pieces. When properly analyzed, the raw ratings encode information on how songs are grouped, which hidden patterns link various albums, which artists complement each other, how the popularity of songs, albums and artists vary over time and above all, which songs users would like to listen to. Such an analysis introduces new scientific challenges. Inspired by the success of the Netflix Prize contest <ref type="bibr" target="#b4">[5]</ref>, we have created a large scale music dataset and challenged the research world to model it through the KDD Cup 2011 contest <ref type="foot" target="#foot_0">1</ref> . The contest released over 250 million ratings performed by over 1 million anonymized users. The ratings are given to different types of items: tracks, albums, artists, genres, all tied together within a known taxonomy. At the time of writing, half throughout the contest, the contest has attracted thousands of actively participating teams trying to crack the unique properties of the dataset.</p><p>Noteworthy characteristics of the dataset include: First, it is of a larger scale compared to other datasets in the field. Second, it has a very large set of items (over 600K) -much larger than similar datasets, where usually only the number of users is large. This is mostly attributed to the large number of available music tracks. Third, there are four different categories of items, which are all linked together within a defined taxonomy thereby alleviating the unusually low number of ratings per item. Finally, given the recently shown importance of temporal dynamics in modeling user rating behavior <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b25">26]</ref>, we included in the dataset a fine resolution of rating timestamps. Such timestamps allow performing session analysis of user activities or determining the exact order in which ratings were given. Prior to the release of the dataset, we have conducted an extensive analysis and modeling of its properties. This work reports our main results and methodologies. In the following we highlight our main modeling contributions.</p><p>Music consumption is biased towards a few popular artists and so is the rating data. Therefore, collaborative filtering (CF) techniques suffer from a cold-start problem in many of the less popular artists in the "long tail" <ref type="bibr" target="#b6">[7]</ref>. The problem becomes even more severe when considering individual tracks and albums. We tackle this item sparsity issue with a novel usage of music taxonomy information. Accordingly, we describe a method for sharing information across different items of the same taxonomy, which mitigates the problem of predicting items with insufficient rating data.</p><p>Our model, which is based on matrix factorization, incorporates temporal analysis of user ratings, and item popularity trends. We show the significance of a temporal analysis of user behavior-within a refined session-based resolution-in improving the model predictive accuracy. In particular, we show how to perform such an analysis in a computationally friendly framework.</p><p>Last but not least, we have invested much efforts in uncovering biases, which is based on our experience that a CF model would significantly benefit from accounting for user and item biases. Indeed empirical evidence shows that biases explain a significant part of the observed rating behavior. Hence, we provide detailed parameterizations of biases combining conventional user and item biases with the readily available taxonomy and temporal information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>There are several approaches to music recommendations <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b21">22]</ref>:</p><p>• Collaborative Filtering (CF) methods utilize user feedback (explicit or implicit) to infer relations between users, between items, and ultimately relate users to items they like.</p><p>Unlike the other approaches they are content agnostic and do not use domain knowledge. • Signal Filtering methods (also known as "content filtering") analyze the audio content for characterizing tracks and establishing item-to-item similarities <ref type="bibr" target="#b1">[2]</ref>. For example, Mel-Frequency Cepstral Coefficients (MFCCs) are often used to generate feature vectors, which can be used to find other items with acoustic resemblance <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b17">18]</ref>. Given the nature of our dataset, we focus on a CF approach. In general, CF has proved more accurate in predicting rating datasets devoid of intrinsic item information such as the Netflix dataset <ref type="bibr" target="#b3">[4]</ref>. However, algorithms based on collaborative filtering typically suffer from the cold-start problem when encountering items with little rating information <ref type="bibr" target="#b23">[24]</ref>. Several hybrid approaches are suggested for merging content filtering and CF; see, e.g. some of the more recent approaches <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>. They allow relying on item attributes when rating information is not sufficient, while still enjoying the improved accuracy CF offers as more ratings are gathered. In our system, we use a taxonomy to share information between rated items. For example, the representation of tracks with a little rating data naturally collapses to the representation of their respective album and artist as described in Sec. 5.3 and 6.1.</p><p>We employ a Matrix Factorization (MF) model, which maps items and users into comparable latent factors. Such techniques became a popular choice for implementing CF and a survey can be found at <ref type="bibr" target="#b13">[14]</ref>. Typically, in MF a user is modeled by a factor vector pu ∈ R d , and an item is modeled by a factor vector qi ∈ R d . A predicted rating rui by user u to item i is given by</p><formula xml:id="formula_0">rui = µ + bi + bu + p T u qi<label>(1)</label></formula><p>where µ is the average rating, and bu and bi are the user and item biases respectively. The term p T u qi captures the affinity of user u to item i. Sec. 5 and 6 discuss these components in depth.</p><p>User preferences and item popularity tend to drift over time. Thus, a few recent works <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b25">26]</ref> highlighted the significance of a delicate modeling of temporal dynamics when devising collaborative filtering models. Our approach is related to <ref type="bibr" target="#b12">[13]</ref>. The two  <ref type="bibr" target="#b0">(1)</ref> This work applies more refined session analysis rather than working at a coarser day resolution. <ref type="bibr" target="#b1">(2)</ref> We employ a much more memory efficient method for modeling the way user factor vectors drift over time.</p><p>We have also benefited from techniques suggested by Piotte and Chabbert <ref type="bibr" target="#b20">[21]</ref> in their Netflix Prize solution. First, we adopted their method of using Nelder Mead optimization <ref type="bibr" target="#b19">[20]</ref> for automatically setting meta-parameters, and have taken it a step further by using a parallel implementation; see Sec. 7.1. Second, we have used their idea of modeling smooth temporal dynamics by learning to combine several basis functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">THE YAHOO! MUSIC DATASET</head><p>Yahoo! Music<ref type="foot" target="#foot_1">3</ref> offers a wealth of information and services related to many aspects of music. We have compiled a dataset of user ratings of music items collected during a decade of using the Yahoo! Music website. The dataset was released within the first track of the KDD Cup 2011 contest. It comprises of 262,810,175 ratings of 624,961 items by 1,000,990 users. The ratings include both date and one-minute resolution timestamps, allowing refined temporal analysis. Each item and each user has at least 20 ratings in the whole dataset. The available ratings were split into train, validation and test sets such that the last 6 ratings of each user were placed in the test set and the preceding 4 ratings were used in the validation set. All earlier ratings (at least 10) comprise the train set. Table <ref type="table" target="#tab_1">1</ref> details the total number of ratings in the train, validation and test sets. The ratings are integers between 0 and 100. Figure <ref type="figure" target="#fig_0">1</ref> depicts the distribution of ratings in the train set using a logarithmic vertical scale. The vast majority of the ratings are multiples of ten, and only a minuscule fraction are not. This mixture reflects the fact that several interfaces ("widgets") were used to rate the items, some of them changing throughout the years while allowing different usage options. While different widgets have different appearances, scores have always been stored internally at a common 0-100 scale. We possess only the 0-100 internal representation, and do not know the exact widget used for creating each rating. Still, the popularity of a widget used to enter ratings at a 1-to-5 star scale is reflected by the dominance of the peaks at 0, 30, 50, 70 and 90 into which star ratings were translated. Not surprisingly, most items have intermediate mean rating and only few items have a mean rating on extreme high or low ends of the scale. Indeed, the distribution of item mean ratings follow a unimodal distribution, with a mode at 50 as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. Interestingly, the distribution of item mean ratings presented in Fig. <ref type="figure" target="#fig_1">2</ref> is very different from the distribution of mean ratings of users, depicted in Fig. <ref type="figure" target="#fig_2">3</ref>: the distribution is now strongly skewed, with mode shifted to a mean rating of 89. Different rating behavior of users accounts for the apparent difference between the distributions. It turns out that users who rate more items tend to have considerably lower mean ratings. Fig. <ref type="figure" target="#fig_3">4</ref> substantiates this effect. Users were binned according to the number of items they rated, on a linear scale. The graph shows the median of the mean ratings in each bin, as well as the inter-quantile range in each bin plotted as a vertical line. One of the explanations for this effect is that among the tens of thousands of items rated by the "heavy" raters, the majority do not match their taste.</p><p>A distinctive feature of this dataset is that user ratings are given to entities of four different types: tracks, albums, artists, and genres. The majority of items (81.15%) are tracks, followed by albums (14.23%), artists (4.46%) and genres (0.16%). The ratings however, are not uniformly distributed: Only 46.85% of the ratings belong to tracks, followed by 28.84% to artists, 19.01% to albums and 5.3% to genres. Moreover, these proportions are strongly dependent on the number of ratings a user has entered. Heavier raters naturally cover more of the numerous tracks, while the light raters mostly concentrate on artists; the effect is shown in Fig. <ref type="figure" target="#fig_4">5</ref>. Thus, the validation and test sets, which equally weight all users, are dominated by the many light-raters and dedicate most of their ratings to artists rather than to tracks; see Table <ref type="table" target="#tab_3">3</ref>. All rated items are tied together within a taxonomy. That is, for a track we know the identity of its album, performing artist and associated genres. Similarly we have artist and genre annotation for the albums. There is no genre information for artists, as artists may switch between many genres in their career. We show that this taxonomy is particularly useful, due to the large number of items and the sparseness of data per item (mostly attributed to "tracks" and "albums").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">NOTATION</head><p>We reserve special indexing letters for distinguishing users from items: for users u, and for items i. A rating rui indicates the rating given by user u to item i. We distinguish predicted ratings from known ones using the notation rui for the predicted value of rui.</p><p>For tracks, we denote by album(i) and artist(i) the album and the artist of track i respectively. Similarly, for albums, we denote by artist(i) the artist of album i. Tracks and albums in the Yahoo! Music dataset may belong to one or more genres. We denote by genres(i) the set of genres of item i. Lastly, we denote by type(i) the type of item i, with type(i) ∈ {track, album, artist, genre}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">BIAS MODELING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Why biases?</head><p>When considering their vast explanation power, biases are among the most overlooked components of recommender models. In the context of rating systems, biases model the portion of the observed signal that is derived either solely by the rating user or solely by rated item, but not by their interaction. For example, user bias may model a user's tendency to rate on a higher or lower scale than the average rater, while the item bias may capture the extent of the item popularity. A general framework for capturing the bias of the rating by user u to item i is described as</p><formula xml:id="formula_1">bui = µ + Bi + Bu (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where µ is the overall mean rating value (a constant), and Bi and Bu stand for item and user biases, respectively. Since components of the user bias are independent of the item being rated, while components in the item bias are independent of any user, they do not take part in modeling personalization, e.g., modeling user musical taste. After all, ordering items by using only a bias model (2) necessarily produces the same ranking for all users, hence personalization-the cornerstone of recommendation systems-is not achieved at all.</p><p>Lack of personalization power should not be confused with lack of importance for biases. There is plenty of evidence that much of the observed variability in rating signal should be attributed to biases. Hence, properly modeling biases would effectively amount to cleaning the data from signals unrelated to personalization purposes. This will allow the personalization part of the model (e.g., matrix factorization), where users and items do interact, to be applied to a signal more purely relevant for personalization. Perhaps the best evidence is the heavily analyzed Netflix Prize dataset <ref type="bibr" target="#b4">[5]</ref>. The total variance of the ratings in this dataset is 1.276, corresponding to a Root Mean Squared Error (RMSE) of 1.1296 by a constant predictor. Three years of multi-team concentrated efforts reduced the RMSE to 0.8556, thereby leaving the unexplained ratings variance at 0.732. Hence the fraction of explained variance (known as R 2 ) is 42.6%, whereas the rest 57.4% of the ratings variability is due to unmodeled effects (e.g., noise). Now, let us analyze how much of the explained variance should be attributed to biases, unrelated to personalization. The best published pure bias model <ref type="bibr" target="#b11">[12]</ref> yields an RMSE=0.9278, which is equivalent to reducing the variance to 0.861 thereby explaining 32.5% of the observed variance. This (quite surprisingly) means that the vast majority of the 42.6% explainable variance in the Netflix dataset, should be attributed to user and item biases having nothing to do with personalization. Only about 10% of the observed rating variance comes from effects genuinely related to personalization. In fact, as we will see later (Sec. 7), our experience with the music dataset similarly indicates the importance role biases play. Here the total variance of the test dataset is 1084.5 (reflecting the 0-100 rating scale). Our best model could reduce this variance to around 510.3 (R 2 = 52.9%). Out of this 52.9% explained variance <ref type="foot" target="#foot_2">4</ref> , once again the vast majority (41.4%) is attributed to pure biases, leaving about 11.5% to be ex-plained by personalization effects. Hence, the big importance one should put on well modeling biases.</p><p>In this section, we present a rich model for both the item and user biases, which accounts for the item taxonomy, user rating sessions, and items' temporal dynamics. The model adheres to the framework of Eq. ( <ref type="formula" target="#formula_1">2</ref>). In the following we will gradually develop its Bi and Bu components. The predictive performance of the various components of the bias model is discussed in Sec. 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">A basic bias model</head><p>The most basic bias model captures the main effects associated with users and items <ref type="bibr" target="#b10">[11]</ref>. Following bias template (2), we set the item bias Bi as a distinct parameter associated with each item denoted by bi, and similarly the user bias Bu as a user-specific parameter bu. This gives rise to the model bui = µ + bi + bu</p><p>(3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Taxonomy biases</head><p>We start enhancing our bias model by letting item biases share components for items linked by the taxonomy. For example, tracks in a good album may all be rated somewhat higher than the average, or a popular artist may have all her songs rated a bit higher than the average. We therefore add shared bias parameters to different items with a common ancestor in the taxonomy hierarchy. We expand the item bias model for tracks as follows</p><formula xml:id="formula_3">B (0) i = bi + b album(i) + b artist(i) + 1 |genres(i)| X g∈genres(i) bg<label>(4</label></formula><p>) Here, the total bias associated with a track i sums both its own specific bias modifier (bi), together with the bias associated with its album (album(i)) and its artist (artist(i)), and the mean bias associated with its genres( 1 |genres| P g∈G bg). Similarly for each album we expand the bias model as follows</p><formula xml:id="formula_4">B (0) i = bi + b artist(i) + 1 |genres(i)| X g∈genres(i) bg<label>(5)</label></formula><p>One could view these extensions as a gradual accumulation of the biases. For example, when modeling the bias of album i, the start point is b artist(i) + 1 |genres(i)| P g∈genres(i) bg, and then bi adds a residual correction on top of this start point. Similarly, when i is a track another item-specific correction is added on top of the above. As bias estimates for tracks and albums are less reliable, such a gradual estimation allows basing them on more robust initial values.</p><p>Note that such a framework not only relates items to their taxonomy ancestors, but (indirectly) also to other related items in the taxonomy (e.g., a track will get related to all other tracks in its album, and to lesser extent to all other tracks by the same artist).</p><p>Also, note that while artists and genres are less susceptible to the sparsity problem, they also benefit from this model as any rating to track and album also influences the biases of their corresponding artist and genre.</p><p>The taxonomy of items is also useful for expanding the user bias model. For example, a user may tend to rate artists or genres higher than songs. Therefore, given an item i the user bias is</p><formula xml:id="formula_5">B (0) u = bu + b u,type(i) (<label>6</label></formula><formula xml:id="formula_6">)</formula><p>where bu is user specific bias component and b u,type(i) is a shared component of all the ratings by user u to items of type type(i).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">User sessions</head><p>A distinctive property of the Yahoo! Music dataset is its temporal information. Each rating is marked by a date and a timestamp with resolution down to minutes. We used this information for modeling temporal dynamics of both items and users. We start by modeling user sessions. Unlike movies, in music it is common for users to listen to many songs and rate them one after the other. A rating session is therefore a set of consecutive ratings without an extended time gap between them. There are many psychological phenomena that affect ratings grouped in a single session. These effects are captured by user session biases.</p><p>One example is the fact that the order in which the songs were listened by the user might determine the ratings scores, a phenomenon known as the drifting effect <ref type="bibr" target="#b9">[10]</ref>. Users tend to rate items in the context of previous items they rated. If the first song a user hears is particularly good, the following items are likely to be rated by that user lower than the first song. Similarly, if the user did not enjoy the first song, the ratings of subsequent songs may shift upwards. The first song therefore may serve as a reference rating to all the following ratings. However, with no absolute reference for the first rating, the user sometimes find it hard to rate, and some users tend to give it a default rating (e.g., 70 or 50). Consequently, all the following ratings in that same session may be biased higher or lower according to the first rating. Another source for session biases is the mood of the user. A user may be in a good/bad mood that may affect her ratings within a particular session. It is also common to listen to similar songs in the same session, and thus their ratings become similar.</p><p>To take such effects into account, we added a session bias term to our user bias model. We thus marked users' consecutive ratings with session numbers separated by a time gap of at least 5 hours in which the user was idle (no rating activity). We denote by session(u, i) the rating session of the rating rui, and expand our user bias model to include session biases</p><formula xml:id="formula_7">B (1) u = B (0) u + b u,session(i,u)<label>(7)</label></formula><p>The session bias parameter b u,session(i,u) models the bias component common to all ratings of u in the same session he rated i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Items temporal dynamics</head><p>The popularity of songs may change dramatically over time. While users' temporal dynamics seem to follow abrupt changes across sessions, items' temporal dynamics are much smoother and slower, thus calling for a different modeling approach.</p><p>Given item i and the time t since i's first rating, we define a time dependent item bias as a linear combination of n temporal basis functions f (t) = (f1(t), f2(t), ...fn(t)) T and expand the item bias component to be</p><formula xml:id="formula_8">B (1) i = B (0) i + c T i f (t)<label>(8)</label></formula><p>where ci ∈ R n is an item specific vector of coefficients. Both f (t) and ci are learned from data using the standard RMSEminimizing stochastic gradient descent (SGD), which is also used for learning the other model components. In practice, a 2-week coarse time resolution is sufficient for the rather slow changing item temporal dynamics, therefore the basis functions are only estimated at a small number of points and can be easily learned. This process does not guarantee an orthogonal or normalized basis, however it finds a basis that fits the patterns seen in the dataset.</p><p>We have found that a basis of 4 functions is sufficient to represent the temporal dynamics of item biases in our dataset. Figure <ref type="figure" target="#fig_5">6</ref> depicts the learned basis functions {fi(t)} 4 i=1 . Since the coefficients of the basis function can be be either positive or negative, it is hard to give a clear interpretation to any specific basis function. How- i=1 vs. time since an item's first rating measured in weeks ever, an interesting observation is that basis functions seem to have high gradients right after an item was released, indicating more dynamic temporal effects in this time period. It is also interesting to note that after a long time period (above 360 weeks), the temporal basis functions converge into relatively steady values. This indicates that at a longer perspective, items seem to have either a positive or a negative bias, with much less temporal dynamics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Full bias model</head><p>To summarize, our complete bias model, including both enhanced user and item biases is (for a track i) bui =µ + b u,type(i) + b u,session(i,u) + bi + b album(i)</p><formula xml:id="formula_9">+ b artist(i) + 1 |genres(i)| X g∈genres(i) bg + c T i f (tui) (9)</formula><p>where tui is the time elapsed from i's first rating till u's rating of i.</p><p>Learning the biases is performed by SGD together with the other model components as described in the next section. The extended bias model dramatically reduced the RMSE even before any personalization components were added into the model (see results in Sec. 7). Biases were able to absorb much of the effects irrelevant to personalization. Such a "cleaning" proved to be a key for accurately modeling personalization in later stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">PERSONALIZATION MODEL</head><p>Our initial personalization model is based on a classical matrix factorization approach. Each user u is associated with a user-factor vector pu ∈ R d , and each item i with an item-factor vector qi ∈ R d . Predictions are done using the rule</p><formula xml:id="formula_10">rui = bui + p T u qi (<label>10</label></formula><formula xml:id="formula_11">)</formula><p>where bui is the bias model ( <ref type="formula">9</ref>), and p T u qi is the personalization model which captures user's u affinity to item i. In this section, we expand this basic personalization model to encompass more patterns observed in the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Taxonomy in personalization</head><p>Musical artists often have a distinct style that can be recognized in all their songs. Similarly, artists style can be recognized across different albums of the same artist. Therefore, we introduce shared factor components to reflect the affinity of items linked by the taxonomy. Specifically, for each artist and album i, we employ a factor vector vi ∈ R d (in addition to also using the aforementioned qi). We expand our item representation for tracks to explicitly tie tracks linked by the taxonomy</p><formula xml:id="formula_12">qi def = qi + v album(i) + v artist(i)<label>(11)</label></formula><p>Therefore, qi represents the difference of a specific track from the common representation of all other related tracks, which is especially beneficial when dealing with less popular items. Similarly, we expand our item representation for albums to be</p><formula xml:id="formula_13">qi def = qi + v artist(i)<label>(12)</label></formula><p>One may also add shared factor parameters for tracks and albums sharing the same genre, similarly to the way genres were exploited for enhancing biases. However, our experiments did not show an RMSE improvement by incorporating shared genre information. This indicates that after exploiting the shared information in albums and artists, the remaining information shared by common items of the same genre is limited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Session specific user factors</head><p>As discussed earlier, much of the observed changes in user behavior are local to a session and unrelated to longer term trends. Thus, after obtaining a fully trained model (hereinafter, "Phase I") we perform a second phase of training, which isolates rating components attributed to session-limited phenomena. In this second phase, when we reach each user session, we try to absorb any session specific signal in separated component of the user factor. To this end we expand the user representation into</p><formula xml:id="formula_14">pu = pu + pu,session<label>(13)</label></formula><p>where the user representation pu consists of both the original user factor pu and and the session factor vector pu,session. We learn pu,session by fixing all other parameters and making a few (e.g., 3) SGD iterations only on the ratings given in the current session in order to learn pu,session. After these iterations, we are able to absorb much of the temporary per-session user behavior into pu,session, which is not explained by the model learned in Phase I. We then move to a final relaxation step, where we run one more iteration over all ratings in the same session, now allowing all other model parameters to change and shed away any per session specific characteristics. Since pu,session already captures much of the per-session effects of the user factor, the other model parameters adjust themselves accordingly and capture possible small changes since the previous rating session. After this relaxation step, we reset pu,session to zero, and move on to the next session, repeating the above process.</p><p>Our approach is related to <ref type="bibr" target="#b12">[13]</ref>, which has also employed day specific factor vectors for each user. However, there are two notable differences. First, we apply a more refined session analysis rather than working at a coarser day resolution. Second, we employ a much more memory efficient method: since we discard the per session components pu,session after iterating through each session, there is no need to store session vectors for every session in the dataset. At the time of prediction, we only use the last session vector. We therefore avoid the high memory consumption that occurs in previous approaches. For example, our dataset consists of 13,844,810 ratings sessions (for all users). Using a 100-D factorization model with single precision floating point numbers (4 bytes), it would have taken more than 5.5GB of memory to store all the user session factors, significantly larger than the 400MB required to store only a single session factor for each user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Learning the model</head><p>Our final prediction model takes the following form</p><formula xml:id="formula_15">rui = bui + pT u qi<label>(14)</label></formula><p>where bui is the detailed bias model as in <ref type="bibr" target="#b8">(9)</ref>, qi is our enhanced item factor representation as described in ( <ref type="formula" target="#formula_12">11</ref>) and ( <ref type="formula" target="#formula_13">12</ref>), and pu is defined in <ref type="bibr" target="#b12">(13)</ref>.</p><p>As previously alluded, learning proceeds by stochastic gradient descent (SGD), where all learned parameters are L2-regularized. SGD visits the training examples one-by-one, and for each example updates its corresponding model parameters. More specifically, for training example (u, i), SGD lowers the squared prediction error e 2 ui = (rui -rui) 2 by updating each individual parameter θ by</p><formula xml:id="formula_16">∆θ = -η ∂e 2 ui ∂θ -λθ = 2ηeui ∂ rui ∂θ -λθ<label>(15)</label></formula><p>here η is the learning rate and λ is the regularization rate.</p><p>Our dataset spans over a very long time period (a decade). In such a long period musical taste of users slowly drifts. We therefore expect model parameters to change with time. We exploit the fact that the SGD optimization procedure gradually updates the model parameters while visiting training examples one by one. It is a common practice in online learning to order training examples by their time, so when the model training is complete, the learned parameters reflect the latest time point, which is most relevant to the test period. Since we perform a batch learning including several sweeps through the dataset, we need to enhance this simple technique.</p><p>We loop through the data in a cyclic manner: we visit user-byuser, whereas for each user first we sweep forward from the earliest rating to the latest one, and then (after also visiting all other users) we sweep backward from the latest rating to the earliest one, and so on. This way, we avoid the otherwise discontinuous jump from the latest rating to the first one when starting a new iteration. This allows parameters to slowly drift with time as the user changes her taste. The process always terminates with a forward iteration ending at the latest rating.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">EVALUATION</head><p>We learned our model on the train dataset using a stochastic gradient descent algorithm with 20 iterations. We used the validation dataset for early termination and for setting meta-parameters; see Sec. 7.1. We then tested the results in terms of RMSE as described in Sec. 7.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Optimizing with Nelder-Mead</head><p>For each type of learned parameter we set a distinct learning rate (aka, step size) and regularization rate (aka, weight decay). This grants us the flexibility to tune learning rates such that, e.g., parameters that appear more often in a model are learned more slowly (and thus more accurately). Similarly, the various regularization coefficients allow assuming different scales for different types of parameters.</p><p>We have used the validation dataset to find proper values for these meta parameters. Optimization of meta-parameters is a costly procedure, since we know very little on the behavior of the objective function, and because every evaluation requires running the SGD algorithm on the entire dataset. The fact that we have multiple learning and regularization parameters further complicates the matter. For optimizing more than 20 meta-parameters we resorted to the Nelder-Mead simplex search algorithm <ref type="bibr" target="#b19">[20]</ref>. Though not guaranteed to converge to the global minimum <ref type="bibr" target="#b14">[15]</ref>, Nelder-Mead search is a widely used algorithm with excellent results on real world scenarios <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b24">25]</ref> a parallel version of the algorithm <ref type="bibr" target="#b16">[17]</ref>. We consider such an automated meta-parameters optimization process as key ingredient in enabling the development of a rich and flexible model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Experimental results</head><p>After the parameters optimization step of Sec. 7.1, we fixed the meta-parameters and re-built our final model using both the train and validation sets. We then report our results on the test set. We measured the RMSE of our predictions as we gradually add components to the bias models, and then as we gradually add components to the personalization model. This approach allows isolating the contribution of each component in the model. The results are presented in Table <ref type="table" target="#tab_2">2</ref>.</p><p>The most basic model is a constant predictor. In the case of the RMSE cost function, the optimal constant predictor would be the mean train rating, rui = µ; see row 1 of the table. In row 2 we present the basic bias model rui = µ + bi + bu (3). In row 3 we report the results after expanding the item and user biases to include also taxonomy terms, which mitigate data sparseness by capturing relations between items of the same taxonomy; see Sec. 5.3. We then added the user session bias of Sec. 5.4. This gave a significant reduction in terms of RMSE as reported in row 4. We believe that modeling session biases in users' ratings is key in explaining ratings behavior in domains like music in which users evaluate and rate multiple items at short time frames. In row 5 we add the item temporal bias from Sec. 5.5. This term captures changes in item biases that occur over the lifespan of items since their first ratings. This bias is especially useful in domains in which item popularity easily changes over time such as in music, or datasets in which the ratings history is long. The result in row 5 reflects the RMSE of our final bias model (defined in Sec. 5.6), when no personalization is yet in place.</p><p>We move on to personalized models, which utilize a matrix factorization component of dimension 50. The model of (10) yields RMSE of 22.9235 (row 6). By adding taxonomy terms to the item factors, we were able to reduce this result to 22.8254 (row 7). Finally, in row 8 we report the full prediction model including user session factors (as in Sec. 6.2). The relatively large drop in RMSE, even when the model is already fully developed, highlights the significance of temporal dynamics at the user factor level. The result given in row 8 puts our model in par with the leading models in the KDD Cup 2011 competition (as of the time of writing), which  Let us consider the effect of the taxonomy on the RMSE results of each item type. Table <ref type="table" target="#tab_3">3</ref> breaks down the RMSE results per item type of the three personalized models. It is clear that incorporating the taxonomy is most helpful for the sparsely rated tracks and albums. It is much less helpful for artists, and becomes counterproductive for the densely rated genres.</p><p>We further investigate the performance of our model as more factors are added. Figure <ref type="figure" target="#fig_6">7</ref> depicts the RMSE vs. factors dimensionality. Since we carefully tune the regularization terms, there is no overfitting even as the dimensionality reaches 500. However, there are clearly diminishing returns of increasing dimensionality, with almost no improvement over 100 dimensions. Note that the reduction in RMSE given by the taxonomy and session factors remains steady even as the dimensionality increases.</p><p>Lastly, we investigate the relation of the test RMSE to the time distance from the train set. Figure <ref type="figure" target="#fig_7">8</ref> depicts the mean RMSE and the elapsed time for each bin. Ratings with a zero elapsed time, which mostly correspond to user sessions artificially split between train and test set, were excluded from this analysis, as they are not relevant for any real recommender system. The plateau on the left part of the figure suggests that the performance of the model is stable for about three months since the time it was trained, whereupon the RMSE of its predictions gradually increases. Thus the model needs updating only once in a month or so in order to exhibit uniform performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">DISCUSSION</head><p>In this work, we introduced a large scale music rating dataset that is likely to be the largest of its kind. We believe that data availability is a key in enabling the progress of Web science, as demonstrated by the impact of the Netflix Prize dataset release. In the same spirit, we decided to share a large industrial dataset with the public, and to increase its impact and reach by including it in the KddCup-2011 contest.</p><p>While releasing real commercial data to the research world is critical to facilitating scientific progress, this process is far from trivial and definitely not risk free. On the one hand privacy advocates tend to push for over-sanitizing the data to the extent of putting an intermediary between the public and the dataset. The 2006 privacy crisis related to the AOL query data release and the more recent claims concerning privacy of the Netflix data clearly demonstrate this point. On the other hand, scientists are eager to receive the data in a form as complete as possible to facilitate unrestricted analysis. This has put us through a real dilemma, having to justify the release despite what seems to be a no win situation.</p><p>After conducting a thorough due diligence, we opted to release a sampled dataset, where both users and items are fully anonymized, which in our opinion maintains a good balance between privacy needs and scientific progress. The resulting dataset favors the application of collaborative filtering (CF) methods, which can excel without relying on item identities or attributes. We aimed at structuring the data in a way that offers a potential to sharpen current CF methods, by posing new scientific challenges and methodologies not offered by most prior datasets. The developments permitted by using the dataset, such as those discussed in this paper, are likely to be applicable at other setups, not necessarily music-related, reaping the benefits of using the domain-free CF approach.</p><p>Prior to releasing a dataset it is essential to go through data organization and sanitization. Consequently, we conducted an intensive analysis of the dataset to ensure a successful public release. The efforts reported in this work are based on our pre-release extensive analyzing and modeling efforts. We formulated a detailed collaborative filtering model, specifically designed to account for the dataset properties. The underlying design process can be valuable in many other recommendation setups. The process is based on gradual modeling of additive components of the model, each trying to reflect a unique characteristic of the data. Within this process, a major lesson is the need to dedicate significant efforts to estimating and modeling biases in the data, which tend to capture much of the observed data variability. Analyzing the effect of each component on the performance of the model supports this approach.</p><p>Finally, we are encouraged by the large number of teams (over 1000) currently analyzing the dataset within the KddCup-2011 contest, and look forward to observing new progress and getting new insights from the contest community.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The distribution of ratings. The approximately discrete nature of the distribution is evident</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FrequencyFigure 2 :</head><label>2</label><figDesc>Figure 2: The distribution of item mean ratings</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FrequencyFigure 3 :</head><label>3</label><figDesc>Figure 3: The distribution of user mean ratings</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Median of user ratings as a function of the number of ratings issued by the user. The vertical lines represent interquartile range.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The fraction of ratings the four item types receive as a function of the number of ratings a user gives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Items temporal basis functions {fi(t)} 4 i=1 vs. time since an item's first rating measured in weeks</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: RMSE vs. dimensionality of factors (d). We track regular MF, MF enhanced by taxonomy and the final model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: RMSE vs. number of days elapsed since last user's training exampleis notable considering the fact that we are not blending multiple models, neither impute information taken from the test set.Let us consider the effect of the taxonomy on the RMSE results of each item type. Table3breaks down the RMSE results per item type of the three personalized models. It is clear that incorporating the taxonomy is most helpful for the sparsely rated tracks and albums. It is much less helpful for artists, and becomes counterproductive for the densely rated genres.We further investigate the performance of our model as more factors are added. Figure7depicts the RMSE vs. factors dimensionality. Since we carefully tune the regularization terms, there is no overfitting even as the dimensionality reaches 500. However, there are clearly diminishing returns of increasing dimensionality, with almost no improvement over 100 dimensions. Note that the reduction in RMSE given by the taxonomy and session factors remains steady even as the dimensionality increases.Lastly, we investigate the relation of the test RMSE to the time distance from the train set. Figure8depicts the mean RMSE and the elapsed time for each bin. Ratings with a zero elapsed time, which mostly correspond to user sessions artificially split between train and test set, were excluded from this analysis, as they are not relevant for any real recommender system. The plateau on the left part of the figure suggests that the performance of the model is stable for about three months since the time it was trained, whereupon the RMSE of its predictions gradually increases. Thus the model needs updating only once in a month or so in order to exhibit uniform performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 : Train, validation and test set sizes notable differences are:</head><label>1</label><figDesc></figDesc><table><row><cell>Train</cell><cell>Validation</cell><cell>Test</cell></row><row><cell cols="3">252,800,275 4,003,960 6,005,940</cell></row></table><note><p>2 www.pandora.com</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 : Root Mean Squared Error (RMSE) of the evolving model. RMSE reduces while adding model components.</head><label>2</label><figDesc>. To speed up the search we implemented</figDesc><table><row><cell cols="2"># Model Name</cell><cell>RMSE</cell></row><row><cell cols="2">1 Mean Score</cell><cell>38.0617</cell></row><row><cell cols="2">2 Items and Users Bias</cell><cell>26.8561</cell></row><row><cell cols="2">3 Taxonomy Bias</cell><cell>26.2553</cell></row><row><cell cols="2">4 User Sessions Bias</cell><cell>25.3901</cell></row><row><cell cols="3">5 Items Temporal Dynamics Bias 25.2095</cell></row><row><cell>6 MF</cell><cell></cell><cell>22.9533</cell></row><row><cell cols="2">7 Taxonomy</cell><cell>22.7906</cell></row><row><cell>8 Final</cell><cell></cell><cell>22.5918</cell></row><row><cell></cell><cell cols="2">Track Album Artist Genre</cell></row><row><cell>%Test</cell><cell cols="2">28.7% 11.01% 51.61% 8.68%</cell></row><row><cell>MF</cell><cell cols="2">27.1668 24.5203 20.9815 15.7887</cell></row><row><cell cols="3">Taxonomy 26.8899 24.3531 20.8766 15.7965</cell></row><row><cell>Final</cell><cell cols="2">26.85 24.1854 20.566 15.4801</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 : RMSE per item type for the three personalized models. We also report the fraction of each item type in the test dataset.</head><label>3</label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>kddcup.yahoo.com   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>new.music.yahoo.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>Unlike the Netflix dataset case in which tremendous efforts were invested, here we can safely assume that eventually the explained variance will exceed</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>52.9% by subsequent works and by blending multiple predictors.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">ACKNOWLEDGEMENTS</head><p>The authors would like to thank Prof. Yuval Shavitt for his support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Regression-based latent factor models</title>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">B.-C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Content-based transformations</title>
		<author>
			<persName><forename type="first">X</forename><surname>Amatriain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bonada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Àlex Loscos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Arcos</surname></persName>
		</author>
		<author>
			<persName><surname>Verfaille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of New Music Research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Music similarity measures: What&apos;s the use?</title>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Aucouturier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pachet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Symposium on Music Information Retrieval</title>
		<meeting>3rd Symposium on Music Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="157" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Lessons from the netflix prize challenge</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explor. Newsl</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="75" to="79" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The netflix prize</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lanning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. KDD Cup and Workshop</title>
		<meeting>KDD Cup and Workshop</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Music Recommendation and Discovery in the Long Tail</title>
		<author>
			<persName><forename type="first">O</forename><surname>Celma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
		<respStmt>
			<orgName>Universitat Pompeu Fabra</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">From hits to niches? or how popular artists can bias music recommendation and discovery</title>
		<author>
			<persName><forename type="first">O</forename><surname>Celma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd KDD Workshop on Large-Scale Recommender Systems and the Netflix Prize Competition</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning attribute-to-feature mappings for cold-start recommendations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Drumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="176" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Tied boltzmann machines for cold start recommendations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gunawardana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Gibbons</surname></persName>
		</author>
		<title level="m">Rank Correlation Methods</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Factorization meets the neighborhood: a multifaceted collaborative filtering model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="426" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The bellkor solution to the netflix grand prize</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Collaborative filtering with temporal dynamics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="447" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Convergence properties of the nelder-mead simplex algorithm in low dimensions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Lagarias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Reeds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal of Optimization</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="112" to="147" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Social tagging and music information retrieval</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lamere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of New Music Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="114" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A parallel implementation of the simplex function minimization routine</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wiswall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Econ</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="171" to="187" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mel frequency cepstral coefficients for music modeling</title>
		<author>
			<persName><forename type="first">B</forename><surname>Logan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symposium on Music Information Retrieval</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Musicbox: Personalized music recommendation based on cubic analysis of social tags</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nanopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rafailidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Symeonidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Manolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Audio, Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="407" to="412" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A simplex method for function minimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Nelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Computer Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The pragmatic theory solution to the netflix grand prize</title>
		<author>
			<persName><forename type="first">M</forename><surname>Piotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chabbert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rokach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shapira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Kantor</surname></persName>
		</author>
		<title level="m">Recommender Systems Handbook</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Context-based Music Similarity Estimation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Knees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd International Workshop on Learning the Semantics of Audio Signals</title>
		<meeting>3rd International Workshop on Learning the Semantics of Audio Signals</meeting>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Methods and metrics for cold-start recommendations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Schein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Popescul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Pennock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>25th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="253" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Direct search methods: Once scorned, now respectable</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Numerical Analysis</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Griffiths</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Watson</surname></persName>
		</editor>
		<imprint>
			<publisher>Addison Wesley</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="191" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Temporal recommendation on graphs via long-and short-term preference fusion</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="723" to="732" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
