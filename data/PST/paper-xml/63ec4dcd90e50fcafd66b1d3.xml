<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PrefixMol: Target-and Chemistry-aware Molecule Design via Prefix Embedding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-02-14">14 Feb 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhangyang</forename><surname>Gao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuqi</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Cheng</forename><surname>Tan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
						</author>
						<title level="a" type="main">PrefixMol: Target-and Chemistry-aware Molecule Design via Prefix Embedding</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-02-14">14 Feb 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2302.07120v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Is there a unified model for generating molecules considering different conditions, such as binding pockets and chemical properties? Although targetaware generative models have made significant advances in drug design, they do not consider chemistry conditions and cannot guarantee the desired chemical properties. Unfortunately, merging the target-aware and chemical-aware models into a unified model to meet customized requirements may lead to the problem of negative transfer. Inspired by the success of multi-task learning in the NLP area, we use prefix embeddings to provide a novel generative model that considers both the targeted pocket's circumstances and a variety of chemical properties. All conditional information is represented as learnable features, which the generative model subsequently employs as a contextual prompt. Experiments show that our model exhibits good controllability in both single and multi-conditional molecular generation. The controllability enables us to outperform previous structure-based drug design methods. More interestingly, we open up the attention mechanism and reveal coupling relationships between conditions, providing guidance for multi-conditional molecule generation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recently, deep learning methods have shown promising potential for discovering desired drug molecules. Given that the order of drug-like spaces is 10 60 to 10 100 <ref type="bibr" target="#b53">(Schneider &amp; Fechner, 2005)</ref>, de novo drug discovery is often described as finding a needle in a haystack. In recent years, numerous rule-based algorithms <ref type="bibr" target="#b48">(Patel et al., 2009)</ref> to explore the chemical space have been presented; however, the computational overhead and results have been far from ideal. Inspired by the success of image, audio, and text generation models (Kiros et al., 2014; Baltru?aitis et al., 2018; Xu   * Equal contribution 1 AI Research and Innovation Lab, Westlake University 2 Zhejiang University 3 BDI, Shenzhen Technology University, Shenzhen, China. Correspondence to: Stan Z. Li &lt;Stan.ZQ.Li@westlake.edu.cn&gt;.</p><p>Preprint version <ref type="bibr" target="#b40">et al., 2022b;</ref><ref type="bibr">Gao et al., 2022e;</ref><ref type="bibr">b;</ref><ref type="bibr" target="#b63">Tan et al., 2023;</ref><ref type="bibr">2022a;</ref><ref type="bibr">b;</ref><ref type="bibr" target="#b18">Gao et al., 2023)</ref>, researchers have recently turned to deep learning models to generate the desired molecules directly, eliminating the need to search the vast drug-like space <ref type="bibr" target="#b49">(Peng et al., 2022;</ref><ref type="bibr" target="#b40">Liu et al., 2022b)</ref>. The critical issue in this type of research is determining how to control the behavior of the model to generate molecules with desired features.</p><p>Target-aware generative models have generated considerable attention in AI-assisted drug discovery. As pharmaceutical molecules are only effective when they bind to target proteins, creating molecules with a high affinity to the target is crucial. To meet this requirement, sequencebased <ref type="bibr" target="#b1">(Bagal et al., 2021)</ref>, graph-based <ref type="bibr">(Tan et al., 2022c)</ref>, and 3D-based <ref type="bibr" target="#b40">(Liu et al., 2022b;</ref><ref type="bibr" target="#b49">Peng et al., 2022;</ref><ref type="bibr" target="#b51">Ragoza et al., 2022;</ref><ref type="bibr" target="#b43">Luo et al., 2022)</ref> generative models that consider protein-ligand interactions are proposed. As these methods can manufacture targeted therapeutic molecules, they are more likely to be applicable in drug discovery. However, they impose no constraints on the chemistry of the generated molecules and are, therefore, unable to control their chemical properties.</p><p>Considering the targeted protein in conjunction with multiple chemical properties remains explored. Few models can produce compounds that target specific proteins and simultaneously regulate their chemical properties. The difficulty comes from several aspects: First, there needs to be more high-quality datasets that contain both target-protein affinity and molecular chemical characteristics. Molecules with missing property values further complicate the modeling process due to the absence of labels. Second, it is far more challenging to use a unified model to meet the customized requirements than to generate molecules based on a single condition, as the pocket-aware generative models do. Treating the modelling of each condition as a separate task, the unified model is a mixture of numerous multi-task models, which may suffer from the problem of negative transfer <ref type="bibr" target="#b6">(Crawshaw, 2020)</ref>: joint training of tasks hurts learning instead of helping it. The challenge is to develop an effective unified model considering multiple conditions (tasks) such as binding pockets and chemical properties.</p><p>To address the problems above, we extend the CrossDocked data set containing protein-ligand pairs with molecular properties and develop a prefix-conditional model to unify multi-conditional generation. Inspired by the success of multitask learning in the NLP area <ref type="bibr" target="#b22">(He et al., 2021;</ref><ref type="bibr" target="#b50">Pilault et al., 2020;</ref><ref type="bibr">Liu et al., 2022a;</ref><ref type="bibr" target="#b70">Wu et al., 2020;</ref><ref type="bibr" target="#b68">Wortsman et al., 2022;</ref><ref type="bibr" target="#b36">Li &amp; Liang, 2021;</ref><ref type="bibr" target="#b25">Hu et al., 2021;</ref><ref type="bibr" target="#b24">Houlsby et al., 2019)</ref>, we suggest prepending learnable conditional feature vectors to the query and key of the attention module, resulting in the PrefixMol method. The prefix embedding is always on the left side, serving as a task-related contextual prompt to affect the predicted outcomes on its right. These prefix embeddings are learned by auxiliary neural networks, considering the 3D pocket and chemical properties. Experiments show that PrefixMol demonstrates good controllability in both single-and multi-conditional settings. Moreover, the controllability enables us to outperform previous structure-based drug design methods. Last but not least, we open up the attention mechanism and reveal the coupling relationships between conditions, providing guidance for multi-conditional molecule generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><formula xml:id="formula_0">Problem Definition. Denote x ? R l is the SMILES molecular representation of length l, with n c chemical properties c = {c 1 , c 2 , ? ? ? , c nc }. In our setting, n c = 6 and {c 1 , c 2 , c 3 , c 4 , c 5 , c 6 } := {Pocket, VINA, QED, LogP, SA, Lipinski}. Considering the user has a desired ranges of properties c * = {c * 1 , c * 2 , ? ? ? , c * nc }</formula><p>, controllable molecule generation aims to learn a data generator g ? : z ? x, to satisfy the user desires, such that c ? c * . Target-aware generative model maximizes p(x|c 1 ) through the model g ?1 (x, c 1 ) with learnable parameter ? 1 , while we aim to merge {g ?i (x|c i )} N i=1 as a unified model g ? (x, c).</p><p>Target-aware Molecular Generation. Recently, various molecular generation methods have attracted extensive attention <ref type="bibr" target="#b19">(Gebauer et al., 2019;</ref><ref type="bibr" target="#b56">Simm &amp; Hernandez-Lobato, 2020;</ref><ref type="bibr">Simm et al., 2020;</ref><ref type="bibr" target="#b54">Shi et al., 2021;</ref><ref type="bibr" target="#b74">Xu et al., 2021;</ref><ref type="bibr" target="#b42">Luo et al., 2021b;</ref><ref type="bibr" target="#b73">Xu et al., 2020;</ref><ref type="bibr" target="#b10">Ganea et al., 2021;</ref><ref type="bibr">Xu et al., 2022a;</ref><ref type="bibr" target="#b23">Hoogeboom et al., 2022;</ref><ref type="bibr" target="#b33">Jing et al., 2022;</ref><ref type="bibr">Zhu et al., 2022;</ref><ref type="bibr" target="#b8">Du et al., 2022;</ref><ref type="bibr" target="#b46">Nesterov et al., 2020;</ref><ref type="bibr" target="#b20">Gebauer et al., 2022;</ref><ref type="bibr" target="#b69">Wu et al., 2022;</ref><ref type="bibr">Huang et al., 2022a;</ref><ref type="bibr">b;</ref><ref type="bibr">Wang et al., 2022a;</ref><ref type="bibr" target="#b11">Gao et al., 2020;</ref><ref type="bibr">2021;</ref><ref type="bibr">2022c;</ref><ref type="bibr">d;</ref><ref type="bibr" target="#b72">Xia et al., 2021;</ref><ref type="bibr">Gao et al., 2022a;</ref><ref type="bibr">Tan et al., 2022e;</ref><ref type="bibr">d;</ref><ref type="bibr">Xia et al.)</ref>. However, few methods consider protein-ligand interactions to generate molecules that bind to specific protein targets <ref type="bibr" target="#b28">(Imrie et al., 2020;</ref><ref type="bibr" target="#b43">Luo et al., 2022;</ref><ref type="bibr" target="#b51">Ragoza et al., 2022;</ref><ref type="bibr" target="#b49">Peng et al., 2022;</ref><ref type="bibr" target="#b40">Liu et al., 2022b)</ref>. In Table <ref type="table" target="#tab_4">4</ref> (Appendix), we divide target-aware molecular generation models into two types: graph-based and 3D structure-based. Graphbased methods generate molecular graphs given the protein sequence information. For example, SiamFlow <ref type="bibr">(Tan et al., 2022c</ref>) develops a flow model to generate molecular graphs given the targeted protein sequence. To better consider the spatial information, such as spatial isomerism and non-bonded interaction, more 3D structure-based methods have been proposed <ref type="bibr" target="#b28">(Imrie et al., 2020;</ref><ref type="bibr" target="#b43">Luo et al., 2022;</ref><ref type="bibr" target="#b51">Ragoza et al., 2022;</ref><ref type="bibr" target="#b49">Peng et al., 2022;</ref><ref type="bibr" target="#b40">Liu et al., 2022b)</ref>. Among them, Pocket2Mol <ref type="bibr" target="#b49">(Peng et al., 2022)</ref> and GraphBP <ref type="bibr" target="#b40">(Liu et al., 2022b)</ref> are representative models to autoregressively generate the atoms.</p><p>Controllable Molecule Generation. Although compounds are selected based on their projected bioactivities, their absorption, distribution, metabolism, excretion, and toxicity (ADMET) properties are frequently difficult to predict and adjust, causing bottlenecks in downstream investigations and applications. It would be more productive if candidate molecules with adequate chemical properties were developed at the outset of the molecule design process. Most recent research <ref type="bibr" target="#b29">(Jensen, 2019;</ref><ref type="bibr" target="#b47">Olivecrona et al., 2017;</ref><ref type="bibr">Zhou et al., 2019;</ref><ref type="bibr">Jin et al., 2020a;</ref><ref type="bibr" target="#b37">Lim et al., 2018;</ref><ref type="bibr" target="#b55">Shin et al., 2021;</ref><ref type="bibr" target="#b7">Das et al., 2021;</ref><ref type="bibr">Wang et al., 2022b)</ref> proposes to synthesize molecules in a controlled manner using generative models, which we summarize four different generation approaches shown in Table <ref type="table" target="#tab_5">5</ref> (Appendix). On the one hand, reinforcement-learning (RL) and supervisedlearning (SL) approaches necessitate extensive task-specific fine-tuning. Optimization-based techniques, on the other hand, train latent-space property predictors to uncover latent information relating to the target molecules. However, in real-world circumstances, we only have a limited amount of active molecules accessible for training. To address these problems, RetMol <ref type="bibr">(Wang et al., 2022b)</ref> proposes a retrieval-based framework for controllable molecule generation. <ref type="bibr" target="#b55">(Shin et al., 2021)</ref> develops CMG extending the self-attention technique Transformer to a molecular sequence by incorporating molecule properties and additional regularization network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Overall Framework</head><p>We propose PrefixMol, inserting learnable conditional feature vectors into the attention module to unify multiconditional molecule generative models to support the modeling of customized requirements. We illustrate the overall framework in Figure <ref type="figure" target="#fig_0">1</ref>. Compared to previous conditional generative models, our innovations include the following:</p><p>1. Extending the CrossDocked data set with molecular properties for multi-conditional generation.</p><p>2. Proposing PrefixMol to support multi-condition modeling for meeting customized requirements.</p><p>3. Providing insight into how the conditions control the model behavior and correlate with each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>Conducting systematic experiments to evaluate the proposed method. We append these conditional embeddings in the left side of the sequence, serving as a contextual prompt for a molecular generation. We call this method PrefixMol which allows customized models for generating molecules with single or multiple desired properties by modifying the prefix features. The auto-regressive loss and triplet property prediction loss train PrefixMol.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Prefix-conditional GPT</head><p>GPT Transformer. We adopt the GPT model <ref type="bibr" target="#b5">(Brown et al., 2020)</ref> to generate the molecular SMILES string, where the critical component is the transformer layer (Attention+FFN).</p><p>The output of the k-th multi-head attention (MHA) layer presents as follows.</p><formula xml:id="formula_1">? ? ? ? ? Attn(q, k, v) = softmax( qk T ? d k )v MHA(x, c) = Cat(head 1 , ? ? ? , head h )W o head i = Attn(xW (i) q , cW (i) k , cW (i) v ),<label>(1)</label></formula><p>where x ? R l?d is a sequence of l vectors over which we would like to perform attention. The i-th head is parameterized by</p><formula xml:id="formula_2">W (i) q , W (i) k , W (i) v</formula><p>? R d?d h to project inputs to queries, keys, and values. W o ? R d h ?d projects features into the model dimension. Later on, the attention output z = Attn(q, k, v) are fed into a fully connected feed-forward network (FFN):</p><formula xml:id="formula_3">FFN(z) = ReLU(zW 1 + b 1 )W 2 + b 2 ,<label>(2)</label></formula><p>where</p><formula xml:id="formula_4">W 1 ? R d?dm , W 2 ? R dm?d , d m = 4d.</formula><p>Finally, a residual connection is used, followed by layer normalization.</p><p>Prefix Conditional Embeddings. Upon the original sequence embedding x ? R l,d of length l, we suggest prepending conditional features on the left, resulting in extended input x = [PREFIX; x], as shown in Figure <ref type="figure" target="#fig_0">1</ref>. We use an additional learnable matrix p ? ? R nc,d to store the learnable prefix parameters. For simplicity, we write the i-th prefix feature vector as p ?,i . The output features of the language model will be:</p><formula xml:id="formula_5">h i = p ?,i , if i &lt; n c LM ? (x i , h &lt;i ), otherwise.<label>(3)</label></formula><p>where x i is the i-th element of the extended input, h i is the i-th output feature, ? and ? are learnable parameters. The prefix condition features are always on the left context and therefore affect any predictions on its right. More importantly, this approach decouples task-specific (?) and generic (?) knowledge, allowing the user to apply different tasks by modifying the conditional vector.</p><p>Condition Controlling &amp; Correlation. By analyzing the extended attention layer, we can determine: (1) how the conditions affect the behavior of the model and (2) how the conditions are interrelated. As to the first question, we provide the formula derivation procedure and variable declarations in the Appendix, reformulating the attention mechanism for the sequence embedding x as follows:</p><formula xml:id="formula_6">head = (1 -?(x)) Attn(xWq, cW k , cWv) self attention + ?(x) Attn(xWq, p ? W k , p ? Wv) prefix attention (4)</formula><p>From Equation <ref type="formula">4</ref>, we know that the prefix conditions control the model behavior by modifying the original attention weights. Thus, the activation map derived from softmax(xW q W k p ? ) could be used for analyzing how the conditions control the model behavior. Similarly, we re-formulate the attention computation of the prefix features p ? , detailed in Appendix D and written as:</p><formula xml:id="formula_7">head = Attn(p ? Wq, p ? W k , p ? Wv) prefix correlation (5)</formula><p>where the Attn(p ? W k , cW k , cW v ) term equal to zero, due to the causal mask applied on the model. The remaining term, i.e., Attn(p ? W q , p ? W k , p ? W v ), reveals how prefix features correlate with each other.</p><p>Auto-regressive Loss. Similar to GPT-3 <ref type="bibr" target="#b5">(Brown et al., 2020)</ref>, we use the auto-regressive loss to train the generative model:</p><formula xml:id="formula_8">L AT = -min ?,? log p ?,? (x 1:t | x 0:t-1 , p ? ) = - 1&lt;i?t log p ?,? (x i | x &lt;i , p ? ) (6)</formula><p>The difference is that we introduce prefix conditions during the generative process.</p><p>Property Prediction Loss. In addition to the autoregressive loss, we impose triplet predictive loss upon the model for generating molecules with desired properties:</p><formula xml:id="formula_9">L P red = max((? -c) 2 -(? -?) 2 , 0) (7)</formula><p>Where c is the input properties serving as conditions, ? is the properties calculated by an MLP prediction head, and ? is the properties of the generated molecule. The triplet loss requires the model to generate molecules whose properties are consistent with the input conditions. Since ? is computed by RDKit according to the generated SMILES and is nondifferentiable, we propagate the gradient with the help of ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Conditional Embeddings</head><p>3D Pocket Embedding. We propose GVF (Geometric Vector Transformer), a variant of GVP (Geometric Vector Perceptrons) GNN <ref type="bibr" target="#b32">(Jing et al., 2020)</ref>, to extract 3D pocket features. Consider a pocket that has n v atoms, we represent it as a 3D graph G(V, V, E, E) , consisting of node features (V ? R nv,d f , V ? R nv,3 ) and edge features (E ? R nv,de , E ? R nv,3 ). Note that V and E are invariant features with dimension d f and d e , respectively, and V, E are equivariant geometric features. Previous works <ref type="bibr" target="#b32">(Jing et al., 2020;</ref><ref type="bibr" target="#b49">Peng et al., 2022)</ref> have shown that considering both scalar (V, E) and vector features ( V, E) helps the model to learn expressive 3D representations. However, all these methods only consider local interactions through graph message passing while ignoring global contextual interactions, which may limit the expressive power of the model. As a remedy, we introduce a new GVF layer considering both local and global geometric interactions by adding a global attention module upon the GNN layer. The GVF layer is formulated as follows:</p><formula xml:id="formula_10">? ? ? ? ? ? ? (V, V) = GNN(V, V, E, E) A = Softmax( V T W T q W k V ? d ) (V , E) ? (FFN v (AV ), FFN e (AV ||E))<label>(8)</label></formula><p>Where W q and W k are learnable global attention parameters, FFN v and FFN e are feed-forward MLPs that transform node and edge features. We use the same GNN architecture as Pocket2Mol <ref type="bibr" target="#b49">(Peng et al., 2022)</ref> for considering local interactions. We randomly choose an anchor node v i that is within 5 ? to the bounded ligand molecule and computing the pocket embedding p 1 through position-aware attention:</p><formula xml:id="formula_11">h 1 = nv j=1 MLP att (rbf(d ij )||v i ||v j ))v i (9)</formula><p>where MLP att is an MLP used for computing attention weights, rbf(?) is a radial basis function, || indicates the concatenate operation.</p><p>Property Embedding. In addition to the 3D pocket condition, we also consider multiple chemistry properties as conditions, including Vina (c 2 ), QED (c 3 ), SA (c 4 ), LogP (c 5 ) and Lipinski (c 6 ); see the experiment section for more details about these properties. We use separate MLPs to embed each property, formulated as follows:</p><formula xml:id="formula_12">? ? ? ? ? ? ? ? ? ? ? ? ? ? ? p 2 = MLP vina (c 2 ) p 3 = MLP qed (c 3 ) p 4 = MLP sa (c 4 ) p 5 = MLP logp (c 5 ) p 6 = MLP lip (c 6 )<label>(10)</label></formula><p>4. Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Settings</head><p>In this section, we conduct extensive experiments to evaluate the proposed method. Specifically, we would like to answer the following questions:</p><p>Q1: Comparision. How does PrefixMol perform compared to previous structure-based drug design methods without conditions?</p><p>Q2: Controllability. Could PrefixMol outperform baselines with controllable conditions? How well does it work in single and multi-conditional settings?</p><p>Q3: Condition relations. Are there coupling relationships between control conditions?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Basic Settings</head><p>Data Set. We use the CrossDocked data set <ref type="bibr" target="#b9">(Francoeur et al., 2020)</ref> with 22.5 million protein-ligand structures to evaluate the proposed method, in which we add chemical properties for each ligand. We follow the same data splitting and evaluation protocols as <ref type="bibr" target="#b49">(Peng et al., 2022)</ref> and <ref type="bibr">(Masuda et al., 2020a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrics.</head><p>To measure the quality of the generated drug candidates, we adopt the following widely known metrics, including VINA, QED, SA, LogP, and Lipinski. We provide a detailed explanation of these metrics in the appendix.</p><p>In addition, three additional metrics are included for assessing each binding site's generational quality and diversity:</p><p>(1) High Affinity is the proportion of pockets whose generated molecules have higher or equal affinities than those in the test set.</p><p>(2) Diversity <ref type="bibr">(Jin et al., 2020b)</ref> quantifies the diversity of compounds synthesized for a binding site. It is computed by average pairwise Tanimoto similarity <ref type="bibr" target="#b2">(Bajusz et al., 2015;</ref><ref type="bibr" target="#b64">Tanimoto, 1958)</ref> over Morgan fingerprints for all produced molecules of a target. (3) Sim.Train indicates the most related molecules in training set for Tanimoto similarity. In our work, VINA is calculated by QVina <ref type="bibr" target="#b65">(Trott &amp; Olson, 2010;</ref><ref type="bibr" target="#b0">Alhossary et al., 2015)</ref> to compute the binding affinity. Before putting the molecules into the calculation of Vina score, we use universal force fields (UFF <ref type="bibr" target="#b52">(Rapp? et al., 1992)</ref>) to refine the produced structures according to <ref type="bibr">(Masuda et al., 2020b)</ref>. Other chemical properties can be calculated by RDKit <ref type="bibr" target="#b35">(Landrum, 2016)</ref>. Multi-properties Control. We investigate whether Pre-fixMol is effective at controlling many characteristics and emphasize multi-condition modeling is challenging due to the fact that modeling each condition is a distinct work and multi-task models would be susceptible to negative transfer. Consequently, few approaches could jointly maximize diverse molecular properties. We show in Figure <ref type="figure">2</ref> that Pre-fixMol performs well when jointly controlling two or three properties, then simultaneously change all the input conditions and report results in Table <ref type="table" target="#tab_2">3</ref>. The experimental results reveal that all properties fluctuate with control conditions and have consistent positive relationships, indicating that PrefixMol has good controllability in the multi-conditional generation. We also observe that Lipinski is coupled to QED and SA with a saturation value of 5.0 when both QED and SA are at least +2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visualization.</head><p>Several examples of generated molecules with higher binding affinities (lower VINA) than the corresponding reference compounds and four case studies are VINA (?,QED) -6.498 -6.000(-0.498) -6.325(-0.173) -6.220(-0.278) -6.011(-0.487) -5.942(-0.556) -6.876(+0.378) -7.733(+1.235) -7.5625(+1.0645) -7.150(+0.652) -7.256(+0.758) -7.288 VINA (?,LOGP) -6.498 -6.229(-0.269) -6.100(-0.398) -6.490(-0.008) -6.325(-0.173) -6.315(-0.183) -6.820(+0.322) -7.377(+0.879) -7.465(+0.967) -7.210(+0.712) -7.250(+0.752) -7.288 shown in Appendix E.1. Our generated molecules with more excellent affinity structures differ significantly from reference molecules, suggesting our method can generate novel compounds that bind target proteins rather than just copying or changing reference molecules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Condition relations (Q3)</head><p>Objective &amp; Setting.</p><p>As derived in Equation.5, Attn(p ? W q , p ? W k , p ? W v ) reveals how prefix features correlate with each other. We write the corresponding attention map as A(p ? ) = softmax(P ? W q W k P ? ), and add perturbations on input conditions to see how the attention map changes and how they are interrelated. Recall that A(P ? ) is a function of input conditions, which could be rewritten as A(c 1 , c 2 , c 3 , c 4 , c 5 , c 6 ), where c 1 indicates the protein pocket, (c 2 , c 3 , c 4 , c 5 , c 5 , c 6 ) represents other input conditions whose corresponding condition types are (VINA, QED, LogP, SA, Lipinski). Taking VINA as an example, the partial differentiation of the attention map is</p><formula xml:id="formula_13">?A ?c2 = A(c1, c2 + ?, c3, c4, c5, c6) -A(c1, c2, c3, c4, c5, c6) ?</formula><p>where we set ? = 1. We take the absolute values of all partial differentiations and add them together to obtain the relation matrix R:</p><formula xml:id="formula_14">R = 6 i=2 | ?A ?c i | (11)</formula><p>As the causal mask is applied to the attention model for auto-regressive generation, the relation matrix R computed from attention maps is triangular.</p><p>Results &amp; Analysis. We visualize the relationship matrix in Figure <ref type="figure">3</ref> to uncover how conditions are interrelated. There are a number of noteworthy observations:(1) The diagonal numbers indicate self-controllability when a single input condition is altered, but the lower left values indicate crosscontrollability between many conditions. Cross-control plays a significant role in optimizing molecules properties.</p><p>(2) The VINA is weakly controlled by itself; instead, it is sensitive to other conditions like QED, LogP, and SA. This discovery explains why changing QED and LogP allows the VINA to exceed SOTA baselines in Table <ref type="table" target="#tab_1">2</ref> and why the model is poor at controlling individual VINA but works well when controlling multiple properties. A similar explanation holds for the Lipinski improvement achieved by simultaneously changing the QED and SA in Table <ref type="table" target="#tab_2">3</ref>. (3) LogP and QED are the most correlated properties. We show the relationships between QED, SA, and LogP in Appendix E.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We propose PrefixMol, a unified model for multi-conditional molecular generation, supporting customized requirements. PrefixMol exhibits good controllability in both single and multi-conditional molecular generation and outperforms previous baselines with the help of controllable generation. More interestingly, we reveal coupling relationships between conditions to provide insights into multi-conditional molecular generation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Related work</head><p>Target-aware Molecular Generation. In recent years, various molecular generation methods have attracted extensive attention <ref type="bibr" target="#b19">(Gebauer et al., 2019;</ref><ref type="bibr" target="#b56">Simm &amp; Hernandez-Lobato, 2020;</ref><ref type="bibr">Simm et al., 2020;</ref><ref type="bibr" target="#b54">Shi et al., 2021;</ref><ref type="bibr" target="#b74">Xu et al., 2021;</ref><ref type="bibr" target="#b42">Luo et al., 2021b;</ref><ref type="bibr" target="#b73">Xu et al., 2020;</ref><ref type="bibr" target="#b10">Ganea et al., 2021;</ref><ref type="bibr">Xu et al., 2022a;</ref><ref type="bibr" target="#b23">Hoogeboom et al., 2022;</ref><ref type="bibr" target="#b33">Jing et al., 2022;</ref><ref type="bibr">Zhu et al., 2022;</ref><ref type="bibr" target="#b8">Du et al., 2022;</ref><ref type="bibr" target="#b46">Nesterov et al., 2020;</ref><ref type="bibr" target="#b20">Gebauer et al., 2022;</ref><ref type="bibr" target="#b69">Wu et al., 2022;</ref><ref type="bibr">Huang et al., 2022a;</ref><ref type="bibr">b;</ref><ref type="bibr">Wang et al., 2022a)</ref>. However, only some of them could obtain molecules that bind to specific protein targets <ref type="bibr" target="#b28">(Imrie et al., 2020;</ref><ref type="bibr" target="#b43">Luo et al., 2022;</ref><ref type="bibr" target="#b51">Ragoza et al., 2022;</ref><ref type="bibr" target="#b49">Peng et al., 2022;</ref><ref type="bibr" target="#b40">Liu et al., 2022b)</ref>. As shown in Table .4 (Appendix), we divide target-ware molecular generation models into two types: graph-based and 3D structure-based. Graph-based methods generate molecular graphs given the protein sequence information. For example, SiamFlow <ref type="bibr">(Tan et al., 2022c</ref>) develops a flow model to generate molecular graphs given the targeted protein sequence. To better consider the spatial information, such as spatial isomerism and non-bonded interaction, more 3D structure-based methods have been proposed <ref type="bibr" target="#b28">(Imrie et al., 2020;</ref><ref type="bibr" target="#b43">Luo et al., 2022;</ref><ref type="bibr" target="#b51">Ragoza et al., 2022;</ref><ref type="bibr" target="#b49">Peng et al., 2022;</ref><ref type="bibr" target="#b40">Liu et al., 2022b)</ref>. Among them, Pocket2Mol <ref type="bibr" target="#b49">(Peng et al., 2022)</ref> and GraphBP <ref type="bibr" target="#b40">(Liu et al., 2022b)</ref> are representative models to autoregressively generate the atom types and positions, taking the protein pocket as input.  <ref type="bibr" target="#b28">(Imrie et al., 2020)</ref> 3D Tensorflow 2020 Luo's model <ref type="bibr" target="#b43">(Luo et al., 2022)</ref> 3D PyTorch 2021 LiGAN <ref type="bibr" target="#b51">(Ragoza et al., 2022)</ref> 3D PyTorch 2021 Pocket2Mol <ref type="bibr" target="#b49">(Peng et al., 2022)</ref> 3D PyTorch 2022 GraphBP <ref type="bibr" target="#b40">(Liu et al., 2022b)</ref> 3D PyTorch 2022</p><p>Target-aware Molecular Generation. In recent years, various molecular generation methods have attracted extensive attention <ref type="bibr" target="#b19">(Gebauer et al., 2019;</ref><ref type="bibr" target="#b56">Simm &amp; Hernandez-Lobato, 2020;</ref><ref type="bibr">Simm et al., 2020;</ref><ref type="bibr" target="#b54">Shi et al., 2021;</ref><ref type="bibr" target="#b74">Xu et al., 2021;</ref><ref type="bibr" target="#b42">Luo et al., 2021b;</ref><ref type="bibr" target="#b73">Xu et al., 2020;</ref><ref type="bibr" target="#b10">Ganea et al., 2021;</ref><ref type="bibr">Xu et al., 2022a;</ref><ref type="bibr" target="#b23">Hoogeboom et al., 2022;</ref><ref type="bibr" target="#b33">Jing et al., 2022;</ref><ref type="bibr">Zhu et al., 2022;</ref><ref type="bibr" target="#b8">Du et al., 2022;</ref><ref type="bibr" target="#b46">Nesterov et al., 2020;</ref><ref type="bibr" target="#b20">Gebauer et al., 2022;</ref><ref type="bibr" target="#b69">Wu et al., 2022;</ref><ref type="bibr">Huang et al., 2022a;</ref><ref type="bibr">b;</ref><ref type="bibr">Wang et al., 2022a)</ref>. However, only some of them could obtain molecules that bind to specific protein targets <ref type="bibr" target="#b28">(Imrie et al., 2020;</ref><ref type="bibr" target="#b43">Luo et al., 2022;</ref><ref type="bibr" target="#b51">Ragoza et al., 2022;</ref><ref type="bibr" target="#b49">Peng et al., 2022;</ref><ref type="bibr" target="#b40">Liu et al., 2022b)</ref>. As shown in Table .4 (Appendix), we divide target-ware molecular generation models into two types: graph-based and 3D structure-based. Graph-based methods generate molecular graphs given the protein sequence information. For example, SiamFlow <ref type="bibr">(Tan et al., 2022c</ref>) develops a flow model to generate molecular graphs given the targeted protein sequence. To better consider the spatial information, such as spatial isomerism and non-bonded interaction, more 3D structure-based methods have been proposed <ref type="bibr" target="#b28">(Imrie et al., 2020;</ref><ref type="bibr" target="#b43">Luo et al., 2022;</ref><ref type="bibr" target="#b51">Ragoza et al., 2022;</ref><ref type="bibr" target="#b49">Peng et al., 2022;</ref><ref type="bibr" target="#b40">Liu et al., 2022b)</ref>. Among them, Pocket2Mol <ref type="bibr" target="#b49">(Peng et al., 2022)</ref> and GraphBP <ref type="bibr" target="#b40">(Liu et al., 2022b)</ref> are representative models to autoregressively generate the atom types and positions, taking the protein pocket as input.  <ref type="bibr">(Jin et al., 2020a)</ref> RL PyTorch 2020 CVAE <ref type="bibr" target="#b37">(Lim et al., 2018)</ref> SL Tensorflow 2018 CMG <ref type="bibr" target="#b55">(Shin et al., 2021)</ref> SL Tensorflow 2021 CLaSS <ref type="bibr" target="#b7">(Das et al., 2021)</ref> Opt PyTorch 2021 RetMol <ref type="bibr">(Wang et al., 2022b)</ref> Retrival -2022</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure1. The overall framework. Multiple conditions are embedded as learnable features, including the 3D pocket, Vina Score, QED, SA, LogP, and Lipinski. We append these conditional embeddings in the left side of the sequence, serving as a contextual prompt for a molecular generation. We call this method PrefixMol which allows customized models for generating molecules with single or multiple desired properties by modifying the prefix features. The auto-regressive loss and triplet property prediction loss train PrefixMol.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Figure 2. We present condition relations of the metrics (a). Distribution of property of generated molecules conditioned on (b) QED+SA, (c) Lipinski+LogP and (d) QED+SA+Lipinski. The values that the generation is conditioned to are given in the legends of the panels.</figDesc><graphic url="image-13.png" coords="6,219.47,521.48,151.91,166.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparing the properties of the molecules in the test set to those generated by algorithms. Here we present the unconditional version of PrefixMol. The best and suboptimal results are labeled with bold and underlined. Interestingly, the metrics Sim. Train and Diversity of PrefixMol exceed other computational models. This phenomenon suggests that PrefixMol is not simply memorizing training data, and that it is more capable than baselines at producing novel molecules.</figDesc><table><row><cell>Metrics</cell><cell>Test Set</cell><cell>CVAE</cell><cell>AR</cell><cell>Pocket2 Mol</cell><cell>PrefixMol (unconditional)</cell></row><row><cell>VINA</cell><cell>-7.158</cell><cell>-6.144</cell><cell>-6.215</cell><cell>-7.288</cell><cell>-6.532</cell></row><row><cell>(kcal/mol, ?)</cell><cell>? 2.10</cell><cell>? 1.57</cell><cell>? 1.54</cell><cell>? 2.53</cell><cell>? 1.76</cell></row><row><cell>QED (?)</cell><cell>0.484 ?0.21</cell><cell>0.369 ?0.22</cell><cell>0.502 ?0.17</cell><cell>0.563 ?0.16</cell><cell>0.551 ? 0.18</cell></row><row><cell>SA (?)</cell><cell>0.732 ?0.14</cell><cell>0.590 ?0.15</cell><cell>0.675 ?0.14</cell><cell>0.765 ?0.13</cell><cell>0.750 ? 0.09</cell></row><row><cell>LogP</cell><cell>0.947 ?2.65</cell><cell>-0.140 ?2.73</cell><cell>0.257 ?2.01</cell><cell>1.586 ?1.82</cell><cell>1.415 ? 2.11</cell></row><row><cell>Lipinski (?)</cell><cell>4.367 ?1.14</cell><cell>4.027 ?1.38</cell><cell>4.787 ?0.50</cell><cell>4.902 ?0.42</cell><cell>4.710 ? 0.63</cell></row><row><cell>High Affinity (%, ?)</cell><cell>-</cell><cell>0.238</cell><cell>0.267</cell><cell>0.542</cell><cell>0.432</cell></row><row><cell>Diversity (?)</cell><cell>-</cell><cell>0.654 ?0.12</cell><cell>0.742 ?0.09</cell><cell>0.688 ?0.14</cell><cell>0.856 ?0.17</cell></row><row><cell>Sim. Train (?)</cell><cell>-</cell><cell>0.460 ?0.18</cell><cell>0.409 ?0.19</cell><cell>0.376 ?0.22</cell><cell>0.239 ?0.07</cell></row><row><cell cols="3">4.3. Comparison (Q1)</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Objective &amp; Setting. How does PrefixMol perform com-</cell></row><row><cell cols="6">pared to previous structure-based drug design methods</cell></row><row><cell cols="6">without conditions? We train the unconditional PrefixMol,</cell></row><row><cell cols="6">where conditions do not use for controlling the generation.</cell></row><row><cell cols="6">We compare PrefixMol with recent strong baselines, includ-</cell></row><row><cell cols="6">ing CVAE (Masuda et al., 2020a), AR (Luo et al., 2021a),</cell></row><row><cell cols="4">and Pocket2Mol (Peng et al., 2022).</cell><cell></cell><cell></cell></row><row><cell cols="6">Results &amp; Analysis. The mean values and standard devia-</cell></row></table><note><p><p><p>tions of the measures above are presented in Table</p>1</p>, with the Prefix version lacking conditional inputs. Probably because PrefixMol (unconditional) does not explicitly model the 3D ligand structure and molecular properties, it could only achieve sub-optimal results on VINA, QED, SA, and LogP.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>PrefixMol Single-property Control. Our method PrefixMol is evaluated with the conditions for VINA, QED, SA, LogP, and Lipinski. The method column Pocket2Mol provided in the table compares the controlling effect, and the outcomes surpassing the comparative method Pocket2Mol are bolded. Colors indicate the performance inferior (lower baseline) or superior (lower baseline) and (+ or -) represent the relative amounts of the baseline.</figDesc><table><row><cell></cell><cell>BASELINE</cell><cell></cell><cell></cell><cell>NEGATIVE</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>POSITIVE</cell><cell></cell><cell></cell><cell>METHOD</cell></row><row><cell>METRICS</cell><cell>0</cell><cell>-5</cell><cell>-4</cell><cell>-3</cell><cell>-2</cell><cell>-1</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>Pocket2Mol</cell></row><row><cell>VINA (?)</cell><cell>-6.532</cell><cell cols="5">-6.518(+0.014) -6.515(+0.017) -6.522(+0.01) -6.497(+0.035) -6.505(+0.027)</cell><cell>-6.502(+0.03)</cell><cell>-6.442(+0.09)</cell><cell>-6.541(-0.009)</cell><cell cols="2">-6.552(-0.02) -6.351(+0.181)</cell><cell>-7.288</cell></row><row><cell>QED (?)</cell><cell>0.551</cell><cell>0.473(-0.078)</cell><cell cols="3">0.520(-0.031) 0.354(-0.197) 0.303(-0.248)</cell><cell>0.456(-0.095)</cell><cell>0.757(+0.206)</cell><cell>0.732(+0.181)</cell><cell>0.767(+0.216)</cell><cell cols="2">0.754(+0.203) 0.767(+0.216)</cell><cell>0.563</cell></row><row><cell>SA (?)</cell><cell>0.750</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">0.889 (+0.139) 0.911(+0.161)</cell><cell>0.913(+0.163)</cell><cell cols="2">0.920(+0.170) 0.924(+0.174)</cell><cell>0.765</cell></row><row><cell>LOGP</cell><cell>1.415</cell><cell cols="4">-1.062(-2.477) -0.804(-2.219) 0.486(-0.929) 0.056(-1.359)</cell><cell>0.676(-0.739)</cell><cell cols="2">2.191 (+0.776) 2.930(+1.515)</cell><cell>3.358(+1.943)</cell><cell cols="2">3.395(+1.980) 3.631(+2.216)</cell><cell>1.586</cell></row><row><cell>LIPINSKI (?)</cell><cell>4.710</cell><cell>4.676(-0.034)</cell><cell>4.7(-0.01)</cell><cell>4.86(+0.15)</cell><cell>4.759(+0.049)</cell><cell>4.710(-)</cell><cell>4.721(+0.011)</cell><cell>4.721(+0.011)</cell><cell>4.7(-0.01)</cell><cell>4.672(-0.038)</cell><cell>4.677(-0.033)</cell><cell>4.902</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>PrefixMol Multi-properties Control. Generated molecules conditioned on five metrics verify the controllability. Colors indicate the performance of the controlling effect, and the values are shown as the combination of the mean average deviation(MAD) and standard deviation(SD).</figDesc><table><row><cell>Control Scales</cell><cell>VINA (?)</cell><cell>QED (?)</cell><cell>SA (?)</cell><cell>LogP</cell><cell>Lipinski (?)</cell></row><row><cell>-4(all)</cell><cell cols="4">-4.567(?0.82) 0.286(?0.11) 0.557(?0.02) -1.494(?0.85)</cell><cell>3.7</cell></row><row><cell>0(all)</cell><cell cols="4">-6.220(?1.12) 0.547(?0.18) 0.755(?0.07) 0.796(?1.96)</cell><cell>4.8</cell></row><row><cell>+4(all)</cell><cell cols="4">-6.333(?0.70) 0.722(?0.006) 0.913(?0.04) 2.433(?1.25)</cell><cell>5.0</cell></row><row><cell cols="5">+0.5(QED,SA) -5.888(?1.46) 0.596(?0.16) 0.847(?0.08) 1.328(?2.06)</cell><cell>4.75</cell></row><row><cell cols="5">+1.5(QED,SA) -5.742(?1.60) 0.660(?0.12) 0.872(?0.04) 1.530(?1.10)</cell><cell>4.917</cell></row><row><cell cols="5">+2.0(QED,SA) -5.715(?0.65) 0.671(?0.09) 0.876(?0.04) 1.320(?0.78)</cell><cell>5.0</cell></row><row><cell cols="3">+2.5(QED,SA) -5.589(?0.71) 0.667(?0.09)</cell><cell>0.89(?0.04)</cell><cell>1.511(?0.62)</cell><cell>5.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Xu, P., Zhu, X., and Clifton, D. A. Multimodal learning with transformers: A survey. arXiv preprint arXiv:2206.06488, 2022b. Zhou, Z., Kearnes, S., Li, L., Zare, R. N., and Riley, P. Optimization of molecules via deep reinforcement learning.</figDesc><table><row><cell>Scientific reports, 9(1):1-10, 2019.</cell></row><row><cell>Zhu, J., Xia, Y., Liu, C., Wu, L., Xie, S., Wang, T., Wang,</cell></row><row><cell>Y., Zhou, W., Qin, T., Li, H., et al. Direct molecular con-</cell></row><row><cell>formation generation. arXiv preprint arXiv:2202.01356,</cell></row><row><cell>2022.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Target-aware molecular generation models.</figDesc><table><row><cell>Method</cell><cell>Type</cell><cell>Github</cell><cell>Year</cell></row><row><cell>SiamFlow (Tan et al., 2022c)</cell><cell>Graph</cell><cell>-</cell><cell>2022</cell></row><row><cell>DeLinker</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>Controllable molecule generation models.</figDesc><table><row><cell>Method</cell><cell>Type</cell><cell>Github</cell><cell>Year</cell></row><row><cell>REINVENT (Olivecrona et al., 2017)</cell><cell>RL</cell><cell>PyTorch</cell><cell>2017</cell></row><row><cell>MolDQN (Zhou et al., 2019)</cell><cell>RL</cell><cell cols="2">Tensorflow 2019</cell></row><row><cell>RationaleRL</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. GNN layer</head><p>Denote G as a GVP layer and the l-th GNN layer, i.e., GNN(V, V, E, E), is:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Properties</head><p>? VINA: Vina score is a theoretical evaluation of the binding affinity between a small molecule and a target. A molecule with higher affinity is likely to have a higher potential for bioactivity.</p><p>? QED: The quantitative estimate of drug-likeness <ref type="bibr" target="#b4">(Bickerton et al., 2012)</ref> takes molecular properties into account in order to quantify drug-likeness. It ranges from 0 (all properties unfavorable) to 1 (all properties favorable).</p><p>? SA: Synthetic accessibility score is a measure of the difficulty of synthesizing a chemical, standardized between 0 and 1, with greater values indicating simpler synthesis.</p><p>? LogP: LogP, the octanol-water partition coefficient, is a measure of hydrophobicity when one of the solvents is water and the other is a nonpolar solvent. Typically, promising medication candidates should have LogP values <ref type="bibr" target="#b21">(Ghose et al., 1999)</ref> between -0.4 and 5.6.</p><p>? Lipinski: Lipinski's rule of five is used to determine a drug's similarity to another drug by calculating the number of rules the drug follows <ref type="bibr" target="#b38">(Lipinski et al., 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Further Explanations</head><p>The formula of the attention mechanism of the sequence embedding x. Here we show the attention mechanism of the sequence embedding x and the attention computation of the prefix features p ? in detail.</p><p>Where Cat is the concatenate operation, and ?(x) shown below is a scalar that represents the sum of normalized attention weights on the prefixes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Additional Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1. Molecule Design</head><p>We present examples of generated molecules by our method as four case studies shown in Figure .4. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2. Correlated Properties</head><p>As Table .2 shows, QED, SA, and LogP follow the conditional inputs well. Therefore, we reveal them in Figure .5 to further explore their potential relationship. We can clearly see that the slope of the regression curve of QED and LogP is high and positively correlated. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast, accurate, and reliable molecular docking with quickvina 2</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alhossary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Handoko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Kwoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="2214" to="2216" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Molecular generation using a transformerdecoder model</title>
		<author>
			<persName><forename type="first">V</forename><surname>Bagal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vinod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">D</forename><surname>Priyakumar</surname></persName>
		</author>
		<author>
			<persName><surname>Molgpt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Information and Modeling</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2064" to="2076" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Why is tanimoto index an appropriate choice for fingerprint-based similarity calculations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bajusz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>R?cz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>H?berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of cheminformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multimodal machine learning: A survey and taxonomy</title>
		<author>
			<persName><forename type="first">T</forename><surname>Baltru?aitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="423" to="443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Quantifying the chemical beauty of drugs</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Bickerton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">V</forename><surname>Paolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Besnard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Hopkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature chemistry</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="90" to="98" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Multi-task learning with deep neural networks: A survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Crawshaw</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.09796</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Accelerated antimicrobial discovery via deep generative models and molecular dynamics simulations</title>
		<author>
			<persName><forename type="first">P</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sercu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wadhawan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Padhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cipcigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chenthamarakshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dos Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="613" to="623" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Molgensurvey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.14500</idno>
		<title level="m">A systematic survey in machine learning models for molecule design</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Three-dimensional convolutional neural networks and a cross-docked data set for structure-based drug design</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Francoeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Masuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sunseri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Iovanisci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Koes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4200" to="4215" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Geomol: Torsional geometric generation of molecular 3d conformer ensembles</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pattanaik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Coley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="13757" to="13769" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Lookhops: light multi-order convolution and pooling for graph classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15741</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.01274</idno>
		<title level="m">Clustering based on graph of intensity topology</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Alphadesign: A graph protein design method and benchmark on alphafolddb</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.01079</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Pifold</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.12643</idno>
		<title level="m">Toward effective and efficient protein inverse folding</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Cosp</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.12241</idno>
		<title level="m">Cosupervised pretraining of pocket and ligand</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Semiretro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.08205</idno>
		<title level="m">Semitemplate framework boosts deep retrosynthesis prediction</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Simpler yet better video prediction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Simvp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3170" to="3180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Diffsds</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.09642</idno>
		<title level="m">A language diffusion model for protein backbone inpainting under geometric conditions and constraints</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Symmetryadapted generation of 3d point sets for the targeted discovery of molecules</title>
		<author>
			<persName><forename type="first">N</forename><surname>Gebauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gastegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sch?tt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Inverse design of 3d molecular structures with conditional generative neural networks</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Gebauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gastegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Hessmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Sch?tt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A knowledge-based approach in designing combinatorial or medicinal chemistry libraries for drug discovery. 1. a qualitative and quantitative characterization of known drug databases</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Viswanadhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Wendoloski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of combinatorial chemistry</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="68" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Towards a unified view of parameter-efficient transfer learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.04366</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Equivariant diffusion for molecule generation in 3d</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Satorras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vignac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="8867" to="8887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Parameter-efficient transfer learning for nlp</title>
		<author>
			<persName><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Giurgiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>De Laroussilhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gesmundo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Attariyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2790" to="2799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Lora</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.09685</idno>
		<title level="m">Low-rank adaptation of large language models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><surname>Mdm</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.05710</idno>
		<title level="m">Molecular diffusion model for 3d molecule generation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">3dlinker: An e (3) equivariant variational autoencoder for molecular linker design</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.07309</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Journal of chemical information and modeling</title>
		<author>
			<persName><forename type="first">F</forename><surname>Imrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Der Schaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Deane</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983-1995, 2020</date>
			<biblScope unit="volume">60</biblScope>
		</imprint>
	</monogr>
	<note>Deep generative models for 3d linker design</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A graph-based genetic algorithm and generative model/monte carlo tree search for the exploration of chemical space</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemical science</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3567" to="3572" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multi-objective molecule generation using interpretable substructures</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4849" to="4859" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.03244</idno>
		<title level="m">Composing molecules with multiple property constraints</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Eismann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suriana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Townshend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dror</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.01411</idno>
		<title level="m">Learning from protein structure with geometric vector perceptrons</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Torsional diffusion for molecular conformer generation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.01729</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multimodal neural language models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="595" to="603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Rdkit: Open-source cheminformatics software</title>
		<author>
			<persName><forename type="first">G</forename><surname>Landrum</surname></persName>
		</author>
		<ptr target="https://github.com/rdkit/rdkit/releases/tag/Release_2016_09_4" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Prefix-tuning: Optimizing continuous prompts for generation</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00190</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Molecular generative model based on conditional variational autoencoder for de novo molecular design</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of cheminformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Experimental and computational approaches to estimate solubility and permeability in drug discovery and development settings</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Lipinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Dominy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Feeney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advanced drug delivery reviews</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="4" to="17" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Muqeeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.05638</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Generating 3d molecules for target protein binding</title>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Uchino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Maruhashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A 3d generative model for structure-based drug design</title>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="6229" to="6239" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Predicting molecular conformation via dynamic graph score matching. Advances in Neural Information Processing Systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">19784-19795, 2021b</date>
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.10446</idno>
		<title level="m">A 3d molecule generative model for structure-based drug design</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Masuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ragoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Koes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.14442</idno>
		<title level="m">Generating 3d molecular structures conditional on a receptor binding site with deep generative models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Masuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ragoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Koes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.14442</idno>
		<title level="m">Generating 3d molecular structures conditional on a receptor binding site with deep generative models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">dmolnet: a generative network for molecular structures</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nesterov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Roth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.06477</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Molecular de-novo design through deep reinforcement learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Olivecrona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Blaschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Engkvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of cheminformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Knowledge-based approach to de novo design using reaction vectors</title>
		<author>
			<persName><forename type="first">H</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Bodkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Gillet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1163" to="1184" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Pocket2mol: Efficient molecular sampling based on 3d protein pockets</title>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.07249</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Conditionally adaptive multi-task learning: Improving transfer learning in nlp using fewer parameters &amp; less data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pilault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elhattami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.09139</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Generating 3D molecules conditional on receptor binding sites with deep generative models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ragoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Masuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Koes</surname></persName>
		</author>
		<idno type="DOI">10.1039/D1SC05976A</idno>
	</analytic>
	<monogr>
		<title level="j">Chem Sci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2701" to="2713" />
			<date type="published" when="2022-02">Feb 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Uff, a full periodic table force field for molecular mechanics and molecular dynamics simulations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Rapp?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Casewit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Colwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename><surname>Goddard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Skiff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American chemical society</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">25</biblScope>
			<biblScope unit="page" from="10024" to="10035" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Computer-based de novo design of drug-like molecules</title>
		<author>
			<persName><forename type="first">G</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Fechner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Drug Discovery</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="649" to="663" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Learning gradient fields for molecular conformation generation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="9558" to="9568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Controlled molecule generator for optimizing multiple chemical properties</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Health, Inference, and Learning</title>
		<meeting>the Conference on Health, Inference, and Learning</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="146" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A generative model for molecular distance geometry</title>
		<author>
			<persName><forename type="first">G</forename><surname>Simm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hernandez-Lobato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8949" to="8958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Reinforcement learning for molecular design guided by quantum mechanics</title>
		<author>
			<persName><forename type="first">G</forename><surname>Simm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pinsler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hern?ndez-Lobato</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8959" to="8969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Temporal attention unit: Towards efficient spatiotemporal predictive learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.12126</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Rfold</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.14041</idno>
		<title level="m">Towards simple yet effective rna secondary structure prediction</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Target-aware molecular graph generation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.04829</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Hyperspherical consistency regularization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="7244" to="7255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.10673</idno>
		<title level="m">Generative de novo protein design with global context</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.10774</idno>
		<title level="m">Generative tertiary structurebased rna design</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Elementary mathematical theory of classification and prediction</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Tanimoto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Autodock vina: improving the speed and accuracy of docking with a new scoring function, efficient optimization, and multithreading</title>
		<author>
			<persName><forename type="first">O</forename><surname>Trott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Olson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational chemistry</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="455" to="461" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Smidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>G?mez-Bombarelli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.12176</idno>
		<title level="m">Generative coarse-graining of molecular conformations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Baraniuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.11126</idno>
		<title level="m">Retrieval-based controllable molecule generation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wortsman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Gadre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gontijo-Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Morcos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Carmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="23965" to="23998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.00865</idno>
		<title level="m">Diffusionbased molecule generation with informative prior bridges</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Understanding and improving information transfer in multi-task learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>R?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00944</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Mole-bert: Rethinking pre-training graph neural networks for molecules</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Carbon</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="10" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Towards robust graph neural networks against label noise</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Learning neural generative dynamics for molecular conformation generation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">An end-to-end framework for molecular conformation generation via bilevel programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gomez-Bombarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="11537" to="11547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><surname>Geodiff</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.02923</idno>
		<title level="m">A geometric diffusion model for molecular conformation generation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
