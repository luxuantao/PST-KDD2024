<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DISTRIBUTED FOUNTAIN CODES FOR NETWORKED STORAGE</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alexandros</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94704</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vinod</forename><surname>Prabhakaran</surname></persName>
							<email>vinodmp@eecs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94704</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kannan</forename><surname>Ramchandran</surname></persName>
							<email>kannanr@eecs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94704</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DISTRIBUTED FOUNTAIN CODES FOR NETWORKED STORAGE</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B96EE65F987E0FC3D0810B625F426375</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We investigate the problem of constructing fountain codes for distributed storage in sensor networks. Specifically, we assume that there are n storage nodes with limited memory and k &lt; n data nodes generating the data by sensing the environment. We want a data collector who can appear anywhere in the network, to query any k + storage nodes and be able to retrieve almost all the data packets. We demonstrate how it is possible to solve this problem by using a specific kind of fountain code that requires only linear communication and decoding complexity. Further, for a grid topology, we propose a randomized algorithm that constructs the fountain code over a network using only geographical knowledge and local decisions. A key step in the analysis of our algorithm is a novel result concerning random walks on finite grids with traps.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In this paper we address the problem of creating a robust, distributed network memory hence providing fast and reliable access to distributed data using unreliable sensor nodes. The popular approach to retrieving data in wireless sensor networks is for the data collector to query for the data from the sensor nodes of interest. The desired data is then routed from the source nodes to the data collector. This may be categorized as a "pull-based" strategy. In certain scenarios of interest, a pull-based approach at query time may have limitations. Primarily, there can potentially be a large latency in getting the desired data out of a multitude of source nodes scattered randomly across the network due to the multi-hop routing phase following the query. In addition, storage nodes may fail and redundancy might be necessary to ensure that important data will be preserved. There is a tradeoff between the work performed at the time that the data is generated relative to the work performed at query time. In general, processing done at query time introduces latency and unreliability that may not be acceptable for certain applications. This work is accordingly motivated at trying to reduce latency and unreliability between query time and the time that the desired data is made available to the data collector.</p><p>Motivated by "smart dust" sensor networks <ref type="bibr" target="#b9">[9]</ref>, we consider a large scale network with unreliable nodes that have constrained communication, computation, and storage capabilities. Given k data nodes sensing some physical quantity of interest, we would like to use n unreliable storage nodes as a robust distributed network memory. The key issue is to introduce redundancy for reliability while at the same time minimize the required communication cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Problem Description</head><p>We assume that there are k data-generating nodes that are measuring a physical quantity of interest. Without loss of generality, we will assume that each data node generates one data packet of significant size containing the measurements over some time interval.</p><p>In our problem setting, we will assume that the data packets are independent. In most interesting sensing scenarios the data will be highly correlated and our scheme can be combined with distributed source coding to compress correlated data. Essentially, after distributed compression, the large correlated data packets can be replaced by smaller packets that are independent and have the theoretically smallest possible size, equal to the joint entropy of the physical sources.</p><p>Further, assume we have n &gt; k storage nodes that will act as storage and relay devices. Sensor nodes have limited memory and we model that by assuming that each storage node can store only one data packet (or a combination having the same number of bits as a data packet). This is required for the scalability of the network.</p><p>The ratio k/n &lt; 1 is assumed fixed as k and n scale. For example we can assume that some fixed ratio (for example 10%) of nodes in a sensor network are measuring while the rest are used as storage and relay devices.</p><p>We want to add redundancy and store the information contained in the k data packets in the n storage nodes. As there are k data packets of interest, and each storage node can store no more than 1 data packets worth of bits, it is clear that one has to query at least k storage nodes to completely recover the original data. We will refer to this procedure of storing the k data packets in n storage nodes and adding redundancy as a distributed networked storage strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Distributed Networked Storage</head><p>The problem we address in this paper is to find good networked storage strategies for answering approximate data collection queries. In particular, we want to ensure that a data collector who obtains access to (queries) any (1 + )k storage nodes is be able to recover at least (1δ)k original data packets. We will use linear codes over GF (2) for distributed networked storage. Specifically, each data node will be routing its data packet to d randomly selected storage nodes who will be storing the bitwise XOR of what they receive. This has to happen before the data collection can take place and we will therefore refer to this routing of data packets to storage nodes as pre-routing. A data collector who queries k(1 + ) storage nodes receives k(1 + ) linear equations over GF (2) and these can be hopefully used to recover k(1δ) original data packets. We assume that the data collector has enough memory and processing power to store the equations and run the belief propagation algorithm (as will be explained in a subsequent section) to recover the original data.</p><p>Any linear networked storage strategy can be compactly represented as s = mG where s is an 1 × n vector of stored data, m is 1 × k data vector and G is a k × n matrix with non-zero entries corresponding to the data packets that have been routed and combined in the storage nodes. Therefore, the desired properties of linear networked storage strategies can be translated into desired properties for the generator matrix G of a linear code.</p><p>Standard erasure codes can therefore be used for distributed networked storage in sensor networks. For example, Reed-Solomon codes or random linear codes <ref type="bibr" target="#b1">[1]</ref> will produce storage strategies with δ = 0 and = 0.</p><p>However, the key issue is that both the data and the storage nodes are distributed, and the question we explore is how to build codes that are suitable for distributed network constructions. The fact that the code is created over a network introduces new requirements and constraints and therefore requires novel code design. In particular, every non-zero element in the generator matrix of the code, corresponds to a data packet that has to be pre-routed from a data node to a storage node. In fact, the communication required to construct the networked storage code is proportional to the pre-routing degree d of each data node, that is, the number of storage nodes that each data node has to pre-route its packet to. Therefore, one desired property is that the codes used for distributed networked storage have as sparse generator matrices as possible to minimize the required communication.</p><p>The second desired property is random and independent construction. Any requirement on the structure of the generator matrix would require data nodes to coordinate so that they route the correct packets to the appropriate storage nodes. We would ideally like to have each data node choosing which storage nodes to contact randomly and independently, or equivalently every row of the generator matrix created independently. This row independence, which we call "decentralized property", was proposed in our previous work <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b4">4]</ref> and leads to stateless robust randomized algorithms for distributed networked storage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Previous work and Contributions</head><p>The main question we address in this paper is related to the sparsity of G which is measured by how d can scale as a function of the network size n so that almost all the data can be recovered. In our previous work <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b4">4]</ref> we demonstrated how to solve the (exact) distributed networked storage problem when the requirement was to recover all k data packets by querying any k storage nodes 1 . We introduced decentralized erasure codes which can be constructed by having each data node pre-route its data packet to d = Θ(log n) randomly selected storage nodes and further showed how this logarithmic degree is optimal if each data node is acting randomly and independently. This however leaves open the question of what can be possibly achieved when the pre-routing degree is constant (does not grow with the network size n) if some form of coordination between the data nodes is allowed.</p><p>The main contributions of this paper are the following. We show that any networked storage strategy (even if data nodes are coordinated by some centralized authority) with constant degrees d will fail to recover all k data packets with at least a constant probability (section 2). Therefore, since recovering all the data packets with constant degrees is impossible, we relax the problem and investigate how to recover a linear fraction of the k data packets. We show that this problem can be solved with constant pre-routing degrees using a 1 Which corresponds to setting δ = 0, = 0 in our problem setting specific choice of fountain codes (section 3). The surprising fact that one can construct such sparse linear equations that can still be used to recover almost all the data stems from carefully designed degree distributions <ref type="bibr" target="#b11">[11]</ref>. The last part of the paper (section 4) focuses on grid topologies and proposes a randomized algorithm to create the fountain codes over the network. A key step in the analysis of our algorithm is a novel result on the time until a random walk on a grid is absorbed, when there are randomly scattered traps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">LOWER BOUND ON THE ERROR PROBABILITY FOR CONSTANT DEGREES</head><p>As mentioned, any deterministic or randomized linear distributed networked storage strategy can be described in terms of a linear code and its generator matrix G. In this section we show that networked storage strategies with constant pre-routing degrees that do not grow with n, will fail with at least a constant probability if we require that δ = 0, = 0. Assume that some data node pre-routes its packet to a constant number of storage nodes. This means that there exists a row in the generator matrix of the code that has only a constant number of nonzero elements. The probability that the networked storage code fails (when δ = 0, = 0) is the probability that k randomly selected storage nodes do not contain enough information to recover all k data packets. We present the following bound (Proof omitted due to space constraints): Proposition 1. For an (n, k) linear code where n = qk, q &gt; 1, if there exists a row in the generator matrix that has no more than c constant nonzero elements, the probability that the corresponding networked storage fails is always larger than ( q-1 q ) c .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">FOUNTAIN CODES FOR APPROXIMATE DATA COLLECTION</head><p>Proposition 1 demonstrates that if we desire to have constant prerouting degrees that do not scale with the network size, it is not possible reliably to recover all the k data packets by querying any k storage nodes. Therefore, one natural question to ask is: what is the best that can be achieved with constant pre-routing degrees. In this section we show how one can use a fountain code to recover a constant fraction of the k data packets with pre-routing degrees which are random but bounded by a constant almost surely. A fountain code <ref type="bibr" target="#b11">[11]</ref> is created by a set of k input symbols and a degree distribution D. Each encoded symbol of a fountain code is created independently as follows: First, a degree d is sampled from the distribution D. Then d out of k input symbols are chosen uniformly and independently (without replacement) and the resulting output symbol is the bitwise XOR of the d selected input symbols. Fountain codes are decoded by running the belief propagation algorithm and the key technical challenge is the careful design of the degree distribution D so that this iterative decoding procedure succeeds. The first fountain codes where invented by Luby and called LT-Codes <ref type="bibr" target="#b10">[10]</ref>.</p><p>The degree distribution used is called the robust soliton distribution and has logarithmic degree. This would correspond to logarithmic pre-routing degree for our networked storage problem. Raptor codes <ref type="bibr" target="#b11">[11]</ref> manage to reduce the degrees from logarithmic to constant by using an appropriate pre-code. This idea cannot be used for our problem however, since the standard pre-codes do not have sparse and independent generator matrices. However we can use the LT code used inside the Raptor codes and still recover a constant fraction of the original data. Specifically, if we use the degree distribution with</p><p>V 1150</p><p>generating function:</p><formula xml:id="formula_0">ΩD(x) = 1 µ + 1 µx + x 2 1 • 2 + x 3 2 • 3 + • • • (1) + x D (D -1) • D + x D+1 D .<label>(2)</label></formula><p>where D = 4(1 + )/ and µ = /2 + ( /2) 2 for any &gt; 0. then we can use the following result <ref type="bibr" target="#b11">[11]</ref>:</p><p>Lemma 1. There exists positive c (depending on ) such that with an error probability of at most e -ck any set of (1 + /2)k + 1 output symbols of the fountain code with parameters (k, ΩD) are sufficient to recover at least (1δ)k input symbols via belief propagation decoding, where δ = ( /4)/(1 + ).</p><p>Therefore this fountain code can be used for approximate networked storage if one wants to query (1 + /2)k + 1 storage nodes and recover (1 -( /4)/(1 + ))k data nodes. Each storage node can independently sample its degree d from the given distribution ΩD and then it needs to request d data packets randomly and independently. Notice that since d is always smaller than the constant D = 4(1 + )/ and therefore the total number of pre-routed messages per data node is bounded by a constant almost surely (since k/n is fixed). A data collector can collect any (1+ /2)k+1 encoded packets and run the belief propagation decoder which will require a number of iterations proportional to the average degree of ΩD. Since this average is Ed ≈ ln(1/ ) <ref type="bibr" target="#b11">[11]</ref>, the decoding complexity will be only O(log(1/ )k) which is linear in k and therefore order optimal. Note that for this construction each storage node is picking its degree and which data nodes to contact. This property, which is sometimes called the rateless property of fountain codes, corresponds to having each column of the G matrix being created independently and is the transpose of the decentralized property <ref type="bibr" target="#b4">[4]</ref> mentioned in the previous section. Therefore, to construct these fountain codes over a network we need a mechanism for storage nodes to be able to find random data nodes and request for their data packets which will be in turned routed back to them. Such a mechanism is presented in the next section for grid topologies. Here, storage node A wants to find a random data node. It selects a random location on the grid (the location of node B) and a request is routed greedily (solid arrows). Since there is no data node in site B, a random walk starts (dotted arrows) until data node C is found. In the example R = 4, W = 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RANDOMIZED ALGORITHM FOR GRID TOPOLOGIES</head><p>In this section we address the problem of how to construct the fountain code over a grid topology with only local randomized decisions. We assume that our storage nodes are placed on the sites of a grid (of size √ n × √ n) with wireless transmission radius large enough for the four nearest neighbor connectivity. Grid topologies of sensor networks have been analyzed and many results are known, see for example <ref type="bibr" target="#b2">[2]</ref>. We further assume that the k = qn data nodes are placed randomly on some sites of the grid (as an extra device placed on the same location with the storage node and operating independently). We also assume that each node knows its location on the grid.</p><p>We want to use the networked storage strategy proposed in the previous section but we need a mechanism to send requests to random data nodes who can then route back their data packet. After d data packets have been received the storage node can XOR them, store the result and essentially become a fountain code encoded symbol. To find a random data node, we propose the following scheme. First a randomly selected location of the grid is selected by the storage node who is going to initiate the request. Then, a request packet is routed to that random location using greedy geographic routing. Since every node knows their location this procedure can be performed with only local information and will terminate after R steps, and R is always O( √ n). If that randomly selected site happens to have a data node, then that data node receives the request, routes back the data packet using greedy geographic routing and the procedure terminates. If however the randomly selected site is occupied only by a storage node, then the request initiates a (simple) random walk until it hits a site containing a data node. We assume that the k = qn data nodes are randomly scattered, such that all the n qn ways of choosing their locations are equally probable. Therefore, the data nodes are acting like traps for the random walk and what we want to show is that the walk is trapped sufficiently fast. Specifically, let a random walk start from a uniformly selected position (which we assume not to be a data node). Let W denote the (random) number of steps before the random walk is trapped (i.e. hits a data node and terminates). Therefore, in the proposed protocol there are two phases: the routing phase (geographic routing to the uniformly preselected position) which takes R = O( √ n) steps and the random walk phase which takes W steps. We want to show that</p><formula xml:id="formula_1">R + W R<label>(3)</label></formula><p>asymptotically almost surely (a.a.s.) for large n. This means that the cost of the random routing dominates and the average cost is nearly equal to the case where the measuring node knew where to send the packet.</p><p>Note that the actual probabilities that each data node receives the request under this algorithm are random variables that depend on the realization of their locations. For example if there is a cluster of data nodes somewhere, the nodes having only data node neighbors will be receiving the requests with lower probability relative to data nodes with many storage node neighbors. However, the expected reception probabilities are uniform and large fluctuations should not typically happen. In this paper we only analyze this expected behavior and in future work we plan to establish a concentration result around this expectation for large networks.</p><p>There has been significant work on problems related to random walks on infinite lattices with traps <ref type="bibr">[6,</ref><ref type="bibr" target="#b7">7]</ref>, but to the best of our knowledge, there are no known results for the scaling behavior of the trapping time for finite lattices. Therefore the following result might be of independent mathematical interest: </p><formula xml:id="formula_2">(W &gt; log n) = O( 1 log log n ).<label>(4)</label></formula><p>Proof: Due to space constraints, we present a sketch of the proof to highlight the techniques. We define an "inner region" Rinner inside the grid which has enough distance from the boundary so that a random walk that starts inside it will not be affected by the boundary before it takes log n steps.</p><formula xml:id="formula_3">Pr(W &gt; log n) ≤Pr(W &gt; log n|W0 ∈ Rinner) + 4 log n √ n</formula><p>where the last inequality follows from the fact that all nodes have a probability of 1/n of being W0 and there are less than 4 √ n log n nodes in Rinner. To bound the first term, let S (called the range of the random walk) denote the number of distinct sites visited by the random walk in steps. If we know S , the probability that the walk has not ended after ≤ log n steps is</p><formula xml:id="formula_4">Pr(W &gt; |W0 ∈ Rinner, S = s) = n -s qn n qn .<label>(5)</label></formula><p>Using Stirling's approximation, for s ≤ log n and ρ def = s/n, it is not hard to show that there exits a constant cs such that Pr(W &gt; |W0 ∈ Rinner) ≤ cs i=1 (1q) i Pr(S = i|W0 ∈ Rinner).</p><p>The sum goes only up to because S can never be larger than . Notice that random walks that start inside Rinner and take less than log n steps are indistinguishable from random walks on the infinite grid (since they are not affected by the boundary), so if S is the range of the random walk on the infinite grid, we can write Pr(W &gt; |W0 ∈ Rinner) ≤ cs i=1 (1-q) i Pr( S = i) = csE(1-q)</p><p>S .</p><p>(6) The following results are known from Dvoretzky and Erd ős <ref type="bibr" target="#b5">[5]</ref>, and Jain and Pruitt <ref type="bibr" target="#b8">[8]</ref> for S . </p><formula xml:id="formula_5">µ = E[ S ] = c1 log + O (log( ) 2 ) .<label>(7)</label></formula><p>Let k( ) = µtσ = c1 log -c2t( ) (log( )) 2 , where t( ) is a free parameter of the Chebyschev bound. We choose t( ) = log( ) So from (9), we obtain</p><formula xml:id="formula_7">Pr( S ≤ k( )) ≤ 1 t 2 = 1 ( log( )) 2 . (<label>10</label></formula><formula xml:id="formula_8">)</formula><p>Recall that the sum we want to bound is Pr(W &gt; |W0 ∈ Rinner) ≤ cs i=1 (1q) i Pr( S = i). <ref type="bibr" target="#b11">(11)</ref> This is the sum of the density of S weighted with a decreasing function (1q) i . It is therefore clear that if we shift some probability mass of the distribution of S to smaller values of i, we will get a larger sum. We define a new function g(i) by shifting all the probability mass of S that is smaller than k( ) to 1: g(1) = 1 log( ) . The remaining mass Pr( S &gt; k) is of course smaller than 1. So we may define g(k( )) = 1 and let g(i) = 0 for all other values. We therefore have the key inequality:</p><formula xml:id="formula_9">Pr(W &gt; |W0 ∈ Rinner) ≤ cs i=1 (1 -q) i Pr( S = i) (12) ≤ cs i=1 (1 -q) i g(i)</formula><p>= (1q)cs 1 log( ) + cs(1q) c 1 log( ) -√ log( )c 2 log( ) 2 .</p><p>If we choose the number of steps taken by the random walk as = log n it is not hard to use the previous bound and obtain the desired result.</p><p>We have therefore shown that for grids each storage node can follow this simple randomized protocol to find random data nodes using O( √ n) communication. Note that this is the diameter of the network and therefore the communication required to find a random data node is order optimal.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig 1 .</head><label>1</label><figDesc>Fig 1.Example of the randomized algorithm for grids (n = 25, k = 4). The nodes with the thermometer are data nodes placed on the same grid site as a storage node. Here, storage node A wants to find a random data node. It selects a random location on the grid (the location of node B) and a request is routed greedily (solid arrows). Since there is no data node in site B, a random walk starts (dotted arrows) until data node C is found. In the example R = 4, W = 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>σ 2 = 2 (</head><label>22</label><figDesc>Var( S ) ≤ c2 s inequality for S we getPr( S ≤ µtσ) ≤ Pr(| S -µ| ≥ tσ) ≤ 1 t 2</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">ACKNOWLEDGEMENTS</head><p>The authors would like to thank the anonymous reviewer for providing numerous suggestions for improving this paper and Prof. David Aldous of UC Berkeley for references and insightful discussions about the random walk problem.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This research was supported by NSF under grants CCR-0219722 and CCR-0330514.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">How Good is Random Linear Coding Based Distributed Networked Storage?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Acedanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Médard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Koetter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>NetCod</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Lattice Networks: Capacity Limits, Optimal Routing and Queueing Behavior</title>
		<author>
			<persName><forename type="first">G</forename><surname>Barrenetxea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Beferull-Lozano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Networking</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ubiquitous Access to Distributed Data in Large-Scale Sensor Networks through Decentralized Erasure Codes</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IPSN</title>
		<meeting>of IPSN</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Decentralized Erasure Codes for Distributed Networked Storage</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Special Issue of IEEE Trans. on Inf. Theory: Networking and Information Theory</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Some problems on random walk in space</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dvoretzky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Erdős</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Second Berkeley Symp. Math. Statist. Probab. 1951</title>
		<meeting>of Second Berkeley Symp. Math. Statist. Probab. 1951<address><addrLine>Berkeley</addrLine></address></meeting>
		<imprint>
			<publisher>Univ. California Press</publisher>
			<biblScope unit="page" from="353" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Random Walks on Random Lattices</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Th</surname></persName>
		</author>
		<author>
			<persName><surname>Hollander</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
	<note>Ph.D thesis</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Random walks and random environments</title>
		<author>
			<persName><forename type="first">D</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName><surname>Hughes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The range of random walk</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Pruitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Sixth Berkeley Symp. Math. Statist. Probab</title>
		<meeting>of Sixth Berkeley Symp. Math. Statist. Probab<address><addrLine>Berkeley</addrLine></address></meeting>
		<imprint>
			<publisher>Univ. California Press</publisher>
			<date type="published" when="1972">1972</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="31" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Next century challenges: mobile networking for Smart Dust</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S J</forename><surname>Pister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 5th annual ACM/IEEE Int. Conf. on Mobile computing and networking</title>
		<meeting>of the 5th annual ACM/IEEE Int. Conf. on Mobile computing and networking</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">LT Codes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE FOCS</title>
		<meeting>of IEEE FOCS</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Raptor Codes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shokrollahi</surname></persName>
		</author>
		<idno>DF2003-06- 001</idno>
		<imprint>
			<date type="published" when="2003-06">June, 2003</date>
			<publisher>Digital Fountain, Inc</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
