<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On Sampling Strategies for Neural Network-based Collaborative Filtering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
							<email>tingchen@cs.ucla.edu</email>
						</author>
						<author>
							<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
							<email>yzsun@cs.ucla.edu</email>
						</author>
						<author>
							<persName><forename type="first">Yue</forename><surname>Shi</surname></persName>
							<email>yueshi@acm.org</email>
							<affiliation key="aff4">
								<orgName type="department">Now at Facebook</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles Los Angeles</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles Los Angeles</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Yahoo! Research Sunnyvale</orgName>
								<address>
									<postCode>94089</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Liangjie Hong Etsy Inc. Brooklyn</orgName>
								<address>
									<postCode>11201</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On Sampling Strategies for Neural Network-based Collaborative Filtering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3097983.3098202</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent advances in neural networks have inspired people to design hybrid recommendation algorithms that can incorporate both (1) user-item interaction information and (2) content information including image, audio, and text. Despite their promising results, neural network-based recommendation algorithms pose extensive computational costs, making it challenging to scale and improve upon. In this paper, we propose a general neural network-based recommendation framework, which subsumes several existing stateof-the-art recommendation algorithms, and address the efficiency issue by investigating sampling strategies in the stochastic gradient descent training for the framework. We tackle this issue by first establishing a connection between the loss functions and the useritem interaction bipartite graph, where the loss function terms are defined on links while major computation burdens are located at nodes. We call this type of loss functions "graph-based" loss functions, for which varied mini-batch sampling strategies can have different computational costs. Based on the insight, three novel sampling strategies are proposed, which can significantly improve the training efficiency of the proposed framework (up to ×30 times speedup in our experiments), as well as improving the recommendation performance. Theoretical analysis is also provided for both the computational cost and the convergence. We believe the study of sampling strategies have further implications on general graphbased loss functions, and would also enable more research under the neural network-based recommendation framework.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Collaborative Filtering (CF) has been one of the most effective methods in recommender systems, and methods like matrix factorization <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b26">27]</ref> are widely adopted. However, one of its limitation is the dealing of "cold-start" problem, where there are few or no observed interactions for new users or items, such as in news recommendation. To overcome this problem, hybrid methods are proposed to incorporate side information <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28]</ref>, or item content information <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b30">31]</ref> into the recommendation algorithm. Although these methods can deal with side information to some extent, they are not effective for extracting features in complicated data, such as image, audio and text. On the contrary, deep neural networks have been shown very powerful at extracting complicated features from those data automatically <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b18">19]</ref>. Hence, it is natural to combine deep learning with traditional collaborative filtering for recommendation tasks, as seen in recent studies <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>In this work, we generalize several state-of-the-art neural networkbased recommendation algorithms <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b29">30]</ref>, and propose a more general framework that combines both collaborative filtering and deep neural networks in a unified fashion. The framework inherits the best of two worlds: (1) the power of collaborative filtering at capturing user preference via their interaction with items, and (2) that of deep neural networks at automatically extracting high-level features from content data. However, it also comes with a price. Traditional CF methods, such as sparse matrix factorization <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b26">27]</ref>, are usually fast to train, while the deep neural networks in general are much more computationally expensive <ref type="bibr" target="#b18">[19]</ref>. Combining these two models in a new recommendation framework can easily increase computational cost by hundreds of times, thus require a new design of the training algorithm to make it more efficient.</p><p>We tackle the computational challenges by first establishing a connection between the loss functions and the user-item interaction bipartite graph. We realize the key issue when combining the CF and deep neural networks are in: the loss function terms are defined over the links, and thus sampling is on links for the stochastic gradient training, while the main computational burdens are located at nodes (e.g., Convolutional Neural Network computation for image of an item). For this type of loss functions, varied mini-batch sampling strategies can lead to different computational costs, depending on how many node computations are required in a mini-batch. The existing stochastic sampling techniques, such as IID sampling, are inefficient, as they do not take into account the node computations that can be potentially shared across links/data points.</p><p>Inspired by the connection established, we propose three novel sampling strategies for the general framework that can take coupled computation costs across user-item interactions into consideration. The first strategy is Stratified Sampling, which try to amortize costly node computation by partitioning the links into different groups based on nodes (called stratum), and sample links based on these groups. The second strategy is Negative Sharing, which is based on the observation that interaction/link computation is fast, so once a mini-batch of user-item tuples are sampled, we share the nodes for more links by creating additional negative links between nodes in the same batch. Both strategies have their pros and cons, and to keep their advantages while avoid their weakness, we form the third strategy by combining the above two strategies. Theoretical analysis of computational cost and convergence is also provided.</p><p>Our contributions can be summarized as follows.</p><p>• We propose a general hybrid recommendation framework (Neural Network-based Collaborative Filtering) combining CF and content-based methods with deep neural networks, which generalize several state-of-the-art approaches. • We establish a connection between the loss functions and the user-item interaction graph, based on which, we propose sampling strategies that can significantly improve training efficiency (up to ×30 times faster in our experiments) as well as the recommendation performance of the proposed framework. • We provide both theoretical analysis and empirical experiments to demonstrate the superiority of the proposed methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A GENERAL FRAMEWORK FOR NEURAL NETWORK-BASED COLLABORATIVE FILTERING</head><p>In this section, we propose a general framework for neural networkbased Collaborative Filtering that incorporates both interaction and content information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Text Recommendation Problem</head><p>In this work, we use the text recommendation task <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32]</ref> as an illustrative application for the proposed framework. However, the proposed framework can be applied to more scenarios such as music and video recommendations. We use x u and x v to denote features of user u and item v, respectively. In text recommendation setting, we set x u to one-hot vector indicating u's user id (i.e. a binary vector with only one at the u-th position) 1 , and x v as the text sequence, i.e.</p><formula xml:id="formula_0">x v = (w 1 , w 2 , • • • , w t ).</formula><p>A response matrix R is used to denote the historical interactions between users and articles, where ruv indicates interaction between a user u and an article v, such as "click-or-not" and "like-or-not". Furthermore, we consider R as implicit feedback in this work, which means only positive interactions are provided, and non-interactions are treated as negative feedback implicitly. 1 Other user profile features can be included, if available. Given user/item features {x u }, {x v } and their historical interaction R, the goal is to learn a model which can rank new articles for an existing user u based on this user's interests and an article's text content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Functional Embedding</head><p>In most of existing matrix factorization techniques <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b26">27]</ref>, each user/item ID is associated with a latent vector u or v (i.e., embedding), which can be considered as a simple linear transformation from the one-hot vector represented by their IDs, i.e. u u = f (x u ) = W T x u (W is the embedding/weight matrix). Although simple, this direct association of user/item ID with representation make it less flexible and unable to incorporate features such as text and image.</p><p>In order to effectively incorporate user and item features such as content information, it has been proposed to replace embedding vectors u or v with functions such as decision trees <ref type="bibr" target="#b37">[38]</ref> and some specific neural networks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4]</ref>. Generalizing the existing work, we propose to replace the original embedding vectors u and v with general differentiable functions f (•) ∈ R d and g(•) ∈ R d that take user/item features x u , x v as their inputs. Since the user/item embeddings are the output vectors of functions, we call this approach Functional Embedding. After embeddings are computed, a score function r (u, v) can be defined based on these embeddings for a user/item pair (u, v), such as vector dot product r (u, v) = f (x u ) T g(x v ) (used in this work), or a general neural network. The model framework is shown in Figure <ref type="figure" target="#fig_0">1</ref>. It is easy to see that our framework is very general, as it does not explicitly specify the feature extraction functions, as long as the functions are differentiable. In practice, these function can be specified with neural networks such as CNN or RNN, for extracting high-level information from image, audio, or text sequence. When there are no features associated, it degenerates to conventional matrix factorization where user/item IDs are used as their features.</p><p>For simplicity, we will denote the output of f (x u ) and g(x v ) by f u and g v , which are the embedding vectors for user u and item v.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Loss Functions for Implicit Feedback</head><p>In many real-world applications, users only provide positive signals according to their preferences, while negative signals are usually implicit. This is usually referred as "implicit feedback" <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1: Examples of loss functions for recommendation.</head><p>Pointwise loss SG-loss <ref type="bibr" target="#b21">[22]</ref>:</p><formula xml:id="formula_1">-(u,v )∈D log σ (f T u g v ) + λE v ′ ∼Pn log σ (−f T u g v ′ )</formula><p>MSE-loss <ref type="bibr" target="#b29">[30]</ref>:</p><formula xml:id="formula_2">(u,v )∈D ( r + uv − f T u g v ) 2 + λE v ′ ∼Pn ( r − uv ′ − f T u g v ′ ) 2</formula><p>Pairwise loss Log-loss <ref type="bibr" target="#b25">[26]</ref>:</p><formula xml:id="formula_3">-(u,v )∈D E v ′ ∼Pn log σ γ (f T u g v − f T u g v ′ )</formula><p>Hinge-loss <ref type="bibr" target="#b32">[33]</ref>:</p><formula xml:id="formula_4">(u,v )∈D E v ′ ∼Pn max f T u g v ′ − f T u g v + γ , 0</formula><p>In this work, we consider two types of loss functions that can handle recommendation tasks with implicit feedback, namely, pointwise loss functions and pairwise loss functions. Pointwise loss functions have been applied to such problems in many existing work. In <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">32]</ref>, mean square loss (MSE) has been applied where "negative terms" are weighted less. And skip-gram (SG) loss has been successfully utilized to learn robust word embedding <ref type="bibr" target="#b21">[22]</ref>. These two loss functions are summarized in Table <ref type="table">1</ref>. Note that we use a weighted expectation term over all negative samples, which can be approximated with small number of samples. We can also abstract the pointwise loss functions into the following form:</p><formula xml:id="formula_5">L pointwise = E u∼P d (u ) E v∼P d (v |u ) c + uv L + (u, v |θ ) + E v ′ ∼P n (v ′ ) c − uv ′ L − (u, v ′ |θ )<label>(1)</label></formula><p>where P d is (empirical) data distribution, P n is user-defined negative data distribution, c is user defined weights for the different useritem pairs, θ denotes the set of all parameters, L + (u, v |θ ) denotes the loss function on a single positive pair (u, v), and L − (u, v |θ ) denotes the loss on a single negative pair. Generally speaking, given a user u, pointwise loss function encourages her score with positive items {v}, and discourage her score with negative items {v ′ }.</p><p>When it comes to ranking problem as commonly seen in implicit feedback setting, some have argued that the pairwise loss would be advantageous <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b32">33]</ref>, as pairwise loss encourages ranking of positive items above negative items for the given user. Different from pointwise counterparts, pairwise loss functions are defined on a triplet of (u, v, v ′ ), where v is a positive item and v ′ is a negative item to the user u. Table <ref type="table">1</ref> also gives two instances of such loss functions used in existing papers <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b32">33]</ref> (with γ being the predefined "margin" parameter). We can also abstract pairwise loss functions by the following form:</p><formula xml:id="formula_6">L pairwise = E u∼P d (u ) E v∼P d (v |u ) E v ′ ∼P n (v ′ ) c uvv ′ L(u, v, v ′ |θ )<label>(2)</label></formula><p>where the notations are similarly defined as in Eq. 1 and L(u, v, v ′ |θ ) denotes the loss function on the triplet (u, v, v ′ ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Stochastic Gradient Descent Training and Computational Challenges</head><p>To train the model, we use stochastic gradient descent based algorithms <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b15">16]</ref>, which are widely used for training matrix factorization and neural networks. The main flow of the training algorithm Algorithm 1 Standard model training procedure while not converged do // mini-batch sampling draw a mini-batch of user-item tuples (u, v)<ref type="foot" target="#foot_0">2</ref> // forward pass compute f (x u ), g(x v ) and their interaction f T u g v compute the loss function L // backward pass compute gradients and apply SGD updates end while is summarized in Algorithm 1. By adopting the functional embedding with (deep) neural networks, we can increase the power of the model, but it also comes with a cost. Figure <ref type="figure" target="#fig_1">2</ref> shows the training time (for CiteULike data) with different item functions g(•), namely linear embedding taking item id as feature (equivalent to conventional MF), CNN-based content embedding, and RNN/LSTM-based content embedding. We see orders of magnitude increase of training time for the latter two embedding functions, which may create barriers to adopt models under this framework.</p><p>Breaking down the computation cost of the framework, there are three major parts of computational cost. The first part is the user based computation (denoted by t f time units per user), which includes forward computation of user function f (x u ), and backward computation of the function output w.r.t. its parameters. The second part is the item based computation (denoted by t д time units per item), which similarly includes forward computation of item function g(x v ), as well as the back computation. The third part is the computation for interaction function (denoted by t i time units per interaction). The total computational cost for a mini-batch is then t f × # of users + t д × # of items + t i × # of interactions, with some other minor operations which we assume ignorable. In the text recommendation application, user IDs are used as user features (which can be seen as linear layer on top of the one-hot inputs), (deep) neural networks are used for text sequences, vector dot product is used as interaction function, thus the dominant computational cost is t д (orders of magnitude larger than t f and t i ). In other words, we assume t д ≫ t f , t i in this work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>%(')</head><p>)(')</p><p>ℒ 2 (+ " , -" ) ℒ<ref type="foot" target="#foot_1">3</ref> (+ " , -4 )</p><p>ℒ 2 (+ # , -4 )</p><formula xml:id="formula_7">ℒ 3 (+ # , -# ) %(') )(')</formula><p>)(')</p><p>Figure <ref type="figure">3</ref>: The bipartite interaction graph for pointwise loss functions, where loss functions are defined over links. The pairwise loss functions are defined over pairs of links.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MINI-BATCH SAMPLING STRATEGIES FOR EFFICIENT MODEL TRAINING</head><p>In this section, we propose and discuss different sampling strategies that can improve the efficiency of the model training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Computational Cost in a Graph View</head><p>Before the discussion of different sampling strategies, we motivate our readers by first making a connection between the loss functions and the bipartite graph of user-item interactions. In the loss functions laid out before, we observed that each loss function term in Eq. 1, namely, L(u, v), involves a pair of user and item, which corresponds to a link in their interaction graph. And two types of links corresponding to two types of loss terms in the loss functions, i.e., positive links/terms and negative links/terms. Similar analysis holds for pairwise loss in Eq. 2, though there are slight differences as each single loss function corresponds to a pair of links with opposite signs on the graph. We can also establish a correspondence between user/item functions and nodes in the graph, i.e., f (u) to user node u and g(v) to item node v. The connection is illustrated in Figure <ref type="figure">3</ref>. Since the loss functions are defined over the links, we name them "graph-based" loss functions to emphasize the connection.</p><p>The key observation for graph-based loss functions is that: the loss functions are defined over links, but the major computational burden are located at nodes (due to the use of costly g(•) function). Since each node is associated with multiple links, which are corresponding to multiple loss function terms, the computational costs of loss functions over links are coupled (as they may share the same nodes) when using mini-batch based SGD. Hence, varied sampling strategies yield different computational costs. For example, when we put links connected to the same node together in a mini-batch, the computational cost can be lowered as there are fewer g(•) to compute 3 . This is in great contrast to conventional optimization problems, where each loss function term dose not couple with others in terms of computation cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Existing Mini-Batch Sampling Strategies</head><p>In standard SGD sampler, (positive) data samples are drawn uniformly at random for gradient computation. Due to the appearance of negative samples, we draw negative samples from some predefined probability distribution, i.e. (u ′ , v ′ ) ∼ P n (u ′ , v ′ ). We call this approach "IID Sampling", since each positive link is dependently and identical distributed, and the same holds for negative links (with a different distribution).</p><p>Many existing algorithms with graph-based loss functions <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b28">29]</ref> adopt the "Negative Sampling" strategy, in which k negative samples are drawn whenever a positive example is drawn. The negative samples are sampled based on the positive ones by replacing the items in the positive samples. This is illustrated in Algorithm 2 and Figure <ref type="figure" target="#fig_5">4(a)</ref>. The IID Sampling strategy dose not take into account the property of graph-based loss functions, since samples are completely independent of each other. Hence, the computational cost in a single mini-batch cannot be amortized across different samples, leading to very extensive computations with (deep) neural networks. The Negative Sampling does not really help, since the item function computation cost t д is the dominant one. To be more specific, consider a mini-batch with b (1 + k ) links sampled by IID Sampling or Negative Sampling, we have to conduct item based g(•) computation b (1 + k ) times, since items in a mini-batch are likely to be non-overlapping with sufficient large item sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Proposed Sampling Strategies</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Stratified Sampling (by Items</head><p>). Motivated by the connection between the loss functions and the bipartite interaction graph as shown in Figure <ref type="figure">3</ref>, we propose to sample links that share nodes, in particular those with high computational cost (i.e. t д for item function g(•) in our case). By doing so, the computational cost within a mini-batch can be amortized, since fewer costly functions are computed (in both forward and backward propagations).</p><p>In order to achieve this, we (conceptually) partition the links, which correspond to loss function terms, into strata. A stratum in the strata is a set of links on the bipartite graph sharing the same source or destination node. Instead of drawing links directly for training, we will first draw stratum and then draw both positive and negative links. Since we want each stratum to share the same item, we can directly draw an item and then sample its links. The details are given in Algorithm 3 and illustrated in Figure <ref type="figure" target="#fig_5">4(b)</ref>.</p><p>Compared to Negative Sampling in Algorithm 2, there are several differences: (1) Stratified Sampling can be based on either item or user, but in the negative sampling only negative items are drawn; and (2) each node in stratified sampling can be associated with  With s = 4, k = 10 as used in some of our experiments, it yields to ×40 speedup optimally. However, it is worth pointing out that item-based Stratified Sampling cannot be applied to pairwise loss functions, which compare preferences over items based on a given user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Negative</head><p>Sharing. The idea of Negative Sharing is inspired from a different aspect of the connection between the loss functions and the bipartite interaction graph. Since t i ≪ t д , i.e. the computational cost of interaction function (dot product) is ignorable compared to that of item function, when a mini-batch of users and items are sampled, increasing the number of interactions among them may not result in a significant increase of computational cost. This can be achieved by creating a complete bipartite graph for a mini-batch by adding negative links between all non-interaction pairs between users and items. Using this strategy, we can draw NO negative links at all! More specifically, consider the IID Sampling, when b positive links are sampled, there will be b users and b items involved (assuming the sizes of user set and item set are much larger than b). Note that, there are b (b −1) non-interactions in the mini-batch, which are not considered in IID Sampling or Negative Sampling, instead they Since Negative Sharing avoids sampling k negative links, it only contains b items while in Negative Sampling contains b (1 + k ) items. So it can provide (1 +k ) times speedup compared to Negative Sampling (assuming t д ≫ t f , t i , and total interaction cost is still insignificant). Given the batch size b is usually larger than k (e.g., b = 512, k = 20 in our experiments), much more negative links (e.g. 512 × 511) will also be considered, this is helpful for both faster convergence and better performance, which is shown in our experiments. However, as the number of negative samples increases, the performance and the convergence will not be improved linearly. diminishing return is expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Stratified</head><p>Sampling with Negative Sharing. The two strategies above can both reduce the computational cost by smarter sampling of the mini-batch. However, they both have weakness: Stratified Sampling cannot deal with pairwise loss and it is still dependent on the number of negative examples k, and Negative Sharing introduces a lot of negative samples which may be unnecessary due to diminishing return.</p><p>The good news is, the two sampling strategies are proposed from different perspectives, and combining them together can preserve their advantages while avoid their weakness. This leads to the Stratified Sampling with Negative Sharing, which can be applied to both pointwise and pairwise loss functions, and it can have flexible ratio between positive and negative samples (i.e. more positive links given the same negative links compared to Negative Sharing). To do so, basically we sample positive links according to Stratified Sampling, and then sample/create negative links by treating noninteractions as negative links. The details are given in Algorithm 5 and illustrated in Figure <ref type="figure" target="#fig_5">4(d)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Implementation Details.</head><p>When the negative/noise distribution P n is not unigram <ref type="foot" target="#foot_2">4</ref> , we need to adjust the loss function in order to make sure the stochastic gradient is unbiased. For pointwise loss, each of the negative term is adjusted by multiplying a weight of</p><formula xml:id="formula_8">P n (v ′ ) P d (v ′ )</formula><p>; for pairwise loss, each term based on a triplet of (u, v, v ′ ) is adjusted by multiplying a weight of</p><formula xml:id="formula_9">P n (v ′ ) P d (v ′ ) where v ′ is the sampled negative item.</formula><p>Instead of sampling, we prefer to use shuffling as much as we can, which produces unbiased samples while yielding zero variance. This can be a useful trick for achieving better performance when the number of drawn samples are not large enough for each loss terms. For IID and Negative Sampling, this can be easily done for positive links by simply shuffling them. As for the Stratified Sampling (w./wo. Negative Sharing), instead of shuffling the positive links directly, we shuffle the randomly formed strata (where each stratum contains roughly a single item) <ref type="foot" target="#foot_3">5</ref> . All other necessary sampling operations required are sampling from discrete distributions, which can be done in O (1) with Alias method.</p><p>In Negative Sharing (w./wo. Stratified Sampling), We can compute the user-item interactions with more efficient operator, i.e. replacing the vector dot product between each pair of (f, g) with matrix multiplication between (F, G), where</p><formula xml:id="formula_10">F = [f u 1 , • • • , f u n ], G = [g v 1 , • • • , g v m ]</formula><p>. Since matrix multiplication is higher in BLAS level than vector multiplication <ref type="bibr" target="#b13">[14]</ref>, even we increase the number of interactions, with medium matrix size (e.g. 1000× 1000) it does not affect the computational cost much in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Computational Cost and Convergence Analysis</head><p>Here we provide a summary for the computational cost for different sampling strategies discussed above, and also analyze their convergences. Two aspects that can lead to speedup are analyzed: (1) the computational cost for a mini-batch, i.e. per iteration, and (2) the number of iterations required to reach some referenced loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Computational Cost.</head><p>To fairly compare different sampling strategies, we fix the same number of positive links in each of the mini-batch, which correspond to the positive terms in the loss function. Table <ref type="table">2</ref> shows the computational cost of different sampling strategies for a given mini-batch. Since t д ≫ t f , t i in practice, we approximate the theoretical speedup per iteration by comparing the number of t д computation. We can see that the proposed sampling strategies can provide (1 + k ), by Negative Sharing, or s (1 + k ), by Stratified Sampling (w./w.o. Negative Sharing), times speedup for each iteration compared to IID Sampling or Negative Sampling. As for the number of iterations to reach a reference loss, it is related to number of negative samples utilized, which is analyzed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Convergence</head><p>Analysis. We want to make sure the SGD training under the proposed sampling strategies can converge correctly. The necessary condition for this to hold is the stochastic gradient estimator has to be unbiased, which leads us to the following lemma. Lemma 1. (unbiased stochastic gradient) Under sampling Algorithm 2, 3, 4, and 5, we have E B [∇L B (θ t )] = ∇L(θ t ). In other words, the stochastic mini-batch gradient equals to true gradient in expectation.</p><p>This holds for both pointwise loss and pairwise loss. It is guaranteed since we draw samples stochastically and re-weight certain samples accordingly. The detailed proof can be found in the supplementary material.</p><p>Given this lemma, we can further analyze the convergence behavior of the proposed sampling behaviors. Due to the highly nonlinear and non-convex functions composed by (deep) neural networks, the convergence rate is usually difficult to analyze. So we show the SGD with the proposed sampling strategies follow a local convergence bound (similar to <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b23">24]</ref>). , and θ * is the minimizer to L. Then, the following holds for the proposed sampling strategies given in Algorithm 2, 3, 4, 5</p><formula xml:id="formula_11">min 0≤t ≤T −1 E[∥∇L(θ t )∥ 2 ] ≤ 2(L(θ 0 ) − L(θ * )) T σ</formula><p>The detailed proof is also given in the supplementary material. Furthermore, utilizing more negative links in each mini-batch can lower the expected stochastic gradient variance. As shown in <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref>, the reduction of variance can lead to faster convergence. This suggests that Negative Sharing (w./wo. Stratified Sampling) has better convergence than the Stratified Sampling (by Items).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS 4.1 Data Sets</head><p>Two real-world text recommendation data sets are used for the experiments. The first data set CiteULike, collected from CiteU-Like.org, is provided in <ref type="bibr" target="#b30">[31]</ref>. The CiteULike data set contains users bookmarking papers, where each paper is associated with a title Table 2: Computational cost analysis for a batch of b positive links. We use vec to denote vector multiplication, and mat to denote matrix multiplication. Since t д ≫ t f , t i in practice, the theoretical speedup per iteration can be approximated by comparing the number of t д computation, which is colored red below. The number of iterations to reach a referenced loss is related to the number of negative links in each mini-batch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sampling</head><p># pos. links # neg. links</p><formula xml:id="formula_12"># t f # t д # t i pointwise pairwise IID [3] b bk b (1 + k ) b (1 + k ) b (1 + k ) vec ✓ × Negative [1, 21, 29] b bk b b (1 + k ) b (1 + k ) vec ✓ ✓ Stratified (by Items) b bk b (1 + k ) b s b (1 + k ) vec ✓ × Negative Sharing b b (b − 1) b b b × b mat ✓ ✓ Stratified with N.S. b b (b−1) s b b s b × b s mat ✓ ✓</formula><p>and an abstract. The second data set is a random subset of Yahoo! News data set 6 , which contains users clicking on news presented at Yahoo!. There are 5,551 users and 16,980 items, and total of 204,986 positive interactions in CiteULike data. As for Yahoo! News data, there are 10,000 users, 58,579 items and 515,503 interactions. Following <ref type="bibr" target="#b3">[4]</ref>, we select a portion (20%) of items to form the pool of test items. All user interactions with those test items are held-out during training, only the remaining user-item interactions are used as training data, which simulates the scenarios for recommending newly-emerged text articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Settings</head><p>The main purpose of experiments is to compare the efficiency and effectiveness of our proposed sampling strategies against existing ones. So we mainly compare Stratified Sampling, Negative Sharing, and Stratified Sampling with Negative Sharing, against IID sampling and Negative Sampling. It is worth noting that several existing stateof-the-art models <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b29">30]</ref> are special cases of our framework (e.g. using MSE-loss/Log-loss with CNN or RNN), so they are compared to other loss functions under our framework.</p><p>Evaluation Metrics. For recommendation performance, we follow <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b31">32]</ref> and use recall@M. As pointed out in <ref type="bibr" target="#b31">[32]</ref>, the precision is not a suitable performance measure since non interactions may be due to (1) the user is not interested in the item, or (2) the user does not pay attention to its existence. More specifically, for each user, we rank candidate test items based on the predicted scores, and then compute recall@M based on the list. Finally the recall@M is averaged over all users.</p><p>As for the computational cost, we mainly measure it in three dimensions: the training time for each iteration (or epoch equivalently, since batch size is fixed for all methods), the number of iterations needed to reach a referenced loss, and the total amount of computation time needed to reach the same loss. In our experiments, we use the smallest loss obtained by IID sampling in the maximum 30 epochs as referenced loss. Noted that all time measure mentioned here is in Wall Time.</p><p>Parameter Settings. The key parameters are tuned with validation set, while others are simply set to reasonable values. We adopt Adam <ref type="bibr" target="#b15">[16]</ref> as the stochastic optimizer. We use the same batch size b = 512 for all sampling strategies, we use the number of positive link per sampled stratum s = 4, learning rate is set to 0.001 for MSE-loss, and 6 https://webscope.sandbox.yahoo.com/catalog.php?datatype=r&amp;did=75 0.01 for others. γ is set to 0.1 for Hinge-loss, and 10 for others. λ is set to 8 for MSE-loss, and 128 for others. We set number of negative examples k = 10 for convolutional neural networks, and k = 5 for RNN/LSTM due to the GPU memory limit. All experiments are run with Titan X GPUs. We use unigram noise/negative distribution.</p><p>For CNN, we adopt the structure similar in <ref type="bibr" target="#b14">[15]</ref>, and use 50 filters with filter size of 3. Regularization is added using both weight decay on user embedding and dropout on item embedding. For RNN, we use LSTM <ref type="bibr" target="#b11">[12]</ref> with 50 hidden units. For both models, the dimensions of user and word embedding are set to 50. Early stop is utilized, and the experiments are run to maximum 30 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Speedup Under Different Sampling Strategies</head><p>Table <ref type="table" target="#tab_0">3</ref> breaks down the speedup into (1) speedup for training on a given mini-batch, (2) number of iterations (to reach referenced cost) speedup, and (3) the total speedup, which is product of the first two. Different strategies are compared against IID Sampling. It is shown that Negative Sampling has similar computational cost as IID Sampling, which fits our projection. All three proposed sampling strategies can significantly reduce the computation cost within a mini-batch. Moreover, the Negative Sharing and Stratified Sampling with Negative Sharing can further improve the convergence w.r.t.  the number of iterations, which demonstrates the benefit of using larger number of negative examples. Figure <ref type="figure" target="#fig_6">5</ref> and 6 shows the convergence curves of both loss and test performance for different sampling strategies (with CNN + SGloss). In both figures, we measure progress every epoch, which is equivalent to a fixed number of iterations since all methods have the same batch size b. In both figures, we can observe mainly two types of convergences behavior. Firstly, in terms of number of iterations, Negative Sharing (w./wo. Stratified Sampling) converge fastest, which attributes to the number of negative samples used. Secondly, in terms of wall time, Negative Sharing (w./wo. Stratified Sampling) and Stratified Sampling (by Items) are all significantly faster than baseline sampling strategies, i.e. IID Sampling and Neagtive Sampling. It is also interesting to see that that overfitting occurs earlier as convergence speeds up, which does no harm as early stopping can be used.</p><p>For Stratified Sampling (w./wo. negative sharing), the number of positive links per stratum s can also play a role to improve speedup as we analyzed before. As shown in Figure <ref type="figure" target="#fig_10">7</ref>, the convergence time as well as recommendation performance can both be improved with a reasonable s, such as 4 or 8 in our case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Recommendation Performance Under Different Sampling Strategies</head><p>It is shown in above experiments that the proposed sampling strategies are significantly faster than the baselines. But we would also like to further access the recommendation performance by adopting the proposed strategies. Table <ref type="table" target="#tab_1">4</ref> compares the proposed sampling strategies with CNN/RNN models and four loss functions (both pointwise and pairwise). We can see that IID Sampling, Negative Sampling and Stratified Sampling (by Items) have similar recommendation performances, which is expected since they all utilize same amount of negative links. For Negative Sharing and Stratified Sampling with Negative Sharing, since there are much more negative samples utilized, their performances are significantly better. We also observe that the current recommendation models based on MSE-loss <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b29">30]</ref> can be improved by others such as SG-loss and pairwise loss functions <ref type="bibr" target="#b3">[4]</ref>.</p><p>To further investigate the superior performance brought by Negative Sharing. We study the number of negative examples k and  the convergence performance. Figure <ref type="figure" target="#fig_11">8</ref> shows the test performance against various k. As shown in the figure, we observe a clear diminishing return in the improvement of performance. However, the performance seems still increasing even we use 20 negative examples, which explains why our proposed method with negative sharing can result in better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>Collaborative filtering <ref type="bibr" target="#b17">[18]</ref> has been one of the most effective methods in recommender systems, and methods like matrix factorization <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b26">27]</ref> are widely adopted. While many papers focus on the explicit feedback setting such as rating prediction, implicit feedback is found in many real-world scenarios and studied by many papers as well <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">26]</ref>. Although collaborative filtering techniques are powerful, they suffer from the so-called "cold-start" problem since side/content information is not well leveraged. To address the issue and improve performance, hybrid methods are proposed to incorporate side information <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b37">38]</ref>, as well as content information <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32]</ref>. Deep Neural Networks (DNNs) have been showing extraordinary abilities to extract high-level features from raw data, such as video, audio, and text <ref type="bibr">[8, 15,</ref> Compared to traditional feature detectors, such as SIFT and n-grams, DNNs and other embedding methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b28">29]</ref> can automatically extract better features that produce higher performance in various tasks. To leverage the extraordinary feature extraction or content understanding abilities of DNNs for recommender systems, recent efforts are made in combining collaborative filtering and neural networks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">32]</ref>. <ref type="bibr" target="#b31">[32]</ref> adopts autoencoder for extracting item-side text information for article recommendation, <ref type="bibr" target="#b0">[1]</ref> adopts RNN/GRU to better understand the text content. <ref type="bibr" target="#b3">[4]</ref> proposes to use CNN and pairwise loss functions, and also incorporate unsupervised text embedding. The general functional embedding framework in this work subsumes existing models <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>Stochastic Gradient Descent <ref type="bibr" target="#b2">[3]</ref> and its variants <ref type="bibr" target="#b15">[16]</ref> have been widely adopted in training machine learning models, including neural networks. Samples are drawn uniformly at random (IID) so that the stochastic gradient vector equals to the true gradient in expectation. In the setting where negative examples are overwhelming, such as in word embedding (e.g., Word2Vec <ref type="bibr" target="#b21">[22]</ref>) and network embedding (e.g., LINE <ref type="bibr" target="#b28">[29]</ref>) tasks, negative sampling is utilized. Recent efforts have been made to improve SGD convergence by (1) reducing the variance of stochastic gradient estimator, or (2) distributing the training over multiple workers. Several sampling techniques, such as stratified sampling <ref type="bibr" target="#b34">[35]</ref> and importance sampling <ref type="bibr" target="#b35">[36]</ref> are proposed to achieve the variance reduction. Different from their work, we improve sampling strategies in SGD by reducing the computational cost of a mini-batch while preserving, or even increasing, the number of data points in the mini-batch. Sampling techniques are also studied in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b38">39]</ref> to distribute the computation of matrix factorization, their objectives in sampling strategy design are reducing the parameter overlapping and cache miss. We also find that the idea of sharing negative examples is exploited to speed up word embedding training in <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSIONS</head><p>While it is discussed under content-based collaborative filtering problem in this work, the study of sampling strategies for "graphbased" loss functions have further implications. The IID sampling strategy is simple and popular for SGD-based training, since the loss function terms usually do not share the common computations. So no matter how a mini-batch is formed, it almost bears the same amount of computation. This assumption is shattered by models that are defined under graph structure, with applications in social and knowledge graph mining <ref type="bibr" target="#b1">[2]</ref>, image caption ranking <ref type="bibr" target="#b19">[20]</ref>, and so on. For those scenarios, we believe better sampling strategies can result in much faster training than that with IID sampling.</p><p>We would also like to point out limitations of our work. The first one is the setting of implicit feedback. When the problem is posed under explicit feedback, Negative Sharing can be less effective since the constructed negative samples may not overlap with the explicit negative ones. The second one is the assumption of efficient computation for interaction functions. When we use neural networks as interaction functions, we may need to consider constructing negative samples more wisely for Negative Sharing as it will also come with a noticeable cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS AND FUTURE WORK</head><p>In this work, we propose a hybrid recommendation framework, combining conventional collaborative filtering with (deep) neural networks. The framework generalizes several existing state-of-theart recommendation models, and embody potentially more powerful ones. To overcome the high computational cost brought by combining "cheap" CF with "expensive" NN, we first establish the connection between the loss functions and the user-item interaction bipartite graph, and then point out the computational costs can vary with different sampling strategies. Based on this insight, we propose three novel sampling strategies that can significantly improve the training efficiency of the proposed framework, as well as the recommendation performance.</p><p>In the future, there are some promising directions. Firstly, based on the efficient sampling techniques of this paper, we can more efficiently study different neural networks and auxiliary information for building hybrid recommendation models. Secondly, we can also study the effects of negative sampling distributions and its affect on the design of more efficient sampling strategies. Lastly but not least, it would also be interesting to apply our sampling strategies in a distributed training environments where multi-GPUs and multi-machines are considered.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The functional embedding framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Model training time per epoch with different types of item functions (in log-scale).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 2</head><label>2</label><figDesc>Negative Sampling<ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b28">29]</ref> Require: number of positive links in a mini-batch b, number of negative links per positive one: k draw b positive links uniformly at random for each of b positive links do draw k negative links by replacing true item v with v ′ ∝ P n (v ′ ) end for</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(a) Negative (b) Stratified (by Items) (c) Negative Sharing (d) Stratified with N.S.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Illustration of four different sampling strategies. 4(b)-4(d) are the proposed sampling strategies. Red lines denote positive links/interactions, and black lines denote negative links/interactions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm 4</head><label>4</label><figDesc>Negative SharingRequire: number of positive links in a mini-batch: b draw b positive user-item pairs {(u, v)} uniformly at random construct negative pairs by connecting non-linked users and items in the batch draw additional negative samples. Since the main computational cost of training is on the node computation and the node set is fixed given the batch of b positive links, we can share the nodes for negative links without increasing much of computational burdens. Based on this idea, Algorithm 4 summarizes an extremely simple sampling procedure, and it is illustrated in Figure4(c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Algorithm 5</head><label>5</label><figDesc>Stratified Sampling with Negative Sharing Require: number of positive links in a mini-batch: b, number of positive links per stratum: s repeat draw an item v ∝ P d (v) draw s positive users of item v uniformly at random until a mini-batch of b/s items are sampled construct negative pairs by connecting non-linked users and items in the batch Computationally, Stratified Sampling with Negative Sharing only involve b/s item nodes in a mini-batch, so it can provide the same s (1 + k ) times speedup over Negative Sampling as Stratified Sampling (by Items) does, but it will utilize much more negative links compared to Negative Sampling. For example, in our experiments with b = 512, s = 4, we have 127 negative links per positive one, much larger than k = 10 in Negative Sampling, and only requires 1/4 times of g(•) computations compared to Negative Sharing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Proposition 1 .</head><label>1</label><figDesc>(local convergence) Suppose L has σ -bounded gradient; let η t = η = c/ √ T where c = 2( L(θ 0 )−L(θ * ) Lσ 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Training loss curves (all methods have the same number of b positive samples in a mini-batch)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Test performance/recall curves (all methods have the same number of b positive samples in a mini-batch).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The number of positive links per stratum s VS loss and performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: The number of negatives VS performances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 3 :</head><label>3</label><figDesc>Comparisons of speedup for different sampling strategies against IID Sampling: per iteration, # of iteration, and total speedup.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>CiteULike</cell><cell></cell><cell></cell><cell>News</cell><cell></cell></row><row><cell cols="2">Model Sampling</cell><cell cols="6">Per it. # of it. Total Per it. # of it. Total</cell></row><row><cell></cell><cell>Negative</cell><cell>1.02</cell><cell>1.00</cell><cell>1.02</cell><cell>1.03</cell><cell>1.03</cell><cell>1.06</cell></row><row><cell></cell><cell>Stratified</cell><cell>8.83</cell><cell>0.97</cell><cell>8.56</cell><cell>6.40</cell><cell>0.97</cell><cell>6.20</cell></row><row><cell>CNN</cell><cell>N.S.</cell><cell>8.42</cell><cell>2.31</cell><cell>19.50</cell><cell>6.54</cell><cell>2.21</cell><cell>14.45</cell></row><row><cell></cell><cell cols="2">Strat. w. N.S. 15.53</cell><cell>1.87</cell><cell cols="2">29.12 11.49</cell><cell>2.17</cell><cell>24.98</cell></row><row><cell></cell><cell>Negative</cell><cell>0.99</cell><cell>0.96</cell><cell>0.95</cell><cell>1.0</cell><cell>1.25</cell><cell>1.25</cell></row><row><cell></cell><cell>Stratified</cell><cell>3.1</cell><cell>0.77</cell><cell>2.38</cell><cell>3.12</cell><cell>1.03</cell><cell>3.22</cell></row><row><cell>LSTM</cell><cell>N.S.</cell><cell>2.87</cell><cell>2.45</cell><cell>7.03</cell><cell>2.78</cell><cell>4.14</cell><cell>11.5</cell></row><row><cell></cell><cell>Strat. w. N.S.</cell><cell>3.4</cell><cell>2.22</cell><cell>7.57</cell><cell>3.13</cell><cell>3.32</cell><cell>10.41</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 4 :</head><label>4</label><figDesc>Recall@50 for different sampling strategies under different models and losses.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">CiteULike</cell><cell>News</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Model</cell><cell></cell><cell>Sampling</cell><cell cols="4">SG-loss MSE-loss Hinge-loss Log-loss SG-loss MSE-loss Hinge-loss Log-loss</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>IID</cell><cell>0.4746</cell><cell>0.4437</cell><cell>-</cell><cell>-</cell><cell>0.1091</cell><cell>0.0929</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Negative</cell><cell>0.4725</cell><cell>0.4408</cell><cell>0.4729</cell><cell>0.4796</cell><cell>0.1083</cell><cell>0.0956</cell><cell>0.1013</cell><cell>0.1009</cell></row><row><cell></cell><cell></cell><cell></cell><cell>CNN</cell><cell></cell><cell></cell><cell>Stratified</cell><cell>0.4761</cell><cell>0.4394</cell><cell>-</cell><cell>-</cell><cell>0.1090</cell><cell>0.0913</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Negative Sharing</cell><cell>0.4866</cell><cell>0.4423</cell><cell>0.4794</cell><cell>0.4769</cell><cell>0.1131</cell><cell>0.0968</cell><cell>0.0909</cell><cell>0.0932</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Stratified with N.S. 0.4890</cell><cell>0.4535</cell><cell>0.4790</cell><cell>0.4884</cell><cell>0.1196</cell><cell>0.1043</cell><cell>0.1059</cell><cell>0.1100</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>IID</cell><cell>0.4479</cell><cell>0.4718</cell><cell>-</cell><cell>-</cell><cell>0.0971</cell><cell>0.0998</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Negative</cell><cell>0.4371</cell><cell>0.4668</cell><cell>0.4321</cell><cell>0.4540</cell><cell>0.0977</cell><cell>0.0977</cell><cell>0.0718</cell><cell>0.0711</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">LSTM</cell><cell></cell><cell>Stratified</cell><cell>0.4344</cell><cell>0.4685</cell><cell>-</cell><cell>-</cell><cell>0.0966</cell><cell>0.0996</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Negative Sharing</cell><cell>0.4629</cell><cell>0.4839</cell><cell>0.4605</cell><cell>0.4674</cell><cell>0.1121</cell><cell>0.0982</cell><cell>0.0806</cell><cell>0.0862</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Stratified with N.S. 0.4742</cell><cell>0.4877</cell><cell>0.4703</cell><cell>0.4730</cell><cell>0.1051</cell><cell>0.1098</cell><cell>0.1017</cell><cell>0.1002</cell></row><row><cell></cell><cell>0.500</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.480</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Recall@50</cell><cell>0.400 0.420 0.440 0.460 0.380</cell><cell></cell><cell></cell><cell cols="3">Negative distribution uniform unigram</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.360</cell><cell>1</cell><cell>5</cell><cell>10</cell><cell>15</cell><cell>20</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="5">Number of negative examples k</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">(a) CiteULike</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">Draw a mini-batch of user-item triplets (u, v, v ′ ) if a pairwise loss function is adopted.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">This holds for both forward and backward computation. For the latter, the gradient from different links can be aggregated before back-propagating to g(•).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2">Unigram means proportional to item frequency, such as node degree in user-item interaction graph.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3">This can be done by first shuffling users associated with each item, and then concatenating all links according to items in random order, random strata is then formed by segmenting the list.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The authors would like to thank anonymous reviewers for helpful suggestions. The authors would also like to thank NVIDIA for the donation of one Titan X GPU. This work is partially supported by NSF CAREER #1741634.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ask the GRU: Multi-task Learning for Deep Text Recommendations</title>
		<author>
			<persName><forename type="first">Trapit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys&apos;16</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="107" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;13</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Large-scale machine learning with stochastic gradient descent</title>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COMPSTAT&apos;2010</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Joint Text Embedding for Personalized Content-based Recommendation</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liangjie</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXivpreprintarXiv:1706.01084</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Task-Guided and Path-Augmented Heterogeneous Network Embedding for Author Identification</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM&apos;17</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="295" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Entity Embedding-based Anomaly Detection for Heterogeneous Categorical Events</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu-An</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengzhang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI&apos;16</title>
				<meeting><address><addrLine>Miami</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">SVDFeature: a toolkit for feature-based collaborative filtering</title>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiuxia</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kailong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="3619" to="3622" />
			<date type="published" when="2012-12">2012. Dec (2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08">2011. Aug (2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Largescale matrix factorization with distributed stochastic gradient descent</title>
		<author>
			<persName><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannis</forename><surname>Sismanis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;11</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="69" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Stochastic first-and zeroth-order methods for nonconvex stochastic programming</title>
		<author>
			<persName><forename type="first">Saeed</forename><surname>Ghadimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanghui</forename><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2341" to="2368" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Content-based recommendations with poisson factorization</title>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Prem K Gopalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;14</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3176" to="3184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Collaborative filtering for implicit feedback datasets</title>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM&apos;08</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Shihao</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadathur</forename><surname>Satish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Dubey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.04661</idno>
		<title level="m">Parallelizing word2vec in shared and distributed memory</title>
				<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5882</idno>
		<title level="m">Convolutional neural networks for sentence classification</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Factorization meets the neighborhood: a multifaceted collaborative filtering model</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;08</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="426" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;12</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Leveraging visual question answering for imagecaption ranking</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV&apos;16</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="261" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m">Efficient estimation of word representations in vector space</title>
				<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><surname>Dean</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">One-class collaborative filtering</title>
		<author>
			<persName><forename type="first">Rong</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><forename type="middle">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajan</forename><surname>Lukose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Scholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM&apos;08</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="502" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Stochastic Variance Reduction for Nonconvex Optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sashank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suvrit</forename><surname>Hefny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barnabas</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Poczos</surname></persName>
		</author>
		<author>
			<persName><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;16</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="314" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Factorization machines</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM&apos;10</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="995" to="1000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">BPR: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI&apos;09</title>
				<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Probabilistic matrix factorization</title>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;11</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Relational learning via collective matrix factorization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ajit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;08</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="650" to="658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;15</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep content-based music recommendation</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Schrauwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;13</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2643" to="2651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Collaborative topic modeling for recommending scientific articles</title>
		<author>
			<persName><forename type="first">Chong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;11</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Collaborative deep learning for recommender systems</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;15</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1235" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Improving maximum margin matrix factorization</title>
		<author>
			<persName><forename type="first">Markus</forename><surname>Weimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="263" to="276" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Character-level convolutional networks for text classification</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;15</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="649" to="657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Accelerating minibatch stochastic gradient descent using stratified sampling</title>
		<author>
			<persName><forename type="first">Peilin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.3080</idno>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Stochastic Optimization with Importance Sampling for Regularized Loss Minimization</title>
		<author>
			<persName><forename type="first">Peilin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;15</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A Neural Autoregressive Approach to Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Yin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bangsheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenkui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanning</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;16</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="764" to="773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Functional matrix factorizations for cold-start recommendation</title>
		<author>
			<persName><forename type="first">Ke</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuang-Hong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;11</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="315" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">A fast parallel SGD for matrix factorization in shared memory systems</title>
		<author>
			<persName><forename type="first">Yong</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Sheng</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu-Chin</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
	<note>In Recsys</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
