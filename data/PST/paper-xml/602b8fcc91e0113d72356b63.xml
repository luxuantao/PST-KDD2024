<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Controllable Multi-Interest Framework for Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-08-03">3 Aug 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yukuo</forename><surname>Cen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ‡ DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianwei</forename><surname>Zhang</surname></persName>
							<email>zhangjianwei.zjw@alibaba-inc.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ‡ DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xu</forename><surname>Zou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ‡ DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ‡ DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
							<email>yang.yhx@alibaba-inc.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ‡ DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ‡ DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Controllable Multi-Interest Framework for Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-08-03">3 Aug 2020</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3394486.3403344</idno>
					<idno type="arXiv">arXiv:2005.09347v2[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>recommender system</term>
					<term>sequential recommendation</term>
					<term>multi-interest framework</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, neural networks have been widely used in e-commerce recommender systems, owing to the rapid development of deep learning. We formalize the recommender system as a sequential recommendation problem, intending to predict the next items that the user might be interacted with. Recent works usually give an overall embedding from a user's behavior sequence. However, a unified user embedding cannot reflect the user's multiple interests during a period. In this paper, we propose a novel controllable multi-interest framework for the sequential recommendation, called ComiRec. Our multi-interest module captures multiple interests from user behavior sequences, which can be exploited for retrieving candidate items from the large-scale item pool. These items are then fed into an aggregation module to obtain the overall recommendation. The aggregation module leverages a controllable factor to balance the recommendation accuracy and diversity. We conduct experiments for the sequential recommendation on two real-world datasets, Amazon and Taobao. Experimental results demonstrate that our framework achieves significant improvements over state-of-the-art models 1 . Our framework has also been successfully deployed on the offline Alibaba distributed cloud platform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>• Information systems → Recommender systems; • Computing methodologies → Neural networks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The development of e-commerce revolutionized our shopping styles in recent years. Recommender systems play a fundamental role in e-commerce companies. Traditional recommendation methods mainly use collaborative filtering methods <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref> to predict scores between users and items. Recently, neural networks have been widely used in e-commerce recommender systems, owing to the rapid development of deep learning. Neural recommender systems generate representations for users and items and outperform traditional recommendation methods. However, due to the large-scale e-commerce users and items, it is hard to use deep models to directly give the click-through rate (CTR) prediction between each pair of users and items. Current industrial practice is to use fast K nearest neighbors (e.g., Faiss <ref type="bibr" target="#b24">[25]</ref>) to generate the candidate items and then use a deep model (e.g., xDeepFM <ref type="bibr" target="#b32">[33]</ref>) to integrate the attributes of users and items to optimize the business metrics such as CTR.</p><p>Some recent works leverage graph embedding methods to obtain representations for users and items, which can be used for downstream applications. For example, PinSage <ref type="bibr" target="#b55">[56]</ref> builds on Graph-SAGE <ref type="bibr" target="#b14">[15]</ref> and has applied graph convolutional network based methods to production-scale data with billions of nodes and edges. GATNE <ref type="bibr" target="#b5">[6]</ref> considers different user behavior types and leverages a heterogeneous graph embedding method to learn representations for users and items. However, this kind of method ignores the sequential information in the user behaviors and cannot capture the correlations between adjacent user behaviors.</p><p>Recent researches <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b35">36</ref>] formalize the recommender system as a sequential recommendation problem. With a user's behavior history, the sequential recommendation task is to predict the next item he/she might be interested in. This task reflects the real-world recommendation situation. Many recent models can give an overall embedding for each user from his/her behavior sequence. However, a unified user embedding is hard to represent multiple interests. For example, in Figure <ref type="figure" target="#fig_0">1</ref>, the click sequence shows three different interests of Emma. As a modern girl, Emma is interested in jewelry, handbags, and make-ups. Therefore, she may click items of the three categories during this period of time.</p><p>In this paper, we propose a novel controllable multi-interest framework, called ComiRec. Our multi-interest module can capture the multiple interests of users, which can be exploited for retrieving candidate items. Our aggregation module combines these items from different interests and outputs the overall recommendation. Figure <ref type="figure" target="#fig_0">1</ref> shows a motivating example of our multi-interest framework. We conduct experiments for the sequential recommendation, which is similar to our online situation. The experimental results show that our framework outperforms other state-of-the-art models. Our framework has also been successfully deployed on the Alibaba distributed cloud platform. Results on the billion-scale industrial dataset further confirm the effectiveness and efficiency of our model in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Click</head><p>To summarize, the main contributions of this paper are:</p><p>• We propose a comprehensive framework that integrates the controllability and multi-interest components in a unified recommender system. • We investigate the role of controllability on personalized systems by implementing and studying in an online recommendation scenario. • Our framework achieves state-of-the-art performance on two real-world challenging datasets for the sequential recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we introduce the related literature about recommender systems and recommendation diversity, as well as capsule networks and the attention mechanism we used in the paper.</p><p>Collaborative filtering <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref> methods have been proven successful in real-world recommender systems, which find similar users and items and make recommendations on this basis. Matrix factorizaion <ref type="bibr" target="#b29">[30]</ref> is the most popular technique in classical recommender research, which maps both users and items to a joint latent factor space, such that user-item interactions are modeled as inner products in that space. Factorization Machines (FMs) <ref type="bibr" target="#b43">[44]</ref> model all interactions between variables using factorized parameters and thus can estimate interactions even in problems with huge sparsity like recommender systems.</p><p>Neural Recommender Systems. Neural Collaborative Filtering (NCF) <ref type="bibr" target="#b19">[20]</ref> uses a neural network architecture to model latent features of users and items. NFM <ref type="bibr" target="#b18">[19]</ref> seamlessly combines the linearity of FMs in modeling second-order feature interactions and the non-linearity of neural networks in modeling higher-order feature interactions. DeepFM <ref type="bibr" target="#b13">[14]</ref> designs an end-to-end learning model that emphasizes both low-order and high-order feature interactions for CTR prediction. xDeepFM <ref type="bibr" target="#b32">[33]</ref> extends DeepFM and can learn specific bounded-degree feature interactions explicitly. Deep Matrix Factorization (DMF) <ref type="bibr" target="#b54">[55]</ref> uses a deep structure learning architecture to learn a common low dimensional space for the representations of users and items based on explicit ratings and non-preference implicit feedback. DCN <ref type="bibr" target="#b52">[53]</ref> keeps the benefits of a deep model and introduces a novel cross network that is more efficient in learning specific bounded-degree feature interactions. CMN <ref type="bibr" target="#b11">[12]</ref> uses deep architecture to unify the two classes of CF models capitalizing on the strengths of the global structure of the latent factor model and local neighborhood-based structure in a nonlinear fashion.</p><p>Sequential Recommendation. The sequential recommendation is the crucial problem of recommender systems. Many recent works about recommender systems focus on this problem. FPMC <ref type="bibr" target="#b44">[45]</ref> subsumes both a common Markov chain and the normal matrix factorization model for sequential basket data. HRM <ref type="bibr" target="#b51">[52]</ref> extends the FPMC model and employs a two-layer structure to construct a hybrid representation over users and items from the last transaction. GRU4Rec <ref type="bibr" target="#b20">[21]</ref> first introduces an RNN-based approach to model the whole session for more accurate recommendations. DREAM <ref type="bibr" target="#b56">[57]</ref>, based on Recurrent Neural Network (RNN), learns a dynamic representation of a user for revealing the user's dynamic interests. Fossil <ref type="bibr" target="#b16">[17]</ref> integrates similarity-based methods with Markov Chains smoothly to make personalized sequential predictions on sparse and long-tailed datasets. TransRec <ref type="bibr" target="#b15">[16]</ref> embeds items into a vector space where users are modeled as vectors operating on item sequences for large-scale sequential prediction. RUM <ref type="bibr" target="#b6">[7]</ref> uses a memory-augmented neural network integrated with the insights of collaborative filtering for the recommendation. SASRec <ref type="bibr" target="#b26">[27]</ref> uses a self-attention based sequential model to capture long-term semantics and uses an attention mechanism to make its predictions based on relatively few actions. DIN <ref type="bibr" target="#b59">[60]</ref> designs a local activation unit to adaptively learn the representation of user interests from past behaviors with respect to a certain ad. SDM <ref type="bibr" target="#b35">[36]</ref> encodes behavior sequences with a multi-head self-attention module to capture multiple types of interests and a long-short term gated fusion module to incorporate long-term preferences.</p><p>Recommendation Diversity. Researchers have realized that following only the most accurate way of recommendation may not result in the best recommendation results, since the highest accuracy results tend to recommend similar items to users, yielding boring recommendation results <ref type="bibr" target="#b40">[41]</ref>. To address such problems, the diversity of the recommended items also plays a significant role <ref type="bibr" target="#b48">[49]</ref>. In terms of diversity, there is aggregated diversity <ref type="bibr" target="#b0">[1]</ref>, which refers to the ability to recommend "long-tail items" to users. Many studies focus on improving aggregated diversity of recommendation systems <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b42">43]</ref>. Other works focus on the diversity of items recommended to individual users, i.e., the individual diversity <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b57">58]</ref>, which refers to the dissimilarity of items recommended to an individual user.</p><p>Attention The originality of attention mechanism can be traced back to decades ago in fields of computer vision <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b49">50]</ref>. However, its popularity in various fields in machine learning comes only in recent years. It is first introduced to machine translation by <ref type="bibr" target="#b2">[3]</ref>, and later becomes an outbreaking method as tensor2tensor <ref type="bibr" target="#b50">[51]</ref>. BERT <ref type="bibr" target="#b9">[10]</ref> leverages tensor2tensor and achieves giant success in natural language processing. The attention mechanism is also adapted to recommender systems <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b58">59]</ref> and is rather useful on real-world recommendation tasks.</p><p>Capsule Network. The concept of "capsules" is first proposed by <ref type="bibr" target="#b21">[22]</ref> and has become well-known since the dynamic routing method <ref type="bibr" target="#b45">[46]</ref> is proposed. MIND <ref type="bibr" target="#b30">[31]</ref> introduces capsules into recommendation areas and uses the capsule network to capture multiple interests of e-commerce users based on dynamic routing mechanism, which is applicable for clustering past behaviors and extracting diverse interests. CARP <ref type="bibr" target="#b31">[32]</ref> firstly extracts the viewpoints and aspects from the user and item review documents and derives the representation of each logic unit based on its constituent viewpoint and aspect for rating prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>In this section, we formulate the problem and introduce the proposed framework in detail, as well as showing the difference between our framework and representative existing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Formulation</head><p>Assume we have a set of users u ∈ U and a set of items i ∈ I. For each user, we have a sequence of user historical behaviors (e (u)</p><formula xml:id="formula_0">1 , e (u) 2 , • • • , e (u) n ), sorted by time of the occurrence. e (u)</formula><p>t records the t t h item interacted by the user. Given historical interactions, the problem of sequential recommendation is to predict the next items that the user might be interacted with. Notations are summarized in Table <ref type="table" target="#tab_0">1</ref>.</p><p>In practice, due to the strict requirements of latency and performance, industrial recommender systems usually consist of two indicator function stages, the matching stage and the ranking stage. The matching stage corresponds to retrieving top-N candidate items, while the ranking stage is used for sorting the candidate items by more precise scores. Our paper mainly focuses on improving the effectiveness in the matching stage. In the following parts of this section, we will introduce our controllable multi-interest framework and illustrate the significance of our framework for the sequential recommendation problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multi-Interest Framework</head><p>As the item pools of industrial recommender systems usually consist of millions or even billions of items, the matching stage plays a crucial role in recommender systems. Specifically, the matching model first computes user embeddings from user historical behaviors and then retrieves a candidate set of items for each user based on the user embedding. With the help of fast K nearest neighbors (KNN) algorithm to select the closest items from the large-scale item pool to generate a candidate set for each user, we mainly focus on the computation of user embeddings. In other words, the decisive factor for the matching stage is the quality of user embeddings computed from user historical behaviors. Existing matching models usually use RNN <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b53">54]</ref> to compute embeddings for users, but most of them only generate a single embedding vector for each user. This suffers from the lack of expressiveness of a single embedding since real-world customers usually have several kinds of items in their minds and these items are often for different uses and vary a lot in categories. Such behaviors of real-world customers highlight the need to use multiple vectors to represent their multiple interests. Based on the observations, we propose a multi-interest framework for the sequential recommendation. The input of our framework is a user behavior sequence, which contains a list of item IDs representing the user's interactions with items in time order. The item IDs are fed into an embedding layer and transformed into item embeddings. A multiinterest extraction module receives item embeddings and generates multiple interests for each user.</p><p>To build a multi-interest extraction module, there are many optional methods. In this paper, we explore two methods, dynamic routing method and self-attentive method, as our multi-interest extraction module. Our framework using a dynamic routing method or self-attentive method is named as ComiRec-DR or ComiRec-SA, respectively.</p><p>Dynamic Routing. We utilize a dynamic routing method as a multi-interest extraction module for user behavior sequences. The item embeddings of the user sequence can be viewed as primary capsules, and the multiple user interests can be seen as interest capsules. We use the dynamic routing method from CapsNet <ref type="bibr" target="#b45">[46]</ref>. We briefly introduce dynamic routing for computing vector inputs and outputs of capsules. A capsule is a group of neurons whose activity vectors represent the instantiation parameters of a specific type of entity such as an object or an object part <ref type="bibr" target="#b45">[46]</ref>. The length of the output vector of a capsule represents the probability that the entity represented by the capsule is in the current input. Let e i be the capsule i of the primary layer. We then give the computation of the capsule j of the next layer based on primary capsules. We first compute the prediction vector as</p><formula xml:id="formula_1">êj |i = W i j e i ,<label>(1)</label></formula><p>where W i j is a transformation matrix. Then the total input to the capsule j is the weighted sum over all prediction vectors êj |i as</p><formula xml:id="formula_2">s j = i c i j êj |i ,<label>(2)</label></formula><p>where c i j are the coupling coefficients that are determined by the iterative dynamic routing process. The coupling coefficients between capsule i and all the capsules in the next layer should sum to 1. We use "routing softmax" to calculate the coupling coefficients using initial logits b i j as</p><formula xml:id="formula_3">c i j = exp(b i j ) k exp(b ik ) ,<label>(3)</label></formula><p>where b i j represents the log prior probability that capsule i should be coupled to capsule j. A non-linear "squashing" function <ref type="bibr" target="#b45">[46]</ref> is proposed to ensure short vectors to get shrunk to almost zero length and long vectors to get shrunk to a length slightly below 1.</p><p>Then the vector of of capsule j is computed by</p><formula xml:id="formula_4">v j = squash(s j ) = ∥s j ∥ 2 1 + ∥s j ∥ 2 s j ∥s j ∥ ,<label>(4)</label></formula><p>where s j is the total input of capsule j. To calculate the output capsules v j , we need to calculate the probability distribution based on the inner production of v j and e i . The calculation of v j relies on itself; thus, dynamic routing method is proposed to solve this problem. The whole dynamic routing process is listed in Algorithm 1.</p><p>The output interest capsules of the user u are then formed as a matrix</p><formula xml:id="formula_5">V u = [v 1 , ..., v K ] ∈ R d ×K for downstream tasks.</formula><p>Algorithm 1: Dynamic Routing Input: primary capsules e i , iteration times r , number of interest capsules K Output: interest capsules {v j , j = 1, ..., K } 1 for each primary capsule i and interest capsule j: initialize b i j = 0.</p><formula xml:id="formula_6">2 for iter = 1, • • • , r do 3</formula><p>for each primary capsule i:</p><formula xml:id="formula_7">c i = softmax(b i ).</formula><p>4</p><p>for each interest capsule j: s j = i c i j W i j e i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5</head><p>for each interest capsule j: v j = squash(s j ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6</head><p>for each primary capsule i and interest capsule j:</p><formula xml:id="formula_8">b i j = b i j + v ⊤ j W i j e i .</formula><p>7 return {v j , j = 1, ..., K }</p><p>Self-Attentive Method. The self-attentive method <ref type="bibr" target="#b34">[35]</ref> can also be applied to our multi-interest extraction module. Given the embeddings of user behaviors, H ∈ R d ×n , where n is the length of the user sequence, we use the self-attention mechanism to obtain a vector of weights a ∈ R n :</p><formula xml:id="formula_9">a = softmax(w ⊤ 2 tanh(W 1 H)) ⊤ ,<label>(5)</label></formula><p>where w 2 and W 1 are trainable parameters with size d a and d a × d, respectively. The superscript ⊤ denotes the transpose of the vector or the matrix. The vector a with size n represents the attention weight of user behaviors. When we sum up the embeddings of user behaviors according to the attention weight, we can obtain a vector representation v u = Ha for the user. For the self-attentive method to make use of the order of user sequences, we add trainable positional embeddings <ref type="bibr" target="#b50">[51]</ref> to the input embeddings. The positional embeddings have the same dimension d as the item embeddings and the two can be directly summed. This vector representation focuses on and reflects a specific interest of the user u. To represent the overall interests of the user, we need multiple v u from the user behaviors that focus on different interests. Thus we need to perform multiple times of attention. We extend the w 2 into a d a -by-K matrix as W 2 . Then the attention vector a becomes an attention matrix A as</p><formula xml:id="formula_10">A = softmax(W ⊤ 2 tanh(W 1 H)) ⊤ .<label>(6)</label></formula><p>The final matrix of user interests V u can be computed by</p><formula xml:id="formula_11">V u = HA.<label>(7)</label></formula><p>Model Training. After computing the interest embeddings from user behaviors through the multi-interest extraction module, we use an argmax operator to choose a corresponding user embedding vector for a target item i:</p><formula xml:id="formula_12">v u = V u [:, argmax(V ⊤ u e i )],<label>(8)</label></formula><p>where e i denotes the embedding of the target item i, and V u is the matrix formed by user interest embeddings. Given a training sample (u, i) with the user embedding v u and the item embedding e i , we can compute the likelihood of the user u interacting with the item i as Algorithm 2: Greedy Inference Input: Candidate item set M, number of output items N Output:</p><formula xml:id="formula_13">Output item set S 1 S = 2 for iter = 1, • • • , N do 3 j = argmax i ∈M\S f (u, i) + λ k ∈S д(i, k) 4 S = S ∪ {j} 5 return S P θ (i |u) = exp(v ⊤ u e i ) k ∈I exp(v ⊤ u e k ) .<label>(9)</label></formula><p>The objective function of our model is to minimize the following negative log-likelihood</p><formula xml:id="formula_14">loss = u ∈U i ∈I u − log P θ (i |u).<label>(10)</label></formula><p>The sum operator of equation ( <ref type="formula" target="#formula_13">9</ref>) is computationally expensive; thus, we use a sampled softmax technique <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b23">24]</ref> to train our model.</p><p>Online Serving. For online serving, we use our multi-interest extraction module to compute multiple interests for each user. Each interest vector of a user can independently retrieve top-N items from the large-scale item pool by the nearest neighbor library such as Faiss <ref type="bibr" target="#b24">[25]</ref>. The items retrieved by multiple interests are fed into an aggregation module to determine the overall item candidates. Finally, the items with higher ranking scores will be recommended for users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Aggregation Module</head><p>After the multi-interest extraction module, we obtain multiple interest embeddings for each user based on his/her past behavior. Each interest embedding can independently retrieve top-N items based on the inner production proximity. But how to aggregate these items from different interests to obtain the overall top-N items? A basic and straightforward way is to merge and filter the items based on their inner production proximity with user interests, which can be formalized as</p><formula xml:id="formula_15">f (u, i) = max 1≤k ≤K (e ⊤ i v (k ) u ),<label>(11)</label></formula><p>where v</p><formula xml:id="formula_16">(k )</formula><p>u is the k-th interest embedding of the user u. This is an effective method for the aggregation process to maximize the recommendation accuracy. However, it is not all about the accuracy of current recommender systems. People are more likely to be recommended with something new or something diverse. The problem can be formulated in the following. Given a set M with K • N items retrieved from K interests of a user u, find a set S with N items such that a pre-defined value function is maximized. Our framework uses a controllable procedure to solve this problem. We use the following value function Q(u, S) to balance the accuracy and diversity of the recommendation by a controllable factor λ ≥ 0, Here д(i, j) is a diversity or dissimilarity function such as</p><formula xml:id="formula_17">Q(u, S) = i ∈S f (u, i) + λ i ∈S j ∈S д(i, j). (<label>12</label></formula><formula xml:id="formula_18">)</formula><formula xml:id="formula_19">д(i, j) = δ (CATE(i) CATE(j)). (<label>13</label></formula><formula xml:id="formula_20">)</formula><p>where CATE(i) means the category of item i and δ (•) is an indicator function. For the most accurate case, i.e., λ = 0, we just use the above straightforward method to obtain the overall items. For the most diverse case, i.e., λ = ∞, the controllable module finds the most diverse items for users. We study the controllable factor in the Section 4.3. We propose a greedy inference algorithm to approximately maximize the value function Q(u, S), which is listed in the Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Connections with Existing Models</head><p>We make a comparison between our model and existing models.</p><p>MIMN. MIMN <ref type="bibr" target="#b41">[42]</ref>, a recent representative work for the ranking stage of recommendation, uses memory networks to capture user interests from long sequential behavior data. Both MIMN and our model target at the multiple interests of users. For very long sequential behaviors, a memory-based architecture may also be insufficient to capture the long-term interests of users. Compared with MIMN, our model utilizes the multi-interest extraction module to leverage multiple interests of users instead of a complicated memory network with memory utilization regularization and memory induction unit.</p><p>MIND. MIND <ref type="bibr" target="#b30">[31]</ref>, a recent representative work for the matching stage of recommendation, proposes a Behavior-to-Interest (B2I) dynamic routing for adaptively aggregating user's behaviors into interest representation vectors. Compared with MIND, ComiRec-DR follows the original dynamic routing method used by CapsNet <ref type="bibr" target="#b45">[46]</ref>, which can capture the sequential information of user behaviors.</p><p>Our framework also explores a self-attentive method for multiinterest extraction. Moreover, our framework utilizes a controllable aggregation module to balance the recommendation accuracy and diversity based on users' multiple interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we experiment on the sequential recommendation to evaluate the performance of our framework compared with other state-of-the-art methods. Besides, we also report the experimental results of our framework on a billion-scale industrial dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>We evaluate the performance of all methods under strong generalization <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38]</ref>: We split all users into training/validation/test sets by the proportion of 8:1:1. We train models using the entire click sequences of training users. To evaluate, we take the first 80% of the user behaviors from validation and test users to infer user embeddings from trained models and compute metrics by predicting the remaining 20% user behaviors. This setting is more difficult than weak generalization where the users' behavior sequences are used during both training and evaluation processes <ref type="bibr" target="#b33">[34]</ref>. In detail, we adopt a common setting of training sequential recommendation models.</p><p>Let the behavior sequence of user u be (</p><p>n ). Each training sample uses the first k behaviors of u to predict the (k + 1)-th behavior, where k = 1, 2, ..., (n − 1).</p><p>Datasets. We conduct experiments on two challenging public datasets. The statistics of the two datasets are shown in Table <ref type="table" target="#tab_2">2</ref>.</p><p>• Amazon<ref type="foot" target="#foot_0">2</ref> consists of product reviews and metadata from Amazon <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b38">39]</ref>. In our experiment, we use the Books category of the Amazon dataset. Each training sample is truncated at length 20. • Taobao<ref type="foot" target="#foot_1">3</ref> collects user behaviors from Taobao's recommender systems <ref type="bibr" target="#b60">[61]</ref>. In our experiment, we only use the click behaviors and sort the behaviors from one user by time. Each training sample is truncated at length 50.</p><p>Competitors. We compare our proposed models, ComiRec-SA and ComiRec-DR, with state-of-the-art models. In our experimental setting, models should give the prediction for the unseen users of validation and test sets. Thus factorization-based methods are inappropriate for this setting.</p><p>• MostPopular is a traditional recommendation method that recommends the most popular items to users. • YouTube DNN <ref type="bibr" target="#b8">[9]</ref> is one of the most successful deep learning models for industrial recommender systems. • GRU4Rec <ref type="bibr" target="#b20">[21]</ref> is the first work that introduces recurrent neural networks for the recommendation. • MIND <ref type="bibr" target="#b30">[31]</ref> is a recent state-of-the-art model related with our model. It designs a multi-interest extractor layer based on the capsule routing mechanism, which is applicable for clustering past behaviors and extracting diverse interests.</p><p>Implementation Notes. The code used by our experiments is implemented with TensorFlow<ref type="foot" target="#foot_2">4</ref> 1.14 in Python 3.6.</p><p>Parameter Configuration. The number of dimensions d for embeddings is set to 64. The number of samples for sampled softmax loss is set to 10. The number of maximum training iterations is set to 1 million. The number of interest embeddings for multi-interest models is set to 4. We use Adam optimizer <ref type="bibr" target="#b28">[29]</ref> with learning rate lr = 0.001 for optimization.</p><p>Evaluation Metrics. We use the following metrics to evaluate the performance of our proposed model. We use three commonly used evaluation criteria in our experiments.</p><p>• Recall. We adopt per-user average instead of global average for better interpretability <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b27">28]</ref>. where Îu, N denotes the set of top-N recommended items for user u and I u is the set of testing items for user u. • Hit Rate. Hit rate (HR) measures the percentage that recommended items contain at least one correct item interacted by the user, which has been widely used in previous works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b27">28]</ref>.</p><formula xml:id="formula_22">Recall@N = 1 |U| u ∈U | Îu, N ∩ I u | |I u | ,<label>(14)</label></formula><formula xml:id="formula_23">HR@N = 1 |U| u ∈U δ (| Îu, N ∩ I u | &gt; 0),<label>(15)</label></formula><p>where δ (•) is the indicator function. • Normalized Discounted Cumulative Gain. Normalized Discounted Cumulative Gain (NDCG) takes the positions of correct recommended items into consideration <ref type="bibr" target="#b22">[23]</ref>.</p><formula xml:id="formula_24">NDCG@N = 1 Z DCG@N = 1 Z 1 |U| u ∈U N k =1 δ ( îu,k ∈ I u ) log 2 (k + 1) ,<label>(16)</label></formula><p>where îu,k denotes the k-th recommended item for the user u, and Z is a normalization constant denoting the ideal discounted cumulative gain (IDCG@N), which is the maximum possible value of DCG@N.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Quantitative Results</head><p>To make a fair comparison with other models, we set λ = 0 in our aggregation module. We give a detailed illustration of retrieving top-N items of our framework. For our framework, each interest of a user independently retrieves top-N candidate items. Thus, our model retrieves a total of K •N items for each user. We sort the items by the inner product of the item embedding and the corresponding interest embedding. After the sorting, top-N items from these K • N items are viewed as the final candidate items of our model. The way of retrieving candidate items is also applied to MIND. The model performance for the sequential recommendation is shown in Table <ref type="table" target="#tab_3">3</ref>. Our models outperform all state-of-the-art models by a wide margin on all the evaluation criteria. GRU4Rec obtains the best performance over other models that only output single embedding for each user. Compared with MIND, ComiRec-DR obtains better performance due to the difference of the dynamic routing method. ComiRec-SA shows the strong ability to capture user interests by the self-attention mechanism and gets comparable results with ComiRec-DR. Parameter Sensitivity. We investigate the sensitivity of the number of interests K of our framework. Table <ref type="table" target="#tab_4">4</ref> illustrates the performance of our framework when the hyperparameter K changes. Our two models show the different properties of this hyperparameter. For the Amazon dataset, ComiRec-SA obtains the better performance when K = 2, 6 and ComiRec-DR gets the best result when K = 4. For the Taobao dataset, ComiRec-DR gets better performance when K increases from 2 to 8 but ComiRec-SA obtains the best result when K = 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Controllable Study</head><p>To obtain the final top-N candidate items for each user, we propose a novel module to aggregate the items retrieved by different interests of each user. In addition to aim at achieving high prediction accuracy for the recommendation, some studies suggest the need for diversified recommendations to avoid monotony and improve customers' experience <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13]</ref>.</p><p>Recommendation diversity plays a more important role in current recommender systems. Many pieces of research target on improving the recommendation diversity <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b42">43]</ref>. Our proposed aggregation module can control the balance of recommendation accuracy and diversity. We use the following definition of individual diversity based on item categories:</p><formula xml:id="formula_25">Diversity@N = N j=1 N k =j+1 δ (CATE( îu, j ) CATE( îu,k )) N × (N − 1)/2 ,<label>(17)</label></formula><p>where CATE(i) is the category of item i, îu, j denotes the j-th recommended item for the user u, and δ (•) is an indicator function.</p><p>Table <ref type="table" target="#tab_5">5</ref> shows the model performance of the Amazon dataset when we control the factor λ to balance the recommendation quality and diversity. From the table, recommendation diversity increases substantially and recall decreases slightly when the controllable factor λ increases. Our aggregation module can achieve the optimum trade-off between the accuracy and diversity by choosing an appropriate value for the hyperparameter λ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Industrial Results</head><p>We further experiment on the industrial dataset collected by Mobile Taobao App on February 8th, 2020. The statistics of the industrial dataset are shown in the Table <ref type="table" target="#tab_6">6</ref>. The industrial dataset contains 22 million high-quality items, 145 million users, and 4 billion behaviors between them.</p><p>Our framework has been deployed on the Alibaba distributed cloud platform, where every two workers share an NVIDIA Tesla P100 GPU with 16GB memory. We split the users and use the click sequences of training users to train our model. To evaluate, we use our model to compute multiple interests for each user in the test set. Each interest vector of a user independently retrieves top-N items from the large-scale item pool by a fast nearest neighbor method. The items retrieved by different user interests are fed into our aggregation module. After this module, top-N items out of K • N items are the final candidate items and are used to compute the evaluation metric, recall@50.</p><p>We conduct an offline experiment between our framework and the state-of-the-art sequential recommendation method, MIND <ref type="bibr" target="#b30">[31]</ref>, which has shown significant improvement in the recommender system of Alibaba Group. The experimental result demonstrates that our ComiRec-SA and ComiRec-DR improve recall@50 by 1.39% and 8.65% compared with MIND, respectively.</p><p>Case Study. From the Figure <ref type="figure" target="#fig_2">3</ref>, we can see that our model learns four different interests of the user from her click sequence. It is worth noting that our model only uses item IDs for training and does not use the manually defined category information of items.  Despite that, our model still can learn the item categories from user behavior sequences. Each interest learned by our model approximately corresponds to one specific category and can retrieve similar items of the same category from the large-scale industrial item pool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we propose a novel controllable multi-interest framework for the sequential recommendation. Our framework uses a multi-interest extraction module to generate multiple user interests and uses an aggregation module to obtain the overall top-N items.</p><p>Experimental results demonstrate that our models can achieve significant improvements over start-of-the-art models on two challenging datasets. Our framework has also been successfully deployed on the Alibaba distributed cloud platform. Results on the billion-scale industrial dataset further confirm the effectiveness and efficiency of our framework in practice. Recommender systems start a new phase owing to the rapid development of deep learning. Traditional recommendation methods cannot meet the requirements of the industry. For the future, we plan to leverage memory networks to capture the evolving interests of users and introduce cognitive theory to make better user modeling.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A motivating example of our proposed framework. An e-commerce platform user, Emma, has multiple interests including jewelry, handbags, and make-ups. Our multi-interest extraction module can capture these three interests from her click sequence. Each interest retrieves items from the large-scale item pool based on the interest embedding independently. An aggregation module combines items from different interests and outputs the overall top-N recommended items for Emma.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: A case study of an e-commerce user. We generate four interest embeddings from the click sequence of a user by our model. We find that the four interests of the user are about sweets, gift boxes, phone cases, and accessories. We report those items in the click sequence that correspond to the four interests. The right part shows the items retrieved from the industrial item pool by interest embeddings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Notations.</figDesc><table><row><cell cols="2">Notation Description</cell></row><row><cell>u</cell><cell>a user</cell></row><row><cell>i</cell><cell>an item</cell></row><row><cell>e</cell><cell>an interaction</cell></row><row><cell>U</cell><cell>the set of users</cell></row><row><cell>I</cell><cell>the set of items</cell></row><row><cell>I u</cell><cell>the set of testing items of user u</cell></row><row><cell>d</cell><cell>the dimension of user/item embeddings</cell></row><row><cell>K</cell><cell>the number of interest embeddings</cell></row><row><cell>N</cell><cell>the number of candidate items</cell></row><row><cell>V u</cell><cell>the matrix of interest embeddings of user u</cell></row><row><cell>δ (•)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Statistics of datasets.</figDesc><table><row><cell>Dataset</cell><cell># users</cell><cell># items</cell><cell># interactions</cell></row><row><cell cols="3">Amazon Books 459,133 313,966</cell><cell>8,898,041</cell></row><row><cell>Taobao</cell><cell cols="2">976,779 1,708,530</cell><cell>85,384,110</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Model performance on public datasets. Bolded numbers are the best performance of each column. All the numbers in the table are percentage numbers with '%' omitted.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Amazon Books</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Taobao</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Metrics@20</cell><cell></cell><cell cols="2">Metrics@50</cell><cell></cell><cell cols="2">Metrics@20</cell><cell></cell><cell>Metrics@50</cell><cell></cell></row><row><cell></cell><cell cols="12">Recall NDCG Hit Rate Recall NDCG Hit Rate Recall NDCG Hit Rate Recall NDCG Hit Rate</cell></row><row><cell>MostPopular</cell><cell>1.368</cell><cell>2.259</cell><cell>3.020</cell><cell>2.400</cell><cell>3.936</cell><cell>5.226</cell><cell>0.395</cell><cell>2.065</cell><cell>5.424</cell><cell>0.735</cell><cell>3.603</cell><cell>9.309</cell></row><row><cell cols="2">YouTube DNN 4.567</cell><cell>7.670</cell><cell>10.285</cell><cell cols="2">7.312 12.075</cell><cell>15.894</cell><cell cols="2">4.205 14.511</cell><cell>28.785</cell><cell cols="2">6.172 20.248</cell><cell>39.108</cell></row><row><cell>GRU4Rec</cell><cell>4.057</cell><cell>6.803</cell><cell>8.945</cell><cell cols="2">6.501 10.369</cell><cell>13.666</cell><cell cols="2">5.884 22.095</cell><cell>35.745</cell><cell cols="2">8.494 29.396</cell><cell>46.068</cell></row><row><cell>MIND</cell><cell>4.862</cell><cell>7.933</cell><cell>10.618</cell><cell cols="2">7.638 12.230</cell><cell>16.145</cell><cell cols="2">6.281 20.394</cell><cell>38.119</cell><cell cols="2">8.155 25.069</cell><cell>45.846</cell></row><row><cell>ComiRec-SA</cell><cell>5.489</cell><cell>8.991</cell><cell>11.402</cell><cell cols="2">8.467 13.563</cell><cell>17.202</cell><cell cols="2">6.900 24.682</cell><cell>41.549</cell><cell cols="2">9.462 31.278</cell><cell>51.064</cell></row><row><cell>ComiRec-DR</cell><cell>5.311</cell><cell>9.185</cell><cell>12.005</cell><cell cols="2">8.106 13.520</cell><cell>17.583</cell><cell cols="2">6.890 24.007</cell><cell cols="4">41.746 9.818 31.365 52.418</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Model performance of parameter sensitivity. All the numbers are percentage numbers with '%' omitted.</figDesc><table><row><cell></cell><cell>Amazon Books</cell><cell cols="2">Taobao</cell></row><row><cell>Metric@50</cell><cell cols="3">Recall NDCG Recall NDCG</cell></row><row><cell cols="2">ComiRec-SA (K=2) 8.835 14.273</cell><cell>9.935</cell><cell>32.873</cell></row><row><cell cols="2">ComiRec-SA (K=4) 8.467 13.563</cell><cell>9.462</cell><cell>31.278</cell></row><row><cell cols="2">ComiRec-SA (K=6) 8.901 14.167</cell><cell>9.378</cell><cell>31.020</cell></row><row><cell cols="2">ComiRec-SA (K=8) 8.547 13.631</cell><cell>9.493</cell><cell>31.196</cell></row><row><cell cols="2">ComiRec-DR (K=2) 7.081 12.068</cell><cell>9.293</cell><cell>30.735</cell></row><row><cell cols="2">ComiRec-DR (K=4) 8.106 13.520</cell><cell>9.818</cell><cell>31.365</cell></row><row><cell cols="4">ComiRec-DR (K=6) 7.904 13.219 10.836 34.048</cell></row><row><cell cols="4">ComiRec-DR (K=8) 7.760 12.900 10.841 33.895</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Model performance of Amazon dataset for the controllable study. All the numbers are percentage numbers with '%' omitted.</figDesc><table><row><cell></cell><cell cols="4">ComiRec-SA (K=4) ComiRec-DR (K=4)</cell></row><row><cell cols="5">Metric@50 Recall Diversity Recall Diversity</cell></row><row><cell>λ = 0.00</cell><cell>8.467</cell><cell>23.237</cell><cell>8.106</cell><cell>19.036</cell></row><row><cell>λ = 0.05</cell><cell>8.347</cell><cell>38.808</cell><cell>7.931</cell><cell>42.915</cell></row><row><cell>λ = 0.10</cell><cell>8.229</cell><cell>46.731</cell><cell>7.850</cell><cell>46.258</cell></row><row><cell>λ = 0.15</cell><cell>8.142</cell><cell>51.135</cell><cell>7.820</cell><cell>46.912</cell></row><row><cell>λ = 0.20</cell><cell>8.086</cell><cell>53.671</cell><cell>7.783</cell><cell>47.581</cell></row><row><cell>λ = 0.25</cell><cell>8.034</cell><cell>55.100</cell><cell>7.764</cell><cell>48.375</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Statistics of the industrial dataset</figDesc><table><row><cell>Dataset</cell><cell># users</cell><cell># items</cell><cell># interactions</cell></row><row><cell cols="4">Industrial 145,606,322 22,554,170 4,322,505,616</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">http://jmcauley.ucsd.edu/data/amazon/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">https://tianchi.aliyun.com/dataset/dataDetail?dataId=649&amp;userId=1</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2">https://www.tensorflow.org/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The work is supported by the NSFC for Distinguished Young Scholar (61825602), NSFC (61836013), and a research fund supported by Alibaba Group.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX</head><p>In the appendix, we give the implementation notes of our proposed models. The details of other models and descriptions of datasets are then given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Implementation Notes</head><p>Running Environment. The experiments in this paper can be divided into two parts. One is conducted on two public datasets using a single Linux server with 4 Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz, 256G RAM, and 8 NVIDIA GeForce RTX 2080 Ti. The codes of our proposed models in this part are implemented with TensorFlow 5 1.14 in Python 3.6. The other part is conducted on the industrial dataset using Alibaba's distributed cloud platform 6  which contains thousands of workers. Every two workers share an NVIDIA Tesla P100 GPU with 16GB memory. Our proposed models are implemented with TensorFlow 1.4 in Python 2.7 in this part.</p><p>Implementation Details. Our codes used by a single Linux server can be split into three parts: data iterator, model training, and evaluation. For each training iteration, the data iterator selects random training users with a size of batch_size. For each selected user, we randomly select an item in his/her click sequence as the training label and use the items before that item as the training sequence. The training part is implemented following the training loop in the Algorithm 3 based on the Tensorflow 1.x APIs. Our loss function is based on tf.nn.sampled_softmax_loss. The evaluation part replies on Faiss 7 , a library for efficient similarity search and clustering of dense vectors. We use the GpuIndexFlatIP class of Faiss, which implements an exact search for the inner product on GPU. All model parameters are updated and optimized by stochastic gradient descent with Adam updating rule <ref type="bibr" target="#b28">[29]</ref>. The distributed version of our proposed models is implemented based on the coding rules of Alibaba's distributed cloud platform in order to maximize the distribution efficiency.</p><p>Parameter Configuration. Our user/item embedding dimension d is set to 64. The number of samples for sampled softmax loss is set to 10. The number of maximum training iterations is set to 1 million and all models use early stopping based on the Recall@50 on the validation set. The batch size for the Amazon dataset and Taobao dataset is set to 128 and 256, respectively. The number of iterations for the dynamic routing method is set to 3. The number of interest embeddings K for multi-interest models is set to 4 for a fair comparison. We use the Adam optimizer <ref type="bibr" target="#b28">[29]</ref> with learning rate lr = 0.001 for optimization.</p><p>Code and Dataset Releasing Details. The code of all models and our partition of the two public datasets are available 8 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Compared Methods</head><p>We give the implementation details about all compared methods as follows. 5    Compute sampled softmax loss using Equation <ref type="bibr" target="#b9">(10)</ref>. Update model parameters by the Adam optimizer.</p><p>• MostPopular is a non-personalized method that recommends the most popular items to users. This method does not need training and we implement it separately. • YouTube DNN is one of the most successful deep learning models for industrial recommender systems. We implement the model in our code based on the original paper. • GRU4REC is the first work that introduces recurrent neural networks for the recommendation. We implement the model by tf.nn.rnn_cell.GRUCell and tf.nn.dynamic_rnn of TensorFlow in our code. • MIND is a recent state-of-the-art model. We implement the model based on the original paper and an internal version of the code in Alibaba Group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Datasets</head><p>Our experiments evaluate on three datasets, including two public datasets and a billion-scale industrial dataset. For the two public datasets, we keep users and items with at least 5 behaviors.</p><p>• Amazon 9 consists of product reviews and metadata from Amazon <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b38">39]</ref>. In our experiment, we use the Books category of the Amazon dataset. For each user u, we sort the reviews from the user by time, and our task is to predict whether the user will write the review for the item based on previous reviews. Each training sample is truncated at length 20. • Taobao 10 collects user behaviors from Taobao's recommender systems <ref type="bibr" target="#b60">[61]</ref>. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Improving aggregate recommendation diversity using ranking-based techniques</title>
		<author>
			<persName><forename type="first">Gediminas</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngok</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="896" to="911" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An integrated recommender system for improved accuracy and aggregate diversity</title>
		<author>
			<persName><forename type="first">Sujoy</forename><surname>Bag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhijeet</forename><surname>Ghadge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manoj</forename><forename type="middle">Kumar</forename><surname>Tiwari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Industrial Engineering</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="page" from="187" to="197" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Improving recommendation diversity</title>
		<author>
			<persName><forename type="first">Keith</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Smyth</surname></persName>
		</author>
		<editor>AICS&apos;01. Citeseer</editor>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="85" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Attention mechanisms for vision in a dynamic world</title>
		<author>
			<persName><forename type="first">Burt</forename><surname>Peter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR&apos;88. IEEE</title>
				<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="977" to="987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Representation learning for attributed multiplex heterogeneous network</title>
		<author>
			<persName><forename type="first">Yukuo</forename><surname>Cen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;19</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1358" to="1368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sequential recommendation with user memory networks</title>
		<author>
			<persName><forename type="first">Hongteng</forename><surname>Xu Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM&apos;18</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="108" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning to recommend accurate and diverse items</title>
		<author>
			<persName><forename type="first">Peizhe</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuaiqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiankai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;17</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep neural networks for youtube recommendations</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Sargin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys&apos;16</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="191" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">An analysis of users&apos; propensity toward diversity in recommendations</title>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Di Noia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Vito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Ostuni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Rosati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugenio</forename><forename type="middle">Di</forename><surname>Tomeo</surname></persName>
		</author>
		<author>
			<persName><surname>Sciascio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="285" to="288" />
		</imprint>
	</monogr>
	<note>In RecSys&apos;14</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Collaborative memory network for recommendation systems</title>
		<author>
			<persName><forename type="first">Travis</forename><surname>Ebesu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;18</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="515" to="524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Balancing accuracy and diversity in recommendations using matrix completion framework</title>
		<author>
			<persName><forename type="first">Anupriya</forename><surname>Gogna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angshul</forename><surname>Majumdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="83" to="95" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">DeepFM: a factorization-machine based neural network for CTR prediction</title>
		<author>
			<persName><forename type="first">Huifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
		<idno>IJCAI&apos;17</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;17</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Translation-based recommendation</title>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys&apos;17</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="161" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fusing similarity models with markov chains for sparse sequential recommendation</title>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM&apos;16</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering</title>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;16. International World Wide Web Conferences Steering Committee</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="507" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural factorization machines for sparse predictive analytics</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;17</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="355" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;17. International World Wide Web Conferences Steering Committee</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Session-based recommendations with recurrent neural networks</title>
		<author>
			<persName><forename type="first">Balázs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linas</forename><surname>Baltrunas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domonkos</forename><surname>Tikk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>In ICLR&apos;16</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Transforming auto-encoders</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sida D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICANN&apos;11</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">IR evaluation methods for retrieving highly relevant documents</title>
		<author>
			<persName><forename type="first">Kalervo</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaana</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;00</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">On using very large target vocabulary for neural machine translation. ACL&apos;15</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hervé</forename><surname>Jégou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08734</idno>
		<title level="m">Billion-scale similarity search with GPUs</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Recommendation system based on statistical analysis of ranking from user</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kalaivanan</surname></persName>
		</author>
		<author>
			<persName><surname>Vengatesan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICICES&apos;13. IEEE</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="479" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Self-attentive sequential recommendation</title>
		<author>
			<persName><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM&apos;18. IEEE</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evaluation of item-based top-n recommendation algorithms</title>
		<author>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM&apos;01</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="247" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Chao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengmeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pipei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiwei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dik</forename><surname>Lun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1904.08030</idno>
		<title level="m">Multi-Interest Network with Dynamic Routing for Recommendation at Tmall</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A Capsule Network for Recommendation and Explaining What You Like and Dislike</title>
		<author>
			<persName><forename type="first">Chenliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunwei</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuming</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Libing</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;19</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="275" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">xDeepFM: Combining explicit and implicit feature interactions for recommender systems</title>
		<author>
			<persName><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongxia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangzhong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;18</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1754" to="1763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Variational autoencoders for collaborative filtering</title>
		<author>
			<persName><forename type="first">Dawen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">D</forename><surname>Rahul G Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><surname>Jebara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;18</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="689" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">A structured self-attentive sentence embedding</title>
		<author>
			<persName><forename type="first">Zhouhan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cicero</forename><surname>Nogueira Dos Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>ICLR&apos;17</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Fuyu</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taiwei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changlong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keping</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wilfred</forename><surname>Ng</surname></persName>
		</author>
		<title level="m">SDM: Sequential deep matching model for online large-scale recommender system. In CIKM&apos;19</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2635" to="2643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning disentangled representations for recommendation</title>
		<author>
			<persName><forename type="first">Jianxin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;19</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5712" to="5723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Collaborative filtering: A machine learning perspective</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Marlin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>University of Toronto Toronto</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Image-based recommendations on styles and substitutes</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Targett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;15</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
	<note>Qinfeng Shi, and Anton Van Den Hengel</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A new collaborative filtering approach for increasing the aggregate diversity of recommender systems</title>
		<author>
			<persName><forename type="first">Katja</forename><surname>Niemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Wolpers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;13</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="955" to="963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Comparing context-aware recommender systems in terms of accuracy and diversity</title>
		<author>
			<persName><forename type="first">Umberto</forename><surname>Panniello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Tuzhilin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Gorgoglione</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">UMUAI</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="35" to="65" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Practice on long sequential user behavior modeling for click-through rate prediction</title>
		<author>
			<persName><forename type="first">Qi</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijie</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guorui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqiang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;19</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2671" to="2679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Promoting diversity in recommendation by entropy regularizer</title>
		<author>
			<persName><forename type="first">Lijing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<idno>IJCAI&apos;13</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Factorization machines</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM&apos;10. IEEE</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="995" to="1000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Factorizing personalized markov chains for next-basket recommendation</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;10</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="811" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Dynamic routing between capsules</title>
		<author>
			<persName><forename type="first">Sara</forename><surname>Sabour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Frosst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;17</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3856" to="3866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName><forename type="first">George</forename><surname>Badrul Munir Sarwar</surname></persName>
		</author>
		<author>
			<persName><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Joseph A Konstan</surname></persName>
		</author>
		<author>
			<persName><surname>Riedl</surname></persName>
		</author>
		<idno>WWW&apos;01</idno>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Collaborative filtering recommender systems</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Frankowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shilad</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The adaptive web</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="291" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Measuring playlist diversity for recommendation systems</title>
		<author>
			<persName><forename type="first">Malcolm</forename><surname>Slaney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMCMM&apos;06 workshop</title>
				<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="77" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Object-based visual attention for computer vision</title>
		<author>
			<persName><forename type="first">Yaoru</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="77" to="123" />
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;17</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning hierarchical representation model for nextbasket recommendation</title>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengxian</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;15</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="403" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Deep &amp; cross network for ad click predictions</title>
		<author>
			<persName><forename type="first">Ruoxi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingliang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ADKDD&apos;17</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Recurrent recommender networks</title>
		<author>
			<persName><surname>Chao-Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amr</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">How</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><surname>Jing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM&apos;17</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="495" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep Matrix Factorization Models for Recommender Systems</title>
		<author>
			<persName><forename type="first">Hong-Jian</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianbing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI&apos;17</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3203" to="3209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pong</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;18</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="974" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A dynamic recurrent model for next basket recommendation</title>
		<author>
			<persName><forename type="first">Feng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;16</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="729" to="732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Recommendation with diversity: An adaptive trust-aware model</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junpeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harry</forename><forename type="middle">Jiannan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ling</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page">113073</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Atrank: An attention-based user behavior modeling framework for recommendation</title>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinze</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junshuai</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengchao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiusi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI&apos;18</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Deep interest network for click-through rate prediction</title>
		<author>
			<persName><forename type="first">Guorui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqiang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenru</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanghui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junqi</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;18</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1059" to="1068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Learning tree-based deep model for recommender systems</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengye</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guozheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;18</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1079" to="1088" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
