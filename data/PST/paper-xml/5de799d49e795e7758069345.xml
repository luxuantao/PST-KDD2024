<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pareto Multi-Task Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xi</forename><surname>Lin</surname></persName>
							<email>xi.lin@my.cityu.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="institution">City University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hui-Ling</forename><surname>Zhen</surname></persName>
							<email>huilzhen@um.cityu.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="institution">City University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenhua</forename><surname>Li</surname></persName>
							<email>zhenhua.li@nuaa.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">Nanjing University of Aeronautics and Astronautics</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qingfu</forename><surname>Zhang</surname></persName>
							<email>qingfu.zhang@cityu.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="institution">City University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sam</forename><surname>Kwong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">City University of Hong Kong</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Pareto Multi-Task Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9AA58899544A73F272142302DC01378B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multi-task learning is a powerful method for solving multiple correlated tasks simultaneously. However, it is often impossible to find one single solution to optimize all the tasks, since different tasks might conflict with each other. Recently, a novel method is proposed to find one single Pareto optimal solution with good trade-off among different tasks by casting multi-task learning as multiobjective optimization. In this paper, we generalize this idea and propose a novel Pareto multi-task learning algorithm (Pareto MTL) to find a set of well-distributed Pareto solutions which can represent different trade-offs among different tasks. The proposed algorithm first formulates a multi-task learning problem as a multiobjective optimization problem, and then decomposes the multiobjective optimization problem into a set of constrained subproblems with different trade-off preferences. By solving these subproblems in parallel, Pareto MTL can find a set of well-representative Pareto optimal solutions with different trade-off among all tasks. Practitioners can easily select their preferred solution from these Pareto solutions, or use different trade-off solutions for different situations. Experimental results confirm that the proposed algorithm can generate well-representative solutions and outperform some state-of-the-art algorithms on many multi-task learning applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Multi-task learning (MTL) <ref type="bibr" target="#b0">[1]</ref>, which aims at learning multiple correlated tasks at the same time, is a popular research topic in the machine learning community. By solving multiple related tasks together, MTL can further improve the performance of each task and reduce the inference time for conducting all the tasks in many realworld applications. Many MTL approaches have been proposed in the past, and they achieve great performances in many areas such as computer vision <ref type="bibr" target="#b1">[2]</ref>, natural language processing <ref type="bibr" target="#b2">[3]</ref> and speech recognition <ref type="bibr" target="#b3">[4]</ref>.</p><p>Most MTL approaches are proposed for finding one single solution to improve the overall performance of all tasks <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. However, it is observed in many applications that some tasks could conflict with each other, and no single optimal solution can optimize the performance of all tasks at the same time <ref type="bibr" target="#b6">[7]</ref>. In real-world applications, MTL practitioners have to make a trade-off among different tasks, such as in self-driving car <ref type="bibr" target="#b7">[8]</ref>, AI assistance <ref type="bibr" target="#b8">[9]</ref> and network architecture search <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>.</p><p>How to combine different tasks together and make a proper trade-off among them is a difficult problem. In many MTL applications, especially those using deep multi-task neural networks, all tasks are first combined into a single surrogate task via linear weighted scalarization. A set of fixed weights, which reflects the practitioners' preference, is assigned to these tasks. Then the single surrogate task is optimized. Setting proper weights for different tasks is not easy and usually requires exhaustive weights search. In fact, no single solution can achieve the best performance on all tasks at the same time if some tasks conflict with each other.</p><p>Recently, Sener and Koltun <ref type="bibr" target="#b11">[12]</ref> formulate a multi-task learning problem as a multi-objective optimization problem in a novel way. They propose an efficient algorithm to find one Pareto optimal solution among different tasks for a MTL problem. However, the MTL problem can have many (even an infinite number of ) optimal trade-offs among its tasks, and the single solution obtained by this method might not always satisfy the MTL practitioners' needs.</p><p>In this paper, we generalize the multi-objective optimization idea <ref type="bibr" target="#b11">[12]</ref> and propose a novel Pareto Multi-Task Learning (Pareto MTL) algorithm to generate a set of well-representative Pareto solutions for a given MTL problem. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, MTL practitioners can easily select their preferred solution(s) among the set of obtained Pareto optimal solutions with different trade-offs, rather than exhaustively searching for a set of proper weights for all tasks.</p><p>The main contributions of this paper are: <ref type="foot" target="#foot_1">1</ref>• We propose a novel method to decompose a MTL problem into multiple subproblems with different preferences. By solving these subproblems in parallel, we can obtain a set of well-distributed Pareto optimal solutions with different trade-offs for the original MTL. • We show that the proposed Pareto MTL can be reformulated as a linear scalarization approach to solve MTL with dynamically adaptive weights. We also propose a scalable optimization algorithm to solve all constrained subproblems with different preferences. • Experimental results confirm that the proposed Pareto MTL algorithm can successfully find a set of well representative solutions for different MTL applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Multi-task learning (MTL) algorithms aim at improving the performance of multiple related tasks by learning them at the same time. These algorithms often construct shared parameter representation to combine multiple tasks. They have been applied in many machine learning areas. However, most MTL algorithms mainly focus on constructing shared representation rather than making trade-offs among multiple tasks <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>.</p><p>Linear tasks scalarization, together with grid search or random search of the weight vectors, is the current default practice when a MTL practitioner wants to obtain a set of different trade-off solutions. This approach is straightforward but could be extremely inefficient. Some recent works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13]</ref> show that a single run of an algorithm with well-designed weight adaption can outperform the random search approach with more than one hundred runs. These adaptive weight methods focus on balancing all tasks during the optimization process and are not suitable for finding different trade-off solutions.</p><p>Multi-objective optimization <ref type="bibr" target="#b13">[14]</ref> aims at finding a set of Pareto solutions with different trade-offs rather than one single solution. It has been used in many machine learning applications such as reinforcement learning <ref type="bibr" target="#b14">[15]</ref>, Bayesian optimization <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref> and neural architecture search <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">19]</ref>. In these applications, the gradient information is usually not available. Population-based and gradientfree multi-objective evolutionary algorithms <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> are popular methods to find a set of welldistributed Pareto solutions in a single run. However, it can not be used for solving large scale and gradient-based MTL problems.</p><p>Multi-objective gradient descent <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref> is an efficient approach for multi-objective optimization when gradient information is available. Sener and Koltun <ref type="bibr" target="#b11">[12]</ref> proposed a novel method for solving MTL by treating it as multi-objective optimization. However, similar to the adaptive weight methods, this method tries to balance different tasks during the optimization process and does not have a systematic way to incorporate trade-off preference. In this paper, we generalize it for finding a set of well-representative Pareto solutions with different trade-offs among tasks for MTL problems. 3 Multi-Task Learning as Multi-Objective Optimization</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">MTL as Multi-Objective Optimization</head><p>A MTL problem involves a set of m correlated tasks with a loss vector:</p><formula xml:id="formula_0">min θ L(θ) = (L 1 (θ), L 2 (θ), • • • , L m (θ)) T ,<label>(1)</label></formula><p>where L i (θ) is the loss of the i-th task. A MTL algorithm is to optimize all tasks simultaneously by exploiting the shared structure and information among them.</p><p>Problem (1) is a multi-objective optimization problem. No single solution can optimize all objectives at the same time. What we can obtain instead is a set of so-called Pareto optimal solutions, which provides different optimal trade-offs among all objectives. We have the following definitions <ref type="bibr" target="#b24">[25]</ref>: Pareto dominance. Let θ a , θ b be two points in Ω, θ a is said to dominate θ b (θ a ≺ θ b ) if and only if L i (θ a ) ≤ L i (θ b ), ∀i ∈ {1, ..., m} and L j (θ a ) &lt; L j (θ b ), ∃j ∈ {1, ..., m}.</p><p>Pareto optimality. θ * is a Pareto optimal point and L(θ * ) is a Pareto optimal objective vector if it does not exist θ ∈ Ω such that θ ≺ θ * . The set of all Pareto optimal points is called the Pareto set. The image of the Pareto set in the loss space is called the Pareto front.</p><p>In this paper, we focus on finding a set of well-representative Pareto solutions that can approximate the Pareto front. This idea and the comparison results of our proposed method with two others are presented in Fig. <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Linear Scalarization</head><p>Linear scalarization is the most commonly-used approach for solving multi-task learning problems. This approach uses a linear weighted sum method to combine the losses of all tasks into a single surrogate loss:</p><formula xml:id="formula_1">min θ L(θ) = m i=1 w i L i (θ),<label>(2)</label></formula><p>where w i is the weight for the i-th task. This approach is simple and straightforward, but it has some drawbacks from both multi-task learning and multi-objective optimization perspectives.</p><p>In a typical multi-task learning application, the weights w i are needed to be assigned manually before optimization, and the overall performance is highly dependent on the assigned weights. Choosing a proper weight vector could be very difficult even for an experienced MTL practitioner who has expertise on the given problem.</p><p>Solving a set of linear scalarization problems with different weight assignments is also not a good idea for multi-objective optimization. As pointed out in <ref type="bibr" target="#b25">[26,</ref><ref type="bibr">Chapter 4.7]</ref>, this method can only provide solutions on the convex part of the Pareto front. The linear scalarization method with different weight assignments is unable to handle a concave Pareto front as shown in Fig. <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Gradient-based method for multi-objective optimization</head><p>Many gradient-based methods have been proposed for solving multi-objective optimization problems <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>. Fliege and Svaiter <ref type="bibr" target="#b23">[24]</ref> have proposed a simple gradient-based method, which is a generalization of a single objective steepest descent algorithm. The update rule of the algorithm is θ t+1 = θ t + ηd t where η is the step size and the search direction d t is obtained as follows:</p><formula xml:id="formula_2">(d t , α t ) = arg min d∈R n ,α∈R α + 1 2 ||d|| 2 , s.t. ∇L i (θ t ) T d ≤ α, i = 1, ..., m.<label>(3)</label></formula><p>The solutions of the above problem will satisfy:</p><p>Lemma 1 <ref type="bibr" target="#b23">[24]</ref>:</p><formula xml:id="formula_3">Let (d k , α k ) be the solution of problem (3). 1. If θ t is Pareto critical, then d t = 0 ∈ R n and α t = 0. 2. If θ t is not Pareto critical, then α t ≤ -(1/2)||d t || 2 &lt; 0, ∇L i (θ t ) T d t ≤ α t , i = 1, ..., m,<label>(4)</label></formula><p>where θ is called Pareto critical if no other solution in its neighborhood can have better values in all objective functions. In other words, if d t = 0, no direction can improve the performance for all tasks at the same time. If we want to improve the performance for a specific task, another task's performance will be deteriorated (e.g., ∃i, L i (θ t ) T d t &gt; 0). Therefore, the current solution is a Pareto critical point. When d t = 0, we have ∇L i (θ t ) T d t &lt; 0, i = 1, ..., m, which means d t is a valid descent direction for all tasks. The current solution should be updated along the obtained direction</p><formula xml:id="formula_4">θ t+1 = θ t + ηd t .</formula><p>Recently, Sener and Koltun <ref type="bibr" target="#b11">[12]</ref> used the multiple gradient descent algorithm (MGDA) <ref type="bibr" target="#b21">[22]</ref> for solving MTL problems and achieve promising results. However, this method does not have a systemic way to incorporate different trade-off preference information. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>, running the algorithm multiple times can only generate some solutions in the middle of the Pareto front on the synthetic example. In this paper, we generalize this method and propose a novel Pareto MTL algorithm to find a set of well-distributed Pareto solutions with different trade-offs among all tasks.</p><p>4 Pareto Multi-Task Learning We adopt the idea from <ref type="bibr" target="#b28">[29]</ref> and decompose the MTL into K subproblems with a set of well-distributed unit preference vectors {u 1 , u 2 , ..., u K } in R m + . Suppose all objectives in the MOP are non-negative, the multiobjective subproblem corresponding to the preference vector u k is:</p><formula xml:id="formula_5">min θ L(θ) = (L 1 (θ), L 2 (θ), • • • , L m (θ)) T , s.t. L(θ) ∈ Ω k ,<label>(5)</label></formula><p>where Ω k (k = 1, ..., K) is a subregion in the objective space:</p><formula xml:id="formula_6">Ω k = {v ∈ R m + |u T j v ≤ u T k v, ∀j = 1, ..., K}<label>(6)</label></formula><p>and u T j v is the inner product between the preference vector u j and a given vector v. That is to say, v ∈ Ω k if and only if v has the smallest acute angle to u k and hence the largest inner product u T k v among all K preference vectors.</p><p>The subproblem (5) can be further reformulated as:</p><formula xml:id="formula_7">min θ L(θ) = (L 1 (θ), L 2 (θ), • • • , L m (θ)) T s.t. G j (θ t ) = (u j -u k ) T L(θ t ) ≤ 0, ∀j = 1, ..., K,<label>(7)</label></formula><p>As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, the preference vectors divide the objective space into different sub-regions. The solution for each subproblem would be attracted by the corresponding preference vector and hence be guided to its representative sub-region. The set of solutions for all subproblems would be in different sub-regions and represent different trade-offs among the tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Gradient-based Method for Solving Subproblems</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Finding the Initial Solution</head><p>To solve the constrained multi-objective subproblem (5) with a gradient-based method, we need to find an initial solution which is feasible or at least satisfies most constraints. For a randomly generated solution θ r , one straightforward method is to find a feasible initial solution θ 0 which satisfies:</p><formula xml:id="formula_8">min θ0 ||θ 0 -θ r || 2 s.t. L(θ 0 ) ∈ Ω k .<label>(8)</label></formula><p>However, this projection approach is an n dimensional constrained optimization problem <ref type="bibr" target="#b29">[30]</ref>. It is inefficient to solve this problem directly, especially for a deep neural network with millions of parameters. In the proposed Pareto MTL algorithm, we reformulate this problem as unconstrained optimization, and use a sequential gradient-based method to find the initial solution θ 0 .</p><p>For a solution θ r , we define the index set of all activated constraints as I(θ r ) = {j|G j (θ r ) ≥ 0, j = 1, ..., K}. We can find a valid descent direction d r to reduce the value of all activated constraints {G j (θ r )|j ∈ I(θ r )} by solving:</p><formula xml:id="formula_9">(d r , α r ) = arg min d∈R n ,α∈R α + 1 2 ||d|| 2 , s.t.∇G j (θ r ) T d ≤ α, j ∈ I(θ r ).<label>(9)</label></formula><p>This approach is similar to the unconstrained gradient-based method (3), but it reduces the value of all activated constraints. The gradient-based update rule is θ rt+1 = θ rt + η r d rt and will be stopped once a feasible solution is found or a predefined number of iterations is met.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Solving the Subproblem</head><p>Once we have an initial solution, we can use a gradient-based method to solve the constrained subproblem. For a constrained multiobjective optimization problem, the Pareto optimality restricted on the feasible region Ω k can be defined as <ref type="bibr" target="#b23">[24]</ref>:</p><formula xml:id="formula_10">Restricted Pareto Optimality. θ * is a Pareto optimal point for L(θ) restricted on Ω k if θ * ∈ Ω k and it does not exist θ ∈ Ω k such that θ ≺ θ * .</formula><p>According to <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b29">30]</ref>, we can find a descent direction for this constrained MOP by solving a subproblem similar to the subproblem (3) for the unconstrained case:</p><formula xml:id="formula_11">(d t , α t ) =arg min d∈R n ,α∈R α + 1 2 ||d|| 2 s.t. ∇L i (θ t ) T d ≤ α, i = 1, ..., m. ∇G j (θ t ) T d ≤ α, j ∈ I (θ t ),<label>(10)</label></formula><p>where I (θ) is the index set of all activated constraints:</p><formula xml:id="formula_12">I (θ) = {j ∈ I|G j (θ) ≥ -}.<label>(11)</label></formula><p>We add a small threshold to deal with the solutions near the constraint boundary. Similar to the unconstrained case, for a feasible solution θ t , by solving problem <ref type="bibr" target="#b9">(10)</ref>, we either obtain d t = 0 and confirm that θ t is a Pareto critical point restricted on Ω k , or obtain d t = 0 as a descent direction for the constrained multi-objective problem <ref type="bibr" target="#b6">(7)</ref>. In the latter case, if all constraints are inactivated (e.g., I (θ) = ∅), d t is a valid descent direction for all tasks. Otherwise, d t is a valid direction to reduce the values for all tasks and all activated constraints.</p><p>Lemma 2 <ref type="bibr" target="#b29">[30]</ref>: Let (d k , α k ) be the solution of problem <ref type="bibr" target="#b9">(10)</ref>.</p><p>1. If θ t is Pareto critical restricted on Ω k , then d t = 0 ∈ R n and α t = 0.</p><p>2. If θ t is not Pareto critical restricted on Ω k , then</p><formula xml:id="formula_13">α t ≤ -(1/2)||d t || 2 &lt; 0, ∇L i (θ t ) T d t ≤ α t , i = 1, ..., m ∇G j (θ t ) T d t ≤ α t , j ∈ I (θ t ).<label>(12)</label></formula><p>Therefore, we can obtain a restricted Pareto critical solution for each subproblem with simple iterative gradient-based update rule θ t+1 = θ t + η r d t . By solving all subproblems, we can obtain a set of diverse Pareto critical solutions restricted on different sub-regions, which can represent different trade-offs among all tasks for the original MTL problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Scalable Optimization Method</head><p>By solving the constrained optimization problem <ref type="bibr" target="#b9">(10)</ref>, we can obtain a valid descent direction for each multi-objective constrained subproblem. However, the optimization problem itself is not scalable well for high dimensional decision space. For example, when training a deep neural network, we often have more than millions of parameters to be optimized, and solving the constrained optimization problem <ref type="bibr" target="#b9">(10)</ref> in this scale would be extremely slow. In this subsection, we propose a scalable optimization method to solve the constrained optimization problem.</p><p>Inspired by <ref type="bibr" target="#b23">[24]</ref>, we first rewrite the optimization problem <ref type="bibr" target="#b9">(10)</ref> in its dual form. Based on the KKT conditions, we have</p><formula xml:id="formula_14">d t = -( m i=1 λ i ∇L i (θ t ) + j∈I (x) β i ∇G j (θ t )), m i=1 λ i + j∈I (θ) β j = 1,<label>(13)</label></formula><p>where λ i ≥ 0 and β i ≥ 0 are the Larange multipliers for the linear inequality constraints. Therefore, the dual problem is:</p><formula xml:id="formula_15">max λi,βj - 1 2 || m i=1 λ i ∇L i (θ t ) + j∈I (x) β i ∇G j (θ t )|| 2 s.t. m i=1 λ i + j∈I (θ) β j = 1, λ i ≥ 0, β j ≥ 0, ∀i = 1, ..., m, ∀j ∈ I (θ). (<label>14</label></formula><formula xml:id="formula_16">)</formula><p>For the above problem, the decision space is no longer the parameter space, and it becomes the objective and constraint space. For a multiobjective optimization problem with 2 objective function and 5 activated constraints, the dimension of problem ( <ref type="formula" target="#formula_15">14</ref>) is 7, which is significantly smaller than the dimension of problem <ref type="bibr" target="#b9">(10)</ref> which could be more than a million.</p><p>The algorithm framework of Pareto MTL is shown in Algorithm 1. All subproblems can be solved in parallel since there is no communication between them during the optimization process. The only preference information for each subproblem is the set of preference vectors. Without any prior knowledge for the MTL problem, a set of evenly distributed unit preference vectors would be a reasonable default choice, such as K + 1 preference vectors {(cos( kπ 2K ), sin( kπ 2K ))|k = 0, 1, ..., K} for 2 tasks. We provide more discussion on preference vector setting and sensitivity analysis of the preference vectors in the supplementary material. calculate the direction d</p><formula xml:id="formula_17">(k) t = -( m i=1 λ (k) ti ∇L i (θ (k) t ) + j∈I (x) β (k) ti ∇G j (θ (k) t ) 10:</formula><p>update the parameters θ</p><formula xml:id="formula_18">(k) t+1 = θ (k) t + ηd (k) t 11:</formula><p>end for 12: end for 13: Output: The set of solutions for all subproblems with different trade-offs {θ</p><formula xml:id="formula_19">(k) T |k = 1, •, K}</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Pareto MTL as an Adaptive Linear Scalarization Approach</head><p>We have proposed the Pareto MTL algorithm from the multi-objective optimization perspective. In this subsection, we show that the Pareto MTL algorithm can be reformulated as a linear scalarization of tasks with adaptive weight assignment. In this way, we can have a deeper understanding of the differences between Pareto MTL and other MTL algorithms.</p><p>We first tackle the unconstrained case. Suppose we do not decompose the multi-objective problem and hence remove all constraints from the problem <ref type="bibr" target="#b13">(14)</ref>, it will immediately reduce to the update rule proposed by MGDA <ref type="bibr" target="#b21">[22]</ref> which is used in <ref type="bibr" target="#b11">[12]</ref>. It is straightforward to rewrite the corresponding MTL into a linear scalarization form:</p><formula xml:id="formula_20">L(θ t ) = m i=1 λ i L i (θ t ),<label>(15)</label></formula><p>where we adaptively assign the weights λ i by solving the following problem in each iteration:</p><formula xml:id="formula_21">max λi - 1 2 || m i=1 λ i ∇L i (θ t )|| 2 , s.t. m i=1 λ i = 1, λ i ≥ 0, ∀i = 1, ..., m.<label>(16)</label></formula><p>In the constrained case, we have extra constraint terms G j (θ t ). If G j (θ t ) is inactivated, we can ignore it. For an activated G j (θ t ), assuming the corresponding reference vector is u k , we have:</p><formula xml:id="formula_22">∇G j (θ t ) = (u j -u k ) T ∇L(θ t ) = m i=1 (u ji -u ki )∇L i (θ t ).<label>(17)</label></formula><p>Since the gradient direction d t can be written as a linear combination of all ∇L i (θ t ) and ∇G j (θ t ) as in <ref type="bibr" target="#b12">(13)</ref>, the general Pareto MTL algorithm can be rewritten as:</p><formula xml:id="formula_23">L(θ t ) = m i=1 α i L i (θ t ), where α i = λ i + j∈I (θ) β j (u ji -u ki ),<label>(18)</label></formula><p>where λ i and β j are obtained by solving problem <ref type="bibr" target="#b13">(14)</ref> with assigned reference vector u k .</p><p>Therefore, although MOO-MTL <ref type="bibr" target="#b11">[12]</ref> and Pareto MTL are both derived from multi-objective optimization, they can also be treated as linear MTL scalarization with adaptive weight assignments.</p><p>Both methods are orthogonal to many existing MTL approaches. We provide further discussion on the adaptive weight vectors in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">A Synthetic Example</head><p>To better analyze the convergence behavior of the proposed Pareto MTL, we first compare it with two commonly used methods, namely the linear scalarization method and the multiple gradient descent algorithm used in MOO-MTL <ref type="bibr" target="#b11">[12]</ref>, on a simple synthetic multi-objective optimization problem:</p><formula xml:id="formula_24">min x f 1 (x) = 1 -exp (- d i=1 (x d - 1 √ d ) 2 ) min x f 2 (x) = 1 -exp (- d i=1 (x d + 1 √ d ) 2 )<label>(19)</label></formula><p>where f 1 (x) and f 2 (x) are two objective functions to be minimized at the same time and x = (x 1 , x 2 , ..., x d ) is the d dimensional decision variable. This problem has a concave Pareto front on the objective space.</p><p>The results obtained by different algorithms are shown in Fig. <ref type="figure" target="#fig_1">2</ref>. In this case, the proposed Pareto MTL can successfully find a set of well-distributed Pareto solutions with different trade-offs. Since MOO-MTL tries to balance different tasks during the optimization process, it gets a set of solutions with similar trade-offs in the middle of the Pareto front in multiple runs. It is also interesting to observe that the linear scalarization method can only generate extreme solutions for the concave Pareto front evenly with 100 runs. This observation is consistent with the theoretical analysis in <ref type="bibr" target="#b25">[26]</ref> that the linear scalarization method will miss all concave parts of a Pareto front. It is evident that fixed linear scalarization is not always a good idea for solving the MTL problem from the multi-objective optimization perspective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>In this section, we compare our proposed Pareto MTL algorithm on different MTL problems with the following algorithms: 1) Single Task: the single task baseline; 2) Grid Search: linear scalarization with fixed weights; 3) GradNorm <ref type="bibr" target="#b12">[13]</ref>: gradient normalization; 4) Uncertainty <ref type="bibr" target="#b6">[7]</ref>: adaptive weight assignments with uncertainty balance; 5) MOO-MTL <ref type="bibr" target="#b11">[12]</ref>: finding one Pareto optimal solution for multi-objective optimization problem. More experimental results and discussion can be found in the supplementary material. In order to evaluate the performance of Pareto MTL on multi-task learning problems with different tasks relations, we first conduct experiments on MultiMNIST <ref type="bibr" target="#b30">[31]</ref> and two MultiMNIST-like datasets.</p><p>To construct the MultiMNIST dataset, we randomly pick two images with different digits from the original MNIST dataset <ref type="bibr" target="#b31">[32]</ref>, and then combine these two images into a new one by putting one digit on the top-left corner and the other one on the bottom-right corner. Each digit can be moved up to 4 pixels on each direction. With the same approach, we can construct a MultiFashionMINST dataset with overlap FashionMNIST items <ref type="bibr" target="#b32">[33]</ref>, and a Multi-(Fashion + MNIST) with overlap MNIST and FashionMNIST items. For each dataset, we have a two objective MTL problem to classify the item on the top-left (task 1) and to classify the item on the bottom-right (task 2). We build a LeNet <ref type="bibr" target="#b31">[32]</ref> based MTL neural network similar to the one used in <ref type="bibr" target="#b11">[12]</ref>. The obtained results are shown in Fig. <ref type="figure" target="#fig_4">4</ref>.</p><p>In all experiments, since the tasks conflict with each other, solving each task separately results in a hard-to-beat single-task baseline. Our proposed Pareto MTL algorithm can generate multiple well-distributed Pareto solutions for all experiments, which are compatible with the strong single-task baseline but with different trade-offs among the tasks. Pareto MTL algorithm achieves the overall best performance among all MTL algorithms. These results confirm that our proposed Pareto MTL can successfully provide a set of well-representative Pareto solutions for a MTL problem.</p><p>It is not surprising to observe that the Pareto MTL's solution for subproblems with extreme preference vectors (e.g., (0, 1) and (1, 0)) always have the best performance in the corresponding task. Especially in the Multi-(Fashion-MNIST) experiment, where the two tasks are less correlated with each other. In this problem, almost all MTL's solutions are dominated by the strong single task's baseline. However, Pareto MTL can still generate solutions with the best performance for each task separately. It behaves as auxiliary learning, where the task with the assigned preference vector is the main task, and the others are auxiliary tasks.</p><p>Pareto MTL uses neural networks with simple hard parameter sharing architectures as the base model for MTL problems. It will be very interesting to generalize Pareto MTL to other advanced soft parameter sharing architectures <ref type="bibr" target="#b4">[5]</ref>. Some recently proposed works on task relation learning <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref> could also be useful for Pareto MTL to make better trade-offs for less relevant tasks.  We further evaluate Pareto MTL on an autonomous driving self-localization problem <ref type="bibr" target="#b7">[8]</ref>. In this experiment, we simultaneously estimate the location and orientation of a camera put on a driving car based on the images it takes. We use data from the apolloscape autonomous driving dataset <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref>, and focus on the Zpark sample subset. We build a PoseNet with a ResNet18 <ref type="bibr" target="#b38">[39]</ref> encoder as the MTL model. The experiment results are shown in Fig. <ref type="figure" target="#fig_5">5</ref>. It is obvious that our proposed Pareto MTL can generate solutions with different trade-offs and outperform other MTL approaches.</p><p>We provide more experiment results and analysis on finding the initial solution, Pareto MTL with many tasks, and other relative discussions in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we proposed a novel Pareto Multi-Task Learning (Pareto MTL) algorithm to generate a set of well-distributed Pareto solutions with different trade-offs among tasks for a given multi-task learning (MTL) problem. MTL practitioners can then easily select their preferred solutions among these Pareto solutions. Experimental results confirm that our proposed algorithm outperforms some state-of-the-art MTL algorithms and can successfully find a set of well-representative solutions for different MTL applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Pareto MTL can find a set of widely distributed Pareto solutions with different trade-offs for a given MTL. Then the practitioners can easily select their preferred solution(s).</figDesc><graphic coords="1,341.64,515.70,162.36,120.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The convergence behaviors of different algorithms on a synthetic example. (a) The obtained solutions of random linear scalarization after 100 runs. (b) The obtained solutions of the MOO-MTL [12] method after 10 runs. (c) The obtained solutions of the Pareto MTL method proposed by this paper after 10 runs. The proposed Pareto MTL successfully generates a set of widely distributed Pareto solutions with different trade-offs. Details of the synthetic example can be found in section 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Pareto MTL decomposes a given MTL problem into several subproblems with a set of preference vectors. Each MTL subproblem aims at finding one Pareto solution in its restricted preference region.</figDesc><graphic coords="4,325.80,497.58,178.20,127.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 1</head><label>1</label><figDesc>Pareto MTL Algorithm 1: Input: A set of evenly distributed vectors {u 1 , u 2 , ..., u K } 2: Update Rule: 3: (can be solved in parallel) 4: for k = 1 to K do ti ≥ 0, ∀i = 1, ..., m, ∀j ∈ I (θ) by solving subproblem<ref type="bibr" target="#b13">(14)</ref> 9:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The results for three experiments with Task1&amp;2 accuracy: our proposed Pareto MTL can successfully find a set of well-distributed solutions with different trade-offs for all experiments, and it significantly outperforms Grid Search, Uncertainty and GradNorm. MOO-MTL algorithm can also find promising solutions, but their diversity is worse than the solutions generated by Pareto MTL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The results of self-location MTL experiment: Our proposed Pareto MTL outperforms other algorithms and provides solutions with different trade-offs.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>The code is available at: https://github.com/Xi-L/ParetoMTL</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments This work was supported by the Natural Science Foundation of China under Grant 61876163 and Grant 61672443, ANR/RGC Joint Research Scheme sponsored by the Research Grants Council of the Hong Kong Special Administrative Region, China and France National Research Agency (Project No. A-CityU101/16), and Hong Kong RGC General Research Funds under Grant 9042489 (CityU 11206317) and Grant 9042322 (CityU 11200116).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="75" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ubernet: Training a universal convolutional neural network for low-, mid-, and high-level vision using diverse datasets and limited memory</title>
		<author>
			<persName><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6129" to="6138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning general purpose distributed sentence representations via large scale multi-task learning</title>
		<author>
			<persName><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Pal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Rapid adaptation for deep neural networks through multi-task learning</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabato</forename><surname>Marco Siniscalchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I-Fan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin-Hui</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixteenth Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">An overview of multi-task learning in deep neural networks</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05098</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A survey on multi-task learning</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.08114</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multi-task learning using uncertainty to weigh losses for scene geometry and semantics</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dels-3d: Deep localization and segmentation with a 3d semantic map</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruigang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binbin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanqing</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5860" to="5869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Towards speech emotion recognition &quot;in the wild&quot; using aggregated corpora and deep multi-task learning</title>
		<author>
			<persName><forename type="first">Jaebok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gwenn</forename><surname>Englebienne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Khiet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vanessa</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName><surname>Evers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">18th Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1113" to="1117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dpp-net: Device-aware progressive search for pareto-optimal neural architectures</title>
		<author>
			<persName><forename type="first">Jin-Dong</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">An-Chieh</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da-Cheng</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="517" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Proxylessnas: Direct neural architecture search on target task and hardware</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-task learning as multi-objective optimization</title>
		<author>
			<persName><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="525" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks</title>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Zhao Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen-Yu</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="794" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Nonlinear multiobjective optimization</title>
		<author>
			<persName><forename type="first">Kaisa</forename><surname>Miettinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-objective reinforcement learning using sets of pareto dominating policies</title>
		<author>
			<persName><forename type="first">Kristof</forename><surname>Van Moffaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><surname>Nowé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3483" to="3512" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Active learning for multiobjective optimization</title>
		<author>
			<persName><forename type="first">Marcela</forename><surname>Zuluaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Sergent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Püschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="462" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Predictive entropy search for multi-objective bayesian optimization</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><surname>Hernandez-Lobato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amar</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1492" to="1501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pareto frontier learning with expensive correlated objectives</title>
		<author>
			<persName><forename type="first">Amar</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1919" to="1927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Efficient multi-objective neural architecture search via lamarckian evolution</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Evolutionary algorithms for multiobjective optimization: Methods and applications</title>
		<author>
			<persName><forename type="first">Eckart</forename><surname>Zitzler</surname></persName>
		</author>
		<imprint>
			<publisher>Citeseer</publisher>
			<biblScope unit="volume">63</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Multi-Objective Optimization Using Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">Deb</forename><surname>Kalyanmoy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>John Wiley &amp; Sons, Inc</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mutiple-gradient descent algorithm for multiobjective optimization</title>
		<author>
			<persName><forename type="first">Jean-Antoine</forename><surname>Désidéri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Congress on Computational Methods in Applied Sciences and Engineering (ECCOMAS</title>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A method for constrained multiobjective optimization based on sqp techniques</title>
		<author>
			<persName><forename type="first">Jorg</forename><surname>Fliege</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ismael</surname></persName>
		</author>
		<author>
			<persName><surname>Vaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2091" to="2119" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Steepest descent methods for multicriteria optimization</title>
		<author>
			<persName><forename type="first">Jörg</forename><surname>Fliege</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fux</forename><surname>Benar</surname></persName>
		</author>
		<author>
			<persName><surname>Svaiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Methods of Operations Research</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="479" to="494" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multiobjective evolutionary algorithms: a comparative case study and the strength pareto approach</title>
		<author>
			<persName><forename type="first">Eckart</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lothar</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="257" to="271" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lieven</forename><surname>Vandenberghe</surname></persName>
		</author>
		<title level="m">Convex optimization</title>
		<imprint>
			<publisher>Cambridge university press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Moea/d: A multiobjective evolutionary algorithm based on decomposition</title>
		<author>
			<persName><forename type="first">Qingfu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on evolutionary computation</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="712" to="731" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A survey of multiobjective evolutionary algorithms based on decomposition</title>
		<author>
			<persName><forename type="first">Anupam</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipti</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishnendu</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhiroop</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="440" to="462" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Decomposition of a multiobjective optimization problem into a number of simple multiobjective subproblems</title>
		<author>
			<persName><forename type="first">Hai-Lin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangqing</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingfu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="450" to="455" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A descent method for equality and inequality constrained multiobjective optimization problems</title>
		<author>
			<persName><forename type="first">Bennet</forename><surname>Gebken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Peitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Dellnitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Numerical and Evolutionary Optimization</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="29" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dynamic routing between capsules</title>
		<author>
			<persName><forename type="first">Sara</forename><surname>Sabour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Frosst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3856" to="3866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kashif</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Taskonomy: Disentangling task transfer learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Sax</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonidas</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jitendra</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3712" to="3722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Modeling task relationships in multi-task learning with multi-gate mixture-of-experts</title>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Zhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyang</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning to multitask</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5771" to="5782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The apolloscape dataset for autonomous driving</title>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinjing</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qichuan</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binbin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dingfu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanqing</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruigang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The apolloscape open dataset for autonomous driving and its application</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinjing</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dingfu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qichuan</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruigang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Posenet: A convolutional network for real-time 6-dof camera relocalization</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Grimes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2938" to="2946" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
