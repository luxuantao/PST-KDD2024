<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Distance Embeddings for Biological Sequences</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Gabriele</forename><surname>Corso</surname></persName>
							<email>gcorso@mit.edu</email>
						</author>
						<author>
							<persName><surname>Mit</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michal</forename><surname>Pándy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Veličković</forename><surname>Petar</surname></persName>
						</author>
						<author>
							<persName><surname>Deepmind</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pietro</forename><surname>Liò</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Rex Ying Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Jure Leskovec Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="laboratory">35th Conference on Neural Information Processing Systems</orgName>
								<address>
									<postCode>2021)</postCode>
									<settlement>Sydney</settlement>
									<region>NeurIPS</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Distance Embeddings for Biological Sequences</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The development of data-dependent heuristics and representations for biological sequences that reflect their evolutionary distance is critical for large-scale biological research. However, popular machine learning approaches, based on continuous Euclidean spaces, have struggled with the discrete combinatorial formulation of the edit distance that models evolution and the hierarchical relationship that characterises real-world datasets. We present Neural Distance Embeddings (NeuroSEED), a general framework to embed sequences in geometric vector spaces, and illustrate the effectiveness of the hyperbolic space that captures the hierarchical structure and provides an average 22% reduction in embedding RMSE against the best competing geometry. The capacity of the framework and the significance of these improvements are then demonstrated devising supervised and unsupervised NeuroSEED approaches to multiple core tasks in bioinformatics. Benchmarked with common baselines, the proposed approaches display significant accuracy and/or runtime improvements on real-world datasets. As an example for hierarchical clustering, the proposed pretrained and from-scratch methods match the quality of competing baselines with 30x and 15x runtime reduction, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Over the course of evolution, biological sequences constantly mutate and a large part of biological research is based on the analysis of these mutations. Biologists have developed accurate statistical models to estimate the evolutionary distance between pairs of sequences based on their edit distance D(s 1 , s 2 ): the minimum number of (weighted) insertions, deletions or substitutions required to transform a string s 1 into another string s 2 .</p><p>However, the computation of this edit distance kernel D with traditional methods is bound to a quadratic complexity and hardly parallelizable, making its computation a bottleneck in large scale analyses, such as microbiome studies <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref>. Furthermore, the accurate computation of similarities among multiple sequences, at the foundation of critical tasks such as hierarchical clustering and multiple sequence alignment, is computationally intractable even for relatively small numbers of sequences. Problems that in other spaces are relatively simple become combinatorially hard in the space of sequences defined by the edit distance. For example, finding the Steiner string, a classical problem in bioinformatics that can be thought of as computing the geometric median in the space of sequences, is NP-complete.</p><p>Classical algorithms and heuristics <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7]</ref> widely used in bioinformatics for these tasks are data-independent and, therefore, cannot exploit the low-dimensional manifold assumption that characterises real-world data <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>. Leveraging the available data to produce efficient and data- The vector space can then be used to study the relationship between sequences and, potentially, decode new ones (see Section 7.2). On the right, an example of the hierarchical clustering produced on the Poincaré disk. The data was downloaded from UniProt <ref type="bibr" target="#b13">[14]</ref> and consists of the P53 tumour protein from 20 different organisms.</p><p>dependent heuristics and representations would greatly accelerate large-scale analyses that are critical to biological research.</p><p>While the number of available biological sequences has grown exponentially over the past decades, machine learning approaches to problems related to string matching <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> have not been adopted widely in bioinformatics due to their limitation in accuracy and speed. In contrast to most tasks in computer vision and NLP, string matching problems are typically formalised as combinatorial optimisation problems. These discrete formulations do not fit well with the current deep learning approaches. Moreover, representation learning methods based on Euclidean spaces struggle to capture the hierarchical structure that characterises real-world biological datasets due to evolution. Finally, common self-supervised learning approaches, very successful in NLP, are less effective in the biological context where relations tend to be between sequences rather than between bases <ref type="bibr" target="#b12">[13]</ref>.</p><p>In this work, we present Neural Distance Embeddings (NeuroSEED), a general framework to produce representations for biological sequences where the distance in the embedding space is correlated with the evolutionary distance D between sequences. NeuroSEED provides fast approximations of the distance kernel D, low-dimensional representations for biological sequences, tractable analysis of the relationship between multiple sequences in the embedding geometry and a way to decode novel sequences.</p><p>Firstly, we reformulate several existing approaches into NeuroSEED highlighting their contributions and limitations. Then, we examine the task of embedding sequences to preserve the edit distance that is the basis of the framework. This analysis reveals the importance of data-dependent approaches and of using a geometry that matches the underlying data distribution well. The hyperbolic space is able to capture the implicit hierarchical structure given by biological evolution and provides an average 22% reduction in embedding RMSE against the best competing geometry.</p><p>We show the potential of the framework and its wide applicability by analysing two fundamental tasks in bioinformatics involving the relations between multiple sequences: hierarchical clustering and multiple sequence alignment. For both tasks, unsupervised approaches using NeuroSEED encoders are able to match the accuracy of common heuristics while being orders of magnitude faster. For hierarchical clustering, we also explore a method based on the continuous relaxation of Dasgupta's cost in the hyperbolic space which provides a 15x runtime reduction at similar quality levels. Finally, for multiple sequence alignment, we devise an original approach based on variational autoencoders that matches the performance of competitive baselines while significantly reducing the runtime complexity.</p><p>As a summary our contributions are: (i) We introduce NeuroSEED, a general framework to map sequences in geometric vector spaces, and reformulate existing approaches into it. (ii) We show how the hyperbolic space can bring significant improvements to the data-dependent analysis of biological sequences. (iii) We propose several heuristic approaches to classical bioinformatics problems that can be constructed on top of NeuroSEED embeddings and provide significant running time reduction against classical baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Bioinformatics tasks</head><p>The field of bioinformatics has developed a wide range of algorithms to tackle the classical problems that we explore. Here we present the tasks and briefly mention their motivation and some of the baselines we test. More details are provided in Appendix B.</p><p>Edit distance approximation In this work, we always deal with the classical edit distance where the same weight is given to every string operation, but all the approaches developed can be applied to any distance function of choice (which is given as an oracle). For example, when using amino acid sequences, one of the different metric variants of the classical substitution matrices such as mPAM250 <ref type="bibr" target="#b14">[15]</ref> would be a good choice. As baseline approximation heuristics, we take k-mer <ref type="bibr" target="#b4">[5]</ref>, which is the most commonly used alignment-free method and represents sequences by the frequency vector of subsequences of a certain length, and FFP <ref type="bibr" target="#b15">[16]</ref>, another alignment-free method which looks at the Jensen-Shannon divergence between distributions of k-mers.</p><p>Hierarchical clustering (HC) Discovering the intrinsic hierarchical structure given by evolutionary history is a critical step of many biological analyses. Hierarchical clustering (HC) consists of, given a pairwise distance function, defining a tree with internal points corresponding to clusters and leaves to datapoints. Dasgupta's cost <ref type="bibr" target="#b16">[17]</ref> measures how well the tree generated respects the similarities between datapoints. As baselines we consider classical agglomerative clustering algorithms (Single <ref type="bibr" target="#b17">[18]</ref>, Complete <ref type="bibr" target="#b18">[19]</ref> and Average Linkage <ref type="bibr" target="#b5">[6]</ref>) and the recent technique <ref type="bibr" target="#b19">[20]</ref> that uses a continuous relaxation of Dasgupta's cost in the hyperbolic space.</p><p>Multiple sequence alignment (MSA) Aligning three or more sequences is used for the identification of active and binding sites as well as conserved protein structures, but finding its optimal solution is NP-complete. A related task to MSA is the approximation of the Steiner string which minimises the sum of the distances (consensus error) to the sequences in a set.</p><p>Datasets To evaluate the heuristics we chose three datasets containing different portions of the 16S rRNA gene, crucial in microbiome analysis <ref type="bibr" target="#b20">[21]</ref>, one of the most promising applications of our approach. The first, Qiita <ref type="bibr" target="#b20">[21]</ref>, contains more than 6M sequences of up to 152 bp that cover the V4 hyper-variable region. The second, RT988 <ref type="bibr" target="#b10">[11]</ref>, has only 6.7k publicly available sequences of length up to 465 bp covering the V3-V4 regions. Both datasets were generated by Illumina MiSeq <ref type="bibr" target="#b21">[22]</ref> and contain sequences of approximately the same length. Qiita was collected from skin, saliva and faeces samples, while RT988 was from oral plaques. The third dataset is the Greengenes full-length 16S rRNA database <ref type="bibr" target="#b22">[23]</ref>, which contains more than 1M sequences of length between 1,111 to 2,368. Moreover, we used a dataset of synthetically generated sequences to test the importance of data-dependent approaches. A full description of the data splits for each of the tasks is provided in Appendix B.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Neural Distance Embeddings</head><p>The underlying idea behind the NeuroSEED framework, represented in Figure <ref type="figure" target="#fig_0">1</ref>, is to map sequences in a continuous space so that the distance between embedded points is correlated to the one between sequences. Given a distribution of sequences and a distance function D between them, any NeuroSEED approach is formed by four main components: an embedding geometry, an encoder model, a decoder model, and a loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Embedding geometry</head><p>The distance function d between the embedded points defines the geometry of the embedding space. While this factor has been mostly ignored by previous work <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref>, we show that it is critical for this geometry to reflect the relations between the sequences in the domain. In our experiments, we provide a comparison between Euclidean, Manhattan, cosine, squared Euclidean (referred to as Square) and hyperbolic distances (details in Appendix D).</p><p>Encoder model The encoder model f θ maps sequences to points in the embedding space. In this work we test a variety of models as encoder functions: linear layer, MLP, CNN, GRU <ref type="bibr" target="#b27">[28]</ref> and transformer <ref type="bibr" target="#b28">[29]</ref> with local and global attention. The details on how the models are adapted to the sequences are provided in Appendix C. Chen et al. <ref type="bibr" target="#b23">[24]</ref> proposed CSM, an encoder architecture based on the convolution of subsequences. However, as also noted by Koide et al. <ref type="bibr" target="#b11">[12]</ref>, this model does not perform well when various layers are stacked and, due to the interdependence of cells in the dynamic programming routine, it cannot be efficiently parallelised on GPU.</p><p>Decoder model For some tasks it is also useful to decode sequences from the embedding space. This idea, employed in Section 7.2 and novel among the works related to NeuroSEED, enables to apply the framework to a wider set of problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loss function</head><p>The simplest way to train a NeuroSEED encoder is to directly minimise the MSE between the sequences' distance and its approximation as the distance between the embeddings:</p><formula xml:id="formula_0">L(θ, S) = s1,s2∈S (D(s 1 , s 2 ) − α d(f θ (s 1 ), f θ (s 2 ))) 2<label>(1)</label></formula><p>where α is a constant or learnable scalar. Depending on the application that the learned embeddings are used for, the MSE loss may be combined or substituted with other loss functions such as the triplet loss for closest string retrieval (Appendix F), the relaxation of Dasgupta's cost for hierarchical clustering (Section 7.1) or the sequence reconstruction loss for multiple sequence alignment (Section 7.2).</p><p>There are at least five previous works <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref> that have used approaches that can be described using the NeuroSEED framework. These methods, summarised in Table <ref type="table" target="#tab_0">1</ref>, show the potential of approaches based on the idea of NeuroSEED, but share two significant limitations. The first is the lack of analysis of the geometry of the embedding space, which we show to be critical. The second is that the range of tasks is limited to edit distance approximation (EDA) and closest string retrieval (CSR). We highlight how this framework has the flexibility to be adapted to significantly more complex tasks involving relations between multiple sequences such as hierarchical clustering and multiple sequence alignment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related work</head><p>Hyperbolic embeddings Hyperbolic geometry is a non-Euclidean geometry with constant negative sectional curvature and is often referred to as a continuous version of a tree for its ability to embed trees with arbitrarily low distortion. The advantages of mapping objects with implicit or explicit hierarchical structure in the hyperbolic space have also been shown in other domains <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b9">10]</ref>. In comparison, this work deals with a very different space defined by the edit distance in biological sequences and, unlike most of the previous works, we do not only derive embeddings for a particular set of datapoints, but train an encoder to map arbitrary sequences from the domain in the space.</p><p>Sequence Distance Embeddings The clear advantage of working in more computationally tractable spaces has motivated significant research in Sequence Distance Embeddings <ref type="bibr" target="#b32">[33]</ref> (also known as low-distortion embeddings) approaches to variants of the edit distance <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40]</ref>. However, they are all data-independent and have shown weak performance on the 'unconstrained' edit distance.</p><p>Hashing and metric learning NeuroSEED also fits well into the wider research on learning to hash <ref type="bibr" target="#b40">[41]</ref>, where the goal is typically to map a high dimensional vector space into a smaller one preserving distances. Another field related to NeuroSEED is metric learning <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref>, where models are trained to learn embeddings from examples of similar and dissimilar pairs.</p><p>Locality-sensitive hashing Finally, the work presented is complementary to the line of research in locality-sensitive hashing methods. Researchers have developed a series of heuristics especially for the tasks of sequence clustering <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b44">45]</ref> and local alignment <ref type="bibr" target="#b45">[46]</ref>. These use as subroutines embeddings/features based on alignment-based or alignment-free methods, and therefore, fall into the limitations we highlight in the paper. Future work could analyse how to improve these heuristics with NeuroSEED embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Edit distance approximation</head><p>In this section we test<ref type="foot" target="#foot_0">2</ref> the performance of different encoder models and distance functions to preserve an approximation of the edit distance in the NeuroSEED framework trained with the MSE loss. To make the results more interpretable and comparable across datasets, we report results using % RMSE:</p><formula xml:id="formula_1">% RMSE(θ, S) = 100 n L(θ, S) = 100 n s1,s2∈S (ED(s 1 , s 2 ) − n d(f θ (s 1 ), f θ (s 2 ))) 2 (2)</formula><p>where n is the maximum sequence length. This can be interpreted as an approximate average error in the distance prediction as a percentage of the size of the sequences. The baselines CNN and GRU correspond, therefore, with <ref type="bibr" target="#b25">[26]</ref> and <ref type="bibr" target="#b24">[25]</ref>. The training and inference time comparisons provided in the Greengenes dataset are shown for a set of 5k sequences and were all run on a CPU (Intel Core i7) with the exception of the neural models' training that was run on GPU (GeForce GTX TITAN Xp). The distance function used does not significantly impact the runtime of any of the models. In all the tables: T. stands for transformer, -indicates that is not applicable or the model did not converge, bold the best results and the green-to-white colour scale the range of results best-to-worst. Full results for every geometry can be found in Figure <ref type="figure" target="#fig_0">10</ref> in Appendix E. Data-dependent vs data-independent methods Figures <ref type="figure" target="#fig_1">2 and 3</ref> show that, across the datasets and the distance functions, the data-dependent models learn significantly better representations than data-independent baselines. The main reason for this is their ability to focus on and dedicate the embedding space to a manifold of much lower dimensionality than the complete string space. This observation is further supported by the results in Appendix E, where the same models are trained on synthetic random sequences and the data-independent baselines are able to better generalise.</p><p>Our analysis also confirms the results from Zheng et al. <ref type="bibr" target="#b10">[11]</ref> and Dai et al. <ref type="bibr" target="#b25">[26]</ref> which showed that convolutional models outperform feedforward and recurrent models. We also show that transformers, even when with local attention, produce, in many cases, better representations. Attention could provide significant advantages when considering more complex definitions of distance that include, for example, inversions <ref type="bibr" target="#b46">[47]</ref>, duplications and transpositions <ref type="bibr" target="#b47">[48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyperbolic space</head><p>The most interesting and novel results come from the analysis of the geometry of the embedding space. In these biological datasets, there is an implicit hierarchical structure that is well reflected by the hyperbolic space. Thanks to this close correspondence even relatively simple models perform very well with the hyperbolic distance. In convolutional models, the hyperbolic space provides a 22% average RMSE reduction against the best competing geometry for each model. The benefit of using the hyperbolic space is clear when analysing the dimension required (Figure <ref type="figure" target="#fig_2">4</ref>). The hyperbolic space provides significantly more efficient embeddings, with the model reaching the 'elbow' at dimension 32 and matching the performance of the other spaces with dimension 128 with only 4 to 16. Given that the space to store the embeddings and the time to compute distances between them scale linearly with the dimension, this provides a significant improvement in downstream tasks over other NeuroSEED approaches.</p><p>Running time The computational complexity of approximating the pairwise distance matrix <ref type="foot" target="#foot_1">3</ref> for N sequences of length M is reduced from O(N 2 M 2 / log M ) to O(N (M + N )) assuming constant embedding size and a model linear with respect to the sequence length. This translates into a very significant runtime improvement even when comparing only 5000 sequences, as can be seen from the last column in Figure <ref type="figure">2</ref>. Moreover, while the training takes longer than the baselines due to the more complex optimisation, in applications such as microbiome analysis, biologists typically analyse data coming from the same distribution (e.g. the 16S rRNA gene) for multiple individuals, therefore the initial cost would be significantly amortised.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Unsupervised heuristics</head><p>In this section, we show how competitive heuristics for hierarchical clustering and multiple sequence alignment can be built on the low-distortion embeddings produced by the models trained in the previous section.</p><p>Hierarchical clustering Agglomerative clustering, the most commonly used class of HC algorithms, can be accelerated when run directly on NeuroSEED embeddings produced by the pretrained model. This reduces the complexity to generate the pairwise distance matrix from O(N 2 M 2 / log M ) to O(N (M + N )) and allows to accelerate the clustering itself using geometric optimisations like locality-sensitive hashing.</p><p>We test models with no further tuning from Section 5 on a dataset of 10k unseen sequences from the Qiita dataset. The results (Figure <ref type="figure" target="#fig_3">5</ref>) show that there is no statistical difference in the quality of the hierarchical clustering produced with ground truth distances compared to that with convolutional or attention hyperbolic NeuroSEED embeddings. Instead, the difference in Dasgupta's cost between different architectures and geometries is statistically significant and it results in a large performance gap when these trees are used for tasks such as MSA shown below. The total CPU time taken to construct the tree is reduced from more than 30 minutes to less than one in this dataset and the difference gets significantly larger when scaling to datasets of more and longer sequences.  Multiple sequence alignment Clustal, the most popular MSA heuristic, is formed by a phylogenetic tree estimation phase that produces a guide tree then used by a progressive alignment phase to compute the complete alignment. However, the first of the two phases, based on hierarchical clustering, is typically the bottleneck of the algorithm. On 1200 RT988 sequences (used below), the construction of the guide tree takes 35 minutes compared to 24s for the progressive alignment. Therefore, it can be significantly accelerated using NeuroSEED heuristics to generate matrix and guide tree. In these experiments, we construct the tree running the Neighbour Joining algorithm (NJ) <ref type="bibr" target="#b48">[49]</ref> on the NeuroSEED embeddings and then pass it on the Clustal command-line routine that performs the alignment and returns an alignment score.</p><p>Again, the results reported in Figure <ref type="figure" target="#fig_4">6</ref> show that the alignment scores obtained when using the NeuroSEED heuristics with attention models are not statistically different from those obtained with the ground truth distances. Most of the models also show a relatively large variance in performance across different runs. This has positive and negative consequences: the alignment obtained using a single run may not be very accurate, but, by training an ensemble of models and applying each of them, we are likely to obtain a significantly better alignment than the baseline while still only taking a fraction of the time.  returned by Clustal when using the heuristics to generate the tree as opposed to its default setting using NJ on real distances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Supervised heuristics</head><p>In this section we propose and evaluate two methods to adapt NeuroSEED to the tasks of hierarchical clustering and multiple sequence alignment with tailored loss functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Relaxed approach to hierarchical clustering</head><p>An alternative approach to hierarchical clustering uses the continuous relaxation <ref type="bibr" target="#b19">[20]</ref> of Dasgupta's cost <ref type="bibr" target="#b16">[17]</ref> as loss function to embed sequences in the hyperbolic space (for more details see Appendix B.2 and <ref type="bibr" target="#b19">[20]</ref>). In comparison to Chami et al. <ref type="bibr" target="#b19">[20]</ref>, we show that it is possible to significantly decrease the number of pairwise distances required by directly mapping the sequences into the space. This allows to considerably accelerate the construction, especially when dealing with a large number of sequences without requiring any pretrained model. Figure <ref type="figure" target="#fig_0">1</ref> shows an example of the relaxed approach when applied to a small dataset of proteins. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Qiita dataset</head><p>Figure <ref type="figure">7</ref>: Average Dasgupta's cost of the various approaches with respect to the number of pairwise distances used in the RT988 and Qiita datasets. The performances are reported as the percentage increase in cost compared to the one of the Average Linkage (best performing). Embedding refers to the baseline <ref type="bibr" target="#b19">[20]</ref> while Linear to the relaxed NeuroSEED approach. The attached number represents the dimension of the hyperbolic space used.</p><p>The results, plotted in Figure <ref type="figure">7</ref>, show that a simple linear layer mapping sequences to the hyperbolic space is capable of obtaining with only N pairwise distances very similar results to those from agglomerative clustering (N 2 distances) and hyperbolic embedding baselines (N √ N distances). In the RT988 dataset this corresponds to, respectively, 6700x and 82x fewer labels and leads to a reduction of the total running time from several hours (&gt;2.5h on CPU for agglomerative clustering, 1-4h on GPU for hyperbolic embeddings) to less than 10 minutes on CPU for the relaxed NeuroSEED approach (including label generation, training and tree inference) with no pretraining required. Finally, using more complex encoding architectures such as MLPs or CNNs does not provide significant improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Steiner string approach to multiple sequence alignment</head><p>An alternative approach to multiple sequence alignment uses a decoder from the vector space to convert the Steiner string approximation problem (Appendix B.3) in a continuous optimisation task. This method, summarised in Figure <ref type="figure" target="#fig_5">8</ref> and detailed in Appendix G, consists of training an autoencoder to map sequences to and from a continuous space preserving distances using only pairs of sequence at a time (where calculating the distance is feasible). This is achieved by combining in the loss function a component for the latent space edit distance approximation and one for the reconstruction accuracy of the decoder. The first is expressed as the MSE between the edit distance and the vector distance in the latent space. The second consists of the mean element-wise cross-entropy loss of the decoder's outputs with the real sequences. At test time the encoder embeds all the sequences in the set, the geometric median point (minimising the sum of distances in the embedding space) is found with a relatively simple optimisation procedure and then the decoder is used to find an approximation of the Steiner string. During training, Gaussian noise is added to the embedded point in the latent space forcing the decoder to be robust to points not directly produced by the encoder. As baselines, we report the average consensus error (average distance to the strings in the set) obtained using: a random sequence in the set (random), the centre string of the set (centre) and two competitive greedy heuristics (greedy-1 and greedy-2) proposed respectively by <ref type="bibr" target="#b49">[50]</ref> and <ref type="bibr" target="#b50">[51]</ref>.  The results show that the models consistently outperform the centre string baseline and are close to the performance of the greedy heuristics suggesting that they are effectively decoding useful information from the embedding space. The computational complexity for N strings of size M is reduced from O(N 2 M 2 / log M ) for the centre string and O(N 2 M ) for the greedy baselines to O(N M ) for the proposed method. Future work could employ models that directly operate in the hyperbolic space <ref type="bibr" target="#b51">[52]</ref> to further improve the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In this work, we proposed and explored Neural Distance Embeddings, a framework that exploits the recent advances in representation learning to embed biological sequences in geometric vector spaces. By studying the capacity to approximate the evolutionary edit distance between sequences, we showed the strong advantage provided by the hyperbolic space which reflects the biological hierarchical structure.</p><p>We then demonstrated the effectiveness and wide applicability of NeuroSEED on the problems of hierarchical clustering and multiple sequence alignment. For each task, we experimented with two different approaches: one unsupervised tying NeuroSEED embeddings into existing heuristics and a second based on direct exploitation of the geometry of the embedding space via a tailored loss function. In all cases, the proposed approach performed on par with or better than existing baselines while being significantly faster.</p><p>Finally, NeuroSEED provides representations that are well suited for human interaction as the embeddings produced can be visualised and easily interpreted. Towards this goal, the very compact representation of hyperbolic spaces is of critical importance <ref type="bibr" target="#b9">[10]</ref>. This work also opens many opportunities for future research direction with different types of sequences, labels, architectures and tasks. We present and motivate these directions in Appendix A.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: On the left, the key idea of NeuroSEED: learn an encoder function f θ that preserves distances between the sequence and vector space (D and d). The vector space can then be used to study the relationship between sequences and, potentially, decode new ones (see Section 7.2). On the right, an example of the hierarchical clustering produced on the Poincaré disk. The data was downloaded from UniProt<ref type="bibr" target="#b13">[14]</ref> and consists of the P53 tumour protein from 20 different organisms.</figDesc><graphic url="image-1.png" coords="2,327.72,85.85,158.12,157.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Qualitative comparison in the Qiita dataset between the best performing baseline (5-mer with cosine distance) and the CNN in the Euclidean and hyperbolic space. For every test set sequence pair, predicted vs real distances are plotted, the darkness represents the density of points. The CNN model follows much more tightly the red line of the oracle across the whole range of distances in the hyperbolic space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Edit distance approximation % RMSE on Qiita dataset for a global transformer with different distance functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Average Linkage % increase in Dasgupta's cost of NeuroSEED models compared to the performance of clustering on the ground truth distances, ubiquitously used in bioinformatics. Average Linkage was the best performing clustering heuristic across all models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure6: Percentage improvement (average of 3 runs) in the alignment cost (the lower the better) returned by Clustal when using the heuristics to generate the tree as opposed to its default setting using NJ on real distances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Figure8: Diagram for the Steiner string approach to multiple sequence alignment. On the left, the training procedure using pairs of sequences and a loss combining edit distance approximation and sequence reconstruction. On the right the extrapolation for the generation of the Steiner string by decoding the geometric median in the embedding space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Average consensus error for the baselines (left) and NeuroSEED models (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Summary of the previous and the proposed NeuroSEED approaches. EDA stands for edit distance approximation and CSR for closest string retrievals. For our experiments, in the columns geometry and encoder we report those that performed best among the ones tested.</figDesc><table><row><cell>Method</cell><cell>Geometry</cell><cell>Encoder</cell><cell>Decoder</cell><cell>Loss</cell><cell>Tasks</cell></row><row><cell>Zheng et al. [11]</cell><cell>Jaccard</cell><cell>CNN</cell><cell></cell><cell>MSE</cell><cell>EDA</cell></row><row><cell>Chen et al. [24]</cell><cell>Cosine</cell><cell>CSM</cell><cell></cell><cell>MSE</cell><cell>EDA</cell></row><row><cell>Zhang et al. [25]</cell><cell>Euclidean</cell><cell>GRU</cell><cell></cell><cell>MAE + triplet</cell><cell>EDA &amp; CSR</cell></row><row><cell>Dai et al. [26]</cell><cell>Euclidean</cell><cell>CNN</cell><cell></cell><cell>MAE + triplet</cell><cell>EDA &amp; CSR</cell></row><row><cell>Gomez et al. [27]</cell><cell>Square</cell><cell>CNN</cell><cell></cell><cell>MSE</cell><cell>EDA &amp; CSR</cell></row><row><cell>Section 5</cell><cell cols="2">Hyperbolic CNN &amp; transformer</cell><cell></cell><cell>MSE</cell><cell>EDA</cell></row><row><cell>Section 6</cell><cell cols="2">Hyperbolic CNN &amp; transformer</cell><cell></cell><cell>MSE</cell><cell>HC &amp; MSA</cell></row><row><cell>Section 7.1</cell><cell>Hyperbolic</cell><cell>Linear</cell><cell></cell><cell>Relaxed Dasgupta</cell><cell>HC</cell></row><row><cell>Section 7.2</cell><cell>Cosine</cell><cell>Linear</cell><cell></cell><cell>MSE + reconstr.</cell><cell>MSA</cell></row><row><cell>Appendix F</cell><cell cols="2">Hyperbolic CNN &amp; transformer</cell><cell></cell><cell>MSE &amp; triplet</cell><cell>CSR</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">Code, datasets and tuned hyperparameters can be found at https://github.com/gcorso/NeuroSEED.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">Computing the pairwise distance matrix of a set of sequences is a critical step of many algorithms including the ones analysed in the next section.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors thank Saro Passaro for his insightful comments and suggestions and Frank Stajano, Andrei Margeloiu, Hannes Stärk and Cristian Bodnar their review of the manuscript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Disclosure of Funding</head><p>G.C. is funded by the Robert Shillman (1974) Fellowship at MIT. P.V. is a Research Scientist at DeepMind. J.L. is a Chan Zuckerberg Biohub investigator. We also gratefully acknowledge the support of DARPA under Nos. HR00112190039 (TAMI), N660011924033 (MCS); ARO under Nos. W911NF-16-1-0342 (MURI), W911NF-16-1-0171 (DURIP); NSF under Nos. OAC-1835598 (CINES), OAC-1934578 (HDR), CCF-1918940 (Expeditions), IIS-2030477 (RAPID), NIH under No. R56LM013365; Stanford Data Science Initiative, Wu Tsai Neurosciences Institute, Chan Zuckerberg Biohub, Amazon, JPMorgan Chase, Docomo, Hitachi, Intel, JD.com, KDDI, NVIDIA, Dell, Toshiba, Visa, and UnitedHealth Group.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Large-scale analyses of human microbiomes reveal thousands of small, novel genes</title>
		<author>
			<persName><forename type="first">Hila</forename><surname>Sberro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumaya</forename><surname>Brayon J Fremin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fredrik</forename><surname>Zlitni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Edfors</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">P</forename><surname>Greenfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><forename type="middle">A</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><forename type="middle">C</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ami</forename><forename type="middle">S</forename><surname>Kyrpides</surname></persName>
		</author>
		<author>
			<persName><surname>Bhatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Large-scale genome-wide analysis links lactic acid bacteria from food with the gut microbiome</title>
		<author>
			<persName><forename type="first">Edoardo</forename><surname>Pasolli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><forename type="middle">De</forename><surname>Filippis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Italia</forename><forename type="middle">E</forename><surname>Mauriello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Cumbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">M</forename><surname>Walsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Leech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">D</forename><surname>Cotter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Segata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Ercolini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Large-scale association analyses identify host factors influencing human gut microbiome composition</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kurilshikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolina</forename><surname>Medina-Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Bacigalupe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Djawad</forename><surname>Radjabzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayse</forename><surname>Demirkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Antonio Raygoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Casey</forename><forename type="middle">T</forename><surname>Garay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingrong</forename><surname>Finnicum</surname></persName>
		</author>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Genetics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A general method applicable to the search for similarities in the amino acid sequence of two proteins</title>
		<author>
			<persName><forename type="first">Christian</forename><forename type="middle">D</forename><surname>Saul B Needleman</surname></persName>
		</author>
		<author>
			<persName><surname>Wunsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of molecular biology</title>
		<imprint>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dinucleotide relative abundance extremes: a genomic signature</title>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Kariin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Burge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in genetics</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A statistical method for evaluating systematic relationships</title>
		<author>
			<persName><surname>Robert R Sokal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Univ. Kansas, Sci. Bull</title>
		<imprint>
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multiple sequence alignment with the Clustal series of programs</title>
		<author>
			<persName><forename type="first">Ramu</forename><surname>Chenna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hideaki</forename><surname>Sugawara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tadashi</forename><surname>Koike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toby</forename><forename type="middle">J</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Desmond</forename><forename type="middle">G</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><forename type="middle">D</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A robust nonlinear low-dimensional manifold for single cell rna-seq data</title>
		<author>
			<persName><forename type="first">Archit</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbara</forename><forename type="middle">E</forename><surname>Engelhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Low-dimensional representation of biological sequence data</title>
		<author>
			<persName><surname>Richard C Tillquist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics</title>
				<meeting>the 10th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Poincaré maps for analyzing complex hierarchies in single-cell data</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Klimovskaia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">SENSE: Siamese neural network for sequence embedding and alignment-free comparison</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Genco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Wactawski-Wende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yijun</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural edit operations for biological sequences</title>
		<author>
			<persName><forename type="first">Satoshi</forename><surname>Koide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keisuke</forename><surname>Kawano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Takuro</forename><surname>Kutsuna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Rethinking relational encoding in language model: Pre-training for general sequences</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Yap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.10334</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Uniprot: a hub for protein information</title>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A metric model of amino acid substitution</title>
		<author>
			<persName><forename type="first">Weijia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">P</forename><surname>Miranker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Alignment-free genome comparison with feature frequency profiles (FFP) and optimal resolutions</title>
		<author>
			<persName><forename type="first">Se-Ran</forename><surname>Gregory E Sims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guohong</forename><forename type="middle">A</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sung-Hou</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Proceedings of the National Academy of Sciences</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A cost function for similarity-based hierarchical clustering</title>
		<author>
			<persName><forename type="first">Sanjoy</forename><surname>Dasgupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annual ACM SIGACT Symposium on Theory of Computing</title>
				<meeting>Annual ACM SIGACT Symposium on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sur la liaison et la division des points d&apos;un ensemble fini</title>
		<author>
			<persName><forename type="first">Kazimierz</forename><surname>Florek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Łukaszewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Perkal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Steinhaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Zubrzycki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Colloquium mathematicum</title>
				<imprint>
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A method of establishing groups of equal amplitude in plant sociology based on similarity of species content and its application to analyses of the vegetation on Danish commons</title>
		<author>
			<persName><forename type="first">Thorvald</forename><surname>Julius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sørensen</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">From trees to continuous embeddings and back: Hyperbolic hierarchical clustering</title>
		<author>
			<persName><forename type="first">Ines</forename><surname>Chami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaggos</forename><surname>Chatziafratis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Óscar Noya-Alarcón, et al. The microbiome of uncontacted amerindians</title>
		<author>
			<persName><forename type="first">Erica</forename><forename type="middle">C</forename><surname>Jose C Clemente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">J</forename><surname>Pehrsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuldip</forename><surname>Blaser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhan</forename><surname>Sandhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magda</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glida</forename><surname>Magris</surname></persName>
		</author>
		<author>
			<persName><surname>Hidalgo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science advances</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Miseq: a next generation sequencing platform for genomic analysis. Disease gene identification</title>
		<author>
			<persName><forename type="first">Rupesh</forename><surname>Kanchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravi</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Kendra</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahdieh</forename><surname>Khosroheidari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An improved greengenes taxonomy with explicit ranks for ecological and evolutionary analyses of bacteria and archaea</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><forename type="middle">N</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Nawrocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">Z</forename><surname>Desantis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Probst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Gary L Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><surname>Hugenholtz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The ISME journal</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Predicting alignment distances via continuous sequence matching</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yijun</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Neural embeddings for nearest neighbor search under edit distance</title>
		<author>
			<persName><forename type="first">Xiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Indyk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Convolutional embedding for edit distance</title>
		<author>
			<persName><forename type="first">Xinyan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiwen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR</title>
				<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Lsde: Levenshtein space deep embedding for query-by-string word spotting</title>
		<author>
			<persName><forename type="first">Lluís</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marçal</forename><surname>Rusinol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimosthenis</forename><surname>Karatzas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDAR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
				<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.08039</idno>
		<title level="m">Poincaré embeddings for learning hierarchical representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Paul Chamberlain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deisenroth</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10359</idno>
		<title level="m">Neural embeddings of graphs in hyperbolic space</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Low-dimensional hyperbolic knowledge graph embeddings</title>
		<author>
			<persName><forename type="first">Ines</forename><surname>Chami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adva</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da-Cheng</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederic</forename><surname>Sala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sujith</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
				<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Sequence distance embeddings</title>
		<author>
			<persName><forename type="first">Graham</forename><surname>Cormode</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Warwick</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Approximate nearest neighbors and sequence comparison with block operations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Süleyman Cenk</forename><surname>Sahinalp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. annual ACM symposium on Theory of computing</title>
				<meeting>annual ACM symposium on Theory of computing</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Permutation editing and matching via embeddings</title>
		<author>
			<persName><forename type="first">Graham</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shan</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Süleyman Cenk</forename><surname>Sahinalp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Colloquium on Automata, Languages, and Programming</title>
				<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Low distortion embeddings for edit distance</title>
		<author>
			<persName><forename type="first">Rafail</forename><surname>Ostrovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Rabani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Oblivious string embeddings and edit distance approximations</title>
		<author>
			<persName><forename type="first">Tugkan</forename><surname>Batu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Funda</forename><surname>Ergun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cenk</forename><surname>Sahinalp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SODA</title>
				<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Efficient communication protocols for deciding edit distance</title>
		<author>
			<persName><forename type="first">Hossein</forename><surname>Jowhari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Symposium on Algorithms</title>
				<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Approximating edit distance in near-linear time</title>
		<author>
			<persName><forename type="first">Alexandr</forename><surname>Andoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krzysztof</forename><surname>Onak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Streaming algorithms for embedding and computing edit distance in the low distance regime</title>
		<author>
			<persName><forename type="first">Diptarka</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elazar</forename><surname>Goldenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michal</forename><surname>Koucký</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of STOC</title>
				<meeting>of STOC</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">A survey on learning to hash</title>
		<author>
			<persName><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName><surname>Heng Tao Shen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Metric learning: A survey. Foundations and trends in machine learning</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Kulis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">A survey on metric learning for feature vectors and structured data</title>
		<author>
			<persName><forename type="first">Aurélien</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amaury</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Sebban</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.6709</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences</title>
		<author>
			<persName><forename type="first">Weizhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Godzik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Clustering huge protein sequence sets in linear time</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Steinegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Söding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Basic local alignment search tool</title>
		<author>
			<persName><forename type="first">Warren</forename><surname>Stephen F Altschul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Webb</forename><surname>Gish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><forename type="middle">W</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of molecular biology</title>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Inversions in the chromosomes of Drosophila pseudoobscura</title>
		<author>
			<persName><forename type="first">Th</forename><surname>Dobzhansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alfred</forename><forename type="middle">H</forename><surname>Sturtevant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<date type="published" when="1938">1938</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Computational molecular biology: an algorithmic approach</title>
		<author>
			<persName><forename type="first">Pavel</forename><surname>Pevzner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The neighbor-joining method: a new method for reconstructing phylogenetic trees</title>
		<author>
			<persName><forename type="first">Naruya</forename><surname>Saitou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masatoshi</forename><surname>Nei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Molecular biology and evolution</title>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Improved greedy algorithm for computing approximate median strings</title>
		<author>
			<persName><forename type="first">Ferenc</forename><surname>Kruzslicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Cybernetica</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A greedy algorithm for computing approximate median strings</title>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Casacuberta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of National Symposium on Pattern Recognition and Image Analysis</title>
				<meeting>of National Symposium on Pattern Recognition and Image Analysis</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">Wei</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tuomas</forename><surname>Varanka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdelrahman</forename><surname>Mostafa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henglin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoying</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.04562</idno>
		<title level="m">Hyperbolic deep neural networks: A survey</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning mixed-curvature representations in product spaces</title>
		<author>
			<persName><forename type="first">Albert</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederic</forename><surname>Sala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beliz</forename><surname>Gunel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
				<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Mixed-curvature variational autoencoders</title>
		<author>
			<persName><forename type="first">Ondrej</forename><surname>Skopek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Octavian-Eugen</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><surname>Bécigneul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
				<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Hyperbolic neural networks</title>
		<author>
			<persName><forename type="first">Octavian-Eugen</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><surname>Bécigneul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Hyperbolic graph convolutional neural networks</title>
		<author>
			<persName><forename type="first">Ines</forename><surname>Chami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Geometric deep learning: going beyond Euclidean data</title>
		<author>
			<persName><forename type="first">Joan</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><surname>Vandergheynst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>IEEE Signal Processing Magazine</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Geometric deep learning: Grids, groups, graphs, geodesics, and gauges</title>
		<author>
			<persName><forename type="first">M</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taco</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petar</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><surname>Veličković</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Algorithms on stings, trees, and sequences: Computer science and computational biology</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Gusfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Sigact News</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Bioinformatics algorithms: an active learning approach</title>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Compeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Pevzner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A faster algorithm computing string edit distances</title>
		<author>
			<persName><forename type="first">J</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName><surname>Masek</surname></persName>
		</author>
		<author>
			<persName><surname>Michael S Paterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System sciences</title>
		<imprint>
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Edit distance cannot be computed in strongly subquadratic time (unless SETH is false)</title>
		<author>
			<persName><forename type="first">Arturs</forename><surname>Backurs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Indyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of STOC</title>
				<meeting>of STOC</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">The average common substring approach to phylogenomic reconstruction</title>
		<author>
			<persName><forename type="first">Igor</forename><surname>Ulitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Burstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamir</forename><surname>Tuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benny</forename><surname>Chor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Biology</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Kmacs: the k-mismatch average common substring approach to alignment-free sequence comparison</title>
		<author>
			<persName><forename type="first">Chris-Andre</forename><surname>Leimeister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Burkhard</forename><surname>Morgenstern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">On the complexity of multiple sequence alignment</title>
		<author>
			<persName><forename type="first">Lusheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational biology</title>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">MUSCLE: multiple sequence alignment with high accuracy and high throughput</title>
		<author>
			<persName><forename type="first">Edgar</forename><surname>Robert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The journal of machine learning research</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
				<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lei Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Ryan Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
				<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Deep metric learning using triplet network</title>
		<author>
			<persName><forename type="first">Elad</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nir</forename><surname>Ailon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International workshop on similarity-based pattern recognition</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Learning local feature descriptors with triplets and shallow convolutional neural networks</title>
		<author>
			<persName><forename type="first">Vassileios</forename><surname>Balntas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edgar</forename><surname>Riba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ponsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krystian</forename><surname>Mikolajczyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of BMVC</title>
				<meeting>of BMVC</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
				<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Continuous hierarchical representations with Poincaré variational auto-encoders</title>
		<author>
			<persName><forename type="first">Emile</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charline</forename><forename type="middle">Le</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryota</forename><surname>Tomioka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A direct search optimization method that models the objective and constraint functions by linear interpolation</title>
		<author>
			<persName><forename type="first">Powell</forename><surname>Michael</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in optimization and numerical analysis</title>
				<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">The convergence of a class of double-rank minimization algorithms 1. general considerations</title>
		<author>
			<persName><forename type="first">Charles</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Broyden</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IMA Journal of Applied Mathematics</title>
		<imprint>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">A new approach to variable metric algorithms</title>
		<author>
			<persName><forename type="first">Roger</forename><surname>Fletcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The computer journal</title>
		<imprint>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">A family of variable-metric methods derived by variational means. Mathematics of computation</title>
		<author>
			<persName><forename type="first">Donald</forename><surname>Goldfarb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Conditioning of quasi-newton methods for function minimization</title>
		<author>
			<persName><surname>David F Shanno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematics of computation</title>
				<imprint>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Scipy 1.0: fundamental algorithms for scientific computing in Python</title>
		<author>
			<persName><forename type="first">Pauli</forename><surname>Virtanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Gommers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Travis</forename><forename type="middle">E</forename><surname>Oliphant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Haberland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyler</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evgeni</forename><surname>Burovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pearu</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Warren</forename><surname>Weckesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Bright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature methods</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
