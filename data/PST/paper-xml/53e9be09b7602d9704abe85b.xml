<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Space-Code Bloom Filter for Efficient Per-Flow Traffic Measurement</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
							<email>akumar@cc.gatech.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computing Georgia Institute of Technology Atlanta</orgName>
								<address>
									<postCode>30332-0280</postCode>
									<country key="GE">Georgia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jim</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computing Georgia Institute of Technology Atlanta</orgName>
								<address>
									<postCode>30332-0280</postCode>
									<country key="GE">Georgia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jia</forename><surname>Wang</surname></persName>
							<email>jiawang@research.att.com</email>
						</author>
						<author>
							<persName><forename type="first">Oliver</forename><surname>Spatschek</surname></persName>
							<email>spatsch@research.att.com</email>
						</author>
						<author>
							<persName><roleName>Erran</roleName><forename type="first">Li</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">Bell Labs Lucent Technologies Holmdel</orgName>
								<address>
									<postCode>07733-3030</postCode>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Ý AT&amp;T Labs -Research Florham Park</orgName>
								<address>
									<postCode>07932-0971</postCode>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Space-Code Bloom Filter for Efficient Per-Flow Traffic Measurement</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7EA734C997109A570572FCCB7E75F8C1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Network Measurement</term>
					<term>Traffic Analysis</term>
					<term>Data Structures</term>
					<term>Statistical Inference</term>
					<term>Bloom Filter</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Per-flow traffic measurement is critical for usage accounting, traffic engineering, and anomaly detection. Previous methodologies are either based on random sampling (e.g., Cisco's NetFlow), which is inaccurate, or only account for the "elephants". We introduce a novel technique for measuring perflow traffic approximately, for all flows regardless of their sizes, at very high-speed (say, OC768). The core of this technique is a novel data structure called Space Code Bloom Filter (SCBF). A SCBF is an approximate representation of a multiset; each element in this multiset is a traffic flow and its multiplicity is the number of packets in the flow. The multiplicity of an element in the multiset represented by SCBF can be estimated through either of two mechanisms -Maximum Likelihood Estimation (MLE) or Mean Value Estimation (MVE). Through parameter tuning, SCBF allows for graceful tradeoff between measurement accuracy and computational and storage complexity. SCBF also contributes to the foundation of data streaming by introducing a new paradigm called blind streaming. We evaluate the performance of SCBF through mathematical analysis and through experiments on packet traces gathered from a tier-1 ISP backbone. Our results demonstrate that SCBF achieves reasonable measurement accuracy with very low storage and computational complexity.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Accurate traffic measurement and monitoring is critical for network management. For example, per-flow traffic accounting has applications in usage-based charging/pricing, network anomaly detection, security, and traffic engineering <ref type="bibr" target="#b0">[1]</ref>. While there has been considerable research on characterizing the statistical distribution of per-flow traffic <ref type="bibr">[2]</ref> or on identifying and measuring a few large flows (elephants) <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[3]</ref>, <ref type="bibr" target="#b2">[4]</ref>, little work has been done on investigating highly efficient algorithms and data structures to facilitate per-flow measurement on very high-speed links.</p><p>To fill this gap, we propose a novel data structure called Space-Code Bloom Filter (SCBF) and explore its applications to network measurement in general, and to per-flow traffic accounting in particular. A (traditional) bloom filter <ref type="bibr" target="#b3">[5]</ref> is an approximate representation of a set Ë, which given an arbitrary This work was supported in part by the National Science Foundation under Grant ITR/SY ANI-0113933 and under NSF CAREER Award Grant ANI-0238315. element Ü, allows for the membership query "Ü ¾ Ë?". A Space-Code Bloom Filter (SCBF), on the other hand, is an approximate representation of a multiset Å, which allows for the query "how many occurrences of Ü are there in Å?". Just as a bloom filter achieves a nice tradeoff between space efficiency (bits per element) and the ratio of false positives, SCBF achieves a nice tradeoff between the accuracy of counting and the number of bits used for counting.</p><p>SCBF has several important applications in network measurement. This paper focuses on its application to performing "per-flow" traffic accounting without per flow state on a highspeed link. Given a flow identifier, SCBF returns the estimated number of packets in the flow during a measurement epoch.</p><p>Here, a flow identifier can be an IP address, a source and destination IP address pair, the combination of IP addresses and port numbers, or other attributes that can identify a flow.</p><p>Per-flow accounting is a challenging task on high-speed network links. While keeping per-flow state would make accounting straightforward, it is not desirable since such a large state will only fit on DRAM and the DRAM speed can not keep up with the rate of a high-speed link. While random sampling, such as used in Cisco Netflow, reduces the requirement on memory speed, it introduces excessive measurement errors for flows other than elephants, as shown in Section II.</p><p>Our approach is to perform traffic accounting on a very small amount of high-speed SRAM, organized as an SCBF page. Once an SCBF page becomes full (we formalize this notion later), it is eventually paged to persistent storages such as disks. Later, to find out the traffic volume of a flow identified by a label Ü during a measurement epoch, the SCBF pages corresponding to the epoch can be queried using Ü to provide the approximate answer. The challenges facing this approach are threefold. First, the amount of persistent storage to store SCBF pages cannot be unreasonably large, even for a high-speed link like OC-768 (40 Gbps). Second, the computational complexity of processing each packet needs to be low enough to catch up with the link speed. Third, the accounting needs to be fairly accurate for all the flows, despite the aforementioned storage and complexity constraints.</p><p>SCBF is designed to meet all these challenges. Our design can easily scale to maintaining approximate per-flow counts at an OC-192 <ref type="bibr">(10 Gbps)</ref> or even an OC-768 (40 Gbps) link using a limited amount of fast memory. The storage cost for a fully utilized OC-192 link is tolerable: about 4 bits per packet or 18 GB per hour. Such a cost is manageable for tier-1 ISPs as the storage cost right now is about 1 dollar per GB. In addition, it is very amenable to pipelined hardware implementation to facilitate high-speed processing.</p><p>Conceptually, an SCBF can be thought of as a large number of statistical estimators running in parallel. Each estimator tracks the traffic volume of a certain flow. SCBF nicely codes and compresses the current "readings" of these estimators within a small memory module so that they do not interfere with each other. Like space-time coding allows signals to multiplex on both space and time domains, SCBF allows "signals" to multiplex on both space and code domains, hence the name Space-Code. The demultiplexing operation for obtaining the "reading" of a given flow in an SCBF employs an estimation procedure. We present two alternative estimation mechanisms, Maximum Likelihood Estimation (MLE) and Mean Value Estimation (MVE). We show through careful analysis that the "readings" of all flows will be accurate to a certain ratio with high probability.</p><p>SCBF not only has important applications in network measurement, but also contributes to the foundation of data streaming <ref type="bibr" target="#b2">[4]</ref>, <ref type="bibr" target="#b4">[6]</ref>. Data streaming is concerned with processing a long stream of data items in one pass using a small working memory in order to answer a class of queries regarding the stream. The challenge is to use this small memory to "remember" as much information pertinent to the queries as possible. The contributions of SCBF to data streaming are twofold. First, it is among the earliest work in the networking context <ref type="bibr" target="#b2">[4]</ref>. Although data streaming has emerged as a major field in database <ref type="bibr" target="#b5">[7]</ref>, <ref type="bibr" target="#b4">[6]</ref>, <ref type="bibr" target="#b6">[8]</ref>, the techniques invented in the database context tend to be computationally complex, and thus have limited application to problems in networking. Second, SCBF introduces a new paradigm called blind streaming in which incrementing the reading of an estimator does not require the decoding of its current reading, and hence the blindness. This significantly reduces the computational and hardware implementation complexity of each operation, as discussed in Section II-B.</p><p>The rest of this paper is organized as follows. The next section presents an overview of the architecture of SCBF and introduces the metrics for measuring its performance. We also introduce the paradigm of blind streaming and discuss its impact on our design. Section III describes the design of SCBF in detail. We provide some essential mathematical details of the design of SCBF in Section IV, deferring the rest to the appendix. Section V presents analytical results on the accuracy of SCBF followed by experimental evaluation of a software implementation using packet header traces from a tier-1 ISP IP backbone network. A brief review of related work is presented in Section VI. We conclude in Section VII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. ARCHITECTURE, PERFORMANCE METRICS, AND BLIND STREAMING</head><p>The proposed SCBF scheme is motivated by the need to provide per-flow traffic accounting at very high speed (e.g, OC-768). A naïve solution to this problem would be to maintain per-flow counters that are updated upon every packet arrival. However, as shown in <ref type="bibr" target="#b0">[1]</ref>, this approach cannot scale to the link speed of OC-192 since fast SRAM modules can only hold a tiny fraction of per-flow state due to their size limitations, and large DRAM modules cannot support such speed. Random sampling with a small rate such as 1% may meet the speed requirement for keeping the per-flow state in DRAM. However, such sampling leads to intolerable inaccuracies in network measurement <ref type="bibr" target="#b0">[1]</ref>. In particular, sampling will typically miss the majority of small flows (containing only a few packets). Ignoring these mice altogether may lead to wrong conclusions in applications such as estimation of flow distribution and network anomaly detection. Our vision is to design a synopsis data structure that keeps track of the approximate number of packets in each flow regardless of its size, yet is small enough to fit in fast SRAM. The proposed SCBF scheme is a brainchild of this vision.</p><p>Here we describe the conceptual design of SCBF, deferring its detailed description to Section III. The overall architecture of using SCBF to perform per-flow accounting is shown in Figure <ref type="figure">1</ref>. SCBF is updated upon each packet arrival (arcs 1 and 2 in Figure <ref type="figure">1</ref>) so that it will not fail to record the presence of any flow, small or large. When the SCBF becomes full, it will be paged to persistent storage devices (arc 3). Typically, two alternating SCBF modules will be used so that one can process new packets while the other is being paged, as shown in Figure <ref type="figure">1</ref>. In other words, these two SCBF modules store approximate flow accounting information in alternating measurement epochs. In addition, SCBF succinctly represents a large number of counters so that paging is infrequent enough to fit within the disk bandwidth even for OC-768 link speed. Finally, a query concerning the size of a flow can be made to a SCBF page stored on the disk (arc 4). The result of the query (arc 5) is the approximate number of packets in the flow during the measurement epoch recorded by that SCBF page. The aggregate size of a flow, independent of measurement epochs, can be obtained by taking the sum of flow-size estimates obtained by querying pages corresponding to consecutive epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Performance Metrics</head><p>The key challenge in designing SCBF is to achieve a nice tradeoff between the following three key performance metrics. 1. Storage complexity. This refers to the amount of space consumed on persistent storage to store the SCBF pages. This can be equivalently characterized as the traffic rate between the SCBF module and the disk. Our goal is to make this complexity as small as possible, given a fixed link speed. At least this rate should not exceed the disk bandwidth. We will show that this complexity is manageable even on OC-768 speed since SCBF takes advantage of the "quasi-Zipf Law" of the Internet traffic: a small number of flows contribute to the majority of Internet traffic while the majority of flows are small <ref type="foot" target="#foot_0">1</ref> . 2. Computational complexity. We are also concerned with the number of memory accesses to the SCBF module for each packet. This has to be minimized. We show that on the average, our scheme will incur no more than 5 bits of write per packet to the memory. We will see later that most of these writes overwrite already written bits, thus filling up the SCBF page at a much slower rate. 3. Accuracy of estimation. We would like our estimation of the traffic-volume of individual flows in a measurement epoch to be as close to the actual value as possible. In this work, our goal is constant relative error tolerance, i.e., for the estimate to be within ´½ ¯µ ´½ • ¯µ ℄ with a constant high probability. Here is the actual value of the trafficvolume of a given flow and is our estimate of this value. We present two estimation mechanisms -Maximum Likelihood Estimation (MLE) and Mean value Estimation (MVE) -to achieve this.</p><p>With SCBF, a very high level of accuracy can be achieved if one is willing to incur more complexity in terms of storage and computation. Therefore, there is an inherent tradeoff between the complexities and the accuracy of estimation. This tradeoff can be exploited through the choice of various design parameters, as explained in Section III-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Blind Streaming</head><p>The reader might have noticed that in Figure <ref type="figure">1</ref>, we do not have an arc from the SCBF module to the CPU. One may also wonder whether this is a mistake, since when a new packet arrives, its flow identifier should be used to look up a corresponding entry for update. In fact, SCBF is designed to avoid such a read before update, i.e., the SCBF data structure is write-only! We refer to this feature as blind streaming, in the sense that reading and decoding data in the SCBF is not required before updating it.</p><p>Blind streaming is a new paradigm of data streaming that is especially suitable for high-speed networks for the following reasons. First, in blind streaming, we do not need to deal with the race condition between read and write operations, making a pipelined hardware implementation extremely simple. Note that in traditional data processing, a datum has to be locked after read and unlocked after write to ensure consistency. Second, blind streaming also doubles the streaming speed by eliminating the reading process. The loss of accuracy due to this blindness is tolerable, as we will show in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. DESIGN DETAILS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Space-Code Bloom Filter</head><p>At the core of our scheme lies a novel data structurethe Space-Code Bloom Filter (SCBF). It represents a multiset approximately, extending the capability of a traditional Bloom Filter (BF) to represent a set. Given an element Ü, it not only allows one to check if Ü is in a multiset, but also counts the number of occurrences of Ü. In the following, we describe the design of both BF and SCBF.</p><p>A traditional Bloom filter representing a set Ë Ü ½ Ü ¾ Ü Ò of size Ò is described by an array of Ñ bits, initialized to 0. A Bloom filter uses independent hash functions ½ ¾ with range ½ Ñ . We refer to this set of hash functions as a group. During insertion , given an element Ü to be inserted into a set Ë, the bits</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>´Üµ℄, ½</head><p>, are set to 1. To query for an element Ý, i.e. to check if Ý is in Ë, we check the value of the bits ´Ýµ℄, ½ ¾ . The answer to the query is yes if all these bits are 1, and no otherwise.</p><p>A Bloom filter guarantees not to have any false negatives, i.e., returning "no" even though the set actually contains the element. However, it may contain false positives, i.e., returning "yes" while the element is not in the set. There is a convenient tradeoff between the probability of encountering a false positive and the number of elements the filter tries to hold. It was shown in <ref type="bibr" target="#b3">[5]</ref> that fixing a false positive threshold , the filter can hold the highest number of elements Ò when the parameter is set to around ´ ÐÓ ¾ µ. In this case the completely full filter contains exactly half the bits set to 1, and the other half to 0. We refer to this as the "50% golden rule".</p><p>In a traditional Bloom filter, once an element Ü is inserted, later insertions of Ü will write to the same bits ½ ´Üµ℄ ¾ ´Üµ℄ ¡ ¡ ¡ ´Üµ℄, and will not result in any change to . SCBF, on the other hand, uses a filter made </p><formula xml:id="formula_0">up of Ð groups of hash functions ½ ½ ´Üµ ½ ¾ ´Üµ ¡ ¡ ¡ ½ ´Üµ , ¾ ½ ´Üµ ¾ ¾ ´Üµ ¡ ¡ ¡ ¾ ´Üµ ¡ ¡ ¡ Ð ½ ´Üµ Ð ¾ ´Üµ ¡ ¡ ¡ Ð ´Üµ</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">for(</head><formula xml:id="formula_1">½; Ð; • •) 4.</formula><p>if (bits ½ ´Ýµ℄, ..., ´Ýµ℄ are all 1) 5.</p><p>• ½;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.</head><p>return ×Ø Ñ Ø ´ µ; From an implementation perspective, both MLE and MVE can be implemented as a simple lookup into an estimate table precomputed for all possible values of . Thus each call to ×Ø Ñ Ø ´ µ involves a single lookup into a small table.</p><p>The precomputation of the estimate tables themselves is a computationally intensive procedure but has to be done only once, during the design of the SCBF. We present the theoretical details of MLE and MVE and discuss the precomputation of the estimate tables in Section IV. Although the one-time precomputation of lookup tables is equally involved for both MLE and MVE, we run into precision issues in floating point computation in the case of MLE. Fortunately, these precision problems do not dominate the computation for a range of parameters. Thus we were able to evaluate and compare the levels of accuracy attained by both these mechanisms in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Multi-Resolution Space-Code Bloom Filter</head><p>The distribution of flow-sizes in Internet traffic is known to be heavy-tailed, implying that the potential multiplicity of an element can be very high (i.e. some flows are very large). By the Coupon Collector's problem <ref type="bibr" target="#b7">[9]</ref>, all Ð groups in a SCBF will be used for insertion at least once with high probability after about ´Ð ÐÒ Ðµ copies of Ü are inserted. In other words almost all elements with multiplicities of ´Ð ÐÒ Ðµ or more will match all the Ð groups in an SCBF. For example, in an SCBF with 32 groups of hash functions (Ð ¿¾ Ð ÐÒ Ð ½½½), if 200 copies of Ü are inserted, it is almost certain that all 32 groups will be chosen at least once. Inserting an additional 200 copies of Ü will not change anything as all the 32 groups have already been used. Thus any estimation mechanism will be unable to decide whether the number of copies of Ü inserted in the SCBF was 200 or 400. So, an SCBF with Ð groups is unable to distinguish between multiplicities that are larger than ´Ð ÐÒ Ðµ. Making Ð very large does not solve this problem  become large with larger Ð, and if the actual multiplicity of an element Ý (signal) is small, the noise will overwhelm the signal. Second, the storage efficiency of the scheme worsens as multiple occurrences of an element are spread to a very large space. Our solution to this problem is Multi-Resolution SCBF (MRSCBF). An MRSCBF employs multiple SCBFs (or filters), operating at different resolutions and uses all of them together to cover the entire range of multiplicities. The insertion and query algorithms for MRSCBF are shown in Figure <ref type="figure" target="#fig_1">3</ref>. The insertion algorithm for MRSCBF is a simple extension of that of SCBF. When a packet arrives, it will result in an insertion into each SCBF with a corresponding sampling probability Ô . Suppose there are a total of Ö filters (SCBFs). Without loss of generality, we assume Ô ½ Ô ¾ Ô Ö . The higher Ô values correspond to higher resolution while lower Ô values imply lower resolution. In this scheme, the elements with low multiplicities will be estimated by filter(s) of higher resolutions, while elements with high multiplicities will be estimated by filters of lower resolutions. In other words, filters into which packets are sampled and inserted with high probabilities can keep track of small flows while filters with low sampling probabilities track the larger flows.</p><p>In the query algorithm, we count the number of groups that Ü matches in filters ½ ¾ ¡ ¡ ¡ Ö, denoted as ½ ¾ ¡ ¡ ¡ Ö respectively. Due to the varying sampling probabilities of the individual filters, in general the values ½ ¾ ¡ ¡ ¡ Ö will all be different. The final estimate will be ×Ø Ñ Ø ´ ½ ¾ ¡ ¡ ¡ Ö µ, the result of a joint estimation procedure based on the observations. The first step in this estimation procedure is to identify one or more of the total Ö filters whose observations are the most relevant for estimation. The theory and mechanism for identifying relevant filters is explained in Section IV-C. Once the relevant filter(s) are identified, a precomputed estimate table can be looked-up using the corresponding observations. Like in SCBF, the estimate table for MRSCBF again will be precomputed. We developed techniques, discussed in section IV-A.2 and IV-C, to optimally compute the estimate table without sacrificing accuracy.</p><p>Tuning the sampling probabilities Ô ½ Ô ¾ Ô Ö , and the number of groups Ð is closely related to the level of estimation accuracy we would like to achieve. To achieve the constant relative error tolerance (discussed in Section II-A), ½ ¾ Ö, i.e., a geometric progression. Here ½ is a constant, which is a function of the number of groups Ð. The philosophy behind setting parameters this way is captured in Figure <ref type="figure" target="#fig_2">4</ref>. Each group covers a certain multiplicity range and in part of this range, it has accurate coverage. When the parameters Ô ¼ × are set as above, the accurate coverage ranges of these groups "touch" each other on the borders and jointly cover the whole multiplicity range. With geometrically decreasing sampling probabilities, the absolute inaccuracy in estimation by the corresponding filters also increases geometrically. But filters with small sampling probabilities are only used to estimate the size of large flows, or in other words, have a geometrically larger range of coverage. So the relative accuracy of estimation remains constant. For the analysis and evaluation of MRSCBF throughout the rest of the paper, we set Ð ¿¾ and ½ , unless specified otherwise.</p><p>This multi-resolution design works very well for Internet traffic, in which the majority of the flows are mice but a small number of large flows (elephants) account for the majority of the packets (the aforementioned "quasi-Zipf" law). Our design ensures that for each possible flow size, one of the filters will have a resolution that measures its count with reasonable accuracy. The storage efficiency of MRSCBF is reasonable since the small flows are restricted to filters with high sampling probabilities, and hence will not occupy too many bits. Only large flows get sampled into other filters 2 , and due to the geometrically decreasing sampling probability, the bits occupied by large flows will grow only logarithmically with their size. However, MRSCBF pays a little price on storage efficiency for blind streaming, which is that the high multiplicity elements will completely fill up all the high resolution filters so that these filters do not carry much information 3 . Nevertheless, this price is moderate because the fraction of large flows is very small in the Internet traffic.</p><p>2 Some small flows too might get sampled into filters with small sampling probabilities, but their impact on storage efficiency is negligible. This does not impact the accuracy either, because the mechanism for choosing the most relevant filter(s) identifies such filters as irrelevant. 3 Recall that flows with distinct labels hash to different location in the filter array. Though a high multiplicity element fills up the high resolution filter for itself, it does not have any impact at all on the accuracy of the same filter for other elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Performance Guarantees</head><p>At this point in our discussion, we are ready to evaluate the performance of MRSCBF according to one of the three metrics discussed in Section II-A -its computational complexity.</p><p>Consider an MRSCBF configured with aforementioned parameters (Ð ¿¾, ½ ). Let be the number of hash functions used in a group <ref type="foot" target="#foot_1">4</ref> belonging to filter , and let Ô be the sampling probability of filter . The computational complexity of the scheme is È Ö ¼ £Ô bits per packet. When the sampling probabilities Ô follow a geometric progression, as described in section III-B, this value tends to be small. In our experiments with MRSCBF, we set ½ to 3, ¾ to 4,and ¿ ¡ ¡ ¡ Ö to 6. With other parameters shown above , the total complexity is no more than 5 bits per packet. This would allow us to comfortably support OC-768 speed using SRAM with access latency of 5ns. Assuming average packet-size of 1000 bits and full utilization, an OC-768 link would see 40 million packets per second or one packet every 25ns, thus leaving 5ns for each of the 5 bits to be written to bit-addressable SRAM.</p><p>The performance of MRSCBF along the other two metrics of storage complexity and accuracy is evaluated in Section V through analysis and experiments on real packet-header traces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. MAXIMUM LIKELIHOOD ESTIMATION AND ANALYSIS</head><p>In this section, we formally specify the two estimation mechanisms -Maximum Likelihood Estimation (MLE) (Section IV-A) and Mean Value estimation (MVE) (Section IV-B), and present the mathematics behind the two procedures. We also describe the mechanism used to choose the "most relevant" filter(s) in an MRSCBF (Section IV-C). Finally, we compare the advantages and disadvantages of MLE and MVE in Section IV-D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Maximum Likelihood Estimation 1) MLE with observations from one SCBF:</head><p>We first describe the MLE procedure for one SCBF in a MRSCBF. Let ¢ be the set of groups that are matched by an element Ü in SCBF . We know from the design of MRSCBF that elements are inserted into SCBF with sampling probability Ô . To find out the number of occurrences of Ü from the observation ¢, we use the principle of MLE, i.e., we would like to find that maximizes È Ö ¢℄. In other words, Ö Ñ Ü È Ö ¢℄. However, to compute È Ö ¢℄,</p><p>we need to prescribe an a priori distribution for . We found that, when is assumed to have a uniform a priori distribution, ℄ becomes a constant with respect to and the result follows.</p><formula xml:id="formula_2">Ö Ñ Ü È Ö ¢℄ Ö Ñ Ü È Ö ¢ ℄.</formula><p>How to prescribe the default a priori distribution (the belief before any observation) has always been a controversial issue in statistics <ref type="bibr" target="#b8">[10]</ref>. It is however a widely acceptable practice to use uniform as the default when there are no obviously better choices. Assuming uniform as the default is reasonable also for the following reason. It can be shown quantitatively that the evidence ¢ in general significantly outweighs the skew caused by any a priori distribution that is slowly varying. A distribution is slowly varying if È Ö ℄ È Ö • ½℄ ¯when ¯is a very small constant. Clearly there is no reason to believe that the a priori distribution of is not slowly varying. Now that maximizing È Ö ¢℄ becomes maximizing È Ö ¢ ℄. The following theorem characterizes how to compute È Ö ¢ ℄. Its proof can be found in the Appendix.</p><p>Theorem 1: Let ¢ , Ô be the sampling probability and « be the fraction of bits that are set to '1' in the MRSCBF.</p><p>Then È Ö ¢ ℄ is equal to</p><formula xml:id="formula_3">½ « Ð Õ ¼ Õ Ô Õ ´½ Ôµ ´ Õµ ¬ ¼ Ð Õ ¬ « ¬ ½ « ¬ ½ ¬ ½ ½ Õ • ¬ ¾ ¾ Õ ¡¡ ¡ • ´ ½µ ¬ ¬ ¬ ¬ Õ (1)</formula><p>2) MLE with observations from multiple SCBF's in MRSCBF: Now we describe the MLE process for MRSCBF.</p><p>Let ¢ ½ , ¢ ¾ , ..., ¢ Ö be the set of groups that are matched by the element Ü in SCBF 1, 2, ..., Ö respectively. Since ¢ ½ , ¡ ¡ ¡ ,¢ Ö are independent, when independent hash functions are used in SCBF's, we have</p><formula xml:id="formula_4">È Ö ¢ ½ ¡¡ ¡ ¢Ö ℄ Ö ½ È Ö ¢ ℄ (2) Therefore ÅÄ ´¢½ ¡ ¡ ¡ ¢ Ö µ = Ö Ñ Ü É Ö ½ È Ö ¢ ℄.</formula><p>Note that È Ö ¢ ℄ can be computed from Equation <ref type="formula">1</ref>. However, although above MLE decoding formula (Equation <ref type="formula">2</ref>) is correct in principle, it cannot be used in practice since the complexity of precomputing the decoding table is prohibitive. We return to this issue in Section IV-C, after discussing MVE in the following subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Mean Value Estimation</head><p>We begin with the description of MVE procedure for a single SCBF. Again, Let be the multiplicity of an element Ü. The number of positives (number of matched groups) we observe from the SCBF, when queried for Ü, is clearly a random variable that is a function of (not a function of Ü with good hash functions). We denote this random variable as .</p><p>Let ´ µ ℄ be the function that maps the multiplicity to the average number of positives it will generate. Clearly</p><p>´ ½ µ ´ ¾ µ when ½ ¾ since the higher the multiplicity of Ü, the higher number of positives it will generate. So ½ exists since it is monotonically increasing.</p><p>Our MVE estimation rule is the following. Given an observation , which is the number of groups matched by the flow Ü that is being queried for, we declare that ÅÎ ´ µ ½ ´ µ.</p><p>In other words, given the observation , our estimate is the value of that, on the average, produces positives. We abused the notation ½ here since ½ is only defined on the discrete points by the above definition. However, we can use linear extrapolation to extend both and ½ to the continuous domain. In the following, we use the notation ½ to represent both the strictly defined discrete functions and their continuous counterparts.</p><p>The following theorem characterizes the function .</p><p>Theorem 2:</p><p>´ µ</p><formula xml:id="formula_5">Ð ¼ Õ ¼ Õ Ô Õ ´½ Ôµ Õ Ð ´« µ ´½ « µ Ð ´ • ´Õ µµ (3)</formula><p>where ´Õ µ is the value of that satisfies the equation</p><formula xml:id="formula_6">Õ Ð Ð • Ð Ð ´ • ½µ • • Ð Ð ´ • ½µ .</formula><p>Proof: Let be the random variable that denotes the number of positives obtained on querying the SCBF for Ü, given that Ü has been inserted into the SCBF times. By the definition of , ´ µ ℄. Let Ê be the random variable that denotes the number of false positives. Let É be the number of sampled packets that on the average result in positives that do not overlap with any of the Ê false positives. We claim that Ê É Õ℄</p><formula xml:id="formula_7">• ´Õ µ, where Õ Ð Ð • Ð Ð ´ •½µ • • Ð</formula><p>Ð ´ • ½µ . To see this, we view this as an instance of the coupon collector's problem, where we want to collect unique coupons. Now different coupons (the false positives) have already been collected, and the question is how many more coupons on the average do we have to collect to bring the total number of unique coupons we collect to . It can be verified that the answer to this question is ´Õ µ, using arguments from the coupon collector's problem <ref type="bibr" target="#b7">[9]</ref>. Therefore,</p><formula xml:id="formula_8">℄ Ê É Õ℄℄ Ð ¼ Õ ¼ È Ö Ê É Õ℄ Ê É Õ℄ Ð ¼ Õ ¼ Õ Ô Õ ´½ Ôµ Õ Ð ´« µ ´½ « µ Ð • ℄</formula><p>In an MRSCBF with multiple filters running in parallel, MVE can be used by first identifying the most relevant among the various SCBF (through the mechanism described in the following subsection) and then running MVE for the observation from that SCBF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Choosing the most relevant filters in an MRSCBF</head><p>Using multiple SCBFs in an MRSCBF with different, independent sampling probabilities, allows it to account for items with large multiplicities with a constant relative accuracy. But the estimation procedure becomes more complex for both MLE and MVE. Equation 2 shows how the joint probability distribution of multiple filters can be calculated from the probability distribution for individual filters. But the complexity of this operation is Ð Ö where Ð is the number of possible outcomes in an individual filter and Ö is the total number of filters. This combinatorial explosion in complexity rules out an implementation of the estimation procedure in this form.</p><p>Fortunately, we can solve this problem by using the observations from the "most relevant" filters. The key observation here is that due to the varying sampling probabilities of different independent SCBF's in an MRSCBF, for a given multiplicity, only a few filters have a resolution that is good enough to estimate that particular multiplicity. All other filters have a resolution that is either too fine or too coarse to have any relevance. For example, if an item Ü has multiplicity of 1000, then the filter sampling with probability 1 (resolution too fine) will have all the groups matched by Ü (i.e., Ð), and thus will not be able to provide any information 5 about the multiplicity of Ü . On the other hand a filter that samples with a probability of ½ ½¼¾ (resolution too coarse) will have ¼ or 1 most of the time, when looked up for Ü. Such a value of ¼ or 1 is so small that it will be dominated by the false positives. Intuitively, we can see that filters that sample with probabilities ½ ½ , or ½ ¿¾ might provide the best estimates. In our experiments we observed that choosing the filter £ with the "best resolution" and the two filters £ ½ and £ • ½, and then using the joint probability distribution for these three filters using (2) was a sound strategy.</p><p>We now explain the mechanism used to identify the most relevant filter (i.e., the filter with the most relevant observation for a particular item Ü). As explained above, filters with very small or very large observations do not provide enough information about the given item. More formally, we can talk about the relative incremental inaccuracy of a given observation. For a filter with Ð groups, of which are matched by an item Ü, it would take about Ð Ð insertions on the average to match another unmatched group, and increase the observation to • ½. On the other hand we know from the coupon collector's problem that the total number of insertions required to cause the observation is</p><formula xml:id="formula_9">´Ð Ð • Ð Ð ½ •¡ ¡ ¡• Ð Ð •½ µ.</formula><p>Thus the relative incremental inaccuracy of this observation 5 All we can determine from an observation Ð is that the multiplicity of Ü is too large to be estimated by this filter. Notice the logscale on the Ý-axis.</p><formula xml:id="formula_10">is Ð ´Ð µ ´Ð Ð • Ð Ð ½ •¡ ¡ ¡• Ð Ð •½ µ.</formula><p>To identify the most relevant filter, we calculate the value of relative incremental inaccuracy of the observations ¢ from each of the Ö windows and choose the filter with the smallest inaccuracy. Figure <ref type="figure" target="#fig_3">5</ref> shows a plot of the relative incremental inaccuracy for different values of . Note that the Ý-axis is on logscale. We can observe in both curves, for filters with 32 and 64 groups respectively, that the inaccuracy is the least when is an intermediate value between 0 and the total number of groups. Another observation is that the relative incremental inaccuracy of a filter with 64 groups is better than that of a filter with 32 groups for any observation .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Comparison of MLE and MVE</head><p>In statistics, MLE is the provably-optimal decoding procedure for minimizing estimation error. However, the error metric in that context is È Ö ℄, i.e., the probability that the estimate is different from the actual value, given an observation . In our application, however, È Ö ℄ is very close to 1, since many possible ¼ × are almost equally likely to produce the observation , and ÅÄ ´ µ is only slightly more likely than many of its neighbors to produce ("peak of an almost-flat hill"). So we use È Ö ´ µ ¯ ℄ as our metric for evaluation. But under this metric, it can be shown that MLE may not give us optimal performance, and MVE can actually perform better, as shown in Section V-A. The decoding table for MVE is also easier to compute than that of MLE, especially when the number of groups is over 35 (due to the floating point precision limit). However, MLE does have an advantage in our context. Extending MLE for joint estimation from multiple observations is straightforward (Section IV-A.2). On the other hand, it is hard, if not impossible, to find a mathematically sound extention of MVE for multiple observations in our context. So the MLE decoding for MRSCBF is based on three observations, while MVE is only based on the one observation, chosen through the mechanism described in Section IV-C. We will revisit this in Section V-A.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EVALUATION</head><p>In this section we present an evaluation of MRSCBF using the metrics of accuracy and storage complexity. Section V-A evaluates the theoretical accuracy of MRSCBF through analytical calculations only. We then present an evaluation of MRSCBF using real Internet traces in Section V-B. The chief achievement of MRSCBF is accurate estimation of flow sizes as depicted in Figures <ref type="figure" target="#fig_9">8(a</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Theoretical accuracy of Estimation</head><p>The accuracy of estimation by MRSCBF is a function of the various design parameters, including the number of filters Ö, the number of groups ´Ð µ, the sampling rate ´Ô µ (resolution), and the number of hash functions ´ used in each SCBF , ½ ¾ Ö. The accuracy of the estimation can be characterized by the probability of the estimated value being within the interval ´½ ¯µ ´½ • ¯µ ℄, where is the real value. It can also be characterized by the mean of relative error (</p><p>). Both these quantities can be computed from Equation <ref type="formula">1</ref>. ¿ hash functions per group in the first SCBF, for the second and for the rest. Each curve corresponds to a specific level of relative error tolerance (i.e. a specific choice of ¯), and represents the probability that the estimated value is within this factor of the actual value. For example, the curve for ¯ ¼ ¾ shows that around 85% of the time, the estimate is within 25% of the actual value.</p><p>Figures <ref type="figure">6(a</ref>) and 6(b) show similar curves for MVE in filters with 32 and 64 groups respectively. The figures for MVE have been drawn using computations from Theorem 1 (also useful for MVE) and the MVE decoding rule. For the same number of groups (Ð = 32), we observe that MVE (Figure <ref type="figure">6(a)</ref>) has very similar accuracy as MLE (Figure <ref type="figure" target="#fig_7">7</ref>). However, curves with MLE are much more smooth than those with MVE for the following reason. In MLE, we use the joint observations from three filters for estimation (discussed in Section IV), and this evens out the variations that occur in different windows. However, such a joint estimation procedure does not exist for MVE, and variations in the "most relevant" filter (determined through the mechanism discussed in Section IV-C) reflect directly in Figure <ref type="figure">6</ref>(a). We have plotted accuracy curves (not shown here due to lack of space) for MLE using a single "most relevant" filter, and the curves are just as "noisy" as the MVE curves in Figure <ref type="figure">6</ref>(a), thus supporting our interpretation here.  We also observe that the accuracy of filters with 32 groups (Figure <ref type="figure">6(a)</ref>) is lower compared to that of the filter with 64 groups (Figure <ref type="figure">6</ref>(b)), thus indicating the gain in accuracy with an increase in the number of groups per filter. However this gain comes at the cost of increased storage complexity as the "code" for different flows is spread over a larger "space". We could not compute the accuracy of MLE with filters containing 64 groups of hash functions, because standard floating point libraries will not work for computations involved in Theorem 1 when the window size grows beyond 35 (the computation of MLE decoding table clearly requires the computation of the formula in Theorem 1). We expect to see a similar gain in accuracy with MLE on increasing the number of groups, and plan to verify this using high precision floating point library in the future. In separate calculations for both MLE (32 groups) and MVE (32 and 64 groups), we observed that the mean of relative error (</p><p>) is less than 0.15, implying that on the average, the error in estimation is no more than 15%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Packet header trace measurements</head><p>To evaluate the performance of MRSCBF on real-world Internet traffic, we use a set of three packet header traces obtained from a tier-1 ISP backbone. These traces were collected by a Gigascope probe <ref type="bibr" target="#b9">[11]</ref> on a high speed link leaving a data center in April, 2003. Among them two were gathered on weekdays and one on a weekend. Each of the packet header traces lasts few hours and consists of 588 632 million packet headers and carries 280 329 GB traffic. The number of unique IP addresses observed in each trace is around 10 million.</p><p>We developed a software implementation of MRSCBF with both MLE and MVE estimation mechanisms. Throughout the rest of this section, we use the results obtained from processing packet header traces using this implementation. The operation of MRSCBF is independent of the definition of "flow". We (iii) (source IP, destination IP); (iv) (destination IP, destination port); (v) (source IP, source port, destination IP, destination port). We observed similar trends using all five alternatives, and use (source IP, source port, destination IP, destination port) as the flow identifier in the rest of this section to illustrate the measurement results. The figures drawn in this section are all from a trace-segment of about 2 million packets taken from one of the packet header traces obtained on April 17, 2003. Other traces produced virtually identical results.</p><p>1) Storage Complexity: With both MLE and MVE, we observed that MRSCBF is able to process<ref type="foot" target="#foot_2">6</ref> over 2 million  packets before 50% of the bits in a bit-array of size 1MB are set to 1. At this point the array is paged to disk and a new array is initialized and used. If we scale this observation to a fully loaded 10 Gigabit link, with an average packet-size of 1000 bits <ref type="bibr" target="#b10">[12]</ref>, MRSCBF will need to page 5 MB (uncompressed data) to the disk every second. On the other hand, storing a trace of all packet-headers would take 40 times more space. Note that our estimate of 5 MB of data per second is arrived at with conservative assumptions of very small packets (1000 bits) and 100% link utilization. The average utilization of high capacity links is usually below 50% <ref type="bibr" target="#b11">[13]</ref> and the average packetsize is 2 to 6 times higher <ref type="bibr" target="#b12">[14]</ref> than our assumption of 1000 bits. Thus we believe that while the worst case storage requirement for MRSCBF is 5 MB per second, the average requirement is quite likely to be an order of magnitude smaller.</p><p>2) Maximum Likelihood Estimation: Figure <ref type="figure" target="#fig_9">8</ref>(a) shows the scatter diagram of flow size estimated using MLE (Ý axis) vs. actual flow size (Ü axis) in terms of the number of packets in the flow. The fact that all the points are concentrated within a narrow band of fixed width along the Ý Ü line indicates that our estimates are consistently within a constant factor of the actual multiplicity. Figure <ref type="figure" target="#fig_9">8(b)</ref> shows the distribution of the original and estimated flow volume (both of them are sorted by the number of packets in a flow). We found that MLE gives a near-perfect flow size distribution, indicated by the overlap of the two curves in this figure. This is very useful in applications such as network anomaly detection.</p><p>Figure <ref type="figure" target="#fig_10">9</ref> shows the cumulative distribution of relative error. Different curves in this figure correspond to flows that are larger than a particular size. We observe that about 30% of the time MLE estimates the correct flow-size exactly. We also observe that the relative accuracy of MLE is significantly better if we consider only the flows with actual size 10 or more. The reasons for this are twofold. First, we use only 3 hash functions in each group in the first SCBF (with sampling probability 1) to improve the overall computational complexity, and thus incur more false positives in the first filter, leading to poor accuracy for small flows. Second, MLE only returns integer estimates which magnifies the relative error at small absolute values. MLE is not unbiased and tends to slightly over-estimate flow size. During estimation using MLE, the MRSCBF over-estimated the total number of packets by about 3%. Similar observations hold on all three packet header traces.</p><p>3) Mean Value Estimation: We ran MRSCBF with MVE on the same sets of packet header traces. We evaluated filters with 32 and 64 groups keeping the remaining parameters same as before. We observed that like MLE, MVE also achieves a constant relative error tolerance and produces a near-perfect distribution of flow sizes. Figures <ref type="figure" target="#fig_12">10(a</ref>) and 10(b) illustrate these results. It can be seen that these figures are virtually identical to Figures <ref type="figure" target="#fig_9">8(a</ref>) and 8(b) presenting similar results for MLE. However, unlike MLE, MVE is close to unbiased, and over-estimated the total number of packets by only about 0.3%. This is 10 times less than what we observed from MLE. In our experiments, we observe that increasing the number of groups in MVE will improve the accuracy of estimation for larger flows, which again matches our expectations from Section V-A and is consistent with our results on relative incremental inaccuracy in Section IV-C.</p><p>Figure <ref type="figure" target="#fig_13">11</ref> shows the cumulative distribution of the relative error of flow size distribution using a filter of 32 groups. The slight bias in the curves for MLE in Figure <ref type="figure" target="#fig_10">9</ref> compared to the roughly symmetric nature of the curves in Figure <ref type="figure" target="#fig_13">11</ref> is another manifestation of the bias of MLE towards over-estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. RELATED WORK</head><p>Burton Bloom <ref type="bibr" target="#b3">[5]</ref> designed the Bloom filter as a spaceefficient data structure for answering set-membership queries with a certain probability of false-positives that can be made arbitrarily small. Bloom filters have found application in numerous areas of Computer Science, most notably in database applications, and more recently, in networking. A thorough survey of Network Applications of Bloom Filters is presented in <ref type="bibr" target="#b13">[15]</ref>.</p><p>Previous attempts at using Bloom filters to answer multiset queries have produced a number of variations of counting Bloom filter <ref type="bibr" target="#b14">[16]</ref>. In its most basic form, a counting Bloom filter has a counter associated with each bit in the array. When an element Ü is inserted in a counting Bloom filter with hash functions ½ ¡ ¡ ¡ , each of the counters associated with the bits ½ ´Üµ ¡ ¡ ¡ ´Üµ are incremented by one. Unfortunately, due to collisions in hashing, quantitative estimates based on counters might be a long way off the correct value of the frequency of occurrence of any element in counting Bloom filters. Approaches like conservative update <ref type="bibr" target="#b0">[1]</ref> have been proposed to counter this problem to some extent. Such heuristics fail to provide any bounds on the estimation error and do not yield to analysis. Counting Bloom filters are not suitable from the implementation perspective either. They require a large number of counters, each of them capable of counting up to the largest possible multiplicity, thus wasting both space and computation cycles. Attempts to improve the space efficiency of counting Bloom filters have resulted in the proposal of variable size counters <ref type="bibr" target="#b5">[7]</ref>. Unfortunately, the mechanism required to implement variable size counters is complex, and unlikely to match the rate of a high speed link.</p><p>Estan and Varghese present algorithms in <ref type="bibr" target="#b0">[1]</ref> that can identify and monitor a small number of elephants with a small amount of fast memory. The approach in <ref type="bibr" target="#b0">[1]</ref> is to use a fast mechanism to identify packets belonging to large flows and then maintain per-flow state for such packets only. While this work successfully addresses the problem of tracking the largest few flows, monitoring just a few large flows precludes a range of applications that would be served better with approximate monitoring of all flows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSIONS</head><p>Per-flow traffic accounting is important in a number of network applications. However, current solutions such as maintaining per-flow state or random sampling are either not scalable or not accurate. We propose a novel data structure called Space Code Bloom Filter that performs approximate yet reasonably accurate per-flow accounting without maintaining per-flow state. It is very amenable to pipelined hardware implementation since its logic is simple and it is a write-only data structure (blind streaming). We develop two procedures for estimating the flow volume from observations of SCBF based on the principles of Maximum Likelihood Estimation (MLE) and Mean Value Estimation (MVE) respectively. Our analysis shows that our estimation procedure will guarantee constant relative error with high probability. Experiments with a software implementation of SCBF and both estimation algorithms on traffic traces from a Tier-1 ISP backbone agree very well with our theoretical analysis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Insertion and Query in SCBF</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Insertion and Query Algorithms in MRSCBF</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The conceptual design of MRSCBF</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5. The relative incremental inaccuracy for filters with 32 and 64 groups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Theoretical accuracy of MVE using 64 groups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig. 6. Probability that the estimate is within a factor of ´½ ¦ ¯µ of the actual frequency for various values of ¯.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>) and 8(b) and discussed in Section V-B.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7</head><label>7</label><figDesc>Figure 7 shows the plot of ´½ AEµ for different values of , where ½ AE È Ö ´½ ¯µ ´½•¯µ ℄. The parameters used for the MRSCBF are Ö SCBFs, Ð ¿¾ groups in each SCBF, sampling probabilities of ½ ½ ½ ½ ¡ ¡ ¡ ½ Ö ½ for</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Original vs. estimated flow size. Note that both axes are on logscale. Distribution of the original and estimated flow size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Estimation with MRSCBF using MLE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Accuracy of estimation using MLE. CDF of relative error for flows of various size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Original vs. estimated flow size. Note that both axes are on logscale. Distribution of the original and estimated flow size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Estimation with MRSCBF using MVE with 32 groups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. The cumulative distribution of relative error in flow size estimation using MVE with 32 groups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>.</head><label></label><figDesc>Each group can be viewed as a traditional Bloom filter.The insertion and query algorithms of SCBF are shown in Figure2. During insertion, one group of hash functions ½ ´Üµ ¾ ´Üµ ¡ ¡ ¡ ´Üµ is chosen randomly, and the bits ½ ´Üµ℄ ¾ ´Üµ℄ ¡ ¡ ¡ ´Üµ℄ are set to 1. While querying to find out the number of occurrences of element Ý in the set, we count the number of groups that Ý has matched. An</figDesc><table><row><cell>2.</cell><cell>Ö Ò ´½ Ðµ;</cell></row><row><cell>3.</cell><cell>Set bits</cell></row></table><note><p>element Ý matches a group ½ ¾ ¡ ¡ ¡ if all the bits ½ ´Ýµ℄ ¾ ´Ýµ℄ ¡ ¡ ¡ ´Ýµ℄ are 1. Based on the number of groups that Ý has matched, denoted as , we can estimate the multiplicity of Ý in the multiset, and return the result generated by this estimation procedure as the answer. In other words, a query for the flow Ý first counts the number of groups matched 1. Insertion algorithm (given Ü): ½ ´Üµ℄, ..., ´Üµ℄ to 1; 1. Query algorithm (given Ý): 2. ¼;</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Our measurement results in Figure8(b) are an independent verification of this "law".</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>Group sizes can be different from one SCBF to another in MRSCBF, but we use the same group size across all SCBFs for simplicity.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2"><p>The insertion algorithm of MRSCBF is independent of the estimation mechanism.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>We first describe how a single Bloom filter with multiple groups of hash functions (i.e. a SCBF) can be queried to obtain an estimate of the number of insertions in the Bloom filter. We then extend this result to address the possibility of false positives and the impact of sampling before insertion. Finally, we combines these results to complete the proof of Theorem 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. MLE of a SCBF</head><p>Le É be the random variable representing the number of elements inserted in the SCBF. All the events defined henceforth are conditioned on the event É Õ. Define 7   as the event that a particular set of groups of hash functions</p><p>happens if and only if events B and C happen, where event B</p><p>is the event that each of the Õ elements chooses one group from ¢ when the element is inserted into the SCBF, and C is the event that all groups of hash function in ¢ are chosen. Then È Ö ℄ È Ö ℄ È Ö ℄ÈÖ ℄ where È Ö´ µ ´ Ð µ Õ .</p><p>Define ½ as the event that for each of the Õ insertions, the group ½ was never chosen given that all the Õ insertions chose one of the groups in ¢. We claim that È ½ ℄ ½ ¡ Õ for any ½ , È ½ ¾ ℄ ¾ ¡ Õ for any ½ ¾ and so on. Now, the probability È Ö ℄ is the same as the probability that none of the events</p><p>By the principle of inclusion and exclusion, we obtain the following lemma.</p><p>Lemma 1: The probability that the set ¢ groups of hash functions is chosen given Õ insertions of an item is given by:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Impact of false positives</head><p>We have assumed that false positives are negligible in the proof of Lemma 1. In the following we incorporate the effect of false positives into our equation. Suppose the fraction of "1" in the array that holds all the SCBFs is «. Then the probability of false positive in one of the virtual Bloom filters with hash functions in each group is « . The proof of lemma 1 can now be suitably modified to reflect the possibility of false positives.</p><p>Lemma 2 (Decoding with false positives): Let be a Space-code Bloom filter such that elements of a multiset of size Ò are inserted using one of Ð groups of hash functions. Let « be the fraction of '1's in the SCBF. The probability that the set ¢ groups of hash functions returns positive given Õ insertions of an item is given by: 7 Strictly speaking, we should call this event ´Õµ because it is conditioned upon the event É Õ. In the interest of simplicity, we use in the place of ´Õµ everywhere except equation 9 where this conditioning needs to be made explicit.</p><p>Proof: By elementary probability theory, we get</p><p>where, Ê ¬ represents the event that there are ¬ false positives out of virtual Bloom filters. From the above discussion on false positives, we know that the probability of a false positive is « . Using this, we get the probability of ¬ false positives out of positives:</p><p>Suppose the set of virtual Bloom filters that cause false positives are associated with the groups of hash functions ½ , ¾ , ..., ¬ . Suppose the remaining ¬ groups of hash functions are Ø½ , Ø¾ , ¡ ¡ ¡ , Ø ¬ . È Ö Ê ¬℄ is the probability that the Õ packets have been inserted using at least all the remaining ¬ groups. Note that "false positive" is a misnomer here -it only means that each of these filters returns positive (when queried) even without insertions of these Õ packets. So it is possible that some of the Õ packets chose one or more of the when they are inserted.</p><p>We conditioned all probability on the fact that all Õ packets used one of the groups. Let be the event that the groups of hash functions Ø ,</p><p>È Ö Ê ¬℄ is the probability that, there are no positives other than the positives and each of the q insertions chooses one of the groups of hash func-</p><p>By the principle of inclusion and exclusion, we get</p><p>Substituting the terms in equation 6 using equations 7 and 8 completes the proof.</p><p>After incorporating the effect of sampling in the decoding mechanism we obtain the following equation:</p><p>See footnote 7 for clarification on ´Õµ. Substituting equation 5 into equation 9 completes the proof of Theorem 1.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">New Directions in Traffic Measurement and Accounting</title>
		<author>
			<persName><forename type="first">C</forename><surname>Estan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varghese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2002-08">Aug. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Finding frequent items in data streams</title>
		<author>
			<persName><forename type="first">M</forename><surname>Charikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farach-Colton</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICALP</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="693" to="703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A simple algorithm for finding frequent elements in streams and bags</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Database Systems (TODS)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="51" to="55" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Space/time trade-offs in hash coding with allowable errors</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Bloom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CACM</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="422" to="426" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The space complexity of approximating the frequency moments</title>
		<author>
			<persName><forename type="first">N</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on Theory of Computing</title>
		<meeting>the ACM Symposium on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Spectral bloom filters</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGMOD Conference on Management of Data</title>
		<meeting>ACM SIGMOD Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Frequency estimation of internet packet streams with limited space</title>
		<author>
			<persName><forename type="first">E</forename><surname>Demaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Munro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lopez-Ortiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Symposium on Algorithms (ESA)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Randomized Algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="page" from="57" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Mathematical Statistics, Basic Ideas and Selected Topics</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Bickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Doksum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Gigascope: a stream database for network applications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cranor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Spatscheck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGMOD 2003</title>
		<meeting>SIGMOD 2003</meeting>
		<imprint>
			<date type="published" when="2003-06">Jun 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A 50-gb/s ip router</title>
		<author>
			<persName><forename type="first">C</forename><surname>Partridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Carvey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Castineyra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hathaway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kohalmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcallen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mendez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Milliken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pettyjohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rokosz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Seeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sollins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Storch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tober</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Troxel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Networking (TON)</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="237" to="248" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An approach to alleviate link overload as observed on an IP backbone</title>
		<author>
			<persName><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Taft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Infocom</title>
		<meeting>IEEE Infocom<address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-03">Mar. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Packet-level traffic measurement from the sprint IP backbone</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fraleigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lyles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rockell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Seely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network Magazine</title>
		<imprint>
			<date type="published" when="2003-11">Nov. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Network Applications of Bloom Filters: A Survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Broder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitzenmacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fortieth Annual Allerton Conference on Communication, Control, and Computing</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Summary cache: A scalable wide-area Web cache sharing protocol</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Broder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Networking</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="281" to="293" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
