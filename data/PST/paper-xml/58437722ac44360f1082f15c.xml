<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning to Match using Local and Distributed Representations of Text for Web Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
							<email>bmitra@microsoft.com</email>
							<affiliation key="aff0">
								<address>
									<settlement>Microsoft</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
							<email>fdiaz@microsoft.com</email>
							<affiliation key="aff0">
								<address>
									<settlement>Microsoft</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
							<email>nickcr@microsoft.com</email>
							<affiliation key="aff0">
								<address>
									<settlement>Microsoft</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning to Match using Local and Distributed Representations of Text for Web Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3038912.3052579</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information retrieval</term>
					<term>neural networks</term>
					<term>document ranking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Models such as latent semantic analysis and those based on neural embeddings learn distributed representations of text, and match the query against the document in the latent semantic space. In traditional information retrieval models, on the other hand, terms have discrete or local representations, and the relevance of a document is determined by the exact matches of query terms in the body text. We hypothesize that matching with distributed representations complements matching with traditional local representations, and that a combination of the two is favourable. We propose a novel document ranking model composed of two separate deep neural networks, one that matches the query and the document using a local representation, and another that matches the query and the document using learned distributed representations. The two networks are jointly trained as part of a single neural network. We show that this combination or 'duet' performs significantly better than either neural network individually on a Web page ranking task, and significantly outperforms traditional baselines and other recently proposed models based on neural networks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Neural text embedding models have recently gained significant popularity for both natural language processing (NLP) and information retrieval (IR) tasks. In IR, a significant number of these works have focused on word embeddings <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b40">41]</ref> and modelling short-text similarities <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref>. In traditional Web search, the query consists of only few terms but the body text of the documents may typically have tens or hundreds of sentences.</p><p>In the absence of click information, such as for newly-published or infrequently-visited documents, the body text can be a useful signal to determine the relevance of the document for the query. Therefore, extending existing neural text representation learning approaches to</p><p>The President of the United States of America (POTUS) is the elected head of state and head of government of the United States. The president leads the executive branch of the federal government and is the commander in chief of the United States Armed Forces. Barack Hussein Obama II (born <ref type="bibr">August 4, 1961</ref>) is an American politician who is the 44th and current President of the United States. He is the first African American to hold the office and the first president born outside the continental United States.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) Local model</head><p>The President of the United States of America (POTUS) is the elected head of state and head of government of the United States. The president leads the executive branch of the federal government and is the commander in chief of the United States Armed Forces. Barack Hussein Obama II (born <ref type="bibr">August 4, 1961</ref>) is an American politician who is the 44th and current President of the United States. He is the first African American to hold the office and the first president born outside the continental United States.</p><p>(b) Distributed model long body text for document ranking is an important challenge in IR. However, as was noted during a recent workshop <ref type="bibr" target="#b3">[4]</ref>, despite the recent surge in interests towards applying deep neural network (DNN) models for retrieval, their success on ad-hoc retrieval tasks has been rather limited. Some recent papers <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b33">34]</ref> report worse performance of neural embedding models when compared to traditional term-based approaches, such as BM25 <ref type="bibr" target="#b32">[33]</ref>.</p><p>Traditional IR approaches consider terms as discrete entities. The relevance of the document to the query is estimated based on, amongst other factors, the number of matches of query terms in the document, the parts of the document in which the matches occur, and the proximity between the matches. In contrast, latent semantic analysis (LSA) <ref type="bibr" target="#b4">[5]</ref>, probabilistic latent semantic analysis (PLSA) <ref type="bibr" target="#b13">[14]</ref> and latent Dirichlet allocation (LDA) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b38">39]</ref> learn lowdimensional vector representations of terms, and match the query against the document in the latent semantic space. Retrieval models can therefore be classified based on what representations of text they employ at the point of matching the query against the document. At the point of match, if each term is represented by a unique identifiers (local representation <ref type="bibr" target="#b12">[13]</ref>) then the query-document relevance is a function of the pattern of occurrences of the exact query terms in the document. However, if the query and the document text is first projected into a continuous latent space, then it is their distributed representations that are compared. Along these lines, Guo et al. <ref type="bibr" target="#b11">[12]</ref> classify recent DNN models for short-text matching as either interaction-focused <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b30">31]</ref> or representation-focused <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref>. They claim that IR tasks are different from NLP tasks, and that it is more important to focus on exact matching for the former and on learning text embeddings for the latter. Mitra et al. <ref type="bibr" target="#b26">[27]</ref>, on the other hand, claim that models that compare the query and the document in the latent semantic space capture a different sense of relevance than models that focus on exact term matches, and therefore the combination of the two is more favourable. Our work is motivated by the latter intuition that it is important to match the query and the document using both local and distributed representations of text. We propose a novel ranking model comprised of two separate DNNs that model query-document relevance using local and distributed representations, respectively. The two DNNs, referred to henceforth as the local model and the distributed model, are jointly trained as part of a single neural network, that we name as a duet architecture because the two networks co-operate to achieve a common goal. Figure <ref type="figure" target="#fig_0">1</ref> demonstrates how each subnetwork models the same document given a fixed query. While the local model captures properties like exact match position and proximity, the distributed model detects synonyms (e.g. 'Obama'), related terms (e.g. 'federal'), and even well-formedness of content (e.g. 'the', 'of'). 1  In this paper, we show that the duet of the two DNNs not only outperforms the individual local and distributed models, but also demonstrates large improvements over traditional baselines and other recently proposed models based on DNNs on the document ranking task. Unlike other recent work <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b33">34]</ref>, our model significantly outperforms classic IR approaches by using a DNN to learn text representation.</p><p>Deep neural network models are known to benefit from large training data, achieving state-of-the-art performance in areas where large scale training corpora are available <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>. Some of the lack of positive results from neural models in ad-hoc retrieval is likely due to the scarce public availability of large quantity of training data necessary to learn effective representations of text. In Section 6, we will present some analysis on the effect of training data on the performance of these DNN models. In particular, we found thatunsurprisingly-the performance of the distributed model improves drastically in the presence of more data. Unlike some previous work <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref> that train on clickthrough data with randomly sampled documents as negative examples, we train our model on human-judged labels. Our candidate set for every query consists of documents that were retrieved by the commercial search engine Bing, and then labelled by crowdsourced judges. We found that training with the documents that were rated non-relevant by the human judges as the negative examples is more effective than randomly sampling negative examples from the corpus. To summarize, the key contributions of this work are:</p><p>1. We propose a novel duet architecture for a model that jointly learns two deep neural networks focused on matching using local and distributed representations of text, respectively.</p><p>2. We demonstrate that this architecture out-performs state-ofthe-art neural and traditional non-neural baselines.</p><p>3. We demonstrate that training with documents judged as nonrelevant as the negative examples is more effective than randomly sampling them from the corpus. 1 While surprising, this last property is important for detecting quality web content <ref type="bibr" target="#b41">[42]</ref>.  Query terms are laid out along the vertical axis, and the document terms along the horizontal axis. The short vertical lines correspond to exact matches between pairs of query and document terms. For both queries, the first document was rated relevant by a human judge and the following two as nonrelevant. The query term matches in the relevant documents are observed to be more clustered, and more localized near the beginning of the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">DESIDERATA OF DOCUMENT RANK-ING</head><p>Before describing our ranking model, we first present three properties found across most effective retrieval systems. We will then operationalize these in our architecture in Section 3.</p><p>First, exact term matches between the query and the document are fundamental to all information retrieval models <ref type="bibr" target="#b6">[7]</ref>. Traditional IR models, such as BM25 <ref type="bibr" target="#b32">[33]</ref>, are based on counts of exact matches of the query terms in the document text. They can be employed with minimal (or no) need for training data, sometimes directly on new tasks or corpora. Exact matching can be particularly important when the query terms are new or rare. For example, if new documents appear on the Web with the television model number 'SC32MN17' then BM25 can immediately retrieve these pages containing precisely that model number without adjusting any parameters of the ranking model. A good ranking model needs to take advantage of exact matches to perform reliably on queries containing terms with rare or no occurrences in the data the model is trained on.</p><p>Second, match positions of the query terms in the document not only reflect where potentially the relevant parts of the document are localized (e.g. title, first paragraph, closing paragraph) but also how clustered the individual query term matches are with each other. Figure <ref type="figure" target="#fig_2">2</ref> shows the position of matches on two different queries and a sample of relevant and non-relevant documents. In the first query, we see that the query term matches in the relevant document are much more clustered than in the non-relevant documents. We observe this behaviour also in the second query but in addition notice that the clustered matches are localized near the beginning of the relevant document. Match proximity serves as a foundation for effective methods such as sequential dependence models <ref type="bibr" target="#b22">[23]</ref>.</p><p>Finally, inexact term matches between the query and the document refer to techniques for addressing the vocabulary mismatch problem. The main disadvantage of term matching is that related terms are ignored, so when ranking for the query 'Australia' then only the term frequency of 'Australia' is considered, even though counting terms like 'Sydney' and 'koala' can be good positive evidence. Mitra et al. <ref type="bibr" target="#b26">[27]</ref> anecdotally demonstrate that a distributed representation based retrieval model that considers all document terms can better distinguish between a passage that is truly relevant to the query "Cambridge" from a passage on a different topic (e.g., giraffes) with artificially injected occurrences of the term "Cambridge". They claim that any IR model that considers the distribution of nonmatching terms is likely to benefit from this additional evidence of relevance, and be able to tell "Cambridge" apart from "an African even-toed ungulate mammal". 2  In practice, the most effective IR methods leverage combinations of these techniques. Dependence models combine exact matching with proximity <ref type="bibr" target="#b22">[23]</ref>. LDA-based document models combine exact matching with inexact matching <ref type="bibr" target="#b38">[39]</ref>. Query hypergraphs capture all three <ref type="bibr" target="#b0">[1]</ref>. Our method also combines these techniques but, unlike prior work, jointly learns all the free parameters of the different components within a single deep neural network architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">THE DUET ARCHITECTURE</head><p>Figure <ref type="figure">3</ref> provides a detailed schematic view of the duet architecture. The distributed model projects the query and the document text into an embedding space before matching, while the local model operates over an interaction matrix comparing every query term to every document term. The final score under the duet setup is the sum of scores from the local and the distributed networks,</p><formula xml:id="formula_0">f (Q, D) = f (Q, D) + f d (Q, D)<label>(1)</label></formula><p>where both the query and the document are considered as ordered list of terms, Q = [q1, . . . , qn q ] and D = [d1, . . . , dn d ]. Each query term q and document term d is a m × 1 vector where m is the input representation of the text (e.g. the number of terms in the vocabulary for the local model).</p><p>We fix the length of the inputs across all the queries and the documents such that we consider only the first 10 terms in the query and the first 1000 terms in the document. If either the query or the document is shorter than these target dimensions, then the input vectors are padded with zeros. The truncation of the document body text to the first 1000 terms is performed only for our model and its variants, but not for the baseline models. For all the neural and the non-neural baseline models we consider the full body text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Local Model</head><p>The local model estimates document relevance based on patterns of exact matches of query terms in the document. To this end, each term is represented by its one-hot encoding in a m -dimensional space, where m is the size of the vocabulary. The model then generates the n d × nq binary matrix X = D T Q, capturing every exact match (and position) of query terms in the document. This interaction matrix is similar to the visual representation of term matches in Figure <ref type="figure" target="#fig_2">2</ref>, and therefore captures both the exact term matches and the match positions. It is also similar to the indicator matching matrix proposed previously by Pang et al. <ref type="bibr" target="#b30">[31]</ref>. While the interaction matrix X perfectly captures every query term match in the document, it does not retain any information about the actual terms themselves. Therefore, the local model cannot learn termspecific properties from the training corpus, nor model interactions between dissimilar terms.</p><p>The interaction matrix X is first passed through a convolutional layer with c filters, a kernel size of n d × 1, and a stride of 1. The output Zi corresponding to the i th convolutional window over X is a function of the match between the qi term against all the terms in the document,</p><formula xml:id="formula_1">Zi = tanh X T i W (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where Xi is the row i of X, tanh is performed elementwise, and the n d × c matrix W contains the learnable parameters of the convolutional layer. The output Z of the convolutional layer is a matrix of dimension c × nq. We use a filter size (c) of 300 for all the evaluations reported in this paper. The output of the convolutional layer is then passed through two fully-connected layers, a dropout layer, and a final fully-connected layer that produces a single realvalued output. All the nodes in the local model uses the hyperbolic tangent function for non-linearity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Distributed Model</head><p>The distributed model learns dense lower-dimensional vector representations of the query and the document text, and then computes the positional similarity between them in the learnt embedding space. Instead of one-hot encoding of terms, as in the local model, we use a character n-graph based representation of each term in the query and document. Our n-graph based input encoding is motivated by the trigraph encoding proposed by Huang et al. <ref type="bibr" target="#b15">[16]</ref>, but unlike their approach we don't limit our input representation to n-graphs of a fixed length. For each term, we count all the n-graphs present for 1 ≤ n ≤ G. We then use this n-graph frequency vector of length m d to represent the term.</p><p>Instead of directly computing the interaction between the m d ×nq matrix Q and the m d × n d matrix D, we first learn a series of nonlinear transformations to the character-based input. For both the query and the document, the first step is convolution. The m d × 3 convolution window has filter size of 300. It projects 3 consecutive terms to a 300-dimensional vector, then takes a stride by 1 position, and projects the next 3 terms, and so on. For the query, the convolution step generates a tensor of dimensions 300 × 8. For the document, it generates one of dimensions 300 × 998.</p><p>Following this, we conduct a max-pooling step. For the query the pooling kernel dimensions are 1 × 8. For the document, it is 1 × 100. Thus, we get one 300 × 1 matrix Q for the query and a 300 × 899 matrix D for the document. The document matrix D can be interpreted as 899 separate embeddings, each corresponding to different equal-sized spans of text within the document. Our choice of a window-based max-pooling strategy, instead of global maxpooling as employed by CDSSM <ref type="bibr" target="#b36">[37]</ref>, is motivated by the fact that the window-based approach allows the model to distinguish between matches in different parts of the document. As posited in Section 2, a model that is aware of match positions may be more suitable when dealing with long documents, especially those containing mixture of many different topics.</p><p>The output of the max-pooling layer for the query is then passed through a fully-connected layer. For the document, the 300 × 899 dimensional matrix output is operated on by another convolutional layer with filter size of 300, kernel dimensions of 300 × 1, and a stride of 1. The combination of these convolutional and max-pooling layers enable the distributed model to learn suitable representations of text for effective inexact matching.</p><p>To perform the matching, we conduct the element-wise or Hadamard product between the embedded document matrix and the extended or broadcasted query embedding,</p><formula xml:id="formula_3">X = ( Q . . . Q 899 times ) • D<label>(3)</label></formula><p>After this, we pass the matrix through fully connected layers, and a dropout layer until we arrive at a single score. Like the local model, we use hyperbolic tangent function here for non-linearity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Optimization</head><p>Each training sample consists of a query Q, a relevant document D * and a set of non-relevant documents N = {D0, . . . , DN}. We use a softmax function to compute the posterior probability of the positive document given a query based on the score.</p><formula xml:id="formula_4">p(D * |Q) = exp(f (Q, D * )) D∈N exp(f (Q, D))<label>(4)</label></formula><p>and we maximize the log likelihood log p(D * |Q) using stochastic gradient descent. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">MATERIALS AND METHODS</head><p>We conducted three experiments to test: (1) the effectiveness of our duet model compared to the local and distributed models separately, and (2) the effectiveness of our duet model compared to existing baselines for content-based web ranking, (3) the effectiveness of training with judged negative documents compared to random negative documents. In this section, we detail our experiment setup and baseline implementations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>The training dataset consisted of 199,753 instances in the format described in Section 4.2. The queries in the training dataset were randomly sampled from Bing's search logs from a period between January 2012 and September 2014. Human judges rated the documents on a five-point scale (perfect, excellent, good, fair, and bad). The document body text was retrieved from Bing's Web document index. We used proprietary parsers for extracting the body text from raw HTML content. All query and document text were normalized by down-casing and removing all non-alphanumeric characters.</p><p>We considered two different test sets, both sampled from Bing search logs. The weighted set consisted of queries sampled per their frequency in the search logs. Thus, frequent queries were wellrepresented in this dataset. Queries were sampled between October 2014 and December 2014. The unweighted set consisted of queries sampled uniformly from the entire population of unique queries. The queries in this samples removed the bias toward popular queries found in the weighted set. The unweighted queries were sampled between January 2015 and June 2015.</p><p>Because all of our datasets were derived from sampling real query logs and because queries will naturally repeat, there was some overlap in queries between the training and testing sets. Specifically, 14% of the testing queries in the weighted set occurred in the training set, whereas only 0.04% of the testing queries in the unweighted set occurred in the training set. We present both results for those who may be in environments with repeated queries (as is common in production search engines) and for those who may be more interested in cold start situations or tail queries. Table <ref type="table" target="#tab_0">1</ref> summarizes statistics for the two test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training</head><p>Besides the architecture (Figure <ref type="figure">3</ref>), our model has the following free parameters: the maximum order of the character-based representation for the distributed model (G), the number of negative documents to sample at training time (N), the dropout rate, and the learning rate.</p><p>We used a maximum order of five for our character n-graphs in the distributed model. Instead of using the full 62,193,780-dimensional vector, we only considered the top 2,000 most popular n-graphs, resulting 36 unigraphs (a-z and 0-9), 689 bigraphs, 1149 trigraphs, 118 4-graphs, and eight 5-graphs.</p><p>When training our model (Section 3.3), we sampled four negative documents for every one relevant document. More precisely, for each query we generated a maximum of one training sample of each form, (1) One excellent document with four fair documents (2) One excellent document with four bad documents (3) One good document with four bad documents. Pilot experiments showed that treating documents judged as fair or bad as the negative examples resulted in significantly better performance, than when the model was trained with randomly sampled negatives. For training, we discarded all documents rated as perfect because a large portion of them fall under the navigational intent, which can be better satisfied by historical click based ranking signals.</p><p>The dropout rate and the learning rate were set to 0.20 and 0.01, respectively, based on a validation set. We implemented our model using CNTK <ref type="bibr" target="#b39">[40]</ref> and trained the model with stochastic gradient descent based optimization (with automatic differentiation) on a single GPU. <ref type="foot" target="#foot_0">3</ref> It was necessary to use a small minibatch size of 8 to fit the whole data in GPU memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines</head><p>Our baselines capture the individual properties we outlined in Section 2. Exact term matching is effectively performed by many classic information retrieval models. We used the Okapi BM25 <ref type="bibr" target="#b32">[33]</ref> and query likelihood (QL) <ref type="bibr" target="#b31">[32]</ref> models as representative of this class of model. We used Indri<ref type="foot" target="#foot_1">4</ref> for indexing and retrieval.</p><p>Match positions are handled by substantially fewer models. Metzler's dependence model (DM) <ref type="bibr" target="#b22">[23]</ref> provides an inference network approach to modeling term proximity. We used the Indri implementation for our experiments.</p><p>Inexact term matching received both historic and modern treatments in the literature. Deerwester et al. originally presented latent semantic analysis (LSA) <ref type="bibr" target="#b4">[5]</ref> as a method for addressing vocabulary mismatch by projecting words and documents into a lowerdimension latent space. The dual embedding space model (DESM) <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref> computes a document relevance score by comparing every term in the document with every query term using pre-trained word embeddings. We used the same pre-trained word embeddings dataset that the authors made publicly available online for download <ref type="foot" target="#foot_2">5</ref> . These embeddings, for approximately 2.8M words, were previously trained on a corpus of Bing queries. In particular, we use the DESMIN-OUT model, which was reported to have the best performance on the retrieval task, as a baseline in this paper. Both the deep structured semantic model (DSSM) <ref type="bibr" target="#b15">[16]</ref> and its convolutional variant CDSSM <ref type="bibr" target="#b36">[37]</ref> consider only the document title for matching with the query. While some negative results have been reported for title-based DSSM and CDSSM on the ad hoc document retrieval tasks <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">30]</ref>, we included document-based variants appropriately retrained on the same set of positive query and document pairs as our model. As with the original implementation we choose the non-relevant documents for training by randomly sampling from the document corpus. For the CDSSM model, we concatenated the trigraph hash vectors of the first T terms of the body text followed by a vector that is a sum of the trigraph hash vectors for the remaining terms. The choice of T was constrained by memory requirements, and we pick 499 for our experiments.</p><p>The DRMM model <ref type="bibr" target="#b11">[12]</ref> uses a DNN to perform term matching, with few hundred parameters, over histogram-based features. The histogram features, computed using exact term matching and pretrained word embeddings based cosine similarities, ignoring the ac- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation</head><p>All evaluation and empirical analysis used the normalized discounted cumulative gain (NDCG) metric computed at positions one and ten <ref type="bibr" target="#b17">[18]</ref>. All performance metrics were averaged over queries for each run. Whenever testing for significant differences in performance, we used the paired t-test with a Bonferroni correction.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RESULTS</head><p>Table <ref type="table" target="#tab_1">2</ref> reports NDCG based evaluation results on two test datasets for our model and all the baseline models. Our main observation is that the duet model performs significantly better than the individual local and distributed models. This supports our underlying hypothesis that matching in a latent semantic space can complement exact term matches in a document ranking task, and hence a combination of the two is more appropriate. Note that the NDCG numbers for the local and the distributed models correspond to when these DNNs are trained individually, but for the 'duet' the two DNNs are trained together as part of a single neural network.</p><p>Among the baseline models, including both traditional and neural network based models, CDSSM and DESM achieve the highest NDCG at position one and ten, respectively, on the weighted test set. On the unweighted test set DRMM is our best baseline model at both rank positions. The duet model demonstrates significant improvements over all these baseline models on both test sets and at both NDCG positions.</p><p>We also tested our independent local and distributed models against their conceptually closest baselines. Because our local model captures both matching and proximity, we compared performance to dependence models (DM). While the performance in terms of NDCG@1 is statistically indistinguishable, both NDCG@10 results are statistically significant (p &lt; 0.05). We compared our distributed model to the best neural model for each test set and metric. We found no statistically significant difference except for NDCG@10 for the weighted set.</p><p>We were interested in testing our hypotheses that training with labeled negative documents is superior to training with randomly sampled documents presumed to be negative. We conducted an experiment training with negative documents following each of the two protocols. Figure <ref type="figure" target="#fig_5">4</ref> shows the results of these experiments. We found that, across all our models, using judged nonrelevant documents was more effective than randomly sampling documents from the corpus and considering them as negative examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">DISCUSSION</head><p>Our results demonstrated that our joint optimization of local and distributed models provides substantial improvement over all baselines. Although the independent models were competitive with existing baselines, the combination provided a significant boost.</p><p>We also confirmed that using judged negative documents should be used when available. We speculate that training with topicallysimilar (but non-relevant) documents allows the model to better discriminate between the confusable documents provided by an earlier retrieval stage. This sort of staged ranking, first proposed by Cambazoglu et al. <ref type="bibr" target="#b2">[3]</ref>, is now a common web search engine architecture.</p><p>In Section 4.3 we described our baseline models according to which of the properties of effective retrieval systems, that we outlined in Section 2, they incorporate. It is reasonable to expect that models with certain properties are better suited to deal with certain segments of queries. For example, the relevant Web page for the query "what channel are the seahawks on today" may contain the name of the actual channel (e.g., "ESPN" or "FOX") and the actual date for the game, instead of the terms "channel" or "today". A retrieval model that only counts repetitions of query terms is likely to retrieve less relevant documents for this query -compared to a model that considers "ESPN" and "FOX" to be relevant document terms. In contrast, the query "pekarovic land company", which may be considered as a tail navigational intent, is likely to be better served by a retrieval model that simply retrieves documents containing many matches for the term "pekarovic". A representation learning model is unlikely to have a good representation for this rare term, and therefore may be less equipped to retrieve the correct documents. These anecdotal examples agree with the results in in Table <ref type="table" target="#tab_1">2</ref> that show that on the weighted test set all the neural models whose main focus is on learning distributed representations of text (duet model, distributed model, DESM, DSSM, and CDSSM) perform better than the models that only look at patterns of term matches (local model and DRMM). We believe that this is because the DNNs can learn better representations for more popular queries, and perform particularly well on this segment. Figure <ref type="figure" target="#fig_6">5</ref> provides further evidence towards this hypothesis by demonstrating that the distributed model has a larger NDCG gap with the local model for queries containing more popular terms, and when the number of terms in the query is small. The duet model, however, is found to perform better than both the local and the distributed models across all these segments.</p><p>To better understand the relationship of our models to existing baselines, we compared the per-query performance amongst all models. We conjecture that similar models should perform similarly for the same queries. We represented a retrieval model as a vector where each position of the vector contains the performance of the model on a different query. We randomly sample two thousand queries from our weighted test set and represent all ranking models as vectors of their NDCG values against these two thousand queries. We visualized the similarity between models by projecting using principal component analysis on the set of performance vectors. The two-dimensional projection of this analysis is presented in Figure <ref type="figure" target="#fig_7">6</ref>. The figure largely confirms our intuitions about properties of retrieval models. Models that use only local representation of terms are closer together in the projection, and further away from models that learn distributed representations of text. Interestingly, the plot does not distinguish between whether the underlying model is based on a neural network based or not -with neural networks of different retrieval properties appearing in each of the three clusters. Another interesting distinction between deep neural models and traditional approaches is the effect of the training data size on the performance of the model. BM25 has very few parameters and can be applied to new corpus or task with almost no training. On the other hand, DNNs like ours demonstrate significant improvements when trained with larger datasets. Figure <ref type="figure" target="#fig_9">7</ref> shows that the effect of training data size particularly pronounced for the duet and the distributed models that learns representations of text. The trends in these plots indicate that training on even larger datasets may result in further improvements in model performance over what is reported in this paper. We believe this should be a promising direction for future work.</p><p>A last consideration when comparing these models is runtime efficiency. Web search engines receive tens of thousands of queries per second. Running a deep neural model on raw body text at that scale is a hard problem. The local sub-network of our model operates on the term interaction matrix that should be reasonable to generate using an inverted index. For the distributed model, it is important to note that the 300 × 899 dimensional matrix representation of the document, that is used to compute the Hadamard product with the query, can be pre-computed and stored as part the document cache. At runtime, only the Hadamard product and the subsequent part of the network needs to be executed. Such caching strategies, if employed effectively, can mitigate large part of the runtime cost of running a DNN based document ranking model at scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">RELATED WORK</head><p>Representations of data can be local or distributed. In a local representation, a single unit represents an entity, for example there is a particular memory cell that represents the concept of a grandmother. That cell should be active if and only if the concept of a grandmother is present. By contrast, in a distributed representation, the concept of grandmother would be represented by a pattern of active cells. Hinton et al. <ref type="bibr" target="#b12">[13]</ref> provides an overview contrasting distributed and local representations, listing their good and bad points. In a distributed representation, an activation pattern that has some errors or other differences from past data can still be mapped to the entity in question and to related entities, using a similarity function. A local representation lacks this robustness to noise and ability to generalize, but is better at precisely storing a large set of data.</p><p>This paper considers local and distributed representations of queries and documents for use in Web page ranking. Our measure of ranking quality is NDCG <ref type="bibr" target="#b16">[17]</ref>, which rewards a ranker for returning documents with higher gain nearer to the top, where gain is determined based on labels from human relevance assessors. We describe different ranking methods in terms of their representations and how this should help them achieve good NDCG.</p><p>Exact term matching models such as BM25 <ref type="bibr" target="#b32">[33]</ref> and query likelihood <ref type="bibr" target="#b31">[32]</ref> tend to rank a document higher if it has a greater number of query term matches, while also potentially employing a variety of smoothing, weighting and normalization approaches. Such exact matching is done with a local representation of terms. Exact match systems do not depend on a large training set, since they do not need to learn a distributed representation of queries and documents. They are useful in cases where the relevant documents contain exactly the query terms entered by the user, including very rare or new vocabulary, since new terms can be incorporated with no adjustments to the underlying model. They can also be extended to reward matches of query phrases and proximity <ref type="bibr" target="#b22">[23]</ref>.</p><p>To deal with the vocabulary mismatch problem that arises with local representations, it is possible to do document ranking using a distributed representation of terms. Mikolov et al. <ref type="bibr" target="#b23">[24]</ref> developed the popular word2vec embedding approach that has been used in several retrieval studies. Zheng and Callan <ref type="bibr" target="#b40">[41]</ref> use term embeddings as evidence for term weighting, learning regression models to optimize weighting in a language modeling and a BM25 retrieval model. Ganguly et al. <ref type="bibr" target="#b7">[8]</ref> used term embeddings for smoothing in the language modeling approach of information retrieval. Nalisnick et al. <ref type="bibr" target="#b27">[28]</ref> used dual embeddings, one for document terms and one for query terms, then ranked based on the all-pairs similarity between vectors. Diaz et al. <ref type="bibr" target="#b5">[6]</ref> used term embeddings to generate query expansion candidates in the language modelling retrieval framework, also finding better performance when training a specialized term embedding. Other papers incorporating word embeddings include <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b33">34]</ref>.</p><p>Pang et al. <ref type="bibr" target="#b30">[31]</ref> propose the use of matching matrices to represent the similarity of short texts, then apply a convolutional neural network inspired by those in computer vision. They populate the matching matrix using both local and distributed term representations. In the local representation, an exact match is used to generate binary indicators of whether the ith term of one text and jth term of the other are the same, as in our local model. In the distributed representation, a pre-trained term embedding is used instead, populating the match matrix with cosine or inner product similarities. The method works for some problems with short text, but not for document ranking <ref type="bibr" target="#b29">[30]</ref>. However, by using the match matrix to generate summary statistics it is possible to make the method work well <ref type="bibr" target="#b11">[12]</ref>, which is our DRMM baseline.</p><p>These term embeddings are a learned representation of language, but in most cases, they are not learned on query-document relevance labels. More often they are trained based on a a corpus, where a term's representation is learned from its surrounding terms or other document context. The alternative, learning a representation based on NDCG labels, is in keeping with recent progress in deep learning.  Deep models have multiple layers that learn distributed representations with multiple levels of abstraction. This kind of representation learning, along with other factors such as the availability of large labelled data sets, has yielded performance improvements on a variety of tasks such as speech recognition, visual object recognition and object detection <ref type="bibr" target="#b19">[20]</ref>.</p><p>This paper learns a text representation end-to-end based on querydocument ranking labels. This has not been done often in related work with document body text, but we can point to related papers that use short text such as title, for document ranking or related tasks. Huang et al. <ref type="bibr" target="#b15">[16]</ref> learn a distributed representation of query and title, for document ranking. The input representation is character trigraphs, the training procedure asks the model to rank clicked titles over randomly chosen titles, and the test metric is NDCG with human labels. Shen et al. <ref type="bibr" target="#b35">[36]</ref> developed a convolutional version of the model. These are our DSSM and CDSSM baselines. Other convolutional models that match short texts using distributed representations include <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b34">35]</ref>, also showing good performance on short text ranking tasks.</p><p>Outside of document ranking, learning text representations for the target task has been explored in the context of other IR scenarios, including query classification <ref type="bibr" target="#b20">[21]</ref>, query auto-completion <ref type="bibr" target="#b25">[26]</ref>, next query prediction <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b37">38]</ref>, and entity extraction <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSION</head><p>We propose a novel document ranking model composed of two separate deep neural network sub-models, one that matches using a local representation of text, and another that learns a distributed representation before matching. The duet of these two neural networks demonstrated a higher performance than the solo models on the document ranking task as well as significant improvements over all baselines, including both traditional IR baselines and other recently proposed models based on shallow and deep neural networks. Our analysis indicate that these models may achieve even more substantial improvements in the future with much larger datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Visualizing the drop in the local and the distributed model's retrieval score by individually removing each of the passage terms for the query "united states president". Darker green signifies a bigger drop. The local model uses only exact term matches. The distributed model uses matches based on a learned representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Visualizing patterns of query term matches in documents. Query terms are laid out along the vertical axis, and the document terms along the horizontal axis. The short vertical lines correspond to exact matches between pairs of query and document terms. For both queries, the first document was rated relevant by a human judge and the following two as nonrelevant. The query term matches in the relevant documents are observed to be more clustered, and more localized near the beginning of the document.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2 AFigure 3 :</head><label>23</label><figDesc>Figure 3: The duet architecture is composed of the local model (left) and the distributed model (right). The local sub-network takes an interaction matrix of query and document terms as input, whereas the distributed sub-network learns embeddings of the query and the document text before matching. The parameters of both models are optimized jointly during training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The duet model demonstrates significantly better NDCG performance (p &lt; 0.05) on both test sets when trained with judged non-relevant documents as the negative examples, instead of randomly sampling them from the document corpus. The distributed model also shows statistically significant NDCG gain (p &lt; 0.05) on the weighted set, and a non-statistically significant NDCG gain on the unweighted set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure5: NDCG performance of different models by length of query and how rare the rarest query term is in the training data. For the rare term analysis, we place all query terms into one of five categories based on their occurrence counts in the training data. Then we then categorize each query in the test dataset based on the frequency of the rarest term belongs in the query. We include a category for queries with at least one term which has no occurrences in the training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure6: Principal component analysis of models based on retrieval performance across testing queries. Models using exact term matches ( ), proximity (•), and inexact matches ( ) are presented. Our models are presented as black squares.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>2 7 2 8 2 9 2 17 Same2 7 2 8 2 9 2</head><label>2172</label><figDesc>10 2 11 2 12 2 13 2 14 2 15 2 16 2 10 2 11 2 12 2 13 2 14 2 15 2 16 2 17 Same # of total samples Same # of epochs QL baseline (c) Duet model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: We study the performance of our model variants when trained with different size datasets. For every, dataset size we train two models -one for exactly one epoch and another one with multiple epochs such that the total number of training samples seen by the model during training is 131,072.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the three test sets randomly sampled from Bing's search logs. The candidate documents are generated by querying Bing and then rated using human judges.</figDesc><table><row><cell></cell><cell cols="3">queries documents documents query</cell></row><row><cell>training</cell><cell>199,753</cell><cell>998,765</cell><cell>5</cell></row><row><cell>weighted test</cell><cell>7,741</cell><cell>171,302</cell><cell>24.9</cell></row><row><cell>unweighted test</cell><cell>6,808</cell><cell>71,722</cell><cell>10.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance on test data. All duet runs significantly outperformed our local and distributed model (p &lt; 0.05). All duet runs also outperformed non-neural and neural baselines. The difference between the duet model and the best performing baseline per dataset and position (italics) is statistically significant (p &lt; 0.05). The best NDCG performance on each dataset and position is highlighted in bold.</figDesc><table><row><cell cols="2">(a) weighted</cell><cell></cell></row><row><cell></cell><cell cols="2">NDCG@1 NDCG@10</cell></row><row><cell>Non-neural baselines</cell><cell></cell><cell></cell></row><row><cell>LSA</cell><cell>22.4</cell><cell>44.2</cell></row><row><cell>BM25</cell><cell>24.2</cell><cell>45.5</cell></row><row><cell>DM</cell><cell>24.7</cell><cell>46.2</cell></row><row><cell>QL</cell><cell>24.6</cell><cell>46.3</cell></row><row><cell>Neural baselines</cell><cell></cell><cell></cell></row><row><cell>DRMM</cell><cell>24.3</cell><cell>45.2</cell></row><row><cell>DSSM</cell><cell>25.8</cell><cell>48.2</cell></row><row><cell>CDSSM</cell><cell>27.3</cell><cell>48.2</cell></row><row><cell>DESM</cell><cell>25.4</cell><cell>48.3</cell></row><row><cell>Our models</cell><cell></cell><cell></cell></row><row><cell>Local model</cell><cell>24.6</cell><cell>45.1</cell></row><row><cell>Distributed model</cell><cell>28.6</cell><cell>50.5</cell></row><row><cell>Duet model</cell><cell>32.2</cell><cell>53.0</cell></row><row><cell cols="2">(b) unweighted</cell><cell></cell></row><row><cell></cell><cell cols="2">NDCG@1 NDCG@10</cell></row><row><cell>Non-neural baselines</cell><cell></cell><cell></cell></row><row><cell>LSA</cell><cell>31.9</cell><cell>62.7</cell></row><row><cell>BM25</cell><cell>34.9</cell><cell>63.3</cell></row><row><cell>DM</cell><cell>35.0</cell><cell>63.4</cell></row><row><cell>QL</cell><cell>34.9</cell><cell>63.4</cell></row><row><cell>Neural baselines</cell><cell></cell><cell></cell></row><row><cell>DRMM</cell><cell>35.6</cell><cell>65.1</cell></row><row><cell>DSSM</cell><cell>34.3</cell><cell>64.4</cell></row><row><cell>CDSSM</cell><cell>34.3</cell><cell>64.0</cell></row><row><cell>DESM</cell><cell>35.0</cell><cell>64.7</cell></row><row><cell>Our models</cell><cell></cell><cell></cell></row><row><cell>Local model</cell><cell>35.0</cell><cell>64.4</cell></row><row><cell>Distributed model</cell><cell>35.2</cell><cell>64.9</cell></row><row><cell>Duet model</cell><cell>37.8</cell><cell>66.4</cell></row><row><cell cols="3">tual position of matches. We implemented the DRMMLCH×IDF vari-</cell></row><row><cell cols="3">ant of the model on CNTK [40] using word embeddings trained on</cell></row><row><cell cols="3">a corpus of 341,787,174 distinct sentences randomly sampled from</cell></row><row><cell cols="3">Bing's Web index, with a corresponding vocabulary of 5,108,278</cell></row><row><cell cols="3">words. Every training sample for our model was turned into four</cell></row><row><cell cols="3">corresponding training samples for DRMM, comprised of the query,</cell></row><row><cell cols="3">the positive document, and each one of the negative documents.</cell></row><row><cell cols="3">This guaranteed that both models observed the exact same pairs of</cell></row><row><cell cols="3">positive and negative documents during training. We adopted the</cell></row><row><cell cols="2">same loss function as proposed by Guo et al.</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0">A CNTK implementation of the Duet model is available at https://github.com/bmitra-msft/NDRM/blob/ master/notebooks/Duet.ipynb</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1">http://www.lemurproject.org/indri/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2">https://www.microsoft.com/en-us/download/ details.aspx?id=52597</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. The authors are grateful to Rich Caruana, Abdelrahman Mohamed, Pushmeet Kohli, Emine Yilmaz, Filip Radlinski, David Barber, David Hawking, and Milad Shokouhi for the insightful discussions and feedback during this work, and to Frank Seide and Dong Yu for their incredible support with CNTK.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Modeling higher-order term dependencies in information retrieval using query hypergraphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
				<meeting>SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="941" to="950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Quantifying performance and quality gains in distributed web search engines</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Cambazoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<idno type="DOI">10.1145/1571941.1572013</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;09</title>
				<meeting>the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="411" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<title level="m">Report on the sigir 2016 workshop on neural information retrieval (neu-ir)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="96" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Indexing by latent semantic analysis</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JASIS</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="391" to="407" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Query expansion with locally-trained word embeddings</title>
		<author>
			<persName><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
				<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An exploration of axiomatic approaches to information retrieval</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
				<meeting>SIGIR</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="480" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Word embedding based generalized language model for information retrieval</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ganguly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
				<meeting>SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="795" to="798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Modeling interestingness with deep neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Search retargeting using directed query embeddings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grbovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Djuric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Radosavljevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bhamidipati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WWW</title>
				<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="37" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Context-and content-aware embeddings for query rewriting in sponsored search</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grbovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Djuric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Radosavljevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Silvestri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bhamidipati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
				<meeting>SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="383" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A deep relevance matching model for ad-hoc retrieval</title>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CIKM</title>
				<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Parallel distributed processing: Explorations in the microstructure of cognition</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>MIT Press</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="77" to="109" />
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
	<note>chapter Distributed Representations</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic indexing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
				<meeting>SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Convolutional neural network architectures for matching natural language sentences</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
				<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2042" to="2050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning deep structured semantic models for web search using clickthrough data</title>
		<author>
			<persName><forename type="first">P.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CIKM</title>
				<meeting>CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2333" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cumulated gain-based evaluation of IR techniques</title>
		<author>
			<persName><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOIS</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cumulated gain-based evaluation ir techniques</title>
		<author>
			<persName><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOIS</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Exploring the limits of language modeling</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02410</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Representation learning using multi-task deep neural networks for semantic classification and information retrieval</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL</title>
				<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A deep architecture for matching short texts</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1367" to="1375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A markov random field model for term dependencies</title>
		<author>
			<persName><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
				<meeting>SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
				<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Exploring session context using distributed representations of queries and reformulations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
				<meeting>SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Query auto-completion for rare prefixes</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CIKM. ACM</title>
				<meeting>CIKM. ACM</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.01137</idno>
		<title level="m">A dual embedding space model for document ranking</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Improving document ranking with dual word embeddings</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WWW</title>
				<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep sentence embedding using long short-term memory networks: Analysis and application to information retrieval</title>
		<author>
			<persName><forename type="first">H</forename><surname>Palangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="694" to="707" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A study of matchpyramid models on ad-hoc retrieval</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neu-IR &apos;16 SIGIR Workshop on Neural Information Retrieval</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Text matching as image recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI</title>
				<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A language modeling approach to information retrieval</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
				<meeting>SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The probabilistic relevance framework: BM25 and beyond</title>
		<author>
			<persName><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Now Publishers Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Using word embeddings for automatic query expansion</title>
		<author>
			<persName><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Garain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neu-IR &apos;16 SIGIR Workshop on Neural Information Retrieva</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning to rank short text pairs with convolutional deep neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
				<meeting>SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A latent semantic model with convolutional-pooling structure for information retrieval</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mesnil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CIKM</title>
				<meeting>CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning semantic representations using convolutional neural networks for web search</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mesnil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WWW</title>
				<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="373" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A hierarchical recurrent encoder-decoder for generative context-aware query suggestion</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Vahabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Grue</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CIKM</title>
				<meeting>CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="553" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Lda-based document models for ad-hoc retrieval</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
				<meeting>SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="178" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">An introduction to computational networks and the computational network toolkit</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eversole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Seltzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Guenter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kuchaiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Seide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="http://codebox/cntk" />
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<publisher>Microsoft Research</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep. MSR</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning to reweight terms with distributed representations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGIR</title>
				<meeting>SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="575" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Document quality models for web ad hoc retrieval</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CIKM</title>
				<meeting>CIKM</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="331" to="332" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
