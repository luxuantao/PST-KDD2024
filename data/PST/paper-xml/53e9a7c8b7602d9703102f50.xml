<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning to divide and conquer: applying the L* algorithm to automate assume-guarantee reasoning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2008-01-25">25 January 2008</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Corina</forename><forename type="middle">S</forename><surname>Pȃsȃreanu</surname></persName>
							<email>corina.s.pasareanu@nasa.gov</email>
						</author>
						<author>
							<persName><roleName>RIACS</roleName><forename type="first">Dimitra</forename><surname>Giannakopoulou</surname></persName>
							<email>dimitra.giannakopoulou@nasa.gov</email>
						</author>
						<author>
							<persName><forename type="first">Mihaela</forename><surname>Gheorghiu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bobaru</forename><forename type="middle">•</forename><surname>Jamieson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">M</forename><surname>Cobleigh</surname></persName>
							<email>jcobleig@cs.umass.edu</email>
						</author>
						<author>
							<persName><forename type="first">Howard</forename><surname>Barringer</surname></persName>
							<email>howard.barringer@manchester.ac.uk</email>
						</author>
						<author>
							<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Bobaru</surname></persName>
						</author>
						<author>
							<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Cobleigh</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Apple Hill Drive</orgName>
								<address>
									<postCode>01760</postCode>
									<settlement>Natick</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">NASA Ames Research Center</orgName>
								<address>
									<postCode>N269-230, 94035</postCode>
									<settlement>Perot Systems, Moffett Field</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">NASA Ames Research Center</orgName>
								<address>
									<postCode>N269-230, 94035</postCode>
									<settlement>Moffett Field</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<addrLine>10 King&apos;s College Road</addrLine>
									<postCode>M5S 3G4</postCode>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<addrLine>140 Governor&apos;s Drive</addrLine>
									<postCode>01003</postCode>
									<settlement>Amherst</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Manchester</orgName>
								<address>
									<addrLine>Oxford Road</addrLine>
									<postCode>M13 9PL</postCode>
									<settlement>Manchester</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning to divide and conquer: applying the L* algorithm to automate assume-guarantee reasoning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2008-01-25">25 January 2008</date>
						</imprint>
					</monogr>
					<idno type="MD5">1DAFA19FA7AAA3C311663A48BDD9DD99</idno>
					<idno type="DOI">10.1007/s10703-008-0049-6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Assume-guarantee reasoning</term>
					<term>Model checking</term>
					<term>Labeled transition systems</term>
					<term>Learning</term>
					<term>Proof rules</term>
					<term>Compositional verification</term>
					<term>Safety properties</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Assume-guarantee reasoning enables a "divide-and-conquer" approach to the verification of large systems that checks system components separately while using assumptions about each component's environment. Developing appropriate assumptions used to be a difficult and manual process. Over the past five years, we have developed a framework for performing assume-guarantee verification of systems in an incremental and fully automated fashion. The framework uses an off-the-shelf learning algorithm to compute the assumptions. The assumptions are initially approximate and become more precise by means of counterexamples obtained by model checking components separately. The framework supports different assume-guarantee rules, both symmetric and asymmetric. Moreover, we have recently introduced alphabet refinement, which extends the assumption learning process to also infer assumption alphabets. This refinement technique starts with assumption alpha-J.M. Cobleigh currently employed by The MathWorks, Inc.,</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Model checking is an effective technique for finding subtle errors in concurrent systems. Given a finite model of a system and a required property of that system, model checking determines automatically whether the property is satisfied by the system. The cost of model checking techniques may be exponential in the size of the system being verified, a problem known as state explosion <ref type="bibr" target="#b11">[12]</ref>. This can make model checking intractable for systems of realistic size.</p><p>Compositional verification techniques address the state-explosion problem by using a "divide-and-conquer" approach: properties of the system are decomposed into properties of its components and each component is then checked separately. In checking components individually, it is often necessary to incorporate some knowledge of the context in which each component is expected to operate correctly. Assume-guarantee reasoning <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b27">28]</ref> addresses this issue by using assumptions that capture the expectations that a component makes about its environment. Assumptions have traditionally been developed manually, which has limited the practical impact of assume-guarantee reasoning.</p><p>To address this problem, we have proposed a framework <ref type="bibr" target="#b12">[13]</ref> that fully automates assume-guarantee model checking of safety properties for finite labeled transition systems. At the heart of this framework lies an off-the-shelf learning algorithm, namely L* <ref type="bibr" target="#b3">[4]</ref>, that is used to compute the assumptions. In one instantiation of this framework, a safety property P is verified on a system consisting of components M 1 and M 2 by learning an assumption under which M 1 satisfies P . This assumption is then discharged by showing it is satisfied by M 2 . In <ref type="bibr" target="#b5">[6]</ref> we extended the learning framework to support a set of novel symmetric assumeguarantee rules that are sound and complete. In all cases, this learning-based framework is guaranteed to terminate, either stating that the property holds for the system, or returning a counterexample if the property is violated.</p><p>Compositional techniques have been shown particularly effective for well-structured systems that have small interfaces between components <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18]</ref>. Interfaces consist of all communication points through which components may influence each other's behavior. In our initial presentations of the framework <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13]</ref> the alphabets of the assumption automata included all the actions in the component interface. In a case study presented in <ref type="bibr" target="#b26">[27]</ref>, however, we observed that a smaller alphabet can be sufficient to prove a property. This smaller alphabet was determined through manual inspection and with it, assume-guarantee reasoning achieves orders of magnitude improvement over monolithic, i.e., non-compositional, model checking <ref type="bibr" target="#b26">[27]</ref>.</p><p>Motivated by the successful use of a smaller assumption alphabet in learning, we investigated in <ref type="bibr" target="#b16">[17]</ref> whether the process of discovering a smaller alphabet that is sufficient for checking the desired properties can be automated. Smaller alphabets mean smaller interfaces among components, which may lead to smaller assumptions, and hence to smaller verification problems. We developed an alphabet refinement technique that extends the learning framework so that it starts with a small subset of the interface alphabet and adds actions to it as necessary until a required property is either shown to hold or shown to be violated by the system. Actions to be added are discovered by analysis of the counterexamples obtained from model checking the components.</p><p>The learning framework and the alphabet refinement have been implemented within the LTSA model checking tool <ref type="bibr" target="#b23">[24]</ref> and they have been effective in verifying realistic concurrent systems, such as the ones developed in NASA projects. This paper presents and expands the material presented in <ref type="bibr" target="#b12">[13]</ref> (original learning framework for automated assume-guarantee reasoning with an asymmetric rule), <ref type="bibr" target="#b5">[6]</ref> (learning for symmetric rules), and <ref type="bibr" target="#b16">[17]</ref> (alphabet refinement for the original framework). In addition, we describe here a new extension that uses a circular rule, alphabet refinement for symmetric and circular rules, and present new experimental data.</p><p>The rest of the paper is organized as follows. Section 2 provides background on labeled transition systems, finite-state machines, assume-guarantee reasoning, and the L* algorithm. Section 3 follows with a presentation of the learning framework that automates assumeguarantee reasoning for asymmetric and circular rules. Section 4 presents the extension of the framework with symmetric rules, followed by Sect. 5 which presents the algorithm for interface alphabet refinement. Section 6 provides an experimental evaluation of the described techniques. Section 7 surveys related work and Sect. 8 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>In this section we give background information for our work: we introduce labeled transition systems and finite-state machines, together with their associated operators, and also present how properties are expressed and checked in this context. We also introduce assumeguarantee reasoning and the notion of the weakest assumption. Moreover we provide a detailed description of the learning algorithm that we use to automate assume-guarantee reasoning. The reader may wish to skip this section on the first reading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Labeled transition systems (LTSs)</head><p>Let Act be the universal set of observable actions and let τ denote a local action unobservable to a component's environment. We use π to denote a special error state, which models the fact that a safety violation has occurred in the associated transition system. We require that the error state have no outgoing transitions. Formally, an LTS M is a four-tuple Q, αM, δ, q 0 where:</p><formula xml:id="formula_0">• Q is a finite non-empty set of states • αM ⊆ Act is a set of observable actions called the alphabet of M • δ ⊆ Q × (αM ∪ {τ }) × Q is a transition relation • q 0 ∈ Q is the initial state</formula><p>We use to denote the LTS {π}, Act, ∅, π . An LTS M = Q, αM, δ, q 0 is nondeterministic if it contains τ -transitions or if there exists (q, a, q ), (q, a, q ) ∈ δ such that q = q . Otherwise, M is deterministic.</p><p>As an example, consider a simple communication channel that consists of two components whose LTSs are shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Note that the initial state of all LTSs in this paper is state 0. The Input LTS receives an input when the action input occurs, and then sends it to the Output LTS with action send. After being sent some data, Output produces some output using the action output and acknowledges that it has finished, by using the action ack. At this point, both LTSs return to their initial states so the process can be repeated. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Traces</head><p>A trace t of an LTS M is a finite sequence of observable actions that label the transitions that M can perform starting at its initial state (ignoring the τ -transitions). For example, input and input, send are both traces of the Input LTS in Fig. <ref type="figure" target="#fig_0">1</ref>. We sometimes abuse this notation and denote by t both a trace and its trace LTS. For a trace t of length n, its trace LTS consists of n + 1 states, where there is a transition between states m and m + 1 on the m th action in the trace t . The set of all traces of an LTS M is the language of M and is denoted L(M). We denote as errTr(M) the set of traces that lead to π , which are called the error traces of M.</p><p>For ⊆ Act , we use t to denote the trace obtained by removing from t all occurrences of actions a / ∈ . Similarly, M is defined to be an LTS over alphabet which is obtained from M by renaming to τ all the transitions labeled with actions that are not in . Let t , t be two traces. Let , be the sets of actions occurring in t , t , respectively. By the symmetric difference of t and t we mean the symmetric difference of the sets and .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Parallel composition</head><p>Let M = Q, αM, δ, q 0 and M = Q , αM , δ , q 0 . We say that M transits into M with action a, denoted M a -→ M , if and only if (q 0 , a, q 0 ) ∈ δ and either Q = Q , αM = αM , and δ = δ for q 0 = π , or, in the special case where q 0 = π , M = .</p><p>The parallel composition operator is a commutative and associative operator that combines the behavior of two components by synchronizing the actions common to their alphabets and interleaving the remaining actions. For example, in the parallel composition of the Input and Output components from Fig. <ref type="figure" target="#fig_0">1</ref>, actions send and ack will each be synchronized while input and output will be interleaved.</p><p>Formally, let</p><formula xml:id="formula_1">M 1 = Q 1 , αM 1 , δ 1 , q 1 0 and M 2 = Q 2 , αM 2 , δ 2 , q 2 0 be two LTSs. If M 1 = or M 2 = , then M 1 M 2 = . Otherwise, M 1 M 2 is an LTS M = Q, αM, δ, q 0 , where Q = Q 1 × Q 2 , q 0 = (q 1 0 , q 2 0 ), αM = αM 1 ∪ αM 2 ,</formula><p>and δ is defined as follows, where a is either an observable action or τ :</p><formula xml:id="formula_2">M 1 a -→ M 1 , a / ∈ αM 2 M 1 M 2 a -→ M 1 M 2 , M 2 a -→ M 2 , a / ∈ αM 1 M 1 M 2 a -→ M 1 M 2 , M 1 a -→ M 1 , M 2 a -→ M 2 , a = τ M 1 M 2 a -→ M 1 M 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Properties</head><p>We call a deterministic LTS that contains no π states a safety LTS. A safety property is specified as a safety LTS P , whose language L(P ) defines the set of acceptable behaviors When checking a property P , an error LTS denoted P err is created, which traps possible violations with the π state. Formally, the error LTS of a property P = Q, αP , δ, q 0 is P err = Q ∪ {π}, αP err , δ , q 0 , where αP err = αP and δ = δ ∪ {(q, a, π) | q ∈ Q, a ∈ αP , and q ∈ Q : (q, a, q ) ∈ δ}.</p><p>Note that the error LTS is complete, meaning each state other than the error state has outgoing transitions for every action in its alphabet. Also note that the error traces of P err define the language of P 's complement (see Sect. 2.2.3 below).</p><p>For example, the Order property shown in Fig. <ref type="figure" target="#fig_1">2</ref> captures a desired behavior of the communication channel shown in Fig. <ref type="figure" target="#fig_0">1</ref>. The property comprises states 0 and 1, and the transitions denoted by solid arrows. It expresses the fact that inputs and outputs come in matched pairs, with the input always preceding the output. The dashed arrows illustrate the transitions to the error state that are added to the property to obtain its error LTS, Order err .</p><p>To detect violations of a property P by a component M, the parallel composition M P err is computed. It has been proved that M violates P if and only if the π state is reachable in M P err <ref type="bibr" target="#b7">[8]</ref>. For example, state π is not reachable in Input Output Order err , so we conclude that Input Output |= Order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">LTSs and finite-state machines</head><p>As described in Sect. 4, some of the assume-guarantee rules require the use of the "complement" of an LTS. LTSs are not closed under complementation, so we need to define here a more general class of finite-state machines (FSMs) and associated operators for our framework.</p><p>An FSM M is a five-tuple Q, αM, δ, q 0 , F where Q, αM, δ, and q 0 are defined as for LTSs, and F ⊆ Q is a set of accepting states.</p><p>For an FSM M and a trace t , we use δ(q, t) to denote the set of states that M can reach after reading t starting at state q. A trace t is said to be accepted by an FSM M = Q, αM, δ, q 0 , F if δ(q 0 , t) ∩ F = ∅. The language accepted by M, denoted L(M) is the set {t | δ(q 0 , t) ∩ F = ∅}.</p><p>For an FSM M = Q, αM, δ, q 0 , F , we use LTS(M) to denote the LTS Q, αM, δ, q 0 defined by its first four fields. Note that this transformation does not preserve the language of the FSM, i.e., in some cases L(M) = L(LTS(M)). On the other hand, an LTS is in fact a special instance of an FSM, since it can be viewed as an FSM for which all states are accepting. From now on, whenever we apply operators between FSMs and LTSs, it is implied that each LTS is treated as its corresponding FSM.</p><p>We call an FSM M deterministic if and only if LTS(M) is deterministic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Parallel composition of FSMs</head><formula xml:id="formula_3">Let M 1 = Q 1 , αM 1 , δ 1 , q 1 0 , F 1 and M 2 = Q 2 , αM 2 , δ 2 , q 2 0 , F 2 be two FSMs. Then M 1 M 2 is an FSM M = Q, αM, δ, q 0 ,</formula><p>F , where:</p><p>• Q, αM, δ, q 0 = LTS(M 1 ) LTS(M 2 ), and</p><formula xml:id="formula_4">• F = {(s 1 , s 2 ) ∈ Q 1 × Q 2 | s 1 ∈ F 1 and s 2 ∈ F 2 }. Note 1 L(M 1 M 2 ) = {t | t αM 1 ∈ L(M 1 ) ∧ t αM 2 ∈ L(M 2 ) ∧ t ∈ (αM 1 ∪ αM 2 ) * }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Properties</head><p>For FSMs M and P where αP ⊆ αM, M |= P if and only if ∀t ∈ L(M) : t αP ∈ L(P ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Complementation</head><p>The complement of an FSM (or an LTS) M, denoted coM, is an FSM that accepts the complement of M's language. It is constructed by first making M deterministic, subsequently completing it with respect to αM, and finally turning all accepting states into non-accepting ones, and vice-versa. An automaton is complete with respect to some alphabet if every state has an outgoing transition for each action in the alphabet. Completion typically introduces a non-accepting state and appropriate transitions to that state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Assume-guarantee reasoning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Assume-guarantee triples</head><p>In the assume-guarantee paradigm a formula is a triple A M P , where M is a component, P is a property, and A is an assumption about M's environment. The formula is true if whenever M is part of a system satisfying A, then the system must also guarantee P <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b27">28]</ref>, i.e., ∀E, E M |= A implies E M |= P . For LTS M and safety LTSs A and P , checking A M P reduces to checking if state π is reachable in A M P err . Note that when αP ⊆ αA ∪ αM, this is equivalent to A M |= P . Also note that we assume that M contains no π states.</p><p>Theorem 1 A M P is true if and only if π is unreachable in A M P err .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof</head><p>• "⇒": Assume A M P is true. We show that π is unreachable in A M P err by contradiction. Assume π is reachable in A M P err by a trace t . As a result, t αA ∈ L(A), t αM ∈ L(M), and t αP ∈ errTr(P err ) (see <ref type="bibr">Note 1)</ref>.</p><p>Let E be the trace LTS for the trace t αA, with its alphabet augmented so that E M |= A and E M |= P are well defined, i.e., αA ⊆ (αM ∪ αE) and αP ⊆ (αM ∪ αE). By construction, L(E) consists of t αA and all of its prefixes. Since t αA ∈ L(A), we can conclude that E |= A. As a result, E M |= A.</p><p>From our hypothesis that A M P is true, it follows that E M |= A implies E M |= P . However, t αE ∈ L(E), t αM ∈ L(M), and t αP ∈ errTr(P err ). Moreover t 's actions belong to αE ∪ αM ∪ αP . Therefore π is reachable in E M P err on trace t . As a result, we can conclude that E M |= P , which is a contradiction. Thus, π is not reachable in A M P err , as desired.</p><p>• "⇐": Assume π is unreachable in A M P err . We show that A M P by contradiction.</p><p>Assume A M P is not true, i.e., assume ∃E such that E M |= A but E M |= P .</p><p>(Again, we assume that αE is such that |= is well defined in the previous sentence.) Since E M |= P then π is reachable in E M P err by some trace t . As a result, t αE ∈ L(E), t αM ∈ L(M), and t αP ∈ errTr(P err ). Since E M |= A and αA ⊆ αE ∪ αM, it follows that t αA ∈ L(A). As a result, π is reachable in A M P err by t (αA ∪ αM ∪ αP ), which is a contradiction. Thus, A M P is true, as desired.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Weakest assumption</head><p>A central notion of our work is that of the weakest assumption <ref type="bibr" target="#b17">[18]</ref>, defined formally here. Definition 2 (Weakest Assumption for ) Let M 1 be an LTS for a component, P be a safety LTS for a property required of M 1 , and be the interface of the component to the environment. The weakest assumption A w, of M 1 for and for property P is a deterministic LTS such that: (1) αA w, = , and (2) for any component</p><formula xml:id="formula_5">M 2 , true M 1 (M 2 ) P if and only if true M 2 A w, .</formula><p>The notion of a weakest assumption depends on the interface between the component and its environment. Accordingly, in the second condition above, projecting M 2 onto forces M 2 to communicate with M 1 only through actions in . In <ref type="bibr" target="#b17">[18]</ref> we showed that weakest assumptions exist for components expressed as LTSs and properties expressed as safety LTSs. Additionally, we provided an algorithm for computing weakest assumptions.</p><p>The definition above refers to any environment component M 2 that interacts with component M 1 via an alphabet . When M 2 is given, there is a natural notion of the complete interface between M 1 and its environment M 2 , when property P is checked. Definition 3 (Interface Alphabet) Let M 1 and M 2 be component LTSs, and P be a safety LTS. The interface alphabet I of M 1 is defined as:</p><formula xml:id="formula_6">I = (αM 1 ∪ αP ) ∩ αM 2 .</formula><p>Definition 4 (Weakest Assumption) Given M 1 , M 2 , and P as above, the weakest assumption A w is defined as A w, I .</p><p>Note that from the above definitions, it follows that true M 1 M 2 P if and only if true M 2 A w . The following lemma will be used later in the paper.</p><p>Lemma 5 Given M 1 , P , and as above, then A w, M 1 P holds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof A w,</head><p>= A w, . If in Definition 2 we substitute A w, for M 2 , we obtain that: true M 1 A w, P if and only if true A w, A w, . But the latter holds trivially, so we conclude that true M 1 A w, P , which is equivalent to A w, M 1 P , always holds.</p><p>(1) Let S = E = {λ} loop { (2)</p><p>Update T using queries while (S, E, T ) is not closed { (3)</p><p>Add sa to S to make S closed where s ∈ S and a ∈ (4)</p><p>Update T using queries } <ref type="bibr" target="#b4">(5)</ref> Construct candidate DFSM C from (S, E, T ) <ref type="bibr" target="#b5">(6)</ref> Make the conjecture C <ref type="bibr" target="#b6">(7)</ref> if C is correct return C else <ref type="bibr" target="#b7">(8)</ref> Add e ∈ * that witnesses the counterexample to E } Fig. <ref type="figure" target="#fig_2">3</ref> The L* algorithm</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">The L* learning algorithm</head><p>The learning algorithm L* was developed by Angluin <ref type="bibr" target="#b3">[4]</ref> and later improved by Rivest and Schapire <ref type="bibr" target="#b28">[29]</ref>. L* learns an unknown regular language U over alphabet and produces a deterministic finite-state machine (DFSM) that accepts it. L* interacts with a Minimally Adequate Teacher, henceforth referred to as the Teacher, that answers two types of questions. The first type is a membership query, in which L* asks whether a string s ∈ * is in U . The second type is a conjecture, in which L* asks whether a conjectured DFSM C is such that L(C) = U . If L(C) = U the Teacher returns a counterexample, which is a string s in the symmetric difference of L(C) and U .</p><p>At the implementation level, L* creates a table where it incrementally records whether strings in * belong to U . It does this by making membership queries to the Teacher. At various stages L* decides to make a conjecture. It constructs a candidate automaton C based on the information contained in the table and asks the Teacher whether the conjecture is correct. If it is, the algorithm terminates. Otherwise, L* uses the counterexample returned by the Teacher to extend the table with strings that witness differences between L(C) and U .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Details of L*</head><p>In the following more detailed presentation of the algorithm, line numbers refer to L*'s illustration in Fig. <ref type="figure" target="#fig_2">3</ref>. L* builds the observation table (S, E, T ) where S and E are a set of prefixes and suffixes, respectively, both over * . In addition, T is a function mapping (S ∪ S • ) • E to {true, false}, where the operator "•" is defined as follows. Given two sets of sequences of actions P and Q, P • Q = {pq | p ∈ P and q ∈ Q}, where pq represents the concatenation of the sequences p and q. Initially, L* sets S and E to {λ} (line 1), where λ represents the empty string. Subsequently, it updates the function T by making membership queries so that it has a mapping for every string in (S ∪ S • ) • E (line 2). It then checks whether the observation table is closed, i.e., whether ∀s ∈ S, ∀a ∈ , ∃s ∈ S, ∀e ∈ E : T (sae) = T (s e).</p><p>If (S, E, T ) is not closed, then sa is added to S where s ∈ S and a ∈ are the elements for which there is no s ∈ S (line 3). Once sa has been added to S, T needs to be updated (line 4). Lines 3 and 4 are repeated until (S, E, T ) is closed.</p><p>Once the observation table is closed, a candidate DFSM C = Q, αC, δ, q 0 , F is constructed (line 5), with states Q = S, initial state q 0 = λ, and alphabet αC = , where is the alphabet of the unknown language U . The set F consists of the states s ∈ S such that T (s) = true. The transition relation δ is defined as δ(s, a) = s where ∀e ∈ E : T (sae) = T (s e). Such an s is guaranteed to exist when (S, E, T ) is closed. The DFSM C is presented as a conjecture to the Teacher (line 6). If the conjecture is correct, i.e., if L(C) = U , L* returns C as correct (line 7), otherwise it receives a counterexample c ∈ * from the Teacher.</p><p>The counterexample c is analyzed using a process described below to find a suffix e of c that witnesses a difference between L(C) and U (line 8). Suffix e must be such that adding it to E will cause the next conjectured automaton to reflect this difference. Once e has been added to E, L* iterates the entire process by looping around to line 2.</p><p>As stated previously, on line 8 L* must analyze the counterexample c to find a suffix e of c that witnesses a difference between L(C) and U . This is done by finding the earliest point in c at which the conjectured automaton and the automaton that would recognize the language U diverge in behavior. This point found by determining where ζ i = ζ i+1 , where ζ i is computed as follows:</p><p>(1) Let p be the sequence of actions made up of the first i actions in c. Let r be the sequence made up of the actions after the first i actions in c. Thus, c = pr. (2) Run C on p. This moves C into some state q. By construction, this state q corresponds to a row s ∈ S of the observation table. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Characteristics of L*</head><p>L* is guaranteed to terminate with a minimal automaton M for the unknown language U . Moreover, for each closed observation table (S, E, T ), the candidate DFSM C that L* constructs is smallest, in the sense that any other DFSM consistent<ref type="foot" target="#foot_0">1</ref> with the function T has at least as many states as C. This characteristic of L* makes it particularly attractive for our framework. The conjectures made by L* strictly increase in size; each conjecture is smaller than the next one, and all incorrect conjectures are smaller than M. Therefore, if M has n states, L* makes at most (n -1) incorrect conjectures. The number of membership queries made by L* is O(kn 2 + n log m), where k is the size of the alphabet of U , n is the number of states in the minimal DFSM for U , and m is the length of the longest counterexample returned when a conjecture is made.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Learning for assume-guarantee reasoning</head><p>In this section we introduce a simple, asymmetric assume-guarantee rule and we describe a framework which uses L* to learn assumptions that automate reasoning about two compo-nents based on this rule. We also discuss how the framework has been extended to reason about n components and to use circular rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Assume-guarantee rule ASYM</head><p>Our framework incorporates a number of symmetric and asymmetric rules for assumeguarantee reasoning. The simplest assume-guarantee proof is for checking a property P on a system with two components M 1 and M 2 and is as follows <ref type="bibr" target="#b18">[19]</ref>:</p><formula xml:id="formula_7">Rule ASYM 1 : A M 1 P 2 : true M 2 A true M 1 M 2 P</formula><p>In this rule, A denotes an assumption about the environment in which M 1 is placed. Soundness of the rule follows from true M 2 A implies true M 1 M 2 A and from the definition of assume-guarantee triples. Completeness holds trivially, by substituting M 2 for A.</p><p>Note that the rule is not symmetric in its use of the two components, and does not support circularity. Despite its simplicity, our experience with applying compositional verification to several applications has shown it to be most useful in the context of checking safety properties.</p><p>For the use of rule ASYM to be justified, the assumption must be more abstract than M 2 , but still reflect M 2 's behavior. Additionally, an appropriate assumption for the rule needs to be strong enough for M 1 to satisfy P in premise 1. Developing such an assumption is difficult to do manually. In the following, we describe a framework that uses L* to learn assumptions automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning framework for rule ASYM</head><p>To learn assumptions, L* needs to be supplied with a Teacher capable of answering queries and conjectures. We use the LTSA model checker to answer both of these questions. The learning framework for rule ASYM is shown in Fig. <ref type="figure">4</ref>. The alphabet of the learned assumption is = I . As a result, the sequence of automata conjectured by L* converges to the weakest assumption A w .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">The Teacher</head><p>To explain how the teacher answers queries and conjectures we use the following lemma.</p><p>Lemma 6 Let t ∈ * . Then t ∈ L(A w ) if and only if t M 1 P holds. In the assumeguarantee triple, we treat t as its corresponding trace LTS with the alphabet set to .</p><p>Proof By Theorem 1, t M 1 P holds if and only if π is unreachable in t M 1 P err , which is equivalent to checking true M 1 t P . By Definition 2, this is the same as checking true t A w , which is equivalent to checking t ∈ L(A w ).</p><p>Answering queries Recall that L* makes a query by asking whether a trace t is in the language being learned, which is L(A w ). The Teacher must return true if t is in L(A w ) and false otherwise. To answer a query, the Teacher uses LTSA to check t M 1 P (here t is treated as a trace LTS and its alphabet is ). From Lemma 6 it follows if this check is false, then t / ∈ L(A w ) and false is returned to L*. Otherwise, t ∈ L(A w ) and true is returned to L*.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 4 Learning framework for rule ASYM</head><p>Answering conjectures A conjecture consists of an FSM that L* believes will recognize the language being learned. The Teacher must return true if the conjecture is correct. Otherwise, the Teacher must return false and a counterexample that witnesses an error in the conjectured FSM, i.e., a trace in the symmetric difference of the language being learned and that of the conjectured automaton. In our framework, the conjectured FSM is an assumption that is being used to complete an assume-guarantee proof. We treat the conjectured FSM as an LTS, as described in Sect. 2.2, which we denote as the LTS A. To answer the conjecture, the Teacher uses two oracles:</p><p>• Oracle 1 guides L* towards a conjecture that makes premise 1 of rule ASYM true. It checks A M 1 P and if the result is false, then a counterexample t is produced. Since the A M 1 P is false, we know that t ∈ L(A). But, since π is reachable in t M 1 P err , by Lemma 6 we know that t / ∈ L(A w ). Thus, t witnesses a difference between A and A w so it is returned to L* to answer the conjecture. If the triple is true, then the Teacher moves on to Oracle 2.</p><p>• Oracle 2 is invoked to check premise 2 of rule ASYM, i.e., to discharge A on M 2 by verifying that true M 2 A is true. This triple is checked and if it is true, then the assumption makes both premises true and thus, the assume-guarantee rule guarantees that true M 1 M 2 P is true. The Teacher then returns true and the computed assumption A. Note that A is not necessarily A w , it can be stronger than A w , i.e., L(A) ⊆ L(A w ), but the computed assumption is sufficient to prove that the property holds. If the triple is not true, then a counterexample t is produced. In this case further analysis is needed to determine if either P is indeed violated by M 1 M 2 or if A is not precise enough, in which case A needs to be modified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Counterexample analysis</head><p>The counterexample t from Oracle 2 must be analyzed to determine if it is a real counterexample, i.e., if it causes M 1 M 2 to violate P . To do this, the Teacher performs a query on t , in other words it uses LTSA to check t M 1 P (here again t is treated as a trace LTS and its alphabet is ). If this triple is true, then by Lemma 6 we know that t ∈ L(A w ). Since this trace caused true M 2 A to be false, we also know that t / ∈ L(A), thus t witnesses a difference between A and A w . Therefore, t is returned to L* to answer its conjecture. If the triple t M 1 P is false, then the model checker returns a (new) counterexample c that witnesses the violation of P on M 1 in the context of t . With = I , c is guaranteed to be a real error trace in M 1 M 2 P err (we will see in Sect. 5 that when is only a subset of I , this is no longer the case). Thus, true M 1 M 2 P is false and c is returned to the user as a counterexample.</p><p>Remarks A characteristic of L* that makes it particularly attractive for our framework is its monotonicity. This means that the intermediate candidate assumptions that are generated increase in size; each assumption is smaller than the next one. We should note, however, that there is no monotonicity at the semantic level. If A i is the i th assumption conjectured by L*, then</p><formula xml:id="formula_8">|A i | &lt; |A i+1 |, but it is not necessarily the case that L(A i ) ⊂ L(A i+1 ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Example</head><p>Given components Input and Output shown in Fig. <ref type="figure" target="#fig_0">1</ref> and the property Order shown in Fig. <ref type="figure" target="#fig_1">2</ref>, we will check true Input Output Order using rule ASYM. To do this, we set M 1 = Input, M 2 = Output, and P = Order. The alphabet of the interface for this example is = ((αInput ∪ αOrder) ∩ αOutput) = {send, output, ack}.</p><p>As described, at each iteration L* updates its observation table and produces a candidate assumption whenever the table becomes closed. The first closed table obtained is shown in Table <ref type="table" target="#tab_0">1</ref> and its associated assumption, A 1 , is shown in Fig. <ref type="figure">5</ref>. The Teacher answers conjecture A 1 by first invoking Oracle 1, which checks A 1 Input Order . Oracle 1 returns false, with counterexample t = input, send, ack, input , which describes a trace in A 1 Input Order err that leads to state π .</p><p>The Teacher therefore returns counterexample t = send, ack to L*, which uses queries to again update its observation table until it is closed. From this table, shown in Table <ref type="table" target="#tab_1">2</ref>, the assumption A 2 , shown in Fig. <ref type="figure">6</ref>, is constructed and conjectured to the Teacher. This time, Oracle 1 reports that A 2 Input Order is true, meaning the assumption is not too weak. The Teacher then calls Oracle 2 to determine if true Output A 2 . This is also true, so the framework reports that true Input Output Order is true.  This example did not involve weakening of the assumptions produced by L*, since the assumption A 2 was sufficient for the compositional proof. This will not always be the case. Consider Output , shown in Fig. <ref type="figure">9</ref>, which allows multiple send actions to occur before producing output. If Output were replaced by Output , then the verification process would be identical to the previous case, until Oracle 2 is invoked by the Teacher for conjecture A 2 . Oracle 2 returns that true Output A 2 is false, with counterexample send, send, output . The Teacher analyzes this counterexample and determines that in the context of this trace, Input does not violate Order. This trace (projected onto ) is returned to L*, which will weaken the conjectured assumption. The process involves two more iterations, during which assumptions A 3 (Fig. <ref type="figure">7</ref>) and A 4 (Fig. <ref type="figure">8</ref>), are produced. Using A 4 , which is the weakest assump-Fig. <ref type="figure">8 A 4</ref> Fig. <ref type="figure">9</ref> LTS for Output tion A w , both Oracles report true, so it can be concluded that true Input Output Order also holds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Correctness and termination</head><p>Theorem 7 Given components M 1 and M 2 , and property P , the algorithm implemented by our framework for rule ASYM terminates and correctly reports on whether true M 1 M 2 P holds.</p><p>Proof To prove the theorem, we first argue the correctness, and then the termination of our algorithm.</p><p>Correctness: The Teacher in our framework uses the two premises of the assumeguarantee rule to answer conjectures. It only reports that true M 1 M 2 P is true when both premises are true, and therefore correctness is guaranteed by the compositional rule. Our framework reports an error when it detects a trace t of M 2 which, when simulated on M 1 , violates the property, which implies that M 1 M 2 violates P .</p><p>Termination: At any iteration, after an assumption is conjectured, our algorithm reports on whether true M 1 M 2 P is true and terminates, or continues by providing a counterexample to L*. By correctness of L*, we are guaranteed that if it keeps receiving counterexamples to conjectures, it will eventually, at some iteration i, produce A w . During this iteration, Oracle 1 will return true by definition of A w . The Teacher will therefore apply Oracle 2, which will return either true and terminate, or will return a counterexample. This counterexample represents a trace of M 2 that is not contained in L(A w ). Since, as discussed before, A w is both necessary and sufficient, analysis of the counterexample will report that this is a real counterexample, and the algorithm will terminate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Generalization to n components</head><p>We presented our approach so far to the case of two components. Assume now that a system consists of n ≥ 2 components. To</p><formula xml:id="formula_9">check if system M 1 M 2 • • • M n satisfies P , we decompose it into: M 1 and M 2 = M 2 M 3 • • • M n</formula><p>and the learning framework is applied recursively to check the second premise of the assume-guarantee rule.</p><p>At each recursive invocation for M j and M j = M j +1 M j +2 • • • M n , we solve the following problem: find assumption A j such that the following are both true:</p><formula xml:id="formula_10">• A j M j A j -1 and • true M j +1 M j +2 • • • M n A j .</formula><p>Here A j -1 is the assumption for M j -1 and plays the role of the property for the current recursive call. Correctness and termination for this extension follows by induction on n from Theorem 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Extension with a circular rule</head><p>Our framework can accommodate a variety of assume-guarantee rules that are sound. Completeness of rules is required to guarantee termination. We investigate here another rule, that is similar to ASYM but it involves some form of circular reasoning. This rule appeared originally in <ref type="bibr" target="#b18">[19]</ref> (for reasoning about two components). The rule can be extended easily to reasoning about n ≥ 2 components.</p><formula xml:id="formula_11">Rule CIRC-N 1 : A 1 M 1 P 2 : A 2 M 2 A 1 . . . n : A n M n A n-1 n + 1 : true M 1 A n true M 1 M 2 • • • M n P</formula><p>Soundness and completeness of this rule follow from <ref type="bibr" target="#b18">[19]</ref>. Note that this rule is similar to the rule ASYM applied recursively for n + 1 components, where the first and the last component coincide (hence the term "circular"). Learning based assume-guarantee reasoning proceeds as described in Sect. 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Learning with symmetric rules</head><p>Although sound and complete, the rules presented in the previous section are not always satisfactory since they are not symmetric in the use of the components. In <ref type="bibr" target="#b5">[6]</ref> we proposed a set of symmetric rules that are sound and complete and we also described their automation using learning. They are symmetric in the sense that they are based on establishing and discharging assumptions for each component at the same time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Symmetric assume-guarantee rules</head><p>Here we present one of the rules that we found particularly effective in practice. The rule may be used for reasoning about a system composed of n ≥ 2 components:</p><formula xml:id="formula_12">M 1 M 2 • • • M n . Rule SYM-N 1 : A 1 M 1 P 2 : A 2 M 2 P . . . n : A n M n P n + 1 : L(coA 1 coA 2 • • • coA n ) ⊆ L(P ) true M 1 M 2 • • • M n P We require αP ⊆ αM 1 ∪ αM 2 ∪ • • • ∪ αM n and that for i ∈ {1, 2, . . . n} αA i ⊆ (αM 1 ∩ αM 2 ∩ • • • ∩ αM n ) ∪ αP .</formula><p>Informally, each A i is a postulated environment assumption for the component M i to achieve to satisfy property P . Recall that coA i is the complement of A i .</p><p>Theorem 8 Rule SYM-N is sound and complete.</p><p>Proof To establish soundness, we show that the premises together with the negated conclusion lead to a contradiction. Consider a trace t for which the conclusion fails, i.e., t is a trace of M 1 M 2 • • • M n that violates property P , in other words t is not accepted by P . By the definition of parallel composition, t αM 1 is accepted by M 1 . Hence, by premise 1, the trace t αA 1 can not be accepted by A 1 , i.e., t αA 1 is accepted by coA 1 . Similarly, by premise i = 2 . . . n, the trace t αA i is accepted by coA i . By the definition of parallel composition and the fact that an FSM and its complement have the same alphabet, t (αA</p><formula xml:id="formula_13">1 ∪A 2 ∪• • •∪A n ) is accepted by coA 1 coA 2 • • • coA n</formula><p>and it violates P . But premise n + 1 states that the common traces in the complements of the assumptions belong to the language of P . Hence we have a contradiction.</p><p>Our argument for the completeness of Rule SYM-N relies on weakest assumptions. To establish completeness, we assume the conclusion of the rule and show that we can construct assumptions that will satisfy the premises of the rule. We construct the weakest assumptions A w1 , A w2 , . . . A wn for M 1 , M 2 , . . . M n , respectively, to achieve P and substitute them for A 1 , A 2 , . . . A n . Premises 1 through n are satisfied. It remains to show that premise n + 1 holds. Again we proceed by contradiction. Suppose there is a trace t in L(coA w1 coA w2 • • • coA wn ) that violates P ; more precisely t αP ∈ L(coP ). By definition of parallel composition, t is accepted by all coA w1 , coA w2 , . . . coA wn . Furthermore, there will exist t 1 ∈ L(M 1 coP ) such that t 1 αt = t , where αt is the alphabet of the assumptions. Similarly for i = 2 . . . n, t i ∈ L(M i coP ). t 1 , t 2 , . . . t n can be combined into trace t of M 1 M 2 • • • M n such that t αt = t . This contradicts the assumed conclusion that M 1 M 2 • • • M n satisfies P , since t violates P . Therefore, there can not be such a common trace t , and premise n + 1 holds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Learning framework for rule SYM-N</head><p>The framework for rule SYM-N is illustrated in Fig. <ref type="figure" target="#fig_8">10</ref>. To obtain appropriate assumptions, the framework applies the compositional rule in an iterative fashion. At each iteration L* is used to generate appropriate assumptions for each component, based on querying the system and on the results of the previous iteration. Each assumption is then checked to establish the premises of Rule SYM-N. We use separate instances of L* to iteratively learn A w1 , A w2 , . . . A wn .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">The Teacher</head><p>As before, we use model checking to implement the Teacher needed by L*. The conjectures returned by L* are the intermediate assumptions A 1 , A 2 , . . . , A n . The Teacher implements n + 1 oracles, one for each premise in the SYM-N rule:</p><p>• Oracles 1, 2, . . . n guide the corresponding L* instances towards conjectures that make the corresponding premise of rule SYM-N true. Once this is accomplished, Fig. <ref type="figure" target="#fig_8">10</ref> Learning framework for rule SYM-N</p><p>• Oracle n + 1 is invoked to check the last premise of the rule, i.e.,</p><formula xml:id="formula_14">L(coA 1 coA 2 • • • coA n ) ⊆ L(P ). If this is true, rule SYM-N guarantees that M 1 M 2 • • • M n satisfies P .</formula><p>If the result of Oracle n + 1 is false (with counterexample trace t ), by counterexample analysis we identify either that P is indeed violated in M 1 M 2 • • • M n or that some of the candidate assumptions need to be modified. If (some of the) assumptions need to be refined in the next iteration, then behaviors must be added to those assumptions. The result will be that at least the behavior that the counterexample represents will be allowed by those assumptions during the next iteration. The new assumptions may of course be too abstract, and therefore the entire process must be repeated.</p><p>Counterexample analysis Counterexample t is analyzed in a way similar to the analysis for rule ASYM, i.e., we analyze t to determine whether it indeed corresponds to a violation in M 1 M 2 • • • M n . This is checked by simulating t on M i coP , for all i = 1 . . . n. The following cases arise:</p><formula xml:id="formula_15">• If t is a violating trace of all components M 1 , M 2 , . . . M n , then M 1 M 2 • • • M n indeed</formula><p>violates P , which is reported to the user. • If t is not a violating trace of at least one component M i , then we use t to weaken the corresponding assumption(s).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Correctness and termination</head><p>Theorem 9 Given components M 1 , M 2 , . . . M n and property P , the algorithm implemented by our framework for rule SYM-N terminates and correctly reports on whether P holds on</p><formula xml:id="formula_16">M 1 M 2 • • • M n .</formula><p>Proof Correctness: The Teacher returns true only if the premises of rule SYM-N hold, and therefore correctness is guaranteed by the soundness of the rule. The Teacher reports a counterexample only when it finds a trace that is violating in all components, which implies that M 1 M 2 • • • M n also violates P . Termination: At any iteration, the Teacher reports on whether or not P holds on M 1 M 2 • • • M n and terminates, or continues by providing a counterexample to L*. By the correctness of L*, we are guaranteed that if it keeps receiving counterexamples, it eventually produces A w1 , A w2 , . . . A wn , respectively. During this last iteration, premises 1 through n will hold by definition of the weakest assumptions. The Teacher therefore checks premise n + 1, which either returns true and terminates, or returns a counterexample. Since the weakest assumptions are used, by the completeness of the rule, we know that the counterexample analysis reveals a real error, and hence the process terminates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Learning with alphabet refinement</head><p>In this section, we present a technique that extends the learning based assume-guarantee reasoning framework with alphabet refinement. We first illustrate the benefits of smaller interface alphabets for assume-guarantee reasoning through a simple client-server example from <ref type="bibr" target="#b26">[27]</ref>. Then, we explain the effect of smaller interface alphabets on learning assumptions. We then describe the alphabet refinement algorithm, give its properties, and discuss how it extends to reasoning about n components as well as to circular and symmetric rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Example</head><p>Consider a system consisting of a server component and two identical client components that communicate through shared actions. Each client sends requests for reservations to use a common resource, waits for the server to grant the reservation, uses the resource, and then cancels the reservation. For example, the LTS of a client is shown in Fig. <ref type="figure" target="#fig_8">11</ref>, where i = 1, 2. The server, shown in Fig. <ref type="figure" target="#fig_8">13</ref> can grant or deny a request, ensuring that the resource is used only by one client at a time. We are interested in checking the mutual exclusion property illustrated in Fig. <ref type="figure" target="#fig_8">12</ref>, that captures a desired behavior of the client-server application.</p><p>To check the property compositionally, assume that we decompose the system as: M 1 = Client 1 Client 2 and M 2 = Server. The complete alphabet of the interface between M 1 P and M 2 (see Fig. <ref type="figure" target="#fig_8">14</ref>) is:</p><formula xml:id="formula_17">I = {client 1 .cancel, client 1 .grant, client 1 .deny, client 1 .request, client 2 .cancel, client 2 .grant, client 2 .deny, client 2 .request}.</formula><p>Using this alphabet and the learning framework in Sect. 3, an assumption with eight states is learned, shown in Fig. <ref type="figure" target="#fig_6">16</ref>. However, a (much) smaller assumption is sufficient for proving the mutual exclusion property. With the assumption alphabet = {client 1 .cancel, client 1 .grant, client 2 .cancel, client 2 .grant}, which is a strict subset of I (and, in fact, the alphabet of the property), a three-state assumption is learned, shown in Fig. <ref type="figure" target="#fig_8">15</ref>. This smaller assumption enables more efficient verification than the eight state assumption obtained with the complete alphabet. In the following section, we present an extension of the learning framework that infers automatically smaller interface alphabets (and the corresponding assumptions). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Learning based assume-guarantee reasoning and small interface alphabets</head><p>Before describing the alphabet refinement algorithm, let us first consider the effect of smaller interface alphabets on our learning framework. Let M 1 and M 2 be components, P be a property, I be the interface alphabet, and be an alphabet such that ⊂ I . Suppose that we use the learning framework of Sect. 3 but we now set this smaller to be the alphabet that the framework uses when learning the assumption. From the correctness of the assume-guarantee rule, if the framework reports true, true M 1 M 2 P . When it reports false, it is because it finds a trace t in M 2 that falsifies t M 1 P . This, however, does not necessarily mean that M 1 M 2 violates P . Real violations are discovered by our original framework only when the alphabet is I , and are traces t of M 2 that falsify t I M 1 P .  (0, 0, 0)</p><formula xml:id="formula_18">client 1 .request -→ (1, 0, 0) client 2 .request -→ (1, 1, 0) client 2 .grant -→ (1, 2, 2) client 1 .grant -→ (2, 2, π)</formula><p>Learning therefore reports false. This behavior is not feasible, however, in the context of t I = client 2 .request, client 2 .grant, client 2 .cancel, client 1 .request, client 1 .grant . This trace requires a client 2 .cancel action to occur before the client 1 .grant action. Thus, in the context of I the above violating behavior would be infeasible. We conclude that when applying the learning framework with alphabets smaller than I , if true is reported then the property holds in the system, but violations reported may be spurious.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Algorithm for alphabet refinement</head><p>Alphabet refinement extends the learning framework to deal with alphabets that are smaller than I while avoiding spurious counterexamples. The steps of the algorithm are as follows (see Fig.  When spurious counterexamples are detected, the Refiner extends the alphabet with actions from the alphabet of the weakest assumption and the learning of assumptions is restarted. In the worst case, I is reached and, as proven in our previous work, learning then only Fig. <ref type="figure" target="#fig_7">17</ref> Learning with alphabet refinement Fig. <ref type="figure" target="#fig_8">18</ref> Extended counterexample analysis reports real counterexamples. The highlighted steps in the above high-level algorithm are further specified next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alphabet initialization</head><p>The correctness of our algorithm is insensitive to the initial alphabet. We set the initial alphabet to those actions in the alphabet of the property that are also in I , i.e., αP ∩ I . The intuition is that these interface actions are likely to be significant in proving the property, since they are involved in its definition. A good initial guess of the alphabet may achieve big savings in terms of time since it results in fewer refinement iterations.</p><p>Extended counterexample analysis An additional counterexample analysis is appended to the original learning framework as illustrated in Fig. <ref type="figure" target="#fig_7">17</ref>. The steps of this analysis are outlined in Fig. <ref type="figure" target="#fig_8">18</ref>. The extension takes as inputs both the counterexample t returned by Oracle 2, and the counterexample c that is returned by the original counterexample analysis. We modified the "classic" learning framework (Fig. <ref type="figure">4</ref>) to return both c and t to be used in alphabet refinement (as explained below). As discussed, c is obtained because t M 1 P does not hold. The next step is to check whether in fact t uncovers a real violation in the system. As illustrated by the client-server example, the results of checking M 1 P err in the context of t projected to different alphabets may be different. The correct (non-spurious) results are obtained by projecting t on the alphabet I of the weakest assumption. Counterexample analysis therefore calls LTSA to check t I M 1 P . If LTSA finds an error, the resulting counterexample c is real. If error is not reached, then the counterexample is spurious and the alphabet needs to be refined. Refinement proceeds as described next.</p><p>Alphabet refinement When spurious counterexamples are detected, we need to augment the current alphabet so that these counterexamples are eventually eliminated. A counterexample c is spurious if in the context of t I it would not be obtained. Our refinement heuristics are therefore based on comparing c and t I to discover actions in I to be added to the learning alphabet (for this reason c is also projected on I in the refinement process). We have currently implemented the following heuristics:</p><p>AllDiff: adds all the actions in the symmetric difference of t I and c I . A potential problem of this heuristic is that it may add too many actions too soon. If it happens to add useful actions, however, it may terminate after a small number of iterations. Forward: scans the traces t I and c I in parallel from beginning to end looking for the first index i where they disagree; if such an i is found, both actions t I (i), c I (i) are added to the alphabet. By adding fewer actions during each iteration, the algorithm may end up with a smaller alphabet. But, it may take more iterations before it does not produce a spurious result. Backward: is similar to Forward, but scans from the end of the traces to the beginning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Correctness and termination</head><p>For correctness and termination of learning with alphabet refinement, we first show progress of refinement, meaning that at each refinement stage, new actions are discovered to be added to .</p><p>Proposition 10 (Progress of alphabet refinement) Let I = (αM 1 ∪ αP ) ∩ αM 2 be the alphabet of the weakest assumption and let ⊂ I be that of the assumption at the current alphabet refinement stage. Let t be a trace of M 2 A err such that t leads to error on M 1 P err by an error trace c, but t I does not lead to error on M 1 P err . Then t I = c I and there exists an action in their symmetric difference that is not in .</p><p>Proof We prove by contradiction that t I = c I . Suppose t I = c I . We know that c is an error trace on M 1 P err . Since actions of c that are not in I are internal to M 1 P err , then c I also leads to error on M 1 P err . But then t I leads to error on M 1 P err , which is a contradiction.</p><p>We now show that there exists an action in the symmetric difference between t I and c I that is not in (this action will be added to by alphabet refinement). Trace t I is t , with some interleaved actions from I \ . Similarly, c I is t with some interleaved actions from I \ , since c is obtained by composing the trace LTS t with M 1 P err . Thus t = c . We again proceed by contradiction. If all the actions in the symmetric difference between t I and c I were in , we would have</p><formula xml:id="formula_19">t I = t = c = c I , which contradicts t I = c I .</formula><p>Correctness follows from the assume-guarantee rule and the extended counterexample analysis. Termination follows from termination of the original framework, from the progress property and also from the finiteness of I . Moreover, from the progress property it follows that the refinement algorithm for two components has at most | I | iterations.</p><p>Theorem 11 Given components M 1 and M 2 , and property P , L* with alphabet refinement terminates and returns true if M 1 M 2 satisfies P and false otherwise.</p><p>Proof Correctness: When the teacher returns true, then correctness is guaranteed by the assume-guarantee compositional rule. If the teacher returns false, the extended counterexample analysis reports an error for a trace t of M 2 , such that t I in the context of M 1 violates the property (the same test is used in the algorithm from <ref type="bibr" target="#b12">[13]</ref>) hence M 1 M 2 violates the property.</p><p>Termination: From the correctness of L*, we know that at each refinement stage (with alphabet ), if L* keeps receiving counterexamples, it is guaranteed to generate A w, . At that point, Oracle 1 will return true (from Lemma 5). Therefore, Oracle 2 will be applied, which will return either true, and terminate, or a counterexample t . This counterexample is a trace that is not in L(A w, ). It is either a real counterexample (in which case the algorithm terminates) or it is a trace t such that t leads to error on M 1 P err by an error trace c, but t I does not lead to error on M 1 P err . Then from Proposition 10, we know that t I = c I and there exists an action in their symmetric difference that is not in . The Refiner will add this action (and possibly more actions, depending on the refinement strategy) to and the learning algorithm is repeated for this new alphabet. Since I is finite, in the worst case, grows into I , for which termination and correctness follow from Theorem 7.</p><p>We also note a property of weakest assumptions, which states that by adding actions to an alphabet , the corresponding weakest assumption becomes weaker (i.e., contains more behaviors) than the previous one.</p><p>Proposition <ref type="bibr" target="#b11">12</ref> Assume components M 1 and M 2 , property P and the corresponding interface alphabet I . Let , be sets of actions such that: ⊂ ⊂ I . Then:</p><formula xml:id="formula_20">L(A w, ) ⊆ L(A w, ) ⊆ L(A w, I ).</formula><p>Proof Since ⊆ , we know that A w, = A w, . By substituting, in Definition 2, A w, for M 2 , we obtain that: A w, M 1 P if and only if true A w, A w, . From Lemma 5 we know that A w, M 1 P . Therefore, true A w, A w, holds, which implies that</p><formula xml:id="formula_21">L(A w, ) ⊆ L(A w, ). Similarly, L(A w, ) ⊆ L(A w, I ).</formula><p>With alphabet refinement, our framework adds actions to the alphabet, which translates into adding more behaviors to the weakest assumption that L* tries to learn. This means that at each refinement stage i, when the learning framework is started with a new alphabet i such that i-1 ⊂ i , it will try to learn a weaker assumption A w, i than A w, i-1 , which was its goal in the previous stage. Moreover, all these assumptions are under-approximations of the weakest assumption A w, I that is necessary and sufficient to prove the desired property. Note that at each refinement stage the learning framework might stop before computing the corresponding weakest assumption. The above property allows reuse of learning results across refinement stages (see Sect. 8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Generalization to n components</head><p>Alphabet refinement can also be used when reasoning about more than two components using rule ASYM. Recall from Sect. 3 that to check if system M 1 M 2 • • • M n satisfies P we decompose it into: M 1 and M 2 = M 2 M 3 • • • M n and the learning algorithm (without refinement) is invoked recursively for checking the second premise of the assume-guarantee rule.</p><p>Learning with alphabet refinement follows this recursion. At each recursive invocation for M j and M j = M j +1 M j +2 • • • M n , we solve the following problem: find assumption A j and alphabet A j such that the rule premises hold, i.e.</p><p>Oracle 1: A j M j A j -1 and Oracle 2: true</p><formula xml:id="formula_22">M j +1 M j +2 • • • M n A j .</formula><p>Here A j -1 is the assumption for M j -1 and plays the role of the property for the current recursive call. Thus, the alphabet of the weakest assumption for this recursive invocation is j I = (αM j ∪αA j -1 )∩(αM j +1 ∪αM j +2 ∪• • •∪αM n ). If Oracle 2 returns a counterexample, then the counterexample analysis and alphabet refinement proceed exactly as in the twocomponent case. Note that at a new recursive call for M j with a new A j -1 , the alphabet of the weakest assumption is recomputed.</p><p>Correctness and termination of this extension follow from Theorem 11 (and from finiteness of n). The proof proceeds by induction on n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Extension to circular and symmetric rules</head><p>Alphabet refinement also applies to the rules CIRC-N and SYM-N. As mentioned, CIRC-N is a special case of the recursive application of rule ASYM for n + 1 components, where the first and last component coincide. Therefore alphabet refinement applies to CIRC-N as we described here.</p><p>For rule SYM-N, the counterexample analysis for the error trace t obtained from checking premise n + 1 is extended for each component M i , for i = 1 . . . n. The extension works similarly to that for ASYM discussed earlier in this section. The error trace t is simulated on each M i coP with the current assumption alphabet.</p><p>• If t is violating for some i, then we check whether t , with the entire alphabet of the weakest assumption for i is still violating. If it is, then t is a real error trace for M i . If it is not, the alphabet of the current assumption for i is refined with actions from the alphabet of the corresponding weakest assumption. • If t is a real error trace for all i, then it is reported as a real violation of the property on the entire system.</p><p>If alphabet refinement takes place for some i, the learning of the assumption for this i is restarted with the refined alphabet, and premise n + 1 is re-checked with the new learned assumption for i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>We implemented learning with rules ASYM, SYM-N, CIRC-N, with and without alphabet refinement in LTSA and evaluated the implementations for checking safety properties of various concurrent systems that we briefly describe below. The goal of the evaluation was to assess the performance of learning, the effect of alphabet refinement on learning, to compare the effect of the different rules, and to also compare the scalability of compositional verification by learning to that of non-compositional verification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models and properties</head><p>We used the following LTSA models. Gas Station <ref type="bibr" target="#b19">[20]</ref> models a self-serve gas station consisting of k customers, two pumps, and an operator. For k = 3, 4, 5, we checked that the operator correctly gives change to a customer for the pump that he/she used. Chiron <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b22">23]</ref> models a graphical user interface consisting of k artists, a wrapper, a manager, a client initialization module, a dispatcher, and two event dispatchers. For k = 2 . . . 5, we checked two properties: the dispatcher notifies artists of an event before receiving a next event, and the dispatcher only notifies artists of an event after it receives that event. MER <ref type="bibr" target="#b26">[27]</ref> models the flight software component for JPL's Mars Exploration Rovers. It contains k users competing for resources managed by an arbiter. For k = 2 . . . 6, we checked that communication and driving cannot happen at the same time as they share common resources. Rover Executive <ref type="bibr" target="#b12">[13]</ref> models a subsystem of the Ames K9 Rover. The models consists of a main 'Executive' and an 'ExecCondChecker' component responsible for monitoring state conditions. We checked that for a specific shared variable, if the Executive reads its value, then the ExecCondChecker should not read it before the Executive clears it. Gas Station and Chiron were analyzed before, in <ref type="bibr" target="#b13">[14]</ref>, using learning-based assumeguarantee reasoning (with ASYM and no alphabet refinement). Four properties of Gas Station and nine properties of Chiron were checked to study how various 2-way model decompositions (i.e., grouping the modules of each analyzed system into two "super-components") affect the performance of learning. For most of these properties, learning performs better than non-compositional verification and produces small (one-state) assumptions. For some other properties, learning does not perform that well, and produces much larger assumptions. To stress-test our implementation, we selected some of the latter, more challenging properties for our studies here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We performed several sets of experiments. All experiments were performed on a Dell PC with a 2.8 GHz Intel Pentium 4 CPU and 1.0 GB RAM, running Linux Fedora Core 4 and using Sun's Java SDK version 1.5. The results are shown in Tables <ref type="table" target="#tab_3">3,</ref><ref type="table" target="#tab_4">4</ref>, 5, and 6. In the tables, |A| is the maximum assumption size reached during learning, 'Mem.' is the maximum memory used by LTSA to check assume-guarantee triples, measured in MB, and 'Time' is the total CPU running time, measured in seconds. Column 'Monolithic' reports the memory and run-time of non-compositional model checking. We set a limit of 30 minutes for each run. The sign '-' indicates that the limit of 1 GB of memory or the time limit has been exceeded. For these cases, the data is reported as it was when the limit was reached.</p><p>In Table <ref type="table" target="#tab_3">3</ref>, we show the performance of learning with the ASYM rule, without alphabet refinement, and with different alphabet refinement heuristics, for two-way decompositions of the systems we studied. For Gas Station and Chiron we used decompositions generalized from the best two-way decompositions at size 2, as described in <ref type="bibr" target="#b13">[14]</ref>. For Gas Station, the operator and the first pump are one component, and the rest of the modules are the other. For Chiron, the event dispatchers are one component, and the rest of the modules are the other. For MER, half of the users are in one component, and the other half with the arbiter in the other. For the Rover we used the two components described in <ref type="bibr" target="#b12">[13]</ref>. As these results indicate that 'bwd' heuristic is slightly better than the others, we used this heuristic for alphabet refinement in the rest of the experiments.</p><p>Table <ref type="table" target="#tab_4">4</ref> shows the performance of the recursive implementation of learning with rule ASYM, with and without alphabet refinement, as well as that of monolithic (noncompositional) verification, for increasing number of components. For these experiments we used an additional heuristic to compute the ordering of the modules in the sequence M 1 , . . . M n for the recursive learning, to minimize the sizes of the interface alphabets 1 I , . . . n I . We generated offline all possible orders with their associated interface alphabets and then chose the order that minimizes the sum n j =1 | j I |. Automatic generation of orderings was not always possible because of the combinatorial explosion. In some cases with large parameter n, we lifted the results obtained for small values of the parameter on the same model to the model with the larger parameter.</p><p>We also compared learning with and without alphabet refinement for rules SYM-N and CIRC-N under the same conditions as in the previous experiments. The results are in Tables <ref type="table" target="#tab_5">5</ref> and<ref type="table" target="#tab_6">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The results overall show that rule ASYM is more effective than the other rules and that alphabet refinement improves learning significantly.</p><p>Tables <ref type="table" target="#tab_5">5</ref> and<ref type="table" target="#tab_6">6</ref> indicate that generally rules SYM-N and CIRC-N do not improve the performance of learning or the effect of alphabet refinement, but they can sometimes handle cases which were challenging for ASYM, as is the case of SYM-N for Chiron, property 2. Thus there is some benefit in using all of these rules.</p><p>Table <ref type="table" target="#tab_3">3</ref> shows that alphabet refinement improved the assumption size in all cases, and in a few, up to almost two orders of magnitude (see Gas Station with k = 3, 4, Chiron, Property 2, with k = 5, MER with k = 3). It improved memory consumption in 10 out of 15 cases, and also improved running time, as for Gas Station and for MER with k = 3, 4 learning without refinement did not finish within the time limit, whereas with refinement it did. The benefit of alphabet refinement is even more obvious in Table <ref type="table" target="#tab_4">4</ref> where 'No refinement' exceeded the time limit in all but one case, whereas refinement completed in almost all cases, producing smaller assumptions, and using less memory in all the cases, up to two orders of magnitude less in a few.</p><p>Table <ref type="table" target="#tab_4">4</ref> indicates that learning with refinement scales better than without refinement for increasing number of components. As k increases, the memory and time consumption for 'Refinement' grows slower than that of 'Monolithic'. For Gas Station, Chiron (Property 1), and MER, for small values of k, 'Refinement' consumes more memory than 'Monolithic', but as k increases the gap is narrowing, and for the largest k 'Refinement' becomes better than 'Monolithic'. This leads to cases such as MER with k = 6 where, for a large enough parameter value, 'Monolithic' runs out of memory, whereas 'Refinement' succeeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related work</head><p>Several frameworks have been proposed to support assume-guarantee reasoning <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b27">28]</ref>. For example, the Calvin tool <ref type="bibr" target="#b15">[16]</ref> uses assume-guarantee reasoning for the analysis of Java programs, while Mocha <ref type="bibr" target="#b0">[1]</ref> supports modular verification of components with requirements specified based in the Alternating-time Temporal Logic. The practical impact of these approaches has been limited because they require non-trivial human input in defining appropriate assumptions.</p><p>Our previous work <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b17">18]</ref> proposed to use L* to automate assume-guarantee reasoning. Since then, several other frameworks that use L* for learning assumptions have been developed; <ref type="bibr" target="#b2">[3]</ref> presents a symbolic BDD implementation using NuSMV <ref type="bibr" target="#b8">[9]</ref>. This symbolic version was extended in <ref type="bibr" target="#b25">[26]</ref> with algorithms that decompose models using hypergraph partitioning, to optimize the performance of learning on resulting decompositions. Different decompositions are also studied in <ref type="bibr" target="#b13">[14]</ref> where the best two-way decompositions are computed for model-checking with the FLAVERS <ref type="bibr" target="#b14">[15]</ref> and LTSA tools. L* has also been used in <ref type="bibr" target="#b1">[2]</ref> to synthesize interfaces for Java classes, and in <ref type="bibr" target="#b29">[30]</ref> to check component compatibility after component updates.</p><p>Our approach for alphabet refinement is similar in spirit to counterexample-guided abstraction refinement (CEGAR) <ref type="bibr" target="#b10">[11]</ref>. CEGAR computes and analyzes abstractions of programs (usually using a set of abstraction predicates) and refines them based on spurious counter-examples. However, there are some important differences between CEGAR and our algorithm. Alphabet refinement works on actions rather than predicates, it is applied compositionally in an assume-guarantee style and it computes under-approximations (of assumptions) rather than behavioral over-approximations (as it happens in CEGAR). In the future, we plan to investigate more the relationship between CEGAR and our algorithm. The work of <ref type="bibr" target="#b20">[21]</ref> proposes a CEGAR approach to interface synthesis for C libraries. This work does not use learning, nor does it address the use of the resulting interfaces in assume-guarantee verification.</p><p>A similar idea to our alphabet refinement for L* in the context of assume-guarantee verification has been developed independently in <ref type="bibr" target="#b6">[7]</ref>. In that work, L* is started with an empty alphabet, and, similar to our approach, the assumption alphabet is refined when a spurious counterexample is obtained. At each refinement stage, a new minimal alphabet is computed that eliminates all spurious counterexamples seen so far. The computation of such a minimal alphabet is shown to be NP-hard. In contrast, we use much cheaper heuristics, but do not guarantee that the computed alphabet is minimal. The approach presented in <ref type="bibr" target="#b30">[31]</ref> improves upon assume-guarantee learning for systems that communicate based on shared memory, by using SAT based model checking and alphabet clustering.</p><p>The theoretical results in <ref type="bibr" target="#b24">[25]</ref> show that circular assume-guarantee rules can not be both sound and complete. These results do not apply to rules such as ours that involve additional assumptions which appear only in the premises and not in the conclusions of the rules. Note that completeness is not required by our framework (however incompleteness may lead to inconclusive results).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions and future work</head><p>We have introduced a framework that uses a learning algorithm to synthesize assumptions that automate assume-guarantee reasoning for finite-state machines and safety properties. The framework incorporates symmetric, asymmetric and circular assume-guarantee rules and uses alphabet refinement to compute small assumption alphabets that are sufficient for verification. The framework has been applied to a variety of systems where it showed its effectiveness.</p><p>In future work we plan to look beyond checking safety properties and to address further algorithmic optimizations, e.g., reuse of query results and learning tables across alphabet refinement stages. Moreover, we plan to explore techniques alternative to learning for computing assumptions, e.g., we are investigating abstraction refinement techniques for computing assumptions incrementally as abstractions of environments. Finally we plan to perform more experiments to further evaluate our framework.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Example LTSs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 Order property</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( 3 )</head><label>3</label><figDesc>Perform a query on the actions sequence sr. (4) Return the result of the membership query as ζ i . By using binary search, the point where ζ i = ζ i+1 can be found in O(log |c|) queries, where |c| is the length of c.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 A 1 Fig. 6 A 2 Fig. 7 A 3</head><label>516273</label><figDesc>Fig. 5 A 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 11 Fig. 12</head><label>1112</label><figDesc>Fig. 11 Example LTS for a client</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 13 Fig. 15</head><label>1315</label><figDesc>Fig.<ref type="bibr" target="#b12">13</ref> Example LTS for a server</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 16</head><label>16</label><figDesc>Fig.<ref type="bibr" target="#b15">16</ref> Assumption obtained with the complete interface alphabet</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>17</head><label>17</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>): ( 1 )</head><label>1</label><figDesc>Initialize such that ⊆ I . (2) Use the classic learning framework for . If the framework returns true, then report true and STOP. If the framework returns false with counterexamples c and t , go to the next step. (3) Perform extended counterexample analysis with c and t . If c is a real counterexample, then report false and STOP. If c is spurious, then refine , which consists of adding actions to from I . Go to step 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Mapping T 1 E 1</figDesc><table><row><cell></cell><cell>T 1</cell><cell>λ</cell></row><row><cell>S 1</cell><cell>λ</cell><cell>true</cell></row><row><cell></cell><cell>output</cell><cell>false</cell></row><row><cell></cell><cell>ack</cell><cell>true</cell></row><row><cell></cell><cell>output</cell><cell>false</cell></row><row><cell>S 1 •</cell><cell>send</cell><cell>true</cell></row><row><cell></cell><cell>output, ack</cell><cell>false</cell></row><row><cell></cell><cell>output, output</cell><cell>false</cell></row><row><cell></cell><cell>output, send</cell><cell>false</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Mapping T 2 E 2</figDesc><table><row><cell></cell><cell>T 2</cell><cell>λ</cell><cell>ack</cell></row><row><cell></cell><cell>λ</cell><cell>true</cell><cell>true</cell></row><row><cell>S 2</cell><cell>output</cell><cell>false</cell><cell>false</cell></row><row><cell></cell><cell>send</cell><cell>true</cell><cell>false</cell></row><row><cell></cell><cell>ack</cell><cell>true</cell><cell>true</cell></row><row><cell></cell><cell>output</cell><cell>false</cell><cell>false</cell></row><row><cell></cell><cell>send</cell><cell>true</cell><cell>false</cell></row><row><cell></cell><cell>output, ack</cell><cell>false</cell><cell>false</cell></row><row><cell>S 2 •</cell><cell>output, output</cell><cell>false</cell><cell>false</cell></row><row><cell></cell><cell>output, send</cell><cell>false</cell><cell>false</cell></row><row><cell></cell><cell>send, ack</cell><cell>false</cell><cell>false</cell></row><row><cell></cell><cell>send, output</cell><cell>true</cell><cell>true</cell></row><row><cell></cell><cell>send, send</cell><cell>true</cell><cell>true</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc>Comparison of learning for 2-way decompositions with ASYM, with and without alphabet refinement Case</figDesc><table><row><cell></cell><cell>Time</cell><cell>7.76</cell><cell>52.72</cell><cell>530.71</cell><cell>1.90</cell><cell>7.77</cell><cell>35.32</cell><cell>300</cell><cell>0.74</cell><cell>0.92</cell><cell>1.67</cell><cell>17.99</cell><cell>1.01</cell><cell>11.85</cell><cell>1226.80</cell><cell>2.88</cell></row><row><cell>Refinement + allDiff</cell><cell>|A| Mem.</cell><cell>18 4.58</cell><cell>18 36.06</cell><cell>18 360.04</cell><cell>8 1.22</cell><cell>20 6.06</cell><cell>38 44.20</cell><cell>110 -</cell><cell>3 1.05</cell><cell>3 2.20</cell><cell>3 8.13</cell><cell>3 163.85</cell><cell>6 1.78</cell><cell>8 10.56</cell><cell>10 514.41</cell><cell>11 2.54</cell></row><row><cell></cell><cell>Time</cell><cell>36.52</cell><cell>256.82</cell><cell>-</cell><cell>1.86</cell><cell>7.40</cell><cell>33.13</cell><cell>300</cell><cell>0.73</cell><cell>0.92</cell><cell>1.67</cell><cell>18.05</cell><cell>1.02</cell><cell>11.86</cell><cell>1225.95</cell><cell>4.17</cell></row><row><cell>Refinement + fwd</cell><cell>|A| Mem.</cell><cell>37 6.47</cell><cell>37 46.95</cell><cell>20 414.19</cell><cell>8 1.22</cell><cell>20 6.06</cell><cell>38 44.20</cell><cell>110 -</cell><cell>3 1.05</cell><cell>3 2.20</cell><cell>3 8.13</cell><cell>3 163.85</cell><cell>6 1.78</cell><cell>8 10.56</cell><cell>10 514.41</cell><cell>11 2.67</cell></row><row><cell></cell><cell>Time</cell><cell>2.70</cell><cell>19.58</cell><cell>183.70</cell><cell>3.53</cell><cell>23.82</cell><cell>154.00</cell><cell>300</cell><cell>0.73</cell><cell>0.93</cell><cell>1.69</cell><cell>18.08</cell><cell>1.01</cell><cell>11.86</cell><cell>1193.53</cell><cell>2.53</cell></row><row><cell>Refinement + bwd</cell><cell>|A| Mem.</cell><cell>8 3.29</cell><cell>8 24.06</cell><cell>8 248.17</cell><cell>8 1.22</cell><cell>20 6.10</cell><cell>38 44.20</cell><cell>110 -</cell><cell>3 1.05</cell><cell>3 2.20</cell><cell>3 8.13</cell><cell>3 163.85</cell><cell>6 1.78</cell><cell>8 10.56</cell><cell>10 514.41</cell><cell>4 2.37</cell></row><row><cell></cell><cell>Time</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>1.23</cell><cell>5.71</cell><cell>28.00</cell><cell>607.72</cell><cell>1.57</cell><cell>6.39</cell><cell>32.18</cell><cell>246.84</cell><cell>7.84</cell><cell>-</cell><cell>-</cell><cell>1.82</cell></row><row><cell>No refinement</cell><cell>|A| Mem.</cell><cell>177 4.34</cell><cell>195 100.21</cell><cell>53 263.38</cell><cell>9 1.30</cell><cell>21 5.70</cell><cell>3 9 2 7 .10</cell><cell>111 569.24</cell><cell>9 1.14</cell><cell>25 4.45</cell><cell>4 5 2 5 .49</cell><cell>122 131.49</cell><cell>40 6.57</cell><cell>377 158.97</cell><cell>38 391.24</cell><cell>11 2.65</cell></row><row><cell>k</cell><cell></cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell>Gas Station</cell><cell></cell><cell></cell><cell>Chiron,</cell><cell>Property 1</cell><cell></cell><cell></cell><cell>Chiron,</cell><cell>Property 2</cell><cell></cell><cell></cell><cell>MER</cell><cell></cell><cell></cell><cell>Rover Exec.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc>Comparison of recursive learning for ASYM rule with and without alphabet refinement, and monolithic verification</figDesc><table><row><cell>Case</cell><cell>k</cell><cell>ASYM</cell><cell></cell><cell></cell><cell cols="2">ASYM + ref</cell><cell></cell><cell>Monolithic</cell><cell></cell></row><row><cell></cell><cell></cell><cell>|A|</cell><cell>Mem.</cell><cell>Time</cell><cell>|A|</cell><cell>Mem.</cell><cell>Time</cell><cell>Mem.</cell><cell>Time</cell></row><row><cell>Gas Station</cell><cell>3</cell><cell>473</cell><cell>109.97</cell><cell>-</cell><cell>25</cell><cell>2.41</cell><cell>13.29</cell><cell>1.41</cell><cell>0.034</cell></row><row><cell></cell><cell>4</cell><cell>287</cell><cell>203.05</cell><cell>-</cell><cell>25</cell><cell>3.42</cell><cell>22.50</cell><cell>2.29</cell><cell>0.13</cell></row><row><cell></cell><cell>5</cell><cell>268</cell><cell>283.18</cell><cell>-</cell><cell>25</cell><cell>5.34</cell><cell>46.90</cell><cell>6.33</cell><cell>0.78</cell></row><row><cell>Chiron,</cell><cell>2</cell><cell>352</cell><cell>343.62</cell><cell>-</cell><cell>4</cell><cell>0.93</cell><cell>2.38</cell><cell>0.88</cell><cell>0.041</cell></row><row><cell>Property 1</cell><cell>3</cell><cell>182</cell><cell>114.57</cell><cell>-</cell><cell>4</cell><cell>1.18</cell><cell>2.77</cell><cell>1.53</cell><cell>0.062</cell></row><row><cell></cell><cell>4</cell><cell>182</cell><cell>116.66</cell><cell>-</cell><cell>4</cell><cell>2.13</cell><cell>3.53</cell><cell>2.75</cell><cell>0.147</cell></row><row><cell></cell><cell>5</cell><cell>182</cell><cell>115.07</cell><cell>-</cell><cell>4</cell><cell>7.82</cell><cell>6.56</cell><cell>13.39</cell><cell>1.202</cell></row><row><cell>Chiron,</cell><cell>2</cell><cell>190</cell><cell>107.45</cell><cell>-</cell><cell>11</cell><cell>1.68</cell><cell>40.11</cell><cell>1.21</cell><cell>0.035</cell></row><row><cell>Property 2</cell><cell>3</cell><cell>245</cell><cell>68.15</cell><cell>-</cell><cell>114</cell><cell>28</cell><cell>-</cell><cell>1.63</cell><cell>0.072</cell></row><row><cell></cell><cell>4</cell><cell>245</cell><cell>70.26</cell><cell>-</cell><cell>103</cell><cell>23.81</cell><cell>-</cell><cell>2.89</cell><cell>0.173</cell></row><row><cell></cell><cell>5</cell><cell>245</cell><cell>76.10</cell><cell>-</cell><cell>76</cell><cell>32.03</cell><cell>-</cell><cell>15.70</cell><cell>1.53</cell></row><row><cell>MER</cell><cell>2</cell><cell>40</cell><cell>8.65</cell><cell>21.90</cell><cell>6</cell><cell>1.23</cell><cell>1.60</cell><cell>1.04</cell><cell>0.024</cell></row><row><cell></cell><cell>3</cell><cell>501</cell><cell>240.06</cell><cell>-</cell><cell>8</cell><cell>3.54</cell><cell>4.76</cell><cell>4.05</cell><cell>0.111</cell></row><row><cell></cell><cell>4</cell><cell>273</cell><cell>101.59</cell><cell>-</cell><cell>10</cell><cell>9.61</cell><cell>13.68</cell><cell>14.29</cell><cell>1.46</cell></row><row><cell></cell><cell>5</cell><cell>200</cell><cell>78.10</cell><cell>-</cell><cell>12</cell><cell>19.03</cell><cell>35.23</cell><cell>14.24</cell><cell>27.73</cell></row><row><cell></cell><cell>6</cell><cell>162</cell><cell>84.95</cell><cell>-</cell><cell>14</cell><cell>47.09</cell><cell>91.82</cell><cell>-</cell><cell>600</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc>Comparison of learning for SYM-N rule with and without alphabet refinement</figDesc><table><row><cell>Case</cell><cell>k</cell><cell>SYM-N</cell><cell></cell><cell></cell><cell>SYM-N + ref</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>|A|</cell><cell>Mem.</cell><cell>Time</cell><cell>|A|</cell><cell>Mem.</cell><cell>Time</cell></row><row><cell>Gas Station</cell><cell>3</cell><cell>7</cell><cell>1.34</cell><cell>-</cell><cell>83</cell><cell>31.94</cell><cell>874.39</cell></row><row><cell></cell><cell>4</cell><cell>7</cell><cell>2 .05</cell><cell>-</cell><cell>139</cell><cell>38.98</cell><cell>-</cell></row><row><cell></cell><cell>5</cell><cell>7</cell><cell>2 .77</cell><cell>-</cell><cell>157</cell><cell>52.10</cell><cell>-</cell></row><row><cell>Chiron,</cell><cell>2</cell><cell>19</cell><cell>2.21</cell><cell>-</cell><cell>21</cell><cell>4.56</cell><cell>52.14</cell></row><row><cell>Property 1</cell><cell>3</cell><cell>19</cell><cell>2.65</cell><cell>-</cell><cell>21</cell><cell>4.99</cell><cell>65.50</cell></row><row><cell></cell><cell>4</cell><cell>1 9</cell><cell>4 .70</cell><cell>-</cell><cell>21</cell><cell>6.74</cell><cell>70.40</cell></row><row><cell></cell><cell>5</cell><cell>1 9</cell><cell>1 7 .65</cell><cell>-</cell><cell>21</cell><cell>28.38</cell><cell>249.3</cell></row><row><cell>Chiron,</cell><cell>2</cell><cell>7</cell><cell>1.16</cell><cell>-</cell><cell>8</cell><cell>0.93</cell><cell>6.35</cell></row><row><cell>Property 2</cell><cell>3</cell><cell>7</cell><cell>1.36</cell><cell>-</cell><cell>16</cell><cell>1.43</cell><cell>9.40</cell></row><row><cell></cell><cell>4</cell><cell>7</cell><cell>2 .29</cell><cell>-</cell><cell>32</cell><cell>3.51</cell><cell>16.00</cell></row><row><cell></cell><cell>5</cell><cell>7</cell><cell>8 .20</cell><cell>-</cell><cell>64</cell><cell>20.90</cell><cell>57.94</cell></row><row><cell>MER</cell><cell>2</cell><cell>40</cell><cell>6.56</cell><cell>9.00</cell><cell>6</cell><cell>1.69</cell><cell>1.64</cell></row><row><cell></cell><cell>3</cell><cell>6 4</cell><cell>1 1 .90</cell><cell>25.95</cell><cell>8</cell><cell>3.12</cell><cell>4.03</cell></row><row><cell></cell><cell>4</cell><cell>8 8</cell><cell>1 .82</cell><cell>83.18</cell><cell>10</cell><cell>9.61</cell><cell>9.72</cell></row><row><cell></cell><cell>5</cell><cell>112</cell><cell>27.87</cell><cell>239.05</cell><cell>12</cell><cell>19.03</cell><cell>22.74</cell></row><row><cell></cell><cell>6</cell><cell>136</cell><cell>47.01</cell><cell>608.44</cell><cell>14</cell><cell>47.01</cell><cell>47.90</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6</head><label>6</label><figDesc>Comparison of learning for CIRC-N rule with and without alphabet refinement</figDesc><table><row><cell>Case</cell><cell>k</cell><cell>CIRC-N</cell><cell></cell><cell></cell><cell cols="2">CIRC-N + ref</cell><cell></cell></row><row><cell></cell><cell></cell><cell>|A|</cell><cell>Mem.</cell><cell>Time</cell><cell>|A|</cell><cell>Mem.</cell><cell>Time</cell></row><row><cell>Gas Station</cell><cell>3</cell><cell>205</cell><cell>108.96</cell><cell>-</cell><cell>25</cell><cell>2.43</cell><cell>15.10</cell></row><row><cell></cell><cell>4</cell><cell>205</cell><cell>107.00</cell><cell>-</cell><cell>25</cell><cell>3.66</cell><cell>25.90</cell></row><row><cell></cell><cell>5</cell><cell>199</cell><cell>105.89</cell><cell>-</cell><cell>25</cell><cell>5.77</cell><cell>58.74</cell></row><row><cell>Chiron,</cell><cell>2</cell><cell>259</cell><cell>78.03</cell><cell>-</cell><cell>4</cell><cell>0.96</cell><cell>2.71</cell></row><row><cell>Property 1</cell><cell>3</cell><cell>253</cell><cell>77.26</cell><cell>-</cell><cell>4</cell><cell>1.20</cell><cell>3.11</cell></row><row><cell></cell><cell>4</cell><cell>253</cell><cell>77.90</cell><cell>-</cell><cell>4</cell><cell>2.21</cell><cell>3.88</cell></row><row><cell></cell><cell>5</cell><cell>253</cell><cell>81.43</cell><cell>-</cell><cell>4</cell><cell>7.77</cell><cell>7.14</cell></row><row><cell>Chiron,</cell><cell>2</cell><cell>67</cell><cell>100.91</cell><cell>-</cell><cell>327</cell><cell>44.17</cell><cell>-</cell></row><row><cell>Property 2</cell><cell>3</cell><cell>245</cell><cell>75.76</cell><cell>-</cell><cell>114</cell><cell>26.61</cell><cell>-</cell></row><row><cell></cell><cell>4</cell><cell>245</cell><cell>77.93</cell><cell>-</cell><cell>103</cell><cell>23.93</cell><cell>-</cell></row><row><cell></cell><cell>5</cell><cell>245</cell><cell>81.33</cell><cell>-</cell><cell>76</cell><cell>32.07</cell><cell>-</cell></row><row><cell>MER</cell><cell>2</cell><cell>148</cell><cell>597.30</cell><cell>-</cell><cell>6</cell><cell>1.89</cell><cell>1.51</cell></row><row><cell></cell><cell>3</cell><cell>281</cell><cell>292.01</cell><cell>-</cell><cell>8</cell><cell>3.53</cell><cell>4.00</cell></row><row><cell></cell><cell>4</cell><cell>239</cell><cell>237.22</cell><cell>-</cell><cell>10</cell><cell>9.60</cell><cell>10.64</cell></row><row><cell></cell><cell>5</cell><cell>221</cell><cell>115.37</cell><cell>-</cell><cell>12</cell><cell>19.03</cell><cell>27.56</cell></row><row><cell></cell><cell>6</cell><cell>200</cell><cell>88.00</cell><cell>-</cell><cell>14</cell><cell>47.09</cell><cell>79.17</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>A DFSM C is consistent with function T if, for every t in (S ∪ S • ) • E, t ∈ L(C) if and only if T (t) = true.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">MOCHA: modularity in model checking</title>
		<author>
			<persName><forename type="first">R</forename><surname>Alur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Henzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qadeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tasiran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CAV&apos;98</title>
		<meeting>CAV&apos;98<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="521" to="525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Synthesis of interface specifications for Java classes</title>
		<author>
			<persName><forename type="first">R</forename><surname>Alur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cerny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Madhusudan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nam</forename><forename type="middle">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of POPL&apos;05</title>
		<meeting>POPL&apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="98" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Symbolic compositional verification by learning assumptions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Alur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Madhusudan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nam</forename><forename type="middle">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CAV&apos;05</title>
		<meeting>CAV&apos;05<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3576</biblScope>
			<biblScope unit="page" from="548" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning regular sets from queries and counterexamples</title>
		<author>
			<persName><forename type="first">D</forename><surname>Angluin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf Comput</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="87" to="106" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Comparing finite-state verification techniques for concurrent software</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Avrunin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Corbett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Pȃsȃreanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Siegel</surname></persName>
		</author>
		<idno>TR 99-69</idno>
		<imprint>
			<date type="published" when="1999-11">1999. November</date>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts, Department of Computer Science</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Proof rules for automated compositional verification through learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Barringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Giannakopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Pȃsȃreanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SAVCBS&apos;03</title>
		<meeting>SAVCBS&apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="14" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optimized L*-based assume-guarantee reasoning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Strichman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of TACAS&apos;07</title>
		<meeting>TACAS&apos;07<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4424</biblScope>
			<biblScope unit="page" from="276" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Checking safety properties using compositional reachability analysis</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kramer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans Softw Eng Methodol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="78" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">NuSMV 2: an opensource tool for symbolic model checking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cimatti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Giunchiglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Giunchiglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pistore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Roveri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sebastiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tacchella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CAV&apos;02</title>
		<meeting>CAV&apos;02<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="359" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Compositional model checking</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Mcmillan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LICS&apos;89</title>
		<meeting>LICS&apos;89</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Counterexample-guided abstraction refinement</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grumberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Veith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CAV&apos;00</title>
		<meeting>CAV&apos;00<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="154" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Model checking</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grumberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Peled</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning assumptions for compositional verification</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Cobleigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Giannakopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Pȃsȃreanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of TACAS&apos;03</title>
		<meeting>TACAS&apos;03<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="331" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Breaking up is hard to do: an investigation of decomposition for assume-guarantee reasoning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Cobleigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Avrunin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISSTA&apos;06</title>
		<meeting>ISSTA&apos;06<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="97" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Flow analysis for verifying properties of concurrent software systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Cobleigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Naumovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans Softw Eng Methodol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="359" to="430" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Thread-modular verification for shared-memory programs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Flanagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qadeer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ESOP&apos;02</title>
		<meeting>ESOP&apos;02</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="262" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Refining interface alphabets for compositional verification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gheorghiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Giannakopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Pȃsȃreanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of TACAS&apos;07</title>
		<meeting>TACAS&apos;07<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4424</biblScope>
			<biblScope unit="page" from="292" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Component verification with automatically generated assumptions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Giannakopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Pȃsȃreanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Barringer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Autom Softw Eng</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="320" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Model checking and modular verification</title>
		<author>
			<persName><forename type="first">O</forename><surname>Grumberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CON-CUR&apos;91</title>
		<meeting>CON-CUR&apos;91</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="250" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Debugging Ada tasking programs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Helmbold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luckham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Softw</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="47" to="57" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Permissive interfaces</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Henzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jhala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Majumdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ESEC/SIGSOFT FSE&apos;05</title>
		<meeting>ESEC/SIGSOFT FSE&apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Specification and design of (parallel) programs</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the IFIP 9th world congress. IFIP: Amsterdam</title>
		<meeting>the IFIP 9th world congress. IFIP: Amsterdam</meeting>
		<imprint>
			<date type="published" when="1983">1983</date>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="321" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">User interface development and software environments: the Chiron-1 system</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Troup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICSE&apos;91</title>
		<meeting>ICSE&apos;91</meeting>
		<imprint>
			<date type="published" when="1991-05">May 1991</date>
			<biblScope unit="page" from="208" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Concurrency: state models &amp; Java programs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Magee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kramer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Compositional circular assume-guarantee rules cannot be sound and complete</title>
		<author>
			<persName><forename type="first">P</forename><surname>Maier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of FOSSACS</title>
		<meeting>FOSSACS</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning-based symbolic assume-guarantee reasoning with automatic decomposition</title>
		<author>
			<persName><forename type="first">W</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ATVA&apos;06</title>
		<meeting>ATVA&apos;06<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4218</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Towards a compositional SPIN</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Pȃsȃreanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Giannakopoulou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SPIN&apos;06</title>
		<meeting>SPIN&apos;06<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">3925</biblScope>
			<biblScope unit="page" from="234" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">In transition from global to modular temporal reasoning about programs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pnueli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Log Models Concurr Syst</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="123" to="144" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Inference of finite automata using homing sequences</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rivest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Shapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf Comput</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="299" to="347" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dynamic component substitutability analysis</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sharygina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of FM&apos;05</title>
		<meeting>FM&apos;05<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3582</biblScope>
			<biblScope unit="page" from="512" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">SAT-based compositional verification using lazy learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CAV&apos;07</title>
		<meeting>CAV&apos;07<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4590</biblScope>
			<biblScope unit="page" from="39" to="54" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
