<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Topology-Preserving Deep Image Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiaoling</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Li</forename><surname>Fuxin</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Oregon State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dimitris</forename><surname>Samaras</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chao</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Topology-Preserving Deep Image Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0C0667929BF9EA5A85541F5CF8ABB8CC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Segmentation algorithms are prone to topological errors on fine-scale structures, e.g., broken connections. We propose a novel method that learns to segment with correct topology. In particular, we design a continuous-valued loss function that enforces a segmentation to have the same topology as the ground truth, i.e., having the same Betti number. The proposed topology-preserving loss function is differentiable and we incorporate it into end-to-end training of a deep neural network. Our method achieves much better performance on the Betti number error, which directly accounts for the topological correctness. It also performs superiorly on other topology-relevant metrics, e.g., the Adjusted Rand Index and the Variation of Information. We illustrate the effectiveness of the proposed method on a broad spectrum of natural and biomedical datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Image segmentation, i.e., assigning labels to all pixels of an input image, is crucial in many computer vision tasks. State-of-the-art deep segmentation methods <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref> learn high quality feature representations through an end-to-end trained deep network and achieve satisfactory per-pixel accuracy. However, these segmentation algorithms are still prone to make errors on fine-scale structures, such as small object instances, instances with multiple connected components, and thin connections. These fine-scale structures may be crucial in analyzing the functionality of the objects. For example, accurate extraction of thin parts such as ropes and handles is crucial in planning robot actions, e.g., dragging or grasping. In biomedical images, correct delineation of thin objects such as neuron membranes and vessels is crucial in providing accurate morphological and structural quantification of the underlying system. A broken connection or a missing component may only induce marginal per-pixel error, but can cause catastrophic functional mistakes. See Fig. <ref type="figure" target="#fig_0">1</ref> for an example.</p><p>We propose a novel deep segmentation method that learns to segment with correct topology. In particular, we propose a topological loss that enforces the segmentation results to have the same topology as the ground truth, i.e., having the same Betti number (number of connected components and handles). A neural network trained with such loss will achieve high topological fidelity without sacrificing per-pixel accuracy. The main challenge in designing such loss is that topological information, namely, Betti numbers, are discrete values. We need a continuous-valued measurement of the topological similarity between a prediction and the ground truth; and such measurement needs to be differentiable in order to backpropagate through the network.</p><p>To this end, we propose to use theory from computational topology <ref type="bibr" target="#b12">[13]</ref>, which summarizes the topological information from a continuous-valued function (in our case, the likelihood function f is predicted by a neural network). Instead of acquiring the segmentation by thresholding f at 0.5 and inspecting its topology, persistent homology <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b43">44]</ref> captures topological information carried by f over all possible thresholds. This provides a unified, differentiable approach of measuring the topological similarity between f and the ground truth, called the topological loss. We derive the gradient of the loss so that the network predicting f can be optimized accordingly. We focus on 0and 1-dimensional topology (components and connections) on 2-dimensional images.</p><p>Our method is the first end-to-end deep segmentation network with guaranteed topological correctness.</p><p>We show that when the topological loss is decreased to zero, the segmentation is guaranteed to be topologically correct, i.e., have identical topology as the ground truth. Our method is empirically validated by comparing with state-of-the-arts on natural and biomedical datasets with fine-scale structures. It achieves superior performance on metrics that encourage structural accuracy. In particular, our method significantly outperforms others on the Betti number error which exactly measures the topological accuracy. Fig. <ref type="figure" target="#fig_0">1</ref> shows a qualitative result.</p><p>Our method shows how topological computation and deep learning can be mutually beneficial. While our method empowers deep nets with advanced topological constraints, it is also a powerful approach on topological analysis; the observed function is now learned with a highly nonlinear deep network. This enables topology to be estimated based on a semantically informed and denoised observation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related work.</head><p>The closest method to ours is by Mosinska et al. <ref type="bibr" target="#b26">[27]</ref>, which also proposes a topologyaware loss. Instead of actually computing and comparing the topology, their approach uses the response of selected filters from a pretrained VGG19 network to construct the loss. These filters prefer elongated shapes and thus alleviate the broken connection issue. But this method is hard to generalize to more complex settings with connections of arbitrary shapes. Furthermore, even if this method achieves zero loss, its segmentation is not guaranteed to be topologically correct.</p><p>Different ideas have been proposed to capture fine details of objects, mostly revolving around deconvolution and upsampling <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b33">34]</ref>. However these methods focus on the prediction accuracy of individual pixels and are intrinsically topology-agnostic. Topological constraints, e.g., connectivity and loop-freeness, have been incorporated into variational <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b17">18]</ref> and MRF/CRF-based segmentation methods <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b14">15]</ref>. However, these methods focus on enforcing topological constraints in the inference stage, while the trained model is agnostic of the topological prior. In neuron image segmentation, some methods <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b38">39]</ref> directly find an optimal partition of the image into neurons, and thus avoid segmenting membranes. These methods cannot be generalized to other structures, e.g., vessels, cracks and roads.</p><p>For completeness, we also refer to other existing works on topological features and their kernels <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b4">5]</ref>. In graphics, topological similarity was used to simplify and align shapes <ref type="bibr" target="#b31">[32]</ref>. Chen et al. <ref type="bibr" target="#b6">[7]</ref> proposed a topological regularizer to simplify the decision boundary of a classifier. As for deep neural networks, Hofer et al. <ref type="bibr" target="#b20">[21]</ref> proposed a CNN-based topological classifier. This method directly extracts topological information from an input image/shape/graph as input for CNN, hence cannot generate segmentations that preserve topological priors learned from the training set. To the best of our knowledge, no existing work uses topological information as a loss for training a deep neural network in an end-to-end manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>Our method achieves both per-pixel accuracy and topological correctness by training a deep neural network with a new topological loss, L topo (f, g). Here f is the likelihood map predicted by the network and g is the ground truth. The loss function on each training image is a weighted sum of the per-pixel cross-entropy loss, L bce , and the topological loss:</p><formula xml:id="formula_0">L(f, g) = L bce (f, g) + λL topo (f, g),<label>(2.1)</label></formula><p>in which λ controls the weight of the topological loss. We assume a binary segmentation task. Thus, there is one single likelihood function f , whose value ranges between 0 and 1.</p><p>In Sec. 2.1, we introduce the mathematical foundation of topology and how to measure topology of a likelihood map robustly using persistent homology. In Sec. 2.2, we formalize the topological loss as the difference between persistent homology of f and g. We derive the gradient of the loss and prove its correctness. In Sec. 2.3 we explain how to incorporate the loss into the training of a neural network. Although we fix one architecture in experiments, our method is general and can use any neural network that provides pixel-wise prediction. Fig. <ref type="figure" target="#fig_1">2</ref> illustrates the overview of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Topology and Persistent Homology</head><p>Given a continuous image domain, Ω ⊆ R<ref type="foot" target="#foot_0">2</ref> (e.g., a 2D rectangle), we study a likelihood map f (x) : Ω → R, which is predicted by a deep neural network (Fig. <ref type="figure" target="#fig_2">3(c)</ref>). 2 Note that in practice, we only have samples of f at all pixels. In such case, we extend f to the whole image domain Ω by linear interpolation. Therefore, f is piecewise-linear and is controlled by values at all pixels. A segmentation, X ⊆ Ω (Fig. <ref type="figure" target="#fig_2">3</ref>(a)), is calculated by thresholding f at a given value α (often set to 0.5).</p><p>Given X, its d-dimension topological structure, called a homology class <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b27">28]</ref>, is an equivalence class of d-manifolds which can be deformed into each other within X. <ref type="foot" target="#foot_1">3</ref> In particular, 0-dim and 1-dim structures are connected components and handles, respectively. For example, in Fig. <ref type="figure" target="#fig_2">3</ref>(a), the segmentation X has two connected components and one handle. Meanwhile, the ground truth (Fig. <ref type="figure" target="#fig_2">3(b</ref>)) has one connected component and two handles. Given X, we can compute the number of topological structures, called the Betti number, and compare it with the topology of the ground truth.</p><p>However, simply comparing Betti numbers of X and g will result in a discrete-valued topological error function. To incorporate topological prior into deep neural networks, we need a continuousvalued function that can reveal subtle difference between similar structures. Fig. <ref type="figure" target="#fig_2">3(c</ref>) and 3(d) show two likelihood maps f and f with identical segmentations, both with incorrect topology comparing with the ground truth g (Fig. <ref type="figure" target="#fig_2">3(b)</ref>). However, f is more preferable as we need much less effort to change it so that the thresholded segmentation X has a correct topology. In particular, look closely to Fig. <ref type="figure" target="#fig_2">3(c</ref>) and 3(d) near the broken handles and view the landscape of the function. To restore the broken handle in Fig. <ref type="figure" target="#fig_2">3</ref>(d), we need to spend more effort to fill a much deeper gap than Fig. <ref type="figure" target="#fig_2">3(c</ref>). The same situation happens near the missing bridge between the two connected components.</p><p>To capture such subtle structural difference between different likelihood maps, we need a holistic view. In particular, we use the theory of persistent homology <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b12">13]</ref>. Instead of choosing a fixed threshold, persistent homology theory captures all possible topological structures from all thresholds, and summarize all these information in a concise format, called a persistence diagram.</p><formula xml:id="formula_1">X (a) g (b) f f f c b (p) c d (p) (c) f' f' f' (d)</formula><p>Fig. <ref type="figure" target="#fig_2">3</ref> shows that only considering one threshold α = 0.5 is insufficient. We consider thresholding the likelihood function with all possible thresholds. The thresholded results, f α := {x ∈ Ω|f (x) ≥ α} at different α's, constitute a filtration, i.e., a monotonically growing sequence induced by decreasing the threshold α : ∅ ⊆ f α1 ⊆ f α2 ⊆ ... ⊆ f αn = Ω, where α 1 ≥ α 2 ≥ ... ≥ α n . As α decreases, the topology of f α changes. Some new topological structures are born while existing ones are killed. When α &lt; α n , only one connected component survives and never gets killed. See Fig. <ref type="figure" target="#fig_6">4</ref>(a) and 4(d) for filtrations induced by the ground truth g (as a binary-valued function) and the likelihood f . For a continuous-valued function f , its persistence diagram, Dgm(f ), contains a finite number of dots in 2-dimensional plane, called persistent dots. Each persistent dot p ∈ Dgm(f ) corresponds to a topological structure born and dies in the filtration. Denote by birth(p) and death(p) the birth and death time/threshold of the structure. For the connected component born at global minimum and never dies, we say it dies at max x f (x) = 1. The coordinates of the dot p in the diagram are (1birth(p), 1death(p)). <ref type="foot" target="#foot_2">4</ref> Fig. <ref type="figure" target="#fig_6">4</ref>(b) and 4(e) show the diagrams of g and f , respectively. Instead of comparing discrete Betti numbers, we can use the information from persistence diagrams to compare a likelihood f with the ground truth g in terms of topology.</p><p>To compute the persistence diagram Dgm(f ), we use the classic algorithm <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>: we first discretize an image patch into vertices (pixels), edges and squares. Note we adopt a cubical complex discretization, which is more suitable for image analysis <ref type="bibr" target="#b40">[41]</ref>. The adjacency relationship between these discretized elements and their likelihood function values are encoded in a boundary matrix, whose rows and columns correspond to vertices/edges/squares. The matrix is reduced using a modified Gaussian elimination algorithm. The pivoting entries of the reduced matrix correspond to all the dots in Dgm(f ). This algorithm is cubic to the matrix dimension, which is linear to the image size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Topological Loss and its Gradient</head><p>We are now ready to formalize the topological loss, which measures the topological similarity between the likelihood f and the ground truth g. We abuse the notation and also view g as a binary valued function. We use the dots in the persistence diagram of f as they capture all possible topological structures f potentially has. We slightly modify the Wasserstein distance for persistence diagrams <ref type="bibr" target="#b11">[12]</ref>. For persistence diagrams Dgm(f ) and Dgm(g), we find a best one-to-one correspondence between the two sets of dots, and measure the total squared distance between them. <ref type="foot" target="#foot_3">5</ref> An unmatched dot will be matched to the diagonal line. Fig. <ref type="figure" target="#fig_6">4</ref>(c) shows the optimal matching of the diagrams of g and f . Fig. <ref type="figure" target="#fig_6">4</ref>(f) shows the optimal matching of Dgm(g) and Dgm(f ). The latter is clearly more expensive.    The matching algorithm is as follows. A total of k (=Betti number) dots from ground truth (Dgm(g)) are at the upper-left corner p ul = (0, 1), with birth(p ul ) = 1 and death(p ul ) = 0 (Fig. <ref type="figure" target="#fig_6">4(b)</ref>). In Dgm(f ), we find the k dots closest to the corner p ul and match them to the ground truth dots. The remaining dots in Dgm(f ) are matched to the diagonal line. The algorithm computes and sorts the squared distances from all dots in Dgm(f ) to p ul . The complexity is O(n log n), n = the number of dots in Dgm(f ). In general, the state-of-the-art matches two arbitrary diagrams in O(n 3/2 ) time <ref type="bibr" target="#b21">[22]</ref>.</p><p>Let Γ be the set of all possible bijections between Dgm(f ) and Dgm(g). The loss L topo (f, g) is:</p><formula xml:id="formula_2">min γ∈Γ p∈Dgm(f ) ||p -γ(p)|| 2 = p∈Dgm(f ) [birth(p) -birth(γ * (p))] 2 + [death(p) -death(γ * (p))] 2</formula><p>(2.2) where γ * is the optimal matching between two different point sets.</p><p>Intuitively, this loss measures the minimal amount of necessary effort to modify the diagram of Dgm(f ) to Dgm(g) by moving all dots toward their matches. Note there are more dots in Dgm(f ) (Fig. <ref type="figure" target="#fig_6">4(c)</ref>) than in Dgm(g) (Fig. <ref type="figure" target="#fig_6">4(b)</ref>); there will usually be some noise in predicted likelihood map. If a dot p cannot be matched, we match it to its projection on the diagonal line, {(1b, 1d)|b = d}. This means we consider it as noise that should be removed. The dots matched to the diagonal line correspond to small noisy components or noisy loops. These dots will be pushed to the diagonal. And their corresponding components/loops will be removed or merged with others.</p><p>In this example, the extra connected component (a blue cross) in Dgm(f ) will be removed. For comparison, we also show in Fig. <ref type="figure" target="#fig_6">4</ref>(f) the matching between diagrams of the worse likelihood f and g. The cost of the matching is obviously higher, i.e., L topo (f , g) &gt; L topo (f, g). As a theoretical reassurance, it has been proven that this metric for diagrams is stable, and the loss function L topo (f, g) is Lipschitz with regard to the likelihood function f <ref type="bibr" target="#b10">[11]</ref>.</p><p>The following theorem guarantees that the topological loss, when minimized to zero, enforces the constraint that the segmentation has the same topology and the ground truth. Theorem 1 (Topological Correctness). When the loss function L topo (f, g) is zero, the segmentation by thresholding f at 0.5 has the same Betti number as g.</p><p>Proof. Assume L topo (f, g) is zero. By Eq. (2.2), Dgm(f ) and Dgm(g) are matched perfectly, i.e., p = γ * (p), ∀p ∈ Dgm(f ). The two diagrams are identical and have the same number of dots.</p><p>Since g is a binary-valued function, as we decrease the threshold α continuously, all topological structures are created at α = 1. The number of topological structures (Betti number) of g α for any 0 &lt; α &lt; 1 is the same as the number of dots in Dgm(g). Note that for any α ∈ (0, 1), g α is the ground truth segmentation. Therefore, the Betti number of the ground truth is the number of dots in Dgm(g). Similarly, for any α ∈ (0, 1), the Betti number of f α equals to the number of dots in Dgm(f ). Since the two diagrams Dgm(f ) and Dgm(g) are identical, the Betti number of the segmentation f 0.5 is the same as the ground truth segmentation. <ref type="foot" target="#foot_4">6</ref>Topological gradient. The loss function (Eq. (2.2)) depends on crucial thresholds at which topological changes happen, e.g., birth and death times of different dots in the diagram. These crucial thresholds are uniquely determined by the locations at which the topological changes happen. When the underlying function f is differentiable, these crucial locations are exactly critical points, i.e., points with zero gradients. In the training context, our likelihood function f is a piecewise-linear function controlled by the neural network predictions at pixels. For such f , a critical point is always a pixel, since topological changes always happen at pixels. Denote by ω the neural network parameters. For each dot p ∈ Dgm(f ) , we denote by c b (p) and c d (p) the birth and death critical points of the corresponding topological structure (See Fig. <ref type="figure" target="#fig_2">3(c</ref>) for examples).</p><p>Formally, we can show that the gradient of the topological loss ∇ ω L topo (f, g) is:</p><formula xml:id="formula_3">p∈Dgm(f ) 2[f (c b (p)) -birth(γ * (p))] ∂f (c b (p)) ∂ω + 2[f (c d (p)) -death(γ * (p))] ∂f (c d (p)) ∂ω (2.3)</formula><p>To see this, within a sufficiently small neighborhood of f , any other piecewise linear function will have the same super level set filtration as f . The critical points of each persistent dot in Dgm(f ) remains constant within such small neighborhood. So does the optimal mapping γ * . Therefore, the gradient can be straightforwardly computed based on the chain rule, as Eq. ( <ref type="formula" target="#formula_0">2</ref>.3). When function values at different vertices are the same, or when the matching is ambiguous, the gradient does not exist. However, these cases constitute a measure zero subspace in the space of likelihood functions. In summary, L topo (f, g) is a piecewise differentiable loss function over the space of all possible likelihood functions f .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intuition.</head><p>During training, we take the negative gradient direction, i.e.,-∇ ω L topo (f, g). For each topological structure the gradient descent step is pushing the corresponding dot p ∈ Dgm(f ) toward its match γ * (p) ∈ Dgm(g). These coordinates are the function values of the critical points c b (p) and c d (p). They are both moved closer to the matched persistent dot in Dgm(g). We also show the negative gradient force in the landscape view of function f (blue arrow in Fig. <ref type="figure" target="#fig_2">3(c)</ref>). Intuitively, force from the topological gradient will push the saddle points up so that the broken bridge gets connected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Training a Neural Network</head><p>We present some crucial details of our training algorithm. Although our method is architectureagnostic, we select one architecture inspired by DIVE <ref type="bibr" target="#b15">[16]</ref>, which was designed for neuron image segmentation tasks. Our network contains six trainable weight layers, four convolutional layers and two fully connected layers. The first, second and fourth convolutional layers are followed by a single max pooling layer of size 2 × 2 and stride 2 by the end of the layer. Particularly, because of the computational complexity, we use a patch size of 65 × 65 during all the training process.</p><p>We use small patches (65 × 65) instead of big patches/whole image. The reason is twofold. First, the computation of topological information is relatively expensive. Second, the matching process between the persistence diagrams of predicted likelihood map and ground truth can be quite difficult. For example, if the patch size is too big, there will be many persistent dots in Dgm(g) and even more dots in Dgm(g). The matching process is too complex and prone to errors. By focusing on smaller patches, we localize topological structures and fix them one by one.</p><p>Topology of small patches and relative homology. The small patches (65 × 65) often only contain partial branching structures rather than closed loops. To have meaningful topological measure on these small patches, we apply relative persistent homology as a more localized approach for the computation of topological structures. Particularly, for each patch, we consider the topological structures relative to the boundary. It is equivalent to padding a black frame to the boundary and compute the topology to avoid trivial topological structures. As shown in the figure on the right, with the additional frame, a Y -shaped branching structure cropped within the patch will create two handles and be captured by persistent homology.</p><p>Training using these localized topological loss can be very efficient via random patch sampling. Specifically, we do not partition the image into patches. Instead, we randomly and densely sample patches which can overlap. As Theorem 1 guarantees, Our loss enforces correct topology within each sampled patch. These overlaps between patches propagate correct topology everywhere. On the other hand, correct topology within a patch means the segmentation can be a deformation of the ground truth. But the deformation is constrained within the patch. The patch size controls the tolerable geometric deformation.</p><p>Note that during training, even for a same patch, the diagram Dgm(f ), the critical pixels, and the gradients change over every epoch. At each epoch, we resample patches, reevaluate their persistence diagrams, and the loss gradients. After computing topological gradients of all sampled patches from a mini-batch, we aggregate them for backpropagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We evaluate our method on six natural and biomedical datasets: CREMI<ref type="foot" target="#foot_5">7</ref> , ISBI12 <ref type="bibr" target="#b3">[4]</ref>, ISBI13 <ref type="bibr" target="#b2">[3]</ref>, CrackTree <ref type="bibr" target="#b44">[45]</ref>, Road <ref type="bibr" target="#b25">[26]</ref> and DRIVE <ref type="bibr" target="#b35">[36]</ref>. The first three are neuron image segmentation datasets. CREMI contains 125 images of size 1250x1250. ISBI12 <ref type="bibr" target="#b3">[4]</ref> contains 30 images of size 512x512. ISBI13 <ref type="bibr" target="#b2">[3]</ref> contains 100 images of size 1024x1024. These three datasets are neuron images (Electron Microscopy images). The task is to segment membranes and eventually partition the image into neuron regions. CrackTree <ref type="bibr" target="#b44">[45]</ref> contains 206 images of cracks in road (resolution 600x800). Road <ref type="bibr" target="#b25">[26]</ref> has 1108 images from the Massachusetts Roads Dataset. The resolution is 1500x1500. DRIVE <ref type="bibr" target="#b35">[36]</ref> is a retinal vessel segmentation dataset with 20 images. The resolution is 584x565. For all datasets, we use a three-fold cross-validation and report the mean performance over the validation set.</p><p>Evaluation metrics. We use four different evaluation metrics. Pixel-wise accuracy is the percentage of correctly classified pixels. The remaining three metrics are more topology-relevant. The most important one is Betti number error, which directly compares the topology (number of handles) between the segmentation and the ground truth <ref type="foot" target="#foot_6">8</ref> . We randomly sample patches over the segmentation and report the average absolute difference between their Betti numbers and the corresponding ground truth patches. Two more metrics are used to indirectly evaluate the topological correctness: Adapted Rand Index (ARI) and Variation of Information (VOI). They are used in neuron reconstruction to compare the partitioning of the image induced by the segmentation. ARI is the maximal F-score of the foreground-restricted Rand index, a measure of similarity between two clusters. On this version of the Rand index we exclude the zero component of the original labels (background pixels of the ground truth). VOI is a measure of the distance between two clusterings. It is closely related to mutual information; indeed, it is a simple linear expression involving the mutual information.  Baselines. DIVE <ref type="bibr" target="#b15">[16]</ref> is a state-of-the-art neural network that predicts the probability of every individual pixel in a given image being a membrane (border) pixel or not. U-Net <ref type="bibr" target="#b33">[34]</ref> is a popular image segmentation method trained with cross-entropy loss. Mosin. <ref type="bibr" target="#b26">[27]</ref> uses the response of selected filters from a pretrained CNN to construct the topology aware loss. For all methods, we generate segmentations by thresholding the predicted likelihood maps at 0.5.</p><p>Quantitative and qualitative results. Table <ref type="table" target="#tab_0">1</ref> shows the quantitative results for three different neuron image datasets, ISBI12, ISBI13 and CREMI. Table <ref type="table" target="#tab_1">2</ref> shows the quantitative results for DRIVE, CrackTree and Road. Our method significantly outperforms existing methods in topological accuracy (in all three topology-aware metrics), without sacrificing pixel accuracy. Fig. <ref type="figure" target="#fig_7">5</ref> shows qualitative results. Our method demonstrates more consistency in terms of structures and topology. It correctly segments fine structures such as membranes, roads and vessels, while all other methods fail to do so. Note that the topological error cannot be solved by training with dilated ground truth masks. We run additional experiments on CREMI dataset by training a topology-agnostic model with dilated ground truth masks. For 1 and 2 pixel dilation, We have Betti Error 4.126 and 4.431, respectively. They are still significantly worse than TopoLoss (Betti Error = 1.113).</p><p>Ablation study: loss weights. Our loss (Eq. (2.1)) is a weighted combination of cross entropy loss and topological loss. For convenience, we drop the weight of cross entropy loss and weight the topological loss with λ.  Betti error and convergence rate. As we increase lambda, per-pixel accuracy is slightly compromised. The Betti error decreases first but increases later. One important observation is that a certain amount of topological loss improves the convergence rate significantly. Empirically, we choose λ via crossvalidation. Different datasets have different λ's. In general, λ is at the magnitude of 1/10000. This is understandable; while cross entropy loss gradient is applied to all pixels, topological gradient is only applied to a sparse set of critical pixels. Therefore, the weight needs to be much smaller to avoid overfitting with these critical pixels.</p><p>Fig. <ref type="figure" target="#fig_8">6</ref>(a) shows the weighted topological loss (λL topo ), cross entropy loss (L bce ) and total loss (L) at different training epochs. After 30 epochs, the total loss becomes stable. Meanwhile, while L bce increases slightly, L topo decreases. This is reasonable; incorporating of topological loss may force the network to overtrain on certain locations (near critical pixels), and thus may hurt the overall pixel accuracy slightly. This is confirmed by the pixel accuracy of TopoLoss in Tables <ref type="table" target="#tab_0">1</ref> and<ref type="table" target="#tab_1">2</ref>.</p><p>Rationale. To further explain the rationale of topological loss, we first study an example training patch. In Fig. <ref type="figure" target="#fig_9">7</ref>, we plot the likelihood map and the segmentation at different epochs. Within a short period, the likelihood map and the segmentation are stabilized globally, mostly thanks to the cross-entropy loss. After epoch 20, topological errors are gradually fixed by the topological loss. Notice the change of the likelihood map is only at specific topology-relevant locations.</p><p>Our topological loss compliments cross-entropy loss by combating sampling bias. In Fig. <ref type="figure" target="#fig_9">7</ref>, for most membrane pixels, the network learns to make correct prediction quickly. However, for a small amount of difficult locations (blurred regions), it is much harder to learn to predict correctly. The issue is these locations only take a small portion of training pixel samples. Such disproportion cannot be changed even with more annotated training images. Topological loss essentially identifies these difficult locations during training (as critical pixels). It then forces the network to learn patterns near these locations, at the expense of overfitting and consequently slightly compromised per-pixel accuracy.</p><p>On the other hand, we stress that topological loss cannot succeed alone. Without cross-entropy loss, inferring topology from a completely random likelihood map is meaningless. Cross-entropy loss finds a reasonable likelihood map so that the topological loss can improve its topology.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of the importance of topological correctness in a neuron image segmentation task. The goal of this task is to segment membranes which partition the image into regions corresponding to neurons. (a) an input neuron image. (b) ground truth segmentation of the membranes (dark blue) and the result neuron regions. (c) result of a baseline method without topological guarantee [16]. Small pixel-wise errors lead to broken membranes, resulting in merging of many neurons into one. (d) Our method produces the correct topology and the correct partitioning of neurons.</figDesc><graphic coords="2,155.97,76.98,71.28,71.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>•Figure 2 :</head><label>2</label><figDesc>Figure 2: An overview of our method.</figDesc><graphic coords="3,136.70,85.38,52.22,52.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration of topology and topology of a likelihood. For visualization purposes, the higher the function values are, the darker the area is. (a) an example segmentation X with two connected components and one handle. (b) The ground truth with one connected component and two handles. It can also be viewed as a binary valued function g. (c) a likelihood map f whose segmentation (bounded by the red curve) is X. The landscape views near the broken bridge and handle are drawn. Critical points are highlighted in the segmentation. (d) another likelihood map f with the same segmentation as f . But the landscape views reveal that f is worse than f due to deeper gaps.</figDesc><graphic coords="4,120.33,80.96,71.27,70.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Filtration induced by the ground truth function, g.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Filtration induced by the likelihood function, f .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An illustration of persistent homology. Left the filtrations on the ground truth function g and the likelihood function f . The bars of blue and burgundy colors are connected components and handles respectively. (a) For g, all structures are born at α = 1.0 and die at α = 0. (d) For f , from left to right, birth of two components, birth of the longer handle, segmentation at α = 0.5, birth of the shorter handle, death of the extra component, death of both handles. (b) and (e) the persistence diagrams of g and f . (c) the overlay of the two diagrams. Orange arrows denote the matching between the persistent dots. The extra component (a blue cross) from the likelihood is matched to the diagonal line and will be removed if we move Dgm(f ) to Dgm(g). (f) the overlay of the diagrams of g and the worse likelihood Dgm(f ). The matching is obviously more expensive.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Qualitative results of the proposed method compared to other models. From left to right, sample images, ground truth, results for DIVE, U-Net, Mosin. and our proposed TopoLoss.</figDesc><graphic coords="8,116.60,368.38,59.39,59.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: (a) Cross Entropy loss, Topological loss and total loss in terms of training epochs. (b) Ablation studies of lambda on CREMI w.r.t. accuracy, Betti error. (c) Ablation study of lambda on CREMI w.r.t. convergence rate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: For a sample patch from CREMI, we show the likelihood map and segmentation at different training epochs. The first row correspond to likelihood maps and the second row are thresholded results. From left to right, original patch/ground truth, results after 10, 20, 30, 40 and 50 epochs.</figDesc><graphic coords="9,128.47,278.71,55.44,55.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Quantitative results for different models on several medical datasets.</figDesc><table><row><cell>Dataset</cell><cell>Method</cell><cell>Accuracy</cell><cell>ARI</cell><cell>VOI</cell><cell>Betti Error</cell></row><row><cell>ISBI12 ISBI13 CREMI</cell><cell cols="5">DIVE U-Net Mosin. TopoLoss 0.9626 ± 0.0038 0.9444 ± 0.0076 0.782 ± 0.019 0.429 ± 0.104 0.9640 ± 0.0042 0.9434 ± 0.0087 1.235 ± 0.025 3.187 ± 0.307 0.9678 ± 0.0021 0.9338 ± 0.0072 1.367 ± 0.031 2.785 ± 0.269 0.9532 ± 0.0063 0.9312 ± 0.0052 0.983 ± 0.035 1.238 ± 0.251 DIVE 0.9642 ± 0.0018 0.6923 ± 0.0134 2.790 ± 0.025 3.875 ± 0.326 U-Net 0.9631 ± 0.0024 0.7031 ± 0.0256 2.583 ± 0.078 3.463 ± 0.435 Mosin. 0.9578 ± 0.0029 0.7483 ± 0.0367 1.534 ± 0.063 2.952 ± 0.379 TopoLoss 0.9569 ± 0.0031 0.8064 ± 0.0112 1.436 ± 0.008 1.253 ± 0.172 DIVE 0.9498 ± 0.0029 0.6532 ± 0.0247 2.513 ± 0.047 4.378 ± 0.152 U-Net 0.9468 ± 0.0048 0.6723 ± 0.0312 2.346 ± 0.105 3.016 ± 0.253 Mosin. 0.9467 ± 0.0058 0.7853 ± 0.0281 1.623 ± 0.083 1.973 ± 0.310 TopoLoss 0.9456 ± 0.0053 0.8083 ± 0.0104 1.462 ± 0.028 1.113 ± 0.224</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Quantitative results for different models on retinal, crack, and aerial datasets. ± 0.0023 0.8407 ± 0.0257 1.936 ± 0.127 3.276 ± 0.642 U-Net 0.9452 ± 0.0058 0.8343 ± 0.0413 1.975 ± 0.046 3.643 ± 0.536 Mosin. 0.9543 ± 0.0047 0.8870 ± 0.0386 1.167 ± 0.026 2.784 ± 0.293 TopoLoss 0.9521 ± 0.0042 0.9024 ± 0.0113 1.083 ± 0.006 1.076 ± 0.265 CrackTree DIVE 0.9854 ± 0.0052 0.8634 ± 0.0376 1.570 ± 0.078 1.576 ± 0.287 U-Net 0.9821 ± 0.0097 0.8749 ± 0.0421 1.625 ± 0.104 1.785 ± 0.303 Mosin. 0.9833 ± 0.0067 0.8897 ± 0.0201 1.113 ± 0.057 1.045 ± 0.214 TopoLoss 0.9826 ± 0.0084 0.9291 ± 0.0123 0.997 ± 0.011 0.672 ± 0.176 Road DIVE 0.9734 ± 0.0077 0.8201 ± 0.0128 2.368 ± 0.203 3.598 ± 0.783 U-Net 0.9786 ± 0.0052 0.8189 ± 0.0097 2.249 ± 0.175 3.439 ± 0.621 Mosin. 0.9754 ± 0.0043 0.8456 ± 0.0174 1.457 ± 0.096 2.781 ± 0.237 TopoLoss 0.9728 ± 0.0063 0.8671 ± 0.0068 1.234 ± 0.037 1.275 ± 0.192</figDesc><table><row><cell>Dataset</cell><cell>Method</cell><cell>Accuracy</cell><cell>ARI</cell><cell>VOI</cell><cell>Betti Error</cell></row><row><cell></cell><cell>DIVE</cell><cell>0.9549</cell><cell></cell><cell></cell><cell></cell></row><row><cell>DRIVE</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>f depends on the network parameter ω, which will be optimized during training. For convenience, we only use x as the argument of f .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>To be exact, a homology class is an equivalent class of cycles whose difference is the boundary of a (d + 1)-dimensional patch.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>Unlike traditional setting, we use 1 -birth and 1 -death as the x and y axes, because we are using an upperstar filtration, i.e., using the superlevel set, and decreasing α value.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>To be exact, the matching needs to be done on separate dimensions. Dots of 0-dim structures (blue markers in Fig.4(b) and 4(e)) should be matched to the diagram of 0-dim structures. Dots of 1-dim structures (red markers in Fig. 4(b) and 4(e)) should be matched to the diagram of 1-dim structures.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>Note that a more careful proof should be done for diagrams of 0-and 1-dimension separately.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>https://cremi.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6"><p>Note we focus on 1-dimensional topology in evaluation and training as they are more crucial in practice.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgement. The research of Xiaoling Hu and Chao Chen is partially supported by NSF IIS-1909038. The research of Li Fuxin is partially supported by NSF IIS-1911232.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Persistence images: A stable vector representation of persistent homology</title>
		<author>
			<persName><forename type="first">Henry</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tegan</forename><surname>Emerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Shipman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sofya</forename><surname>Chepushtanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Motta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lori</forename><surname>Ziegelmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="218" to="252" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Probabilistic image segmentation with closedness constraints</title>
		<author>
			<persName><forename type="first">Bjoern</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jörg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Kappes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ullrich</forename><surname>Beier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fred</forename><forename type="middle">A</forename><surname>Köthe</surname></persName>
		</author>
		<author>
			<persName><surname>Hamprecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2611" to="2618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">3d segmentation of neurites in em images challenge-isbi</title>
		<author>
			<persName><surname>Arganda-Carreras</surname></persName>
		</author>
		<author>
			<persName><surname>Seung</surname></persName>
		</author>
		<author>
			<persName><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName><surname>Berger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Crowdsourcing the creation of image segmentation algorithms for connectomics</title>
		<author>
			<persName><forename type="first">Ignacio</forename><surname>Arganda-Carreras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivas</forename><forename type="middle">C</forename><surname>Turaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">R</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Cireşan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Giusti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarvesh</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joachim</forename><forename type="middle">M</forename><surname>Dwivedi</surname></persName>
		</author>
		<author>
			<persName><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in neuroanatomy</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">142</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sliced wasserstein kernel for persistence diagrams</title>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Carriere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Cuturi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Oudot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="664" to="673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Enforcing topological constraints in random field image segmentation</title>
		<author>
			<persName><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2011</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2089" to="2096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A topological regularizer for classifiers via persistent homology</title>
		<author>
			<persName><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuyan</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinxun</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusu</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2573" to="2582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Semantic image segmentation with deep convolutional nets and fully connected crfs</title>
		<author>
			<persName><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.7062</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="834" to="848" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Rethinking atrous convolution for semantic image segmentation</title>
		<author>
			<persName><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05587</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Stability of persistence diagrams</title>
		<author>
			<persName><forename type="first">David</forename><surname>Cohen-Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herbert</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Harer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete &amp; Computational Geometry</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="103" to="120" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Lipschitz functions have l p-stable persistence</title>
		<author>
			<persName><forename type="first">David</forename><surname>Cohen-Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herbert</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Harer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuriy</forename><surname>Mileyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations of computational mathematics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="127" to="139" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Computational topology: an introduction</title>
		<author>
			<persName><forename type="first">Herbert</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Harer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>American Mathematical Soc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Topological persistence and simplification</title>
		<author>
			<persName><forename type="first">Herbert</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Letscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Afra</forename><surname>Zomorodian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 41st Annual Symposium on Foundations of Computer Science</title>
		<meeting>41st Annual Symposium on Foundations of Computer Science</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="454" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Tree topology estimation</title>
		<author>
			<persName><forename type="first">Rolando</forename><surname>Estrada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">C</forename><surname>Schmidler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sina</forename><surname>Farsiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1688" to="1701" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep models for brain em image segmentation: novel insights and improved performance</title>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Fakhry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanchuan</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuiwang</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="2352" to="2358" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Jan</forename><surname>Funke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabian</forename><surname>David Tschopp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Grisaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arlo</forename><surname>Sheridan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandan</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Saalfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivas</forename><forename type="middle">C</forename><surname>Turaga</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.02974</idno>
		<title level="m">A deep structured learning approach towards automating connectome reconstruction from 3d electron micrographs</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Segmenting the papillary muscles and the trabeculae from high resolution cardiac ct through restoration of topological handles</title>
		<author>
			<persName><forename type="first">Mingchen</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Axel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information Processing in Medical Imaging</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="184" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A topology preserving level set method for geometric deformable models</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><forename type="middle">L</forename><surname>Prince</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="755" to="768" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning with topological signatures</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Hofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Kwitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Niethammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Uhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1634" to="1644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Geometry helps to compare persistence diagrams</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Kerber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitriy</forename><surname>Morozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnur</forename><surname>Nigmetov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Algorithmics (JEA)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Persistence weighted gaussian kernel for topological data analysis</title>
		<author>
			<persName><forename type="first">Genki</forename><surname>Kusano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasuaki</forename><surname>Hiraoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenji</forename><surname>Fukumizu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2004" to="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Self-repelling snakes for topology-preserving segmentation models</title>
		<author>
			<persName><forename type="first">Carole</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guyader</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Luminita</forename><forename type="middle">A</forename><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="767" to="779" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Machine learning for aerial image labeling</title>
		<author>
			<persName><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>University of Toronto (Canada)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Beyond the pixelwise loss for topology-aware delineation</title>
		<author>
			<persName><forename type="first">Agata</forename><surname>Mosinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Marquez-Neila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Koziński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3136" to="3145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><surname>James R Munkres</surname></persName>
		</author>
		<title level="m">Elements of algebraic topology</title>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning deconvolution network for semantic segmentation</title>
		<author>
			<persName><forename type="first">Hyeonwoo</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seunghoon</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1520" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Global connectivity potentials for random field models</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="818" to="825" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generalized connectivity constraints for spatio-temporal 3d reconstruction</title>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Oswald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Stühmer</surname></persName>
		</author>
		<author>
			<persName><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="32" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Topological function optimization for continuous shape matching</title>
		<author>
			<persName><forename type="first">Adrien</forename><surname>Poulenard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Primoz</forename><surname>Skraba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maks</forename><surname>Ovsjanikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="13" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A stable multi-scale kernel for topological machine learning</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Reininghaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulrich</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Kwitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="4741" to="4748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Active contours under topology control-genus preserving level sets</title>
		<author>
			<persName><forename type="first">Florent</forename><surname>Ségonne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="107" to="117" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Ridge-based vessel segmentation in color images of the retina</title>
		<author>
			<persName><forename type="first">Joes</forename><surname>Staal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meindert</forename><surname>Michael D Abràmoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><forename type="middle">A</forename><surname>Niemeijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bram</forename><surname>Viergever</surname></persName>
		</author>
		<author>
			<persName><surname>Van Ginneken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="501" to="509" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Tree shape priors with connectivity constraints using convex relaxation on general graphs</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Stuhmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Schroder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2336" to="2343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Global regularizing flows with topology preservation for active contours and polygons</title>
		<author>
			<persName><forename type="first">Ganesh</forename><surname>Sundaramoorthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Yezzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="803" to="812" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">L</forename><surname>Srinivas C Turaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Briggman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Winfried</forename><surname>Helmstaedter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Denk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seung</forename><surname>Sebastian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0911.5372</idno>
		<title level="m">Maximin affinity learning of image segmentation</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Graph cut based image segmentation with connectivity priors</title>
		<author>
			<persName><forename type="first">Sara</forename><surname>Vicente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Efficient computation of persistent homology for cubical data</title>
		<author>
			<persName><forename type="first">Hubert</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erald</forename><surname>Vuçini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Topological methods in data analysis and visualization II</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="91" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Optimal topological cycles and their application in cardiac trabeculae restoration</title>
		<author>
			<persName><forename type="first">Pengxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Axel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information Processing in Medical Imaging</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="80" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Topology cuts: A novel mincut/max-flow algorithm for topology preserving segmentation in n-d images</title>
		<author>
			<persName><forename type="first">Yun</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Samaras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qunsheng</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer vision and image understanding</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="90" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Computing persistent homology</title>
		<author>
			<persName><forename type="first">Afra</forename><surname>Zomorodian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunnar</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete &amp; Computational Geometry</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="274" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Cracktree: Automatic crack detection from pavement images</title>
		<author>
			<persName><forename type="first">Qin</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingquan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingzhou</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="227" to="238" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
