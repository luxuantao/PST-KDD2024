<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptive Operator Selection With Bandits for a Multiobjective Evolutionary Algorithm Based on Decomposition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Student Member, IEEE</roleName><forename type="first">Ke</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Álvaro</forename><surname>Fialho</surname></persName>
							<email>alvaro.fialho@ge.com</email>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Sam</forename><surname>Kwong</surname></persName>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Qingfu</forename><surname>Zhang</surname></persName>
							<email>qingfu.zhang@cityu.edu.hk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Sci-ence</orgName>
								<orgName type="institution">City University of Hong Kong</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">He is now with GE Global Research</orgName>
								<orgName type="institution">Nokia Institute of Technology</orgName>
								<address>
									<postCode>69093-415, 21941-615</postCode>
									<settlement>Manaus, Rio de Janeiro</settlement>
									<country>Brazil., Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">City University of Hong Kong</orgName>
								<address>
									<settlement>Kowloon, Hong Kong SAR</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">School of Computer Science and Electronic Engineering</orgName>
								<orgName type="institution">University of Essex</orgName>
								<address>
									<postCode>CO4 3SQ</postCode>
									<settlement>Colchester</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Adaptive Operator Selection With Bandits for a Multiobjective Evolutionary Algorithm Based on Decomposition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A424AEC4BDB04918B3C6719E09F3D80A</idno>
					<idno type="DOI">10.1109/TEVC.2013.2239648</idno>
					<note type="submission">received April 26, 2012; revised September 9, 2012; accepted December 12</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T05:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Adaptive operator selection (AOS)</term>
					<term>decomposition</term>
					<term>multiarmed bandit</term>
					<term>multiobjective evolutionary algorithm based on decomposition (MOEA/D)</term>
					<term>multiobjective optimization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Adaptive operator selection (AOS) is used to determine the application rates of different operators in an online manner based on their recent performances within an optimization process. This paper proposes a bandit-based AOS method, fitness-rate-rank-based multiarmed bandit (FRRMAB). In order to track the dynamics of the search process, it uses a sliding window to record the recent fitness improvement rates achieved by the operators, while employing a decaying mechanism to increase the selection probability of the best operator. Not much work has been done on AOS in multiobjective evolutionary computation since it is very difficult to measure the fitness improvements quantitatively in most Pareto-dominance-based multiobjective evolutionary algorithms. Multiobjective evolutionary algorithm based on decomposition (MOEA/D) decomposes a multiobjective optimization problem into a number of scalar optimization subproblems and optimizes them simultaneously. Thus, it is natural and feasible to use AOS in MOEA/D. We investigate several important issues in using FRRMAB in MOEA/D. Our experimental results demonstrate that FRRMAB is robust and its operator selection is reasonable. Comparison experiments also indicate that FRRMAB can significantly improve the performance of MOEA/D.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>MOP can be stated as minimize F (x) = (f 1 (x), f 2 (x), . . . , f m (x)) T subject to x ∈</p><p>where ⊂ R n is the decision (variable) space and x = (x 1 , . . . , x n ) T ∈ is a candidate solution. F : → R m constitutes m objective functions.</p><p>Let u, v ∈ R m , and u is said to dominate v if and only if u i ≤ v i for every i ∈ {1, . . . , m} and u j &lt; v j for at least one index j ∈ {1, . . . , m}. A solution x * is Pareto optimal to (1) if there is no other solution x ∈ such that F (x) dominates F (x * ). F (x * ) is then called a Pareto optimal (objective) vector. In other words, any improvement in a Pareto optimal solution in one objective must lead to deterioration in at least one other objective. The set of all the Pareto optimal solutions is called the Pareto set (PS). Accordingly, the set of all the Pareto optimal vectors, PF = {F (x) ∈ R m |x ∈ PS}, is called the Pareto front (PF) <ref type="bibr" target="#b0">[1]</ref>.</p><p>Evolutionary algorithms (EAs) are stochastic optimization algorithms inspired by the Darwinian evolution theory. Over the last two decades, much effort has been devoted to developing multiobjective evolutionary algorithms (MOEAs). These methods can generate a set of representative Pareto optimal solutions in a single run. Moreover, they can be used for solving problems without good mathematical properties. Since the pioneering work of Schaffer <ref type="bibr" target="#b1">[2]</ref>, a number of MOEAs has been proposed (e.g., <ref type="bibr" target="#b2">[3]</ref>- <ref type="bibr" target="#b7">[8]</ref>) and applied to a wide range of problem domains <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>.</p><p>A major issue in using EAs, including MOEAs, is that one has to set a number of control parameters and select genetic operators to which the algorithm performance is often very sensitive. Different problems require different settings; people from other domains often find it very hard to make a proper setting for their problems without help from EA experts. For this reason, automatic parameter and operator configuration has been a very important and active research topic in the EA community <ref type="bibr" target="#b10">[11]</ref>.</p><p>In this paper, we propose and study an adaptive operator selection (AOS) method for deciding which operator should be employed at a time point in an MOEA. There are two main tasks that need to be performed in an AOS method. One is to decide how much reward (i.e., credit) should be assigned to an operator based on its recent performance in the search process. The other is to select an operator to use at the next time point based on these current reward values. A fundamental issue behind these two highly related tasks is the so-called exploration versus exploitation (EvE) dilemma: one hopes to give more chances to operators with better track records (exploitation), but also wants to explore poor operators in the future search (exploration), since an operator might perform significantly differently at different search stages.</p><p>The EvE dilemma has intensively been studied in the game theory community for dealing with the multiarmed bandit (MAB) problem. Many efficient methods for the MAB problem can be found in the literature. A prominent method is the upper confidence bound (UCB) algorithm <ref type="bibr" target="#b11">[12]</ref>, which guarantees asymptotic optimality in terms of the total cumulative reward. However, it is not straightforward to apply these methods to the AOS problem in EAs. The MAB problem in the game theory considers stationary reward distributions, while the performance of an operator in the AOS problem might significantly vary during the search process. Moreover, the range of reward values is problem dependent in the AOS scenario, while, in the original MAB case, the rewards are always Boolean.</p><p>Some effort has been dedicated to the modification of MAB algorithms, in particular, the UCB algorithm to address the dynamic and unpredictable aspects of the AOS problem. The dynamic MAB algorithm <ref type="bibr" target="#b12">[13]</ref> recomputes the bandit statistics from scratch whenever a change in the reward distribution is detected. The sliding MAB method <ref type="bibr" target="#b13">[14]</ref> uses a sliding window to achieve a faster update of the quality measure of each operator to better fit the current stage of the search process. An extreme value-based credit assignment was proposed in <ref type="bibr" target="#b14">[15]</ref>, which assumes that rare but high fitness improvements are more important than frequent and moderate ones. To improve algorithm robustness for different fitness landscapes, two rankbased credit assignment schemes, the area-under-curve (AUC) and the sum-of-ranks (SR), were proposed in <ref type="bibr" target="#b15">[16]</ref>. These bandit-based operator selection methods and credit assignment schemes have been used in several different EAs, including genetic algorithms and differential evolution (DE). Other AOS methods, based on probabilities, can be found in the literature, such as the ones used in SaDE <ref type="bibr" target="#b16">[17]</ref>, JADE <ref type="bibr" target="#b17">[18]</ref>, and jDE <ref type="bibr" target="#b18">[19]</ref> algorithms. However, most of the existing works concern the single-objective optimization problems, in which the fitness improvement of an offspring solution against its parent can easily be measured. In MOPs, however, some solutions are incomparable. Thus, it is not straightforward to define and compute the quality difference between two solutions. Probably, due to this reason, the use of AOS in MOEAs is still relatively scarce. Some pioneering works along this direction include JADE2 <ref type="bibr" target="#b19">[20]</ref>, MOSaDE <ref type="bibr" target="#b20">[21]</ref>, OW-MOSaDE <ref type="bibr" target="#b21">[22]</ref>, Adap-MODE <ref type="bibr" target="#b22">[23]</ref>, and MODE/SN <ref type="bibr" target="#b23">[24]</ref>. It is also worth noting that some other methods consider the so-called multioperators, such as the ensemble-based method <ref type="bibr" target="#b24">[25]</ref> and the composite operators <ref type="bibr" target="#b25">[26]</ref>. However, a bandit-based AOS method is different from these. It selects an operator according to some deterministic rules based on MAB algorithms, while the others usually select an operator based on some stochastic rules.</p><p>Our proposed bandit-based AOS method (FRRMAB), in this paper, employs a sliding window to follow the dynamics of the search process. Instead of using the raw fitness value, the fitness improvement rate is used to evaluate the quality difference between the parent solution and its offspring in a normalized manner. In addition, in order to increase the influence of the best operator at the current time point, a decaying mechanism is introduced to calculate the final credit value of each operator. The FRRMAB AOS method is used within an multiobjective evolutionary algorithm based on a decomposition (MOEA/D) variant, MOEA/D-DRA <ref type="bibr" target="#b26">[27]</ref>, which was the winning algorithm in the CEC 2009 MOEA contest. The underlying mechanism of MOEA/D <ref type="bibr" target="#b5">[6]</ref> is to decompose an MOP into a number of single-objective optimization problems. Thus, strategies for single-objective optimization can easily be used in MOEA/D. The resulting algorithmic combination, referred to as MOEA/D-FRRMAB, is experimentally studied on a set of multiobjective optimization benchmark problems. This outperforms some baseline algorithms, including some state-of-the-art variants of MOEA/D, and MOEA/D using other AOS methods.</p><p>The remainder of this paper is organized as follows. The background and some related works are reviewed in Section II. Our proposed AOS method is described in detail in Section III, while its combination with the MOEA/D algorithm is presented in Section IV. Experimental results are given and analyzed in Section V. Section VI concludes this paper and discusses some possible research issues for further work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Background and Related Work</head><p>The performance of an EA depends on its parameter settings. Operators can also be regarded as parameters in an EA. A brief overview of different manners of doing a parameter setting in EAs is given in Section II-A. Then, Section II-B presents a more detailed description and review on the AOS methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Parameter Setting in Evolutionary Algorithms</head><p>Different kinds of approaches for parameter setting in EAs have been proposed in the literature. A taxonomy proposed in <ref type="bibr" target="#b27">[28]</ref> classifies them into two categories. One is for parameter tuning and the other is for parameter control. The former sets the parameters in an offline manner based on statistics extracted from several runs, and provides a fixed parameter setting that can be used for solving a new instance. Parameter control methods, which dynamically adjust the parameters during the run, can be further divided into three classes. The first is the deterministic method that adjusts the parameters according to some predefined problem-specific rules. The second is the self-adaptive method that lets the parameter values evolve by themselves by encoding them within the genotype of candidate solutions. The last one is the adaptive or feedbackbased method, which adjusts the parameter values based on the feedbacks received from the previous search steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Adaptive Operator Selection</head><p>AOS is a recent paradigm to adaptively select operators for generating a new solution during the search. The selection is conducted based on the recent performances of operators. AOS involves two major tasks: the credit assignment and the operator selection. The former defines how to reward an operator based on its recent performance in the search process, while the latter uses these rewards to decide which operator should be applied next.</p><p>1) Credit Assignment: The most commonly used metric in credit assignment for measuring the quality of an operator is based on the fitness improvement obtained by a new solution, compared with a given baseline solution. In <ref type="bibr" target="#b28">[29]</ref>, for instance, the best solution of the current population is considered baseline, while in <ref type="bibr" target="#b29">[30]</ref> the offspring's parent is used for comparison. Once the quality is measured, there are different ways to use it for rewarding the operator. The most popular approach is to set the reward amount as the average of the recent fitness improvements <ref type="bibr" target="#b30">[31]</ref>. Assuming that rare, but large, improvements might be more important than small ones, <ref type="bibr" target="#b31">[32]</ref> suggests that each operator should be rewarded based on the maximal fitness improvement that it recently achieved. To avoid getting trapped at locally optimal solutions, <ref type="bibr" target="#b32">[33]</ref> takes account of both diversity and fitness improvement for rewarding operators. Aiming at robustness, <ref type="bibr" target="#b15">[16]</ref> has proposed two rank-based credit assignment schemes: the AUC and the SR methods.</p><p>2) Operator Selection: Guided by the reward values, operator selection methods select operators for generating new solutions. The two most promising selection mechanisms are: 1) the probability-based methods, such as the probability matching (PM) <ref type="bibr" target="#b33">[34]</ref> and the adaptive pursuit (AP) <ref type="bibr" target="#b34">[35]</ref>; and 2) the bandit-based methods. As these methods will be used as baselines for comparison in Section V, we will give a detailed review in the following. a) Probability matching and adaptive pursuit: These methods often use a roulette wheel-like process for selecting an operator. Let the set (or pool) of operators be S = {s 1 , . . . , s K }, the selection probability of each operator at time point t be P t = (p 1,t , . . . , p K,t )(∀t : p min ≤ p i,t ≤ 1; K i=1 p i,t = 1), and the estimated quality of operator i be qi,t . At each time point t, these methods:</p><p>1) randomly select an operator, say, operator i, based on the probability vector P t , and use a credit assignment scheme to give it a reward r; 2) update the quality of operator i</p><formula xml:id="formula_1">qi,t+1 = (1 -α) × qi,t + α × r (2)</formula><p>where α ∈ [0, 1] is a user-defined parameter, the adaptation rate. There are different approaches for updating the selection probability. The PM approach does it as</p><formula xml:id="formula_2">p i,t+1 = p min + (1 -K × p min ) × qi,t+1 K j=1 qj,t+1<label>(3)</label></formula><p>where p min ∈ [0, 1] is the minimal selection probability value for each operator. This ensures that all the operators have a nonzero selection probability, which can avoid losing a currently bad operator that might become useful in the future.</p><p>An inefficient operator will have its selection probability converging toward p min , while an operator that works very well will be selected with probability p max = (1 -(K -1) × p min ) after getting very good rewards for a long time period. A criticism of the PM approach is that it gives high probabilities to operators with average performances, which may slow down the underlying optimization algorithms. The AP method, originally proposed for learning automata, adopts a winnertake-all strategy to increase the chance of selecting the best operator i * t . This works as</p><formula xml:id="formula_3">⎧ ⎨ ⎩ i * t = argmax i∈{1•••K} {q i,t } p i,t+1 = p i,t + β × (p max -p i,t ), if i = i * t p i,t+1 = p i,t + β × (p min -p i,t ), otherwise<label>(4)</label></formula><p>where the learning rate β ∈ [0, 1] controls the greediness of the winner-take-all strategy. Some other AOS methods based on probabilities can also be found in the literature, such as the ones used in the SaDE <ref type="bibr" target="#b16">[17]</ref>, JADE <ref type="bibr" target="#b17">[18]</ref>, and jDE <ref type="bibr" target="#b18">[19]</ref> algorithms. b) Bandit-based operator selection: The operator selection problem can be regarded as an instance of the EvE dilemma: one should exploit the operators set by selecting good operators as often as possible, while also doing some exploration to give chances to poor operators since they may become better in the future search. The EvE dilemma has intensively been studied in the context of the MAB problem, which considers a set of K independent arms (equivalent to variation operators or strategies in the AOS literature), and each arm has an unknown probability of being rewarded. An optimal arm selection strategy is the one that maximizes the cumulative reward along time. Many MAB algorithms have been proposed to tackle this problem. Most of the recent ones are based on the UCB algorithm <ref type="bibr" target="#b11">[12]</ref>, which provides asymptotic optimality guarantees. In an UCB-based MAB algorithm, the ith arm has an empirical quality estimate qi and a confidence interval that depends on the number of times n i it has been tried before. At each time point t, the arm maximizing the following function is selected:</p><formula xml:id="formula_4">qi,t + C × 2 × ln K j=1 n j,t n i,t<label>(5)</label></formula><p>where C is a scaling factor to control the tradeoff between exploitation (the first term that favors the arms with best empirical rewards) and exploration (the square root term that favors the infrequently tried arms). Some variants of the UCB algorithm have recently been proposed to address the dynamic aspect of the AOS problem in a more efficient way. A very recent one, the sum-of-ranks MAB (SRMAB) algorithm <ref type="bibr" target="#b15">[16]</ref>, will be used as a baseline for comparison with the new bandit-based AOS method we are proposing in this paper. More specifically, at a given time point t, SRMAB selects an operator to be applied next as follows. First, the latest W fitness improvements achieved by the operators are ranked. Then, a decaying mechanism is applied over these rank values so that the top-ranked rewards, i.e., the highest fitness improvements exert a higher influence on the calculation of the credits assigned to the operators. Finally, it selects the operator that maximizes <ref type="bibr" target="#b4">(5)</ref>, in which the empirical quality estimate qi,t of each operator is the sum of their corresponding decayed rank values, and n i,t is the number of times operator i has been applied in the recent W applications. The SRMAB algorithm is well known as being both very efficient and robust with respect to different fitness landscapes. The robustness comes mainly from the use of ranks on its credit assignment module. A more detailed survey of SRMAB and other bandit-based algorithms for the AOS problem can be found in <ref type="bibr" target="#b35">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. Fitness-Rate-Rank-Based Multiarmed Bandit</head><p>Adaptive Operator Selection In this section, we propose a new bandit-based method for the AOS problem. The proposed method pays particular attention to the AOS dynamic nature. This consists of two modules. One is for credit assignment and the other is for operator selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Credit Assignment</head><p>In credit assignment, one needs, as discussed in Section II-B1, to address the following two issues:</p><p>1) how to measure the impact in the search process caused by the application of an operator; 2) how to assign an appropriate credit value to an operator based on this measured impact. As for the first issue, the most commonly used approach is to directly use the raw values of the fitness improvements caused by the recent uses of the operator under assessment. However, the range of raw fitness improvements varies from problem to problem and even at the different stages of an optimization process. It is common that the raw fitness improvement value is much larger at early stages than at later ones. Therefore, as discussed in <ref type="bibr" target="#b35">[36]</ref>, the direct use of raw fitness improvement could deteriorate the algorithm's robustness. To alleviate this problem, our proposed method uses the fitness improvement rates (FIR). More specifically, the FIR achieved by an operator i at time point t is defined as</p><formula xml:id="formula_5">FIR i,t = pf i,t -cf i,t pf i,t<label>(6)</label></formula><p>where pf i,t is the fitness value of the parent, and cf i,t is the fitness value of the offspring.</p><p>A sliding window with fixed size W is used to store the FIR values of the recently used operators. It is organized as a first-in, first-out (FIFO) queue, i.e., the FIR value of the most recently used operator is added at the tail of the sliding window, while the oldest record (the item at the head of the queue) is removed to keep the window size constant. Fig. <ref type="figure" target="#fig_0">1</ref> illustrates the structure of a sliding window. Each slot in the sliding window stores two components:</p><p>1) the index of the operator op used; 2) its FIR value. The major reason for using the sliding window is that, in dynamic AOS environments, the performance of an operator in a very early stage may be irrelevant to its current performance. The sliding window ensures that the stored FIR information is for the current situation of the search.  To address the second issue set at the outset of this subsection, we first compute Reward i , the sum of all FIR values for each operator i in the current sliding window. Then, we rank all these Reward i values in a descending order. Let Rank i be the rank value of operator i, inspired by other recently proposed rank-based credit assignment schemes <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b31">[32]</ref>, and to give more chances to the best operators, we introduce a decaying factor D ∈ [0, 1] to transform Reward i to</p><formula xml:id="formula_6">Decay i = D Rank i × Reward i . (<label>7</label></formula><formula xml:id="formula_7">)</formula><p>Then, we assign the following credit value to operator i:</p><formula xml:id="formula_8">FRR i,t = Decay i K j=1 Decay j . (<label>8</label></formula><formula xml:id="formula_9">)</formula><p>Clearly, the smaller the value of D, the larger the influence for the best operator. Fig. <ref type="figure" target="#fig_1">2</ref> illustrates FRR versus Rank with three different values of D in a case of 15 distinct rank values. The pseudocode of the proposed credit assignment scheme is given in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Operator Selection</head><p>Based on the received credit values, the operator selection scheme selects operators for generating new solutions. This paper uses a bandit-based operator selection scheme. Our scheme is similar to the original UCB algorithm <ref type="bibr" target="#b11">[12]</ref>. The major difference is that we use FRR values as the quality index instead of the average of all the rewards received so far for an operator. In addition, n i indicates the number of times operator i has been selected in the recent W applications.</p><p>The pseudocode of our proposed bandit-based operator selection scheme is given in Algorithm 2. The combination of this operator selection and the credit assignment schemes constitutes our proposed AOS method, FRRMAB. It is worth noting that no operator has yet been applied at the beginning of the search; thus, we give each operator an equal chance to be selected in this case. FRRMAB is not employed until each operator has been applied at least once.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. Integration of FRRMAB With MOEA/D</head><p>As mentioned in Section I, most existing AOS methods were designed and applied on single-objective optimization. One of the major reasons could be that most popular MOEAs, such as NSGA-II <ref type="bibr" target="#b2">[3]</ref>, SPEA2 <ref type="bibr" target="#b3">[4]</ref>, and PAES <ref type="bibr" target="#b36">[37]</ref>, compare solutions' qualities mainly based on their dominance relations. In these algorithmic frameworks, it is very difficult to quantify the quality difference between two solutions and thus the improvement caused by the application of an operator. Therefore, it is not trivial to use AOS methods, which require a metric for measuring operator performances to enhance these dominancebased MOEAs.</p><p>MOEA/D <ref type="bibr" target="#b5">[6]</ref> decomposes an MOP into a number of singleobjective subproblems. Then, a population-based method is used to solve these subproblems simultaneously. Techniques for single-objective optimization can be naturally, at least in principle, applied to the MOEA/D framework. Several MOEA/D variants have been proposed for dealing with various MOPs, and MOEA/D has also been used as a basic element in some hybrid algorithms (e.g. <ref type="bibr" target="#b37">[38]</ref>- <ref type="bibr" target="#b41">[42]</ref>). Any improvement on MOEA/D could be of practical interest. For these reasons, this paper investigates how to use FRRMAB to improve MOEA/D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. MOEA/D</head><p>It is well known that a Pareto optimal solution to an MOP, under mild conditions, is an optimal solution of a single-objective optimization problem whose objective is a weighted (linear or nonlinear) aggregation of all the individual objectives. To obtain a set of different Pareto optimal solutions to approximate the PF, MOEA/D solves a set of such singleobjective optimization subproblems with different weight vectors simultaneously. MOEA/D defines neighborhood relations among these subproblems based on the distances between their weight vectors. Each subproblem is optimized in MOEA/D by using information mainly from its neighboring subproblems.</p><p>There are several different variants of MOEA/D. This paper uses MOEA/D with dynamical resource allocation (MOEA/D-DRA <ref type="bibr" target="#b26">[27]</ref>), which won the CEC 2009 MOEA contest. In principle, MOEA/D can use any decomposition approach for defining their subproblems; we employ the Tchebycheff approach in this paper. Let = {λ 1 , . . . , λ N } be a set of N evenly spread weight vectors. Each</p><formula xml:id="formula_10">λ j = (λ j 1 , . . . , λ j m ) T satisfies m i=1 λ j i = 1 and λ j i ≥ 0 for all i ∈ {1, • • • , m}. Let z * = (z * 1 , . . . , z * m )</formula><p>T be a utopian ideal point. Then, the problem of approximating the PF of (1) can be decomposed into N scalar optimization subproblems, and the objective function of the jth subproblem is to minimize the following function:</p><formula xml:id="formula_11">g te (x|λ j , z * ) = max 1≤i≤m {λ j i |f i (x) -z * i |}.<label>(9)</label></formula><p>It is worth noting that z * is usually unknown before the search; the algorithm uses the lowest f i -value found during the search to substitute z * i . During the search, MOEA/D maintains: 1) a population of N solutions x 1 , . . . , x N ∈ , where x i is the current solution to the ith subproblem; 2) FV 1 , . . . , FV N , where FV i is the F -value of x i , i.e., FV i = F (x i ) for each i ∈ {1, . . . , N}; 3) z * = (z * 1 , . . . , z * m ) T , where z * i is the best (i.e., smallest) value found so far for objective f i ; 4) π i : utility of subproblem i, which measures how much improvement has been caused by x i in reducing the objective of this subproblem; this is defined as</p><formula xml:id="formula_12">π i = 1, if i &gt; 0.001 0.95 + 0.05 × i 0.001 × π i , otherwise<label>(10</label></formula><p>) where i is the relative decrease of the objective function value of subproblem i. For each weight vector, its T -neighborhoods are the set of T closest weight vectors to it. Correspondingly, each solution and each subproblem have their own T -neighborhoods.</p><p>At each generation, a set of solutions are selected from the current population based on their utilities. For each selected solution x i , MOEA/D does the following procedures.</p><p>1) Set the mating and update range P to be the Tneighborhoods of x i with a large probability δ, and the whole population otherwise. 2) Randomly select several current solutions from P.</p><p>3) Apply genetic operators on the above-selected solutions to generate a new solution y, and evaluate F (y).</p><p>4) Replace at most n r solutions in P by y if it is better than them in terms of their respective subproblems' objective functions. Further details of MOEA/D-DRA can be found in <ref type="bibr" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Using FRRMAB to Enhance MOEA/D</head><p>To use FRRMAB to enhance MOEA/D, the operators pool and reward calculation are set as follows.</p><p>1) Operators Pool: Many different DE mutation operators have been proposed. Four of them, which present distinct search characteristics, are chosen for the AOS in our experiments:</p><p>1) DE/rand/1</p><formula xml:id="formula_13">v i = x i + F × (x r 1 -x r 2 ); 2) DE/rand/2 v i = x i + F × (x r 1 -x r 2 ) + F × (x r 3 -x r 4 ); 3) DE/current-to-rand/2 v i = x i + K × (x i -x r 1 ) + F × (x r 2 -x r 3 ) + F × (x r 4 -x r 5 ); 4) DE/current-to-rand/1 v i = x i + K × (x i -x r 1 ) + F × (x r 2 -x r 3</formula><p>) where x i is called the target vector and v i is the mutant vector. The variables x r 1 , x r 2 , x r 3 , x r 4 , and x r 5 are different solutions randomly selected from P, which are also different from x i . The scaling factor F &gt; 0 controls the impact of the vector differences on the mutant vector. K ∈ [0, 1] plays a similar role to F . For the last two mutation operators, the offspring is the direct output of mutation, where the crossover operator will not be used. For the first two mutation operators, a crossover operator is applied upon x i and v i for generating the offspring u i . The binomial crossover <ref type="bibr" target="#b42">[43]</ref> is used in our experiments. It works as</p><formula xml:id="formula_14">u i j = v i j , if rand ≤ CR or j = j rand x i j , otherwise<label>(11)</label></formula><p>where j ∈ {1, . . . , n} and rand is a uniformly random number from [0, 1]. The crossover rate CR ∈ [0, 1] is a user-defined control parameter. j rand is an integer randomly chosen from the set S = {1, . . . , n}. After the application of these DE operators, a generated offspring might undergo, with a small probability, the polynomial mutation operator <ref type="bibr" target="#b43">[44]</ref>.</p><p>2) Reward Calculation: In a recent work on AOS for selecting DE mutation operators <ref type="bibr" target="#b31">[32]</ref>, a DE mutation operator is rewarded based on the fitness improvement of the offspring compared with its corresponding target vector. In MOEA/D, however, the generated offspring is not directly compared with its target vector. In fact, an offspring is compared with several solutions randomly selected from the mating pool P, and one offspring can replace up to n r solutions in P. Different solutions correspond to different subproblems, and thus, different comparisons are based on different aggregations of objective functions. In this paper, if an offspring successfully replaces x i , the DE mutation operator that generates it will receive the following reward:</p><formula xml:id="formula_15">η = g(x i |λ i , z * ) -g(y|λ i , z * ) g(x i |λ i , z * ) (<label>12</label></formula><formula xml:id="formula_16">)</formula><p>where λ i is the weight vector for subproblem i.</p><p>An operator op may receive several rewards due to its generated offspring y. We sum up all these reward values as its final reward FIR op .</p><p>The pseudocode of the MOEA/D with FRRMAB, denoted as MOEA/D-FRRMAB, is given in Algorithm 3. It is worth pointing out that FRRMAB can be used within other MOEA/D variants in the same way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. Experimental Studies</head><p>Our experimental studies can be divided into six parts. 1) Section V-B investigates how good the performance of MOEA/D-FRRMAB is compared with three other recent MOEA/D variants, namely, MOEA/D-DE <ref type="bibr" target="#b44">[45]</ref>, MOEA/D-DRA <ref type="bibr" target="#b26">[27]</ref>, and ENS-MOEA/D <ref type="bibr" target="#b45">[46]</ref>. The latter ensembles different neighborhood sizes by using a probability-based method. 2) Section V-C investigates what benefits can be obtained by the efficient use of a pool of operators in MOEA/D-FRRMAB. To this end, MOEA/D-FRRMAB is compared with four MOEA/D variants, each of which uses only one DE mutation operator from the operators pool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Section V-D analyzes what advantages FRRMAB has</head><p>over the other operator selection mechanisms. To this end, it compares MOEA/D-FRRMAB with MOEA/D variants using other AOS methods. 4) To gain a deeper understanding about the proposed FRRMAB, the dynamics of its operator selection process are experimentally studied in Section V-E. 5) The proposed FRRMAB has several control parameters.</p><p>Section V-F conducts a sensitivity analysis on some important ones. 6) To study the performance of our proposed algorithm on many-objective optimization problems, Section V-G tests MOEA/D-FRRMAB on three five-objective test instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Settings</head><p>1) Test instances: Ten unconstrained MOP test instances (UF 1 to UF 10) with various characteristics proposed in <ref type="bibr" target="#b46">[47]</ref> and three five-objective test instances (WFG 1, WFG 8, and WFG 9 from <ref type="bibr" target="#b47">[48]</ref>) are used in our experimental studies. The UF instances have nonlinear PSs in the decision space, and their corresponding PFs are given in Fig. <ref type="figure" target="#fig_3">3</ref>. The number of decision variables of the UF instances is set to 30; for the WFG instances it is set to 28, eight of which are position related, while the other 20 are distance related. 2) Performance metrics: As discussed in <ref type="bibr" target="#b48">[49]</ref> and <ref type="bibr" target="#b49">[50]</ref>,</p><p>no unary performance metric is able to give a comprehensive measure on the performance of an MOEA. In our experimental studies, we consider the following two widely used performance metrics. a) Inverted generational distance (IGD) metric <ref type="bibr" target="#b50">[51]</ref>: Let P * be a set of uniformly distributed Pareto optimal solutions in the objective space. Let S be the obtained approximation to the PF in the   </p><formula xml:id="formula_17">for i ← 1 to N do B(i) = {i 1 , • • • , i T } where λ i 1 , • • • , λ i T are</formula><p>where dist(x, S) is the minimal Euclidean distance between x and the points in S, and |P * | is the cardinality of P * . In general, the IGD metric is able to give a reliable measure to the quality of S if |P * | is large enough. In our experiments, the number of points in P * is 1000 for the biobjective test instances, 10 000 for the three-objective ones, and 5000 for the five-objective ones. b) Hypervolume indicator (I H ) <ref type="bibr" target="#b51">[52]</ref>: Let y * = (y * 1 , . . . , y * m ) be a antioptimal reference point in the objective space that is dominated by all Pareto optimal objective vectors. Let S be the obtained approximation to the PF in the objective space. Then, the I H value of S (with regard to y * ) is the volume of the region dominated by S and bounded by y *</p><formula xml:id="formula_19">I H (P) = volume( y∈S [y 1 (x), y * 1 ]×. . . [y m , y * m ]). (<label>14</label></formula><formula xml:id="formula_20">)</formula><p>In our experiments, y * = (2.0, 2.0) for biobjective test instances, y * = (2.0, 2.0, 2.0) for threeobjective ones, and y * = (3.0, 5.0, 7.0, 9.0, 11.0) for five-objective cases. Generally speaking, the lower the IGD value, the better S approximates the true PF. For I H , the higher the better. Moreover, in order to have statistically sound conclusions, Wilcoxon's rank sum test at a 0.05 significance level is adopted to compare the significance of the differences between the solution sets obtained by two competing algorithms.</p><p>3) Parameter settings: The parameters of MOEA/D-DE, MOEA/D-DRA, and ENS-MOEA/D are set according to <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b44">[45]</ref>, and <ref type="bibr" target="#b45">[46]</ref>, respectively. All algorithms are implemented in Java,<ref type="foot" target="#foot_0">1</ref> except for ENS-MOEA/D, which is written in MATLAB. <ref type="foot" target="#foot_1">2</ref> The parameter settings of MOEA/D-FRRMAB are as follows. a) Control parameters in DE and polynomial mutation: Following <ref type="bibr" target="#b26">[27]</ref> and <ref type="bibr" target="#b44">[45]</ref>, we set CR = 1.0 and F = 0.5 for the DE operators, and η = 20, p m = 1/n for the polynomial mutation operator. K = 0.5, as in <ref type="bibr" target="#b16">[17]</ref>. b) Population size: N = 600 for biobjective test instances, 1000 for the three-objective ones, and 1200 for the five-objective cases. c) Number of independent runs and maximum number of function evaluations: 30 independent runs are conducted for each algorithm on each test instance. The maximum number of function evaluations is fixed to be 300 000. d) The neighborhood size: T = 20. e) Maximum number of solutions replaced by each new solution: n r = 2. f) Probability with regard to selecting P: δ = 0.9 as in <ref type="bibr" target="#b26">[27]</ref>. g) Control parameters in FRRMAB: except for Section V-F, in which the robustness of these control parameters is analyzed, they are constantly set as follows. i) Scaling factor: C = 5.0. </p><formula xml:id="formula_21">+ 0 0 1 ≈ 1 4<label>3</label></formula><p>"-," "+," and "≈" denote the number of times the performance of the corresponding algorithm is worse than, better than, and similar to that of the proposed MOEA/D-FRRMAB, respectively, according to the Wilcoxon rank sum test at a 0.05 significance level.</p><p>ii) Size of sliding window: W = 0.5 × N.</p><p>iii) Decaying factor: D = 1.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. MOEA/D-FRRMAB Versus State-of-the-Art MOEA/D Variants</head><p>We have first compared MOEA/D-FRRMAB with three MOEA/D variants, namely, MOEA/D-DE, MOEA/D-DRA, and ENS-MOEA/D on UF 1 to UF 10. Figs. <ref type="figure">4</ref> and<ref type="figure">5</ref> present the box plots of the IGD and I H metric values obtained from 30 independent runs. Table <ref type="table">I</ref> provides the statistics summarizing these performance comparisons. In these figures and tables, MOEA/D-DE, MOEA/D-DRA, ENS-MOEA/D, and MOEA/D-FRRMAB are denoted as MOEA/D, DRA, ENS, and FRRMAB, respectively. These results clearly show that MOEA/D-FRRMAB is the best. Actually, it has obtained better results in 53 out of its 60 performance comparisons with other algorithms (one such comparison compares MOEA/D-FRRMAB with another algorithm on one instance based on IGD or I H ), being significantly better in 45 out of all these comparisons. It is worth noting that our proposed algorithm significantly outperforms the recently proposed MOEA/D variant, ENS-MOEA/D, in 13 out of 20 comparisons. Thus, we can conclude that the use of FRRMAB has successfully improved the performance of the baseline MOEA/D.</p><p>On UF 3 and UF 10, MOEA/D-FRRMAB has been beaten by ENS-MOEA/D and MOEA/D-DRA. Both UF 3 and UF 10 have many local PFs. This may imply that FRRMAB could not efficiently improve the global search ability. One may consider the search diversity in credit assignment as in <ref type="bibr" target="#b32">[33]</ref>, which will be a research issue for our further work.</p><p>The good performance presented by MOEA/D-FRRMAB does not come for free. Here, we also intend to compare the CPU time of the proposed algorithm to the baseline MOEA/D-DRA, MOEA/D-DE, and ENS-MOEA/D, respectively. The average CPU time out of 30 independent runs used by MOEA/D-FRRMAB and its competitors, on all the benchmark test problems, are given in Table <ref type="table" target="#tab_2">II</ref>. <ref type="foot" target="#foot_2">3</ref> The lowest CPU time is highlighted in bold type with a gray background.</p><p>As can be seen, compared to MOEA/D-DRA and MOEA/D-DE, the FRRMAB module needs extra CPU time for updating the credit value of each operator and for making </p><formula xml:id="formula_22">I H + 0 0 0 0 ≈ 3 3 4 0</formula><p>"-," "+," and "≈" denote the number of times the performance of the corresponding algorithm is worse than, better than, and similar to that of the proposed MOEA/D-FRRMAB, respectively, according to the Wilcoxon rank sum test at a 0.05 significance level.</p><p>a decision on which operator to apply at every generation. More specifically, it spends about 2 more seconds on twoobjective test instances, namely, UF 1 to UF 7, and an extra 3 s on three-objective test instances. This corresponds to around 40% of extra time, on average, for all the instances. However, it is worth noting that the CPU time of ENS-MOEA/D is much longer than the other MOEA/D variants. This is mainly due to the fact that it was implemented in MATLAB and its code has not been fully vectorized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Operators Pool Versus a Single DE Mutation Operator</head><p>Now, we investigate what benefits can be obtained by efficiently using a pool of operators in MOEA/D-FRRMAB. For this purpose, MOEA/D-FRRMAB is compared with four MOEA/D variants, each of them using only one DE mutation operator from the operators pool. A variant using a DE mutation operator i is called Op. i. To have a fair comparison, all the parameter settings in Op. i are kept the same as those in MOEA/D-FRRMAB, except that MOEA/D-FRRMAB uses an operators pool while Op. i only uses DE mutation operator i.</p><p>From the experimental results in Figs. <ref type="figure">6,</ref><ref type="figure">7</ref>, and Table <ref type="table" target="#tab_2">III</ref>, it is evident that MOEA/D-FRRMAB is the best among all the five algorithms. Actually, MOEA/D-FRRMAB has produced the best results on almost all the test instances, except for UF 3 and UF 6, in which Op. 2 and Op. 3 perform better, respectively. This indicates that using FRRMAB to manage an operators pool is beneficial, compared with using a single operator. It is noticeable that there is no clear winner among the four MOEA/D variants using a single operator. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. FRRMAB Versus Other AOS Methods</head><p>As mentioned in Section II, some other AOS methods have been proposed before. Among them, PM <ref type="bibr" target="#b33">[34]</ref>, AP <ref type="bibr" target="#b34">[35]</ref>, and SRMAB <ref type="bibr" target="#b15">[16]</ref> are three representative approaches. We have compared FRRMAB with these three AOS methods in the context of MOEA/D. In our implementations, we have replaced FRRMAB in MOEA/D-FRRMAB by each of these three methods, producing three algorithms for comparison. More specifically, PM and AP are coupled with the same credit assignment scheme proposed in Section III, while SRMAB uses its own credit assignment scheme <ref type="bibr" target="#b15">[16]</ref>. The control parameters in these AOS methods are set as recommended by their corresponding original papers <ref type="bibr" target="#b34">[35]</ref>. In particular, for PM and AP, the minimal operator selection probability p min = 0.1 and adaptation rate α = 0.8. For AP, the learning rate β is set to 0.8. The control parameters in SRMAB are set to the same as in our proposed FRRMAB.</p><p>From the experimental results in Figs. <ref type="figure">8,</ref><ref type="figure">9</ref>, and Table <ref type="table" target="#tab_3">IV</ref>, it is clear that the proposed FRRMAB is the best in this comparison. It won on 73 out of 80 performance comparisons and performed significantly better on 63 comparisons. The second best competitor is the other bandit-based method, SRMAB, which won on UF 4, UF 6, and UF 10. The outperformance </p><formula xml:id="formula_23">IGD + 0 0 1 0 ≈ 1 3 4 0 - 9 9 4 1 0 I H + 0 0 1 0 ≈ 1 1 5 0</formula><p>"-," "+," and "≈" denote the number of times the performance of the corresponding algorithm is worse than, better than, and similar to that of the proposed MOEA/D-FRRMAB, respectively, according to the Wilcoxon rank sum test at a 0.05 significance level.</p><p>of SRMAB on these three test instances should be attributed to its comparison-based credit assignment scheme, which might be more suitable for these fitness landscapes. These results confirm that bandit-based methods are able to outperform others in the AOS context. The superiority of bandit should come from its theoretically sound way of balancing exploration and exploitation. Another issue is regarding whether an intelligent AOS method is better than a random AOS one. To address this issue, we have compared MOEA/D-FRRMAB with its counterpart using a uniformly random operator selection strategy (denoted as Uniform). From Figs. <ref type="figure">8,</ref><ref type="figure">9</ref>, and Table <ref type="table" target="#tab_3">IV</ref>, it is evident that the uniformly random selection strategy is the worst among all the methods. This finding confirms that it is worth exploring information about the recent performance of operators, and intelligent AOS methods can significantly improve the performance of the underlying algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Dynamics of Operator Selection</head><p>We have shown that FRRMAB is highly beneficial to MOEA/D performance. To have a deeper understanding of the behavior of FRRMAB, we now investigate how the usage number of each operator changes during the whole search process. For this purpose, we divide the whole search process (i.e., 300 000 function evaluations) into 50 consecutive phases, each of which consists of 6000 function evaluations. We have calculated the usage number of each operator during each phase and plotted the evaluations of these usage numbers in Fig. <ref type="figure" target="#fig_8">10</ref>.</p><p>From Fig. <ref type="figure" target="#fig_8">10</ref>, one can observe that no single operator can dominate over the whole search process on all the test instances. However, the search process for each test instance can be divided into a few stages, each of which is completely dominated by a single operator. For example, on UF 1, the search process can be divided into three stages. Search phase 1 to phase 19 constitute stage 1, on which operator 2 dominates. Search phase 20 to phase 33 constitute stage 2, on which operator 1 dominates, while search phase 34 to phase 50 constitute stage 3, on which operator 4 dominates. These observations show that FRRMAB can use different operators on different search stages and that it can efficiently switch from one operator to another.</p><p>The four DE mutation operators in the operators pool have different characteristics. Operators 2 and 3 have two randomto-random terms, while the other two have only one; therefore, the former two are able to do more exploration than the latter ones. As previously discussed, intuitively, it is desirable to explore the search space in the initial stages of the optimization process, and perform more exploitation at later stages. This is empirically confirmed in Fig. <ref type="figure" target="#fig_8">10</ref>: for most of the instances, operators 2 and/or 3 are preferred at early stages, while operators 1 and/or 4 are more frequently used at later ones. Figs. <ref type="figure">6,</ref><ref type="figure">7</ref>, and Table III suggest that, overall, operator 4 performs worst among the four operators in UF test instances. One can also notice that this operator is rarely selected in FRRMAB. These observations imply that FRRMAB is able to select operators in a reasonable manner.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Parameter Sensitivity Analysis in FRRMAB</head><p>There are three control parameters in FRRMAB.</p><p>1) The scaling factor C. As discussed in Section II-B2b, C balances exploration and exploitation in the operator selection process. A low value of C will favor the operators with the best previous performance, while a high value of C will prefer operators that were infrequently used before.</p><p>2) The size of the sliding window W. This parameter defines how many operator applications are used to calculate the credit values awarded to the operators.</p><p>3) The decaying factor D. D determines the priority level given to the best rewarded operator; a lower value of D will lead to a higher credit value for the top-ranked operators.</p><p>To study how MOEA/D-FRRMAB is sensitive to these three parameters, we have tried to cover a large range of values for each parameter. Four values were considered for scaling factor C: 0.5, 1.0, 2.0, and 5.0, three values for sliding window size W: 0.5 × N, N, and 2 × N, and six values for the decaying factor D: 0.1, 0.3, 0.5, 0.7, 0.9, and 1.0. We have taken UF 3 and UF 7 as test instances and tested all the 72 different parameter configurations. Thirty independent runs have been conducted for each configuration on each test instance. Figs. <ref type="figure" target="#fig_9">11</ref> and<ref type="figure" target="#fig_10">12</ref> show the median IGD and I H metric values found with these 72 different configurations, respectively. From these two figures, one can observe that different configurations can lead to different performances on both test instances. In order to further analyze this issue, for each performance metric and each test instance, we take the best parameter configuration in terms of the median metric value as a baseline, and compare it with each of the other 71 configurations using the Wilcoxon rank sum test at the 0.05 significance level. On UF 3, in terms of the IGD metric, the best configuration (C = 0.5, D = 0.7, W = 0.5 × N) is not significantly different from 30 out of 71 configurations. In terms of I H , the best configuration is not significantly different from 26 out of 71 configurations. On UF 7, in terms of the IGD metric, the best configuration (C = 1.0, D = 0.3, W = 0.5 × N) is not significantly different from 28 out of 71 configurations. In terms of the I H metric, the best configuration (C = 0.5, D = 0.5, W = 0.5 × N) significantly outperforms only ten configurations. Since more than 50% configurations are worse than the best configuration in these cases, one should be careful when setting these parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Performance on Many-Objective Problems</head><p>Most existing MOEAs are designed for and tested on problems with two or three objectives <ref type="bibr" target="#b52">[53]</ref>. Their performances often deteriorate as the number of objectives increases. However, many real-world applications can involve more than three objectives. Many-objective optimization has   "-," "+," and "≈" denote the number of times the performance of the corresponding algorithm is worse than, better than, and similar to that of the proposed MOEA/D-FRRMAB, respectively, according to the Wilcoxon rank sum test at a 0.05 significance level.</p><p>attracted growing attention from the evolutionary computation community. Although the major purpose of this paper is not to address many-objective problems, we still want to investigate whether FRRMAB can improve the abilities of MOEA/D for dealing with many-objective problems. To this end, we have taken three five-objective instances from <ref type="bibr" target="#b47">[48]</ref> (WFG 1, WFG 8, and WFG 9) to test algorithms' abilities for dealing with many objectives. These instances were used in the CEC 2007 MOEA contest <ref type="bibr" target="#b53">[54]</ref>. We have compared our proposed MOEA/D-FRRMAB with MOEA/D-DE, MOEA/D-DRA, and ENS-MOEA/D on these three instances. The parameter settings are the same as in Section V-B, except for N = 1200, and both of IGD and I H are employed as the performance metrics here. Wilcoxon's rank sum test at a 0.05 significance level is used to compare the statistical significance between every two algorithms. From the experimental results in Figs. 13, 14, and Table <ref type="table" target="#tab_4">V</ref>, we can conclude that MOEA/D-FRRMAB is the most competitive algorithm among all these MOEA/D variants. To be specific, WFG 1 can measure an MOEA for coping with bias from the experimental results shown in Figs. <ref type="figure" target="#fig_11">13</ref> and<ref type="figure" target="#fig_2">14</ref>; we can clearly find the superior performance of our proposed MOEA/D-FRRMAB. Similarly to WFG 1, WFG 8 and WFG 9 are also featured with significant bias. In addition, the distancerelated parameters are dependent on position-related parameters. The outperformance of MOEA/D-FRRMAB indicates that the AOS method can be of benefit for finding a promising set of distance parameters. As for WFG 9, although the dependency between position-related and distance-related parameters is not as difficult like that of WFG 8, it has multimodal and nonseparable reduction properties. The performance of MOEA/D-DE is slightly better than that of MOEA/D-DRA, but both perform worse than MOEA/D-FRRMAB. Based on these empirical results, we can conclude that AOS methods are worth considering in MOEAs for many-objective problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. Conclusion</head><p>In this paper, we proposed a new bandit-based AOS method, FRRMAB, to automatically select appropriate operators in an online manner. In FRRMAB, the fitness improvement rate caused by an operator is used to measure its quality. A method with a decaying mechanism was used to calculate the final reward value for each operator based on all the recent fitness improvement rates that were stored in a sliding window. Then, guided by these reward values, a simple bandit-based scheme selected the operator to be used next.</p><p>Since it was not easy to quantify the improvement caused by an operator in most Pareto dominance-based MOEAs, the use of AOS in these algorithms posed a big challenge. The decomposition nature of MOEA/D made it very suitable for using AOS. This paper studied several issues in incorporating our proposed FRRMAB into MOEA/D. We proposed a simple way for measuring the improvement caused by an operator for each subproblem within the MOEA/D framework. We took four commonly used DE mutation operators as candidate operators and conducted extensive experimental studies on some test instances. We showed that FRRMAB was robust, and its operator selection was reasonable in MOEA/D. The comparison experiments also indicated that FRRMAB can significantly improve the performance of MOEA/D.</p><p>Although FRRMAB was used to select operators for static MOPs in this paper, this approach could be generalized in a straightforward way for dealing with dynamic MOPs. It could also be useful to many other online selection issues in evolutionary computation, such as allocating computational efforts to different subproblems in decomposition-based multiobjective optimization, and selecting surrogate models in model-based EAs. Moreover, in addition to the decompositionbased MOEAs, a similar idea can also be applied to the indicator-based MOEAs, in which the fitness improvements caused by an operator can be measured with respect to the improvements evaluated by the underlying indicator. These are possible research issues for the follow-up to this paper.</p><p>The source code of our proposed MOEA/D-FRRMAB, the numerical values of the simulations, and more comprehensive parameter sensitivity studies can be found on K. Li's homepage: a nd Q. Zhang's homepage: .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of the FIFO sliding window structure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Comparison between different decaying mechanisms.</figDesc><graphic coords="4,339.23,119.36,196.32,131.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1 : 4 FIR</head><label>14</label><figDesc>Procedure for the Credit Assignment Initialize each reward Reward i = 0; 1 Initialize n i = 0; 2 for i ← 1 to SlidingWindow.length do 3 op = SlidingWindow.GetIndexOp(i); = SlidingWindow.GetFIR(i);</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. PF of the benchmark problems. (a) UF 1, UF 2, UF 3. (b) UF 4. (c) UF 5. (d) UF 6. (e) UF 7. (f) UF 8, UF 10. (g) UF 9.</figDesc><graphic coords="7,56.01,70.53,504.00,186.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .Fig. 5 .Algorithm 3 :</head><label>453</label><figDesc>Fig. 4. Box plots for the comparison of MOEA/D-DE, MOEA/D-DRA, ENS-MOEA/D, and MOEA/D-FRRMAB on IGD. Wilcoxon's rank sum test at a 0.05 significance level is performed between MOEA/D-FRRMAB and each of MOEA/D-DE, MOEA/D-DRA, and ENS-MOEA/D. "+" and "++" denote that the performance of the corresponding algorithm is significantly worse than or better than that of the proposed MOEA/D-FRRMAB, respectively. The algorithm with the best mean IGD value is underlined.</figDesc><graphic coords="7,56.01,308.71,504.00,153.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>the T closest weight vectors to λ i and set π i = 1; end while Stopping criterion is not satisfied do Let all the indices of the subproblems whose objectives are MOP individual objectives f i form the initial I. By using 10-tournament selection based on π i , select other N/5m indices and add them to I. for each i ∈ I do op = FRRMAB(FRR); if uniform(0, 1) &lt; δ then P := B(i); else P := the entire population; end Randomly select some solutions from P; Generate a candidate ȳ by the application of the chosen DE mutation operator op over the selected solutions; Apply polynomial mutation operator on ȳ with probability p m , to produce the offspring y; Update the current reference point z * ; c = 0; while c &lt; n r P! = ∅ do Randomly pick a solution x j from P; η = g(x j |λ j ,z * )-g(y|λ j ,z * ) g(x j |λ j ,z * ) ; if η &gt; 0 then Replace x j with y; Remove x j from P; FIR op = FIR op + η; end c++; end SlidingWindow.SetIndex(op); SlidingWindow.SetFIR(FIR op ); CreditAssignment(Reward, SlidingWindow); Decay(Reward, FRR); gen++; if mod(gen, 50) == 0 then // mod is the modulo operator update the utility π i of each subproblem; end end end objective space. The IGD value of S is defined as IGD(S, P * ) = x∈P * dist(x, S) |P * |</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig.6. Box plots for the comparison of MOEA/D-FRRMAB and MOEA/D variants with a single DE mutation operator on IGD. (Wilcoxon's rank sum test at a 0.05 significance level is performed between MOEA/D-FRRMAB and each of the static variants. "+" and "++" denote that the performance of the corresponding algorithm is significantly worse than or better than that of the proposed MOEA/D-FRRMAB, respectively. The algorithm with the best mean IGD value is underlined.)</figDesc><graphic coords="10,53.72,252.73,504.00,147.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .Fig. 9 .</head><label>89</label><figDesc>Fig. 8. Box plots for the comparison of MOEA/D-FRRMAB with other AOS variants on IGD. (Wilcoxon's rank sum test at a 0.05 significance level is performed between MOEA/D-FRRMAB and each of the other AOS variants. "+"and "++"denote that the performance of the corresponding algorithm is significantly worse than or better than that of the proposed MOEA/D-FRRMAB, respectively. The algorithm with the best mean IGD value is underlined.)</figDesc><graphic coords="11,56.51,247.43,503.04,157.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Operator adaptation trajectories of MOEA/D-FRRMAB on different benchmark problems. (a) Operator adaptation trajectory on UF 1. (b) Operator adaptation trajectory on UF 2. (c) Operator adaptation trajectory on UF 3. (d) Operator adaptation trajectory on UF 4. (e) Operator adaptation trajectory on UF 5. (f) Operator adaptation trajectory on UF 6. (g) Operator adaptation trajectory on UF 7. (h) Operator adaptation trajectory on UF 8. (i) Operator adaptation trajectory on UF 9. (j) Operator adaptation trajectory on UF 10.</figDesc><graphic coords="12,53.72,108.92,504.00,530.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Median IGD metric values found by MOEA/D-FRRMAB with 72 different combinations of C, D, and W on UF3 (a to c) and UF7 (d to f ). (a) W = 0.5 × NP. (b) W = NP. (c) W = 2 × NP. (d) W = 0.5 × NP. (e) W = NP. (f) W = 2 × NP.</figDesc><graphic coords="13,56.01,53.87,504.00,323.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Median I H values found by MOEA/D-FRRMAB with 72 different combinations of C, D, and W on UF3 (a to c) and UF7 (d to f ). (a) W = 0.5×NP. (b) W = NP. (c) W = 2 × NP. (d) W = 0.5 × NP. (e) W = NP. (f) W = 2 × NP.</figDesc><graphic coords="14,53.72,59.65,504.00,323.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Box plots for the comparison of MOEA/D-DE, MOEA/D-DRA, ENS-MOEA/D, and MOEA/D-FRRMAB on IGD. (Wilcoxon's rank sum test at a 0.05 significance level is performed between MOEA/D-FRRMAB and each of MOEA/D-DE, MOEA/D-DRA, and ENS-MOEA/D. "+" and "++" denote that the performance of the corresponding algorithm is significantly worse than or better than that of the proposed MOEA/D-FRRMAB, respectively. The algorithm with the best mean IGD metric value is underlined.)</figDesc><graphic coords="14,95.72,433.54,420.48,95.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>5</head><label></label><figDesc>Reward op = Reward op + FIR; Rank Reward i in descending order and set Rank i to be Decay op = D Rank op × Reward op ;</figDesc><table><row><cell>6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>7</cell><cell>n op ++;</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>8</cell><cell>end</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">the rank value of operator i;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">for op ← 1 to K do</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>end</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">DecaySum = K op=1 Decay op ;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">for op ← 1 to K do</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">FRR op = Decay op /DecaySum;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>operators pool;</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3</cell><cell>else</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>4</cell><cell>op t = argmax i={1...K}</cell><cell>FRR i,t + C ×</cell><cell>2×ln</cell><cell>n i,t</cell><cell>K j=1 n j,t</cell><cell>;</cell></row><row><cell>5</cell><cell>end</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>end Algorithm 2: The procedure for the bandit-based operator selection if There are operators that have not been selected then 1 op t = one that uniformly randomly selected from the</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II Average</head><label>II</label><figDesc>CPU Time (in Seconds) Needed by MOEA/D-FRRMAB, MOEA/D-DE, MOEA/D-DRA, and ENS-MOEA/D</figDesc><table><row><cell></cell><cell></cell><cell cols="2">FRRMAB MOEA/D</cell><cell>DRA</cell><cell>ENS</cell></row><row><cell></cell><cell>UF 1</cell><cell>5.13</cell><cell>3.66</cell><cell>4.63</cell><cell>1563</cell></row><row><cell></cell><cell>UF 2</cell><cell>5.39</cell><cell>3.81</cell><cell>4.76</cell><cell>1655</cell></row><row><cell></cell><cell>UF 3</cell><cell>6.18</cell><cell>4.35</cell><cell>5.36</cell><cell>1666</cell></row><row><cell></cell><cell>UF 4</cell><cell>5.55</cell><cell>3.91</cell><cell>4.95</cell><cell>1621</cell></row><row><cell></cell><cell>UF 5</cell><cell>5.46</cell><cell>3.82</cell><cell>4.93</cell><cell>1634</cell></row><row><cell></cell><cell>UF 6</cell><cell>5.44</cell><cell>3.90</cell><cell>5.01</cell><cell>1613</cell></row><row><cell></cell><cell>UF 7</cell><cell>5.14</cell><cell>3.53</cell><cell>4.58</cell><cell>1601</cell></row><row><cell></cell><cell>UF 8</cell><cell>7.58</cell><cell>5.09</cell><cell>7.61</cell><cell>1782</cell></row><row><cell></cell><cell>UF 9</cell><cell>7.53</cell><cell>5.22</cell><cell>7.59</cell><cell>1756</cell></row><row><cell></cell><cell>UF 10</cell><cell>8.05</cell><cell>5.60</cell><cell>7.92</cell><cell>1799</cell></row><row><cell></cell><cell></cell><cell></cell><cell>TABLE III</cell><cell></cell><cell></cell></row><row><cell cols="7">Statistics of Comparisons With MOEA/D Variants</cell></row><row><cell></cell><cell cols="5">Using a Single DE Mutation Operator</cell></row><row><cell></cell><cell></cell><cell>Op. 1</cell><cell>Op. 2</cell><cell cols="2">Op. 3</cell><cell>Op. 4</cell></row><row><cell></cell><cell>-</cell><cell>7</cell><cell>8</cell><cell>5</cell><cell></cell><cell>9</cell></row><row><cell>IGD</cell><cell>+</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell></cell><cell>0</cell></row><row><cell></cell><cell>≈</cell><cell>3</cell><cell>2</cell><cell>5</cell><cell></cell><cell>1</cell></row><row><cell></cell><cell>-</cell><cell>7</cell><cell>7</cell><cell>6</cell><cell></cell><cell>1 0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV</head><label>IV</label><figDesc></figDesc><table><row><cell cols="4">Statistics of Performance Comparisons</cell><cell></cell></row><row><cell></cell><cell cols="3">With the Other AOS Variants</cell><cell></cell></row><row><cell></cell><cell>PM</cell><cell>AP</cell><cell>SRMAB</cell><cell>Uniform</cell></row><row><cell>-</cell><cell>9</cell><cell>7</cell><cell>5</cell><cell>1 0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V</head><label>V</label><figDesc>Statistics of Performance Comparisons With the OtherMOEA/D Variants on Many-Objective Problems</figDesc><table><row><cell></cell><cell></cell><cell>MOEA/D</cell><cell>DRA</cell><cell>ENS</cell></row><row><cell></cell><cell>-</cell><cell>3</cell><cell>3</cell><cell>3</cell></row><row><cell>IGD</cell><cell>+</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>≈</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>-</cell><cell>3</cell><cell>2</cell><cell>2</cell></row><row><cell>I H</cell><cell>+</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>≈</cell><cell>0</cell><cell>1</cell><cell>1</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The source codes of MOEA/D-DE and MOEA/D-DRA were obtained from the open source package jMetal, which can be downloaded at .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The source code of ENS-MOEA/D was obtained from its original authors.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>All experiments were run on a 2.3-GHz Intel Core i7 machine, with 16-GB 1600-MHz DDR3 of RAM memory, running Mac OS X 10.8.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the Natural Science Foundation of China under Grant 61272289, and by the City University of Hong Kong under Strategic Grant 7002826. K. Li and S. Kwong are with the</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Nonlinear Multiobjective Optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Miettinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Kluwer Academic</publisher>
			<biblScope unit="volume">12</biblScope>
			<pubPlace>The Netherlands</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Dordrecht</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multiple objective optimization with vector evaluated genetic algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st Int. Conf. Genet. Algorithms</title>
		<meeting>1st Int. Conf. Genet. Algorithms</meeting>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="93" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A fast and elitist multiobjective genetic algorithm: NSGA-II</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meyarivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2002-04">Apr. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SPEA2: Improving the strength Pareto evolutionary algorithm for multiobjective optimization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laumanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Evol</title>
		<meeting>Evol</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="95" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A jumping gene paradigm for evolutionary multiobjective optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="159" />
			<date type="published" when="2008-04">Apr. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">MOEA/D: A multiobjective evolutionary algorithm based on decomposition</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="712" to="731" />
			<date type="published" when="2007-12">Dec. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning paradigm based on jumping genes: A general framework for enhancing exploration in evolutionary multiobjective optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-F</forename><surname>Man</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Sci</title>
		<imprint>
			<biblScope unit="volume">226</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2013-03">Mar. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Achieving balance between proximity and diversity in multiobjective evolutionary algorithm</title>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Sci</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="220" to="242" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Multi-Objective Optimization Using Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Evolutionary Algorithms for Solving Multi-Objective Problems (Genetic and Evolutionary Computation)</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Coello Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Lamont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A V</forename><surname>Veldhuizen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>nd ed</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">G</forename><surname>Lobo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Lima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parameter Setting in Evolutionary Algorithms</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Lobo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lima</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin/Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Finite-time analysis of the multiarmed bandit problem</title>
		<author>
			<persName><forename type="first">P</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learning</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="235" to="256" />
			<date type="published" when="2002-05">May 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adaptive operator selection with dynamic multiarmed bandits</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Da</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fialho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annu. Conf. Genet</title>
		<meeting>Annu. Conf. Genet</meeting>
		<imprint>
			<date type="published" when="2008-07">Jul. 2008</date>
			<biblScope unit="page" from="913" to="920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Analyzing bandit-based adaptive operator selection mechanisms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fialho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Da</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="25" to="64" />
			<date type="published" when="2010-10">Oct. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dynamic multiarmed bandits and extreme value-based rewards for adaptive operator selection in evolutionary algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fialho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Da</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Int. Conf. Learning Intell. Optimization</title>
		<meeting>3rd Int. Conf. Learning Intell. Optimization</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5851</biblScope>
			<biblScope unit="page" from="176" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Toward comparison-based adaptive operator selection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fialho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annu. Conf. Genet</title>
		<meeting>Annu. Conf. Genet</meeting>
		<imprint>
			<date type="published" when="2010-07">Jul. 2010</date>
			<biblScope unit="page" from="767" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Differential evolution algorithm with strategy adaptation for global numerical optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="398" to="417" />
			<date type="published" when="2009-04">Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">JADE: Adaptive differential evolution with optional external archive</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="945" to="958" />
			<date type="published" when="2009-10">Oct. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Selfadapting control parameters in differential evolution: A comparative study on numerical benchmark problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Boskovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mernik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zumer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="646" to="657" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Self-adaptive multiobjective differential evolution with direction information provided by archived inferior solutions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2008-07">Jul. 2008</date>
			<biblScope unit="page" from="2806" to="2815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multiobjective optimization based on self-adaptive differential evolution algorithm</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Tasgetiren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2007-05">May. 2007</date>
			<biblScope unit="page" from="3601" to="3608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multiobjective optimization using self-adaptive differential evolution algorithm</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mallipeddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2009-09">Sep. 2009</date>
			<biblScope unit="page" from="190" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multiobjective differential evolution with adaptive control of parameters and operators</title>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fialho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th Int. Conf. Learning Intell. Optimization (LION)</title>
		<meeting>5th Int. Conf. Learning Intell. Optimization (LION)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="473" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multiobjective differential evolution with self-navigation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Rudas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Syst. Man Cybern</title>
		<meeting>IEEE Int. Conf. Syst. Man Cybern</meeting>
		<imprint>
			<date type="published" when="2012-10">Oct. 2012</date>
			<biblScope unit="page" from="508" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Differential evolution algorithm with ensemble of parameters and mutation strategies</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mallipeddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Tasgetiren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1679" to="1696" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Differential evolution with composite trial vector generation strategies and control parameters</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="66" />
			<date type="published" when="2011-02">Feb. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The performance of a new version of MOEA/D on CEC09 unconstrained MOP test instances</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2009-05">May 2009</date>
			<biblScope unit="page" from="203" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Parameter control in evolutionary algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Eiben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parameter Setting in Evolutionary Algorithms</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Lobo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Lima</surname></persName>
		</editor>
		<editor>
			<persName><surname>Michalewicz</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin/Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="19" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Adapting operator probabilities in genetic algorithms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICGA</title>
		<meeting>ICGA</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="61" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adaptive strategy selection in differential evolution</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fialho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annu. Conf. Genet</title>
		<meeting>Annu. Conf. Genet</meeting>
		<imprint>
			<date type="published" when="2010-07">Jul. 2010</date>
			<biblScope unit="page" from="409" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Use of statistical outlier detection method in adaptive evolutionary algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Whitacre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sarker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annu. Conf. Genet</title>
		<meeting>Annu. Conf. Genet</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1345" to="1352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Comparisonbased adaptive strategy selection in differential evolution</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fialho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th Int. Conf. Parallel Problem Solving From Nature</title>
		<meeting>11th Int. Conf. Parallel Problem Solving From Nature</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="194" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Autonomous operator management for evolutionary algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lardeux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Saubion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Heuristics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="881" to="909" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Probability matching, the magnitude of reinforcement, and classifier system bidding</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learning</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="407" to="425" />
			<date type="published" when="1990-10">Oct. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">An adaptive pursuit strategy for allocating operator probabilities</title>
		<author>
			<persName><forename type="first">D</forename><surname>Thierens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annu. Conf. Genet</title>
		<meeting>Annu. Conf. Genet</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1539" to="1546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adaptive operator selection for optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fialho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Sci. Dept., Univ. Paris-Sud XI</title>
		<imprint>
			<date type="published" when="2010-12">Dec. 2010</date>
			<pubPlace>Orsay, France</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Approximating the nondominated front using the Pareto archived evolution strategy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Corne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="149" to="172" />
			<date type="published" when="2000-06">Jun. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Decomposition-based memetic algorithm for multiobjective capacitated arc routing problem</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="151" to="165" />
			<date type="published" when="2011-04">Apr. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Adaptation of scalarizing functions in MOEA/D: An adaptive scalarizing functionbased multiobjective evolutionary algorithm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sakane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tsukamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nojima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th Int. Conf. Evol. Multi-Criterion Optimization</title>
		<meeting>5th Int. Conf. Evol. Multi-Criterion Optimization</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="438" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A hybrid estimation of distribution algorithm with decomposition for solving the multiobjective multiple traveling salesman problem</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Cheong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern., C Appl. Rev</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="682" to="691" />
			<date type="published" when="2012-09">Sep. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A direct local search mechanism for decomposition-based multiobjective evolutionary algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CEC</title>
		<meeting>IEEE CEC</meeting>
		<imprint>
			<date type="published" when="2012-06">Jun. 2012</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A hybrid framework for evolutionary multiobjective optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sindhya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Miettinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint/>
	</monogr>
	<note>to be published</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Differential evolution: A simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optimization</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997-12">Dec. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A combined genetic adaptive search (geneas) for engineering design</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Sci. Informatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="30" to="45" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Multiobjective optimization problems with complicated pareto sets, MOEA/D and NSGA-II</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="284" to="302" />
			<date type="published" when="2009-04">Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Decomposition based multiobjective evolutionary algorithm with an ensemble of neighborhood sizes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="442" to="446" />
			<date type="published" when="2012-06">Jun. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Multiobjective optimization test instances for the CEC 2009 special session and competition</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tiwari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<pubPlace>Essex, U.K./Singapore, Tech</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Univ. Essex and Nanyang Technological University</orgName>
		</respStmt>
	</monogr>
	<note>Rep. CES-487</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A review of multiobjective test problems and a scalable test problem toolkit</title>
		<author>
			<persName><forename type="first">S</forename><surname>Huband</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hingston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Barone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>While</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="477" to="506" />
			<date type="published" when="2006-10">Oct. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Performance assessment of multiobjective optimizers: An analysis and review</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laumanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Da Fonseca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="117" to="132" />
			<date type="published" when="2003-04">Apr. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Using the averaged hausdorff distance as a performance measure in evolutionary multiobjective optimization</title>
		<author>
			<persName><forename type="first">O</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Esquivel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Coello Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="504" to="522" />
			<date type="published" when="2012-08">Aug. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The balance between proximity and diversity in multiobjective evolutionary algorithms</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bosman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Thierens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="174" to="188" />
			<date type="published" when="2003-04">Apr. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Multiobjective evolutionary algorithms: A comparative case study and the strength pareto approach</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="257" to="271" />
			<date type="published" when="1999-11">Nov. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Pareto-, aggregation-, and indicator-based methods in many-objective optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Beume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Naujoks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Int. Conf. Evol. Multi-Criterion Optimization</title>
		<meeting>4th Int. Conf. Evol. Multi-Criterion Optimization</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="742" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Problem definitions for performance assessment of multiobjective optimization algorithms</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Preuss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huband</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nanyang Technol. Univ</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>Singapore</pubPlace>
		</imprint>
	</monogr>
	<note>Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Since 2012, he has been a Computational Intelligence Researcher within GE Global Research, Rio de Janeiro, Brazil. His current research interests include extension and hybridization of computational intelligence tools for tackling real-world problems</title>
		<author>
			<persName><forename type="first">Ke</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">B</forename><surname>Sc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kowloon</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Kong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dr. Kwong is an Associate Editor of the IEEE Transactions on Industrial Electronics, the IEEE Transactions on Industrial Informatics, and the Information Sciences Journal. Qingfu Zhang (M&apos;01-SM&apos;06) received the B.Sc. degree in mathematics from Shanxi University</title>
		<meeting><address><addrLine>China; Xiangtan, China; São Paulo, Brazil; Orsay, France; Waterloo, ON, Canada; Hagen, Germany; Kowloon, Hong Kong; Shanxi, China; Xi&apos;an, China; Kowloon, Hong Kong; Colchester U.K.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1982">1985. 2007 and 2010. 1982. 2010. 1985. 1996. 1990. 1991 and 1994</date>
		</imprint>
		<respStmt>
			<orgName>degrees in computer science and technology from Xiangtan University ; Department of Computer Science, City University of Hong ; Université Paris-Sud XI ; City University of Hong Kong ; Department of Computer Science, City University of Hong Kong ; School of Computer Science and Electronic Engineering, University of Essex</orgName>
		</respStmt>
	</monogr>
	<note>He holds two patents. His current research interests include evolutionary computation, optimization, neural networks, data analysis, and their applications. He is also an Editorial Board Member of three other international journals. MOEA/D, a multiobjective optimization algorithm developed in his group, won the Unconstrained Multiobjective Optimization Algorithm Competition at the Congress of Evolutionary Computation in 2009, and was a recipient of the 2010 IEEE Transactions on Evolutionary Computation Outstanding Paper Award</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
