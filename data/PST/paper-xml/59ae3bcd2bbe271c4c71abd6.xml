<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A theoretical understanding of self-paced learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-05-26">26 May 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Deyu</forename><surname>Meng</surname></persName>
							<email>dymeng@mail.xjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics and Statistics and Ministry of Education Key Lab of Intelligent Networks and Network Security</orgName>
								<orgName type="institution">Xian Jiaotong University</orgName>
								<address>
									<postCode>710049</postCode>
									<settlement>Xian</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qian</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics and Statistics and Ministry of Education Key Lab of Intelligent Networks and Network Security</orgName>
								<orgName type="institution">Xian Jiaotong University</orgName>
								<address>
									<postCode>710049</postCode>
									<settlement>Xian</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lu</forename><surname>Jiang</surname></persName>
							<email>lujiang@cs.cmu.edu</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A theoretical understanding of self-paced learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-05-26">26 May 2017</date>
						</imprint>
					</monogr>
					<idno type="MD5">B834C9C90DEE601F6FB547A22B69E79A</idno>
					<idno type="DOI">10.1016/j.ins.2017.05.043</idno>
					<note type="submission">Received 14 August 2016 Revised 23 May 2017 Accepted 25 May 2017</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Self-paced learning Curriculum learning Multimedia event detection Non-convex regularized penalty</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Self-paced learning (SPL) is a recently proposed methodology designed by mimicking through the learning principle of humans/animals. A variety of SPL realization schemes have been designed for different computer vision and pattern recognition tasks, and empirically demonstrated to be effective in these applications. However, the literature is in lack of the theoretical understanding of SPL. Regarding this research gap, this study attempts to provide some new theoretical understanding of the SPL scheme. Specifically, we prove that the solution strategy on SPL accords with a majorization minimization algorithm implemented on an implicit objective function. Furthermore, we found that the loss function contained in this implicit objective has a similar configuration with the non-convex regularized penalty (NCRP) known in statistics and machine learning. Such connection inspires us to discover more intrinsic relationships between the SPL regimes and the NCRP forms, like smoothly clipped absolute deviation (SCAD), logarithmic penalty (LOG) and non-convex exponential penalty (EXP). The insight of the robustness under SPL can then be finely explained. We also analyze the capability of SPL regarding its easy loss-priorembedding property, and provide an insightful interpretation of the effectiveness mechanism under current SPL variations. Moreover, we design a group-partial-order loss prior, which is especially useful for weakly labeled large-scale data processing tasks. By applying SPL with this loss prior to the FCVID dataset, which is currently one of the largest manually annotated video dataset, our method achieves state-of-the-art performance above existing methods, which further supports the proposed theoretical arguments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Since their inception, curriculum learning (CL) <ref type="bibr" target="#b1">[2]</ref> and self-paced learning (SPL) <ref type="bibr" target="#b14">[15]</ref> have been attracting increasing attention in the machine learning and pattern recognition fields. The idea under this learning paradigm is to simulate the learning principle of humans/animals, which generally starts by learning easier aspects of a learning task, and then gradually introduces more complex examples into training <ref type="bibr" target="#b12">[13]</ref> . Instead of heuristically designing a curriculum by ranking samples based on manually presetting easiness measurements as in CL <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">24]</ref> , SPL formulates this ad-hoc scheme as a concise model by introducing a regularizor into the learning objective. Such amelioration guides a sound SPL regime to automatically optimize an appropriate curriculum by the model itself, making it general enough to solving problems in various applications and avoid the subjective easiness measure setting problem <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref> . Very recently, a variety of SPL realization schemes, like self-paced reranking (SPaR) <ref type="bibr" target="#b7">[8]</ref> and self-paced multi-instance learning (SP-MIL) <ref type="bibr" target="#b35">[36]</ref> , have been proposed and shown to be effective for multiple computer vision and multimedia analysis tasks.</p><p>Albeit rational in intuition and effective in experience, there are only few investigations on the explanation of the underlying mechanism of SPL. Specifically, even though it is easy to prove that the SPL regime is convergent by adopting an alternative optimization strategy (AOS) on the SPL model, it is still unclear where this SPL iteration converges and why SPL is robust in solving the learning problems especially with highly noisy data. Such in-depth investigations, however, can be considerably necessary for future developments of CL, SPL and their related realizations, and will illuminate whether the SPL methodology is just an idealistic method occasionally performed on several datasets or a rigorous and solid scientific research field worthy of further exploration.</p><p>This study aims at understanding the theoretical insight under SPL. Our main results can be summarized as follows: First, we prove that the AOS algorithm commonly utilized to solve the SPL problem is identical to a majorization minimization (MM) <ref type="bibr" target="#b27">[28]</ref> algorithm implemented on an implicit SPL objective function. In the recent decade, MM has attracted much attention in machine learning and optimization, and many theories have been proposed. Such results facilitate an easy analysis on the properties underlying the SPL solving strategy, like convergence and stability, by utilizing the existing knowledge on MM.</p><p>Second, we prove that the loss function contained in this implicit SPL objective is closely related to the non-convex regularized penalty (NCRP). Specifically, we discover that multiple current SPL realizations exactly comply with some well known NCRP terms (e.g., the hard and linear SPL regimes are equivalent to the optimizations on implicit losses with the forms of capped-norm penalty (CNP) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b37">38]</ref> and minimax concave plus penalty (MCP) <ref type="bibr" target="#b33">[34]</ref> , respectively). Such connection inspires us to discover more intrinsic relationship between SPL regimes and known NCRP forms, like smoothly clipped absolute deviation (SCAD) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b22">23]</ref> , logarithmic penalty (LOG) <ref type="bibr" target="#b31">[32]</ref> , and non-convex exponential penalty (EXP) <ref type="bibr" target="#b2">[3]</ref> .</p><p>Third, by connecting the SPL optimization with the NCRP loss minimization problems, we provide an easy explanation on why SPL is able to perform robust in the presence of outliers/heavy noises, and accordingly illustrate new insightful understandings of the intrinsic working mechanism under SPL. We also analyze the superiority of SPL regarding its easy loss-prior-embedding property beyond conventional learning strategies with a pre-fixed loss function. Such a property is expected to help a non-convex optimization problem better avert unreasonable local minima and makes SPL more compliant with the instructor-student-collaborative-learning mode in human education. Such understanding facilitates an easy interpretation for its intrinsic effective mechanism of SPL in previous applications <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b39">40]</ref> .</p><p>We also propose a group-partial-order loss prior to facilitate better SPL performance in weakly labeled large-scale problems, and implement this SPL regime on the FCVID dataset, which is currently one of the biggest manually annotated video dataset. Our method achieves state-of-the-art performance as compared with previous methods. The results further support the theoretical arguments presented in this study.</p><p>The paper is organized as follows. Section 2 introduces the related work and Section 3 presents our main theoretical results, and clarifies the relationships between AOS and MM algorithms as well as SPL and NCRP problems. Section 4 introduces the group-partial-order loss prior and provides the related experimental results on the FCVID dataset. Finally, concluding remarks are made.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Curriculum Learning (CL). Inspired by the intrinsic learning principle of humans/animals, Bengio et al. <ref type="bibr" target="#b1">[2]</ref> formalized the fundamental definition of CL. The core idea is to incrementally involve samples in learning, where easy samples are introduced first and more complex ones are then gradually included. These gradually included samples from easy to complex correspond to the curricula learned in different grown-up stages of humans/animals. This strategy, as supported by empirical evaluation, is helpful in alleviating the local optimum problem in non-convex optimization <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b21">22]</ref> .</p><p>Self-paced Learning (SPL). Instead of using the heuristic strategies, Kumar et al. <ref type="bibr" target="#b14">[15]</ref> formulated the key principle of CL as a concise SPL model. Formally, given a training dataset D = { (x i , y i ) } n i =1 , in which x i and y i denote the i th observed sample and its label, respectively, L ( y i , g ( x i , w )) denotes the loss function that calculates the cost between the ground truth label y i and the estimated one g ( x i , w ), and w represents the model parameter in the decision function g . The SPL model includes a weighted loss term on all samples and a general self-paced regularizer imposed on sample weights, expressed as:</p><formula xml:id="formula_0">min w , v ∈ [0 , 1] n E (w , v , λ) = n i =1 ( v i L (y i , f (x i , w )) + f (v i , λ) ) , (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where λ is the age parameter for controlling the learning pace, and f ( v, λ) represents the self-paced regularizer (SPregularizer), whose intrinsic conditions have been theoretically abstracted by <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b39">40]</ref> . By jointly learning the model parameter w and the latent weight</p><formula xml:id="formula_2">v = [ v 1 , • • • , v n ]</formula><p>T by AOS with gradually increasing age parameter, more samples can be automatically included in the training from easy to complex in a purely self-paced way.</p><p>Multiple variations of this SPL learning regime, like self-paced reranking <ref type="bibr" target="#b7">[8]</ref> , self-paced multiple instance learning <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref> , self-paced learning with diversity <ref type="bibr" target="#b8">[9]</ref> , and self-paced curriculum learning <ref type="bibr" target="#b9">[10]</ref> , have been proposed under the format <ref type="bibr" target="#b0">(1)</ref> . The effectiveness of this SPL paradigm, especially its robustness in highly corrupted data, has been empirically validated in various machine learning and computer vision tasks, such as object detector adaptation <ref type="bibr" target="#b26">[27]</ref> , specific-class segmentation learning <ref type="bibr" target="#b15">[16]</ref> , visual category discovery <ref type="bibr" target="#b18">[19]</ref> , concept learning <ref type="bibr" target="#b19">[20]</ref> , long-term tracking <ref type="bibr" target="#b24">[25]</ref> , and multimedia event detection <ref type="bibr" target="#b32">[33]</ref> .</p><p>There are few investigations, however, that attempt to theoretically explain the intrinsic mechanism under SPL. In this paper, we attempt to enhance the theoretical understanding on this learning paradigm.</p><p>Non-convex Regularized Penalty (NCRP). NCRP has been demonstrated to have attractive properties in sparse estimation (as a penalty term) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b37">38]</ref> and robust learning (as a loss term) <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b29">30]</ref> both theoretically and practically, and attracted much attention in machine learning and statistics in recent years. Various NCRP realizations have also been proposed. Typical ones include the capped-norm based penalty (CNP) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b37">38]</ref> , the minimax concave plus penalty (MCP) <ref type="bibr" target="#b33">[34]</ref> , the smoothly clipped absolute deviation penalty (SCAD) <ref type="bibr" target="#b4">[5]</ref> , the logarithmic penalty (LOG) <ref type="bibr" target="#b31">[32]</ref> , and the non-convex exponential penalty (EXP) <ref type="bibr" target="#b2">[3]</ref> . The mathematical forms of these NCRP terms in one dimension cases are listed as follows <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b38">39]</ref> :</p><formula xml:id="formula_3">CNP : p CNP γ ,λ (t) = γ min (| t | , λ) , λ &gt; 0 MCP : p MCP γ ,λ (t) = γ (| t | -t 2 2 γ λ ) , if | t | &lt; γ λ γ 2 λ 2 , if | t| ≥ γ λ SCAD : p SCAD γ ,λ (t) = ⎧ ⎪ ⎨ ⎪ ⎩ λ| t| , if | t| ≤ λ t 2 -2 γ λ| t| + λ 2 2(1 -γ ) , if λ &lt; | t| ≤ γ λ (γ +1) λ 2 2 , if | t| ≥ γ λ LOG : p LOG γ ,α (t) = 1 γ log (1 + α| t| ) EXP : p EXP γ ,α (t) = 1 γ (1 -exp (-α| t| )) .</formula><p>(</p><formula xml:id="formula_4">)<label>2</label></formula><p>Albeit possessing elegant statistic properties and empirically verified to be effective in specific applications through finely designed solving strategies, involving such NCRP terms brings non-convexity to the model. This tends to result in the issue in which the algorithm easily becomes stuck at an undesired local minima of the problem <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b29">30]</ref> .</p><p>In this work, we will construct the relationship between the NCRP terms and the SPL regimes and show that helpful loss prior knowledge can be easily embedded into the SPL framework, which is expected to facilitate a NCRP model possibly avoiding unreasonable local minima of the problem and attaining more rational ones that better comply with real states.</p><p>Majorization Minimization (MM) Algorithm. The MM algorithms have wide applications in machine learning and statistical inference <ref type="bibr" target="#b16">[17]</ref> . These algorithms turn a complicated optimization problem into a tractable one by alternatively iterating the majorization and minimization steps. In particular, considering a minimization problem with the objective F ( w ), given an estimate of w k at the k th iteration, a typical MM algorithm consists of the following two steps:</p><p>Majorization Step : Substitute F ( w ) by a surrogate function Q ( w | w k ) such that:</p><formula xml:id="formula_5">F (w ) ≤ Q (w | w k )</formula><p>with equality holding at w = w k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Minimization</head><p>Step : Obtain the next parameter estimate w k +1 by solving the following minimization problem:</p><formula xml:id="formula_6">w k +1 = arg min w Q (w | w k ) .</formula><p>It is easy to see that when the minimization of Q ( w | w k ) is tractable, the MM algorithm can then be very easily implemented, even when the original objective F ( w ) might be difficult to optimize. Such a solving strategy has also been proven to own many good theoretical properties, like convergence and stability, under certain conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">SPL model and algorithm revisit</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Axiomic definition of SP-regularizer</head><p>By mathematically abstracting the insightful properties underlying an SPL regime, <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b39">40]</ref> presented a formal definition for the SP-regularizer f ( v, λ) involved in the SPL model (1) as follows: Definition 3.1 (SP-regularizer) . Suppose that v is a weight variable, is the loss, and λ is the age parameter. <ref type="figure">λ</ref>) is monotonically decreasing with respect to , and it holds that lim <ref type="figure">λ</ref>) is monotonically increasing with respect to λ, and it holds that lim</p><formula xml:id="formula_7">f ( v, λ) is called a self-paced regularizer, if 1. f ( v, λ) is convex with respect to v ∈ [0 , 1] ; 2. v * ( ,</formula><formula xml:id="formula_8">→ 0 v * ( , λ) = 1 , lim →∞ v * ( , λ) = 0 ; 3. v * ( ,</formula><formula xml:id="formula_9">λ → ∞ v * ( , λ) ≤ 1, lim λ→ 0 v * ( , λ) = 0 ; where v * ( , λ) = arg min v ∈ [0 , 1] v + f (v , λ) . (<label>3</label></formula><formula xml:id="formula_10">)</formula><p>The three conditions in Definition 3.1 provide basic principles for constructing an SP-regularizer. Condition 2 indicates that the model inclines to select easy samples (with smaller losses) in favor of complex samples (with larger losses). Condition 3 states that when the model "age" (controlled by the age parameter λ) gets larger, it tends to incorporate more, probably complex, samples to train a "mature" model. The convexity in Condition 1 further ensures the soundness of this regularizer for optimization.</p><p>Under this definition, multiple SP-regularizers have been constructed. The following lists several typical ones, together with their closed-form solutions v * ( λ, ) as defined in Definition 3.1 :</p><formula xml:id="formula_11">f H (v , λ) = -λv ; v * ( , λ) = 1 , if &lt; λ 0 , if ≥ λ f L (v , λ) = λ( 1 2 v 2 -v ) ; v * ( , λ) = -/λ + 1 , if &lt; λ 0 , if ≥ λ f M (v , λ, γ ) = γ 2 v + γ /λ ; v * ( , λ, γ ) = ⎧ ⎪ ⎨ ⎪ ⎩ 1 , if ≤ λγ λ+ γ 2 0 , if ≥ λ 2 γ 1 √ -1 λ , otherwise .<label>(4)</label></formula><p>The above Eq. ( <ref type="formula" target="#formula_11">4</ref>) represents the hard, linear and mixture SP-regularizers proposed in <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b14">15]</ref> , and <ref type="bibr" target="#b39">[40]</ref> , respectively. Using the AOS strategy to iteratively update v and w in the SPL regime <ref type="bibr" target="#b0">(1)</ref> with the gradually increasing age parameter λ, a rational solution to the problem is expected to be progressively approached.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Revisit AOS algorithm for solving SPL</head><p>For convenience of notation, we briefly write L ( y i , g ( x i , w )) as i ( w )/ i and L ( y, g ( x, w )) as ( w )/ in the following equation.</p><p>Given an SP-regularizer f ( v, λ), we can write the integrative function of v * ( , λ) calculated by Eq. ( <ref type="formula" target="#formula_9">3</ref>) as:</p><formula xml:id="formula_12">F λ ( ) = 0 v * (l , λ) dl .</formula><p>(</p><formula xml:id="formula_13">)<label>5</label></formula><p>The following result can then be proved. The proof is listed in the appendix.</p><p>Theorem 1. For v * ( , λ) conducted by an SP-regularizer and F λ ( ) calculated by <ref type="bibr" target="#b4">(5)</ref> , given a fixed w * , it holds that:</p><formula xml:id="formula_14">F λ ( (w )) ≤ Q λ ( w | w * ) = F λ ( (w * )) + v * ( (w * ) , λ)( (w ) -(w * )) .</formula><p>The theorem can be easily understood from the fact that: Since v * ( , λ) is monotonically decreasing in based on Condition 2 of SP-regularizer Definition 3.1 , its integrative F λ ( ) is concave with respect to , and thus it is easy to deduce that its Taylor series to the first order forms an upper bound of F λ ( ). Theorem 1 verifies that Q λ ( w|w * ) represents a tractable surrogate for F λ ( ( w )). Specifically, only considering the terms with respect to w , Q λ ( w|w * ) simplifies F λ ( ( w )), no matter how complicated its format is, as an easy weighted loss form v * ( ( w * ), λ) ( w ). This constitutes the fundament of our new understanding of the AOS algorithm for solving SPL.</p><p>Based on Theorem 1 , denote</p><formula xml:id="formula_15">Q (i ) λ ( w | w * ) = F λ ( i (w * )) + v * ( i (w * ) , λ)( i (w ) -i (w * ) ,</formula><p>and we can then easily attain the following:</p><formula xml:id="formula_16">n i =1 F λ ( i (w )) ≤ n i =1 Q (i ) λ ( w | w * ) . (6)</formula><p>Then, we can prove the equivalence between the AOS strategy for solving the SPL problem (1) and the MM algorithm for</p><formula xml:id="formula_17">solving n i =1 F λ ( i (w )) under surrogate function n i =1 Q (i ) λ ( w | w * ) as follows:</formula><p>If we denote w k as the model parameters in the k th iteration of the AOS implementation on solving SPL, and then its two alternative search steps in the next iteration can be precisely explained as a standard MM scheme:</p><p>Majorization step : To obtain each Q (i )   λ ( w | w k ) , we only need to calculate v * ( i ( w k ), λ) by solving the following problem under the corresponding SP-regularizer f ( v i , λ):</p><formula xml:id="formula_18">v * ( i (w k ) , λ) = min v i ∈ [0 , 1] v i i (w k ) + f (v i , λ) .</formula><p>This exactly complies with the AOS step in updating v in (1) under fixed w . Minimization step : We need to calculate the following:</p><formula xml:id="formula_19">w k +1 = arg min w n i =1 F λ ( i (w k )) + v * ( i (w k ) , λ)( i (w ) -i (w k )) = arg min w n i =1 v * ( i (w k ) , λ) i (w ) ,</formula><p>which is exactly equivalent to the AOS step in updating w in (1) under fixed v . ( ) conducted by the hard, soft and mixture SP-regularizers on different loss functions, including the logistic loss, the hinge loss, the absolute loss, and the least square loss, under various pace parameters in 1-dimensional cases, respectively. Note that when λ = ∞ ( λ, γ = ∞ in the mixture cases), the implicit SPL loss F λ ( ) degenerates to the original loss .</p><p>It is then easy to see that the commonly utilized AOS strategy in previous SPL regimes is exactly the well known MM algorithm on a minimization problem of the implicit SPL objective n i =1 F λ ( i (w )) with the implicit SPL loss F λ ( ( w )). Various off-the-shelf theoretical results of MM can then be readily employed to explain the properties of such SPL solving strategies. For example, based on the MM theory, the lower-bounded implicit SPL objective is monotonically decreasing during MM/AOS iteration, and the convergence of the SPL algorithm can then be guaranteed.</p><p>The above theory provides a new viewpoint for understanding SPL insight. More in-depth knowledge on SPL is then expected to be extracted from it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Revisit SPL model</head><p>Now we try to discover more interesting insights from the implicit SPL objective. To this aim, we first calculate the implicit SPL losses under hard, linear, and mixture SP-regularizers, as introduced in (4) , by Eq. ( <ref type="formula" target="#formula_13">5</ref>) as follows:</p><formula xml:id="formula_20">F H λ ( ) = , &lt; λ, λ, ≥ λ; F L λ ( ) = -2 / 2 λ, &lt; λ, λ/ 2 , ≥ λ; F M λ,γ ( ) = ⎧ ⎨ ⎩ , &lt; 1 (1 /λ+1 /γ ) 2 , γ (2 √ -/λ) - γ (1 /λ+1 /γ ) , 1 (1 /λ+1 /γ ) 2 ≤ &lt; λ 2 , γ (λ -1 1 /λ+1 /γ ) , ≥ λ 2 . (<label>7</label></formula><formula xml:id="formula_21">)</formula><p>The configurations of these F λ ( )s under different age parameters are depicted in Fig. <ref type="figure" target="#fig_0">1</ref> for easy observation. Some common patterns under these implicit SPL losses can be easily observed from Fig. <ref type="figure" target="#fig_0">1</ref> . For example, there is an evident suppressing effect of F λ ( ) on large losses compared to the original loss function . When is larger than a certain threshold, F λ ( ) will become a constant thereafter. This provides a rational explanation regarding why the SPL regime can perform robust in the presence of extreme outliers or heavy noise: The samples with loss values larger than the age threshold will have no influence on model training due to their zero gradients. Corresponding to the original SPL model, these large-loss samples will have zero importance weights v i , and thus have no effect on the optimization of model parameters. Now, we reexamine the intrinsic mechanism inside SPL implementation based on such understanding. In the beginning of SPL iteration, the age λ is small, and the implicit loss function F λ ( ) has a significant suppressing effect on large losses and only allows a small number of high-confidence samples (with small loss values) into training; then, with gradually increasing λ, the suppressing effect of F λ ( ) will gradually become weaker and relatively less informative samples tend to be included in the training. Through such robust guidance, increasingly faithful data knowledge tends to be incrementally learned by such learning schemes. Such a gradually changing tendency of implicit SPL loss F λ ( ) can be easily understood by viewing Fig. <ref type="figure" target="#fig_0">1</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Relationship with NCRP</head><p>An interesting observation is that the implicit SPL objective F λ ( ) has a close relationship with NCRP that has been widely investigated in machine learning and statistics. For example, the hard and linear SPL objectives ( F H λ ( ) and F L λ ( ) ) comply exactly with the forms of CNP and MCP, as defined in Eq. ( <ref type="formula" target="#formula_4">2</ref>) , which are imposed on by setting γ = 1 , respectively, that is,</p><formula xml:id="formula_22">F H λ ( ) = p CNP 1 ,λ ( ) , F L λ ( ) = p MCP 1 ,λ ( ) .</formula><p>Furthermore, the form of F M λ,γ ( ) is almost similar to the SCAD term, both containing three phases of values, and the first and third of both are linear and constant, respectively. The only difference is in the second phase, where F M λ,γ ( ) is of linear+sqrt+constant form while SCAD is of a linear+square+constant form. It is easy to deduce that any F λ ( ) led by an SPregularizer is non-convex and has a very similar configuration with a general NCRP. Such a natural relationship provides a new viewpoint to see NCRP and facilitates more choices of NCRP formulations by virtue of F λ ( ) obtained under various SPregularizers and inspires us to borrow mature statistical tools and theoretical results regarding NCRP to further understand SPL insight in our future investigation. This relationship is also helpful for finding self-paced formats of more typical NCRP terms. Here we also deduce the SP-regularizers of another two commonly utilized NCRP terms <ref type="bibr" target="#b38">[39]</ref> : LOG and EXP (see Eq. ( <ref type="formula" target="#formula_4">2</ref>) ).</p><p>For LOG, we can construct the following SP-regularier:</p><formula xml:id="formula_23">f LOG (v , λ, α) = 1 α KL (1 + αλ, v ) = 1 α (1 + αλ) log 1 + αλ v -(1 + αλ) + v ,</formula><p>where KL ( x, y ) denotes the Kullback-Leibler (KL) distance <ref type="bibr" target="#b38">[39]</ref> between two variables. As calculated by Eq. ( <ref type="formula" target="#formula_9">3</ref>) , its optimal</p><formula xml:id="formula_24">weight v * ( , λ, α) is: v * ( , λ, α) = 1 ≤ λ, 1+ αλ 1+ α &gt; λ.</formula><p>It is easy to prove that such a defined LOG SP-regularizer complies with the three conditions in Definition 3.1 . By virtue of Eq. ( <ref type="formula" target="#formula_13">5</ref>) , we can obtain its implicit SPL loss with the form:</p><formula xml:id="formula_25">F LOG ( , λ, α) = ≤ λ, p LOG 1+ αλ,α ( ) + C λ,α &gt; λ, (<label>8</label></formula><formula xml:id="formula_26">)</formula><p>where C λ,α = λ -1+ αλ α log (1 + αλ) is a constant independent of and p LOG γ ,α (•) is defined as Eq. ( <ref type="formula" target="#formula_4">2</ref>) .</p><p>In addition, the EXP SP-regularizer can be constructed as:</p><formula xml:id="formula_27">f EXP (v ; λ, α) = 1 α KL (v , exp (αλ)) = 1 α (v log v exp (αλ) -v + exp (αλ)) .</formula><p>Its optimal importance weight can be calculated by Eq. ( <ref type="formula" target="#formula_9">3</ref>) as:</p><formula xml:id="formula_28">v * ( , λ, α) = 1 ≤ λ, exp (-α( -λ)) &gt; λ.</formula><p>The corresponding implicit SPL loss is:</p><formula xml:id="formula_29">F EXP ( , λ, α) = ≤ λ, p EXP α, exp (-αλ) ( ) + C λ,α &gt; λ, (<label>9</label></formula><formula xml:id="formula_30">)</formula><p>where C λ,α = λ + 1 α -exp (αλ) α and p EXP γ ,α (•) is defined as Eq. ( <ref type="formula" target="#formula_4">2</ref>) .</p><p>It should be noted that LOG and EXP are different from CNP, MCP, and SCAD in their large-loss-suppressing effects. The latter suppress large losses as a constant (see Eq. ( <ref type="formula" target="#formula_4">2</ref>) ) while the former do this task by the gradually more slowly increasing property of logarithmic and negative exponential functions. It is easy to see that, in large loss cases, the LOG and EXP implicit SPL loss functions ( <ref type="formula" target="#formula_25">8</ref>) and ( <ref type="formula" target="#formula_29">9</ref>) degenerate to the conventional LOG and EXP terms, and thus possess similar robust mechanism for suppressing outliers/heavy noise. By properly adjusting age parameter λ, they are capable of adapting different noise extents in data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Loss-prior-embedding property of SPL</head><p>An intrinsic property of SPL is to decompose the minimization of the robust but difficult-to-solve non-convex loss F λ ( ( w )) into two easier optimization problems with respect to sample importance weights v (solved by the closed-form solution to an SP-regularizer) and model parameters w (solved by the weighted loss problem). Such decomposition not only simplifies the solving of the problem as an easy re-weighted strategy <ref type="bibr" target="#b3">[4]</ref> but makes it feasible to embed helpful loss prior knowledge into an SPL scheme. Specifically, since the sample importance weight imposed on a sample in the SPL model reflects the extent of its loss value based on Condition 2 of Definition 3.1 for SP-regularizer (the larger the loss, the smaller the weight), the loss priors can be readily encoded as a regularization term or a constraint on v to deliver such knowledge in the SPL model.</p><p>In practical cases, some loss priors always exist which can be easily obtained from training data before the learning process. Here, we list some typical ones as follows:</p><p>1. Outlier prior: Some samples are significantly deviated from the main part of data sets, and thus they should show extremely large losses. 2. Spatial/temporal smoothness prior: Some spatially/temporally adjacent samples tend to show relatively similar large/small losses. 3. Sample importance order prior: A sample is pre-known to show smaller loss value (i.e., cleaner, easier, higher-confident) than others. 4. Diversity prior: Meaningful samples, which should be learned with small loss values (i.e., capable of being predicted accurately) for the learning task, should be scattered across the data range so that the learning can possibly include global-scale data knowledge.</p><p>All this loss prior knowledge can be embedded into an SPL scheme by properly encoding v . For example, Prior 1 can be realized by directly constraining the importance weights v i of those outliers to be zeroes; Prior 2 can be formulated as a graph Laplacian term v T Lv , where L is the Laplacian matrix on the data adjacent matrix <ref type="bibr" target="#b36">[37]</ref> ; Prior 3 can be encoded as the constraint v i &gt; v j if the i th sample is known to be more cleaner/easier than the j th sample <ref type="bibr" target="#b9">[10]</ref> ; and Prior 4 can be realized by a -l 2 , 1 norm <ref type="bibr" target="#b8">[9]</ref> or -l 0 . 5 , 1 norm <ref type="bibr" target="#b35">[36]</ref> (anti-group-sparsity) on v .</p><p>We review this loss-prior-embedding property from the perspective of NCRP. Currently various elegant solving strategies have been designed for solving a general or specific NCRP problem <ref type="bibr" target="#b30">[31]</ref> so as to approach a local minimum or stationary point of the problem. In most of these strategies, however, whether the obtained solution complies with some evident loss prior knowledge has been neglected. For example, by using certain techniques, we might obtain a local minimum of the investigated non-convex problem. However, it might occur that the loss of Sample A predicted at this local minimum is larger than that of Sample B, while we have an intuitive or easily-obtained prior that A is more noisy than B. This implies that this solution, albeit being a local minimum, is an irrational one for the problem. If we transform this NCRP problem into an SPL regime based on the analysis provided in Section 3.4 , and readily encode such loss priors (e.g., sample importance order loss prior) into the latent variables v as a regularizer or a constraint to the problem, the obtained solution is expected to more easily avoid such unreasonable local minima that violate the apriori loss priors. Such easy loss-priorembedding capability thus tends to guide a sounder learning manner for NCRP as well as SPL, which might also provide a new viewpoint of alleviating the local-minimum-issue existing in NCRP problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">SPCL revisit</head><p>Self-paced curriculum learning (SPCL) <ref type="bibr" target="#b9">[10]</ref> was proposed to relate CL and SPL from the viewpoint of human learning. As opposed to "instructor-driven" and "student-driven" learning manners, as CL and SPL, respectively, through involving prior knowledge of sample importance into SPL iteration progress, SPCL is analogous to a more rational "instructor-studentcollaborative" learning mode like practical human education.</p><p>The SPCL process actually illuminates the fundament of the SPL regime embedded with loss priors in the perspective of cognitive science. Specifically, the curriculum knowledge in SPCL complies with the loss priors in this study. That is, a teacher might know some curriculum information to guide the learning process of a student, e.g., some curricula are meaningless to learn (outlier prior), multiple curricula are closely related and should be learned jointly (smoothness prior), one curriculum is much more difficult than another and thus should be learned first (sample importance order prior), diverse curricula should be learned together to make the knowledge possibly comprehensive (diversity prior). Such relationship facilitates a natural interpretation for the empirical effectiveness of SPCL by the fact that the embedded loss priors (curricula) help alleviate the local-minimum-issue of the underlying non-convex optimization problems and guarantee a sound robust learning, and illustrate that an SPL scheme with properly specified loss priors corresponds more to a rational human education manner in real life compared to the pure CL or SPL strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">FCVID experiment</head><p>For a real large-scale pattern recognition task, with limited human labor and computation resources, in general we can only obtain weakly labeled samples, containing a large number of low-confidence annotations (with wrong or uncertain labels). This often leads to a noisy training dataset, which can hamper the robustness of the utilized learning algorithm. The SPL strategy is thus appropriate to be employed to alleviate this issue. Highly deviated samples (i.e., with relatively larger loss values) will be automatically screened out (i.e., with zero-valued v i ) from training and will not negatively influence the learning quality, while those samples with high-confidence annotations (i.e., with smaller loss values) tend to be selected and gradually rectify the learning performance. However, as we have analyzed, SPL intrinsically corresponds to solving a non-convex optimization problem, and useful loss priors are thus required to help avoid the problem stuck to an irrational local minimum. Through ameliorating the sample importance loss prior, we introduce an advanced group-partial-order loss prior, which is especially useful in such large-scale weakly labeled scenarios. Specifically, we can construct this loss prior in two steps: first group and rank data based on the difficulty of annotating them, and then impose a hierarchy loss structure by allowing samples located in groups in front of the ranking list (i.e., with higher-confidence labels) with larger weights than those in behind. The SPL regime is then expected to be soundly guided under such loss priors.</p><p>For verification, we use a real-world big dataset called the Fudan-columbia Video Dataset (FCVID) <ref type="bibr" target="#b10">[11]</ref> , which is by far one of the biggest annotated video sets <ref type="bibr" target="#b10">[11]</ref> and thus is challenging for conventional concept detection techniques. Our As manually labeled videos are difficult to collect, we train concept detectors by only using the contexual information about the videos such as their titles, descriptions, and latent topics. For each concept, a video is automatically labeled as a positive sample if the concept name can be found in its video metedata. The generated weak labels are noisy and have both low accuracy and low recall: The labeled concepts may not be present in the video content, whereas concepts that are not in the web label may appear in the video. The ground truth labels are only used in testing to evaluate the performance. The performance is evaluated in terms of the precision of the top 5 and 10 ranked videos (P@5 and P@10) and the mean average precision (mAP) of 239 concepts. We extract the Convolutional Neural Network (CNN), specifically AlexNet <ref type="bibr" target="#b13">[14]</ref> , features over each keyframe and create video-level feature by average pooling. The features are used across all methods. We adopt this feature since it has been widely substantiated that it can be reliably used in many computer vision tasks. We build our method on top of the CNN features and the l 2 -regularized hinge loss is used as our loss function. The AOS algorithm is used to solve the optimization problem. To construct the group-partial-order loss prior knowledge into SPL on this task, we cluster the videos into a number of latent topics based on their metadata. Then, we rank these groups in the ascending order of the distances between cluster centers to the entire concept class center. Samples located in clusters in front of the ranking list should correspond to more high-confident ones and incline to have a larger weights v i (i.e., with smaller loss values) than those ranking backwards. The hard SP-regularizer <ref type="bibr" target="#b14">[15]</ref> was used in the SPL scheme. In implementation, we used 10% of top-ranked samples in the first iteration to get initialization and stopped increasing the model age λ after 100 iterations.</p><p>We compare our method against the following baseline methods, which cover both the classical and the state-of-the-art algorithms on the same problem. Moreover, the comparison to the baseline helps us understand the contribution of the loss prior knowledge on this problem. BatchTrain trains a single SVM model using all videos with noisy labels. AdaBoost is a classical ensemble approach that combines the sequentially trained base classifiers in a weighted fashion <ref type="bibr" target="#b5">[6]</ref> . Self-Paced Learning (SPL) is the original SPL method without considering loss prior knowledge <ref type="bibr" target="#b14">[15]</ref> . BabyLearning is a recently proposed method that simulates baby learning by starting with a few training samples and fine-tuning using more weakly labeled videos crawled from the search engine <ref type="bibr" target="#b20">[21]</ref> . GoogleHNM is a hard negative mining method proposed by Google <ref type="bibr" target="#b28">[29]</ref> . It utilizes hard negative mining to train the mixture of expert models according to the video's YouTube topics. The hyperparameters of all methods including the baseline methods are tuned on the same standard validation set.</p><p>Table <ref type="table" target="#tab_0">1</ref> compares the precision and mAP of different methods. As we see, the SPL method with group-partial-order loss priors achieves the state-of-the-art result, which outperforms the recently proposed methods, BabyLearning <ref type="bibr" target="#b20">[21]</ref> and GoogleHNM <ref type="bibr" target="#b28">[29]</ref> . The average improvement over the baseline method on 239 classes are statistically significant at p -level of 0.05. As compared to classical methods, such as BatchTrain and Adaboost, the results empirically demonstrate the benefit of the robustness mechanism underlying SPL. Moreover, our improvement over the standard SPL method suggests that incorporating loss prior knowledge into learning yields a significant boost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have provided some new insightful understanding regarding the conventional SPL regime in this study. On one hand, we have shown that the AOS algorithm generally utilized for solving SPL exactly complies with the known MM algorithm on an implicit SPL objective, and on the other hand, we have verified that the loss function contained in this latent SPL objective precisely accords with the famous non-convex regularized penalty (NCRP). The effectiveness, especially its robustness to outliers/heavy noises, of SPL, as substantiated by previous experiences, can then be naturally explained under such understanding. We also analyzed the superiority of SPL on its easy loss-prior-embedding property, which provides a new methodology for alleviating the local-minimum-issue in general NCRP optimization problems. In our future investigation, we will attempt to employ the theories on MM and NCRP to more deeply explore the theoretical/statistical properties underlying the SPL regimes, and try to further extend the SPCL methodology and different loss priors to more application domains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Graphical illustration for implicit SPL losses F Hard λ ( ) , F Linear λ ( ) , and F Mixture λ,γ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Performance comparison of the proposed and baseline methods on FCVID. learn detectors that can automatically recognize concepts occurring in the video content, such as people, objects, actions, etc. The FCVID contains 91,223 YouTube videos (4,232 h) from 239 categories. The class covers a wide range of concepts like activities, objects, scenes, sports, DIY, etc. Each video is manually labeled into one or more categories.</figDesc><table><row><cell>Method</cell><cell>P@5</cell><cell>P@10</cell><cell>mAP</cell></row><row><cell>BatchTrain</cell><cell>0.782</cell><cell>0.763</cell><cell>0.469</cell></row><row><cell>Adaboost [6]</cell><cell>0.211</cell><cell>0.173</cell><cell>0.08</cell></row><row><cell>SPL [15]</cell><cell>0.793</cell><cell>0.754</cell><cell>0.414</cell></row><row><cell>GoogleHNM [29]</cell><cell>0.781</cell><cell>0.757</cell><cell>0.472</cell></row><row><cell>BabyLearning [21]</cell><cell>0.834</cell><cell>0.817</cell><cell>0.496</cell></row><row><cell>Ours</cell><cell>0.889</cell><cell>0.874</cell><cell>0.5329</cell></row><row><cell>goal is to</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by the NSFC projects with No. 61373114 , 61661166011 , 11690011 , and 61603292 , Macau Science and Technology Development Funds with No. 003/2016/AFJ and 973 Program of China with No. 3202013CB329404.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix. Proof of Theorem 1</head><p>To prove the theorem, we need to show that F λ ( ) ≤ F λ ( 0 ) + v * ( 0 , λ)( -0 ) .</p><p>There are two cases required to examine.</p><p>1. v * ( , λ) is continuous with respect to .</p><p>From Eq. ( <ref type="formula">3</ref>) , we know that</p><p>By Definition 1, v * ( , λ) ≥ 0 when ≥ 0, and thus F λ ( ) is nondecreasing with respect to on [0, ∞ ). Moreover, v * ( , λ) is monotonically decreasing with respect to . Therefore, we can conclude that F λ ( ) is concave on [0, ∞ ). Based on the property of a concave function, we obtain the following:</p><p>Without loss of generality, suppose there is only one discontinuous</p><p>) , and then: <ref type="figure">λ</ref>) , and let 1 → ˜ -. Since F λ ( ) is continuous, we can deduce that</p><p>where the second inequality holds because ≤ ˜ and v * ( , λ) ≥ 0 is decreasing with respect to .</p><p>Similarly, if ∈ ( ˜ , ∞ ) and 0 ∈ [0 , ˜ ) , the result also holds. Now we consider the case 0 = ˜ . Suppose ∈ [0 , ˜ ) (derivation is similar for ∈ ( ˜ , ∞ ) ), and choose 1 ∈ [0 , ˜ ) , and then:</p><p>where the second inequality holds because ≤ 0 and v * ( , λ) ≥ 0 is decreasing with respect to .</p><p>From the above discussion, we can conclude that:</p><p>F λ ( ) ≤ F λ ( 0 ) + v * ( 0 , λ)( -0 ) .</p><p>If we substitute and 0 with ( w ) and ( w * ), respectively, then Theorem 1 follows.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Teaching classification boundaries to humans</title>
		<author>
			<persName><forename type="first">S</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of American Association for Artificial Intelligence</title>
		<meeting>eeding of American Association for Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="109" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Confenence on Machine Learning</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Feature selection via concave minimization and support vector machines</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">L</forename><surname>Mangasarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Confenence on Machine Learning</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="82" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enhancing sparsity by reweighted l1 minimization</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Wakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Fourier Anal. Appl</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="877" to="905" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Variable selection via nonconcave penalized likelihood and its oracle properties</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">456</biblScope>
			<biblScope unit="page" from="1348" to="1360" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Stochastic gradient boosting</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="367" to="378" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A general iterative shrinkage and thresholding algorithm for non-convex regularized optimization problems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Confenence on Machine Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="37" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Easy samples first: self-paced reranking for zeroexample multimedia search</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hauptmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>ACM Multimedia</publisher>
			<biblScope unit="page" from="547" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Self-paced learning with diversity</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Z</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hauptman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2078" to="2086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Self-paced curriculum learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hauptman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of American Association for Artificial Intelligence</title>
		<meeting>eeding of American Association for Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2694" to="2700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Exploiting feature and class relationships in video categorization with regularized deep neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
		<idno>ArXiv preprint: 1502.07209</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">On the global convergence of majorization minimization algorithms for nonconvex optimization problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>ArXiv preprint: 1504.07791v2</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">How do humans teach: on curriculum learning and teaching dimension</title>
		<author>
			<persName><forename type="first">F</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1449" to="1457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Self-paced learning for latent variable models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1189" to="1197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning specific-class segmentation from diverse data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Turki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Preston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1800" to="1807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Optimization transfer using surrogate objective functions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Graph. Stat</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Are all training examples equally valuable?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bylinskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<idno>arXiv preprint: 1311.6510</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning the easy things first: self-paced visual category discovery</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1721" to="1728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning to detect concepts from webly-labeled video data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hauptman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1746" to="1752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Towards computational baby learning: a weakly-supervised approach for object detection</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="999" to="1007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Supervised learning with minimal effort</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Knowledge Discovery and Data Mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="476" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Relaxed sparse eigenvalue conditions for sparse estimation via non-convex regularized regression</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="231" to="243" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Baby steps: how &quot;less is more&quot; in unsupervised dependency parsing</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">I</forename><surname>Spitkovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Alshawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop: Grammar Induction, Representation of Language and Language Learning</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Self-paced learning for long-term tracking</title>
		<author>
			<persName><forename type="first">J</forename><surname>Supan Či Č Iii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2379" to="2386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Outlier path: a homotopy algorithm for robust SVM</title>
		<author>
			<persName><forename type="first">S</forename><surname>Suzumura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ogawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Takeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1098" to="1106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<title level="m">Shifting weights: adapting object detectors from image to video</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="638" to="646" />
		</imprint>
	</monogr>
	<note>Conference on Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Parameter convergence for EM and MM algorithms</title>
		<author>
			<persName><forename type="first">F</forename><surname>Vaida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Sin</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="831" to="840" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Efficient large scale video classification</title>
		<author>
			<persName><forename type="first">B</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Toderici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vijayanarasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Natsev</surname></persName>
		</author>
		<idno>ArXiv preprint: 1505.06250</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Nonconvex relaxation approaches to robust matrix recovery</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1764" to="1770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimal computational and statistical rates of convergence for sparse nonconvex learning problems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="2164" to="2201" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Use of the zero-norm with linear models and kernel methods</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elisseeff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tipping</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1439" to="1461" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
		<title level="m">CMU-informedia@TRECVID 2014 multimedia eventdetection (MED), TRECVID Video Retrieval Evaluation Workshop</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Nearly unbiased variable selection under minimax concave penalty</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="894" to="942" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A general theory of concave regularization for high-dimensional sparse estimation problems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Sci</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="576" to="593" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Co-saliency detection via a self-paced multiple-instance learning framework</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="594" to="602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Co-saliency detection via a self-paced multiple-instance learning framework</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2016.2567393</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Analysis of multi-stage convex relaxation for sparse regularization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1081" to="1107" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Nonconvex penalization using laplace exponents and concave conjugates</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="611" to="619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Self-paced learning for matrix factorization</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hauptman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of American Association for Artificial Intelligence</title>
		<meeting>eeding of American Association for Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3196" to="3202" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
