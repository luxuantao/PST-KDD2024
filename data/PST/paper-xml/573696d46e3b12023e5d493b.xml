<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Frame-To-Frame Coherence and the Hidden Surface Computation: Constraints For a Convex World</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="1981-08">August 1981</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Harold</forename><surname>Hubschman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="laboratory">Computer Vision and Graphics Laboratory</orgName>
								<orgName type="institution">McGill University Montreal</orgName>
								<address>
									<region>Quebec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Steven</forename><forename type="middle">W</forename><surname>Zucker</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="laboratory">Computer Vision and Graphics Laboratory</orgName>
								<orgName type="institution">McGill University Montreal</orgName>
								<address>
									<region>Quebec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">J</forename><forename type="middle">C R</forename><surname>Licklider</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="laboratory">Computer Vision and Graphics Laboratory</orgName>
								<orgName type="institution">McGill University Montreal</orgName>
								<address>
									<region>Quebec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Frame-To-Frame Coherence and the Hidden Surface Computation: Constraints For a Convex World</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="1981-08">August 1981</date>
						</imprint>
					</monogr>
					<idno type="MD5">BAE24396AADA5F581C0DB53D12D9D598</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computer Graphics</term>
					<term>Computer Animation</term>
					<term>Visible Surface Algorithms</term>
					<term>Frame-to-Frame Coherence</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Frame-to-frame coherence is the highly structured relationship that exists between successive frames of certain animation sequences.</p><p>From the point of view of the hidden surface computation, this implies that parts of the scene will become visible or invisible in a predictable fashion.</p><p>In this paper the frame-toframe coherence constraints are identified and characterized for static scenes restricted to stationary, closed, convex, nonintersecting polyhedra.</p><p>The animation derives from a continuous movement of the viewer. The mathematical analysis of the constraints is geometric, and leads to a characterization of the selfocclusion relationship over a single polyhedron;</p><p>and to a characterization of the occlusion or change of occlusion relationship over two polyhedra.</p><p>Based on these constraints, an algorithm is presented which generates successive frames in an animation sequence.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>An animation sequence is a series of images sampled from a continuously changing scene, such as the movement of a viewer through a three dimensional world.</p><p>In order to create the perception of continuity, a high temporal sampling rate (e.g., 24 frames per second) should be used; as a result, any image in the sequence is almost identical to its predecessor.</p><p>This continuity is refered to as frame-to-frame coherence;</p><p>i.e., the highly structured relationship that exists between successive frames of certain animation sequences.</p><p>Despite this coherence, however, the only approaches available for producing animation regenerate each image in the sequence directly from the underlying scene model, making no use of the similarity between successive images <ref type="bibr">[i,2,3,~]</ref>. Thelmage Synthesis techniques used in these aoproaches are quite sophisticated, and the resultant animation is extremely realistic.</p><p>However, these techniques are computationally very expensive and the cost of generating, individually, the thousands of frames required for a few minutes of animation often prohibits their use. One way to reduce this cost, while still being able to use realistic image synthesis techniques, is to make use of the frameto-frame coherence during the animation process. Computational effort could be saved if it could be concentrated on those parts Qf the image that change, with little (or no) effort expended on those parts that do not.</p><p>Such isthe goal of the approach that will be investigated in this pape~ -a particular method of incorporating frame-to-frame coherence into the design of hidden surface removal algorithms for computer animation.</p><p>A prior knowledge in the form of image or object coherence has always been used to speed up the hidden surface computation in static graphics ~]. A number of these techniques have been extended to animation as well. This is done by precomputing, into the scene model, certain properties of the scene that are independent of viewing position; for example, the hierarchical modeling techniques of <ref type="bibr">Clark [1]</ref>, and of Rubin and Whitted <ref type="bibr" target="#b3">[4]</ref>, and the binary space partitioning scheme of Fuchs, Kedem and Naylor <ref type="bibr" target="#b1">[2]</ref>. This information is then available at runtime, and need not be recomputed for each image. However since the precomputation oflthis viewpoint independent data is many times more expensive than the computation involved in generating a single image, such an approach is only cost-effective when many images (such as in an animation sequence) are to be produced from the model.</p><p>In other words, after an initial computational investment, the cost of generating an animation sequence can be reduced by regenerating each image more quickly.</p><p>No use is made of frame-to-frame coherence, which, as we attempt to show, can lead to even greater computational savings.</p><p>The type of animation that we consider is an (effectively) continuous movement of a viewer's position with respect to a given static scene. As far as the hidden~surface computation is concerned, frame-to-frame coherence implies that what is visible in one frame will, for the most part, remain visible in the next. And, more importantly, parts of ~e scene cannot become visible (or invisible) in an arbitrary fashion, but are constrained to becoming ~isible in a predictable fashion.</p><p>The main purpose of this paper is an identification and a characterization of the frame-to-frame coherence constraints within a restricted universe, and their subsequent use in a hidden surface algorithm. The universe consists entirely of stationary, closed, convex, nonintersecting polyhedra made up of convex, opaque, polygonal surface elements. There will be no relative motion of polyhedra in the scene;</p><p>that is, their relative positions will remain fixed.</p><p>The only motion will be due to movement of the viewer's position.</p><p>This restricted universe permits a clear characterization of the frame-to-frame coherence constraints.</p><p>The mathematical analysis is geometric, and leads to two types of constraint: (i) those pertaining to the self-occlusion or change of self-occlusion relationship over a single polyhedron; and (ii) those pertaining to the occlusion or change of occlusion relationship over two polyhedra.</p><p>A particular partioning of the scene is developed, with the property that a movement of the viewing position across partition boundaries results in either (i) a change in self-occlusion of a single polyhedron;</p><p>(ii) a change in the occlusion of one polyhedron with respect to another ; or (iii) both.</p><p>An encoding of these change of occlusion constraints into the scene data structure is then described which makes these otherwise implicit partition corssings explicit. Using this, it is possible to directly determine, for an incremental change in the viewing position, which polygons have become visible or invisible.</p><p>Based on these constraints, an algorithm is presented that generates a frame in an animation sequence.</p><p>It starts from a description of what was visible in the previous frame, and incrementally updates it to contain only what is visible in the current frame. The updating algorithm uses a list of visible or partly visible polygons, and either deletes polygons that have become invisible, or inserts polygons that have become visible.</p><p>Polygons that are neither appended to nor deleted from this list are never examined.</p><p>In short, space, or the explicit representation of the constraint information for a particular scene, is traded against the time that is required for more traditional hidden surface algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Frame-To-Frame Coherence</head><p>Any polygon in a scene of closed convex poly-hedra will either be visible or invisible from a particular viewing position, and the visible polygons will be either completely or partly visible. These states define what we shall refer to as the visibility status of a polygon.</p><p>In the case of a partly visible polygon, the visibility status also includes a description of which parts are visible. (A partly visible polygon is described by the edges of its visible sub-polygons.)</p><p>The hidden surface problem thus becomes one of determining: <ref type="bibr">(i)</ref> the visibility status of polygons in the scene for a particular viewing position; and</p><p>(ii) the change in visibliity status of polygons from one frame to the next due to an incremental change in the viewing position.</p><p>Consequently, the constraints that we wish to identify are those that pertain to the visibility status, or change in visibility status, of polygons in the scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Static Constraints</head><p>The first two constraints refer to static properties of the scene, in the sense that they are relevant to the computation of the visibility status of the polygons in the scene for a single frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Constraint i: Self Occlusion of a Single Polyhedron</head><p>Silhouette edges are defined as those edges on the polyhedron at which two polygons meet, provided one polygon is forward facing (towards the viewer) and the other is back facing (away from the viewer; i.e., made invisible by the polyhedron itself.) Constraint 1 is that the visibility status of polygons comprising closed convex polyhedra changes only across silhoue£te edges.</p><p>In other words, the silhouette edges of such a polyhedron form a boundary on the polyhedral surface, dividing it into two connected sub-surfaces.</p><p>In one sub-surface, all the surface elements are visible, while, in the other sub-surface, all the surface elements are invisible. This constraint provides the basis for our frame-toframe coherence approach.</p><p>We will show that the computation necessary to go from one frame's description to the next will involve considering only the visible silhouette edges, net the entire scene data base.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.">Constraint 2: Occlusion of Two Polyhedra</head><p>In the case of occlusion of two polyhedra, the visibility status of a polygon on the occluded polyhedron changes:</p><p>(i) across one of its visible silhouette edges; or (ii) across the projection of a visible segment of the silhouette edge of the occluding polyhedron onto the occluded polyhedral surface. This is illustrated in Figure <ref type="figure">2</ref>.1. (An edge is said to project onto a polygon (or polyhedron) when the projection of the polygon (or polyhedron) onto the viewing screen is intersected by the projection of the edge onto the viewing screen.</p><p>The edge may either be occluded by the polyhedron or be in front of the polyhedron.) This leads to the second constraint: that the visible portion of the surface of a closed convex polyhedron is contained inside a closed boundary composed of: (i) its own visible silhouette edges; and</p><p>(ii) the projection of visible silhouette edges of the occluding polyhedra onto its surface.</p><p>The visibility status of polygons comprising polyhedra can only change when we cross such a boundary. This type of boundary will be refered to as a visible-area boundary, because it defines an area of a polyhedral surface which is visible in a particular frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Dynamic Constraints</head><p>The remaining constraints deal with the dynamic properties of the animation process.</p><p>These describe the kinds of changes that can occur in the visibility status of the polygons in the scene when going from one frame to the next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Constraint 3: Change in Polyhedron Selfocclusion</head><p>From a viewer's frame of reference, his motion with respect to a polyhedron manifests itself as a rotation of the polyhedron.</p><p>This rotation causes some of the polygonal surfaces to rotate into view and others to rotate out of view. The third constraint is that those polygons whose visibility status changes in this way will all be contained inside a boundary composed entirely of old and new silhouette edges of the polyhedron. This is illustrated in Figure <ref type="figure">2</ref>.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Constraint 4: Incremental Change in Active</head><p>Occlusion Relationships For configurations involving more t/tan one polyhedron the motion of the viewer causes him to see one polyhedron uncovering (or covering) polygons on another, in addition to the percieved rotation of the individual polyhedra.</p><p>In particular, polygons become uncovered (or covered) as the occluding polyhedron's silhouette sweeps over them. The fourth constraint is that those polygons on the occluded polyhedron that have undergone a change in visibility status as a result of the motion of the viewer are contained inside a closed boundary on the occluded polyhedral surface.</p><p>This boundary is composed of (i) the projection of the occluding polyhedron's silhouette onto the occluded polyhedron, as seen from the initial viewing position;</p><p>(ii) the projection of the occluding polyhedron's silhouette onto the occluded polyhedron, as seen from the final viewing position; and (iii) the silhouette edges of the occluded polyhedron that have become uncovered (or covered) as a result of the viewers motion.</p><p>An example is shown in Figure <ref type="figure">2</ref>.3. Such a boundary, as well as the boundary for constraint 3, will be refered to as a "change of visibility status boundary", or as a "change boundary".</p><p>In short, the projection of the occluding polyhedron's silhouette onto the surface of the occluded polyhedron is useful information.</p><p>It will be refered to as the Occlusion relationship between the two polyhedra.</p><p>An occlusion relationship not only indicates that one polyhedron occludes the other, but gives an exact description of how the viewer sees the occlusion.</p><p>An active occlusion relationship refers to a situation in which one polyhedron partially obscures another, but in which both are visible.</p><p>(This is to be contrasted with one polyhedron being completely hidden behind another.) Constraints 4 and 5 characterize the possible changes in active occlusion relationships from one frame to the next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3.">Constraint 5: Creation of Active Occlusion Relationships</head><p>In the previous constraint, the visibility status of polygons changed as a result of an incremental change in the active occlusion relationship between two polyhedra.</p><p>Another, more extreme possibility is that the change in viewing position causes an occlusion relationship to become active from a configuration in which there was none, or vice versa.</p><p>This corresponds to the case of the silhouette of one polyhedron projecting onto another polyhedron in one frame, while in the previous frame it did not, or vice versa.</p><p>There exists a partitioning of the scene with the property that a movement of the viewing position across a partition boundary results in an occlusion relationship becoming active or inactive. Consider Figure <ref type="figure">2</ref>.4. This is a cross sectional view of two polyhedra.</p><p>AS long as the viewing position is in r~gion A, polyhedron 2 is completely invisible.</p><p>If the viewing position crosses line L1 into region B, then polyhedron 2 becomes ~isible, and the~occlusion relationship between polyhedron 1 and 2 becomes active.</p><p>Altogether there are four such possibilities, and these define our fifth constraint: <ref type="bibr">(i)</ref> Crossing line L1 from region A into region B causes initially invisible polyhedron 2 to become partly visible, and causes the occlusion relationship between the two polyhedra to become active.</p><p>(ii) The sylr~etric case of moving from region B into A causes polyhedron 2 to disappear, and caused the previously active occlusion relationship to become inactive. An example of these two possibilities is shown in Figure <ref type="figure">2</ref>.5.</p><p>(iii) Crossing line L2 from region C into B causes polyhedron 1 to begin occluding polyhedron 2.</p><p>The occlusion relationship between the two polyhedra becomes active.</p><p>(iv) The reverse case of moving from region B into C causes polyhedron 2 to become completely unoccluded and visible.</p><p>The occlusion relationship between the two polyhedra becomes inactive.</p><p>An example of these possibilities is shown in Figure <ref type="figure">2</ref>.6.</p><p>The importance of such a partitioning is that it indicates when a silhouette edgebegins to project onto a particular polyhedron, and when it no longer projects onto that polyhedron.</p><p>For example, in case 1 of Figure <ref type="figure">2</ref>.5, the movement of the viewing position causes edge XY to begin projecting onto polyhedron 2. The reverse movement causes edge XY to stop projecting onto polyhedron 2. The same holds for edge UV in Figure <ref type="figure">2</ref>.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.__~3Representation of Occlusion Relationships</head><p>In order to find those polygons whose visibility status has changed, it is necessary to con~ struct the change of visibility status boundaries on each of the visible or previously visible polyhedral surfaces.</p><p>This requires that we compute the projection of each visible silhouette edge onto the polyhedron which it occludes.</p><p>For an incremental change in an active occlusion relationship, the current projection of a silhouette edge onto a polyhedron can be computed as an incremental change from the previous projection of that edge onto the polyhedron.</p><p>In the case of an occlusion relationship only just becoming active, there is no such reference for the projection computation.</p><p>However, an occlusion relationship becomes active or inactive when the viewing position crosses one of the scene partition boundaries.</p><p>A method will now be presented for determining <ref type="bibr">(i)</ref> when the viewing position crosses one of the scene partition boundaries; and (ii) for which silhouette-edge/polyhedron pair the occlusion relationship is becoming active or inactive.</p><p>This'method involves encoding the change of occlusion constraints into the scene data structure. To describe the encoding scheme, it is first necessary to define two geometric constructs: the viewing ray plane of a silhouette edge, and the support planes of a convex polyhedron.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1.">Viewin 9 Ray Plane of a Silhouette Edge</head><p>The viewing ray plane of a silhouette edge is the plane defined by the silhouette edge and the viewing position.</p><p>The importance of this construct is that the perspective projection of a silhouette edge onto a polyhedron is the contour on the polyhedral surface defined by the intersection of the viewing ray plane of the silhouette edge with the polyhedron. This is illustrated in Figure <ref type="figure">2</ref>.7. The term "viewing ray plane" comes from the fact that the viewing rays which trace out the perspective projection of the silhouette edge onto the polyhedral surface must lie in this plane.</p><p>An important property of the viewing ray plane is its parameterization.</p><p>A line defines a family of planes which can be generated by rotating a plane through 360 degrees about an axis lying along the line. Using some fixed plane in this family as a reference, any plane in the family can be parameterized by its angle of rotation from the reference plan.</p><p>Since the silhouette edges are fixed to their respective polygons, a natural choice of reference plane for the viewing ray plane is the plane of one of the two polygons containing the silhouette edge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3.">support Planes</head><p>Given a convex polyhedron and a line not intersecting the convex polyhedron, the support planes of the polyhedron are defined as the two planes, from the family of planes defined by the given line, which are tangent to the polyhedron.</p><p>By tangent we mean that the plane can touch the polyhedron at a point, a line or at most a plane, but not intersect the polyhedron. This is shown in Figure <ref type="figure">2</ref>.8, which is a cross sectional view. P is the line defining the support planes, shown here perpendicular to the page.</p><p>L1 and L2 are the support planes of the polyhedron.</p><p>(This concept was motivated by a similar concept in the ~ield of Computational C~omet~_r, the supporting line of a convex hull <ref type="bibr" target="#b4">[5]</ref>.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3.">Change of Occlusion Description</head><p>The partition boundaries across which the viewing position must pass in order for the occlusion relationship between a silhouette edge and a polyhedron to become active (or inactive) are precisely the support planes of the polyhedron that are defined by the silhouette edge.</p><p>It is thus possible to encode the partition boundaries directly into the description of the silhouette edge. A support plane is represented by its angle parameter, defined relative to the same reference plane used to compute the angle of the viewing-ray-plane of the silhouette edge.</p><p>In order to determine that the occlusion relationship has become active or inactive, it is only necessary to compare the angle of the viewing ray plane of the silhouette edge for the previous viewing position against the angle for the current viewing position.</p><p>If a support plane angle lies between the previous and the current viewing-ray-plane angles, then the viewing position has crossed the partition boundary and the occlusion relationship has changed. This is illustrated in Figu/e 2.8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Hidden Surface Updating Algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Introduction</head><p>The central idea of frame-to-frame coherence is that by keeping a description of what is visible in the current frame, the next frame in the animation sequence can be generated by incrementally updating this description.</p><p>We will now indicate one description of the visible structure of a frame that is sufficient for characterizing certain frame-to-frame coherence constraints, as will be demonstrated by an algorithm for doing the hidden surface updating computation.</p><p>Given a particular viewing position, the polygons in the scene can be classified as invisible, partly visible or completely visible.</p><p>The visible structure of a frame is described in terms of a list of visible or partly visible polygons.</p><p>If a polygon is completely visible, then its own edges are sufficient to describe it. For a partly visible polygon, the visible parts are themselves bounded by polygons, in general non convex.</p><p>It is sufficient to describe a partly visible polygon by specifying the edges of its visible sub-polygons. These edges correspond either to segments of the polygons own edges, or to the intersection of the polyhedron by edges of a visible area boundary. This is illustrated in Figures 3.1 and 3.2. An image can then be produced by scan converting the visible polygons or sub-polygons in the list.</p><p>The updating algorithm must do two things. Given, at the start of the frame computation, a list of the visible or partly visible polygons of the previous frame, it is necessary to: (a) find those polygons in the list which have become invisible and remove them, or those polygons not in the list which have become visible (or partly visible) and insert them; and (b) compute, for the partly visible polygons, the visible sub-polygon edges.</p><p>We have seen that the area of a polyhedral surface which has just become visible or invisible is contained inside a closed boundary on the polyhedral surface, refered to as a change boundary. The change boundary is composed of segments of the polyhedron's own silhouette edges, from both the current and the previous frames; and of segments of the occluding silhouette edges that project onto the surface in the current and previous frames. The polygons comprising this area are the ones that have undergone a change in visiblility status (constraints 3 and 4). It is precisely these polygons that we wish to identify in step (a) above.</p><p>There are three stages to the hidden surface updating algorithm: <ref type="bibr">(i)</ref> Construct the visible area boundaries on all the visible polyhedra in the scene (constraints 1 and 2).</p><p>(ii) Using the above visible area boundaries, compute the visible sub-polygon edges of the partly visible polygons.</p><p>(iii) Using the visible area boundaries from both the current and the previous frames, identify the polygons contained within the change boundaries (constraints 3 and 4) on all of the currently and previously visible polyhedra in the scene. These polygons are then inserted into, or removed from, the visible polygon list, depending on the change in visibility status that the particular polygon has undergone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Polyhedron Representation</head><p>Each polyhedron in the scene is represented by a graph, which will be refered to as the polyhedron graph. A node in the polyhedron graph corresponds to one of the geometric primatives that make up the polyhedron.</p><p>There are three types of nodes in a polyhedron graph, one for each type of geometric primative (vertex, edge, or polygon) in the polyhedron.</p><p>Arcs between nodes in this graph indicate structural relationships between the geometric primatives represented by the nodes.</p><p>An edge points to its two vertices, and to the two polygons which define it. A vertex points to each of the edges emanating from it. A polygon points to each of the edges that make up its boundary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Initializing the Scene Partitions</head><p>We have seen, in section 2.3.3, that the partition boundaries across which the viewing position must pass in order for the occlusion relationship between a silhouette edge and a polyhedron to become active are the support planes of the polyhedron that are defined by the silhouette edge. It is important to note that an active occlusion relationship between a silhouette edge and a polyhedron is symmetric; it refers to the occlusion of the edge by the polyhedron, as well as the opposite.</p><p>The initialization of the scene partitions involves computing the support planes of each edge in the scene with respect to each polyhedron in the scene. However, only the support which do not intersect the polyhedron containing the edge are stored.</p><p>The following information is comPuted for each support plane that will be stored:</p><formula xml:id="formula_0">(i) (ii) (iii)</formula><p>The angle of the support plane relative to the reference plane used to compute the angles of the viewing ray plane of the silhouette edge CSection 2.3.1).</p><p>A pointer to the vertex of the supported polyhedron where the support plane is tangent.</p><p>A flag indicating whether the supported polyhedron is occluding the edge or is occluded by the edge, provided that the polygon relative to which the support plane angle has been computed is forward facing.</p><p>The support planes defined by a particular edge are stored in a list associated with that edge.</p><p>The list is ordered according to increasing angle value (field (i) ). By encoding the partition boundaries directly into the edge description, there is enough information associated with each silhouette edge to compute which parts of the silhouette edge are visible, and which polyhedron is occluded by each visible segment, without an exhaustive comparison against the entire scene database.</p><p>In other words, the constraint information (i.e., the partitions) is distributed directly to those parts of the scene model (i.e., the polyhedron edges) where it is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Representation and Updatin 9 of an Occlusion Relationship</head><p>An occlusion relationship between a silhouette edge and a polyhedron describes the projection of the silhouette edge onto the polyhedral surface. Recall that the perspective projection of a silhouette edge onto a polyhedron is the contour on the polyhedral surface defined by the intersection of the viewing ray plane of the silhouette edge with the polyhedron (Section 2.3.1). This is described by the two silhouette edges of the polyhedron that are intersected by the viewing ray plane of the projected silhouette edge, and by the points along the infinite line, (defined as the extension of the projected silhouette edge), that project onto the intersected silhouette of the polyhedron. This is illustrated in Figure <ref type="figure">3</ref>.3 The projection of edge P0-PI is described by the intersection of silhouette edges XY and UV, and by points TO and TI, which project onto XY and UV respectively. The Utility of this description is that it indicates precisely which part of the silhouette edge projects onto the polyhedron (for example, segment T0-PI in Figure <ref type="figure">3</ref>.3).</p><p>In the event that the silhouette edge is occluded by the polyhedron, this allows the visible segments of the edge to be inexpensively computed.</p><p>One of the reasons that the two silhouette edges intersected by the viewing ray plane are kept as part of the description of the occlusion relationship is to facilitate the updating of the occlusion relationship from one frame to the next (constraint 4). Because of the incremental change in viewing position, the new viewing ray plane will usually intersect the same silhouette edges as the previous viewing ray plane.</p><p>If it does not, the intersected silhouette edge will be close to the previously intersected silhouette edge. By using the previously intersected silhouette edge as a starting node, and examining the edges in the polyhedron graph in the visinity of this node, and examining the edges in the polyhedron gral~h in the vicinity of this node, the currently intersected silhouette edge can be found directly, without examining all of the edges of the polyhedron.</p><p>In similar fashion, the vertex where a computed support plane is tangent (fiels (ii), Section 3.3) is used as a starting node in the initialization of the occlusion relationship that becomes active when the viewing position crosses that support plane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Input to the Algorithm</head><p>The inputs to the algorithm, prior to processing a frame, are: <ref type="bibr">(i)</ref> The list of visible polygons in the previous frame.</p><p>(ii) A list of all the silhouette edges visible in the previous frame. Associated with each silhouette edge is a list of the edge's active occlusion relationships of the previous frame.</p><p>(iii) The visible area boundaries of the previous frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">The Hidden Surface Updating Algorithm</head><p>Stage One: Computing the visible area boundaries. The visible area boundary on a particular polyhedral surface is composed of visible segments of the polyhedron's own silhouette edges; and of the projection onto the polyhedral surface of visible silhouette edges of occluding polyhedra (constraints 1 and 2). Therefore it is only necessary to consider silhouette edges visible in the current frame. Most of these will already be in the visible silhouette edge list of the previous frame.</p><p>Those silhouette edges not yet in the list can be located directly, by making use of the fact that the edges of the visible area boundary are connected.</p><p>In this way it will not be necessary to exhaustively examine every edge in the scene database; rather the algorithm will start the updating of frame by considering only those edges in the visible silhouette edge list of the previous frame. Whenever a new visible silhouette edge is located, it will be appended to the silhouette edge list.</p><p>The following five steps are executed for each list, including those edges which are inserted into the list during the current frame computation: (i) Check if the edge is still a silhouette edge, that is , check to see that, of the two polygons that define the edge, one is forward facing and the other is backfacing.</p><p>If the edge is no longer a silhouette edge, remove it from the list and go on to the next edge.</p><p>(ii) Compute the new viewing ray plane for the silhouette edge. Find those support planes, in the edge's list of stored support planes, that lie between the current and the previous viewing ray planes.</p><p>These correspond to occlusion relationships that have just become active or inactive. Initiallize the newly active occlusion relationships (Section 3.4).</p><p>Remove those that have become inactive from the silhouette edge's list of occlusion relationships.</p><p>(iii) Update the occlusion relationships that have remained active since the previous frame.</p><p>For example, in Figure <ref type="figure">3</ref>.1, edge CE has two active occlusion relationships, one with polyhedron 1 (segment CD projects onto polyhedron i) and one with polyhedron 3 (segment CB projects onto polyhedron 3).</p><p>(iv) Determine which segments of the silhouette edge are visible and which are invisible.</p><p>The invisible segments of the silhouette edge are those which project onto polyhedra that occlude the silhouette edge.</p><p>If the silhouette edge is completely invisible, remove it from the silhouette edge list. Determine, for each visible segment, which polyhedron the segment projects onto.</p><p>If a visible segment projects onto more than one polyhedron, break the segment up into smaller segments such that each smaller segment projects onto only one polyhedron. In the case where this is not possible, because the projections onto two polyhedra overlap, the polyhedron closest to the edge is chosen.</p><p>For example, silhouette edge CE in Figure <ref type="figure">3</ref>.1 is divided into two segments.</p><p>One is segment BD which projects onto polyhedron i, and the other is segment BC which projects onto both polyhedra 1 and 3. Polyhedron 3 is chosen for segment BC because it is the closer one.</p><p>For a particular polyhedron, the visible segments of its own silhouette edges and the visible silhouette edge segments which have been chosen to project onto it constitute the edges of the polyhedrons visible area boundary.</p><p>For polyhedron i, the boundary segments are AH, AB, BD which project onto it, and GH, GF, FD from its own silhouette edges.</p><p>(v) Link up the individual boundary segments, computed in step (iv) above, into their respective visible area boundaries.</p><p>A visible area boundary edge is a segment of a silhouette edge.</p><p>The end point of a segment occurs for one of two reasons: <ref type="bibr">(i)</ref> The silhouette edge end point is visible. For example, in Figure <ref type="figure">3</ref>.4, point H is the end point of segment GH.</p><p>(ii) Two silhouette edges intersect.</p><p>For example, end point B of segment BC results from the intersection of silhouette edge KC with silhouette edge AH.</p><p>In each of these two cases, we have a pointer to the silhouette edge containing the neighbouring boundary segment.</p><p>In case <ref type="bibr">(i)</ref>, the neighbouring boundary segment to GH, connected at point H, is on silhouette edge HI. We can find this silhouette edge by scanning the list of edges emanating from vertex H (Section 4.3.1.3).</p><p>In case (ii), the neighbouring boundary segment to BC, at point B, is segment AB on silhouette edge AH.</p><p>Silhouette edge AH is one of the two silhouette edges of polyhedron 3 which is intersected by the viewing ray plane of silhouette edge KC.</p><p>(The other silhouette edge is AI; the intersection point is L). Pointers to these two silhouette edges were computed in step (iii).</p><p>The above method of linking boundary segments also solves the problem of finding new silhouette edge list, a flag is set on the edge's descriptor, indicating that the edge is a silhouette edge.</p><p>In the above linking process, when the silhouette edge that contains the neighbouring boundary segment is found, a check is first made to determine if it is already in the silhouette edge list.</p><p>If it is not, it is appended to the list.</p><p>In this way, all of the new silhouette edges of a parhicular boundary can be generated, starting from only one old silhouette edge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage two:</head><p>Compute the edges of the visible sub-polygons of each partly visible polygon.</p><p>The partly visible polygons are precisely those polygons across which a boundary edge lies (Figure <ref type="figure">3</ref>.2, boundary edge BD). This type of boundary edge results from the projection o~ an occludin~ silhouette edge segment Onto the polyhedral surface containing the partly visible polygons (constraint 2). For each occluding silhouette edge segment, that polyhedron which the segment occludes was determined in step (iv) above.</p><p>Using this, the subsegments which intersect individual polygons can be computed.</p><p>For example, in Figure <ref type="figure">3</ref>.2, silhouette edge segment BD occludes polyhedron i, and intersects polygons 1 and 2. The subsegment which intersects polygon 1 is DX, and the subsegment which intersects polygons 2 is XB. The projection of such subsegments onto the polygon which they occlude, together with the visible segments of the polygon's own edges, form the edges of the visible sub-polygons of that polygon.</p><p>The visible area boundaries were linked together in order to speed up this computation.</p><p>Using this linked boundary, together with the structural information in the polyhedron graph, the polygons on the polyhedral surface intersected by a particular visible area boundary segment can be directly computed.</p><p>Consider the visible area boundary on polyhedron 3, in Figure <ref type="figure">3</ref>.5. Boundary segment BC is part of silhouette edge BN.</p><p>In Stage One, the intersection of silhouette edge KL by the viewing ray plane of edge BN was computed.</p><p>Using KL as a starting point, it is found that polygon P1 is intersected by the viewing ray plane of edge BN, as is edge OQ. From the structure of the polyhedron graph, it is known that the polygon sharing edge OQ is polygon P2. This is continued until the polygons intersected by segment BC are encountered. Once this occurs, the visible area boundary is traversed, and for each boundary segment, the intersections of the segment with the polygons that the segment crosses is computed and stored on the polygon node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage Three:</head><p>Updating the visible polygon list. At this point in the algorithm, enough information has been computed to scan convert the visible and the partly visible polygons.</p><p>The final stage of the algorithm involves identifying the polygons contained inside the change boundaries on the currently and previously visible polyhedra, and either appending them to, or removing them from, the visible polygon list, depending on the change in visibility status that the particular polygon has undergone.</p><p>The first case to consider is that of a change boundary resulting from the incremental change in the active occlusion of two polyhedra. Consider Figure <ref type="figure">3</ref>.6, which represents two consecutive frames in an animation sequence.</p><p>Edge A'B' is the projection of edge AB for the viewing position of the previous frame. The motion of the viewer, shown by the arrow, has caused the polygons inside the solid boundary (the change boundary) to become visible.</p><p>In Stage Two, the algorithm determined that boundary .segment VY intersected edge PQ on polyhedron 2. Consequently, one of the two vertices of edge PQ must lie inside the change boundary on polyhedron 2. By comparing these two vertices against edges AB and A'B', vertex P is found to be the one inside the change boundary, since it is the one that lies between the two edges. Since vertex P is "above" the viewing ray plane of silhouette edge AB, it is currently visible, and has therefore undergone a transition from invisible to visible.</p><p>("AbOve" is defined as in the direction of the normal to the viewing ray plane.</p><p>The normal is chosen such that when the viewing ray plane is parallel to the polygon used as the reference, their normals are parallel.</p><p>The normal to the reference polygon points out of the polyhedron.)</p><p>Consequently the contents of this change boundary are all visible polygons, and must be inserted into the visible polygon list, (if they are not already there).</p><p>The polygons contained inside the change boundary are identified by traversing the subgraph contained inside the change boundary, starting from vertex P. The traversal of the subgraph terminates when either (i) a polyhedron edge is encountered that has been intersected by a visible area boundary segment in the current or previous frame (this information is encoded into the edge nodes of the polyhedron), or (ii) a silhouette edge of the current or previous frame is encountered.</p><p>The other case to consider is that of the change boundary resulting from the change in polyhedron self occlusion.</p><p>The same method that is described above can be used to traverse the subgraph contained inside the change boundary.</p><p>However in this case the initial vertex is chosen in a different fashion.</p><p>Starting from a new silhouette edge the polygon defined by this edge that has undergone a change in visibility status as a result of the viewers motion is determined.</p><p>Using one of the non silhouette edge vertices of this polygon as a starting point, the sub-graph defined by the change boundary is traversed, and the polygons contained therein are inserted into the visible polygon list. These two methods are used to identify the contents of all of the change boundaries as well as to determine the change in visibility status undergone by the polygons contained therein.</p><p>After this has been completed for all of the change boundaries, the contents of the visible polygon list can be scan converted to produce the final image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.__~7. Computin~he First Frame of The Animation Sequence</head><p>At the beginning of the computation of the first frame of the animation sequence, both the visible silhouette edge list and the visible polygon list are empty.</p><p>The initialization of the first frame involves examining every edge in the scene data structure, and inserting every silhouette edge into the silhouette edge list. Once this has been done, the updating algorithm can be used to compute the first frame.</p><p>In Stage One, the silhouette edges that are invisible will be identified and removed from the list. From the visible silhouette edges, the visible area boundaries are then constructed. In Stage Three, all of the polygons visible in the first frame can be identified, by traversing the sub-graph contained inside the visible area boundary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Extension to More Complex Scene Domains m</head><p>An obvious question still to be answered is how to make use of the current frame-to-frame coherence techniques for objects which are more complicated than closed convex polyhedral surfaces. In order of increasing structural complexity there are:</p><p>(i) Convex polyhedral surfaces with holes in them.</p><p>(ii) Closed non-convex polyhedral surfaces (that is, surfaces that have no holes in them).</p><p>(iii) Non-convex polyhedral surfaces with holes in them.</p><p>In the above cases, the visibility status of polygons can change not only across the projection of silhouette edges, but also across the projection of edges which lie along the rim of holes in the surfaces.</p><p>Also, the problem of self occlusion for a non-convex polyhedral surface is considerably more complicated.</p><p>Due to the concavity of the polyhedral surfaces, silhouette edges can project onto their own polyhedra; and determining when silhouette edges become visible or invisible is not as simple as in the convex polyhedron case.</p><p>It is necessary to identify the constraints which pertain to these cases.</p><p>Another question is how to deal with higher order curved surfaces.</p><p>While the same types of constraints as are defined in Chapter 3 hold for entities such as spheres or toruses (since the constraints stem in part from the properties of the perspective projection, which remain the same for all types of surfaces), these constraints cannot be encoded into the scene database in the same manner. For polyhedra, the constraints are encoded into the description of each edge, and become active when the edge becomes a silhouette edge. For curved surfaces, a silhouette edge is not a static property of the surface element.</p><p>Rather, it is a contour on the surface which is determined after the viewing position is specified.</p><p>It is therefore necessary to find another way of encoding the constraint information into the description of the surface elements.</p><p>Finally, there is the question of how to handle a non-stationary scene (a scene in which objects are allowed to move).</p><p>The same types of constraints as for the stationary case hold for the non stationary case. However, the constraint information is no longer static, since the relative positions of the polyhedra are allowed to change.</p><p>One possibility is to make the region partitions (Section 3.2.2.3) dynamic, and update them for the parts of the scene which move. The continuity in time underlying the animation process requires that the change in the scene partition structure from one frame to the next be very small. Consequently, the computation involved in updating the partition structure might be sufficiently inexpensive to make this approach feasable for non-stationary scenes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Summary</head><p>We have shown how frame-to-frame coherence can be used to solve a hidden surface problem for threedimensional computer animation.</p><p>The notion of "visibility status" of a surface element has been introduced, and the hidden surface problem has been approached from the point of view of determining how the visibility status of surface elements can change from one frame to the next. The constraints which govern the change in visibility status have been identified and characterized within a restricted universe.</p><p>An algorithm for generating an animation sequence has been presented, which uses the constraints to focus the computation on only those parts of the scene where there is a change.</p><p>If the constraints governing changes in visibility status can be deterrmined, and these constraints can be incorporated into a hidden surface algorithm, then frame-to-frame coherence could be used for more general scene domains as well.         </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 . 1</head><label>21</label><figDesc>Figure 2.1 Occlusion of two polyhedra. The heavily drawn contour represents the visible area boundary of polyhedron 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 . 2</head><label>22</label><figDesc>Figure 2.2 Change in polyhedron self occlusion. The heavily dashed line and the heavy solid line represent part of the polyhedron silhouette as seen from the initial and final viewing posi ~ tions respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3 Figure 2 . 3 Frame b y 2 Figure 2 Figure 2 . 5</head><label>3232225</label><figDesc>Figure 2.3 Incremental change in an active occlusion relationship.The heavily dashed line and the heavy solid line represent the silhouette of polyhedron 1 from the initial and final viewing positions respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 . 6</head><label>26</label><figDesc>Figure 2.6 Creation of an active occlusion relationship.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 . 7</head><label>27</label><figDesc>Figure 2.7 The viewing ray plane of edge P, for viewing position A. The projection of edge P onto the polyhedro n is heavily outlined.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 . 8</head><label>28</label><figDesc>Figure 2.8 The support planes of polyhedron i, defined by silhouette edge P. tl and t2 are the angles of L1 and L2, relative to polygon SI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 . 2</head><label>32</label><figDesc>Figure 3.1 hedron i. The visible area boundary of poly-Figure 3.2 Partly visible polygons are those across which a visible area boundary segment lies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 . 3 Figure 3 . 5</head><label>3335</label><figDesc>Figure 3.3 Description of an active occlusion relationship.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 . 4 BFigure 3 . 6</head><label>3436</label><figDesc>Figure 3.4 Linking the visible area boundary segments together. B"</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledjment:</head><p>We would like to thank John L. Mohammed for his many helpful discussions and suggestions;</p><p>and Cem Jak Eskenazi for his assistance in drawing the diagrams.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Hierarchical Geometric Models for Visible Surface Algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CACM</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">547</biblScope>
			<date type="published" when="1975-10">October 1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On Visible Surface Generation by A Priori Tree Structures</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kedem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Naylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">124</biblScope>
			<date type="published" when="1980-07">July 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A New Approach to the Hidden Line Problem</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Journal</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">232</biblScope>
			<date type="published" when="1971-08">August 1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Three-Dimensional Representation for Fast Rendering of Complex Scenes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Whitted</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">0</biblScope>
			<date type="published" when="1980-07">July 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Computational Geometry</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shamos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978">1978</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science, Yale University</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Characterization of Ten Hidden Surface Algorithms</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">E</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Sproull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Shumacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">p. i</biblScope>
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
