<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SMOOTHING AND FIRST ORDER METHODS: A UNIFIED FRAMEWORK *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012-06-05">June 5, 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Beck</forename><surname>Amir</surname></persName>
							<email>becka@ie.technion.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial Engineering and Management</orgName>
								<address>
									<postCode>32000</postCode>
									<settlement>Technion, Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marc</forename><surname>Teboulle</surname></persName>
							<email>teboulle@post.tau.ac.il</email>
							<affiliation key="aff1">
								<orgName type="department">School of Mathematical Sciences</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
								<address>
									<postCode>69978</postCode>
									<settlement>Tel Aviv</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SMOOTHING AND FIRST ORDER METHODS: A UNIFIED FRAMEWORK *</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2012-06-05">June 5, 2012</date>
						</imprint>
					</monogr>
					<idno type="MD5">F5AF60FD0F388476A13835F4F646CE6E</idno>
					<idno type="DOI">10.1137/100818327</idno>
					<note type="submission">Received by the editors December 15, 2010; accepted for publication (in revised form) February 22, 2012;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>nonsmooth convex minimization</term>
					<term>smoothing methods</term>
					<term>convex minimization</term>
					<term>first order proximal gradients</term>
					<term>rate of convergence</term>
					<term>infimal convolution</term>
					<term>asymptotic functions AMS subject classifications. 90C25</term>
					<term>90C30</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a unifying framework that combines smoothing approximation with fast first order algorithms for solving nonsmooth convex minimization problems. We prove that independently of the structure of the convex nonsmooth function involved, and of the given fast first order iterative scheme, it is always possible to improve the complexity rate and reach an O(ε -1 ) efficiency estimate by solving an adequately smoothed approximation counterpart. Our approach relies on the combination of the notion of smoothable functions that we introduce with a natural extension of the Moreau-infimal convolution technique along with its connection to the smoothing mechanism via asymptotic functions. This allows for clarification and unification of several issues on the design, analysis, and potential applications of smoothing methods when combined with fast first order algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction.</head><p>A well-known methodology for designing solution techniques to nonsmooth optimization (NSO) problems is to replace the original problem by a sequence of approximating smooth problems, which hopefully can be solved more efficiently than by using direct and classical schemes such as subgradient and bundle type methods <ref type="bibr" target="#b21">[21]</ref>. The basic idea is to transform the nondifferentiable problem into a smooth problem. Many researchers have proposed different smoothing approaches to various classes of NSO problems. Some earlier works on the subject can be found, for example, in <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b10">10]</ref>, and for a more recent account, see, for instance, <ref type="bibr" target="#b2">[3]</ref> and references therein.</p><p>This work is motivated by a paper of Nesterov <ref type="bibr" target="#b17">[17]</ref>, where a new method for minimizing a nonsmooth convex function over a convex compact finite-dimensional set is proposed. The characteristic feature of Nesterov's method is that for a special class of nonsmooth convex functions which are given as specific "max" type functions (see section 4), adopting the smoothing methodology combined with a fast gradient scheme for minimizing smooth convex functions also developed there, i.e., a method that shares a rate of convergence O(1/k 2 ) for function values, where k is the iteration counter, an ε-optimal solution of the original nonsmooth problem can be obtained within O(1/ε) iterations by solving its smoothed counterpart. This clearly outperforms usual subgradient-based schemes which when minimizing a Lipschitz continuous nonsmooth convex function reach an ε-optimal solution within O(1/ε 2 ) iterations. It should be stressed that convergence rates are with respect to the objective function values and not with respect to the iterates. The main difference which explains this improvement relies on the fact that, as opposed to classical subgradient schemes that are black-box oriented and applicable to any convex function, in the approach developed in <ref type="bibr" target="#b17">[17]</ref>, the special structure of the function to be minimized is beneficially exploited when combined with a peculiar fast gradient scheme.</p><p>This paper can be viewed as a natural complement and extension of Nesterov's framework, thus clarifying and unifying several issues on the design, analysis, and potential applications of smoothing methods when combined with fast first order algorithms. Our main observation is that independently of the structure of the convex nonsmooth function involved, and of the given fast first order iterative scheme used, it is always possible to improve the complexity rate for a broad class of NSO problems by solving its corresponding smoothed problem via any given fast first order scheme. Roughly speaking, first we show that the underlying and restrictive max-structure assumption of the nonsmooth convex function <ref type="bibr" target="#b17">[17]</ref> can be removed, and second, we show that given any fast first order iterative method that is capable of producing an O(1/k 2 ) rate of convergence will then naturally induce a method capable of solving a convex NSO model via its smoothed counterpart, with the improved complexity rate O(1/ε), rather than the usual O(1/ε 2 ) obtained by using standard subgradient/bundle schemes.</p><p>In this paper we adopt a partial smoothing approach in which (possibly) only a part of the nonsmooth component of the objective function is actually smoothed. More precisely, we will consider minimization problems of the form min</p><formula xml:id="formula_0">x {F (x) + h 1 (x) + h 2 (x)},</formula><p>where F is smooth and h 1 , h 2 are nonsmooth. (The precise setting is given in section 3.) In the standard smoothing methodology, or full smoothing, both h 1 and h 2 are replaced by approximate smoothing functions H 1 and H 2 , respectively, giving rise to the smoothed problem (CS) min x {F (x) + H 1 (x) + H 2 (x)}.</p><p>However, here we will consider the partial smoothing approach in which only one of the nonsmooth functions, say, h 1 , is smoothed while the other (h 2 ) is kept untouched:</p><formula xml:id="formula_1">(PS) min x {F (x) + H 1 (x) + h 2 (x)}.</formula><p>The motivation for such an approach is twofold. First, with respect to the design and algorithmic analysis of the corresponding scheme, it stems from the fact that minimization problems of composite functions of the form (C) min</p><formula xml:id="formula_2">x {F (x) + h(x)},</formula><p>where F is smooth and h is nonsmooth, can be solved by fast gradient-based methods with an O(1/k 2 ) rate of convergence despite the apparent nonsmoothness of the objective function. That is, the presence of the nonsmooth function does not alter the complexity bound; see the recent algorithms described in <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b18">18]</ref>. In these algorithms, in addition to gradient computations of the smooth function F , a proximal-type operator of the nonsmooth function h is evaluated at each iteration. Therefore, in a sense, these are only conceptual algorithms since evaluating a proximal-type operator can be as difficult as solving the original problem. For a recent analysis on the effects of approximate computation of such operators within fast gradient schemes, see <ref type="bibr" target="#b14">[14]</ref>. Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php 559 Nevertheless, there are some classes of interesting nonsmooth functions h for which the proximal operation is simple; see, for instance, the recent work of Combettes and Pesquet <ref type="bibr" target="#b13">[13]</ref>, which provides a thorough review of proximal-based algorithms and an important list of computable proximity operators arising in many applications. Second, in many of these applications <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b13">13]</ref>, one of the nonsmooth terms in the model (PS), say, h 2 , plays a key role in describing a desirable property of the decision variable x which otherwise could be destroyed by smoothing. Thus, when the nonmooth function h 2 in problem (PS) belongs to the aforementioned class and plays a central role in modeling the problem at hand, it can and should be kept untouched; see section 5, which illustrates such a situation.</p><p>To achieve the aforementioned goals, we introduce and characterize mathematically the broad concept of "smoothable functions" for general convex functions; see section 2. In section 3, we begin by introducing the formulation of the nonsmooth optimization problem of interest, which encapsulates a broad class of NSO problems.</p><p>We then formalize what we call a fast iterative method M for composite convex minimization problems of the form (C), and we establish that when applied to a partially smoothed version of the original nonsmooth problem with an adequate smoothing parameter expressed in terms of the problem's data, we always obtain an improved scheme with complexity O(1/ε). To apply our results, we need a smoothing procedure for a general convex function. This is developed in section 4, where we provide a unifying and general approach which naturally extends the so-called Moreau proximal regularization of a convex function <ref type="bibr" target="#b16">[16]</ref>, and to eventually make a connection with another well-known approach for smoothing which is based on asymptotic functions <ref type="bibr" target="#b2">[3]</ref>, thus closing the loop of various existing smoothing procedures. This also allows us to explain, recover, and extend the smoothing approach of <ref type="bibr" target="#b17">[17]</ref>. Throughout, we illustrate our results with a variety of examples. Finally, section 5 contains a numerical example accompanied with a theoretical justification that illustrates the potential advantage of the proposed partial smoothing approach over the full standard smoothing methodology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Notation.</head><p>Throughout the paper we consider finite-dimensional normed vector spaces, denoted by E, F, V, etc. For a vector space E, the endowed norm is denoted by • E and the space of linear functionals is denoted by E * . The dual norm is denoted by either • * E or • E * and is defined as usual as x * E = x E * = max{ u, x : u E ≤ 1} for any x ∈ E * . Here u, x for u ∈ E * and x ∈ E denotes the value of the functional u at x. The norm of a linear transformation A : E → V, where E and V are finite-dimensional vector spaces with endowed norms • E and • V , respectively, is given by</p><formula xml:id="formula_3">A E,V = max{ Ax V : x E = 1}.</formula><p>The subscript indicating the vector spaces will be omitted when their identity is obvious from the context. The vector of all ones is denoted by e where the dimension of the vector will be clear from the context. The set Δ n = {z ∈ R n : z T e = 1, z ≥ 0} is the unit simplex set. For a set C, we denote by δ C the indicator function of the set, that is, δ C (x) = 0 if x ∈ C and ∞ otherwise. For any function f and x ∈ E, we denote the gradient of f at x to be the vector ∇f (x) ∈ E * for which lim When we say that a function f : X → R is continuously differentiable on any given subset X ⊆ E, it should be understood that this implicity assumes that there exists an open set containing X on which the derivatives are defined as usual. We also often use the standard notation C<ref type="foot" target="#foot_0">1</ref>,1 for a function which is continuously differentiable with Lipschitz gradient. Finally, further standard definitions or notations in convex analysis which are not explicitly mentioned here can be found in the classical book <ref type="bibr" target="#b19">[19]</ref>.</p><formula xml:id="formula_4">d →0 f (x + d) -f (x) -∇f (x), d d = 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Smoothable convex functions.</head><p>We begin by defining the concept of a smoothable function and the corresponding smooth approximation of a given nondifferentiable convex function. 1  Definition 2.1 (smoothable functions). Let g : E → (-∞, ∞] be a closed and proper convex function and let X ⊆ dom g be a closed convex set. The function g is called "(α, β, K)-smoothable" over X if there exist β 1 , β 2 satisfying β 1 + β 2 = β &gt; 0 such that for every μ &gt; 0 there exists a continuously differentiable convex function g μ : E → (-∞, ∞) such that the following hold:</p><formula xml:id="formula_5">(i) g(x) -β 1 μ ≤ g μ (x) ≤ g(x) + β 2 μ for every x ∈ X.</formula><p>(ii) The function g μ has a Lipschitz gradient over X with Lipschitz constant which is less than or equal to K + α μ . That is, there exists K ≥ 0, α &gt; 0, such that</p><formula xml:id="formula_6">(2.1) ∇g μ (x) -∇g μ (y) * ≤ K + α μ x -y for every x, y ∈ X.</formula><p>The function g μ is called a "μ-smooth approximation" of g over X with parameters (α, β, K). If a function is smoothable over the entire vector space E, then it will just be called (α, β, K)-smoothable.</p><p>Remark 2.1. The choice of the decomposition of β as β 1 + β 2 is arbitrary. In fact, if g(x)β 1 μ ≤ g μ (x) ≤ g(x) + β 2 μ for every x ∈ X, then for every γ ∈ R,</p><formula xml:id="formula_7">g(x) -(β 1 -γ)μ ≤ g μ (x) + γμ ≤ g(x) + (β 2 + γ)μ for every x ∈ X,</formula><p>which together with the fact that the Lipschitz constants of the gradients of g μ + γμ and g μ are the same implies that g μ + γμ is also a μ-smooth approximation with parameters (α, β, K), but with β 1γ, β 2 + γ taking the role of β 1 , β 2 in property (i) of the definition.</p><p>It is quite easy to see that the following algebraic rules apply for smoothable functions.</p><p>Lemma 2.1 (sum of smoothable functions). Let γ 1 , γ 2 be nonnegative constants and let g 1 , g 2 be (α 1 , β 1 , K 1 )-and (α 2 , β 2 , K 2 )-smoothable functions, respectively, over some closed convex set X. Then</p><formula xml:id="formula_8">γ 1 g 1 + γ 2 g 2 is a (γ 1 α 1 + γ 2 α 2 , γ 1 β 1 + γ 2 β 2 , γ 1 K 1 + γ 2 K 2 )-smoothable function over X.</formula><p>Proof. Straightforward from the definition of smoothable functions. It is also important to understand the effect of a linear transformation of the variables on the parameters of a smoothable function.</p><p>Lemma 2.2 (linear transformation of a smoothable function). Let A : E → V be a linear transformation. Let g be a (α, β, K)-smoothable function over a closed convex set X ⊆ V, and let b ∈ V.</p><p>Then the function q</p><formula xml:id="formula_9">: E → (-∞, ∞) defined by q(x) = g(Ax + b) is a (α A 2 , β, K A 2 )-smoothable function over A -1 (X -b), where A ≡ A E,V = max { Ax V : x E = 1}</formula><p>and where A -1 is the inverse linear mapping defined by</p><formula xml:id="formula_10">A -1 (S) ≡ {x ∈ E : Ax = s for some s ∈ S} for every S ⊆ V.</formula><p>Proof. First, let g μ be a μ-smooth approximation of g with parameters (α, β, K) over X. Then there exists β 1 , β 2 such that β = β 1 + β 2 , for which it holds that</p><formula xml:id="formula_11">g(y) -β 1 μ ≤ g μ (y) ≤ g(y) + β 2 μ</formula><p>for any y ∈ X. Making the change of variables y = Ax + b, where</p><formula xml:id="formula_12">x ∈ A -1 (X -b), it follows that g(Ax + b) -β 1 μ ≤ g μ (Ax + b) ≤ g(Ax + b) + β 2 μ, implying that q(x) -β 1 μ ≤ g μ (Ax + b) ≤ q(x) + β 2 μ</formula><p>for any x ∈ A -1 (Xb). Therefore, property (i) of Definition 2.1 is satisfied with q μ (x) ≡ g μ (Ax + b). To verify property (ii) of the same definition, note that the gradient of q μ is given by A * ∇g μ (Ax + b) and for any x, y ∈ A -1 (Xb) we have</p><formula xml:id="formula_13">∇q μ (x) -∇q μ (y) * E = A * ∇g μ (Ax + b) -A * ∇g μ (Ay + b) * E ≤ A ∇g μ (Ax + b) -∇g μ (Ay + b) * V ≤ α μ + K A Ax + b -Ay -b V ≤ α μ + K A 2 x -y E ,</formula><p>establishing the desired result. There exist several ways to generate smooth approximations of nondifferentiable convex functions. This issue will be addressed in section 4.4, where we present a general framework for generating such smooth approximations. In the next section, we present a smoothing-based general minimization scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>A smoothing-based fast first order method. We are interested in solving the convex problem (G) given by</p><formula xml:id="formula_14">(3.1) (G) H * = min{H(x) ≡ g(x) + f (x) + h(x) : x ∈ E},</formula><p>where the assumptions on the underlying functions are</p><formula xml:id="formula_15">• h : E → (-∞, ∞</formula><p>] is an extended valued closed proper convex function which is subdifferentiable over its domain which is denoted by X = dom h; Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p><formula xml:id="formula_16">• f : X → (-∞, ∞) is a continuously differentiable function over X whose gradient is Lipschitz with constant L f ; • g : X → (∞, ∞] is a (α, β, K)-smoothable function over X.</formula><p>Problem (G) is rich enough to cover many interesting generic optimization models by appropriate choices of (f, g, h). At a first glance, the use of three functions, with two being nonsmooth, and one smooth, might appear redundant. However, it is relevant since, as mentioned in the introduction, we will invoke what we call partial smoothing, namely, only the function g is smoothed, while the function h remains unchanged. Later on, in section 5, we will demonstrate the advantage of the partial smoothing approach in comparison to the "full" smoothing methodology, i.e., in which h would also be smoothed.</p><p>The partially smoothed problem is thus</p><formula xml:id="formula_17">(3.2) (G μ ) H * μ = min{H μ (x) ≡ g μ (x) + f (x) + h(x) : x ∈ E},</formula><p>where g μ is a μ-smooth approximation of g over X with parameters (α, β, K) for an appropriately chosen μ. Note that (G μ ) remains a nonsmooth problem, due to the presence of the nonsmooth function h. The idea is now to be able to use any adequate algorithm for solving (G μ ). For that purpose we introduce the formal definition of a fast iterative method for solving the convex NSO problem,</p><formula xml:id="formula_18">(3.3) (C) min{D(x) ≡ F (x) + h(x) : x ∈ E},</formula><p>which is assumed to have an optimal solution x * ∈ E, and D * := D(x * ) denotes its optimal value. This problem is called the input convex optimization model and is characterized by the following data:</p><p>• h is an extended valued closed convex function which is subdifferentiable over its domain dom h. • F is a continuously differentiable convex function over dom h whose gradient is Lipschitz with constant L F . The input convex optimization model (C) is thus characterized by the triplet (F, h, L F ) satisfying the above premises.</p><p>Definition 3.1 (fast iterative method). Let (F, h, L F ) be a given input convex optimization model with an optimal solution x * , and let x 0 ∈ E be any given initial point. An iterative method M for solving problem (C) is called a fast method with constant 0 &lt; Λ &lt; ∞, which possibly depends on</p><formula xml:id="formula_19">(x 0 , x * ), if it generates a sequence {x k } k≥0 satisfying for all k ≥ 1, (3.4) D(x k ) -D * ≤ L F Λ k 2 .</formula><p>It is important to stress that within such a general setting, we are not preoccupied with the specific computations that are necessary-and that can be quite involvedto build the method M; see also the remarks and discussion at the end of this section. Here, our interest and main observation is to establish that by applying any fast method M on the partially smoothed problem (G μ ) with an appropriately chosen smoothing parameter μ, an ε optimal solution can be obtained in no more than O(1/ε) iterations, which, as mentioned in the introduction, is much better than the standard bound O(1/ε 2 ) that would be obtained by using a usual black-box nonsmooth subgradient/bundle schemes on a nonsmooth problem (F, h, L F ) with a nontrivial function h. Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p><p>The next result shows that the important idea of Nesterov <ref type="bibr" target="#b17">[17,</ref><ref type="bibr">Theorem 3]</ref>, to combine smoothing with a smooth optimization algorithm for specially structured max-type problems for reducing the complexity rate, can now be extended thanks to the concept of smoothable functions introduced in section 2 and independently of the given smooth optimization algorithm.</p><p>Theorem 3.1. Let {x k } be the sequence generated by a fast iterative method M when applied to problem (G μ ), that is, to the input optimization problem (f + g μ , h, L f +gµ ). Suppose that the smoothing parameter is chosen as</p><formula xml:id="formula_20">(3.5) μ = α β ε √ αβ + αβ + (L f + K)ε .</formula><p>Then for</p><formula xml:id="formula_21">(3.6) k ≥ 2 αβΛ 1 ε + (L f + K)Λ 1 √ ε , it holds that H(x k ) -H * ≤ ε. Proof. Let μ &gt; 0 and F := f + g μ . Using Definition 2.1(ii), one has L F = L f + K + α μ .</formula><p>Therefore, the sequence generated by the method M when applied to</p><formula xml:id="formula_22">(G μ ) satisfies for all k ≥ 1 (3.7) H μ (x k ) -H * μ ≤ L f + K + α μ Λ k 2 .</formula><p>Since g μ is a μ-smooth approximation of g with parameters (α, β, K), by Definition 2.1(i) there exist</p><formula xml:id="formula_23">β 1 , β 2 satisfying β 1 + β 2 = β &gt; 0 for which H(x) -β 1 μ ≤ H μ (x) ≤ H(x) + β 2 μ for any x ∈ E.</formula><p>Thus, in particular, the following inequalities hold:</p><formula xml:id="formula_24">H * ≥ H * μ -β 2 μ and H(x k ) ≤ H μ (x k ) + β 1 μ, k = 1, 2, . . . ,</formula><p>and hence, together with (3.7) we obtain</p><formula xml:id="formula_25">(3.8) H(x k ) -H * ≤ H μ (x k ) -H * μ + (β 1 + β 2 )μ ≤ (L f + K) Λ k 2 + αΛ k 2 1 μ + βμ.</formula><p>Minimizing the right-hand side of (3.8) with respect to μ &gt; 0 we obtain</p><formula xml:id="formula_26">(3.9) μ = αΛ β 1 k .</formula><p>Plugging the above expression for μ in (3.8), we obtain</p><formula xml:id="formula_27">H(x k ) -H * ≤ (L f + K) Λ k 2 + 2 αβΛ 1 k .</formula><p>Thus, given ε &gt; 0, to obtain an ε-optimal solution satisfying H(x k ) -H * ≤ ε, it remains to find values of k for which </p><formula xml:id="formula_28">(3.10) (L f + K)Λ 1 k 2 + 2 αβΛ 1 k ≤ ε.</formula><formula xml:id="formula_29">(L f + K)t 2 + 2 αβt -ε ≤ 0, which is equivalent to (recall that t &gt; 0) √ Λ 1 k = t ≤ - √ αβ + αβ + (L f + K)ε L f + K = ε √ αβ + αβ + (L f + K)ε .</formula><p>Using the value of the upper bound just established for √ Λ 1 k in (3.9), we obtain the desired expression of μ stated in <ref type="bibr">(3.5)</ref>. We have thus shown that by choosing μ as in (3.5) and k satisfying</p><formula xml:id="formula_30">(3.11) k ≥ √ αβΛ + αβΛ + (L f + K)εΛ ε , we have H(x k ) -H * ≤ ε.</formula><p>To complete the proof and obtain the desired lower bound for k as given in (3.6), note that for any A, B ≥ 0, the following inequality holds:</p><p>(3.12)</p><formula xml:id="formula_31">√ A + √ A + B ≤ 2 √ A + √ B.</formula><p>By invoking (3.12) with</p><formula xml:id="formula_32">A := αβΛ ε 2 , B := (L f + K)Λ ε ,</formula><p>together with (3.11), the desired result (3.6) follows. Remark 3.1. Note that the "optimal" smoothing parameter (3.5) does not depend on the constant Λ of the method. Nonetheless, this constant does appear in the expression for the bound on the number of iterations required to obtain an ε-optimal solution.</p><p>This paper is not concerned with the development and applications of fast iterative schemes and we refer the reader to the cited references below for more details, analysis, and applications. We end this section with a brief discussion on such schemes within our result established in Theorem 3.1. Current prominent methods that satisfy the premises of a fast iterative method M for solving problem (C) are first order proximal gradient schemes, i.e., methods that use information on the gradient of F and on the proximal mapping of h, or simply first order gradient schemes in the case h ≡ 0; see <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b7">8]</ref> for the former and <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b17">17]</ref> for the latter. All these methods share the same theoretical complexity rate O(1/k 2 ) but are quite different with respect to their analysis and computational demands. For instance, the methods in <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b18">18]</ref> requires two proximal steps based on two different proximal terms per iteration and accumulated memory of previous gradients, while the methods described in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8]</ref> request only one proximal-based computation per iteration, thus providing computational saving. Finally, note that in all these first order methods, the complexity bounds involve an expression on some kind of distance between the initial point x 0 ∈ E and an optimal solution x * , which has been quantified by the number Λ in Definition 3.1. For example, in the Euclidean setting, one has</p><formula xml:id="formula_33">(3.13) Λ := x * -x 0 2 .</formula><p>When dom h is assumed bounded, for the aforementioned first order schemes, it can be shown that the constant Λ is a positive finite real number. However, even when Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php dom h is not bounded, it is still possible to employ the smoothing-based M scheme, since as shown in Theorem 3.1 the smoothing parameter μ given in (3.5) is in fact independent on the constant Λ of the method M.</p><p>In order to apply a smoothing-based algorithm, it is necessary to specify the smoothing approximation which is being used. This is done in the next section, which provides a unified and general approach for smoothing a general nonsmooth convex function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Smoothing convex functions.</head><p>Nondifferentiable convex functions can be approximated by smooth functions by various techniques. One natural tool for generating an approximate smooth functional is through the use of the so-called proximal map introduced by Moreau <ref type="bibr" target="#b16">[16]</ref>. One can construct a smoothed approximation to a given nonsmooth convex function f by taking its infimal convolution with the quadratic norm || • || 2 . Another general smoothing mechanism is obtained by using asymptotic (recession) functions <ref type="bibr" target="#b2">[3]</ref>. Building on these fundamental tools, we propose a natural and unifying framework to smooth a general class of nonsmooth convex functions. This allows us to extend and connect these techniques as well as to recover recent smoothing proposed in <ref type="bibr" target="#b17">[17]</ref>. Before continuing onto details, for the convenience of the reader we first recall some basic convex analysis results which will be essential for the analysis below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Some convex analysis preliminaries.</head><p>The material in this section can be found in the standard convex analysis literature, e.g., <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b20">20]</ref>. The notion of conjugate function is fundamental in our analysis and is recalled below.</p><p>Definition 4.1. For any extended real-valued function</p><formula xml:id="formula_34">f : E → (-∞, ∞], its convex conjugate f * : E * → (-∞, ∞] is defined by f * (y) = sup x∈E { x, y -f (x)} = sup { x, y -f (x) : x ∈ dom f } .</formula><p>Moreover, if f is closed, proper, and convex on E, then so is f * and f * * = f .</p><p>Recall that a proper function f : E → (-∞, +∞] is called σ-strongly convex with respect to • if there exists a constant σ &gt; 0 (often called the modulus of strong convexity) such that</p><formula xml:id="formula_35">f ((1 -t)x + ty) ≤ (1 -t)f (x) + tf (y) - σ 2 t(1 -t)</formula><p>xy 2 for all x, y ∈ E, t ∈ (0, 1).</p><p>We will use an important equivalence between differentiability of a convex function and strong convexity of its conjugate, which is also known as the Baillon-Haddad theorem; see, e.g., <ref type="bibr">[20,</ref> section 12H] and <ref type="bibr" target="#b4">[5]</ref>.</p><p>Lemma 4.1. Let σ &gt; 0. The following statements are equivalent:  <ref type="bibr" target="#b16">[16]</ref>, for any μ &gt; 0, the function g px μ enjoys several remarkable properties: it is convex continuous, finite-valued, and differentiable with gradient ∇g px μ which is Lipschitz continuous with constant 1/μ. The Moreau approximation of a convex function is the so-called infimal convolution of f with the quadratic function q(x) = 1 2μ x 2 , i.e.,</p><formula xml:id="formula_36">(a) h : E → R is convex differentiable with ∇h which is Lipschitz continuous with respect to • E with constant 1 σ . (b) The conjugate h * : E * → (-∞, ∞] is σ-strongly convex with respect to • * E . 4.</formula><formula xml:id="formula_37">g px μ (x) = inf x1,x2</formula><p>{g(x 1 ) + q(x 2 ) :</p><formula xml:id="formula_38">x 1 + x 2 = x} = inf u∈E {g(u) + q(x -u)} ≡ (g2q)(x).</formula><p>Smoothing techniques that share resemblance to the infimal convolution operation where the quadratic squared distance is replaced by other distance-like functions can be found in other works. In particular we mention the work of Attouch and Wets <ref type="bibr" target="#b0">[1]</ref>, which was probably one of the first studies in that direction and inspired, for instance, the variants proposed in <ref type="bibr" target="#b23">[23]</ref>. However, all the nice properties of the Moreau approximation alluded to above are not preserved in these generalizations.</p><p>A less popular though quite useful representation of Moreau proximal smoothing can be obtained through its dual formulation (see, e.g., [12, Proposition 3.4, p. 171]), which is simply derived by a direct application of the Fenchel duality theorem <ref type="bibr" target="#b19">[19]</ref>:</p><formula xml:id="formula_39">(4.2) g px μ (x) = max y∈E * y, x -g * (y) - μ 2 y 2 .</formula><p>In essence, the above shows that Moreau smoothing is a natural tool to also smooth conjugate functions. This provides the starting point of the forthcoming results.</p><p>Here, we will consider a natural and simple extension of Moreau approximation of a convex function. It also relies on the notion of infimal convolution and allows us to derive a broad family of smooth approximations of convex functions that preserve the fundamental properties established by Moreau. But first, we consider below the smoothing approach given by Nesterov <ref type="bibr" target="#b17">[17]</ref> developed for a class of nonsmooth functions that admit a "max representation" and show its direct relation to the Moreau proximal smoothing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Nesterov's smoothing.</head><p>Let us briefly recall the class of nonsmooth functions considered by Nesterov <ref type="bibr" target="#b17">[17]</ref>. Let E, V be finite-dimensional vector spaces, Q ⊆ V * compact and convex, and φ some continuous convex function on Q ⊆ dom φ. The class of nonsmooth convex functions considered in <ref type="bibr" target="#b17">[17]</ref> are given by</p><formula xml:id="formula_40">(4.3) q(x) = max { u, Ax -φ(u) : u ∈ Q} , x ∈ E,</formula><p>where A : E → V is a linear map.</p><p>The method suggested in <ref type="bibr" target="#b17">[17]</ref> proposes the following smoothing methodology. A function d is called a prox-function of a given compact set C if C ⊆ dom d and d is a σ-strongly convex continuous function over the compact set C. The prox center is defined by u 0 = argmin u∈C d(u) and it can be assumed without loss of generality that u 0 = 0. In this setting it can be shown that d(u) ≥ σ 2 uu 0 2</p><p>V * for every u ∈ C. The smooth approximation of q suggested in <ref type="bibr" target="#b17">[17]</ref> is given by the convex function</p><formula xml:id="formula_41">(4.4) q μ (x) = max { u, Ax -φ(u) -μd(u) : u ∈ Q} , x ∈ E,</formula><p>where d(•) is a prox-function for Q. It was then proved in [17, Theorem 1] that the convex function q μ is C 1,1 (E) with Lipschitz continuous gradient with constant Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php L μ = A 2 /σμ and with gradient ∇q μ (x) = A * u μ (x), where u μ (x) is the unique minimizer of (4.4).</p><p>A close inspection of the above result indicates that the smoothing procedure of <ref type="bibr" target="#b17">[17]</ref> is a natural non-Euclidean extension of the dual Moreau smoothing approximation (4.2) of a conjugate function at the point Ax, whereby the squared norm in (4.2) has been replaced by a prox-function d(•) defined on Q ⊆ dom φ.</p><p>The result obtained in <ref type="bibr" target="#b17">[17]</ref> and within the above interpretation appears to limit the class of convex functions that can be smoothed to be exclusively of the form of (4.3), i.e., conjugate-like convex functions. However, as we shall see now, this is not the case, and in the non-Euclidean setting, we will show that the infimal convolution operation of a given nonsmooth convex function with a properly defined smooth convex function remains the key player in smoothing any convex function without requiring any a priori special structure of the function to be smoothed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">The inf-conv smoothing technique.</head><p>We are now ready to define the inf-conv μ-smooth approximation of a proper, closed, and convex function which is essentially an infimal convolution with a C 1,1 convex function.</p><p>Definition 4.2 (inf-conv μ-smooth approximation). Let g : E → (-∞, ∞] be a closed proper convex function and let ω : E → R be a C 1,1 convex function with Lipschitz gradient constant 1/σ (σ &gt; 0). Suppose that for any μ &gt; 0 and any x ∈ E, the following infimal convolution is finite:</p><formula xml:id="formula_42">(4.5) g ic μ (x) = inf u∈E g(u) + μω x -u μ = (g2ω μ )(x),</formula><p>where</p><formula xml:id="formula_43">(4.6) ω μ (•) ≡ μω • μ .</formula><p>Then g ic μ is called the inf-conv μ-smooth approximation of g. Note that the assumption that g2ω μ is a finite-valued function is satisfied, for example, when ω has bounded level sets and g satisfies that min x∈E g(x) &gt; -∞. It is also satisfied when ω(•) = c • 2 E for any constant c &gt; 0. We are now ready to recall some of the main properties of the inf-conv μ-smooth approximation of a convex function. A self-contained simple proof is given in the appendix for the sake of completeness; see also Remark 4.1 below.</p><p>Theorem 4.1. Consider the setting of Definition 4.2. Then, (a) the following "dual" formulation for g ic μ holds:</p><formula xml:id="formula_44">(4.7) g ic μ (x) = (g * + ω * μ ) * (x) = max y∈E * { y, x -g * (y) -μω * (y)} ;</formula><p>(b) g ic μ is differentiable and with gradient ∇g ic μ which is Lipschitz with constant 1 σμ ; (c) let x ∈ E, and suppose that the minimum in (4.5) is attained at the point u μ (x); then</p><formula xml:id="formula_45">(4.8) ∇g ic μ (x) = ∇ω x -u μ (x) μ = ∇ω μ (x -u μ (x)).</formula><p>Proof. See Appendix A. Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Remark 4.1. As noted earlier, the use of infimal convolution to smooth convex functions is very well known and originates from the seminal work of Moreau <ref type="bibr" target="#b16">[16]</ref>. For a detailed and modern account of such results, see the recent comprehensive monograph of Bauchke and Combettes <ref type="bibr" target="#b5">[6]</ref> and relevant references therein. The proof of the differentiability of g μ and part (c) of Theorem 4.1 can also be found in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr">Proposition 18.7]</ref>. We also note that properties (a) and (b) of Theorem 4.1 were shown in Theorem 1 of <ref type="bibr" target="#b17">[17]</ref>.</p><p>Remark 4.2. It should be noted that part (a) of the theorem, namely, the dual formulation, is always true for any proper closed convex function g and any finite valued convex function ω.</p><p>Remark 4.3. Note that since ω * is strongly convex, it follows that the maximization problem in (4.7) has a unique maximizer. Denote this maximizer by y μ (x). Then by <ref type="bibr" target="#b19">[19,</ref><ref type="bibr">Corollary 23.5</ref>.1] it follows that y μ (x) = ∇g ic μ (x), which combined with part (c) of Theorem 4.1 implies that</p><formula xml:id="formula_46">y μ (x) = ∇ω μ (x -u μ (x)).</formula><p>So far we have shown that g ic μ satisfies property (ii) of Definition 2.1 of a μsmooth approximation, and in fact we have shown that the Lipschitz condition there (2.1) is satisfied for all x ∈ E and not specifically on a certain closed convex subset X ⊆ E. It remains to detect conditions under which g ic μ also satisfies property (i) of Definition 2.1.</p><p>Lemma 4.2. Consider the setting of Definition 4.2 and let X ⊆ E be a closed convex set. Suppose that g is subdifferentiable over X. Then for any μ &gt; 0 and x ∈ X the following holds:</p><formula xml:id="formula_47">g(x) -μω * (γ x ) ≤ g ic μ (x) ≤ g(x) + μω(0),</formula><p>where γ x ∈ ∂g(x) is a subgradient of g at x.</p><p>Proof. By the definition of g ic μ one has</p><formula xml:id="formula_48">g ic μ (x) = inf u∈E g(u) + μω x -u μ ≤ g(x) + μω x -x μ = g(x) + μω(0).</formula><p>For the opposite inequality, we can use the subgradient inequality for g to obtain that for every x ∈ X</p><formula xml:id="formula_49">g ic μ (x) -g(x) = min u∈E g(u) -g(x) + μω x -u μ ≥ min u∈E γ x , u -x + μω x -u μ = min z∈E {-γ x , z + ω μ (z)} = -max z∈E { γ x , z -ω μ (z)} = -μω * (γ x ).</formula><p>The above result readily implies that if max x∈X ω * (γ x ) &lt; ∞, then property (i) of a smooth approximation as given in Definition 2.1 will be satisfied. This is recorded <ref type="bibr">Downloaded 11</ref> </p><formula xml:id="formula_50">ω * (d) &lt; ∞.</formula><p>Then for any μ &gt; 0, g ic μ is a μ-smooth approximation of g over X with parameters 1 σ , D[g, ω * ] + ω(0), 0 .</p><p>Remark 4.4. Note that (4.9) could also be defined by replacing the supremum over d ∈ ∂g(x) by an infimum.</p><p>Going back to the special form of nonsmooth functions q considered by <ref type="bibr" target="#b17">[17]</ref> and given in (4.3), let us show how the smoothing (4.4) can be recovered. First, note that the function to be smoothed can be written as q(x) = g(Ax), where g := ( φ) * and φ := φ + δ Q . Now, let d := d + δ Q . Since d is given σ-strongly convex, so is d, and by Lemma 4.1 it follows that ( d) * ∈ C 1,1 (E). Defining ω = ( d) * , we can invoke Theorem 4.1 to get the corresponding inf-conv μ-smooth approximation: (4.10)</p><formula xml:id="formula_51">g ic μ (x) (4.7) = (g * + ω * μ ) * (x) = ( φ + μ d) * (x) = max u { u, x -φ(u) -μd(u) : u ∈ Q} .</formula><p>By Corollary 4.1 (and the identity (4.9)), it follows that g ic μ is a μ-smooth approximation of g with parameters ( 1 σ , D, 0), where D = max{d(u) : u ∈ Q}. (Note that here ω(0) = ( d) * (0) = 0, by definition of the prox center for d.) Now clearly, the formulation (4.10) implies that q μ given in (4.4) is nothing else but q μ (x) = g ic μ (Ax), and hence by Lemma 2.2 it follows that q μ is a μ-smooth approximation of q with parameters ( A 2 σ , D, 0), where A = max{ Ax V : x E = 1}, thus recovering the result of <ref type="bibr" target="#b17">[17]</ref>.</p><p>The following two examples illustrate well-known instances of smooth approximation.</p><p>Example 4.1 (Euclidean norm function). Let E = R n endowed with the l 2 norm • = • 2 . Consider the setting</p><formula xml:id="formula_52">g(x) = x , X = E, ω(x) = 1 2 x 2 .</formula><p>Then</p><formula xml:id="formula_53">ω(0) = 0, D[g, ω] = 1 2</formula><p>and ω is 1-strongly convex, which implies by Corollary 4.1 that g ic μ , which in this case is the same as g px μ , is a μ-smooth approximation of g (over R n ) with parameters 1, 1 2 , 0 . It is easy to see that for every μ &gt; 0 the smooth approximation is given by (4.11)</p><formula xml:id="formula_54">g px μ (x) = min u u + 1 2μ u -x 2 = x 2 2μ , x ≤ μ, x -μ 2 else,</formula><p>which is the so-called Huber function in R n <ref type="bibr" target="#b15">[15]</ref>. Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Example 4.2 (l 1 norm function). Consider the same vector space E and underlying function ω as in the previous example and let g(x) = x 1 . Then ω(0) = 0, D[g, ω] = n 2 , and hence g px μ , which in this case is the sum of Huber functions on each of the components</p><formula xml:id="formula_55">g px μ (x) = n i=1 H μ (x i ), H μ (y) ≡ y 2 2μ |y| ≤ μ, |y| -μ 2 else, ,</formula><p>is a μ-smooth approximation of g (over R n ) with parameters (1, n 2 , 0). The next example describes a function which is smoothable (via the prox operation) only over bounded sets of the space. </p><formula xml:id="formula_56">∂g(x) = ⎧ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎩ [-1, 1], x= 0, {sign(x)}, 0 &lt; |x| &lt; 1, [1, 2], x= 1, [-2, -1], x = -1, {2x}, |x| &gt; 1.</formula><p>Clearly, the subgradients of g are not bounded over the entire real line R. We will consider the prox-based smooth approximation over X = [-2, 2] which is now computed:</p><formula xml:id="formula_57">g px μ (x) = min u max{|u|, u 2 } + 1 2μ (u -x) 2 = min α≥0 min u:|u|=α max{α, α 2 } + 1 2μ (α 2 -2xu + x 2 ) = min α≥0 max{α, α 2 } + 1 2μ (α 2 -2α|x| + x 2 ) = ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ x 2 2μ , |x| &lt; μ, |x| -μ 2 , μ≤ |x| &lt; μ + 1, 1 + 1 2μ (1 -|x|) 2 , μ + 1 ≤ |x| &lt; 2μ + 1, x 2 2μ+1 , |x| ≥ 2μ + 1.</formula><p>By Corollary 4.1, the above function is a μ-smooth approximation of g over X with parameters (1, 2, 0). The function and its approximations g px 0.5 , g px 0.1 are shown in Figure <ref type="figure">1</ref>.</p><p>More examples in the non-Euclidean setting are given in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Smoothing via asymptotic functions.</head><p>Another general approach to smooth nondifferentiable functions is via the concept of recession or asymptotic functions. This approach was introduced in <ref type="bibr" target="#b10">[10]</ref>, where it was observed that many optimization problems may be formulated in the form</p><formula xml:id="formula_58">(K) inf{u ∞ (f 1 (x), . . . , f m (x)) : x ∈ E},</formula><p>where u ∞ is the asymptotic function of some given function u. This was broadly extended with more general results in <ref type="bibr" target="#b1">[2]</ref>; see also <ref type="bibr" target="#b2">[3,</ref><ref type="bibr">Chapter 3]</ref> for an overview and more references. Here, we will show that there exists an interesting close relation between the asymptotic function-based smoothing and the inf-conv μ-smooth approximation of a convex function discussed in the previous section.</p><p>First, we briefly recall the notion of an asymptotic function; see, e.g., <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b2">3]</ref>. For u : E → (-∞, +∞] proper, closed, and convex, its asymptotic function u ∞ is a closed proper convex function on E which is given by The asymptotic function u ∞ is positively homogeneous<ref type="foot" target="#foot_1">2</ref> with u ∞ (0) = 0. Relation (4.12) was the basis used in <ref type="bibr" target="#b10">[10]</ref> to naturally suggest approximating the problem (K) whereby u ∞ is replaced by u μ .</p><p>We will now show that the inf-conv μ-smooth approximation of a convex function has a simple and special structure when the function g to be smoothed is the asymptotic function of the finite-valued convex function ω : E → (∞, +∞) satisfying the premises of Definition 4.2.</p><p>Before stating our result, we record in the next lemma the following fundamental property of the conjugate of an asymptotic function; see, e.g., [3, Theorem 2.5.4(b), p. 55] for a proof.</p><p>Lemma 4.3. Let u : E → (-∞, +∞] be a closed proper convex function, and let u * be its convex conjugate. Then (u ∞ ) * = δ cl domu * , where cl stands for the closure operation.</p><p>Following <ref type="bibr" target="#b10">[10]</ref>, we make the following assumption. Assumption 1. For any μ &gt; 0</p><formula xml:id="formula_59">μω x μ ≥ ω ∞ (x) for all x.</formula><p>We are ready to state our result.</p><p>Theorem 4.2. Let ω : E → R be a C 1,1 convex function with Lipschitz gradient constant 1/σ, and let g be a convex finite-valued function over E. Suppose that Assumption 1 holds and let g = ω ∞ . Then for any μ &gt; 0,</p><formula xml:id="formula_60">g ic μ (x) = μω x μ for every x ∈ E.</formula><p>Moreover, the function g ic μ is a μ-smooth approximation of g with parameters ( 1 σμ , ω(0), 0).</p><p>Proof. With g = ω ∞ , using Theorem 4.1(a) we have</p><formula xml:id="formula_61">g ic μ (x) = (g * + ω * μ ) * (x) = ((ω ∞ ) * + ω * μ ) * (x), = (δ cl dom ω * + ω * μ ) * [by Lemma 4.3], = (ω * μ ) * (x) [since dom ω * μ = dom ω * ], = ω μ (x) = μω x μ [since ω μ is continuous convex],</formula><p>proving the claimed formula for g ic μ in the theorem. Now, by Theorem 4.1 it follows that ∇g ic μ is Lipschitz with constant 1 σμ . Invoking Lemma 4.2 and using Assumption 1, it follows that for any x ∈ E,</p><formula xml:id="formula_62">g(x) = ω ∞ (x) ≤ g ic μ (x) ≤ g(x)</formula><p>+ μω(0), and the desired result is proved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Examples.</head><p>We now illustrate our results within some interesting examples which have been commonly used and are well known in the smoothing literature; see <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref> and references therein. The last example, Example 4.9, illustrates a situation where Nesterov's smoothing framework is not applicable, since the function to be smoothed cannot be represented in the max-formulation of (4.3) through a linear map A.</p><p>Example 4.4 (smoothing of the max function). Consider the space E = R n with the endowed norm • = • ∞ . The function g(x) = max{x 1 , . . . , x n } is an asymptotic function of ω(x) = log ( n i=1 e xi ). The gradient of ω, ∇ω, is Lipschitz with constant 1. To show this, simply notice that ω * (y) ≡ n i=1 y i log y i with dom ω * = Δ n , which is a 1-strongly convex function with respect to the l 1 norm (see, e.g., <ref type="bibr" target="#b6">[7]</ref>) and therefore ω = ω * * has a gradient which is Lipschitz with respect to the l ∞ norm with constant 1. In addition, ω(0) = log(n) and it is easy to see <ref type="bibr" target="#b10">[10]</ref> that for any μ &gt; 0 and x ∈ E</p><formula xml:id="formula_63">g(x) ≤ μω x μ ,</formula><p>and thus, invoking Theorem 4.2, we have that μω</p><formula xml:id="formula_64">( x μ ) = μ log( n i=1 e xi/μ</formula><p>) is a μsmooth approximation of max{x 1 , . . . , x n } with parameters (1, log n, 0). Example 4.5 (max of linear functions). Recall that by Lemma 2.2 smoothability is preserved under linear transformations of the variables. For instance, if we consider a function which is the maximum of affine functions g(x) = max{a T 1 x + b 1 , . . . , a T m x + b m } over the space R n with the endowed norm • 1 , then by Example 4.4 and Lemma 2.2, a μ-smooth approximation of this function will be</p><formula xml:id="formula_65">g μ (x) = μ log m i=1</formula><p>e (a T i x+bi)/μ . Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p><p>The parameters of the above μ-smooth approximation (computed with respect to the l ∞ norm) are ( A 2 , log m, 0), where A is the m × n matrix whose rows are a T i and</p><formula xml:id="formula_66">A = max{ Ax ∞ : x 1 = 1} = max i,j |A i,j |.</formula><p>The above smoothing of the max function gives rise to a smoothing of the absolute value function which can be also rewritten as the max function g(x) = |x| = max{x, -x}, that is, g(x) = q(Ax), where q(x 1 , x 2 ) := max{x 1 , x 2 } and A = 1 -1 . The corresponding μ-smooth approximation is g μ (x) = q μ (Ax) = μ log( <ref type="formula">1</ref>2 (e x/μ + e -x/μ )) with parameters (1, log 2, 0) since A = 1.</p><p>Example 4.6 (smoothing of the l 1 norm). Consider the space E = R n with the endowed norm</p><formula xml:id="formula_67">• 2 . Let g(x) = x 1 and ω(x) = n i=1 1 + x 2 j .</formula><p>Then g is an asymptotic function of ω. The gradient ∇ω is Lipschitz with constant 1, ω(0) = n, and again (cf. <ref type="bibr" target="#b10">[10]</ref>) we have for any μ &gt; 0 and x ∈ E that</p><formula xml:id="formula_68">g(x) ≤ μω x μ ,</formula><p>which, invoking Theorem 4.2, implies that the function</p><formula xml:id="formula_69">n i=1 μ 2 + x 2 j is a μ-smooth approximation of x 1 with parameters (1, n, 0). Example 4.7. Consider the setting E = R, • E = | • |.</formula><p>By the previous example, y 2 + μ 2 is a μ-smooth approximation of the absolute values with parameters (1, 1, 0). Overall, we have encountered three μ-smooth approximations of the absolute value function: y 2 + μ 2 , μ log 1 2 e y/μ + e -y/μ , and Huber's function</p><formula xml:id="formula_70">y 2 2µ , |y| ≤ μ, |y| -µ 2 else</formula><p>with parameters (1, 1, 0), (1, log 2, 0), (1, 0.5, 0), respectively. Therefore, it is not surprising that, as can be seen in Figure <ref type="figure">2</ref>, Huber's function is the best approximation and the square-root-based approximation is the worst (has the largest β).</p><p>Example 4.8. Let g(x) = x and ω(x) = 1 + x 2 over the space E = R n with the endowed l 2 norm. Then ω * (y) = -1y 2 with dom ω * = {y : y ≤ 1} and g is of course the asymptotic function of ω. In addition, ω satisfies Assumption 1 and thus by Theorem 4.2 it follows that μω( x μ ) = μ + x 2 is a μ-smooth approximation of x with parameters (1, 1, 0), which is a slightly worse approximation than Huber's function recalled in Example 4.1.</p><p>Example 4.9 (maximum of convex functions). For a given integer m &gt; 1, consider the convex function</p><formula xml:id="formula_71">g(x) = max {f 1 (x), . . . , f m (x)} ,</formula><p>where f 1 , . . . , f m are m continuously differentiable convex functions over a compact convex set X ⊆ E with Lipschitz gradients over X with constants L f1 , . . . , L fm , respectively. The vector space E has a norm denoted by • E . Clearly, the function g can also be rewritten as Fig. <ref type="figure">2</ref>. The function |y| and its smooth approximations with μ = 0.2. "Huber" stands for the Huber function given in <ref type="bibr">(4.11)</ref>, "log-exp" is the function μ log( <ref type="formula">1</ref>2 (e y/µ +e -y/µ )), and "squared-based" is the function</p><formula xml:id="formula_72">g(x) = max</formula><formula xml:id="formula_73">y 2 + μ 2 -μ.</formula><p>however, since f i (•) are nonlinear, the smoothing framework of <ref type="bibr" target="#b17">[17]</ref> (cf. (4.3)) cannot be applied.</p><p>Denoting the max function by</p><formula xml:id="formula_74">h(z) ≡ max{z 1 , . . . , z m }, (z ∈ R m ),</formula><p>the function g can be rewritten as g(x) = h(f 1 (x), . . . , f m (x)). Recall that by Example 4.4,</p><formula xml:id="formula_75">h μ (z) = μ log m i=1 e zi/μ</formula><p>is a μ-smooth convex approximation of the max function h with parameters (1, log(m), 0) over the space V which is defined as R m endowed with the norm • ∞ . The next result shows that a μ-smooth convex approximation of the function g over X is given by 3</p><formula xml:id="formula_76">g μ (x) = h μ (f 1 (x), . . . , f m (x)) = μ log m i=1</formula><p>e fi(x)/μ . Proposition 4.1 below computes the parameters (α, β, K) for which this approximation g μ will satisfy the premises of Definition 2.1. The proof of the proposition, which is rather technical, is given in Appendix B.</p><p>Proposition 4.1. Let f 1 , . . . , f m be m continuously differentiable convex functions over a compact convex set X ⊆ E whose gradients are Lipschitz over X with constants L f1 , . . . , L fm , respectively. Let g(x) = max{f 1 (x), . . . , f m (x)}. 3 Recall that the convexity of a composite function h(f 1 , . . . , fm) is preserved when f i are convex and h is convex and isotone, i.e., u i ≤ v i , i = 1, . . . , m, implies h(u) ≤ h(v). where M fi := max{ ∇f i (x) * E : x ∈ X}, i = 1, . . . , m. 5. To smooth or not to smooth? In this section we will demonstrate through a numerical example the advantage of partial smoothing in comparison to full smoothing. Consider the following l 1 -l 1 least fitting problem on the vector space R n endowed with the norm • 1 :</p><p>(5.1)</p><formula xml:id="formula_77">min x∈R n {M (x) ≡ Ax -b 1 + x 1 } ,</formula><p>where A ∈ R m×n , b ∈ R m . This problem does not possess any smooth component, so that f ≡ 0 in the model (G) given in <ref type="bibr">(3.1)</ref>. Note that the objective function is a sum of two l 1 norms, namely, the componentwise sum of absolute value functions which will be smoothed using Huber's function defined by</p><formula xml:id="formula_78">H μ (y) ≡ y 2 2μ , |y| ≤ μ, |y| -μ 2 else.</formula><p>The function H μ is a μ-smooth approximation of the absolute value function |y| with parameters (1, 0.5, 0); see Example 4.7. There are (at least) two possible smoothing approaches for this problem within our model (G):</p><p>A. Full smoothing. Take g(x) ≡ Axb 1 + x 1 and h ≡ 0. B. Partial smoothing. Take g(x) ≡ Axb 1 , h(x) = x 1 . In the partial smoothing setting, the problem to be solved is</p><formula xml:id="formula_79">(PS μ ) m i n x m i=1 H μ (A i x -b i ) + x 1 ≡ g μ (x) + x 1 ,</formula><p>where A i is the ith row of the matrix A. Since 2), it follows by Lemma 2.2 that here g μ is a μ-smooth approximation of g with parameters ( A 2 , m 2 , 0). In the full smoothing setting, the smooth problem to be solved is</p><formula xml:id="formula_80">(FS μ ) m i n x ⎧ ⎨ ⎩ m i=1 H μ (A i x -b i ) + n j=1 H μ (x j ) ≡ h μ (x) ⎫ ⎬ ⎭ .</formula><p>By Lemma 2.1 it follows that here h μ is a μ-smooth approximation of h with parameters ( A 2 + 1, m+n 2 , 0). Note that this is a worse approximation than the one given in the partial smoothing setting since both parameters α, β (corresponding to the proximity between the function and its approximation and the Lipschitz constant of the gradient) are larger. Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php What is important here is that there is really no need to smooth the l 1 part x 1 , since in that case one can directly invoke a fast proximal gradient method, like FISTA devised in <ref type="bibr" target="#b7">[8]</ref>, and still achieve the O(1/k 2 ) rate of convergence. The proximal mapping of the h part is trivial in both settings: in the partial smoothing setting (h(x) ≡ x 1 ) it is equal to the soft thresholding operation, and in the full smoothing setting (h ≡ 0) it is simply the identity mapping; see <ref type="bibr" target="#b7">[8]</ref> for the detailed algorithms. Note also that it would not be advisable to consider the partial smoothing approach in the opposite way, that is, to smooth the l 1 norm function x 1 and keep the l 1 fitting term Axb 1 untouched. The reason for this is that computing a proximal mapping of the l 1 fitting term seems to be as difficult as solving the original problem.</p><p>To compare the two approaches, we performed Monte Carlo runs, where in each run the components of the matrix A and the vector b were randomly and independently generated from a standard normal distribution. The dimensions are set to m = 15, n = 30. For each realization of A and b, we ran FISTA for N = 100, 200, 400 iterations on both (PS μ ) and (FS μ ), where the parameter μ was chosen according to Theorem 3.1 with ε = 0.1. Note that the choice of μ according to (3.5) is different for the two problems (PS μ ) and (FS μ ). To compare the errors obtained by the two methods, we also found for each realization of A and b the optimal value of problem (5.1) using SeDuMi <ref type="bibr" target="#b22">[22]</ref>. The results are summarized in the table below. The second and third columns (Err-FS and Err-PS, respectively) contain the average over the 100 realizations of the errors in function values M (x N ) -M * (M * is the optimal value of the problem computed using SeDuMi and x N is the output of the corresponding method) when using the full and partial smoothing methodologies, respectively. The fourth column contains the average over the 100 realizations of the ratio of errors (M (x FS ) -M * )/(M (x PS ) -M * )), where x FS and x PS are the outputs of FISTA in the full and partial smoothing settings, respectively. Clearly, the partial smoothing approach is superior to the full smoothing approach, as it reaches better accuracies for a given number of iterations. Furthermore, the error in function values of the full smoothing setting is more than 22 times the error obtained by the partial smoothing setting when 400 iterations of FISTA are performed.</p><p>The above empirical observation has a theoretical justification which is now explained. Suppose that we wish to solve a problem of the form min x {g(x) + q(x)}, where both g and q are convex and nonsmooth functions and where as usual we assume that the optimal set of this problem is nonempty and bounded. Assume that g μ is a μ-smooth approximation of g with parameters (α g , β g , K g ) and q μ is a μ-smooth approximation of q with parameters (α q , β q , K q ). In the full smoothing approach, the problem to be solved via the fast method is (5.2) min</p><p>x {g μ (x) + q μ (x)}, Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php while in the partial smoothing approach the relevant problem is (5.3) min</p><p>x {g μ (x) + q(x)}.</p><p>Let (x * ps , x * fs ) be the corresponding optimal solutions of problems (5.3)-(5.2), respectively. Applying a fast iterative method M on both problems with initial x 0 = 0 and setting Λ = max{ x * ps 2 , x * fs 2 } (cf., for example, (3.13)), it follows that by Theorem 3.1, a lower bound on the number of iterations required to obtain an ε-optimal solution via the fast method M to problem (5.2) is</p><formula xml:id="formula_81">N 1 ≡ 2 (α g + α q )(β g + β q )Λ 1 ε + (K g + K q )Λ 1 √ ε ,</formula><p>while the lower bound on the number of iterations required to obtain an ε-optimal solution of problem (5.3) via the same fast method is given by</p><formula xml:id="formula_82">N 2 ≡ 2 α g β g Λ 1 ε + K g Λ 1 √ ε .</formula><p>Obviously, N 1 &gt; N 2 , meaning that at least with respect to the lower bound on the number of iterations, finding an optimal solution of the partially smooth problem (5.3) is easier than finding an optimal solution of the fully smooth problem (5.2). To conclude from this example, the answer to the question in the title of this section is the following: smoothing is a valuable approach for tackling nonsmooth problems, but it should be used "moderately" and only when truly necessary! σμ . Therefore, by Lemma 4.1, it follows that ω * μ , and hence also g * +ω * μ , is strongly convex with parameter σμ. Invoking again Lemma 4.1, we conclude that g ic μ = (g * +ω * μ ) * is differentiable with a Lipschitz gradient with constant 1 σμ . (c) Let x ∈ E be such that there exists a minimizer u μ (x) of (4.5), namely, (A.3) g ic μ (x) = g(u μ (x)) + ω μ (xu μ (x)).</p><p>For convenience, define z ≡ ∇ω μ (xu μ (x)). Our objective is to show that ∇g ic μ (x) = z. By standard calculus this means that we have to show that for any ξ ∈ E, Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php To complete the proof, it remains to show that we also have φ(ξ) ≥ -1 μσ ξ 2 . Since g ic μ is convex, so is φ, which along the fact that φ(0) = 0 implies that φ(ξ) ≥ -φ(-ξ), and hence the desired result follows.</p><p>Appendix B. Proof of Proposition 4.1. Since h μ is a (1, log(m), 0)-smooth approximation of h over V, then by property (i) of Definition 2.1, it follows that there exists a decomposition log(m) = β 1 + β 2 for which h(z)β 1 μ ≤ h μ (z) ≤ h(z) + β 2 μ for every z ∈ V.</p><p>Making the change of variables z = (f 1 (x), . . . , f m (x)) T and within the restriction x ∈ X, we obtain that g(x)β 1 μ ≤ g μ (x) ≤ g(x) + β 2 μ for every x ∈ X, thus proving property (i) with β = log(m). To find the other parameters α and K, we introduce some further notation. Let f := (f 1 , . . . , f m ) T , so that g(x) = h(f (x)) and g μ (x) = h μ (f (x)). The matrix J f (x) denotes the transpose of the Jacobian matrix f given by J f (x) = (∇f 1 (x), ∇f 2 (x), . . . , ∇f m (x)), and by the chain rule it follows that ∇g μ = J f (x)∇h μ (f (x)). Now, for every x, y ∈ X we have </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Example 4 . 3 .</head><label>43</label><figDesc>Consider the setting E = R, • = | • | and let g(x) = max{|x|, x 2 }. The subdifferential set of the function is given by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 Fig. 1 .</head><label>11</label><figDesc>Fig.1. The function g(x) = max{|x|, x 2 } and its smooth approximations g px 0.5 , g px 0.1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( 4 .</head><label>4</label><figDesc>12) u ∞ (d) = lim μ→0 + u μ (d) := μu d μ for every d ∈ dom u.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>λ</head><label></label><figDesc>i f i (x); Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php AMIR BECK AND MARC TEBOULLE</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Downloaded 11 /</head><label>11</label><figDesc>12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Then for every μ &gt; 0 the function g μ (x) = μ log m i=1 e fi(x)/μ is a μ-smooth approximation of g with parameters max i=1,...,m M 2 fi , log(m), max i=1,...,m L fi ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>m i=1 H μ (y i ) is a μ-smooth approximation of the l 1 norm function y 1 = m i=1 |y i | with parameters (1, m 2 , 0) (see Example 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Appendix A. Proof of Theorem 4 . 1 .</head><label>41</label><figDesc>(a) Let x ∈ E and μ &gt; 0. Define s 1 (u) ≡ g(u) and s 2 (u) ≡ μω((xu)/μ) = ω μ (xu). Then by definition we have (A.1) g ic μ (x) = inf u∈E {s 1 (u) + s 2 (u)}.Since here dom ω = E, it follows that dom s 2 = dom ω μ = E and hence that ri(dom s 1 )∩ ri(dom s 2 ) = ∅. Therefore, by Fenchel's duality theorem<ref type="bibr" target="#b19">[19,</ref> Theorem 31.1], the expression (A.1) also reads as(A.2) g ic μ (x) = max y∈E * {-s * 1 (y)s * 2 (-y)} = max y∈E * {-g * (y)s * 2 (-y)}.Finally, by the definition of s 2 and ω μ it follows that s * 2 (-y) = ω * μ (y)y, x and ω * μ (y) = μω * (y), which after substitution in (A.2) proves formula (4.7). (b) Since ∇ω is Lipschitz with constant 1 σ , and since by definition, ω μ (x) = μω( x μ ), it follows that ∇ω μ is Lipschitz with constant 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>1 μσ ξ 2 [</head><label>12</label><figDesc>lim ξ →0 |φ(ξ)|/ ξ = 0, where φ(ξ) ≡ g ic μ (x + ξ)g ic μ (x) -ξ, z . Using the definition of g ic μ we obtaing ic μ (x + ξ) ≤ g(u μ (x)) + ω μ (x + ξu μ (x)),and combining the latter inequality with (A.3) we getφ(ξ) ≤ ω μ (x + ξu μ (x))ω μ (xu μ (x)) -ξ, z , ≤ ξ, ∇ω μ (x + ξu μ (x)) -ξ, z [by the gradient inequality for ω μ ], = ξ, ∇ω μ (x + ξu μ (x)) -∇ω μ (xu μ (x)) [substitution of z], ≤ ξ ∇ω μ (x + ξu μ (x)) -∇ω μ (xu μ (x)) * [Cauchy-Schwarz inequality],≤ Lipschitz constant of ∇ω μ is 1/μσ].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>L</head><label></label><figDesc>∇g μ (x) -∇g μ (y) * E = J f (x)∇h μ (f (x)) -J f (y)∇h μ (f (y)) * E = J f (x) (∇h μ (f (x)) -∇h μ (f (y))) + (J f (x) -J f (y)) ∇h μ (f (y)) * E ≤ J f (x) (∇h μ (f (x)) -∇h μ (f (y))) * E + (J f (x) -J f (y)) ∇h μ (f (y)) * E ≤ J f (x) V * ,E * • ∇h μ (f (x)) -∇h μ (f (y)) * V + J f (x) -J f (y) V * ,E * • ∇h μ (f (y)) * V ≤ 1 μ J f (x) V * ,E * • f (x)f (y) V + J f (x) -J f (y) V * ,E * • ∇h μ (f (y)) * V , (B.1) Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php where the last inequality follows by the fact that ∇h μ is Lipschitz with constant 1 μ . In addition, note that for every z∈ R m (B.2) ∇h μ (z) * V = ∇h μ (z) that M fi = max { ∇f i (x) * E : x ∈ X} , i = 1, . . . , m. Thus, f (x)f (y) V = f (x)f (y) ∞ = max i=1,...,m {|f i (x)f i (y)|} ≤ max i=1,...,m M fi xy E , (B.3) J f (x) V * ,E * = max m i=1 v i ∇f i (x) * E : m i=1 |v i | ≤ 1 ≤ max i=1,...,m M fi , (B.4) J f (x) -J f (y) V * ,E * = max i=1,...,m ∇f i (x) -∇f i (y) * E ≤ max i=1,...,m L fi xy E . (B.5)To conclude, plugging (B.2)-(B.5) into (B.1) we get∇g μ (x) -∇g μ (y) fi xy E , showing that g μ (•) = h μ (f (•)) is a μ-smooth approximation of g(•) = h(f (•))over X with parameters max i=1,...,m M 2 fi , log(m), max i=1,...,m L fi .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</figDesc><table><row><cell>Denoting t :=</cell><cell>√</cell><cell>Λ 1 k , the above inequality reduces to</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>2. The Moreau proximal smoothing.</head><label></label><figDesc>One of the most popular approaches in the Euclidean setting (that is, when E is an Euclidean space with norm • = Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php As proved by Moreau</figDesc><table><row><cell cols="5">, •, • ) is the celebrated Moreau proximal approximation [16] that yields a family of</cell></row><row><cell cols="2">approximations {g px μ } μ&gt;0 via</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(4.1)</cell><cell>g px μ (x) = inf u∈E</cell><cell>g(u) +</cell><cell>1 2μ</cell><cell>u -x 2 ,</cell></row></table><note><p>where g : E → (-∞, ∞] is a closed and proper convex function.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php in Corollary 4.1, which states essentially that any convex function is smoothable over closed convex sets on which its subgradients are bounded. Corollary 4.1. Consider the setting of Definition 4.2 and let X ⊆ E be a closed convex set. Suppose that</figDesc><table><row><cell>(4.9)</cell><cell>D[g, ω  *  ] = sup</cell><cell>sup</cell></row><row><cell></cell><cell>x∈X</cell><cell>d∈∂g(x)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Note that the definition and properties discussed in this section remain valid for any closed proper function. Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>A function p is positively homogeneous on E if 0 ∈ dom p and p(tu) = tp(u) for all u ∈ E and all t &gt; 0. Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Downloaded 11/12/12 to 138.87.11.21. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgment. We would like to thank the associate editor and anonymous reviewers for their useful comments and additional references which helped to improve the presentation of the paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Epigraphical analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Attouch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-B</forename><surname>Wets</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Inst. H. Poincaré Anal. Non Linéaire</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="73" to="100" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Penalty and barrier methods: A unified framework</title>
		<author>
			<persName><forename type="first">A</forename><surname>Auslender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="211" to="230" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Asymptotic Cones and Functions in Optimization and Variational Inequalities</title>
		<author>
			<persName><forename type="first">A</forename><surname>Auslender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Interior gradient and proximal methods for convex and conic optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Auslender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="697" to="725" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Baillon-Haddad theorem revisited</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Bauschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Combettes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Convex Anal</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="781" to="787" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Bauschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Combettes</surname></persName>
		</author>
		<title level="m">Convex Analysis and Monotone Operator Theory in Hilbert Spaces</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Mirror descent and nonlinear projected subgradient methods for convex optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res. Lett</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="167" to="175" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A fast iterative shrinkage-thresholding algorithm for linear inverse problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="183" to="202" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gradient-based algorithms with applications to signal recovery problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Convex Optimization in Signal Processing and Communications</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Palomar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Eldar</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="139" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Redistribution subject to SIAM license or copyright</title>
		<idno>Downloaded 11/12/12 to 138.87.11.21</idno>
		<ptr target="http://www.siam.org/journals/ojsa.phpCopyright©bySIAM" />
		<imprint/>
	</monogr>
	<note>Unauthorized reproduction of this article is prohibited</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A smoothing technique for nondifferentiable optimization problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ben-Tal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Optimization</title>
		<title level="s">Lecture Notes in Math. 1405, S. Dolecki</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nondifferentiable optimization via approximation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program. Stud</title>
		<imprint>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<title level="m">Constrained Optimization and Lagrangian Multipliers</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Proximal splitting methods in signal processing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Combettes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Pesquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fixed-Point Algorithms for Inverse Problems in Science and Engineering</title>
		<title level="s">Springer Ser. Optim. Appl.</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Bauschke</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Devolder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Glineur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
		<ptr target="http://www.optimization-online/DBHTML/2010/12/2865.html" />
		<title level="m">First-Order Methods of Smooth Convex Optimization with Inexact Oracle</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robust</forename><surname>Statistics</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wiley</forename><surname>Ser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Probab. Math. Stat</title>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>John Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Proximité et dualité dans un espace Hilbertien</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Moreau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bull. Soc. Math. France</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="273" to="299" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Smooth minimization of non-smooth functions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="127" to="152" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
		<ptr target="http://www.ecore.beDPs/dp1191313936.pdf" />
		<title level="m">Gradient Methods for Minimizing Composite Objective Function</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rockafellar</surname></persName>
		</author>
		<title level="m">Convex Analysis</title>
		<meeting><address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Wets, Variational Analysis</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rockafellar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Grundlehren Math. Wiss.</title>
		<imprint>
			<biblScope unit="volume">317</biblScope>
			<date type="published" when="1998">1998</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Z</forename><surname>Shor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Minimization Methods for Nondifferentiable Functions</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1985">1985</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using SeDuMi 1.02, a MATLAB toolbox for optimization over symmetric cones</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Sturm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Methods Softw</title>
		<imprint>
			<biblScope unit="page" from="625" to="653" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Entropic proximal mappings with application to nonlinear programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="670" to="681" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
