<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Embedding Network for Clustering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Peihao</forename><surname>Huang</surname></persName>
							<email>phhuang@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation Chinese Academy of Sciences</orgName>
								<orgName type="laboratory">Center for Research on Intelligent Perception and Computing (CRIPAC) National Laboratory of Pattern Recognition</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Huang</surname></persName>
							<email>yhuang@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation Chinese Academy of Sciences</orgName>
								<orgName type="laboratory">Center for Research on Intelligent Perception and Computing (CRIPAC) National Laboratory of Pattern Recognition</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
							<email>wangwei@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation Chinese Academy of Sciences</orgName>
								<orgName type="laboratory">Center for Research on Intelligent Perception and Computing (CRIPAC) National Laboratory of Pattern Recognition</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
							<email>wangliang@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation Chinese Academy of Sciences</orgName>
								<orgName type="laboratory">Center for Research on Intelligent Perception and Computing (CRIPAC) National Laboratory of Pattern Recognition</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Embedding Network for Clustering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AC527F7C1E32079316E41DF1064DBE81</idno>
					<idno type="DOI">10.1109/ICPR.2014.272</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Clustering is a fundamental technique widely used for exploring the inherent data structure in pattern recognition and machine learning. Most of the existing methods focus on modeling the similarity/dissimilarity relationship among instances, such as k-means and spectral clustering, and ignore to extract more effective representation for clustering. In this paper, we propose a deep embedding network for representation learning, which is more beneficial for clustering by considering two constraints on learned representations. We first utilize a deep autoencoder to learn the reduced representations from the raw data. To make the learned representations suitable for clustering, we first impose a locality-persevering constraint on the learned representations, which aims to embed original data into its underlying manifold space. Then, different from spectral clustering which extracts representations from the block diagonal similarity matrix, we apply a group sparsity constraint for the learned representations, and aim to learn block diagonal representations in which the nonzero groups correspond to its cluster. After obtaining the learned representations, we use k-means to cluster them. To evaluate the proposed deep embedding network, we compare its performance with k-means and spectral clustering on three commonly-used datasets. The experiments demonstrate that the proposed method achieves promising performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>It is very important to learn good features for achieving good performance in computer vision and pattern recognition tasks. Taking object recognition for an example, inspired by human visual system, an object can be represented by multiple level features, e.g., bar-like edges or object parts. Generally, the high-level features are made up of the low-level ones, which can achieve better recognition performance since they are more closely related to the abstract semantic concept. To obtain these multiple levels of features, many efforts have been put forward to design various hierarchical feature extractors. Deep neural network (DNN), as a typical hierarchical model, had been utilized for feature learning for a period of time in the 90's, which was abandoned afterwards due to the disadvantages of high computational cost, easily getting stuck in local optimum and over-fitting.</p><p>However, DNN has recently attracted much attention again since Hinton et al. <ref type="bibr" target="#b0">[1]</ref> proposed an efficient learning algorithm for so-called deep belief nets (DBN). The algorithm utilizes a layer-wise unsupervised learning strategy to provide a good initialization for the network, which can greatly alleviate the drawbacks mentioned above. Thus, variants of DNN have exhibited their powerful ability in representation learning and achieved great success in many fields. For example, Lee et al. <ref type="bibr" target="#b1">[2]</ref> propose a convolutional version of DBN to learn hierarchical representations for high-dimensional images, which obtain great improvement in visual recognition tasks. To fuse multiple modalities and obtain their shared representations, Ngiam et al. <ref type="bibr" target="#b2">[3]</ref> propose a multimodal deep auto-encoder which can be learned by pretraining and fine-tuning successively. Krizhevsky et la. <ref type="bibr" target="#b3">[4]</ref> design a very deep convolutional network for largescale high-resolution image classification which largely outperforms the previous state-of-the-art. To better model the emission distribution of hidden Markov models, Mohamed et al. <ref type="bibr" target="#b4">[5]</ref> replace the Gaussian mixture models with DBN and achieve better speech recognition results. However, to the best of our knowledge, there exists few literature which applies the widely used deep neural network for clustering.</p><p>Clustering can be considered as one of the most important unsupervised learning problems, which has been widely used in various fields from computer science to social science. The goal of clustering is to group similar data into the same cluster through measuring the distances between data points. Traditionally, k-means <ref type="bibr" target="#b5">[6]</ref> is one of the most popular and simplest clustering methods, which iteratively assigns data to its nearest centroid and updates k centroids until convergence. Unlike the hard assigning of k-means, the mixture of Gaussians models each cluster as Gaussian distribution and represents the entire data set by a mixture of Gaussians. Without making any assumption on the distribution of the clusters, spectral clustering <ref type="bibr" target="#b6">[7]</ref> makes use of the spectrum of the similarity matrix of data to perform dimensionality reduction before applying k-means. Most of the existing clustering methods focus on modeling the similarity/dissimilarity relationship among instances and ignore to extract more effective representation which largely influences the clustering performance. A few kernel methods, such as kernel k-means <ref type="bibr" target="#b7">[8]</ref>, apply a non-linear transformation to original data and generally measure the similarity in a high-dimensional representation space. However, these kernel methods heavily depend on the choice of the kernel, which is more experience-guided.</p><p>In this paper, we propose a deep neural network based model named deep embedding network (DEN), which learns clustering-oriented representations by imposing two special constraints. First, utilizing the deep autoencoder <ref type="bibr" target="#b8">[9]</ref> to obtain good representations from the raw data by minimizing the data reconstruction error. To uncover the intrinsic manifold from the learned representations, we apply a locality-preserving constraint which preserves the local structure property of the original data. To further facilitate the clustering and make the representations contain cluster information, we also use a group sparsity constraint which aims to diagonalize the affinity of representations. The nonzero values of the representations correspond to its cluster. After obtaining the learned representations, we use k-means to cluster them. To evaluate the proposed deep embedding network, we compare its performance with k-means and spectral clustering on three commonly-used datasets. The experiments demonstrate that the proposed method achieves promising performance.</p><p>The rest of this paper is organized as follows: Section II will introduce some related work about deep learning and clustering methods. The proposed deep embedding network for clustering will be described in detail in Section III followed by some experimental results in Section IV. We conclude the paper in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In this section, we briefly review the existing literature that closely relates to the proposed deep embedding network. First, we will introduce the existing deep neural network methods for clustering. Then, we review current deep neural network methods for nonlinear embedding, which aims to learn robust representations for various tasks. Considering that binary units are used in the top hidden layer of the deep embedding network, deep embedding network seems to become able to learn hash codes, and some related networks need to be introduced below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deep neural network for clustering</head><p>Currently, there is only a little work on deep neural network for clustering. Song et al. <ref type="bibr" target="#b9">[10]</ref> propose an autoencoder-based data clustering method, which defines a new objective function by considering the reconstruction error from an auto-encoder network and restricting the distance in the learned space between data and their corresponding cluster centers. This model follows the two-step iteration procedure of k-means. During optimization, data representation and clustering centers are updated iteratively. Different with their work, our deep embedding network aims to learn effective representation for clustering, but not to simulate any existing clustering methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deep neural network for nonlinear embedding</head><p>Traditional autoencoder is an artificial neural network method for dimensionality reduction, which aims to learn a compressed representation for an input through minimizing its reconstruction error <ref type="bibr" target="#b10">[11]</ref>. More recently, several autoencoder variants are proposed to learn robust features. Sparse autoencoder imposes a sparsity constraint on hidden representation to model the sparse coding of primary visual cortex <ref type="bibr" target="#b11">[12]</ref>. Denoising autoencoder transforms a corrupted input into a hidden representation, and then tries to recover the original input from this representation <ref type="bibr" target="#b12">[13]</ref>. Contractive autoencoder adds a regularization term that is the sum of squares of all partial derivatives of the hidden representations with respect to the input, which penalizes the sensitivity of the hidden representation to the input <ref type="bibr" target="#b13">[14]</ref>. Hinton et al. propose an efficient pretraining algorithm for multilayer autoencoders (socalled deep autoencoder) <ref type="bibr" target="#b14">[15]</ref>. In our deep embedding network, we use multilayer autoencoder to model the reconstruction term, and also adopt the pretraining strategy in <ref type="bibr" target="#b8">[9]</ref>. Another similar work to our deep embedding network is the nonlinear extension of neighborhood component analysis (nonNCA) <ref type="bibr" target="#b15">[16]</ref> <ref type="bibr" target="#b16">[17]</ref>, which uses a deep neural network as the non-linear transformation function and preserves the class neighborhood structure by exploiting class label information. The main difference between our method and nonNCA is that our deep embedding network is an unsupervised representation learning method while nonNCA is a supervised one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deep neural network for learning hash codes</head><p>Both <ref type="bibr" target="#b17">[18]</ref> and <ref type="bibr" target="#b18">[19]</ref> use deep autoencoder to learn hash codes by assuming that the top hidden layer only contains binary units. The former, <ref type="bibr" target="#b17">[18]</ref> aims to learn a representation for each document while the later <ref type="bibr" target="#b18">[19]</ref> for images. During the finetuning procedure, they use backpropagation to find codes that are good at reconstructing the word-count vector or original raw-pixel image but are as close to binary as possible. In order to make the codes binary, they add Gaussian noise to the bottom-up input received by each code unit, and make these bottom-up inputs to be large and negative for some training cases while large and positive for the others. With this binarization strategy, our deep embedding network can also be used to learn hash codes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. CLUSTERING WITH DEEP EMBEDDING NETWORK</head><p>Existing popular clustering methods such as k-means or spectral clustering, use either raw or linear transformed data for clustering. However, it would be insufficient when dealing with most datasets which have complex statistical properties. Recently, deep learning has drawn much attention because its highly nonlinear architecture can help to learn powerful feature representations. Thus, to take advantage of it, we propose a deep embedding network which utilizes deep neural network to learn clustering-oriented representations from raw data, and then performs clustering with k-means. To achieve the clustering-oriented representations, we impose two constraints on the learned representations of deep embedding network. One is a locality-persevering constraint which aims to embed original data into its underlying manifold space. The other one is a group sparsity constraint which aims to learn block diagonal representations in which the nonzero groups correspond to its cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Deep Autoencoder</head><p>In this section, we will briefly review the traditional deep autoencoder (DAE) <ref type="bibr" target="#b8">[9]</ref>, which is the foundation of our proposed deep embedding network.</p><p>Taking the four-layer neural network in Fig. <ref type="figure" target="#fig_1">1</ref> (a) for example, the network serves as an encoder which transforms raw input data (digit 9) to a powerful representation (top layer with 100 units). Particularly, let X = {x i :</p><formula xml:id="formula_0">x i ∈ R n×1 } i=1,2,•••,N</formula><p>denote the set of input data, and W = {W i } i=1,2,3 for the weights of the encoder network. The encoder defines a transformation f (•) : R n×1 → R d×1 which transforms an input x to a d-dimensional representation f (x):</p><formula xml:id="formula_1">f (x) = W T 3 φ( W T 2 φ(W T 1 x))<label>(1)</label></formula><p>where φ(•) is the activation function φ(x) = 1/(1 + e -x ).</p><p>For simplicity, we drop the bias term b i for each layer in the formulation.</p><p>Unrolling the four-layer encoder network, we obtain a deep autoencoder with a symmetric decoder as shown in Fig. <ref type="figure" target="#fig_1">1</ref>   to reconstruct the original input x. When the input is binaryvalued, the reconstructed input is</p><formula xml:id="formula_2">f (x) = φ(W T 1 φ( W T 2 φ(W T 3 f (x))))<label>(2)</label></formula><p>When the input is real-valued, the reconstructed input is</p><formula xml:id="formula_3">f (x) = W T 1 φ( W T 2 φ(W T 3 f (x)))<label>(3)</label></formula><p>After obtaining the reconstructed input, we can define an objective function E r when the input is real-valued:</p><formula xml:id="formula_4">E r = N i=1 x i -f (x i ) 2<label>(4)</label></formula><p>where • denotes the Euclidean norm. When given binaryvalued input, the corresponding objective function is defined as cross entropy:</p><formula xml:id="formula_5">E r = - N i=1 [x i log f (x i ) + (1 -x i ) log(1 -f (x i ))]<label>(5)</label></formula><p>The network weights W = {W i } i=1,2,3 can be learned via gradient descend. We can compute the derivatives of the objective function with respect to all the weights using the backpropagation algorithm <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Objective Function of Deep Embedded Network</head><p>Deep neural network and its variants have been successfully applied to many pattern recognition tasks such as dimensionality reduction, classification and retrieval( <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b17">[18]</ref>). They can learn expressive representations for very complex data with their deep and nonlinear architectures. In this paper, we aim to learn clustering-oriented representations by imposing locality-preserving and group sparsity constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Locality-preserving Constraint:</head><p>To make the learned representations suitable for clustering, they are expected to be embedded into their intrinsic manifold, which preserves their local property. Specifically, we introduce a locality-preserving constraint as follows:</p><formula xml:id="formula_6">E g = i,j∈k(i) S ij f (x i ) -f (x j ) 2<label>(6)</label></formula><p>where k(i) is the set containing the indexes of k nearest neighbors of data x i , f (•) is defined in (1), and S ij is the similarity measure between x i and x j . Here we use the heat kernel S ij = e -x i -x j 2 t (t is a tuning parameter).</p><p>The manifold learned from the above constraint is similar to the one learned from Laplacian Eigenmap (LE) due to the similar formulation. As we know, LE is closely related to spectral clustering <ref type="bibr" target="#b20">[21]</ref>. That is to say, our method is related to spectral clustering to some extent, except the nonlinear transformation implemented by deep neural network.</p><p>Group Sparsity Constraint: Inspired by spectral clustering which exploits block diagonal similarity matrix for representation learning, we aim to diagonalize the learned representations to further facilitate clustering by selecting one or more relevant groups of hidden units which represents inherent properties of data. As we know, group sparsity constraint as an effective feature selection method which has been widely used in many applications. In this paper, we employ group lasso which leads to sparsity within hidden codes on group level <ref type="bibr" target="#b21">[22]</ref>.</p><p>In particular, we divide the hidden units into G groups where G is the assumed number of clusters. When given a data point x i , we obtain the transformed representation f (x i ) and G grouped units {f g (x i )} G g=1 . Thus the group sparsity constraint E s can be defined as follows 1 :</p><formula xml:id="formula_7">E s = N i=1 G g=1 λ g f g (x i )<label>(7)</label></formula><p>where {λ g } G g=1 are the weights to sparsity of groups. Generally, larger weights are given to larger groups and λ g is defined as follows:</p><formula xml:id="formula_8">λ g = λ √ n g</formula><p>where n g is the group size and λ is a constant.</p><p>As we can see, by imposing this group sparsity constraint, only a few groups of the learned representation of each data point can be activated, and the activated groups correspond to specific cluster. As a result, all the representations can be block-diagonalized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Objective function:</head><p>After introducing the localitypreserving and group sparsity constraints in detail, we can derive the objective function of the proposed deep embedding network as follows:</p><formula xml:id="formula_9">E = E r + αE g + βE s (<label>8</label></formula><formula xml:id="formula_10">)</formula><p>where α and β are tuning parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Learning</head><p>To learn the network weights of the proposed deep embedding network, we utilize a two-stage algorithm which contains a pretraining procedure to initialize the network weights followed by a fine-tuning procedure. It should be noticed that both of these two procedures are unsupervised.</p><p>At first, we briefly review restricted Boltzmann machine (RBM) <ref type="bibr" target="#b8">[9]</ref>, which is a basic concept in pretraining. A RBM consists of a visible layer and a hidden layer. Each node in the visible layer is connected to each node in the hidden layer, and values of these nodes are all binary-valued. The energy function of this model is defined as follows:</p><formula xml:id="formula_11">F (v, h) = -v T W h -b 1 v -b 2 h (<label>9</label></formula><formula xml:id="formula_12">)</formula><p>where v and h are respectively the visible and hidden nodes, W is the weight matrix between visible nodes and hidden nodes, b 1 and b 2 are the visible biases and hidden biases, respectively.</p><p>RBM can only deal with binary-valued data, while Gaussian restricted Boltzmann machine (GRBM) can handle realvalued data using real-valued visible nodes. Its energy function is defined as: 1 Noting that for smoothness of the differential of the group lasso regularizer, it is common to add a small positive term to the regularizer in practice <ref type="bibr" target="#b22">[23]</ref> . The formula of regularization term Es then turns to</p><formula xml:id="formula_13">G g=1 λg i∈group g h 2 i + . F (v, h) = i (v i -b i ) 2 2σ 2 i - i j v i σ i W ij h j - j b j h j (10)</formula><p>Where {W, b i , b j } are model parameters, σ i is the standard deviation of the Gaussian noise for visible node i. The joint probability distribution of all the nodes is defined as:</p><formula xml:id="formula_14">P (v, h) = 1 Z exp(-F (v, h))<label>(11)</label></formula><p>where Z is a normalization factor that scales P (v, h) to [0,1]. The RBM parameters can be trained by minimizing the negative log-likelihoodh log P (v, h) via stochastic gradient descend. Here we use Contrastive Divergence (CD) <ref type="bibr" target="#b14">[15]</ref> to approximate the intractable gradients computation.</p><p>Pretraining <ref type="bibr" target="#b8">[9]</ref> treats adjacent layers as a RBM and trains RBMs bottom-up to obtain good initial weights. For example, in Fig. <ref type="figure" target="#fig_1">1 (d)</ref>, the weight W 1 can be trained by treating the bottom two layer as a GRBM. The weight W 2 can be trained in the same way by treating the following two layers as a RBM. Similarly, we can train all the weights in a bottom-up manner. After the pretraining procedure, we use the backpropagation algorithm to fine-tune the network weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. K-means for Clustering</head><p>Given data points, we first utilize the trained deep neural network to obtain the transformed representations, and then employ traditional k-means algorithm to perform clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head><p>To evaluate the proposed deep embedding network, we perform several experiments on three datasets to demonstrate the effectiveness of our method in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Description of Datasets</head><p>We use three datasets (COIL-20, PIE, Yale-B) to evaluate the performance of the proposed deep embedding network. All of these datasets provide ground truth, such as digit label, object class and person id. COIL-20<ref type="foot" target="#foot_1">2</ref> is a dataset for object classification on 20 classes of objects. Each object has 72 images shot in different angles. We use the processed version of this dataset in which every image only contains one object with black background. All images are rescaled into a size of 32×32 pixels.</p><p>CMU PIE <ref type="bibr" target="#b23">[24]</ref> and Yale-B <ref type="bibr" target="#b24">[25]</ref> are both face image datasets, which contains faces of different people under varied poses, illumination conditions and expressions (Yale-B does not consider expression variation). For computational consideration we resize the images in Yale-B<ref type="foot" target="#foot_2">3</ref> to 30×40 pixels. Images in PIE are preprocessed as in <ref type="bibr" target="#b25">[26]</ref>.</p><p>For all datasets listed above, we normalize the data by subtracting the mean and then dividing the data by standard deviation for each feature. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Settings 1) Baselines:</head><p>We compare the proposed method with two most popular clustering algorithms: k-means <ref type="bibr" target="#b5">[6]</ref> and spectral clustering <ref type="bibr" target="#b6">[7]</ref>. Considering that spectral clustering is an approximated solution for normalized cut <ref type="bibr" target="#b26">[27]</ref> or ratio cut <ref type="bibr" target="#b27">[28]</ref>.</p><p>Here we take the normalized cut (Ncut) version of spectral clustering as the baseline.</p><p>2) Evaluation metric: As the group label of each data point is available, we can compare clustering results with these labels to evaluate the performance. Here we use Normalized Mutual Information (NMI) and Accuracy (ACC) to measure the effectiveness of clustering methods. Accuracy is defined as: ACC = N i=1 δ(map(c i ) = y i ) N where δ(•) is an indicator function, c i is the clustering label for x i , map(•) transforms the clustering label c i to its group label by the Hungarian algorithm <ref type="bibr" target="#b29">[30]</ref>, and y i is the true group label of x i . ACC measures the consistency between the true group label and the clustering group label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Normalized Mutual Information</head><p>Initial centroids have significant impact on clustering results when utilizing the k-means algorithm. To alleviate this influence, we repeat k-means for multiple times with random initial centroids (specifically, 100 times for statistical significance). The average NMI and accuracy along with the corresponding standard deviation are taken as the final result. 3) Parameter settings: We manually choose the architecture for each deep embedding network, such as the number of layers and the number of units in each layer. As for the groups of the top hidden layer codes in the deep embedding network, we group adjacent hidden codes together and fix the size of each group to a constant s (e.g., 3 or 5). Note that there is no intersection between groups. When partitioning the dataset into K clusters, we obtain K • s hidden codes in the network. Detailed settings for all datasets are listed in Table <ref type="table" target="#tab_1">II</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Results Analysis</head><p>We train the deep embedding network on the datasets and apply the k-means algorithm on the learned representation. NMI and Accuracy of all the methods are listed in Table <ref type="table" target="#tab_0">I</ref>.</p><p>The experimental results show that the proposed deep embedding network performs significantly better than both k-means and spectral clustering algorithms on all the tested datasets. It is because k-means can discover more accurate cluster structure from the representations learned by deep embedding network than that from raw data. Compared with normalized cut, our method achieves large improvement on all these datasets by 0.01/7.83%, 0.13/19.39%, and 0.17/1.64% (NMI/ACC), respectively. Note that for each dataset, we tune the parameters of normalized cut to obtain the best result (including the number of the nearest neighbors for graph construction and the edge weights). We also plot the learned representations of the 5,850 samples from the Yale-B dataset in Figure <ref type="figure" target="#fig_3">2</ref>. In this figure, the horizontal axis denotes the samples and the blue lines separate the ten group samples from each other. The vertical axis denotes the learned representation and the red lines separate the ten group representations. As we can see, the representations in each sample group show the group sparsity, and different sample groups show different group sparsity patterns, which indicates that the proposed method learns good representations for clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, we have proposed the deep embedding network for clustering, which exploits deep neural network to obtain clustering-oriented representations by considering two constraints, namely the locality-preserving and group sparsity constraints, respectively. The experimental results have demonstrated the effectiveness of our proposed method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(b). The decoder also defines a transformation f (•) : R d×1 → R n×1 which uses the transformed representation f (x) Deep neural network (b) Unrolling the network (c) The proposed deep embedded network (d) Pretraining</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) A four-layer deep neural network. The number in each layer represents the number of units, W 1 , W 2 and W 3 are the weights of the network, the bottom digit image represents the input data, and the top layer with 100 units is the learned representation. (b) Unrolling the network. The encoder and decoder are marked as two dashed rectangles, the top digit image is the reconstruction of the bottom digit image. (c) The proposed deep embedding network. The top layer with 100 units is divided into 10 groups, each of which contains 10 units. (d) The pretraining procedure. The network can be trained successively as a GRBM and two RBMs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc><ref type="bibr" target="#b28">[29]</ref> is a popular metric used for evaluating clustering tasks. It is defined as follows:NMI(Ω, C) = I(Ω, C) H(Ω)H(C)where Ω and C respectively denote clustering label and ground truth label of any given sample. I(Ω, C) is mutual information which measures the information gain to the true partition after knowing the clustering result, H(•) is entropy and the denominator H(Ω)H(C) is used to normalize the mutual information to be in the range of [0, 1]. When we partition the data perfectly, NMI score is 1, and when Ω and C are independent, NMI score is 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Representations learned from 5,850 samples of Yale-B. Horizontal axis represents the samples while vertical axis represents groups in the learned representations. Blue lines separate groups in samples and red ones separate groups in the learned representations. (Best viewed in color.)</figDesc><graphic coords="5,313.94,410.12,260.06,182.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I .</head><label>I</label><figDesc>COMPARISON OF NMI AND ACCURACY OF CLUSTERING METHODS ON THREE DATASETS</figDesc><table><row><cell>Method</cell><cell>NMI</cell><cell>COIL20 ACC (%)</cell><cell>NMI</cell><cell>Yale-B ACC (%)</cell><cell>NMI</cell><cell>PIE</cell><cell>ACC (%)</cell></row><row><cell cols="6">K-means 0.76±0.02 59.02±4.40 0.70±0.04 65.80±6.18 0.19±0.00</cell><cell cols="2">8.36±0.40</cell></row><row><cell>Ncut</cell><cell cols="5">0.86±0.03 64.57±6.87 0.79±0.03 62.34±6.37 0.25±0.01</cell><cell cols="2">9.55±0.65</cell></row><row><cell cols="8">Proposed 0.87±0.01 72.40±3.39 0.92±0.04 81.73±9.64 0.42±0.00 11.19±0.29</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II</head><label>II</label><figDesc></figDesc><table><row><cell>.</cell><cell cols="4">PARAMETER SETTINGS ON THREE DATASETS</cell></row><row><cell>Dataset</cell><cell>Architecture</cell><cell>K s</cell><cell>α</cell><cell>β</cell></row><row><cell cols="2">COIL20 1024-200-80</cell><cell>20 4</cell><cell cols="2">250 0</cell></row><row><cell>Yale-B</cell><cell cols="2">1200-500-100-30 10 3</cell><cell>0.5</cell><cell>1</cell></row><row><cell>PIE</cell><cell>1024-2000-680</cell><cell cols="2">68 10 0</cell><cell>0</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>1051-4651/14 $31.00 © 2014 IEEE DOI 10.1109/ICPR.2014.272</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://www.cs.columbia.edu/CAVE/software/softlib/coil-20.php</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>http://markus-breitenbach.com/machine learning data.php</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ACKNOWLEDGMENT This work is jointly supported by National Natural Science Foundation of China (61175003, 61135002, 61202328), Hundred Talents Program of CAS, National Basic Research Program of China (2012CB316300).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multimodal deep learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khosia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Acoustic modeling using deep belief networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TASLP</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Constrained kmeans clustering with background knowledge</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wagstaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schrödl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="577" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A tutorial on spectral clustering</title>
		<author>
			<persName><forename type="first">U</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Von</forename><surname>Luxburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="395" to="416" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Kernel k-means, spectral clustering and normalized cuts</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="551" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Auto-encoder based data clustering</title>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning deep architectures for ai</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends R in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="127" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sparse deep belief net model for visual area v2</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ekanadham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Contractive auto-encoders: Explicit invariance during feature extraction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neighbourhood components analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning a non-linear embedding by preserving class neighbourhood structure</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI and Statistics</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semantic hashing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJAR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Using very deep autoencoders for content-based image retrieval</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<editor>ESANN. Citeseer</editor>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps and spectral techniques for embedding and clustering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="585" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The group lasso for logistic regression</title>
		<author>
			<persName><forename type="first">L</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Geer</surname></persName>
		</author>
		<author>
			<persName><surname>Bühlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="71" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Efficient and robust feature selection via joint l 21 -norms minimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The cmu pose, illumination, and expression (pie) database</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bsat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Face and Gesture Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002">2002. 2002</date>
			<biblScope unit="page" from="46" to="51" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">From few to many: Illumination cone models for face recognition under variable lighting and pose</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Georghiades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="643" to="660" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>Pattern Analysis and Machine Intelligence</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Face recognition using laplacianfaces</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="328" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>Normalized cuts and image segmentation</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Siskind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="675" to="690" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>Image segmentation with ratio cut</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Parallel spectral clustering in distributed systems</title>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="568" to="586" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Pattern Analysis and Machine Intelligence</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Combinatorial optimization: algorithms and complexity</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Steiglitz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Dover Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
