<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Myeongsu</forename><surname>Kang</surname></persName>
							<email>mskang@calce.umd.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">are with State Key Laboratory of Mechanical Transmission</orgName>
								<orgName type="institution">Chongqing University</orgName>
								<address>
									<postCode>400044</postCode>
									<settlement>Chongqing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Advanced Life Cycle Engineering</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Minghang</forename><surname>Zhao</surname></persName>
							<email>minghang.zhao@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">are with State Key Laboratory of Mechanical Transmission</orgName>
								<orgName type="institution">Chongqing University</orgName>
								<address>
									<postCode>400044</postCode>
									<settlement>Chongqing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Baoping</forename><surname>Tang</surname></persName>
							<email>bptang@cqu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">are with State Key Laboratory of Mechanical Transmission</orgName>
								<orgName type="institution">Chongqing University</orgName>
								<address>
									<postCode>400044</postCode>
									<settlement>Chongqing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Pecht</surname></persName>
							<email>pecht@calce.umd.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Center for Advanced Life Cycle Engineering</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">71A5AC3FF84D471B3D29C09612459BAA</idno>
					<idno type="DOI">10.1109/TIE.2018.2866050</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIE.2018.2866050, IEEE Transactions on Industrial Electronics IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS received September 18, 2017; revised February 5, 2018 and June 14, 2018; accepted August 5, 2018.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deep residual networks</term>
					<term>fault diagnosis</term>
					<term>feature learning</term>
					<term>multi-wavelet coefficients fusion</term>
					<term>planetary gearbox</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Wavelet transform, an effective tool to decompose signals into a series of frequency bands, has been widely used for vibration-based fault diagnosis in machinery. Likewise, the use of deep learning algorithms is becoming popular to automatically learn discriminative features from input data for the sake of improving diagnostic performance. However, the fact that no general consensus has been reached as to which wavelet basis functions are useful for diagnosis motivated this investigation of methods to fuse multi-wavelet transforms into deep learning algorithms. In this paper, two methods-i.e., multi-wavelet coefficients fusion in deep residual networks by concatenation (MWCF-DRN-C) and multi-wavelet coefficients fusion in deep residual networks by maximization (MWCF-DRN-M)-were developed to capture discriminative information from diverse sets of wavelet coefficients for fault diagnosis. The efficacy of the developed methods was verified by applying them to planetary gearbox fault diagnosis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>long-term generation of wind power, and the reliable operation of other related mechanical systems.</p><p>However, fault diagnosis of planetary gearboxes is often more challenging than fixed-shaft gearboxes, because the dynamic characteristics of planetary gearboxes are much more complicated. To be specific, the planet gears not only mesh with the sun gear, but also mesh with the ring gear simultaneously; the planetary gearboxes mostly have to operate together with other rotating components, such as fixed-shaft gearboxes and motors; and there may be irregular noises from the working environments, which make the vibration signals more complex. Furthermore, the operating conditions mostly change with time, so that even the vibration signals of the same health condition may also vary a lot. As a result, it is very difficult for the general signal processing (or envelope analysis) based fault detection methods to detect the defect frequency, and then diagnose the faults of planetary gearboxes accurately.</p><p>The state-of-the-art machine learning-based fault diagnosis methods can be classified into two categories: shallow learning vs. deep learning. In the shallow learning-based methods, feature construction based on statistical features (e.g., root-mean-square (RMS), kurtosis, and energy <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>) is an essential step. Then, the features are fed into shallow learning algorithms, such as support vector machines, neural networks, and decision trees, for the sake of fault diagnosis. The use of shallow learning algorithms with domain knowledge-based statistical features can be computationally more efficient than deep learning-based approaches. Likewise, monitoring the features can offer relatively direct health information about a target system, while learned features derived from deep learning algorithms may not. However, it is difficult and time-consuming to determine which features should be extracted, because an optimized set of features varies from case to case in industrial applications. Further, the fact that conventional shallow learning algorithms are not scalable for dealing with high-volume and high-dimensional data for fault diagnosis will be an issue.</p><p>Deep learning algorithms <ref type="bibr" target="#b4">[5]</ref> that automatically learn a good set of features from the monitoring data for diagnosis can be an effective way to address the above-mentioned disadvantages <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b14">[15]</ref>. For example, Jia et al. <ref type="bibr" target="#b5">[6]</ref> used deep auto-encoders to pre-train the deep neural networks, which achieved higher accuracies than shallow neural networks; Wang et al. <ref type="bibr" target="#b12">[13]</ref> applied convolutional neural networks (CNNs) to the time-frequency representations obtained by using continuous wavelet transform, which yielded higher accuracies than traditional shallow classifiers. Therefore, the feature learning ability of deep learning algorithms is a great benefit for fault diagnosis applications. However, training deep learning algorithms is often not an easy task. For example, traditional deep auto-encoders involve too many weights to be trained, and although convolutional neural networks (CNNs) adopt a weight sharing strategy to reduce the number of weights, back-propagating errors through multiple layers can result in exploding/vanishing gradient problems, which can be a primary cause of training failures. Additionally, most of the previous deep learning algorithms were not specifically designed for vibration-based fault diagnosis. Hence, to further improve diagnostic performance, it is necessary to explore new deep learning architectures. Time-frequency analysis can uncover the dynamic properties of non-stationary vibration signals. Various time-frequency analysis methods (e.g., short-time Fourier transform, wavelet transform, and empirical mode decomposition) have been used in vibration-based fault diagnosis. However, short-time Fourier transform only has a fixed resolution in the frequency domain, and empirical mode decomposition lacks a theoretical demonstration. Due to the merit of multi-resolution localization in detecting faults from gearboxes <ref type="bibr" target="#b15">[16]</ref>, wavelet transform <ref type="bibr" target="#b16">[17]</ref> was used in this study to generate time-frequency representations of vibration signal as the input of the deep learning method. To be specific, discrete wavelet packet transform (DWPT) was adopted, which can generate a series of matrices of wavelet packet coefficients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-wavelet Coefficients Fusion in</head><p>However, there is still no general consensus as to which wavelet can offer optimal performance for fault diagnosis. Furthermore, an optimal wavelet basis function can be varied depending on fault detection and diagnosis applications <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b19">[20]</ref>. For example, Ding and He <ref type="bibr" target="#b11">[12]</ref> employed a deep learning model for fault diagnosis of spindle bearings, which took a matrix containing wavelet packet energies as input. Specifically, the authors used a Daubechies 8 wavelet for DWPT. Wang et al. <ref type="bibr" target="#b12">[13]</ref> used a Morlet wavelet to generate time-frequency representations from the vibration signals and further applied a CNN to fault diagnosis, which took the time-frequency representations as input. Kang et al. <ref type="bibr" target="#b17">[18]</ref> used DWPT with a Daubechies 20 wavelet to decompose acoustic emission signals into a series of wavelet packet nodes and extract features from the nodes, such as relative wavelet packet node energies, for bearing fault diagnosis.</p><p>To address the aforementioned issue, wavelet selection <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref> and multi-wavelet coefficients fusion are two promising solutions. Here, the main objective of wavelet selection is to find an optimal wavelet for fault diagnosis. For example, Vakharia et al. <ref type="bibr" target="#b20">[21]</ref> used a criterion named as "maximum energy to Shannon entropy ratio" to specify an optimal wavelet for feature extraction. However, there is still a likelihood that an optimal wavelet specified by wavelet selection methods may not be effective for time-frequency representations for learning a discriminative set of features that will be used for planetary gearbox fault diagnosis under non-stationary operating conditions. This motivated us to learn a good set of features from time-frequency representations obtained by diverse wavelets and verify the effectiveness of the method to fuse multiple wavelet transforms into deep learning algorithms. That is, this paper aims to learn a good set of features from diverse wavelets. Furthermore, learning diverse features is vital for increasing the performance of deep learning methods <ref type="bibr" target="#b22">[23]</ref>, and the fusion of multi-wavelet coefficients into deep learning algorithms can enable learning diverse features. Therefore, this study can avoid the wavelet selection problem.</p><p>A deep residual network (DRN) <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref> is a state-of-the-art deep learning method. DRNs can automatically learn discriminative features from the input data. The difference between a DRN and the classical CNN is that the DRN uses identity skip-connections (ISCs) in the deep architecture to make the trainable parameters easier to be optimized. The DRN integrates many "tricks" for a better training of deep neural networks, such as momentum, batch normalization (BN), L2 regularization, and variance-scaling weight initialization. These tricks make it reliable and applicable to the experimental data with different properties. Therefore, the DRN has the potential to learn a good set of features from the input data and to correctly identify the health status of an object machine.</p><p>In this study, two multi-wavelet coefficients fusion methods within the DRN architecture were developed for fault diagnosis-multi-wavelet coefficients fusion in a DRN by concatenation (MWCF-DRN-C) and multi-wavelet coefficients fusion in a DRN by maximization (MWCF-DRN-M), respectively. The MWCF-DRN-C method concatenates a series of matrices of wavelet packet coefficients and takes a single concatenated matrix as an input, whereas the MWCF-DRN-M method re-designs the architecture of the DRN for the sake of multi-wavelet coefficients fusion. These methods can adaptively adjust the contribution of wavelet packet coefficients to fault diagnosis, with the goal of improving diagnostic performance. Likewise, these methods can learn better features for fault diagnosis than the state-of-the-art deep learning methods (i.e., CNN and DRN) taking a matrix of wavelet packet coefficients obtained from a certain wavelet basis function.</p><p>The reminder of this paper is organized as follows. Section II describes a simulation system to collect vibration signals under variable operating conditions used for planetary gearbox fault diagnosis. Section III delineates the inclusion of domain knowledge into the deep models-that is, MWCF-DRN-C and MWCF-DRN-M-and defines the input of the methods using multi-wavelet coefficients fusion. In Section IV, performance comparisons are conducted to verify the effectiveness of the developed methods for fault diagnosis, and the limitations are discussed. Section V gives conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. FAULT DESCRIPTION OF PLANETARY GEARBOXES</head><p>To verify the effectiveness of the developed methods, fault diagnosis of a planetary gearbox was considered. A drivetrain dynamics simulator was used to simulate the faults. The simulator was mainly composed of a 3-phase 3 HP motor, a 2-stage planetary gearbox with 192:7 gear ratio (including 4 planet gears in the 1 st stage and 3 planet gears in the 2 nd stage), a 2-stage parallel gearbox (with 29:100 gear ratio in the 1 st stage and 5:2 gear ratio in the 2 nd stage), and a programmable heavy duty magnetic brake (with a maximum torque of 65 lb•ft), as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. More information about the simulator can be found in <ref type="bibr" target="#b25">[26]</ref>. Vibration signals in the vertical direction were collected at 25.6 kHz using an accelerometer, which was mounted at the input side of the planetary gearbox.</p><p>This study considered nine health conditions of a planetary gearbox under non-stationary operating conditions, including 1 normal and 8 faulty statuses (i.e., bearing and gear defects), as summarized in Table <ref type="table" target="#tab_2">I</ref>. For each health condition, 12 16-s vibration signals were collected as the rotational speed of the motor linearly increased from 20 Hz to 36 Hz under three different torsional loads, as described in Table <ref type="table" target="#tab_2">II</ref>. In particular, each 16-s vibration signal was equally divided into 100 observations with each observation in the length of 4,096 samples. Therefore, the total number of observations was 1200 for each health condition, as presented in Table <ref type="table" target="#tab_2">II</ref>. Likewise, although each of the 0.16-s vibration signals already contained a certain level of noise, white Gaussian noise was artificially embedded into them to increase the level of difficulty in fault diagnosis. This is based on the assumption that the vibration signals can contain a higher level of noise in real-world vibration-based fault diagnosis applications; noise was added to the signals to enforce a signal-to-noise ratio of 5 dB. The average RMSs are shown in Table <ref type="table" target="#tab_2">I</ref> to illustrate the intensities of the faults under non-stationary operating conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. DEVELOPED METHODS FOR MULTI-WAVELET COEFFICIENTS FUSION IN A DRN</head><p>As stated in Section I, as a candidate solution to address the fact that no general consensus has been reached as to which wavelet function provides optimal diagnostic performance, multi-wavelet coefficients fusion is considered in this study. Accordingly, this section mainly discusses the essential idea behind the two developed methods, MWCF-DRN-C and MWCF-DRN-M, by presenting the theoretical background of a DRN and the design of DRN architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Input Data Configuration</head><p>As a classical multi-resolution analysis algorithm, DWPT <ref type="bibr" target="#b16">[17]</ref> enables a signal to be decomposed into two sets of wavelet coefficients, i.e., the approximation coefficients at a low-frequency band and the detail coefficients at a relatively high-frequency band. As indicated in Fig. <ref type="figure">2</ref>, the decomposition is then repeated recursively not only on the approximation coefficients but also on the detail coefficients, so that the information on various frequency bands can be revealed.</p><p>Mathematically, DWPT can be implemented using a series of convolutions with a pair of low-pass and high-pass filters <ref type="bibr" target="#b16">[17]</ref>. Specifically, the high-pass filter ℎ(•) and the low-pass filter 𝑔𝑔(•) such that 𝑔𝑔(𝑘𝑘) = (-1) 𝑘𝑘 ℎ(1 -𝑘𝑘) can be defined by:</p><formula xml:id="formula_0">ℎ(𝑘𝑘) = 1 √2 &lt; 𝜑𝜑(𝑡𝑡), 𝜑𝜑(2𝑡𝑡 -𝑘𝑘) &gt;<label>(1)</label></formula><formula xml:id="formula_1">𝑔𝑔(𝑘𝑘) = 1 √2 &lt; 𝜓𝜓(𝑡𝑡), 𝜓𝜓(2𝑡𝑡 -𝑘𝑘) &gt;<label>(2)</label></formula><p>where 𝜑𝜑(•) is a scaling function, 𝜓𝜓(•) is the corresponding wavelet function, &lt;•,•&gt; is an inner product, and 𝑡𝑡 and 𝑘𝑘 are variables. For a discrete 1-dimensional signal, its wavelet coefficients at various frequency sub-bands and decomposition levels can be calculated iteratively by:</p><formula xml:id="formula_2">𝑊𝑊 𝑖𝑖+1,2𝑗𝑗 (𝜏𝜏) = � ℎ(𝑘𝑘 -2𝜏𝜏)𝑊𝑊 𝑖𝑖,𝑗𝑗 (𝑘𝑘) 𝑘𝑘 (3) 𝑊𝑊 𝑖𝑖+1,2𝑗𝑗+1 (𝜏𝜏) = � 𝑔𝑔(𝑘𝑘 -2𝜏𝜏)𝑊𝑊 𝑖𝑖,𝑗𝑗 (𝑘𝑘) 𝑘𝑘<label>(4)</label></formula><p>where 𝑊𝑊 0,0 is the original discrete signal in the length of 𝑁𝑁, {𝑊𝑊 𝑖𝑖,𝑗𝑗 (𝑘𝑘), 𝑘𝑘 = 1,2, … , 𝑁𝑁/2 𝑖𝑖 } are the wavelet coefficients in the 𝑗𝑗th sub-band at the 𝑖𝑖th decomposition level, {𝑊𝑊 𝑖𝑖+1,2𝑗𝑗 (𝜏𝜏), 𝜏𝜏 = 1,2, … , 𝑁𝑁/2 𝑖𝑖+1 } and {𝑊𝑊 𝑖𝑖+1,2𝑗𝑗+1 (𝜏𝜏), 𝜏𝜏 = 1,2, … , 𝑁𝑁/2 𝑖𝑖+1 } are the wavelet coefficients in the (2𝑗𝑗)th and (2𝑗𝑗 + 1)th sub-bands at the (𝑖𝑖 + 1)th decomposition level, respectively, and 𝑗𝑗 ranges from 0 to 2 𝑖𝑖 -1 at the 𝑖𝑖th decomposition level.</p><p>As mentioned in Section I, previous research has found that the performance of the DWPT-assisted fault diagnosis applications was highly dependent on the selected wavelet functions <ref type="bibr" target="#b15">[16]</ref>. Aiming at this problem, a straightforward solution is to use multiple wavelet functions together for comprehensive time-frequency representations of vibration   Fig. <ref type="figure">2</ref>. An example of a 3-level decomposition tree of DWPT, where 𝑊𝑊 𝑖𝑖,𝑗𝑗 is the wavelet coefficients in the 𝑗𝑗 th sub-band at the 𝑖𝑖 th decomposition level. 𝑊𝑊 1,0 and 𝑊𝑊 1,1 are the approximation coefficients and detail coefficients of the original signal, respectively. 𝑊𝑊 2,0 and 𝑊𝑊 2,1 are the approximation coefficients and detail coefficients of 𝑊𝑊 signals. In this study, Daubechies wavelets were used as an example in the experiment since they were widely used in vibration-based fault diagnosis <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b18">[19]</ref>. However, it is notable that the developed methods are applicable to other wavelets, such as Symlet, Coiflet, Morlet, and so forth.</p><p>As depicted in Fig. <ref type="figure" target="#fig_1">3</ref>, the wavelet packet coefficients at different frequency bands obtained using a certain wavelet can be formed into a 2-dimensional (2D) matrix; then, the 2D matrices derived from different wavelets can be stacked together as a 3-dimensional (3D) matrix. Likewise, since the depth of DWPT was 6 (i.e., depth = 6) and the length of an observation was 4,096 in the experiment, the dimension of a 3D matrix of wavelet packet coefficients in this study was 𝑝𝑝 × 𝑞𝑞 × 𝑁𝑁 w = (4096/2 depth ) × (2 depth ) × 𝑁𝑁 w = 64 × 64 × 𝑁𝑁 w , where 𝑁𝑁 w is the number of selected wavelets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Background Theory of a DRN</head><p>A DRN can be interpreted as a model that is a stack of various components, including a convolutional layer, a series of residual building units (RBUs), a BN, a rectifier linear unit activation function (ReLU), a global average pooling (GAP), and a fully connected output layer <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. As shown in Fig. <ref type="figure" target="#fig_2">4</ref>(a), a RBU can be composed of two BNs, two ReLUs, two convolutional layers, and one ISC. A brief architecture of a DRN is shown in Fig. <ref type="figure" target="#fig_2">4(b)</ref>.</p><p>The convolutional layer is used to learn features, in which each convolutional kernel behaves as a trainable feature extractor. Compared with matrix multiplications in the traditional fully connected layers, the use of convolutions in convolutional layers enables reduction of the number of weights and computational complexity, which is expressed by:</p><formula xml:id="formula_3">𝑂𝑂 C (𝑖𝑖, 𝑗𝑗) = � � � 𝐼𝐼 C (𝑖𝑖 -𝑢𝑢, 𝑗𝑗 -𝑣𝑣, 𝑐𝑐) • 𝐾𝐾(𝑢𝑢, 𝑣𝑣, 𝑐𝑐) 𝑐𝑐 𝑣𝑣 𝑢𝑢 + 𝑏𝑏 (5)</formula><p>where 𝐼𝐼 C is the input feature map of a convolutional layer; 𝐾𝐾 is a convolutional kernel; 𝑏𝑏 is a bias; 𝑂𝑂 C is a channel of the output feature map; 𝑖𝑖, 𝑗𝑗, and 𝑐𝑐 are the indexes of row, column, and channel of the feature map, respectively; and 𝑢𝑢 and 𝑣𝑣 are the indexes of row and column of the convolutional kernel, respectively. Since a convolutional layer can have more than one convolutional kernels, more than one channel of output feature map can be obtained. In this study, convolutional kernels at a 3 × 3 size were used because they not only have a higher computational efficiency than larger kernels, but they can also be large enough to detect local maxima <ref type="bibr" target="#b26">[27]</ref>.</p><p>In each training iteration, a mini-batch of observations is randomly selected and fed into the DRN. However, the distributions of learned features in the mini-batches often continuously change in the training iterations, which is known as the internal covariance shift problem <ref type="bibr" target="#b27">[28]</ref>. In such a case, the weights and biases have to be continuously updated to adapt to the changed distributions. As a result, the training of deep networks can be challenging. BN <ref type="bibr" target="#b27">[28]</ref> is a kind of technique which is used to address this problem and is expressed by:</p><formula xml:id="formula_4">𝜇𝜇 = 1 𝑁𝑁 batch � 𝑥𝑥 𝑠𝑠 𝑁𝑁 batch 𝑠𝑠=1 (<label>6</label></formula><formula xml:id="formula_5">)</formula><formula xml:id="formula_6">𝜎𝜎 2 = 1 𝑁𝑁 batch � (𝑥𝑥 𝑠𝑠 -𝜇𝜇) 2 𝑁𝑁 batch 𝑠𝑠=1 (7) 𝑥𝑥 � 𝑠𝑠 = 𝑥𝑥 𝑠𝑠 -𝜇𝜇 √𝜎𝜎 2 + 𝜖𝜖<label>(8)</label></formula><p>𝑦𝑦 𝑠𝑠 = 𝛾𝛾𝑥𝑥 � 𝑠𝑠 + 𝛽𝛽 (9) where 𝑥𝑥 𝑠𝑠 is a feature of the 𝑠𝑠 th observation in a mini-batch, 𝑁𝑁 batch is the mini-batch size, 𝜖𝜖 is a constant value which is close to zero, and 𝑦𝑦 𝑠𝑠 is the output feature of BN. The input features are normalized to have a mean of 0 and a standard deviation of 1 in ( <ref type="formula" target="#formula_4">6</ref>), <ref type="bibr" target="#b6">(7)</ref>, and (8), so that the input features are enforced to have similar distributions; then, 𝛾𝛾 and 𝛽𝛽 are trained to scale and shift the normalized features to desirable distributions. The optimization of 𝛾𝛾 and 𝛽𝛽 is achieved using a gradient descent algorithm, which is expressed by: <ref type="bibr" target="#b10">(11)</ref> where 𝜂𝜂 is the learning rate, 𝐸𝐸 𝑠𝑠 is the error of the 𝑠𝑠 th observation. 𝑃𝑃𝑃𝑃𝑡𝑡ℎ_𝑟𝑟 and 𝑃𝑃𝑃𝑃𝑡𝑡ℎ_𝑏𝑏 are two collections of differentiable paths that connect 𝛾𝛾 and 𝛽𝛽 with the error at the output layer, respectively.</p><formula xml:id="formula_7">𝛾𝛾 ← 𝛾𝛾 - 𝜂𝜂 𝑁𝑁 batch � � 𝜕𝜕𝐸𝐸 𝑠𝑠 𝜕𝜕𝑃𝑃𝑃𝑃𝑡𝑡ℎ_𝑟𝑟 𝑘𝑘 𝜕𝜕𝑃𝑃𝑃𝑃𝑡𝑡ℎ_𝑟𝑟 𝑘𝑘 𝜕𝜕𝛾𝛾 𝑘𝑘 𝑠𝑠 (10) 𝛽𝛽 ← 𝛽𝛽 - 𝜂𝜂 𝑁𝑁 batch � � 𝜕𝜕𝐸𝐸 𝑠𝑠 𝜕𝜕𝑃𝑃𝑃𝑃𝑡𝑡ℎ_𝑏𝑏 𝑘𝑘 𝜕𝜕𝑃𝑃𝑃𝑃𝑡𝑡ℎ_𝑏𝑏 𝑘𝑘 𝜕𝜕𝛽𝛽 𝑘𝑘 𝑠𝑠</formula><p>The ReLU is used to achieve nonlinear transformations by enforcing the negative features to be zero. It is expressed by: 𝑂𝑂 R (𝑖𝑖, 𝑗𝑗, 𝑐𝑐) = max {𝐼𝐼 R (𝑖𝑖, 𝑗𝑗, 𝑐𝑐), 0} (12) where 𝐼𝐼 R and 𝑂𝑂 R are the input and output feature maps of the ReLU, respectively. The derivative of ReLU is expressed by:</p><formula xml:id="formula_8">𝜕𝜕𝑂𝑂 R (𝑖𝑖, 𝑗𝑗, 𝑐𝑐) 𝜕𝜕𝐼𝐼 R (𝑖𝑖, 𝑗𝑗, 𝑐𝑐) = � 1, if 𝐼𝐼 R (𝑖𝑖, 𝑗𝑗, 𝑐𝑐) &gt; 0 0, if 𝐼𝐼 R (𝑖𝑖, 𝑗𝑗, 𝑐𝑐) &lt; 0 (<label>13</label></formula><formula xml:id="formula_9">)</formula><p>Its derivative is either 1 or 0, which can reduce the risk of gradient vanishing and exploding compared with the sigmoid and tanh activation functions.</p><p>The ISCs are the key component that makes a DRN easier to train than the traditional CNNs. In the training process of traditional CNNs without ISCs, the gradients of error with  respect to the weights (and biases) need to be back-propagated layer by layer. For example, the gradients on the 𝑙𝑙 th layer are dependent on the weights at the (𝑙𝑙 + 1) th layer. If the weights at the (𝑙𝑙 + 1) th layer are not optimal, the gradients on the 𝑙𝑙 th layer cannot be optimal as well. As a result, it is difficult to effectively train the weights in a CNN with multiple layers.</p><p>ISCs solve this problem by directly connecting some convolutional layers to deeper layers, so that it can be easy for the gradients to be back-propagated through a deep network. In other words, the gradients can be back-propagated into the layers easier than the traditional CNNs, so that the weights and biases can be updated effectively. It has been shown that a DRN with tens or hundreds of layers can be easily trained and yield higher accuracies than the CNNs without ISCs <ref type="bibr" target="#b24">[25]</ref>.</p><p>A GAP was applied before the final fully connected output layer, which is expressed by: 𝑂𝑂 G (𝑐𝑐) = average</p><formula xml:id="formula_10">𝑖𝑖,𝑗𝑗 𝐼𝐼 G (𝑖𝑖, 𝑗𝑗, 𝑐𝑐)<label>(14)</label></formula><p>where 𝐼𝐼 G and 𝑂𝑂 G are the input and output feature maps of GAP, respectively. The GAP enables the shift variant problem to be addressed by calculating a global feature from each channel of the input feature map. In this study, the shift variant problem means that the fault-related impulses can exist in different locations in the observations, and the GAP can ensure that the DRN learns features which are invariant to the locations. The output feature maps of the GAP are fed to the fully connected output layer to pick up the classification results.</p><p>The training process of a DRN follows the same principle as the general neural networks. The training data are propagated into a DRN and processed while passing through a series of convolutional layers, BNs, and ReLUs followed by a GAP and a fully connected output layer. More specifically, at the fully connected output layer, a softmax function is used to estimate the possibility of an observation belonging to the classes <ref type="bibr" target="#b28">[29]</ref>, which is expressed by:</p><formula xml:id="formula_11">𝑦𝑦 𝑛𝑛 = 𝑒𝑒 𝑥𝑥 𝑛𝑛 ∑ 𝑒𝑒 𝑥𝑥 𝑧𝑧</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>𝑁𝑁 class 𝑧𝑧=1</head><p>, for 𝑛𝑛 = 1, … , 𝑁𝑁 class <ref type="bibr" target="#b14">(15)</ref> where 𝑥𝑥 𝑛𝑛 is the feature at the 𝑛𝑛 th neuron of the output layer, 𝑦𝑦 𝑛𝑛 is the output, which can be seen as the estimated possibility of an observation belonging to the 𝑛𝑛 th class, and 𝑁𝑁 class is the total number of classes. Then, the cross-entropy error, which measures the distance between the true label 𝑡𝑡 and the output 𝑦𝑦, can be calculated by:</p><formula xml:id="formula_12">𝐸𝐸(𝑦𝑦, 𝑡𝑡) = -� 𝑡𝑡 𝑛𝑛 ln (𝑦𝑦 𝑛𝑛 ) 𝑁𝑁 class 𝑛𝑛=1<label>(16)</label></formula><p>where 𝑡𝑡 𝑛𝑛 is the true possibility of the observation belonging to the 𝑛𝑛 th class. Note that the partial derivative of cross-entropy error with respect to the neurons at the fully connected output layer can be expressed by:</p><formula xml:id="formula_13">𝜕𝜕𝐸𝐸 𝜕𝜕𝑥𝑥 𝑛𝑛 = 𝑦𝑦 𝑛𝑛 -𝑡𝑡 𝑛𝑛<label>(17)</label></formula><p>Then, the error is back-propagated through the network to update the weights and biases, which are expressed by:  <ref type="bibr" target="#b18">(19)</ref> where 𝑤𝑤 is a weight, 𝑏𝑏 is a bias, and 𝑁𝑁𝑒𝑒𝑡𝑡_𝑤𝑤 and 𝑁𝑁𝑒𝑒𝑡𝑡_𝑏𝑏 are two collections of differentiable paths that connect the weight and bias with the neurons at the fully connected output layer, respectively. The training procedures can be repeated a certain number of times so that the parameters can be optimized. In summary, the parameters that need to be optimized while training include 𝛾𝛾 and 𝛽𝛽 in BNs and the weights and biases in the convolutional layers and the fully connected output layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Design of the Fundamental Architecture for DRNs</head><p>Deep learning models' architectures, including depth (i.e., the number of nonlinear transformation layers) and width (i.e., the numbers of kernels in the convolutional layers), are key factors that influence the models' performance, such as the test accuracy and computation time. Zoph and Le <ref type="bibr" target="#b29">[30]</ref> employed reinforcement learning for network architecture search, which was computationally expensive and used 800 graphics processing units to train the deep models with different hyperparameters. Suganuma et al. <ref type="bibr" target="#b30">[31]</ref> investigated a method using genetic programming to design deep networks. Despite such studies, neural network architecture optimization is a long-standing issue in the field-that is, there is still no general consensus as to how deep or wide the network should be.</p><p>The fundamental architecture of the DRN used in this study is pictorially illustrated in Fig. <ref type="figure" target="#fig_3">5</ref>. Likewise, the essential idea behind this architecture is described as follows. First, the architecture has 19 convolutional layers and 1 fully connected layer in depth. Note that it is important to contain a sufficient number of nonlinear transformation layers to ensure that the input data can be converted to be discriminative features. In previous studies conducted for vibration-and current-based fault diagnosis using deep learning, no more than 10 nonlinear transformation layers have been used <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b14">[15]</ref>. Considering the increased level of nonlinearity of the acquired data, the DRN contains more nonlinear transformation layers, where a nonlinear transformation layer stands for a convolutional layer with a nonlinear activation function (i.e., ReLU) in this study. As mentioned above, DRNs with tens or hundreds of layers can be easily trained due to the use of ISCs <ref type="bibr" target="#b24">[25]</ref>, so that the depth of the DRN architecture is in a reasonable range.</p><p>Then, the first convolutional layer (i.e., the layer closest to the input layer) and three convolutional layers in the RBUs, which have a stride of 2, are used to reduce the size of the feature maps. In Fig. <ref type="figure" target="#fig_3">5</ref>, 𝑚𝑚 indicates the number of convolutional kernels, which is increased to 2𝑚𝑚 and 4𝑚𝑚 in deeper layers because a few basic features can be integrated to be many different high-level features. 𝑚𝑚 is set to 4 in this study.</p><p>To further alleviate over-fitting, dropout <ref type="bibr" target="#b31">[32]</ref> with a ratio of 50% is applied to the GAP. In other words, half of the neurons in the GAP layer were randomly selected and set to be zero in each training iteration, which can be interpreted as a process of adding noise to the network, in order to prevent the DRN from memorizing too much non-discriminative information and ensure a high generalizability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Multi-wavelet Coefficients Fusion in a DRN</head><p>In this subsection, the motivations for developing multi-wavelet coefficients fusion methods are described, and the architectures of the two developed methods (MWCF-DRN-C and MWCF-DRN-M) are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Motivations of Multi-wavelet Coefficients Fusion</head><p>The faults on bearings and/or gears often produce relatively large amplitudes in the waveform of vibrations signals. For example, for a bearing with a crack on its inner race (see Fig. <ref type="figure" target="#fig_4">6(a)</ref>), there will be a sudden change of contact force every time a rolling ball passes over the crack, and the sudden change of contact force will create an impulse in the waveform, as indicated in Fig. <ref type="figure" target="#fig_4">6(b</ref>). For a bearing with a crack on its outer race, the rolling balls will strike on the crack and lead to impulses as well. Similarly, a broken tooth on a gear (see Fig. <ref type="figure" target="#fig_4">6(c)</ref>) can lead to a large amplitude every time the broken tooth meshes with the tooth of another gear, as indicated in Fig. <ref type="figure" target="#fig_4">6(d)</ref>.</p><p>Conventional signal processing-based fault diagnosis methods often rely on the detection of fault-related waveforms. For example, for a bearing rotating at a constant speed, the fault-related impulses will be generated periodically; if the time interval between the impulses matches the ball passing frequency of the inner race, it is possible to determine whether the bearing has a fault on its inner race. However, for large rotating machines with multi-stage gearboxes, the vibration signals are often composed of multiple components because of vibrations excited by the meshing of multi-stage gear transmissions, rotations of shafts and bearings, or environmental noise. For a rotating machine operating at varying rotating speeds, frequencies of these vibration components can be non-stationary. Moreover, when a fault is at its early stage, the fault-related information in the waveforms is not easily detected. As a result, the fault-related information can be overwhelmed by the other components, which makes the fault diagnosis a challenging task.</p><p>To deal with the non-stationary vibration signals, DWPT is employed to decompose the vibration signals into multiple sub-band signals. However, it is generally unknown which sub-band signal contains the most intrinsic information about the system's health conditions (i.e., normal and several faulty conditions). Likewise, because informative sub-band signals can be varied due to changes in operating conditions (e.g., rotating speeds), this study combines all the wavelet coefficients at each terminal node and uses them as input for the deep learning methods.</p><p>In general, different wavelets may be optimal for diagnosing different types of faults under different operating conditions, so that it is unlikely for a certain wavelet to be the most effective for diagnosing all types of faults in consideration (e.g., bearing inner race faults, outer race faults, ball faults, gear surface pits, and gear root cracks). Therefore, the fusion of multiple wavelets can improve the performance of a fault diagnosis task involving the classification of multiple fault types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) MWCF-DRN-C</head><p>The developed MWCF-DRN-C method is based on a well-known fact in deep learning-that is, learning diverse features is critical for increasing performance <ref type="bibr" target="#b22">[23]</ref>. The multi-wavelet coefficients fusion concept can be considered a promising way to introduce diversity into a DRN. To enable multi-wavelet coefficients fusion, one of the simplest methods is to concatenate all 2D matrices of wavelet packet coefficients and propagate them into the DRN.</p><p>As illustrated in Fig. <ref type="figure" target="#fig_5">7</ref>(a), a special design in MWCF-DRN-C is the use of a concatenation layer to combine multiple wavelet packet coefficients by forming a 𝑝𝑝 × 𝑞𝑞 × 𝑁𝑁 𝑤𝑤 matrix, where 𝑁𝑁 𝑤𝑤 is the number of wavelets in consideration and 𝑝𝑝 and 𝑞𝑞 are the dimensionality of a 2D matrix of wavelet packet coefficients (see Section III.A). Note that the concatenation layer does not have any parameter to be trained. Then, with the use of the concatenation layer, the first convolutional layer has more trainable weights that can be used for multi-wavelet coefficients fusion. To be specific, each convolutional kernel in the first convolutional layer of MWCF-DRN-C has 3 × 3 × 𝑁𝑁 w weights, while a convolutional kernel in the first convolutional layer of the DRN without multi-wavelet coefficients fusion only has 3 × 3 weights, where 3 × 3 indicates that the length and width of a convolutional kernel are both 3. This difference is caused by the nature of convolutional layers, i.e., the number of channels of a convolutional kernel has to be the same with the number of channels of input feature map. After a supervised training process, trainable weights and biases of the MWCF-DRN-C can be optimized to learn a discriminative set of features for accurate fault diagnosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) MWCF-DRN-M</head><p>The development of MWCF-DRN-M is closely related to the working principle of wavelet analysis in fault diagnosis. For fault detection of rotating machinery, wavelet analysis often works as a method to discover fault-related waveforms by generating very positive or negative wavelet packet coefficients. In other words, compared with the wavelet packet coefficients which are close to zero, very positive or negative wavelet packet coefficients are more likely to represent fault-related waveforms if the wavelet is effective in detecting the fault-related waveforms. However, for large rotating machineries with multi-stage gear transmissions, it is often unavoidable that some unimportant wavelet packet coefficients can have large absolute values as well, which is mainly caused by the other vibration components mentioned in section III.D.1.</p><p>Aiming at the above issues, an individual convolutional layer with trainable parameters is applied to each 2D matrix of wavelet packet coefficients with the goal of highlighting the fault-related wavelet packet coefficients, i.e., transforming the important wavelet packet coefficients to be large features. Then, motivated by the fact that it is unknown which wavelet can be the most effective in detecting the fault-related waveforms, the developed MWCF-DRN-M method uses a maximization layer <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b34">[35]</ref> to fuse the information from multiple wavelets (i.e., the output features of the individual convolutional layers). To be specific, the element-wise maximum values are taken as the output in the maximization layer.</p><p>The architecture of the developed MWCF-DRN-M is illustrated in Fig. <ref type="figure" target="#fig_5">7(b</ref>). The individual convolutional layers (which are applied to the 2D matrices of wavelet packet coefficients) and the maximization layer are special designs that differentiate the MWCF-DRN-M from the original DRN. The working principle of the special designs is further explained. Although the maximization layer is parameterless, the individual convolutional layers can make it to be a trainable process, which enable to adjust the values of the features before performing element-wise maximum feature selection. In this way, the developed MWCF-DRN-M can automatically learn which features to select for the sake of yielding high diagnostic accuracy. This alternative method facilitates the inclusion of physics-based knowledge into the DRN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head><p>The two developed methods-i.e., MWCF-DRN-C and MWCF-DRN-M-were implemented using TensorFlow 1.0.1, which is a machine learning library open-sourced by Google. Experimental comparisons were made with the classical CNN and DRN to verify the efficacy of the developed methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Hyperparameters Setup</head><p>The hyperparameters were set based on the setups in generic DRNs <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. The learning rate was initialized to 0.1 and reduced to 0.01 at the 40 th epoch and 0.001 at the 80 th epoch.</p><p>The training was terminated at the 100 th epoch, so that the trainable parameters could be updated in large steps at the beginning and slightly fine-tuned at the end of the training process. The coefficient of momentum <ref type="bibr" target="#b4">[5]</ref> was set to 0.9, which is used to accelerate the training process by making use of the update in the previous iteration. The mini-batch size was set to 128, which indicated that 128 observations were randomly selected and fed into the deep architecture in each iteration; the training process can be accelerated compared with feeding one observation in each iteration. The weight decay coefficient of L2 regularization was set to 0.0001, which was the same with the DRN in <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Performance Comparisons</head><p>In this section, the state-of-the-art deep learning algorithms without multi-wavelet coefficients fusion (i.e., CNN and DRN taking a matrix of wavelet coefficients using a certain Daubechies wavelet) were used for performance comparisons. A 10-fold cross-validation <ref type="bibr" target="#b4">[5]</ref> was conducted to evaluate the methods, that is, the dataset was randomly divided into 10 subsets. In each test, one subset was used as the testing data, and the other nine subsets were put together to be the training data. The tests were repeated 10 times, so that each subset has a chance to be the testing data. As a result, 10 accuracies can be obtained for each method, and their average value (i.e., the average accuracy) was used as the metric to evaluate the method. Experimental results of CNN, DRN, MWCF-DRN-C, and MWCF-DRN-M are given in Tables III-IV. The overall average accuracies are given in Table V and discussed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Performance comparison with CNN and DRN</head><p>As mentioned above, both CNN and DRN took a matrix of wavelet coefficients using a certain Daubechies wavelet, from DB1 to DB30. To ensure a fair and reliable comparison, the same hyperparameters mentioned above were adopted. As shown in Table <ref type="table" target="#tab_8">III</ref>, the DRN outperformed the CNN no matter which DB was used. The overall average test accuracy of the DRN with different DBs was 91.45%, which was 2.89% higher than CNN.</p><p>For the MWCF-DRN-C and MWCF-DRN-M methods, a multiple set of matrices of wavelet packet coefficients using 𝑁𝑁 w randomly selected Daubechies wavelets, from DB1 to DB30, where 𝑁𝑁 w = 2, 6, 10, 14, 18, 22, 26, and 30 were considered in this study (see Table <ref type="table" target="#tab_6">IV</ref>). The reason that the developed methods did not consider a full factorial design was to reduce computational burden. The same 10-fold cross-validation was employed in performance evaluation of the developed methods. As presented in Table <ref type="table" target="#tab_7">V</ref>, the developed MWCF-DRN-C yielded an overall average test accuracy of 92.84%, which achieved 4.28% and 1.39% improvements when compared with the CNN and DRN with no multi-wavelet coefficients fusion. Further, the developed MWCF-DRN-M achieved an overall average test accuracy of 93.64%, which yielded 5.08% and 2.19% improvements compared with the CNN and DRN, respectively.</p><p>To get a sense of the feature learning ability of the methods (i.e., CNN, DRN, MWCF-DRN-C, and MWCF-DRN-M), which further facilitates the improvement of fault diagnosis, the feature maps at four different layers were visualized using t-distributed stochastic neighbor embedding <ref type="bibr" target="#b35">[36]</ref>, which is an effective dimensionality reduction method to visualize high-dimensional data in a lower-dimensional feature space. The working effect of the deep learning methods is shown in          </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Performance comparison between MWCF-DRN-C and MWCF-DRN-M</head><p>As illustrated in Table <ref type="table" target="#tab_7">V</ref>, the MWCF-DRN-M method slightly outperformed the MWCF-DRN-C method, achieving 0.80% improvement in terms of test accuracy. The input indeed involves many redundant wavelet coefficients; the developed MWCF-DRN-M method effectively eliminated redundant information via the element-wise maximization operation and reduced the degree of complexity when optimizing trainable weights during the training process, whereas the MWCF-DRN-C method had to optimize the weights in the convolutional layer to eliminate the redundant information and its high-level features might still contain much redundant information even after the training process.</p><p>Figs. <ref type="figure" target="#fig_9">10(d</ref>) and 11(d) illustrate the high-level feature maps using the developed MWCF-DRN-C and MWCF-DRN-M in a lower-dimensional feature space, respectively. The "TRC" and "TSP" under the MWCF-DRN-M scheme were more agglomerated with themselves than under the MWCF-DRN-C scheme. This was the reason why the MWCF-DRN-M outperformed the MWCF-DRN-C in terms of test accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Discussion on the Limitations of the Developed Methods</head><p>However, a long-standing issue with machine learning-powered fault diagnosis applications is that they often need to deal with a new fault (or a new composition of multiple faults) that was not met before. According to the nature of supervised learning, the new fault would be misclassified into one of the classes in consideration during the training process. A promising solution to this problem is to develop a method to measure the degree of membership for unseen data, where the degree of membership can be defined as the probability that the unseen test data belongs to each of the classes in consideration. If none of the degrees is larger than a pre-defined threshold, the test data (e.g., a fault not met before) would be classified into an unknown class.</p><p>Another unsolved problem with machine learning-powered fault diagnosis applications is how to deal with the same faults with different intensities. Domain adaptation, which refers to a group of techniques that aim to improve the performance of a task by using the knowledge from a closely related domain, can probably be used to address this problem. For example, the difference between the distributions of the same fault at different intensities can be narrowed using some domain adaptation methods, so that a model trained on one intensity can correctly identify the fault under the other intensities.</p><p>Additionally, to apply the developed methods in industry, the following limitations at least need to be addressed. First, unsupervised and semi-supervised versions of the developed methods should be developed, because it is not easy to obtain labelled data. Second, the developed methods were trained on balanced datasets in this study. However, in general, deep learning algorithms often yielded relatively low performance on imbalanced datasets. Thus, it will be necessary to explore the impact of the developed methods on imbalanced datasets. If needed, the integration of generative adversarial network-based approaches into the developed methods will be investigated for the sake of balancing class distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS</head><p>This paper developed two methods to fuse multi-wavelet coefficients in DRNs and thus address the challenges in finding a good set of features for vibration-based fault diagnosis under non-stationary operating conditions. The MWCF-DRN-C method simply concatenated a series of 64 × 64 matrices of wavelet coefficients and used them as an input of the following convolutional layer in a DRN, whereas the MWCF-DRN-M method exploited a combination of the individual convolutional layers connected to 2D matrices of wavelet packet coefficients and the maximization layer at the early stage of a DRN to capture and amplify discriminative information from the input.</p><p>The usefulness of the developed methods was verified by performance comparisons in planetary gearbox fault diagnosis with state-of-the-art deep learning methods (i.e., CNN and DRN) with no multi-wavelet coefficients fusion concept. Experimental results indicated that the developed MWCF-DRN-C and MWCF-DRN-M methods outperformed the CNN-and DRN-based methods by yielding 4.28% and 5.08%, 1.39% and 2.19% performance improvements in terms of average test accuracy (10-fold cross-validation), respectively. These improvements were due to the use of diverse sets of wavelet coefficients with associated trainable weights to adjust the significance of wavelet coefficients for fault diagnosis.</p><p>Likewise, the MWCF-DRN-M method was superior to the MWCF-DRN-C method by slightly improving diagnostic performance-that is, 0.80% performance improvement in terms of average test accuracy. The MWCF-DRN-M method was effective for reducing redundancy in multiple 64 × 64 matrices of wavelet coefficients by a maximization layer, which further enabled the alleviation of DRN's burden to learn discriminative features. Although the MWCF-DRN-C reduced redundancy by applying trainable weights to multiple 64 × 64 matrices, optimizing these weights was not an easy task.</p><p>Further, the underlying structure of the developed methods can be applicable to various time-frequency analysis methods (e.g., local mean decomposition, empirical wavelet transform, and Wigner-Ville distribution), and data (e.g., vibration signals, current signals, and acoustic signals) for fault diagnosis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The drivetrain dynamics simulator used in this study.</figDesc><graphic coords="3,79.08,149.76,187.32,102.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. A series of 2D matrices of wavelet packet coefficients obtained using various Daubechies wavelets.</figDesc><graphic coords="4,60.84,232.68,223.92,144.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. (a) A RBU, (b) a brief architecture of a DRN, in which "Conv 3 × 3" refers to a convolutional layer with convolutional kernel size of 3 × 3.</figDesc><graphic coords="4,63.72,513.60,218.16,113.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5. A typical architecture of a DRN, in which m indicates the number of convolutional kernels, and "/2" is meant to move the convolutional kernels with a stride of 2.</figDesc><graphic coords="5,319.92,311.28,238.20,144.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. (a) Schematic diagram of a rolling element bearing with a crack on its inner race, in which the arrows denote rotating and moving directions, (b) an illustration of impulses due to the crack, (c) schematic diagram of a gear with a broken tooth, and (d) an illustration of the waveform generated by the faulty gear.</figDesc><graphic coords="6,80.40,254.64,184.80,127.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Architectures of (a) MWCF-DRN-C and (b) MWCF-DRN-M, in which a "2D matrix i" refers to a 2-dimensional matrix of wavelet packet coefficients obtained by using an i-tap Daubechies wavelet, abbreviated as DBi in this study, and N is the number of Daubechies wavelets in consideration. Both MWCF-DRN-C and MWCF-DRN-M have the same RBUs as the DRN in Fig. 5.</figDesc><graphic coords="7,48.96,618.84,514.68,93.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figs. 8 - 11 .</head><label>811</label><figDesc>It can be shown that observations of different health conditions at the input layer were highly agglomerated and became more and more separable at deeper layers for the CNN, DRN, MWCF-DRN-C, and MWCF-DRN-M; that is, these methods were effective for transforming the input data to be discriminative features through a series of nonlinear transformations. Likewise, the learned high-level features obtained by the MWCF-DRN-C and MWCF-DRN-M were more separable than those obtained by the CNN and DRN methods, as shown in Figs.8(d), 9(d), 10(d), and 11(d), and they were fed to the fully connected output layer to pick up classification results. For example, the learned features for "TRC" and "TSP" by the CNN and DRN overlapped each other, whereas the learned features by the developed methods had few overlapped points. Additionally, as shown in Figs.10(d) and 11(d), it can be observed that the composite fault "CFB" was also basically separable from the other health conditions, which means that the MWCF-DRN-C and MWCF-DRN-M are able to distinguish the composite fault from the other health states.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. 2D visualization of feature maps at 4 different layers in CNN with DB1, which yields an accuracy of 83.06%, (a) the input layer, (b) the 7 th convolutional layer, (c) the 13 th convolutional layer, (d) the GAP layer.</figDesc><graphic coords="8,319.92,362.04,238.08,90.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. 2D visualization of feature maps at 4 different layers in DRN with DB1, which yields an accuracy of 86.57%, (a) the input layer, (b) the 3 rd RBU, (c) the 6 th RBU, and (d) the GAP layer.</figDesc><graphic coords="8,319.92,480.84,238.08,90.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. 2D visualization of feature maps at 4 different layers in the MWCF-DRN-C with 30 DBs, which yields an accuracy of 92.69%, (a) the input layer, (b) the 3 rd RBU, (c) the 6 th RBU, and (d) the GAP layer.</figDesc><graphic coords="8,319.92,599.76,238.08,90.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. 2D visualization of feature maps at 4 different layers in the MWCF-DRN-M with 30 DBs, which yields an accuracy of 94.35%, (a) the input layer, (b) the 3 rd RBU, (c) the 6 th RBU, and (d) the GAP layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIE.2018.2866050, IEEE Transactions on Industrial Electronics</figDesc><table><row><cell>Deep</cell></row><row><cell>Residual Networks for Fault Diagnosis</cell></row><row><cell>Minghang Zhao, Myeongsu Kang, Member, IEEE, Baoping Tang, and Michael Pecht, Fellow</cell></row><row><cell>Member, IEEE</cell></row></table><note><p><p>P 0278-0046 (c) 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p>IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>0278-0046 (c) 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIE.2018.2866050, IEEE Transactions on Industrial Electronics</figDesc><table><row><cell>IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I A</head><label>I</label><figDesc>SUMMARY OF HEALTH STATES OF THE PLANETARY GEARBOX</figDesc><table><row><cell>Health status</cell><cell>Label</cell><cell>Description</cell><cell>RMS (m/s 2 )</cell></row><row><cell>Healthy</cell><cell>H</cell><cell>Healthy bearings and gears</cell><cell>1.00 ± 0.26</cell></row><row><cell></cell><cell>BFB</cell><cell>A ball fault in a bearing</cell><cell>1.54 ± 0.66</cell></row><row><cell></cell><cell>IFB</cell><cell>An inner race fault in a bearing</cell><cell>1.70 ± 0.82</cell></row><row><cell></cell><cell>OFB</cell><cell>An outer race fault in a bearing</cell><cell>1.86 ± 0.88</cell></row><row><cell>Faulty</cell><cell>CFB TRC</cell><cell>A composite fault of BFB, IFB, and OFB A tooth root crack on a gear</cell><cell>1.77 ± 0.86 1.60 ± 0.66</cell></row><row><cell></cell><cell>TSP</cell><cell>A tooth surface pitting on a gear</cell><cell>1.64 ± 0.68</cell></row><row><cell></cell><cell>TCF</cell><cell>A tooth chipped fault on a gear</cell><cell>1.01 ± 0.25</cell></row><row><cell></cell><cell>TMF</cell><cell>A tooth missing fault on a gear</cell><cell>1.61 ± 0.70</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE IV ACCURACIES</head><label>IV</label><figDesc>OF THE DEVELOPED MWCF-DRN-C AND MWCF-DRN-M METHODS WITH RANDOMLY SELECTED DB WAVELETS (UNIT: %)</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Training accuracy</cell><cell cols="2">Test accuracy</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>MWCF-DRN-C</cell><cell>MWCF-DRN-M</cell><cell>MWCF-DRN-C</cell><cell>MWCF-DRN-M</cell></row><row><cell># of randomly</cell><cell>selected Daubechies</cell><cell>wavelets</cell><cell>2 6 10 14 18 22 26 30</cell><cell>97.05 ± 0.69 98.42 ± 0.20 98.80 ± 0.22 98.95 ± 0.31 99.18 ± 0.17 99.36 ± 0.13 99.43 ± 0.16 99.47 ± 0.09</cell><cell>97.00 ± 0.66 97.80 ± 0.63 98.21 ± 0.23 98.38 ± 0.23 98.59 ± 0.20 98.55 ± 0.37 98.60 ± 0.21 98.69 ± 0.24</cell><cell>91.56 ± 1.49 93.07 ± 0.73 92.72 ± 1.03 93.10 ± 0.79 93.45 ± 0.85 93.01 ± 0.79 92.81 ± 0.78 93.01 ± 0.59</cell><cell>92.41 ± 0.83 93.57 ± 0.98 93.65 ± 0.93 93.80 ± 0.98 94.13 ± 0.45 93.74 ± 0.81 93.94 ± 0.97 93.88 ± 0.67</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE V COMPARISON</head><label>V</label><figDesc>OF THE OVERALL AVERAGE ACCURACIES IN</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE III AND</head><label>III</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE IV (</head><label>IV</label><figDesc>UNIT: %)</figDesc><table><row><cell>Method</cell><cell>Training accuracy</cell><cell>Test accuracy</cell></row><row><cell>CNN</cell><cell>91.44 ± 1.37</cell><cell>88.56 ± 1.61</cell></row><row><cell>DRN</cell><cell>96.59 ± 0.76</cell><cell>91.45 ± 1.08</cell></row><row><cell>MWCF-DRN-C</cell><cell>98.83 ± 0.25</cell><cell>92.84 ± 0.88</cell></row><row><cell>MWCF-DRN-M</cell><cell>98.23 ± 0.35</cell><cell>93.64 ± 0.83</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE III ACCURACIES</head><label>III</label><figDesc>OF THE CNN AND DRN USED FOR FAULT DIAGNOSIS OF THE PLANETARY GEARBOX (UNIT: %) This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIE.2018.2866050, IEEE Transactions on Industrial Electronics</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Training accuracy</cell><cell cols="2">Test accuracy</cell><cell></cell><cell cols="2">Training accuracy</cell><cell cols="2">Test accuracy</cell></row><row><cell></cell><cell></cell><cell>CNN</cell><cell>DRN</cell><cell>CNN</cell><cell>DRN</cell><cell></cell><cell>CNN</cell><cell>DRN</cell><cell>CNN</cell><cell>DRN</cell></row><row><cell></cell><cell>DB1</cell><cell>86.74 ± 2.34</cell><cell>94.98 ± 0.54</cell><cell>83.44 ± 3.01</cell><cell>88.41 ± 0.95</cell><cell>DB16</cell><cell>92.54 ± 1.38</cell><cell>97.09 ± 0.71</cell><cell>89.56 ± 1.96</cell><cell>91.97 ± 1.21</cell></row><row><cell></cell><cell>DB2</cell><cell>88.54 ± 1.03</cell><cell>96.31 ± 0.52</cell><cell>86.05 ± 1.50</cell><cell>90.57 ± 0.64</cell><cell>DB17</cell><cell>91.82 ± 1.53</cell><cell>97.04 ± 0.83</cell><cell>88.81 ± 1.58</cell><cell>92.03 ± 0.76</cell></row><row><cell></cell><cell>DB3</cell><cell>90.86 ± 2.00</cell><cell>96.78 ± 0.54</cell><cell>88.13 ± 1.83</cell><cell>91.21 ± 1.11</cell><cell>DB18</cell><cell>91.38 ± 0.92</cell><cell>96.69 ± 0.98</cell><cell>88.39 ± 1.39</cell><cell>92.18 ± 0.98</cell></row><row><cell>Daubechies wavelets</cell><cell>DB4 DB5 DB6 DB7 DB8 DB9 DB10 DB11 DB12</cell><cell>91.44 ± 1.57 91.70 ± 0.91 91.77 ± 1.60 91.88 ± 0.62 92.27 ± 1.44 92.28 ± 1.64 92.19 ± 0.58 91.83 ± 1.90 91.86 ± 0.84</cell><cell>96.92 ± 0.80 96.93 ± 1.01 97.15 ± 0.63 97.03 ± 0.80 97.32 ± 0.29 97.28 ± 0.49 96.78 ± 0.85 97.07 ± 0.90 97.01 ± 0.71</cell><cell>88.51 ± 1.50 89.01 ± 1.05 89.04 ± 1.72 89.17 ± 0.99 89.39 ± 1.78 89.45 ± 1.54 89.24 ± 1.16 88.43 ± 2.02 89.14 ± 1.06</cell><cell>91.26 ± 1.69 92.18 ± 0.96 91.76 ± 0.85 91.92 ± 0.97 92.93 ± 0.79 91.85 ± 0.84 91.77 ± 1.33 92.19 ± 1.31 92.07 ± 1.29</cell><cell>DB19 DB20 DB21 DB22 DB23 DB24 DB25 DB26 DB27</cell><cell>90.65 ± 2.81 91.62 ± 0.72 91.66 ± 1.22 92.13 ± 0.49 92.18 ± 1.31 92.14 ± 0.59 91.01 ± 1.60 91.88 ± 0.90 90.94 ± 2.05</cell><cell>96.38 ± 0.94 96.66 ± 0.77 96.16 ± 1.11 96.56 ± 1.04 96.22 ± 0.84 95.78 ± 0.89 96.69 ± 0.68 96.11 ± 0.79 95.96 ± 0.85</cell><cell>87.06 ± 3.21 88.53 ± 1.06 88.77 ± 1.53 89.33 ± 1.05 89.58 ± 1.42 89.18 ± 0.95 88.03 ± 1.65 89.12 ± 0.92 88.43 ± 2.16</cell><cell>91.37 ± 1.22 91.40 ± 0.87 91.20 ± 1.42 91.50 ± 0.95 91.62 ± 1.04 90.56 ± 1.12 91.57 ± 0.75 91.18 ± 0.97 90.79 ± 1.44</cell></row><row><cell></cell><cell>DB13</cell><cell>92.13 ± 1.61</cell><cell>96.88 ± 0.88</cell><cell>89.68 ± 1.47</cell><cell>91.87 ± 1.40</cell><cell>DB28</cell><cell>91.35 ± 0.42</cell><cell>96.36 ± 0.72</cell><cell>88.49 ± 0.92</cell><cell>91.05 ± 1.16</cell></row><row><cell></cell><cell>DB14</cell><cell>92.48 ± 1.33</cell><cell>97.05 ± 0.33</cell><cell>89.71 ± 1.66</cell><cell>92.02 ± 0.82</cell><cell>DB29</cell><cell>90.04 ± 4.05</cell><cell>96.31 ± 0.96</cell><cell>86.64 ± 3.69</cell><cell>90.81 ± 0.98</cell></row><row><cell></cell><cell>DB15</cell><cell>92.18 ± 1.09</cell><cell>96.71 ± 0.73</cell><cell>89.48 ± 1.52</cell><cell>91.94 ± 1.43</cell><cell>DB30</cell><cell>91.63 ± 0.60</cell><cell>95.42 ± 0.72</cell><cell>88.98 ± 1.08</cell><cell>90.26 ± 1.29</cell></row></table><note><p><p>0278-0046 (c) 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p>IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS</p></note></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Natural Science Foundation of China under Grant 51775065 and in part by the Technology Innovation Program (or Industrial Strategic Technology Development Program (10076392, Development of Vehicle Self Diagnosis System and Service for Automobile Driving Safety Improvement) funded by the Ministry of Trade, Industry and Energy, Korea).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Condition Monitoring and Fault Diagnosis of Planetary Gearboxes: A Review</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Measurement</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="292" to="305" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Structure Healthy Condition Monitoring and Fault Diagnosis Methods in Wind Turbines: A Review</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Renew. Sustain. Energy Rev</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="466" to="472" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Motor Bearing Fault Diagnosis Using Trace Ratio Linear Discriminant Analysis</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W S</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2441" to="2451" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Motor Bearing Fault Detection Using Spectral Kurtosis-Based Feature Extraction Coupled with K-Nearest Neighbor Distance Analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Morillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Azarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1793" to="1803" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deep</forename><surname>Learning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep Neural Networks: A Promising Tool for Fault Characteristic Mining and Intelligent Diagnosis of Rotating Machinery with Massive Data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mech. Syst. Signal Process</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">73</biblScope>
			<biblScope unit="page" from="303" to="315" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Real-Time Motor Fault Detection by 1-D Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ince</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kiranyaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Askar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="7067" to="7075" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An Intelligent Fault Diagnosis Method Using Unsupervised Feature Learning Towards Mechanical Big Data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="3137" to="3147" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Convolutional Discriminative Feature Learning for Induction Motor Fault Diagnosis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Informat</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1350" to="1359" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An Adaptive Multi-Sensor Data Fusion Method Based on Deep Convolutional Neural Networks for Fault Diagnosis of Planetary Gearbox</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An Adaptive Deep Convolutional Neural Network for Rolling Bearing Fault Diagnosis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Meas. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">95005</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Energy-Fluctuated Multiscale Feature Learning with Deep ConvNet for Intelligent Spindle Bearing Fault Diagnosis</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Instrum. Meas</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1926" to="1935" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Virtualization and Deep Recognition for System Fault Classification</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ananya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Manuf. Syst</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="310" to="316" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fault Diagnosis for Rotating Machinery Using Multiple Sensors and Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ASME Trans. Mechatron</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="101" to="110" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Deep Convolutional Neural Network with New Training Methods for Bearing Fault Diagnosis under Noisy Environment and Different Working Load</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mech. Syst. Signal Process</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="439" to="453" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Wavelets for Fault Diagnosis of Rotary Machines: A Review with Applications</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wavelets</forename><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<pubPlace>Boston, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Reliable Fault Diagnosis for Low-Speed Bearings Using Individually Trained Support Vector Machines with Kernel Discriminative Feature Analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Power Electron</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="2786" to="2797" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Detection of Weak Transient Signals Based on Wavelet Packet Transform and Manifold Learning for Rolling Element Bearing Fault Diagnosis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mech. Syst. Signal Process</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">55</biblScope>
			<biblScope unit="page" from="259" to="276" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A New Family of Model-Based Impulsive Wavelets and Their Sparse Representation for Rolling Bearing Fault Diagnosis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2716" to="2726" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Efficient Fault Diagnosis of Ball Bearing using ReliefF and Random Forest Classifier</title>
		<author>
			<persName><forename type="first">V</forename><surname>Vakharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Braz. Soc. Mech. Sci. &amp; Eng</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2969" to="2982" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Novel Criterion of Wavelet Packet Best Basis Selection for Signal Classification With Application to Brain-Computer Interfaces</title>
		<author>
			<persName><forename type="first">D</forename><surname>Vautrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Artusi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Farina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2734" to="2738" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Training Group Orthogonal Neural Networks with Privileged Information</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Joint Conferences on Artificial Intelligence</title>
		<meeting>International Joint Conferences on Artificial Intelligence<address><addrLine>Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08-25">19-25 August 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2016 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>2016 IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06-30">27-30 June 2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Identity Mappings in Deep Residual Networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th European Conference on Computer Vision</title>
		<meeting>14th European Conference on Computer Vision<address><addrLine>Amsterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-10-16">8-16 October, 2016</date>
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<ptr target="http://spectraquest.com/drivetrains/details/dds/" />
		<title level="m">Drivetrain diagnostics simulator</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Rethinking the Inception Architecture for Computer Vision</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 29th IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>29th IEEE Conf. Comput. Vis. Pattern Recognit<address><addrLine>Las Vegas, NA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-07-01">Jun. 26-Jul. 1, 2016</date>
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 32nd International Conference on Machine Learning</title>
		<meeting>32nd International Conference on Machine Learning<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07-09">7-9 July 2015</date>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning Criteria for Training Neural Network Classifiers</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="334" to="342" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Neural Architecture Search with Reinforcement Learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations</title>
		<meeting>International Conference on Learning Representations<address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04">April, 2017</date>
			<biblScope unit="page" from="24" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A Genetic Programming Approach to Designing Convolutional Neural Network Architectures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Suganuma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shirakawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nagao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the Genetic and Evolutionary Computation Conference</title>
		<meeting>the Genetic and Evolutionary Computation Conference<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-07-19">15-19 July 2017</date>
			<biblScope unit="page" from="497" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Maxout Networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 30th International Conference on Machine Learning</title>
		<meeting>30th International Conference on Machine Learning<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06-21">16-21 June, 2013</date>
			<biblScope unit="page" from="1319" to="1327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Channel-Max, Channel-Drop and Stochastic Max-Pooling</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshop</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. Workshop<address><addrLine>Boston, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06">June 2015</date>
			<biblScope unit="page" from="9" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A Deep Convolutional Neural Network Module that Promotes Competition of Multiple-Size Filters</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gustavo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="94" to="105" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Visualizing High-Dimensional Data Using t-SNE</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J P</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
