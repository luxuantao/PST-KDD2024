<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Flexible Syntactic Matching of Curves and Its Application to Automatic Hierarchical Classification of Silhouettes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yoram</forename><surname>Gdalyahu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science</orgName>
								<orgName type="institution">The Hebrew University</orgName>
								<address>
									<postCode>91904</postCode>
									<settlement>Jerusalem</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><roleName>Member, IEEE</roleName><forename type="first">Daphna</forename><surname>Weinshall</surname></persName>
							<email>daphna@cs.huji.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science</orgName>
								<orgName type="institution">The Hebrew University</orgName>
								<address>
									<postCode>91904</postCode>
									<settlement>Jerusalem</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Flexible Syntactic Matching of Curves and Its Application to Automatic Hierarchical Classification of Silhouettes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E9D5178B255891B487D4EFC7DCD67AD6</idno>
					<note type="submission">received 4 Jan. 1998; revised 19 Oct. 1999. Recommended for acceptance by K. Bowyer.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index TermsÐCurve matching</term>
					<term>syntactic matching</term>
					<term>image database</term>
					<term>silhouettes</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>AbstractÐCurve matching is one instance of the fundamental correspondence problem. Our flexible algorithm is designed to match curves under substantial deformations and arbitrary large scaling and rigid transformations. A syntactic representation is constructed for both curves and an edit transformation which maps one curve to the other is found using dynamic programming. We present extensive experiments where we apply the algorithm to silhouette matching. In these experiments, we examine partial occlusion, viewpoint variation, articulation, and class matching (where silhouettes of similar objects are matched). Based on the qualitative syntactic matching, we define a dissimilarity measure and we compute it for every pair of images in a database of 121 images. We use this experiment to objectively evaluate our algorithm: First, we compare our results to those reported by others. Second, we use the dissimilarity values in order to organize the image database into shape categories. The veridical hierarchical organization stands as evidence to the quality of our matching and similarity estimation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>G IVEN a large collection of images, unraveling its redundancies is an important and challenging task. One could use this knowledge to assist in image querying and to construct more efficient and compact image representations. In order to identify redundancy in the database, we propose the following approach: First, design algorithms to measure the similarity between images. Second, given pairwise image similarity, use similaritybased clustering to reveal the structure in the data by hierarchically dividing the images into distinct clusters. Third, identify redundancy in each cluster and use it to prune the database and pick cluster representatives; this would allow for efficient indexing into the database.</p><p>It is important to distinguish between our approach, where the clustering of x images uses only their x Â x similarity matrix, and the more typical approach, where images are first embedded in some h-dimensional vector space whose dimension should be significantly reduced using such methods as PCA. Mapping an image into such a space, in effect, requires the identification of h measurements (or ªfeaturesº) that completely describe the image. This has proven to be an elusive task. The task of image comparison, on the other hand, seems more within our reach: Rather than look for an explicit representation of images as vectors, we seek an algorithm (as complex as necessary) which receives as input two images and returns as output the similarity between them.</p><p>In this paper, we focus on the design of similarity measures, limiting ourselves to the shape dimension of similarity and ignoring other dimensions (e.g., color, motion, and context). The similarity is, therefore, defined as similarity between silhouettes. We describe our silhouette matching algorithm and show results of extensive experiments with real images. We then outline a stochastic clustering algorithm (described at length in <ref type="bibr" target="#b13">[14]</ref>) and argue that the good clustering results we show give objective evidence to the quality of our silhouette matching algorithm. The issue of database pruning, and how to identify within cluster redundancies to allow for efficient indexing into the database, is discussed in later work <ref type="bibr" target="#b20">[21]</ref>.</p><p>More specifically, we describe a novel flexible curve matching algorithm to relate between feature points that are automatically extracted on the boundaries of objects. Unlike most pattern recognition applications of clustering, we use real images of three-dimensional objects, basing our similarity measure on the shape of their occluding contours. Our algorithm is designed to give a graded similarity value, where low values reflect similarity between weakly similar curves and higher values indicate strong similarity. To illustrate, given two curves describing the shape of two different mammals, we consider our algorithm to be ªsuccessfulº if it matches their limbs and head correspondingly. The matched pairs of feature points are then aligned using an optimal 2D similarity transformation (translation, rotation, and scale). From the residual distances between corresponding features, we compute a robust dissimilarity measure between silhouettes. The matching algorithm is outlined in Section 3 and the resulting dissimilarity values are compared with those reported in the literature.</p><p>According to the general approach adopted in this paper, our next step is to feed the computed dissimilarities into a pairwise clustering algorithm to obtain hierarchical clusters of similar images. A pairwise clustering algorithm exploits only proximity information and, is therefore, suitable when vectorial representation of images is not available. Instead, the images are represented as nodes in a graph with edges whose weight reflect the similarity between every image pair. In <ref type="bibr" target="#b13">[14]</ref>, we describe our stochastic clustering algorithm, which is outlined in Section 4. Our algorithm determines the number of clusters in a (true) hierarchical manner and tolerates, to some extent, violations of metric properties (i.e., violation of the triangle inequality). We demonstrate perceptually veridical results using a database of 121 images of 12 different objects, which are hierarchically classified. The useful clustering results illustrate the quality of our matching algorithm and the usefulness of our general approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">CURVE MATCHING: PROBLEM AND RELATED WORK</head><p>Contour matching is an important problem in computer vision with a variety of applications, including model-based recognition, depth from stereo, and tracking. In these applications, the two matched curves are usually very similar. For example, a typical application of curve matching to model-based recognition would be to decide whether a model curve and an image curve are the same, up to some scaling or 2D rigid transformation and some permitted level of noise.</p><p>In this paper, we are primarily interested in the case where the similarity between the two curves is weak. The organization of silhouettes into shape categories (like tools, cars, etc.) necessitates flexible matching, which can support graded similarity estimation.</p><p>While our approach focuses on the silhouette boundary, a dual approach is based on its medial axis. Specifically, a medial axis, together with singularities labeling, form a shock graph representation, and matching shock graphs is an isomorphism problem. The methods for solving it includes semidefinite programming <ref type="bibr" target="#b37">[38]</ref>, replicator dynamics <ref type="bibr" target="#b31">[32]</ref>, graduated assignment <ref type="bibr" target="#b35">[36]</ref>, and syntactic graph matching <ref type="bibr" target="#b39">[40]</ref>. In some of these cases, the matching is only structural, while, in others, two levels of matching (structural and metrical) are supported. The methods based on shock graphs succeed in defining a graded similarity measure and may be combined with suitable database indexing <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b23">[24]</ref>. In this paper, we show, however, that our results are of the same quality in spite of using boundary representation, which is inherently less sensitive to occlusion and which does not involve the NP-complete graph isomorphism problem.</p><p>To put our method in the context of existing work on boundary matching, we first distinguish between dense matching and feature matching. Dense matching is usually formulated as a parameterization problem, with some cost function to be minimized. The cost might be defined as the ªelastic energyº needed to transform one curve to the other <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b9">[10]</ref>, but other alternatives exist <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b29">[30]</ref>. The main drawbacks of these methods are their high computational complexity (which is reduced significantly if only key points are matched) and the fact that they are usually not invariant under both 2D rotation and scaling. In addition, the computation of elastic energy (which is defined in terms of curvature) is scale dependent and requires accurate evaluation of second order derivatives.</p><p>Feature matching methods may be divided into three groups: proximity matching, spread primitive matching, and syntactic matching. The idea behind proximity matching methods is to search for the best matching while permitting the rotation, translation, and scaling (to be called alignment transformation) of each curve such that the distances between matched key points are minimized <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b44">[45]</ref>. Consequently, these methods are rather slow; moreover, if scaling is permitted, an erroneous shrinking of one feature set may result, followed by the matching of the entire set with a small number of features from the other set. One may avoid these problems by excluding many-to-one matches and by using the points order, but then the method becomes syntactic (see below). Moreover, we illustrate in Section 5.7.3 why proximity matching is not adequate for weakly similar curves. As an alternative to the alignment transformation, features may be mapped to an intrinsic invariant coordinate frame <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>; the drawback of this approach is that it is global, as the entire curve is needed to correctly compute the mapping.</p><p>Features can be used to divide the curves into shape elements or primitives. If a single curve can be decomposed into shape primitives, the matching algorithm should be constrained to preserve their order. But, in the absence of any ordering information (like in stereo matching of many small fragments of curves), the matching algorithm may be called ªspread primitive matching.º In this category, we find algorithms that seek isomorphism between attributed relational graphs <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b25">[26]</ref> and algorithms that look for the largest set of mutually compatible matches. Here, compatibility means an agreement on the induced coordinate transformation and a few techniques exist to find the largest set of mutually compatible matches (e.g., clustering in Hough space <ref type="bibr" target="#b38">[39]</ref>, geometrical hashing <ref type="bibr" target="#b24">[25]</ref>, and clique finding in an association graph <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b22">[23]</ref>). Note that, at the application level, finding isomorphism between attributed relational graphs is the same problem as finding isomorphism between shock graphs (discussed above), although, in the last case, an additional constraint may apply <ref type="bibr" target="#b31">[32]</ref>.</p><p>For our purpose of matching complex outlines, it is advantageous to use the natural order of primitives. This results in a great simplification and there is no need to solve the difficult graph isomorphism problem. Moreover, the relations encoded by the attributed relational graphs need to be invariant with respect to 2D image transformations and as a result they are usually nonlocal.</p><p>A syntactical representation of a curve is an ordered list of shape elements, having attributes like length, orientation, bending angle, etc. Hence, many syntactical matching methods are inspired by efficient and well-known string comparison algorithms, which use edit operations (substitution, deletion, and insertion) to transform one string to the other <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b45">[46]</ref>. The vision problem is different from the string matching problem in two major aspects, however: First, in vision, invariance to certain geometrical transformations is desired; second, a resolution degradation (or smoothing) may create a completely different list of elements in the syntactical representation.</p><p>There are no syntactic algorithms available which satisfactorily solve both of these problems. If invariant attributes are used, the first problem is immediately addressed, but then the resolution problem either remains unsolved <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b26">[27]</ref> or may be addressed by constructing, for each curve, a cascade of representations at different scales <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b43">[44]</ref>. Moreover, invariant attributes are either nonlocal (e.g., length that is measured in units of the total curve length) or they are noninterruptible (see discussion in Section 5.7). Using variant attributes is less efficient, but provides the possibility of defining a merge operator which can handle noise <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref> and might be useful (if correctly defined) in handling resolution change. However, the methods using variant attributes could not ensure rotation and scale invariance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FLEXIBLE SYNTACTIC CURVE MATCHING: ALGORITHM</head><p>In this section, we present a local syntactic matching method which can cope with both occlusion and irrelevant changes due to image transformation, while using variant attributes. These attributes support a simple smoothing mechanism, hence, we can handle true scale (resolution) changes. The algorithm is outlined in Section 3.1, while the missing details are given in Section 5. We are primarily concerned with the amount of flexibility that our method achieves since we aim to apply it to weakly similar curves. Section 3.2 shows extensive experiments with real images, where excellent matching is obtained between weakly similar shapes. We demonstrate silhouette matching under partial occlusion, under substantial change of viewpoint, and even when the occluding contours describe different (but related) objects, like two different cars or mammals. Our method is efficient and fast, taking only a few seconds to match two curves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Proposed Matching Method</head><p>The occluding contours of objects are first extracted from the image and a syntactic representation is constructed, whose primitives are line segments and whose attributes are length and absolute orientation. Our algorithm then uses a variant of the edit matching procedure combined with heuristic search. Thus, we define a novel similarity measure between primitives to assign cost to each edit operation, a novel merge operation, and introduce penalty for interrupting a contour (in addition to the regular deletion/insertion penalty A member f i Y H j g of É (abbreviated fiY jg for convenience) denotes a starting point for our syntactic matching algorithm. The algorithm uses edit operations to extend the correspondence between the remaining unmatched segments, preserving their cyclic order. Total cost is minimized using dynamic programming, where the cost of a match between every two segments depends on their attributes, as well as on the attributes of the initial chosen pair ( i and H j ). This implicitly takes into account the global alignment operation. The various edit operations and their cost functions are described in Section 5.3; the cost of the edit operations can be either negative or positive. 1  We are searching for the member fiY jg P É for which the extended correspondence list has minimal edit cost. Brute force implementation of this search is computationally infeasible. The syntactic matching process is, therefore, interlaced with heuristic search for the best initial pair in É. Namely, a single dynamic programming extension step is performed for the best candidate in É (possibly a different candidate in each extension matching step) while maintaining the lowest cost achieved by any of the sequences. When no candidate in É has the potential to achieve a lower cost, the search is stopped (see below).</p><p>The pseudocode in Fig. <ref type="figure" target="#fig_0">1</ref> integrates the components of our matching algorithm into a procedure which gets two syntactic representations and returns a segment correspondence and a dissimilarity value. The arrays which support the dynamic programming are not referenced in this pseudocode to increase its readability. We note that the procedure CURVE-MATCHING minimizes the edit cost, which is typically negative, thus, in effect, CURVE-MATCHING is maximizing the ªgainº of matching.</p><p>The procedure INITIALIZE performs the initial pruning of pairs of starting points and returns the set of candidates É sorted by increasing potential values (see below). Full description is given in Section 5.2. Its implementation performs a few syntactic matching steps for all xx H possible pairs and computes the intermediate edit cost corresponding to this partial matching. The minimal intermediate edit cost achieved by any of the candidates is returned as ost Ã and the candidate pair which achieves ost Ã is returned as fi Ã Y j Ã g.</p><p>The procedure PICK-CANDIDATE selects a particular member of É to be fed into the syntactic algorithm. To understand its operation, we need to define the concept of potential: For each candidate fiY jg that has been extended to a correspondence list of some length, we compute a lower bound on its final edit cost. This bound is based on the intermediate edit cost which has already been achieved and the cost of the best (lowest cost) possible matching of 1. Negative cost can be interpreted as positive ªgainº or ªreward,º Every matching prefix has a total (accumulated) cost, which should be as negative as possible. A prefix is never extended by a suffix with positive cost since this would increase the cost; hence, partial matching is achieved by leaving the last segments unmatched. Note that if all costs are negative, then the minimal cost must be obtained by matching all the segments of the shorter sequence, and if all costs are positive, then the minimal cost is trivially obtained by leaving all segments unmatched. The average cost value determines the asymptotic matching length for random sequences <ref type="bibr" target="#b12">[13]</ref>.</p><p>the remaining unmatched segments. We call this bound the potentil of the candidate fiY jg. The procedure PICK-CANDIDATE returns the member of É which has best (minimal) potential.</p><p>Technically, we store É as an ordered list sorted by increasing potential value. Each member of É is a candidate fiY jg and its current potential. The procedure PICK-CANDIDATE then returns the first member of É. The list É is initially sorted by INITIALIZE and its order is maintained by the procedure PREDICT-COST discussed below.</p><p>The search for the best candidate fi Ã Y j Ã g continues as long as there exists a candidate whose potential is lower than the best cost achieved so far (ost Ã ). It is implemented by the loop, which iterates as long as ost Ã b potentil. Note that ost Ã cannot increase and potentil cannot decrease during the search.</p><p>The procedure SYNTACTIC-STEP is the core of our algorithm. It is given as input two cyclically ordered sequences e f I Y F F F Y x g and e H f H I Y F F F Y H x H g, which are partially matched from position i of e and onward and from position j of e H and onward. It uses dynamic programming to extend the edit transformation between e and e H by one step. Since our editing cost operation typically takes negative values, the edit cost of fiY jg could become better (lower) than ost Ã . In this case, fi Ã Y j Ã g is set equal to fiY jg and ost Ã is set equal to the newly achieved edit cost (otherwise, fi Ã Y j Ã g and ost Ã remain unchanged). Sections 5.3 and 5.4 give the full description of the procedure SYNTACTIC-STEP.</p><p>Extending the editing sequence of fiY jg is likely to increase its potential, making it a less attractive candidate. This is because the potential of fiY jg is partially determined by a lower bound on the final edit distance between the yet unmatched segments and the edit operation just added can only tighten this bound by decreasing the number of unmatched segments. The procedure PREDICT-COST reestimates the final cost and corrects the potential of fiY jg. Since É is kept as an ordered list, PREDICT-COST pushes the candidate fiY jg down to maintain the order of the list. Section 5. <ref type="bibr" target="#b4">5</ref> gives full details of the potential estimation.</p><p>Assuming that the reader is familiar with conventional dynamic programming implementations, it is sufficient to describe the procedure TRACE as the procedure which reads the lowest cost path from the dynamic programming array. 2 When this procedure is applied to the array associated with the best candidate fi Ã Y j Ã g, the lowest cost editing sequence is obtained. In our implementation, in order to keep space complexity low, we keep just the last few rows and columns for each array. Hence, the prodecure TRACE needs to repeat the syntactic matching for the best pair fi Ã Y j Ã g. See Section 5.4 for a description of the dynamic programming implementation.</p><p>Finally, using the correspondence we found, we refine the global 2D alignment by minimizing the sum of residual distances between matched segments endpoints. The procedure DISSIMILARITY performs the minimization, and uses the residual distances to define a robust measure of dissimilarity between the curves (details in Section 5.6).</p><p>Our approach thus combines syntactic matching with a proximity measure (in this sense, our method resembles that of <ref type="bibr" target="#b0">[1]</ref>). That is, we establish feature correspondence using syntactic matching and then evaluate the dissimilarity according to the residual distances between matched points. We do not use the edit distance as a measure of dissimilarity, mainly due to the fact that this quantity depends on the somewhat arbitrary parameters of the edit operation and segment similarity, whereas, typically, the best matching result is not sensitive to these exact parameters. That is, the same matching is obtained for a range of edit parameter values, although the edit distance may be different. Another advantage to combining syntactic and proximity criteria is that, in many cases, the combination provides a mechanism for outliers removal, as is demonstrated in Section 5.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Matching Results</head><p>We now present a few image pairs and triplets together with the matching results, which demonstrate perceptually appealing matching. In Section 3.3 below, we apply our matching algorithm to a database of 31 silhouettes given to us by Sharvit and Kimia and compare our dissimilarity values to those reported in <ref type="bibr" target="#b35">[36]</ref>. Additional classification results will be presented in Section 4.2, using the matching of a few thousand image pairs, to provide indirect objective examination of the matching quality.</p><p>In all the experiments reported in this paper, we use the same parameter values (defined in Section 5): w I I, w P HXV, w Q VXH, and u R (with the exception of Fig. <ref type="figure">6</ref>, where u S). Each matching of an image pair took only a few seconds (see Section 4.2).</p><p>Fig. <ref type="figure">2</ref> shows two images of different objects. There is a geometrical similarity between the two silhouettes which has nothing to do with the semantic similarity between 2. Note, however, that using both positive and negative costs allows for partial matching, hence the path can terminate at any entry of the dynamical programming array and not necessarily at the last row or column.</p><p>them. The geometrical similarity includes five approximately vertical swellings or lumps (which describe the four legs and the tail). In other words, there are many places where the two contours may be considered locally similar. This local similarity is captured by our matching algorithm.</p><p>The two occluding contours of the two animals and the feature points were automatically extracted in the preprocessing stage. Corresponding points are marked in Fig. <ref type="figure">2</ref> by the same numbers. Hence, the tails and feet are nicely matched, although the two shapes are only weakly similar. The same matching result is obtained under arbitrarily large rotation and scaling of one image relative to the other. Fig. <ref type="figure" target="#fig_1">3</ref> demonstrates the local nature of our algorithm, namely, that partial matching can be found when objects are occluded. Since our method does not require global image normalization, the difference in length between the silhouette outlines does not impede the essentially perfect matching of the common parts. Moreover, the common parts are not identical (note the distance between the front legs and the number of ears) due to a small difference in viewpoint; this also does not impede the performance of our algorithm.</p><p>Fig. <ref type="figure" target="#fig_1">3</ref> also demonstrates outliers pruning using three images. In Fig. <ref type="figure" target="#fig_1">3b</ref>, there is a shadow between two of the leaves (pointed to by the arrow) and, as a result, the outline penetrates inward. The feature points along the penetration are (mistakenly) matched with features along the tail in Fig. <ref type="figure" target="#fig_1">3a</ref>, since the two parts are locally similar. However, we use the procedure of mapping the points of Fig. <ref type="figure" target="#fig_1">3a</ref> to Fig. <ref type="figure" target="#fig_1">3b</ref>, then to Fig. <ref type="figure" target="#fig_1">3c</ref> and back to Fig. <ref type="figure" target="#fig_1">3a</ref>. Only points which are mapped back to themselves are accepted as correct matches; these matches are marked by common numbers in Fig. <ref type="figure" target="#fig_1">3</ref>.</p><p>Figs. <ref type="figure" target="#fig_2">4</ref> and<ref type="figure">6</ref> show results when matching images taken from very different points of view. In Fig. <ref type="figure" target="#fig_2">4</ref>, two different views of the same object are matched and the method of iterative elimination of distances is demonstrated (see Section 5.6). Fig. <ref type="figure">6</ref> shows matching between three different cars, viewed from very different viewpoints and subjected to occlusion. Matching under a large perturbation of viewpoint can be successful as long as the silhouettes remain similar ªenough.º Note that preservation of shape under change of viewpoint is a quality that defines ªcanonicalº or ªstableº views. Stable images of 3D objects Fig. <ref type="figure">2</ref>. Qualitative matching between pictures of toy models of a horse and a wolf. Note the correct correspondence between the feet of the wolf to those of the horse and the correspondence between the tails. The results are shown without outliers pruning. In this example, all the features to which no number is attached had been merged, e.g., the segment 9-10 on the horse outline was matched with three segments on the wolf outline. were proposed as the representative images in an appearance based approach to object representation <ref type="bibr" target="#b46">[47]</ref>.</p><p>The last example (Fig. <ref type="figure">5</ref>), shows results with an articulated object, matching human limbs at different body configurations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Dissimilarity Measurements: Comparison</head><p>In this section, we use our matching algorithm to compute a dissimilarity value, as will be explained in Section 5.6. Good matching is essential for correct dissimilarity estimation, whose values we use for quantitative comparisons with other methods. We use the image database created by Sharvit et al. (see <ref type="bibr" target="#b35">[36]</ref>), which consists of 31 silhouettes of six classes of objects (including fish, airplanes, and tools).</p><p>In <ref type="bibr" target="#b35">[36]</ref>, 25 images were selected out of this database and their pairwise similarities were computed. The measure of quality was the number of instances (out of 25) in which the first, second, and third nearest neighbor of an image was found in its own class. We follow the same procedure and show, in Table <ref type="table" target="#tab_1">1</ref>, the dissimilarity values which we obtain for 25 silhouettes. 3  We find that the fraction of times (out of 25) that the first nearest neighbor of an image belongs to its own class is 25/25, namely, it is always the case. For the second and third nearest neighbors, the results are 21/25 and 19/25. 4  In comparison, the results reported in <ref type="bibr" target="#b35">[36]</ref> are 23/25, 21/25, and 20/25, respectively, whereas our results for their choice of 25 images are the fractions 25/25, 20/25, and 17/25, respectively. It is to be noted, however, that, in the framework of <ref type="bibr" target="#b35">[36]</ref>, one can use additional information, specifically, whether the two graphs that represent a pair of shapes have similar topology.</p><p>We conclude that the two methods are comparable in quality when isolated silhouettes are matched. This is in spite of our using boundary representation, whereas symmetry representation (shock graph) is used in <ref type="bibr" target="#b35">[36]</ref>. The shock graph representation is inherently more sensitive to occlusions, while shock graph matching requires solving the difficult NP-complete graph isomorphism problem (see Section 1). Moreover, our method can easily be adjusted to handle open curves by avoiding the assumption that the syntactic representation is cyclic. On the other hand, shock graphs must distinguish between interior and exterior.</p><p>Recently, progress has been made toward computing the edit distance between shock graphs <ref type="bibr" target="#b39">[40]</ref> using a polynomial time algorithm that exploits their special structure. So far, however, the algorithm is not capable of dealing with invariance to image transformations and no quantitative measures have been reported.   <ref type="table" target="#tab_1">1</ref> shows, we have at least four images in each class. In <ref type="bibr" target="#b35">[36]</ref>, the same images were chosen with the exception that one of the classes consisted of only three images, while the fish class contained five images. However, for members of a class consisting of only three images, the three nearest neighbors can no longer be all in the same class. Hence, we slightly modified the choice of selected images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">As Table</head><p>4. This demostrates the limitation of syntatic curve matching for shape recognition as, in some case, objects have similar bounding curves but different interior regions.</p><p>The next step in our approach involves feeding a graph of image similarity values, computed by the silhouette matching algorithm, to a similarity-based clustering algorithm. By hierarchically dividing the images into distinct clusters, we discover structure in the data. To this end, we developed a stochastic clustering algorithm <ref type="bibr" target="#b13">[14]</ref>, whose full description is beyond the scope of this paper. Instead, we give below a brief review of the algorithm, showing clustering results which demonstrate the usefulness of our approach and the quality of the matching results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Stochastic Clustering Algorithm</head><p>We represent the image database as a graph, with nodes representing the images and similarity values assigning weights to the edges. Every partition of the nodes into r disjoint sets is an r-way cut in the graph and the edges which connect between different sets of nodes are said to cross the cut. The value of a cut is the sum of the weights of all crossing edges.</p><p>Our clustering method induces a probability distribution over the set of all r-way cuts in the graph, with a known lower bound on the probability of the minimal cut. Under this distribution over cuts, we compute, for every two nodes u and v in the graph, their probability p r uv of being in the same component of a random r-way cut.</p><p>The partition of the nodes into disjoint sets, which satisfies p r uv `HXS for every crossing edge uY v, is the output of our clustering algorithm for scale level r r I F F F x. At level r I all the nodes must be in one cluster and, as r is increased, the partitions undergo a series of bifurcations. The ªinterestingº bifurcation points, which account for meaningful data clustering, can be clearly distinguished from the others. This is a major advantage of our algorithm over deterministic agglomerative methods.</p><p>Our clustering method is robust and efficient, running in yx log P x time for sparse graphs and yx P logx for complete graphs. It does not require that the similarity values obey metric relations, hence it is suitable for the present application where the similarity provided  by our matching algorithm does not necessarily satisfy the triangle inequality. 5   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Clustering Results</head><p>We now integrate the two steps of similarity estimation and pairwise clustering into one experiment of image database categorization. The database contains 121 images of 12 different objects; 90 of the images were collected by placing six toy models on a turntable so that the objects could be viewed from different viewpoints. The other images are the 31 silhouettes discussed in Section 3.3. For each of the six toy models, we collected 15 images by rotating them in azimuth</p><formula xml:id="formula_0">5 ÀPH Y ÀIH Y H Y IH Y PH and elevation (9 ÀIH Y H Y IH ).</formula><p>We used models of a cow, wolf, hippopotamus, two different cars, and a child.</p><p>The central images 5 9 H in each of the three groups of pictures of animal models are side views (i.e., four legs, head, and tail are visible). All the different 15 images of each animal model are somewhat similar in that the same parts are visible (though, in some pictures, some parts, such as two legs or a leg and a tail, are merged into one in the silhouette). Thus, there is weak geometrical similarity between all the 45 silhouettes of the three mammals and there is weak geometrical similarity between the 30 different silhouettes of the two cars. A desirable shape categorization procedure should reveal this hidden hierarchical structure.</p><p>All the images were automatically preprocessed to extract the silhouettes of the objects and represent them syntactically (see Section 5.1). The dissimilarities between the silhouettes are estimated using the algorithm described in Section 3.1. In order to compare all the image pairs in our database of 121 images, we performed 7,260 matching assignments; this took about 10 hours on an INDY R4400 175Mhz workstation (about 5 seconds per image pair, on average).</p><p>The dissimilarity matrix constitutes the input to the clustering algorithm outlined above. When the scale parameter r is varied, the hierarchical classification shown in Fig. <ref type="figure" target="#fig_5">7</ref> is obtained. At the highest level r I, all the images belong to a single cluster. As r is increased, finer structure emerges. Note that related clusters (like the two car clusters) split at higher r values, which means that our dissimilarity measure is continuous, assigning low (but reliable) values to weakly similar shapes.</p><p>Since humans can do so, we assume that an ideal shape classifier can put the images of every object in a different class. It is hard to test this hypothesis since, as humans, we cannot ignore the semantic meaning of the shapes. Nevertheless, comparing with the ideal human perceptual classification, our finest resolution level is almost perfect, with only two classification errors (in the boxes marked by Ã) and the undesirable split of the fish cluster.</p><p>5. This would also be the case had we used the generalized Hausdorff distance or the normalized edit distance <ref type="bibr" target="#b28">[29]</ref>. The violation of metric properties is also known to exist in the function underlying our human notion of similarity between both semantic and perceptual stimuli <ref type="bibr" target="#b42">[43]</ref>. Our categorization is obtained using only intrinsic shape information. The relative size, orientation, and position of the silhouettes within each category is arbitrary. Moreover, global information, like the length of the occluding contour or the area it encloses, is not used. Hence, we expect that moderate occlusion will not affect the classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">FLEXIBLE SYNTACTIC MATCHING: DETAILS</head><p>In this section, we give the details of the various procedures and steps involved in the curve matching algorithm, outlined in Section 3.1. Contour representation is discussed in Section 5.1. The initial pruning of candidate global alignments is discussed in Section 5.2, where we describe the procedure INITIALIZE. The syntactic edit operations which are used by SYNTACTIC-STEP, and their respective costs, are discussed in Section 5.3. The details of the dynamic programming procedure, which SYNTACTIC-STEP uses to minimize the edit distance, are given in Section 5.4. In Section 5.5, we define the potentials which are used to guide the search for best starting point and describe the procedure PREDICT-COST. Finally, the procedure DISSIMILARITY is discussed in Section 5.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Preprocessing and Contour Representation</head><p>In the examples shown in this paper, objects appear on dark background and segmentation is successfully accomplished by a commercial k-means segmentation tool. A syntactic representation of the occluding contour is then automatically extracted: It is a polygon whose vertices are either points of extreme curvature or points which are added to refine the polygonal approximation. Thus, the primitives of our syntactic representation are line segments and the attributes are length and absolute orientation. The number of segments depends on the chosen scale and the shape of the contour, but typically it is around 50. Coarser scale descriptions may be obtained using merge operations.</p><p>Feature points (vertices) are initially identified at points of high curvature, according to the following procedure: At every contour pixel p, an angle &amp; is computed between two vectors u and v. The vector u is the vectorial sum of m vectors connecting p to its m neighboring pixels on the left and the vector v is similarly defined to the right. Points where &amp; is locally minimal are defined as feature points. The polygonal approximation (obtained by connecting these points by straight lines) is compared with the original outline. If the distance between the contour points to the polygonal segments is larger than a few pixels, more feature points are added to refine the approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Global Alignment: Pruning the Starting Points</head><p>The procedure INITIALIZE receives two cyclic sequences e and e H of lengths x and x H , respectively, as defined in Section 3.1. Initially, there are xx H possible starting points for the syntactic matching procedure; recall that each starting point corresponds to the matching of one segment i in e to another segment j in e H , thus defining the global 2D alignment between the two curves. However, the number of successful starting points is much smaller than xx H and they tend to correspond to similar global 2D alignment transformations for two reasons: 1) Low cost transformations tend to be similar since any pair of segments f i Y H j g, which belongs to a good correspondence list, is likely to be a good starting point for the syntactic algorithm. 2) The overall number of good starting points tends to be small since most of the pairs in e Â e H cannot be extended to a low cost correspondence sequence; the reason is that it might be possible to find a random match of short length, but it is very unlikely to successfully match long random sequences.</p><p>These observations are used by the procedure INITI-ALIZE to significantly reduce the number of candidate starting points. The procedure uses as a parameter the number t of edit operations which are performed for every one of the xx H possible starting points (in our experiments we use t S or 10). The pruning proceeds using the relation between starting points and global 2D alignments, as follows:</p><p>Every starting point f i Y H j g is associated with a global 2D alignment and, in particular, with a certain rotation angle that maps the direction of i to that of H j . Let n be minxY x H , and observe the distribution of the n rotation angles which achieved the best n edit distances after t steps. If these angles are distributed sharply enough around some central value , we conclude that is a good estimator for the global rotation. Then, we discard every starting point in e Â e H whose associated rotation is too far from . The remaining set of candidates is the set É (see Fig. <ref type="figure" target="#fig_7">8</ref>).</p><p>For each candidate that remains in É, the procedure INITIALIZE computes its future potential, as discussed in Section 5.5, and sorts the list É by increasing potential values. The minimal edit distance (cost) that has been achieved during the first t steps is returned as ost Ã and the candidate possessing this cost is returned as fi Ã Y j Ã g.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Syntactic Operations Which Determine the Edit Distance</head><p>The goal of classical string edit algorithms is to find a sequence of elementary edit operations which transform one string into another at a minimal cost. The elementary operations are substitution, deletion, and insertion of string symbols. Converting the algorithm to the domain of vision, symbol substitution is interpreted as matching two shape primitives and the substitution cost is replaced by the dissimilarity between the matched primitives. The dissimilarity measure is discussed in Section 5.3.1. Novel operations involving gap insertion and the merging of primitives are discussed in Sections 5.3.2 and 5.3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Similarity Between Primitives</head><p>We now define the similarity between line segments k and H l . The cost of a substitution operation is this value with a minus sign. Hence, the more similar the segments are, the lower their substitution cost is. We denote the attributes of k Y H l Ðorientation and lengthÐby Y and H Y H , respectively. The ratio between the length attributes is denoted relative scale a H .</p><p>The term ªreference segmentsº refers to the starting point segments which implicitly determine the global rotation and scale that aligns the two curves (as discussed above). The reference segments are specified by the argument fiY jg in the call to the procedure SYNTACTIC-STEP and are denoted here H Y H H . The segment similarity also depends on the corresponding attributesÐorientation, length, and relative scaleÐof the reference segments: <ref type="figure"></ref>and<ref type="figure">H H a H</ref> H . We first define the component of similarity which is determined by the length (or relative scale) attribute of two matching segments. We map the two matched pairs of length values fY H g and f H Y H H g to two corresponding directions in the Y H -plane and measure the angle between these two directions. The cosine of twice this angle is the length-dependent component of our measure of segment similarity (Fig. <ref type="figure" target="#fig_6">9</ref>). This measure is numerically stable. It is not sensitive to small scale changes nor does it diverge when H H a H H is small. It is measured in intrinsic units between ÀI and I. The measure is symmetric so that the labeling of the contours as ªfirstº and ªsecondº has no effect.</p><formula xml:id="formula_1">H Y H , H H Y H H ,</formula><p>Let be the angle between the vectors Y H and H Y H H . Our scale similarity measure is:</p><formula xml:id="formula_2">Y H j H Y H</formula><p>H os P R H P À I P H À I P I P H I X I Thus, depends explicitly on the scale values and H rather than on their ratio, hence, it cannot be computed from the invariant attributes a H and H a H H . The irrelevance of labeling can be readily verified since</p><formula xml:id="formula_3">Y H ÀI Y ÀI</formula><p>H X We next define the orientation similarity between two line segments whose attributes are and H , respectively. The relative orientation between them is measured in the trigonometric direction (denoted 3 H ) and compared with the reference rotation ( H 3 H H ):</p><formula xml:id="formula_4">Y H j H Y H H os 3 H À H 3 H H X P</formula><p>As with the scale similarity measure, the use of the cosine introduces nonlinearity; we are not interested in fine similarity measurement when the two segments are close to being parallel or antiparallel. Our matching algorithm is designed to be flexible in order to match curves that are only weakly similar; hence, we want to encourage segment matching even if there is a small discrepancy between their orientations. Similarly, the degree of dissimilarity between two nearly opposite directions should not depend too much on the exact angle between them. On the other hand, the point of transition from acute to obtuse angle between the two orientations seems to have a significant effect on the degree of similarity and, therefore, the derivative of is maximal when the line segments are perpendicular. Finally, the combined similarity measure is defined as the weighted sum:</p><formula xml:id="formula_5">w I Y Q</formula><p>The positive weight w I (which equals 1 in all our experiments) controls the coupling of scale and orientation similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Gap Opening</head><p>In string matching, the null symbol ! serves to define the deletion and insertion operations using 3 ! and ! 3 , respectively, where denotes a symbol. In our case, denotes a line segment and ! is interpreted as a ªgap element.º Thus, 3 ! means that the second curve is interrupted and a gap element ! is inserted into it to be matched with . Customarily, we define the same cost for both operations, making the insertion of into one sequence equivalent to its deletion from the other. The cost of interrupting a contour and inserting $ connected gap elements into it (that are matched with $ consecutive segments on the other curve) is defined as w Q À w P Á $, where w P Y w Q are positive parameters. Thus, we assign a penalty of magnitude w Q for each single interruption, which is discounted by w P for every individual element insertion or deletion. This predefined quantity competes with the lowest cost (or best reward) that can be achieved by $ substitutions. A match of $ segments whose cost is higher (less negative) than w Q À w P Á $ is considered to be poor and, in this case, the interruption and gap insertion is preferred.</p><p>In all our experiments, we used w P HXV and w Q VXH. (These values were determined in an ad hoc fashion and not by systematic parameter estimation, which is left for future research). These numbers make it possible to match a gap with a long sequence of segments as required when curves are partially occluded. On the other hand, isolated gaps are discouraged due to the high interruption cost. Our algorithm, therefore, uses deletions in cases of occlusion,  while, for local mismatches, it uses the merging operation, which is described in Section 5.3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Segment Merging</head><p>One advantage of using variant attributes (length and absolute orientation), is that segment merging becomes possible. We use segment merging as the syntactic homologue of curve smoothing, accomplishing noise reduction by local resolution degradation. Segment merging, if defined correctly, should simplify a contour representation by being able to locally and adaptively change its scale from fine to coarse.</p><p>We define the following merging rule: Two adjacent line segments are replaced by the line connecting their two furthest endpoints. If the line segments are viewed as vectors oriented in the direction of propagation along the contour, then the merging operation of any number of segments is simply their vectorial sum. 6 The cost of a merge operation is defined as the dissimilarity between the merged segment and the one it is matched with. A comparison of this rule with the literature in given in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Minimizing Edit Cost via Dynamic Programming</head><p>Procedure SYNTACTIC-STEP is given as input two cyclically ordered sequences e f I Y F F F Y x g and e H f H I Y F F F Y H x H g, which are partially matched from position i of e and onward, and from position j of e H and onward. It uses dynamic programming to extend the edit transformation between e and e H by one step. The edit operations and their cost functions were discussed above in Section 5.3.</p><p>The notation used in Section 3.1 hides, for simplicity, the workspace arrays which are used for path planning. Let us assume that the procedure SYNTACTIC-STEP can access an array which corresponds with the starting point fiY jg. The entry "Y # holds the minimal cost that can be achieved when the " segments of e following i are matched with the # segments of e H following H j . We will see later that it is not necessary to keep the complete array in memory.</p><p>A syntactic step is the operation of getting an array which is partially filled, and extending it by filling some of the missing entries. Our choice of extension is called ªblock completion.º Let us assume for simplicity that the reference segments fiY jg are the first ones. There is no loss of generality here since the order in eY e H is cyclic. Initially, the computed portion of the array corresponds to a diagonal block whose two corners are IY I and "Y #. When the procedure SYNTACTIC-STEP is applied to , it extends by filling in another row (of length #) and/or another column (of length ").</p><p>The decision whether a row or a column is to be added depends on the previous values of and is related to the potential computation that is discussed below in Section 5.5. Roughly speaking, we add a row (column) if the minimum of is in the last computed row (column) and we add both if the minimum is obtained in the last computed corner.</p><p>When extending the block of size " Â #, every new entry kY l is computed according to the following rule:</p><formula xml:id="formula_6">kY l minfr I Y r P Y r Q gY R</formula><p>where</p><formula xml:id="formula_7">r I min YP fY À kY lg r P min H``k fY l w Q À w P Á k À g r Q min H``l fkY w Q À w P Á l À gX</formula><p>xy denotes the vectorial sum of the segments x IY F F F Y y, and the domain is defined below. Unlike in the ªclassicalº editing algorithm, the term r I is computed over a domain , generalizing the simple substitution operation to the substitution of merged segments. We define as a triangular subregion of which contains uu À IaP entries (Fig. <ref type="figure" target="#fig_0">10</ref>). Namely:</p><formula xml:id="formula_8">fY j H ` `kY H ` `lY k À l À ug</formula><p>and the computation of r I involves uu À IaP evaluations of alternatives merges. The minimal value of u is 2, which is the ªclassicalº substitution (diagonal) step.</p><p>The minimization domains for r P and r Q are illustrated in Fig. <ref type="figure" target="#fig_0">10</ref> by the horizontal and vertical dashed lines, generalizing the single element deletion operation to the deletion of $ elements. This operation is associated with an interruption penalty w Q and a guaranteed reward w P $, which competes with the reward of substitutions.</p><p>We note that, in order to find the minimal value for r P along the vertical line, it is not necessary to compare all its k possible values. It is sufficient to keep one index ( H ) for each column l, such that</p><formula xml:id="formula_9">r P H Y l w Q À w P k À H X</formula><p>The initial value of H is 1 and after entry kY l has been evaluated, the value of H should be set to k if kY l H Y l À w P k À H X A similar argument applies to the computation of r Q . Hence, both the computation of r P and r Q have complexity yI.</p><p>Finally, according to the block completion scheme of the array defined above, it is easily verified that only the last uaP rows and columns of the block need to be stored in memory. On the other hand, if only these entries are kept, the complete path cannot be restored after the minimal edit cost is found. Hence, in our implementation, the procedure TRACE (see Section 3.1) repeats the syntactic procedure for the array possessing the best result, while keeping all of it in memory. It then follows the best path, which ends at the entry that achieved minimal edit cost, and returns it as the final matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Potential: Bounding the Edit Distance</head><p>In order to guide the search for the best starting point, which is interlaced with the syntactic steps, it is necessary to bound the final minimal cost of a partially computed matching.</p><p>6. Implementation note: It turns out to be more convenient to keep, for every line segment, the attributes Y sin Y os instead of Y . It is straightforward to express the orientation similarity using the new attributes (and is, of coarse, unaffected). The advantage is that merging segments does not involve the computation of any trigonometric functions. Thus, after merge, using the input attributes i Y sin i Y os i we define x i i os i and y i i sin i , and, then, x P y P p , sin xa and os ya.</p><p>We use a tight lower bound on the edit cost estimation, termed ªpotential.º The optimality of the search is thus guaranteed. In this section, we define the potential function and explain how it is used by the procedure PREDICT-COST.</p><p>Let us consider an entry kY l in the dynamic programming array . Without loss of generality, due to the cyclic segment order, we can assume that the forward path leaving this entry lies in the rectangular block defined by the corners kY l and xY x H . We define and to be the dimensions of this rectangle: minx À kY x H À l and mxx À kY x H À l. We also define to be the maximal similarity between segments ( I w I from (3)). The lowest cost substitution thus has the negative cost À, which acts as a reward.</p><p>The values of the parameters w I Y w P Y w Q are chosen to guarantee that a diagonal path consisting of the lowest cost substitutions has the minimal possible cost. 7 Hence, the lowest cost forward path originating from kY l must contain a diagonal segment of maximal length, namely of length . The cost assigned with this part is À. In addition to the diagonal part, the forward path may contain a vertical or horizontal part of length À . In general, this part can decrease the cost only if w Q À w P À is negative. However, in the case where the value of kY l is set equal to r P or r Q in (4), it is the case that the entry kY l is already considered to be inside a gap. In this case, we can first extend the gap by À moves and only then continue with diagonal steps. Thus, the interruption penalty is avoided, and the forward path cost becomes À À w P À . Combining this bound with the value of kY l, we get a lower bound f kl on the minimal edit cost which can be achieved passing through kY l:</p><formula xml:id="formula_10">f kl kY l À minfHY w Q À w P À g if kY l r I in R kY l À À w P À if kY l r P Y r Q in RX V X</formula><p>We refer to f kl as an entry potential and define the potential of the array as the minimum over active entry potential. An entry is active if there is a future path computation that will use its value. Hence, the entries occupying the last uaP rows and columns of the evaluated block are active.</p><p>The procedure PREDICT-COST receives as input a candidate pair of starting points segments denoted fiY jg. It computes its potential, which is the potential of the array associated with this pair (evidently, the procedure must access the dynamic programming array ). The procedure PREDICT-COST then updates the list É with the new potential value. In our implementation, we keep the list É sorted by increasing potentials and the procedure PREDICT-COST places the candidate fiY jg in its proper position after computing its potential.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Computing Curve Similarity After Matching</head><p>When the line segments are syntactically matched, the procedure DISSIMILARITY transforms the residual distances between their endpoints into a robust dissimilarity value. We may use the edit distance itself, but this quantity has two drawbacks. It depends on the somewhat arbitrary parameters of the edit operations (whereas, typically, the best matching result is not sensitive to these parameters) and it decreases without bound with increasing edited length. Normalizing the edit distance with respect to the curve length is not a trivial task <ref type="bibr" target="#b28">[29]</ref>.</p><p>Instead of the minimal edit distance, we use its corresponding matching sequence to compute a robust proximity measure. A closed form expression for the similarity transformation (rotation, translation, and scale) that minimizes the sum of squared distances between matched point sets is given in <ref type="bibr" target="#b47">[48]</ref>. Applying this transformation to our matched points refines the alignment that was assumed during matching since, at that time, the alignment was chosen from a finite set of xx H candidates. After optimal alignment, we define the dissimilarity d to be equal to the kth shortest residual distance, where k I P minxY x H . In the case of complete matching, the number of matched features is minxY x H and d becomes the median of the residual distances. The median is known to be a robust estimator since it is not affected by extreme outliers. When many feature points are left unmatched, as happens when the two curves are not similar, d becomes larger than the median (since k is defined by the total numbers of points, x and x H ). This increases our dissimilarity measure, reflecting the fact that the matching is partial. If the number of matched features is smaller than k, the dissimilarity is defined to be I.</p><p>We also report on two other techniques which we have found useful for identifying and removing outliers. The first is iterative elimination: In every iteration, the matched pairs that are most distant (after optimal 2D alignment) are eliminated and the rest are realigned. We chose to eliminate IH percent of the pairs at every iteration. The motivation is Fig. <ref type="figure" target="#fig_0">10</ref>. The entry kY l is updated according to (4). Solid lines represent merge steps (with the ªclassicalº substitution as a special case). Dashed lines represent the interruption and deletion of $ connected elements.</p><p>7. A sufficient condition is that w P `aP IwI P . If w Q is nonzero, it is sufficient that w P À aP `wQ ax, where x is the largest possible diagonal path, namely x minxY x H . the following: Features are matched when the local pieces of curve around them have similar shape; if, after alignment, they are also proximal, meaning that they agree with the global alignment, then the match is likely to be correct.</p><p>The other pruning technique can be used when three related images are available (rather than two). Assume that a feature point p on contour 1 is matched with point p H on contour 2 and p H is matched with p HH on contour 3. If the matching between 1 and 3 supports the mapping between p and p HH , then the correspondence list (p 6 p H , p H 6 p HH , p 6 p HH ) is accepted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Discussion and Comparison to Other Methods</head><p>Below we discuss some issues relating to complexity, invariance, and direct proximity computation. A detailed comparison of our syntactic operations to other methods is given in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7.1">Complexity</head><p>The algorithm develops jÉj dynamic programming arrays and, when it terminates, each array has been completed up to a block of some size. Let n P be the average number of entries in a completed block. The total number of computed entries is, therefore, jÉjn P . Clearly, n is a fraction of x. From the considerations discussed in Section 5.2, it follows that jÉj is typically of the order of x as well. It is possible, although not used here, to constrain the procedure INITIALIZE to return a set É of size minxY x H exactly. The overall number of computed entries is, therefore, yx Q .</p><p>Every single entry computation is of complexity yu P since uu À IaP alternative evaluations are required to compute r I in <ref type="bibr" target="#b3">(4)</ref>. Note that u is usually a small constant (we used u R). An entry computation is followed by updating the array potential. We maintain for each row and column the best score achieved there, hence, the array potential is computed in yu time after a block is completed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7.2">How to Achieve Invariance</head><p>Available syntactic matching methods usually achieve scale and rotation invariance (if at all) by using invariant attributes. The benefit of using invariant attributes is efficiency. The drawback is that invariant attributes cannot be smoothed by merging and they are either nonlocal or noninterruptible. For example, in <ref type="bibr" target="#b26">[27]</ref>, the orientation of a line segment is measured with respect to its successor, hence, the opening of a gap between segments introduces ambiguity into the representation (see Fig. <ref type="figure" target="#fig_0">11</ref>). In <ref type="bibr" target="#b15">[16]</ref>, the attributes which describe curve fragments are Fourier coefficients and, in <ref type="bibr" target="#b0">[1]</ref>, an attribute called ªsphericityº is defined. Both are invariant attributes but noninterruptible. 8   Moreover, it seems to be impossible to find operators on invariant attributes that are equivalent to smoothing in real space. Instead, a cascade of different scale representations must be used <ref type="bibr" target="#b43">[44]</ref>, where a few fragments may be replaced by a single one which is their ªancestorº in a scale space description. This requires massive preprocessing, building a cascade of syntactical representations for each curve with consistent fragment hierarchy.</p><p>In contrast, our algorithm is invariant with respect to scaling, rotation, and translation without relying on invariant attributes, while remaining efficient and capable of comparing complex real image curves in a few seconds. Furthermore, a novel merging operation was defined which accomplished curve simplification and helped in noise reduction and resolution change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7.3">Direct Proximity Minimization</head><p>The conversion of residual distances into a dissimilarity measure is explained in Section 5.6. The reader may wonder why we can't choose a proximity criterion, like the average distance between matched points or the Hausdorff distance, and minimize it directly. The Hausdorff distance may appear to be especially attractive since it is not based on any prior feature pairing <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b18">[19]</ref>.</p><p>We claim that direct minimization, which is heavily studied in the literature, is not adequate when the curves are only weakly similar. The reason is that proximity methods treat curves as two sets of points and ignore more qualitative ªstructuralº information.</p><p>An example is shown in Fig. <ref type="figure" target="#fig_8">12</ref>. In this example, we compare two weakly similar curves, where a permissible alignment transformation includes translation, rotation, and uniform scaling. Assuming that two sets of feature points have been extracted from the two curves, we investigate the proximity measure which is defined as the average distance between matched points. This measure is larger for the alignment shown in Fig. <ref type="figure" target="#fig_8">12c</ref> than for the one shown in Fig. <ref type="figure" target="#fig_8">12d</ref>. Hence, a proximity algorithm, which seeks the optimal alignment that achieves minimal residual distances, will consider Fig. <ref type="figure" target="#fig_8">12d</ref> as a better alignment than Fig. <ref type="figure" target="#fig_8">12c</ref>. 9  8. The Fourier coefficients are normalized individually, which means that if every fragment undergoes a different rigid or scaling transformation, the representation remains unchanged. The sphericity representation behaves in the same way. The relative size and orientation information is preserved as long as the sequence is not interrupted since overlapping fragments are used. Note that, in spite of this property, the algorithms are applied to partial matching in the framework of model-based recognition, since the solution that preserves the correct relative size and orientation information between primitives remains a valid solution and the danger of finding an undesired solution (as is demonstrated in Fig. <ref type="figure" target="#fig_0">11</ref>) is small. 9. Note that the lower proximity value in Fig. <ref type="figure" target="#fig_8">12d</ref> is not the result of the use of different global scaling since the shorter curve appears in Fig. <ref type="figure" target="#fig_8">12c</ref> and Fig. <ref type="figure" target="#fig_8">12d</ref> at the same size. Moreover, the lower proximity measure of Fig. <ref type="figure" target="#fig_8">12d</ref> is obtained even though many-to-one matches are avoided and the order of points is kept. Without these constrainst, it is easy to get arbitrarily small proximity values for an arbitrary correspondence by shrinking one set of points and matching it with only a few points (or even a single point) from the other set. Fig. <ref type="figure" target="#fig_0">11</ref>. When the primitive attribute is measured relative to a preceding primitive, interrupting the sequence creates problems. Here, for example, the orientation information is lost when the dotted segment is matched with a gap element. As a result, the two contours may be matched almost perfectly to each other and considered as very similar.</p><p>We continue with the previous example and investigate instead the use of the directed Hausdorff distance as the proximity criterion. The directed Hausdorff distance from a point set to a point set is defined (with the Euclidean norm jj Á jj) as: h Y mx pP min qP jjp À qjj; it is equal to the largest distance from some point in to its nearest neighbor in . This measure is asymmetric and, therefore, the symmetric expression mxfh Y Y hY g is often preferred. However, when there is large image clutter, as in our case, the symmetric distance is not useful since its value is determined by the irrelevant part of the curve. Thus, the directed distance, measured from the shorter curve to the longer one, is larger for the alignment shown in Fig. <ref type="figure" target="#fig_8">12c</ref> than for the one shown in Fig. <ref type="figure" target="#fig_8">12d</ref>. A proximity algorithm that is based on minimizing the directed Hausdorff distance will consider Fig. <ref type="figure" target="#fig_8">12d</ref> as a better alignment than Fig. <ref type="figure" target="#fig_8">12c</ref>.</p><p>In contrast, because it uses local structure, our syntactic matching algorithm provides the correct matching of the curves in Fig. <ref type="figure" target="#fig_8">12c</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>This paper deals with the inherently ill-posed problem of matching weakly similar curves for the purpose of similarity estimation. Our flexible syntactic matching is based on a simple heuristic, guided by the principle that matched features should lie on locally similar pieces of curve. Naturally, this principle cannot guarantee that the results would always agree with our human intuition for ªgoodº matching, but our examples demonstrate that satisfactory and intuitive are usually obtained. In addition, we successfully passed two more objective tests: 1) In a database of 31 images we showed that nearest neighbors, computed according to our distance, are always of the same type; 2) in a database of 121 images, clustering based on our similarity results gave perceptually veridical hierarchical structure. Note that ªsuccessfulº matching depends on the application at hand. Our method is not suitable for recovering depth from stereo, but it is well-suited for more qualitative tasks, such as the organization of an image database, the selection of prototypical shapes, and image morphing for graphics or animation.</p><p>In order to achieve large flexibility, we introduced a nonlinear measure of similarity between line segments which is not sensitive to either very small or very large differences in their scale and orientation. Our specific choice of segment similarity, combined with a novel merging mechanism and an improved interruption operation, add up to a robust and successful algorithm. The most important properties of our algorithm, which make it advantageous over other successful matching algorithms, are its relatively low complexity, its locality, which allows us to deal with occlusions, and its invariance to 2D image transformations.</p><p>We demonstrated excellent results, matching similar curves under partial occlusion, matching similar curves where the curves depict the occluding contours of objects observed from different viewpoints, and matching different but related curves (like the silhouettes of different mammals or cars). Furthermore, in a classification task using our algorithm to precompute image pair similarity, the clustering algorithm detected all the relevant partitions. This kind of database structuring could not have emerged without the reliable estimation of the dissimilarities between weakly similar images. Hence, the classification tree is an indirect and objective evidence for the quality of our matching method.</p><p>Note that, according to the appearance, based approach to object recognition, an object is represented by a collection of images which, in some sense, span the image space of that object. Our method can be used to divide the appearances of an object into clusters of similar views in order to assist the construction of an appearance based representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX SYNTACTIC OPERATIONS: COMPARISONS A How to Measure Similarity</head><p>Local and scale invariant matching methods usually use the normalized length a H . For example, the ratio between normalized lengths a H H a H H is used in <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref> (with global normalization, the difference jav À H av H j can be used <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b43">[44]</ref>). The ratio between normalized lengths may be viewed as the ratio between the relative scale a H and the reference relative scale H H a H H . While this scale ratio is invariant, unlike our measure, it is not bounded and is thus less stable. We are familiar with only one other definition of a symmetric, bounded, and scale invariant measure for segment length similarity <ref type="bibr" target="#b25">[26]</ref>. However, their matching algorithm is not syntactic and is very different from ours. In addition, there is an important qualitative difference between the two definitions (see Fig. <ref type="figure" target="#fig_9">13</ref>), where our measure is more suitable for flexible matching.</p><p>As for our measure of orientation difference, we note that a linear measure of orientation differences has been widely used by others <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>. The nonlinear measure used by <ref type="bibr" target="#b25">[26]</ref> differs from ours in exactly the same way as discussed above concerning length.</p><p>Reminiscent of our combined similarity measure (3), in <ref type="bibr" target="#b32">[33]</ref> a coupled measure is used: The segments are superimposed at one end and their dissimilarity is proportional to the distance between their other ends. However, this measure is too complicated for our case, and it has the additional drawback that it is sensitive to the arbitrary reference scale and orientation (in the character recognition task of <ref type="bibr" target="#b32">[33]</ref>, it is assumed that characters are of the same scale and properly aligned).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B How to Open Gaps</head><p>All the syntactical shape matching algorithms that we are familiar with make use of deletions and insertions as purely local operations, as in classical string matching. That is, the cost of inserting a sequence of gaps into a contour is equal to the cost of spreading the same number of gap elements in different places along the contour. We distinguish the two cases since the first typically arises from occlusion or partial matching, while the second arises typically from curve dissimilarity. In order to make the distinction, we adopt a technique frequently used in protein sequence comparison, namely, we assign a cost to any event of contour interruption, in addition to the (negative) cost from deletion/insertion of any single element.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C How to Merge Segments</head><p>A similar approach to segment merging (Section 5.3.3) was taken in <ref type="bibr" target="#b43">[44]</ref>, but their use of invariant attributes made it impossible to realize the merge operator as an operation on attributes. Specifically, there is no analytical relation between the attributes being merged to the attributes of the new primitive. Instead, a cascade of alternative representations was used, each one obtained by a different Gaussian smoothing of the two-dimensional curve; a primitive sequence is replaced by its ªancestorº in the scale space description. 10  Compare the polygonal approximation after merging with the polygon that would have been obtained had the curve been first smoothed and then approximated. The two polygons are not identical since smoothing may cause displacement of features (vertices). However, a displaced vertex cannot be too far from some feature at the finest scale; the location error caused by ªfreezingº the feature points is clearly bounded by the length of the longest fragment in the initial (finest scale) representation. To ensure good multiscaled feature matching, our suboptimal polygonal approximation is sufficient and the expensive generation of the multiscale cascade is not necessary. Instead, the attributes of the coarse scale representation may be computed directly from the attributes of the finer scale.</p><p>Merging was defined as an operation on attributes by <ref type="bibr" target="#b40">[41]</ref>, which also applied the technique to Chinese character recognition <ref type="bibr" target="#b41">[42]</ref>. Their algorithm suffers from some drawbacks concerning invariance and locality 11 ; below we concentrate on their merging mechanism and compare it to our own. Assume that two line segments characterized by I Y I and P Y P are to be merged into one segment Y . In <ref type="bibr" target="#b40">[41]</ref>,</p><p>I P and is the weighted average between I and P , with weights I a I P and P a I P and with the necessary cyclic correction. 12 Usually, the polygonal shape that is obtained using this simple ad hoc merging scheme cannot approximate the smoothed contour very well.  Merging result according to our scheme. A coarser approximation is obtained. (c) Merging according to Tsai and Yu <ref type="bibr" target="#b40">[41]</ref>. The new polygon does not appear to give a good approximation.</p><p>10. The primitive elements used in <ref type="bibr" target="#b43">[44]</ref> are convex and concave fragments, which are bounded by inflection points. The attributes are the fragment length divided by total curve length (a nonlocal attribute) and the accumulated tangent angle along the fragment (a noninterruptible attribute). The algorithm cannot handle occlusions or partial distortions and massive preprocessing is required to prepare the cascade of syntactical representations for each curve with consistent fragment hierarchy.</p><p>11. The primitives used by <ref type="bibr" target="#b40">[41]</ref> are line segments, the attributes are relative length (with respect to the total length) and absolute orientation (with respect to the first segment). The relative length is, of course, a nonlocal attribute and, in addition, the algorithm uses the total number of segments, meaning that the method cannot handle occlusions. The problem of attribute variance due to rotation remains, in fact, unsolved. The authors assume that the identity of the first segments is known. They comment that if this information is missing, one may try to hypothesize an initial match by labeling the segment that is near the most salient feature as segment number one.</p><p>12. For example, an equal weight average between HXW% (almost ªwestº) and ÀHXW% (almost ªwestº as well) is % (ªwestº) and not zero (ªeastº).</p><p>Satisfactory noise reduction is only achieved in one of the following two extreme cases: Either one segment is dominant (much longer than the other one) or the two segments have similar orientation. If two or more segments having large variance are merged, the resulting curve may be very different from the original curve (see Fig. <ref type="figure" target="#fig_10">14</ref>). Hence, by performing segment merging on the polygonal approximation at fine scale, one typically does not obtain an acceptable coarse approximation of the shape.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Pseudocode for CURVE-MATCHING procedure.</figDesc><graphic coords="4,43.71,69.17,216.06,220.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Dealing with occlusion: partial matching between three images. Points are mapped from (a) to (b) to (c) and back to (a). Only points which are mapped back to themselves are accepted (order is not important). The points on the tail in (a) are matched with the shadow (pointed to by the arrow) in (b), but matching (b) with (c) leaves the shadow unmatched. Hence, the tail is not matched back to itself and the correspondence with the shadow is rejected.</figDesc><graphic coords="5,324.74,69.17,180.06,396.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Matching two views of an object subjected to large foreshortening. Rejected pairs (in circles) were detected in four iterations of eliminating the IH percent most distant pairs and realigning the others. Thirty-three and 35 features were extracted on the two outlines; 32 pairs were initially matched and nine pairs were rejected PV percent.</figDesc><graphic coords="6,31.69,69.17,240.09,165.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. Matching of human limbs at different body configurations. In this case, the outlines were extracted with snakes rather than by gray level clustering (see acknowledgments). Original images are not shown.</figDesc><graphic coords="6,294.69,69.17,240.09,145.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>For each line, the columns that correspond to the three nearest neighbors (and the self-zero distance) are highlighted. The first, second, and third nearest neighbor are in the same class, a fraction of 25/25, 21/25, and 19/25 of the times, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. The classification tree (dendrogram) obtained for an image database consisting of 121 images. The finest classification level is shown by putting each cluster of silhouettes in a box. For the large clusters representing our own toy models (see text), the figure shows only five exemplars, but the other 10 are classified correctly as well. Note that the lower levels of the tree correspond to meaningful hierarchies, where similar classes (like the two cars or the three sets of mammals) are together. The vertical axis is not in scale.</figDesc><graphic coords="8,50.23,69.17,466.02,285.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Length similarity is measured by comparing the corresponding reference length values H Y HH with the corresponding length values of the current segment Y H . Each length pair is mapped to a direction in the plane and similarity is defined as osP. This value is bounded between ÀI and I.</figDesc><graphic coords="10,297.69,70.30,234.09,141.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig.8. An example of initial pruning. Two curves with n minxY x H SH are matched syntactically using t edit steps (see text for details). The SH candidates which achieve best (minimal) edit cost are examined to see whether the distribution of their associated rotations shows central tendency. Here, we sample the distribution after 1, 5, and 10 syntactic steps. In this example, 5-10 steps are sufficient for a reliable estimation of the global rotation angle . We proceed by eliminating the candidates whose associated global rotation is too far from .</figDesc><graphic coords="10,31.69,69.17,240.09,64.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. (a), (b)ÐTwo weakly similar curves. The points are extracted automatically from polygonal approximations that do not depart from the original curves by more than eight pixels. (c) The desirable matching result, as obtained by our matching algorithm. The average distance between matched feature points is 25 pixels. The directed Hausdorff distance is 34 pixels. (d) A nondesirable pairing of points which yields better proximity value. The average distance between matched feature points is only 23 pixels. The directed Hausdorff distance is only 29 pixels.</figDesc><graphic coords="14,31.58,69.17,240.38,241.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Scale similarity: The scale a H is compared with the reference scale H H a H H . Left: The binary relation used by Li [26] to measure scale similarity is expÀjlogaHja' with ' HXS. Right: Our measure function (1) is not sensitive to small scale changes, since it is flat near the line H .</figDesc><graphic coords="15,34.70,69.17,234.09,99.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Comparison between merging rules: (a) A polygonal approximation of a curve with two dotted segments which are to be merged. (b)Merging result according to our scheme. A coarser approximation is obtained. (c) Merging according to Tsai and Yu<ref type="bibr" target="#b40">[41]</ref>. The new polygon does not appear to give a good approximation.</figDesc><graphic coords="15,347.19,69.17,135.16,101.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>). More specifically, let e and e H be two syntactic representations of two contours; e f I Y P Y F F F Y x g is a cyclically ordered list of x line segments and e H f H I Y H P Y F F F Y H x H g is another cyclic list of x H segments. Let i be a segment of e and H j be a segment of e H . Matching these segments uniquely determines the relative global rotation and scale (2D alignment transformation) between the curves. We assume that the optimal alignment is well approximated by at least one of the xx H possible selections of i and H j . In fact, we will discuss in Section 5.2 a method to prune many of them, leaving us with a set É e Â e H of candidate global alignments, such that usually jÉj ( xx H .</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1 The</head><label>1</label><figDesc>Dissimilarity Values Computed between 25 Silhouettes (Multiplied by 1,000 and Rounded)</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors would like to thank Ben Kimia and Daniel Sharvit for the 31 silhouette database and Davi Geiger for the human limbs data. This research is partially funded by the Israeli Ministry of Science.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">ªPartial Shape Recognition: A Landmark Based Approach</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Delp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="470" to="489" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">ªAn Efficiently Computable Metric for Comparing Polygonal Shapes</title>
		<author>
			<persName><forename type="first">E</forename><surname>Arkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Chew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kedem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mitchel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="209" to="216" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">ªThe Curvature Primal Sketch</title>
		<author>
			<persName><forename type="first">H</forename><surname>Asada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="2" to="14" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ªHYPER: A New Approach for the Recognition and Positioning of Two Dimensional Objects</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ayach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Faugeras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="44" to="54" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
		<title level="m">ªDetermining the Similarity of Deformable Shapes,º IEEE Workshop Physics Based Modeling in Computer Vision</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="135" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ªShape Matching of Two Dimensional Objects</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bhanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Faugeras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="137" to="155" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ªRecognizing and Locating Partially Visible Objects: The Focus Feature Method,º Int</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">l J. Robotics Research</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="57" to="81" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Brint</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brady</surname></persName>
		</author>
		<title level="m">ªStereo Matching of Curves,º Image and Vision Computing</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="50" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">ªStructural Matching in Computer Vision Using Probabilistic Relaxation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Christmas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Petrou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="749" to="764" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sulger</surname></persName>
		</author>
		<title level="m">ªTracking Points on Deformable Objects Using Curvature Information,º Proc. European Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="458" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ªShape Matching Using Relaxation Techniques</title>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="60" to="72" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ªVisual Image Retrieval by Elastic Matching of User Sketches</title>
		<author>
			<persName><forename type="first">A</forename><surname>Del Bimbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="121" to="132" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Dembo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Zeitouni</surname></persName>
		</author>
		<title level="m">ªCritical Phenomena for Sequence Matching with Scoring,º Annals of Probability</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Gdalyahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weinshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Werman</surname></persName>
		</author>
		<title level="m">ªStochastic Image Segmentation by Typical Cuts,º Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Fort Collins, Colo</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ªDynamic Programming for Detecting, Tracking and Matching Deformable Contours</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vlontzos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="294" to="302" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ªPartial Shape Recognition Using Dynamic Programming</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gorman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="257" to="266" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">ªDynamic Programming Alignment of Sequences Representing Cyclic Patterns</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Thomason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="129" to="135" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<author>
			<persName><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Skordas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ªStereo Correspondence Through Feature Grouping and Maximal Cliques</title>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="168" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">ªComparing Images Using the Hausdorff Distance</title>
		<author>
			<persName><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Klanderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Rucklidge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="850" to="863" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">ªObject Recognition Using Alignment</title>
		<author>
			<persName><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Computer Vision</title>
		<meeting>Int&apos;l Conf. Computer Vision<address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="102" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">ªCondensing Image Databases when Retrieval Is Based on Nonmetric Distances</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weinshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gdalyahu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Sixth Int&apos;l Conf. Computer Vision</title>
		<meeting>Sixth Int&apos;l Conf. Computer Vision<address><addrLine>Bombay</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Kamger-Parsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Margalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rozenfeld</surname></persName>
		</author>
		<title level="m">General Polygonal Arcs,º Computer Vision, Graphics, and Image Processing: Image Understanding</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="227" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">ªUsing Polygons to Recognize and Locate Partially Occluded Objects</title>
		<author>
			<persName><forename type="first">M</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kashyap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="483" to="494" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">ªShape Similarity Measure for Image Database of Occluding Contours</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Laka</forename><surname>Èmper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fourth IEEE Workshop Applications of Computer Vision</title>
		<meeting>Fourth IEEE Workshop Applications of Computer Vision<address><addrLine>Princeton, N. J.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-10">Oct. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">ªAffine Invariant Model Based Object Recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lamdan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wolfson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robotics and Automation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="578" to="589" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<title level="m">ªMatching: Invariant to Translations, Rotations and Scale Changes,º Pattern Recognition</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="583" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Liuand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Srinath</surname></persName>
		</author>
		<title level="m">ªPartial Shape Classification Using Contour Matching in Distance Transformation,º IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">79</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dunham</surname></persName>
		</author>
		<title level="m">ªShape Matching Using Polygon Approximation and Dynamic Alignment,º Pattern Recongition Letters</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="945" to="949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><surname>Marzal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ªComputation of Normalized Edit Distance and Applications</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="926" to="932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ªÉ-S Correlation and Dynamic Time Warping: Two Methods for Tracking Icefloes in SAR Images</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mcconnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Curlander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kober</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">ªScale-Based Description and Recognition of Planar Curves and Two-Dimensional Shapes</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mokhtarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mackworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="34" to="44" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Pelillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Siddiqi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zucker</surname></persName>
		</author>
		<title level="m">ªMatching Hierarchical structures Using Association Graphs,º Proc. European Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="3" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pavlidis</surname></persName>
		</author>
		<title level="m">ªA Shape Analysis Model with Applications to a Character Recognition System,º IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="393" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">ªModal Matching for Correspondence and Recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="545" to="561" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brady</surname></persName>
		</author>
		<title level="m">ªFeature Based Correspondence: An Eigenvector Approach,º Image and Vision Computing</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="283" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">ªSymmetry Based Indexing of Image Databases</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sharvit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kimia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Visual Comm. and Image Representation</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Shokoufandeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Siddiqi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zucker</surname></persName>
		</author>
		<title level="m">ªIndexing Using a Spectral Encoding of Topological Structure,º Proc. Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="491" to="497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Siddiqi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shokoufandeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zucker</surname></persName>
		</author>
		<title level="m">ªShock Graphs and Shape Matching,º Proc. Int&apos;l Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="222" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">ªMatching Images to Models for Registration and Object Detection via Clustering</title>
		<author>
			<persName><forename type="first">G</forename><surname>Stockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kopstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Benett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="229" to="241" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Tirthapura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sharvit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kimia</surname></persName>
		</author>
		<title level="m">ªIndexing Based on Edit Distance Matching of Shape Graphs,º SPIE Proc. Multimedia Storage and Archiving Systems III</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="25" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">ªAttributed String Matching with Merging for Shape Recognition</title>
		<author>
			<persName><forename type="first">W</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="453" to="462" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">ªAttributed String Matching by Split and Merge for On-Line Chinese Character Recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tsai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="180" to="185" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">ªFeatures of Similarity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="327" to="352" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Ueda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Suzuki</surname></persName>
		</author>
		<title level="m">ªLearning Visual Models from Shape Contours Using Multiscale Covex/Concave Structure Matching,º IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="337" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Point Pattern Matching and Its Application to Recognition of Object Families</title>
		<author>
			<persName><forename type="first">S</forename><surname>Umeyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="136" to="144" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">ªOptimal Correspondence of String Subsequences,º IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pavlidis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">86</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">ªOn View Likelihood and Stability</title>
		<author>
			<persName><forename type="first">D</forename><surname>Weinshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Werman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="97" to="108" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">She received the MSc and PhD degrees in mathematics and statistics from Tel-Aviv University in 1985 and 1986, respectively, for her work on models of evolution and population genetics. Between 1987 and 1992, she visited the center for biological information processing at MIT and the IBM T.J. Watson Research Center. In 1993, she joined the Institute of Computer Science at the Hebrew University of Jerusalem, where she is now an associate professor. Her research interests include computer and biological vision, machine and human learning. She has published papers on learning in machine and human vision, qualitative vision, visual psychophysics, Bayesian vision, invariants, multipoint and multiframe geometry, image and model point-based metrics, motion and structure from motion</title>
		<author>
			<persName><forename type="first">M</forename><surname>Werman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weinshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="810" to="814" />
			<date type="published" when="1982">1995. 1982</date>
			<pubPlace>Jerusalem, Israel; Haifa, Israel; Tel-Aviv, Israel</pubPlace>
		</imprint>
		<respStmt>
			<orgName>ªSimilarity and Affine Invariant Distance Between Point Sets ; from Tel-Aviv University</orgName>
		</respStmt>
	</monogr>
	<note>He received the MSc degree in physics from the Weizmann Institute of Science, Rehovot, Israel for his work on resonant tunneling and inelastic scattering in Gallium Arsenide heterostructures. His PhD thesis was in computer vision, submitted to the senate of the Hebrew University in October 1999. His research combines computer vision and machine learning. Upon graduation, he received the Eshkol scholarship given by the Israeli Ministry of Science to the best PhD students. He is currently with the IBM Research Laboratory. She is a member of the IEEE</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
