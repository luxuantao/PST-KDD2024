<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">JUMPER: Learning When to Make Classification Decisions in Reading</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xianggen</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit1">IDG/McGovern Institute for Brain Research</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lili</forename><surname>Mou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Haotian</forename><surname>Cui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit1">IDG/McGovern Institute for Brain Research</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Sen</forename><surname>Song</surname></persName>
							<email>songsen@mail.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit1">IDG/McGovern Institute for Brain Research</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Laboratory of Brain and Intelligence</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Adeptmind</forename><surname>Ai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Deeplycurious</forename><surname>Ai</surname></persName>
						</author>
						<title level="a" type="main">JUMPER: Learning When to Make Classification Decisions in Reading</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In early years, text classification is typically accomplished by feature-based machine learning models; recently, deep neural networks, as a powerful learning machine, make it possible to work with raw input as the text stands. However, exiting end-to-end neural networks lack explicit interpretation of the prediction. In this paper, we propose a novel framework, JUMPER, inspired by the cognitive process of text reading, that models text classification as a sequential decision process. Basically, JUMPER is a neural system that scans a piece of text sequentially and makes classification decisions at the time it wishes. Both the classification result and when to make the classification are part of the decision process, which is controlled by a policy network and trained with reinforcement learning. Experimental results show that a properly trained JUMPER has the following properties: (1) It can make decisions whenever the evidence is enough, therefore reducing total text reading by 30-40% and often finding the key rationale of prediction. (2) It achieves classification accuracy better than or comparable to state-of-the-art models in several benchmark and industrial datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Text understanding is one of the core goals of natural language processing (NLP), and is related to various applications, including text classification <ref type="bibr" target="#b1">[Kim, 2014]</ref>, information extraction <ref type="bibr" target="#b5">[Zeng et al., 2014]</ref>, and machine comprehension <ref type="bibr" target="#b3">[Rajpurkar et al., 2016]</ref>. Recently, neural networks are playing an increasingly important role in NLP and have achieved significant performance in these tasks. However, previous work mainly focuses on the ultimate performance of a task (e.g., classification accuracy). Humans typically do not have a clear understanding on where and how the model makes such a decision, which are in fact important for debuggability and interpretability especially in real industrial applications <ref type="bibr" target="#b3">[Marcus, 2018]</ref>.</p><p>This paper provides a novel framework that models text understanding as a sequential decision process. Our work is inspired by the cognitive process of humans: during reading, people look for clues, perform reasoning, and obtain information from text. We mimic this process by feeding text to a neural network in a sentence-by-sentence manner. At each sentence, the network makes decisions (also known as actions) based on the input, and at the end of this process, the network would have some "understanding" of the text.</p><p>In particular, we focus on text classification problems with several predefined subtasks (called slots). When our neural network reads a paragraph, a slot is assumed to have a default value "None" at the beginning. At each decision step, a sentence of the paragraph is fed to the neural network in order; the network then decides if it is confident enough to "jump" to a non-default value as the prediction for a particular slot. We impose a constraint that each jump is a finalized decision, which cannot be updated in the future. We call our model JUMPER, and its decision process is depicted in Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>We train JUMPER by reinforcement learning with only weak supervision. In human reading, people are typically certain about reading comprehension results, but it is sometimes difficult to model how human belief changes when they read. Likewise, we also assume our training labels only contain the ultimate results, and no supervision signal is given regarding which step the model should make a decision.</p><p>Intriguingly, the one-jump constraint forces our model to be serious about both when to predict and what to predict. This is because a paragraph does not contain a special symbol indicating the end of the paragraph. If our model defers its decision later than it could have made an accurate enough prediction, it takes a risk of not being able to predict. On the other hand, if the model predicts too early, it takes a risk of low accuracy. By optimizing the expected reward in reinforcement learning, the model learns how it can make decisions at a "right" time.</p><p>The advantage of modeling text classification as a decision process is multi-fold: (1) JUMPER coincides with recent work on rationalizing neural prediction <ref type="bibr" target="#b1">[Lei et al., 2016]</ref> when the evidence of classification is local and isolated. ( <ref type="formula">2</ref>) In those tasks where information is scattered more widely, JUMPER learns to make a decision as long as it is confident enough, making it possible to skip reading the remaining part of a paragraph. (3) In a neural model, the evidence of one classification might get distorted after seeing irrelevant facts due to the distributed representation of knowledge. The (partial) decisions that our model has made can serve as valuable "symbolic" knowledge.</p><p>We evaluated our model on two benchmark datasets; we also collected a new corpus (and make it publicly available) to further evaluate our model in a real, industrial task. Experiments show that our JUMPER achieves comparable or higher ultimate classification accuracy compared with strong baselines. Moreover, it reduces the length of text reading by 30-40%, resulting in fast inference. For information extractionstyle classification where the information is centered in a single sentence, our model can automatically find the key rationale without training signals of jumping positions. We also show that, in a multitask setting, feeding back the partial decisions (called a decision-sharing mechanism) further improves model performance, which indicates that some decisions could help others, serving as symbolic knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Text classification is related to various tasks in NLP, ranging from sentiment analysis <ref type="bibr" target="#b3">[Pang et al., 2002]</ref> to topic classification <ref type="bibr">[Wang and Manning, 2012]</ref>. In early years, text classification uses hand-crafted features or feature templates (e.g., bag-of-words features), based on which machine learning models are used for classification. Recently, deep neural networks have become a prevailing learning model, as they are more powerful classifiers that can work with raw input of words <ref type="bibr" target="#b1">[Kim, 2014]</ref>.</p><p>Recently, researchers focus more on the rationales underlying neural predictions. <ref type="bibr" target="#b6">Zhang et al. [2016]</ref> show that with hu-man annotated rationales, the neural networks' performance could be improved. <ref type="bibr" target="#b1">Lei et al. [2016]</ref> build a neural text classifier on key phrases in a paragraph, where key phrase extraction is learned by reinforcement learning with real-valued reward. However, their method cannot deal with non-existing information because it is unclear how to train and predict without extracted phrases. Also, such approach would be more difficult to train with sparse reward (like 0-1 loss). <ref type="bibr" target="#b4">Yu et al. [2017]</ref> learn to skim text by predicting how many words to skip during reading. However, it is counter-intuitive that a network can learn to skip several future words (which by themselves have a lot of freedom) without actually seeing them. By contrast, our network skims text by ignoring all future sentences after it has been confident enough to predict, where the confidence is said in terms of its expectation of the remaining sentences.</p><p>Different from existing approaches, our paper models text classification as a sequential decision process. The network is similar to the belief tracker in <ref type="bibr" target="#b3">Wen et al. [2017]</ref> for a taskoriented dialog system. However, their network is trained by cross-entropy loss with strong supervision of the groundtruth labels at every step. We instead propose a one-jump constraint in the decision process and train our network by reinforcement learning with weak supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Proposed Method</head><p>Figure <ref type="figure" target="#fig_1">2</ref> shows the overall framework of our approach. We first segment the paragraph into sub-sentences<ref type="foot" target="#foot_1">1</ref> ; each could be thought of as a basic unit for some "proposition," and is fed to our model in order. There are three main components in our neural network:</p><p>• A sentence encoder encodes the semantic features of words in a sentence into a fixed-dimensional vector space. • A controller, essentially a recurrent neural network (RNN), is built upon sentence encoders, and takes actions ("jumps") when appropriate. For each slot, we model it as a classification problem, where a default value "None" (indicating information not existing) is included as the classification objective. In other words, the controller decides not only when to jump, but also where (which class) to jump. • A symbolic (output) layer maintains the decisions that have been made, and ensures consistency according to hard constraints that we impose. In this work, we consider a onejump constraint that allows at most one jump from "None" to others. The classification results are the symbolic output layer's values after the network reads the entire paragraph. JUMPER is trained by reinforcement learning with weak supervision at the end of a paragraph. The rest of this section elaborates these components and the training process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sentence Encoder</head><p>We use a convolutional neural network (CNN) as the sentence encoder <ref type="bibr" target="#b1">[Kim, 2014]</ref>. CNN applies a set of sliding windows to the concatenation of neighboring words to extract local features, which are aggregated by max pooling to represent sentence-level information.</p><p>For a particular sentence in a paragraph, we denote the word embeddings by</p><formula xml:id="formula_0">x 1 , x 2 , • • • , x L ∈ R d ,</formula><p>where L is the number of words in the sentence and d is the dimension of embeddings. We also denote the concatenation of column vectors</p><formula xml:id="formula_1">x i , x i+1 , • • • , x j by x i:j = [x i ⊕ x i+1 ⊕ • • • ⊕ x j ].</formula><p>Then convolution is computed by</p><formula xml:id="formula_2">c k,i = f (w k x i:i+h−1 + b k ) (1) c k = max{c k,1 , c k,2 , • • • , c k,L−h+1 } (2) c = [c 1 ⊕ c 2 ⊕ • • • ⊕ c K ]<label>(3)</label></formula><p>where w k ∈ R hd and b k ∈ R are the weights of the kth convolutional kernel, extracting a local feature c k,i at position i.</p><p>The maximum feature over all positions is chosen as the sentence's representation in terms of this kernel. Finally, the features of different kernels are concatenated as the encoding of the sentence, denoted as c.</p><p>We would like to point out that other networks (e.g., recurrent neural networks) may also be a reasonable architecture for the sentence encoder. In our work, we choose CNN because we hope to further induce word-level rationales by backtracking through the max-pooling layer, as will be described in Subsection 3.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Controller</head><p>Based on encoded sentence features, the controller of JUMPER takes corresponding actions, as in a sequential decision process. Inside the controller are two submodules:</p><p>(1) An RNN fuses the current input and previous sentences, maintaining dependency over the entire history; and (2) A policy network (PolicyNet) makes a decision for each slot at the current step. (See also Figure <ref type="figure" target="#fig_1">2</ref>.) Formally, RNN takes a sequence of sentence features c 1 , • • • , c T and updates its hidden states accordingly. (T is the number of sentences.) In this paper we use the gated recurrent unit (GRU) <ref type="bibr" target="#b0">[Cho et al., 2014]</ref> as our recurrent update:</p><formula xml:id="formula_3">h t = GRU(h t−1 , c t )</formula><p>, where h t is the hidden state of the time step t.</p><p>Based on RNN's hidden states, PolicyNet predicts the decision action for each slot. Suppose slot i has N i possible values, we use a softmax predictor of N i + 1 ways, where an additional way "None" represents information not existing. Notice that the "None" class does not differ from other classification labels at the beginning of training. However, the reinforcement learning with the one-jump constraint would make the model predict "None" before it is confident enough to take an action.</p><p>Formally, JUMPER's decision a (i)</p><p>t ∈ R Ni+1 , after processing the tth sentence, is given by a policy distribution π(a (i)</p><formula xml:id="formula_4">t |c t ) = softmax(W (i) p [c t ⊕ h t ] + b (i) p ) (4)</formula><p>where W p and b p are weights and the bias term. Here, we feed PolicyNet with the concatenation of RNN's hidden state and sentence features, inspired by <ref type="bibr">ResNet [He et al., 2016]</ref>. During training, we sample an action from its predicted distribution, whereas for testing, we choose the action with the maximum a posteriori probability, i.e., a</p><formula xml:id="formula_5">(i) t = argmax π(a (i) t |c t ).</formula><p>PolicyNet appears to resemble a multitask sequential labeler for different slots based on a shared hidden representation. This makes sense because different slots may be correlated with each other (e.g., the occupational injury task in Table <ref type="table" target="#tab_0">1</ref>), and thus some underlying representations could be reused.</p><p>However, PolicyNet cannot be trained with standard crossentropy loss due to the lack of step-by-step supervision. Instead, we apply reinforcement learning, which computes the policy gradient to optimize the expected reward (described in Subsection 3.4). In this way, PolicyNet learns in a trial-anderror fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Symbolic Output Layer</head><p>The output layer of JUMPER keeps the decisions that have been made until the current sentence, and maintains consistency in a "symbolic" fashion. We propose a one-jump constraint that allows at most one non-default prediction (not "None") for each slot.</p><p>Let s</p><formula xml:id="formula_6">(i)</formula><p>t ∈ {0, 1} Ni+1 be the one-hot representation of the symbolic layer's state for slot i at the tth sentence. We have</p><formula xml:id="formula_7">s (i) t = s (i) t−1 • 1 {s (i) t−1 =None} + a t • 1 {s (i) t−1 =None} (5)</formula><p>where 1 {•} is an indicator function that yields 1 when its argument is true, and 0 otherwise. In other words, the state has to be the same as its previous one if it is not "None"; but on the other hand, JUMPER can remain in "None" for the entire paragraph if the information does not exist. The final result, which we use to compare with groundtruth, is the symbolic layer's state after processing the last (T th) sentence, i.e., s</p><p>T . It should be mentioned that, although our current JUMPER considers only one constraint, it is natural to design other reasoning rules within the symbolic layer, like the way in OONP <ref type="bibr" target="#b2">[Lu et al., 2018]</ref>, for example, one slot inferring another. Future work is needed to address more complicated symbolic reasoning in the JUMPER framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Decision-Sharing Mechanism</head><p>In a multi-slot prediction task, some information may be useful for others. Thus we feed the symbolic states back to the neural network, so that different action predictors are aware of each other. We call this a decision-sharing mechanism.</p><p>Concretely, we concatenate one-hot representation of each state with the sentence vector and feed them to GRU, given by h</p><formula xml:id="formula_9">t = GRU(h t−1 , [c t ⊕ s (1) t−1 ⊕ • • • ⊕ s (Ns) t−1 ]),</formula><p>where N s is the number of slots.</p><p>As we shall see in experiments, the decision-sharing mechanism helps to improve the accuracy of both rationale finding and ultimate classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Learning</head><p>The main difficulty of learning JUMPER is the lack of stepby-step supervision, i.e., we assume the labels contain only ultimate results for each slot, but no information for the appropriate position to jump. Admittedly, life will be easier if we have fine-grained annotations regarding which step to predict for each slot, but they are costly and labor-intensive to obtain.</p><p>We therefore apply reinforcement learning to train our JUMPER framework. We define a reward by comparing the model's prediction and the groundtruth. The training objective is to maximize the expected reward over sampled actions.</p><p>Concretely, we define the final reward of JUMPER as</p><formula xml:id="formula_10">R (j,i) final = 1 {s (j,i) T j =t (j,i) }<label>(6)</label></formula><p>for data point j and slot i, where s</p><formula xml:id="formula_11">(j,i) Tj</formula><p>is the symbolic state at the end of the paragraph and t (j,i) is the groundtruth.</p><p>However, it is difficult to train a model by reinforcement learning, with such a sparse reward along the decision process. In particular, our model tends to jump at early stages at the beginning of training, because for an uniform distribution over all N + 1 actions, the probability of jumping at time step t is N (N +1) t . Thus we design an intermediate reward as</p><formula xml:id="formula_12">R (j,i,t) int = r, if s t = None 0, otherwise<label>(7)</label></formula><p>for data step j, slot i, and each step t. Here, r is a (small) positive constant, balancing the importance of R</p><formula xml:id="formula_13">(•) int and R (•)</formula><p>final . We would like to emphasize that the design of R (•) int is different from traditional planning and reinforcement learning (e.g., the maze problem) where the reward for each step is negative. In our problem, however, each step has a positive reward so that it alleviates the early-jumping problem.</p><p>We compute the cumulated reward from step t to the jumping step as: R (j,i)</p><formula xml:id="formula_14">t:T (j,i) jump = T (j,i) jump t =t γ t −t R (j,i,t ) int + R (j,i) final (8)</formula><p>where γ is the discounting rate, and T (j,i) jump denotes the jumping step. To maximize the expected reward, we compute the gradient of the policy, given by</p><formula xml:id="formula_15">∇ Θ J(Θ) = E πΘ T t=1 ∇ Θ R t:T log π Θ (a t |c t ) ≈ N j=1 I i=1 T (j,i) jump t=1 1 N T j R (j,i) t:T (j,i) jump ∇ Θ log π Θ a (j,i) t |c (j) t</formula><p>where Θ denotes all model parameters and I denotes the number of slots. The approximation is due to Monte Carlo sampling and the above updating rule is also known as the REINFORCE algorithm <ref type="bibr" target="#b4">[Williams, 1992]</ref>. To have a balance between exploration and exploitation, we reserve a small probability to uniformly sample from the entire action space. To reduce the variance of REINFORCE, we subtract the reward by a baseline term (computed as the average of the M = 5 samples) and truncate negative rewards as in Mou et al. <ref type="bibr">[2017]</ref>.</p><p>It is interesting to have an intuitive understanding on why JUMPER can find the "right" position to predict with only weak supervision. Let t * be the position that the network could have predicted. The reward encourages the model to predict any time after t * , and later sentences have a slightly higher reward due to R int . However, if the network learns to predict as late as possible by maximizing the reward for a particular training data point, it has to wait for intermediate reward by not predicting. Since there is no clue indicating the end of a paragraph, the network unfortunately cannot learn such information, and thus is in the risk of not being able to predict for other samples, resulting in a low total reward over the training set. Therefore, our JUMPER framework with the one-jump constraint enables the model to find the "right" position to predict by weak supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Backtracking Word-Level Clues</head><p>Currently, our approach works in the sentence level. To obtain word-level rationales in our model, we propose a simple heuristic that backtracks information flow through maxpooling operation, based on the key sentence that we have already found by JUMPER. We compute the gradient of the log-likelihood with respect to the last sentence's representation; it is then multiplied with the magnitude of the difference between two steps (ignoring the sign by taking the square). The two aspects indicate how a feature (at the last step) could have improved the prediction, and what is mostly changed at the current time step. Then we choose the top D = 10 values, yielding the most important D-dimensions in the output of CNN, given by</p><formula xml:id="formula_16">D = top D ∂ log(p t (s t )) ∂c (t−1) (c (t) − c (t−1) ) 2 (9)</formula><p>where indicates point-wise product.</p><p>We backtrack where the maximum values come from in the max-pooling operation in Equation <ref type="formula">2</ref>, obtaining the word that matters in a dimension d as</p><formula xml:id="formula_17">w d = argmax{c 1 , • • • , c K }.</formula><p>The importance of a word is counted as the fraction in D at which the word is backtracked. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluated JUMPER on three tasks, including two benchmark datasets and one real, industrial application. We show the performance of both ultimate classification and jumping positions; we will also have deep analysis into our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>In this part, we describe the datasets used in our experiments.</p><p>• Movie Review (MR), whose objective is a binary sentiment classification (positive vs. negative) for movie reviews [Pang and <ref type="bibr" target="#b3">Lee, 2004]</ref>; it is widely used as a sentence classification task. • AG news corpus (AG), which is a collection of more than one million news articles, and we followed <ref type="bibr" target="#b6">Zhang et al. [2015]</ref>, classifying the largest four categories: world, sports, business, and science. • Occupational Injury (OI). <ref type="foot" target="#foot_2">2</ref> The task-information extraction of occupational injury-originates from a real industrial application in the legal domain. We constructed a dataset (in the Chinese language) of 3995 cases related to occupational injuries from an online domain-specific forum. Based on an established ontology with 15 slots, each text is annotated with answers for these 15 problems. Table <ref type="table" target="#tab_1">2</ref> shows some statistics of the OI dataset. We report two subtasks-occupational injury identification (InjIdn) and injury level (Level)-to evaluate our model in a singletask setting. We used all subtasks to evaluate the decisionsharing mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Competing Methods</head><p>We compare JUMPER with the following baselines:</p><p>• Hierarchical CNN-GRU. We use JUMPER with crossentropy loss as a baseline model, which is essentially a Hierarchical model with CNN and GRU for sentences and paragraphs, respectively. This baseline is similar to our model except training criteria. • Bi-GRU. It reads a text in two opposite directions, and the final states are concatenated for prediction.</p><p>• CNN. This model is proposed by <ref type="bibr" target="#b1">Kim [2014]</ref>, with several different sizes of convolution operators to learn sentence representation.</p><p>• Self-Attentive. <ref type="bibr" target="#b1">Lin et al. [2017]</ref> propose a self-attentive model that attends to the sequence itself. In the latter three baselines, we concatenated all sentences, and the models were applied to the paragraph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation Details</head><p>In our experiments, we applied coarse grid search on both the MR and OI development datasets to select hyperparameters. We did not perform any dataset-specific tuning except early stopping on the development sets. For AG, which does not have a standard split, we randomly selected 5% of the training data as the development set.</p><p>In our model and baselines, the CNN part used rectified linear units (ReLU) as the activation function, filter windows with sizes 1 to 5, 200 feature maps for each filter, and a dropout rate of 0.5; GRU had a hidden size of 20. We reimplemented the self-attentive model using the same hyperparameters as in Lin et al. <ref type="bibr">[2017]</ref>.</p><p>For reinforcement learning, the intermediate reward r was 0.05, discounting rate γ was 0.9, and the exploration rate was 0.1.</p><p>In addition, word embeddings for all of the models were initialized with 300d GloVe vectors <ref type="bibr" target="#b3">[Pennington et al., 2014]</ref> and fine-tuned during training to improve the performance. The other parameters were initialized by randomly sampling from the uniform distribution in [−0.01, 0.01]. For all the models, we used AdaDelta with a learning rate of 0.1 and a batch size of 50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results and Discussion</head><p>In this section, we present JUMPER's performance regarding several aspects: overall accuracy, jumping accuracy, and multi-slot learning. We also present a case study to showcase the behavior of our model.</p><p>Classification Results. We first analyze the classification accuracy of JUMPER when compared with baselines. Table <ref type="table" target="#tab_2">3</ref> shows the test performance on the three datasets with four tasks. We notice that, in the MR and AG datasets, JUMPER occasionally predicts "None," which is not a valid label in these datasets. This puts our model at a disadvantage, and we take the most likely non-default (not "None") as the prediction at the end of a paragraph.</p><p>As shown, our JUMPER model achieves comparable or better performance on all these tasks. This indicates that modeling text classification as a sequential decision process does not hurt or even improves performance. We would also like to point out that "accuracy" is not the only performance that we are considering. More importantly, our proposed model is able to find the key supporting sentence for text classification, or reduce the reading process, as shown in the following experiments.</p><p>Performance of Jumping. JUMPER has to make a decision as long as it sees sufficient evidence during its reading process due to the one-jump constraint, and after prediction, there is no need to read future sentences. We see in Table <ref type="table" target="#tab_3">4</ref> that, although our model achieves similar or higher performance compared with strong baselines, it reduces the length of text reading by 30-40%, leading to fast inference for prediction.</p><p>We are now further curious if JUMPER could "jump" at the right position in an information extraction-style task such as OI-Level. We annotate the rationale sentences in 400 data points (also available on our website in Footnote 2), serving as the test groundtruth. It should be noticed that we still have no training labels for jumping positions in this experiment. We compare JUMPER with the Hierarchical CNN-GRU model, which uses the same neural network, but differs in terms of training methods. The Hierarchical CNN-GRU is trained with cross-entropy loss at the end of a paragraph. During testing, we apply the predictor to every step and find the first position that it makes a prediction other than "None." This heuristic makes some sense, because the RNN is supposed to map information to the same hidden space during its recurrent modeling of a sequence. We also included a competing method that uses a CNN classifier <ref type="bibr" target="#b1">[Kim, 2014]</ref> and chooses the sentence where words are selected the most by max pooling.</p><p>In addition to the classification accuracy (CA) shown in Table <ref type="table" target="#tab_2">3</ref>, we use the following metrics: (1) Jumping accuracy (JA), the percentage of correct jump positions conditioned on correct classification; and (2) Overall accuracy (OA), the percentage of both correct jumping positions and correct classification results. We also include the classification accuracy (CA) as has been shown in Table <ref type="table" target="#tab_2">3</ref>. It is easy to verify that OA = CA • JA.</p><p>The results are shown in   discover the jumping position with a very high accuracy in terms of both JA and OA, and that both CNN and Hierarchical CNN-GRU perform worse in this task. Although they achieve similar classification results (JUMPER slightly outperforming by ∼1%), JUMPER is better at finding the key rationale by 3-6%. This shows that our one-jump constraint forces the model to think more carefully about when to make a decision, and that reinforcement learning is an effective way to learn the correct position of making decisions.</p><p>Another interesting finding is that, for Hierarchical CNN-GRU, the classification accuracy at the end of the paragraph as in Table <ref type="table" target="#tab_2">3</ref> is lower than that when it could have predicted as in Table <ref type="table" target="#tab_4">5</ref>. This shows evidence of the distortion phenomenon of distributed representation: when neural networks are fed with too much irrelevant information, its knowledge is less accurate.</p><p>Evaluating the Decision-Sharing Mechanism. We now evaluate JUMPER in a multitask learning setting to see if the symbolic knowledge can help decision making for other slots. The average accuracy and F 1 scores for the 15 OI subtasks are shown in Table <ref type="table" target="#tab_6">6</ref>. We include F 1 -score because some slots are skewed. We see that JUMPER achieves better performance, with known knowledge formatted in a symbolic way and fed back to the neural network. Although the improvement is not large, the results are consistent in terms of both accuracy and the F 1 -score for both development and test sets.</p><p>Case Study. We show several examples of the decisions made by the neural network in Figure <ref type="figure" target="#fig_2">3</ref>. In the AG and MR datasets, information is located over a wider range, and the network makes a prediction as long as it sees enough evidence (e.g., "trade commissioner" for the business domain). By backtracking the word-level rationales, we find words like "trade commissioner" and "tiresome" play a more important role in the decision making. In these cases, the model does not need to read future sentences, which is more efficient than reading the entire paragraph. For OI-Level classification where information is mostly local, the neural network precisely locates the subsentence that contains the information, as shown in Table <ref type="table" target="#tab_4">5</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, we have proposed a novel model, JUMPER, that modes text classification as a sequential decision process on a sentence-by-sentence basis when reading a paragraph. We train JUMPER by reinforcement learning with a one-jump constraint. Experiments show that JUMPER achieves comparable or higher performance than baselines; that it reduces text reading by a large extent; and that it can find the key rationale if the information is local within a sentence.</p><p>In future work, we would like to incorporate symbolic reasoning into the symbolic layer, where we could explicitly handle inference, contradiction, etc. among different slots.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of JUMPER's decision process. Based on a paragraph of six sub-sentences, JUMPER makes a prediction at an appropriate step for each subtask.</figDesc><graphic url="image-1.png" coords="1,315.00,262.80,250.29,154.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overview of JUMPER. (SentEnc refers to a sentence encoder.)</figDesc><graphic url="image-2.png" coords="3,57.06,54.00,236.88,173.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Case study. We show the histogram of decision distributions and the heatmaps of word importance in MR and AG samples.</figDesc><graphic url="image-3.png" coords="7,54.00,54.00,246.97,177.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the datasets after tokenization: the numbers of classes, data samples, vocabulary size, and test samples. For MR which does not have a standard split, we performed 10-fold crossvalidation.</figDesc><table><row><cell>Data</cell><cell># of class</cell><cell># of samples</cell><cell># of vocab</cell><cell>Test</cell></row><row><cell>MR</cell><cell>2</cell><cell>10,662</cell><cell>18,765</cell><cell>10-fold</cell></row><row><cell>AG</cell><cell>4</cell><cell>127,600</cell><cell>17,836</cell><cell>7,600</cell></row><row><cell>OI</cell><cell>2-12</cell><cell>3,995</cell><cell>2,089</cell><cell>400</cell></row><row><cell cols="2">Subtask</cell><cell># of Class</cell><cell cols="2">Majority Guess (%)</cell></row><row><cell cols="2">IsOccuInj</cell><cell>2</cell><cell>85.68</cell><cell></cell></row><row><cell cols="2">AssoPay</cell><cell>2</cell><cell>81.75</cell><cell></cell></row><row><cell cols="2">LaborContr</cell><cell>2</cell><cell>93.22</cell><cell></cell></row><row><cell cols="2">EndLabor</cell><cell>3</cell><cell>93.67</cell><cell></cell></row><row><cell>OnOff</cell><cell></cell><cell>2</cell><cell>93.69</cell><cell></cell></row><row><cell cols="2">DiseRel</cell><cell>3</cell><cell>99.05</cell><cell></cell></row><row><cell cols="2">OutForPub</cell><cell>2</cell><cell>99.07</cell><cell></cell></row><row><cell cols="2">WorkTime</cell><cell>3</cell><cell>79.75</cell><cell></cell></row><row><cell cols="2">WorkPlace</cell><cell>3</cell><cell>80.60</cell><cell></cell></row><row><cell>JobRel</cell><cell></cell><cell>3</cell><cell>91.34</cell><cell></cell></row><row><cell>InjIdn</cell><cell></cell><cell>3</cell><cell>55.02</cell><cell></cell></row><row><cell cols="2">ConfirmLevel</cell><cell>3</cell><cell>72.99</cell><cell></cell></row><row><cell cols="2">Insurance</cell><cell>3</cell><cell>89.66</cell><cell></cell></row><row><cell cols="2">HaveMedicalFee</cell><cell>3</cell><cell>83.63</cell><cell></cell></row><row><cell>Level</cell><cell></cell><cell>12</cell><cell>82.65</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Statistics of the Occupational Injury (OI) dataset. We chose injury identification (InjIdn) and injury level (Level) as the tasks for single-slot prediction, highlighted in bold; all were used to evaluate the decision-sharing mechanism. Details of the dataset can be found in Footnote 2.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Test accuracy (%) on MR, AG, and OI datasets. † Results quoted from previous papers.</figDesc><table><row><cell>Model</cell><cell>MR</cell><cell cols="3">AG OI-Level OI-InjIdn</cell></row><row><cell>CNN  † [Kim, 2014]</cell><cell>81.00</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>fasttext  † [Joulin et al., 2017]</cell><cell>-</cell><cell>92.50</cell><cell>-</cell><cell>-</cell></row><row><cell>Bi-GRU</cell><cell>77.80</cell><cell>92.44</cell><cell>94.75</cell><cell>73.25</cell></row><row><cell>CNN</cell><cell>80.80</cell><cell>92.58</cell><cell>96.25</cell><cell>74.25</cell></row><row><cell>Self-Attentive</cell><cell>82.10</cell><cell>91.40</cell><cell>97.00</cell><cell>73.25</cell></row><row><cell>Hierarchical CNN-GRU</cell><cell>80.23</cell><cell>92.49</cell><cell>95.75</cell><cell>74.75</cell></row><row><cell>JUMPER</cell><cell>80.67</cell><cell>92.62</cell><cell>97.25</cell><cell>75.50</cell></row><row><cell>Dataset</cell><cell>MR</cell><cell cols="3">AG OI-Level OI-InjIdn</cell></row><row><cell cols="2">Avg # of sub-sentences 2.17</cell><cell>3.46</cell><cell>4.88</cell><cell>4.88</cell></row><row><cell>Avg jumping position</cell><cell>1.46</cell><cell>2.04</cell><cell>3.23</cell><cell>2.87</cell></row><row><cell>Reduced %</cell><cell cols="4">32.7% 41.0% 33.8% 41.2%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Statistics of the average number of sub-sentences, the average jumping position and the proportion of reduced text. The onejump constraint enables the model to skip future sentences after a decision is made.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>We see that JUMPER can</figDesc><table><row><cell>Model</cell><cell>CA</cell><cell>JA</cell><cell>OA</cell></row><row><cell>CNN</cell><cell cols="3">96.25 94.81 91.25</cell></row><row><cell>Self-Attentive</cell><cell cols="3">97.00 98.45 95.50</cell></row><row><cell cols="4">Hierarchical CNN-RNN 96.00 98.18 94.25</cell></row><row><cell>JUMPER</cell><cell>97.25</cell><cell>100</cell><cell>97.25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Performance of finding the key rationale in the OI-Level dataset, where information is often local. CA: Classification accuracy. JA: Jumping accuracy. OA: Overall accuracy.</figDesc><table><row><cell>Model</cell><cell>Accuracy dev test</cell><cell>dev</cell><cell>F 1</cell><cell>test</cell></row><row><cell>Bi-GRU</cell><cell cols="4">90.62 90.18 20.02 20.20</cell></row><row><cell>CNN</cell><cell cols="4">92.41 91.64 30.99 29.05</cell></row><row><cell>Self-Attentive</cell><cell cols="4">92.12 91.85 21.26 22.61</cell></row><row><cell cols="5">Hierarchical CNN-GRU 91.56 91.30 24.80 24.44</cell></row><row><cell>JUMPER</cell><cell cols="4">92.43 92.42 26.57 29.60</cell></row><row><cell>JUMPER-sharing</cell><cell cols="4">92.71 92.65 27.57 30.52</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>The average accuracy and F1 on the OI dataset using the decision-sharing mechanism.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1">Segmented by ",.!?" We abuse the terminologies of sentence and sub-sentence for simplicity if not confusing.Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2">Both code and the Occupational Injury dataset are available at: https://github.com/jumper-data</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank anonymous reviewers for their constructive comments. We also thank Daqi Zheng and Fangzhou Liao for their insightful discussion. This work was supported by the Beijing Innovation Center for Future Chip.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2014">2014. 2014. 2016. 2016. 2017</date>
			<biblScope unit="page" from="427" to="431" />
		</imprint>
	</monogr>
	<note>EACL</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding</title>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<meeting><address><addrLine>Mo Yu, Bing Xiang; Bowen</addrLine></address></meeting>
		<imprint>
			<publisher>Cicero Nogueira dos Santos</publisher>
			<date type="published" when="2014">2014. 2014. 2016. 2016. 2017. 2017</date>
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Object-oriented neural programming (oonp) for document understanding</title>
		<author>
			<persName><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName><forename type="first">Gary</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><surname>Mou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.00631</idno>
	</analytic>
	<monogr>
		<title level="m">Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang</title>
				<imprint>
			<publisher>Stefan Ultes</publisher>
			<date type="published" when="2002">2018. 2018. 2017. 2017. 2004. 2002. 2002. 2014. 2014. 2016. 2016. 2012. 2012. 2017. 2017</date>
			<biblScope unit="page" from="438" to="449" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>EACL</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1992">1992. 1992. 2017. 2017</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1880" to="1890" />
		</imprint>
	</monogr>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Relation classification via convolutional deep neural network</title>
		<author>
			<persName><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="2335" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Rationale-augmented convolutional neural networks for text classification</title>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2015">2015. 2015. 2016. 2016</date>
			<biblScope unit="page" from="795" to="804" />
		</imprint>
	</monogr>
	<note>NIPS</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
