<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predictable Programming on a Precision Timed Architecture</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ben</forename><surname>Lickly</surname></persName>
							<email>blickly@eecs.berkeley.edu</email>
						</author>
						<author>
							<persName><forename type="first">Isaac</forename><surname>Liu</surname></persName>
							<email>liuisaac@berkeley.edu</email>
						</author>
						<author>
							<persName><forename type="first">Sungjun</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hiren</forename><forename type="middle">D</forename><surname>Patel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Stephen</forename><forename type="middle">A</forename><surname>Edwards</surname></persName>
							<email>sedwards@cs.columbia.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley, Berkeley</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley, Berkeley</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Columbia University</orgName>
								<address>
									<postCode>10027</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley, Berkeley</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Columbia University</orgName>
								<address>
									<postCode>10027</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley, Berkeley</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Predictable Programming on a Precision Timed Architecture</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">613A7068AF52D0843A05820177427DD9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>C.1.3 [Computer Systems Organization]: Processor Architectures-Other Architectures Styles; C.3 [Special-Purpose and Application-Based Systems]: Realtime and Embedded Systems Timing Predictability</term>
					<term>Memory Hierarchy</term>
					<term>Pipeline</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In a hard real-time embedded system, the time at which a result is computed is as important as the result itself. Modern processors go to extreme lengths to ensure their function is predictable, but have abandoned predictable timing in favor of average-case performance. Real-time operating systems provide timing-aware scheduling policies, but without precise worst-case execution time bounds they cannot provide guarantees.</p><p>We describe an alternative in this paper: a SPARC-based processor with predictable timing and instruction-set extensions that provide precise timing control. Its pipeline executes multiple, independent hardware threads to avoid costly, unpredictable bypassing, and its exposed memory hierarchy provides predictable latency. We demonstrate the effectiveness of this precision-timed (PRET) architecture through example applications running in simulation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Developing hard real-time software on modern processors has grown very difficult because their complexity has made predicting execution speed nearly impossible. Between multi-stage pipelines with hazards, bypassing, and complex interactions between related instructions, superscalar out-of-order instruction fetch units that almost recompile the program on-the-fly, three-level memory hierarchies with complex cache replacement policies, it is extremely difficult to accurately predict exactly how many cycles it will take to execute a sequence of simple instructions <ref type="bibr" target="#b9">[10]</ref>, let alone code with conditional branches. Modern processors are truly chaotic <ref type="bibr" target="#b5">[6]</ref>.</p><p>Unfortunately, worst-case execution time bounds are the foundation on which all real-time software engineering is built. Of course, one can always be conservative with over-estimates, but this has become unrealistic since the difference between hitting level one cache and main memory can be a thousand cycles.</p><p>We believe the solution for real-time embedded software is no less than a rethinking of processor architecture. As has been argued elsewhere <ref type="bibr" target="#b8">[9]</ref>, it is time to consider architectures that provide timing as predictable as their function. In this paper, we propose a concrete example of such a precision-timed (PRET) architectures: a multithreaded processor based on the SPARC instruction set architecture (ISA) that delivers predictable timing along with predictable function and performance. Below, we present a cycleaccurate model of the PRET architecture using SystemC <ref type="bibr" target="#b22">[23]</ref> and an application running on it to demonstrate how software can take advantage of PRET architectures. In the future, we plan an FPGA implementation as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">THE PRET PHILOSOPHY</head><p>The philosophy behind PRET <ref type="bibr" target="#b8">[9]</ref> is that modern processor architecture has gone down an unpredictability hole due to its singleminded focus on average-case performance. It needs to be rethought to be effective for real-time embedded systems. Patterson and Ditzel's similar observation <ref type="bibr" target="#b23">[25]</ref> started the RISC revolution. In the same way, we must rethink real-time embedded processor architectures.</p><p>The complexity of modern processors <ref type="bibr" target="#b12">[13]</ref> has made the task of calculating or even bounding the execution time of a sequence of  <ref type="bibr" target="#b9">[10]</ref>. While this is not critical for besteffort computing, it is a disaster for hard real-time systems.</p><p>The PRET philosophy is that temporal characteristics should be as predictable as function. Much like how arithmetic on a processor is always consistent, predictable, and documented, we want its speed to be equally consistent, predictable, and documented. While turning the clock back to the era of eight-bit microprocessors is one obvious way to achieve this, instead the goal of PRET is to re-think many of the architectural features enabled by rising integration levels and render them predictable.</p><p>Thus, PRET espouses software-managed scratchpad memories <ref type="bibr" target="#b2">[3]</ref>, thread-interleaved pipelines with no bypassing <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b10">11]</ref>, explicit timing control at the ISA level <ref type="bibr" target="#b14">[15]</ref>, time-triggered communication <ref type="bibr" target="#b16">[17]</ref> with global time synchronization <ref type="bibr" target="#b15">[16]</ref>, and high-level languages with explicit timing <ref type="bibr" target="#b13">[14]</ref>. In this paper, we propose an architecture that embodies many of these tenants, and demonstrate how it can be programmed. In particular, we focus on integrating timing instructions to a thread-interleaved pipeline and a predictable memory system. We then show how to program such a predictable architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RELATED WORK</head><p>The Raw processor of Agarwal et al. <ref type="bibr" target="#b26">[29]</ref> shares certain elements of the PRET philosophy. It, too, employs a software-managed scratchpad instead of an instruction cache <ref type="bibr" target="#b21">[22]</ref>, and definitely takes communication delay into account (the name "raw" is a reminder that its ISA is exposed to wire delay). However, it sports multiple single-threaded pipelines with bypassing, a fairly traditional data cache, and focuses almost purely on performance, as usual at the expense of predictability.</p><p>The Raw architecture is designed as a grid of single-threaded processors connected by a novel interconnection network. While we envision a similar configuration for high-end PRET processors, the implementation we present here does not consider inter-core communication. We may adopt a Raw-like communication network in the future.</p><p>The Java Optimized Processor <ref type="bibr" target="#b25">[27]</ref> enables accurate worst-case execution time bounds, but does not provide support for controlling execution time. The SPEAR <ref type="bibr" target="#b7">[8]</ref> processor prohibits conditional branches, which we find overly restrictive. The REMIC <ref type="bibr" target="#b24">[26]</ref> and KIEL <ref type="bibr" target="#b20">[21]</ref> are predictable in the PRET sense, but they only allow Esterel <ref type="bibr" target="#b4">[5]</ref> as an entry language. Again, we find this overly restrictive; a central goal of our work was to provide a C development environment.</p><p>Ip and Edwards <ref type="bibr" target="#b14">[15]</ref> first implemented the deadline instruction in a very simple non-pipelined processor that did not have C compiler support. This deadline instruction allowed a programmable method to specify the lower bound execution time on segments of program code. Our work extends theirs to a new architecture by borrowing the deadline instruction semantics and integrating it into a thread-interleaved pipeline. We introduce a replaying mechanism to stall particular threads without stalling the entire pipeline. This replaying mechanism is again employed with the deadline instructions.</p><p>The Giotto language <ref type="bibr" target="#b13">[14]</ref> is a novel approach to specifying system timing at the software level. However, it relies on the usual RTOS infrastructure that assumes worst-case execution time is known to establish schedulability <ref type="bibr" target="#b6">[7]</ref>. Our PRET processor would be an ideal target for the Giotto programming environment; constructing one is future work.</p><p>Thread-interleaved pipelines date to at least 1987 <ref type="bibr" target="#b19">[20]</ref>, probably much earlier. Thread-interleaving reduces the area, power and complexity of a processor <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b17">18]</ref>, but more importantly, it promotes predictable execution of instructions in the pipeline. Access to main memory in thread-interleaved pipelines is usually pipelined <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b17">18]</ref>, but modern, large memories usually are not, so instead our approach presents each thread with a window in which it can access main memory. This provides predictable access to memory and mutual exclusion between the threads. We call this a memory wheel.</p><p>The goal of the Virtual Simple Architecture of Mueller et al. <ref type="bibr" target="#b1">[2]</ref> is to enable hard real-time operation of unpredictable processors. They run real-time tasks on a fast, unpredictable processor and a slower, more-predictable one simultaneously, and switch over if the slow ever overtakes the fast. The advantage is that the faster processor will have time to run additional, non-time-critical tasks. By contrast, our PRET approach guarantees detailed timing, not just task completion times, allowing timing to be used for synchronization.</p><p>Scratchpad memories have long been proposed for embedded Boot code This address space contains the boot code used by each thread on startup to initialize all the registers and jump to the start of the thread's program.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shared data (8 MB)</head><p>This address range is reserved in our scheme for data that is shared between multiple threads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Thread-local instructions and data (1 MB per thread)</head><p>First thread starts at address 0x40000000. 512KB is reserved for instruction and the other 512KB for data. Each subsequent thread starts at an offset of 0x100000 bytes from its predecessor. Meaning that the first thread encompasses addresses from 0x40000000-0x400FFFFF, the second 0x40100000-0x401FFFFF, and so on. This approach allows each byte of data in any memory location to be associated uniquely with an address.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Memory-mapped I/O</head><p>We reserve addresses above 0x80000000 for special purposes such as memory-mappings. In particular we follow the map address 0x80000200 to the UART, which is consistent with what our toolchain's GCC generates for printf or puts. systems because they consume less power than caches <ref type="bibr" target="#b3">[4]</ref>, but here we adopt them purely because they enable better predictability. Since scratchpad memories are software managed, the issue of memory allocation schemes become important. Our future work is to build on top of the current PRET architecture and develop a memory allocation scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">OUR ARCHITECTURE</head><p>In this section, we present the design of the PRET processor, its memory system, and ISA extensions to support deadline counters. We have prototyped the PRET architecture (block diagram shown in Figure <ref type="figure" target="#fig_0">1</ref>) with a cycle-accurate SystemC <ref type="bibr" target="#b22">[23]</ref> model that executes programs written in C and compiled with the GNU C compiler. Our simulator implements an extended SPARC v8 ISA <ref type="bibr">[28]</ref>.</p><p>The PRET PROCESSOR component in Figure <ref type="figure" target="#fig_0">1</ref> implements a six-stage thread-interleaved pipeline in which each stage executes a separate hardware thread to avoid the need for bypasses <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b10">11]</ref>. Each hardware thread has its own register file, local on-chip memory, and assigned region of off-chip memory. The THREAD CONTROLLER component is a simple round-robin thread schedulerat any time, each thread occupies exactly one pipeline stage. To handle the stalling of the pipeline predictably, we introduce a replay mechanism that simply repeats the same instruction until the operation completes. Thus, the stalling of one thread does not affect any of the others. The round-robin execution of threads avoids memory consistency issues.</p><p>The memory hierarchy follows a Harvard architecture <ref type="bibr" target="#b12">[13]</ref> that consists of separate fast on-chip scratchpad memories (SPM) for instruction and data, and a large off-chip main memory. They are connected to a direct memory access (DMA) controller responsible for moving data between main memory and the SPMs. Currently, we assume program code fits entirely in the SPMs because we have not developed an automatic program memory management scheme <ref type="bibr" target="#b2">[3]</ref>. The DMA component currently only transfers the program code and data for each thread from main memory to their respective SPMs at power on. As mentioned earlier, memory reads and writes employ the replay mechanism. Each thread has its own access window managed by the MEMORY WHEEL. If a thread misses its window, it blocks until it reaches the start of its window.</p><p>We incorporate a deadline instruction <ref type="bibr" target="#b14">[15]</ref> into our SPARC-based ISA. Such an instruction blocks until a software-programmable dead-line counter reaches zero. Each counter is controlled by a threadlocal phase-locked loop, which can be programmed to count at a rational multiple of the system clock frequency. Below, we describe our implementation in detail. We present the memory system, the memory wheel, the memory map, the thread interleaved pipeline, extension of the timing instructions and the toolchain flow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Memory System</head><p>Caches are known to be a major source of timing unpredictability <ref type="bibr" target="#b27">[30]</ref>, but simply removing them is unacceptable. Instead, we use scratchpad memories for bridging the processor-memory gap. Scratchpad memories are software-managed on-chip memories often employed in hard real-time embedded processors. SPMs are managed by software through DMA transfers, thus avoiding the unpredictability of (often subtle) hardware replacement policies. Each thread-local SPM is 64 KB with 1 cycle latency. We use a 16 MB main memory which we assume to have a realistic latency of 50 ns. This translates to 12.5 cycles on a PRET processor running at approximately 250 MHz, and we round this up to 13 cycles.</p><p>If all threads were able to access the off-chip main memory at arbitrary times, then the off-chip memory access time for one thread could depend on the memory access pattern of another. This type of behavior introduces timing unpredictability and is undesirable. In order to ensure predictable timing, all reads and writes to main memory, such as shared data, must do so through our memory wheel. Like the "hub" in the Parallax Propeller Chip <ref type="bibr">[24]</ref>, this wheel has a fixed round robin schedule for determining which thread is allowed to access memory. Based on the fixed schedule and the time that a thread requests access to main memory, the access can take between 13 and 90 cycles. It is important to note that the exact number of cycles depends only on the cycle in which the request is made, and not on the behavior of other threads or memory access patterns.</p><p>Instead of blocking the entire pipeline during a multi-cycle memory access, we use the replay mechanism as described in the pipeline section. A simple memory management unit selects among the SPMs, the main memory, and memory-mapped I/O based on the address.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Memory Wheel</head><p>The memory wheel controls access to the off-chip main memory in a deterministic and predictable fashion. Each thread is allocated  the wheel schedule repeats every 78 cycles. If a thread starts its access on the first cycle of its window, the access takes exactly 13 cycles. Otherwise, the thread blocks until its window reappears, which may take up to 77 cycles. A successful access after just missing the first cycle of its window results in 77 + 13 = 90 cycles. While this mechanism can cause a thread to block, there is no interthread interaction and the behavior of the window is predictable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Memory Map</head><p>Figure <ref type="figure" target="#fig_2">2</ref> shows the system memory map (addresses are 32 bits). Each piece of memory in the system has a unique global address (main memory and SPMs), but each thread only has access to part of the overall memory map. Addresses 0x3F800000 -0x405FFFFF (14 MB) are main memory, visible to every thread. This layout allows for future expansion: the shared data space can extend downward; thread-local memory can extend upward. Our current implementation has 512 bytes of boot code, 8 MB of shared data and 1 MB total for SPMs. Peripherals start at 0x80000000; we placed a UART at 0x80000200.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Pipeline</head><p>Our architecture implements a six stage thread-interleaved pipeline that supports six independent hardware threads. Each thread has its own set of registers. By design, we implemented one thread per pipeline stage to eliminate dependencies among instructions in the same thread. Thus, it does not need any data hazard detection logic or bypassing.</p><p>The thread controller schedules the threads according to a roundrobin policy and passes a thread identifier to the pipeline that is used to index thread-specific registers and SPMs. In the fetch stage, the instruction pointed to by the current program counter is fetched from the SPM. Because of the thread interleaving, we do not update the program counter of the current thread. Instead, we update the program counter in the except stage. This is acceptable because the current thread will not be fetched until it exits the pipeline at the except stage. This removes the need for any speculative execution because we are sure the program counter is always correct when it is fetched. The decode stage decodes the instruction and sets the corresponding pipeline controls. The regacc stage reads the source operands from the register file and selects between immediate and registered data for the operands. The execute stage performs ALU operations. The mem stage accesses either SPM or main memory. The except stage catches exceptions and writes any results to the register file if there are no exceptions. We update the program counter in this stage after determining its next value depending on stalls and branches.</p><p>Even though we do not need data hazard detection, we do have to consider structural hazards. We address them with a replay mechanism, which we elaborate below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Stalls and the Replay Mechanism</head><p>Our pipeline only updates registers in the except stage. This stage writes data to the register file only if no exception has occurred. This gives a single commit point for each thread. We decide at this commit point whether an instruction needs to be replayed.</p><p>By replaying instructions, we ensure each thread stays in exactly one pipeline stage per cycle before advancing, even for multi-cycle operations such as memory accesses. On a memory stall, for example, the stalled instruction is repeatedly replayed every six cycles until the data is fetched from memory and the thread can continue. Replay thus provides a predictable method for blocking a thread independently of the others, rather than stalling the whole pipeline. The exception stage checks an instruction's replay bit and commits only if the bit is clear. Otherwise, the fetch stage checks and determines the next program counter to be fetched. Therefore, the next iteration of that thread will re-run the same instruction until the multi-cycle operation is complete.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Timing Instructions</head><p>To provide precise timing control to software, we add a "deadline" instruction that allows the programmer to set and access cycleaccurate timers <ref type="bibr" target="#b14">[15]</ref>. This instruction sets a lower bound deadline on the execution time of a segment of code. We provide two types of deadline timers that can be accessed by this instruction: one group counts according to the main clock, the other counts according to a clock generated by a programmable phase-locked loop (PLL). These timers appear as additional registers (Figure <ref type="figure" target="#fig_0">1</ref>) that can only be accessed through the deadline instruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Syntax</head><p>We take the syntax of the deadline instruction from Ip and Edwards <ref type="bibr" target="#b14">[15]</ref>. There is an immediate form, deadi $t i ,v, and a register form, dead $t i ,$r j . Each thread has twelve deadline registers (t 0 -t 11 ), eight of which count instruction cycles, the other four are driven by the PLL; and 32 global registers (r 0 -r 31 ). v is a 13-bit immediate value. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Semantics</head><p>The deadline instruction can only enforce a lower bound on the execution time of code segment; using replay, the deadline instruction blocks the thread whenever the deadline register t i being written is not yet zero.</p><p>Unlike Ip and Edwards <ref type="bibr" target="#b14">[15]</ref>, our processor is pipelined, so we decrease each deadline register once every six clock cycles, i.e., at the instruction execution rate, and the PLL registers at the rate set by the PLL. When a deadline instruction attempts to set a deadline register, it blocks until the deadline register reaches zero, at which point it reloads the register and passes control to the next instruction. Thus, an earlier deadline instruction can set the minimum amount of time that can elapse before the next deadline instruction terminates.</p><p>Currently, if a deadline expires (i.e., the register reaches zero before a deadline instruction reaches it), we do nothing: the deadline instruction simply loads the new value immediately and continues. Later, we plan to allow the architecture to throw an exception when a deadline is missed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Implementation</head><p>To implement the deadline instruction, we chose an unused opcode and followed the usual SPARC instruction coding format, which allowed us to include both register and immediate forms of the instruction. Figure <ref type="figure" target="#fig_7">5</ref> shows two concrete encodings.</p><p>Support for the deadline instruction requires some extra pipeline control logic and deadline registers.  In our pipeline, we check the deadline register in the register access stage and use the replay mechanism to block a deadline instruction until its deadline register is zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Compilation Flow</head><p>We adapted the SPARC toolchain used by the open-source LEON3 implementation <ref type="bibr" target="#b11">[12]</ref>. Figure <ref type="figure" target="#fig_4">3</ref> shows our compilation flow.</p><p>We require the user to provide a main() function for each hardware thread in separate files (e.g., thread0.c). We compile each at locations dictated by our memory map by passing the -Ttext and -Tdata options to the linker. For example, thread0.c starts at address 0x40000000 and thread1.c at 0x40010000. We merge the resulting object files with the setup code and convert them to Motorola S-record (SREC) format. Our simulator then initializes memory with the contents of the SREC files. We plan to use the same SREC files as input to our FPGA implementation of the PRET processor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">BASIC PRET PROGRAMMING</head><p>To illustrate how PRET timing precision can be used for synchronization, we present a simple producer/consumer example with an observer that displays the transferred data. This is a classical mutual exclusion problem in that we must deal with the issue of shared resources. Unlike the classical approach, however, the time that a thread must wait for a lock in our approach is deterministic in that it does not depend on the behavior of the other threads accessing the lock.</p><p>Our approach uses deadline counters and precise knowledge of the timing of instructions to synchronize access to a shared variable used for communication. We take on the role of a worst-case execution time (WCET) analysis tool to analyze the instructions generated from the C programs and compute the exact values for the deadline counters to ensure correct synchronization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Mutual Exclusion</head><p>A general approach to managing shared data across separate threads is to have mutually exclusive critical sections that only a single thread can access at a time. Our memory wheel already guarantees that any accesses to a shared word will be atomic, so we only need to ensure that these accesses occur in the correct order.</p><p>Figure <ref type="figure" target="#fig_5">4</ref> shows the C code for the producer, consumer, and an observer all accessing the shared variable buf (underlined). The producer iterates and writes an integer value to the shared data. The consumer reads this value from this shared data and stores it in an array. For simplicity, our consumer does not perform any other operations on the consumed data. It just stores the data in the array. The observer also reads the shared data and writes it to a memorymapped peripheral.</p><p>The deadline instructions in Figure <ref type="figure" target="#fig_5">4</ref> are marked in bold. We use staggered deadlines at the beginning of each thread to offset  the threads and force the producer to start before the consumer and observer. Inside each thread, deadlines force each loop to run in lock-step with one another, each thread progressing at the same rate. Every loop iteration first executes the critical section of the producer, and then the observer and the consumer in parallel.</p><p>The offsets to achieve this are given by deadlines at the beginning of the program. The deadline of 41, or 41 * 6 = 246 cycles, is the same for the consumer and observer, and this forces both of these threads to enter the loop at the same time. This value is computed from the assembly language instructions and is the minimum deadline that the consumer thread can make. The offset of the producer loop is 28 * 6 = 168 cycles, which is 78 cycles less than the offset of 246 for the consumer and observer. Since this difference is the same as the frequency with which the wheel schedule repeats, this guarantees the producer thread will access the shared data during an earlier rotation of the wheel.</p><p>Once inside the loop, deadlines force each thread to run at the same rate, maintaining the memory access schedule. It is important for this rate to be a multiple of the wheel rate to maintain the schedule. In this example, we would like each loop iteration to take two rotations of the wheel. This allows us to write to the buffer in the first rotation of the wheel, and perform the reads for both the consumer and the observer in the second rotation of the wheel. This also means that our program will function correctly regardless of which C threads are partitioned to which hardware threads. To achieve this, we have set the deadlines in each of the loops to be 26, as 26 * 6 = 156 cycles corresponds exactly two rotations of the wheel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">A SAMPLE APPLICATION: A VIDEO GAME</head><p>Inspired by an example game supplied with the Hydra development board <ref type="bibr" target="#b18">[19]</ref>, we implemented a simple video game in C targeted to our PRET architecture. Our example centers on rendering graphics and is otherwise fairly simple. The objective of the game is to avoid moving obstacles coming at the player's ship. The game ends when the player's ship collides with an obstacle. It uses multiple threads and both types of deadlines to meet its real-time requirements. Our example consists of three main tasks (Figure <ref type="figure" target="#fig_8">6</ref>) running in separate threads: the video driver, which sends pixels in a framebuffer to a VGA port; the graphics controller, which is responsible for depositing pixels in the framebuffer; and the game logic. To the PRET simulator, we added a memory-mapped I/O interface to a VGA controller. The simulator dumps the pixel stream sent to this interface as PBM files for debugging. User input is currently read from an array.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Signal</head><p>For safety, we use a double-buffered command queue for communication between the game logic and the graphics controller, and a double-buffered frame buffer to communicate between the graphics controller and the video driver. During each frame, the game logic puts drawing commands into one of the command queues and the graphics controller interprets those in the other queue and draws them into one of the framebuffers. At the same time, the video controller is displaying the contents of the other framebuffer. This avoids screen flicker and guarantees the contents of each displayed frame is deterministic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">The VGA Driver Thread</head><p>This thread sends groups of sixteen pixels to the VGA controller to display a raster. As mentioned above, we double-buffer the image to avoid glitches: the VGA driver thread takes pixels from one buffer and the graphics controller writes to the other. The timing requirements, listed in Table <ref type="table" target="#tab_1">1</ref>, must be met to produce a stable image.</p><p>Our VGA driver displays four colors (black, white, red, and green) at 640 × 480 resolution with a 60 Hz refresh rate. We set the PLL clock to the 25.175 MHz pixel rate and fill a 32-bit hardware shift register every sixteen clocks. The VGA hardware takes a new pair of bits from this register at the pixel clock rate and sends them to a video DAC connected to a display.   Synchronization requires careful timing. During vertical synchronization (Figure <ref type="figure" target="#fig_10">7</ref>), vsync is asserted for 64 µs. The driver does this by using the PLL deadline instruction to wait 1641 pixel clocks after asserting vsync, then de-asserting it. We also use a deadline instruction to time the vertical backporch (1.02 ms) and the vertical frontporch (350 µs). The driver checks whether it should display the other buffer during vertical sync, and informs the graphics thread if it was requested.</p><p>Horizontal synchronization deadlines are more demanding. (Figure <ref type="figure" target="#fig_11">8</ref>. Horizontal sync is asserted for 3.77 µs (96 pixel times), followed by a 1.89 µs frontporch (24 pixel times). Finally, we use the deadline instruction to control the speed at which data is fed to the video shift register. In a loop, we read data from the framebuffer, wait for the deadline to expire, then write the data to the shift register and update the fetch address.</p><p>Naturally, the inner pixel-drawing loop (Figure <ref type="figure">9</ref>) is the most timing-critical. It requires six instructions: these six instructions must complete in under 16/25.175MHz = 635.6ns. Five of the instructions take six cycles each. However, because it accesses main memory, the load instruction may take as many as 90 cycles, giving a total of 5 × 6 + 90 = 120 cycles overall. This requires a 5.3 ns clock period, or 188 MHz.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Graphics Thread</head><p>Following the example from the Hydra book, our graphics system is sprite-based: to draw to the framebuffer, the graphics thread assembles the overall image starting with a 640 × 480 pixel background, then stacks five 64×64 sprites on top of it. Each sprite may be placed at an arbitrary position on the screen. Figure <ref type="figure" target="#fig_13">11</ref> shows a typical image.</p><p>The graphics thread accepts three types of commands from the main thread through a double-buffered queue: drawing on the background or sprite layer, changing the position of the sprites, and filling the framebuffer according to the contents and position of the sprites and background image.</p><p>Ultimately, each displayed pixel is one of only four colors, but the pixels in our sprites can also be transparent. Such transparent pixels take on the color of any sprite beneath it or the background. The game logic thread takes user input, processes it, and sends commands to the graphic thread. At the moment, we take "user input" from an array; it should come from something like a joystick controller.  The game logic ends the commands for each frame with a screen update request. This prompts the graphics controller to redraw the framebuffer and also blocks the game logic thread until the redraw is complete. This synchronizes the game logic thread to the frame refresh rate, making it operate at a fixed rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Experience and Challenges with Programming for PRET</head><p>Since PRET's programming model has timing constructs, we were able to ensure the real-time constraints of the design with ease. The round-robin scheduling of the threads, predictable execution times of instructions and the deadline instructions make reasoning about the execution time of code segments straightforward.</p><p>However, the method to verify real-time requirement was errorprone; we calculated the timing constraints by hand. In this paper, we had to repeatedly calculate the timing requirement whenever our code is optimized or modified. In this way, it is hard to guarantee the calculated result is always right. Also, calculating by hand is slower than using automated tools for the calculation. We will provide automated methods for calculating and verifying timing constraints.</p><p>In addition, the lack of predictable synchronization primitives such as locks make inter-thread synchronization more challenging. This is because ISAs generally lack timing-predictable synchronization methods. In our game example, we synchronized the different threads by carefully investigating the timing and using deadline instructions as also shown by the simple producer/consumer example. The main advantage from this approach is that we can provide guarantees that the application meets its real-time requirements. We intend to introduce additional instructions that provide timing-predictable synchronization methods for easier programming of the PRET architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">SIMULATION RESULTS</head><p>Although we focus on programming for predictable timing, it is interesting to observe the average-case performance. We compare the performance of the PRET architecture against the LEON3 <ref type="bibr" target="#b11">[12]</ref> SPARC processor. The LEON3 is an implementation of the SPARC v8 ISA for a system-on-chip design. It has a seven-staged conventional pipeline with instruction and data caches, and periph-erals connected through an AMBA bus. We use a subset of the Malardalen WCET benchmarks <ref type="bibr" target="#b0">[1]</ref> and simulate them on the LEON3 and PRET simulators. We compile the benchmarks using GCC's level 3 (-O3) optimization and software floating point (-msoft-float). For PRET, we load the benchmark on one hardware thread and leave the rest empty. Note that our hardwaremultithreaded architecture pays a penalty for these completely sequential benchmarks, since five of its six hardware threads are left idle. One might expect that all of these benchmarks would require exactly six times as many cycles on our architecture as the single threaded SPARC processor, but due to the differences in instruction timings and caching behavior the difference is not that extreme. The cycle counts for the simulation runs are shown in Figure <ref type="figure" target="#fig_15">12(a)</ref>. We use a logarithmic scale for the cycle counts since benchmarks may execute for large varying number of instructions.</p><p>PRET shows a drop in average case performance with every benchmark. This degradation is expected because of PRET's threadinterleaved pipeline. Figure <ref type="figure" target="#fig_15">12(b)</ref> shows the degradation factor for each of the benchmarks and the average degradation factor to be approximately 3.54 for the set of presented benchmarks.</p><p>Note that these benchmarks do not exercise the deadline instruction available in PRET. This is because most architecture such as the LEON3 do not support instructions with the deadline semantics. In addition, we map the benchmark to only one hardware thread. Thus, the simulation runs in Figure <ref type="figure" target="#fig_15">12</ref> do not make full use of PRET's multiple hardware threads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">FUTURE WORK</head><p>We have an enormous amount of future work planned for PRET. One obvious extension is to improve the scratchpad-to-main-memory link. Our current memory wheel, while a step in the right direction, is fairly naive. First of all, modern DRAM is usually banked and designed for burst transfers, yet we treat it as having uniform latency. It should be possible to give each thread a bank that it can access more quickly.</p><p>Modern large off-chip memories are set up for fast burst transfers designed to fill cache lines, yet our current architecture does not take advantage of this. To make the most of shared memory, it would be nice if the thread could move a block of memory to its scratchpad during each turn. The SPARC ISA does not support this at the moment; we plan to add it.</p><p>How software is written can greatly affect how efficiently the memory is used. We plan to integrate many of the algorithms that have been developed for managing scratchpad memory, both for code (traditionally thought of as overlays) and for data. Integrating these with the particular memory movement mechanisms we develop is one of our next projects.</p><p>The memory wheel is one example of what we will expect to be many time-triggered components in a PRET system. An obvious challenge is how to make best use of it by choosing to try to access it at the optimal time. We envision a compiler able to reason about when each instruction will execute (PRET, of course, makes this possible) and thus about when best to attempt access to, say, main memory. This will work something like Dean's software thread integration <ref type="bibr" target="#b28">[31]</ref>, in which a compiler mindful of instruction timing restructures the code to meet real-time deadlines. For periodicaccess components in a PRET setting, we would probably color each instruction with its phase relative to when the thread could access main memory and attempt to reorder instructions to minimize waiting time.</p><p>A compiler for a PRET system would go one step beyond existing C compilers and perform WCET analysis as a normal part of its operation. Perhaps with some user annotation support, it should be able to determine things like loop bounds and see whether the code can meet every deadline. Our goal is to make a timing error as easy to detect, understand, and correct as a syntax error.</p><p>We presented a single-cored PRET machine in this paper, but we plan to extend PRET to multi-core configurations. Much of the basic architecture-the scratchpads and timers-will remain unchanged in this setting, but access to main memory and mechanisms for inter-core communication will have to be added. We envision continuing to take a time-triggered approach in which access to a shared resource like a communications network will be arbitrated periodically.</p><p>Methods for evaluating timing predictability are needed. Our performance results compared the LEON3 with the PRET machine in terms of cycles taken to execute the same set of instructions. This approach does not compare the timing predictability of the processors. For these reasons, we plan on defining a method for testing timing predictability in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">CONCLUSION</head><p>In this paper, we described an architecture that delivers predictable timing and implemented it as a cycle-accurate SystemC model that executes C programs. Our PRET architecture implements and extends the SPARC ISA with a precise timing control instruction called deadline. It presents a two-level memory hierarchy composed of thread-local scratchpad memories and a shared main memory accessed through a memory wheel. We illustrated the programming of a PRET architecture with a simple producer/consumer example and a larger video game example.</p><p>We compared the performance of the PRET core against the LEON3 embedded processor. Our results showed the PRET core to be slower. However, this is an expected degradation in performance caused by the thread-interleaved pipeline architecture of PRET. Note that our comparison favors the LEON3 processor over the PRET architecture. This is because we do not compare the timing predictability of the two processors, which is PRET's forte.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Block Diagram of PRET Architecture</figDesc><graphic coords="2,380.75,159.53,73.70,91.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Memory Map</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Compilation Flow for PRET Simulator</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Simple Producer/Consumer Example</figDesc><graphic coords="5,387.95,53.69,167.66,142.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Encoding of dead $t2,0xFF and dead $t2,$g1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Structure of the Video Game Example</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: VGA Vertical TimingThe VGA driver algorithm is a simple loop: wait for the last pixels to be sent, read color or control data, send these to the VGA controller, and decide what to do next (typically repeat). In this context, control refers to horizontal and vertical synchronization signals. All of this happens at a rate dictated by the pixel-speed PLL clock.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: VGA Horizontal Timing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Pixel Drawing Routine in Assembly</figDesc><graphic coords="7,316.55,168.29,217.94,84.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: A Screen Dump From Our Video Game</figDesc><graphic coords="7,316.80,462.86,215.10,161.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>b i n s e a r c h b u b s o r t c n t c o m p r e s s c r c e d n e x p i n t f a c f f t f i b c a i n s e r t s o r t j a n</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Simulation Runs for LEON3 and PRET Architectures</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>VGA Real-time Constraints</figDesc><table><row><cell></cell><cell cols="2">Time period Pixel periods</cell></row><row><cell>Vertical sync</cell><cell>64µs</cell><cell>1641</cell></row><row><cell>Vertical back-porch</cell><cell>1.02ms</cell><cell>26153</cell></row><row><cell>Drawing 480 lines</cell><cell>15.25ms</cell><cell></cell></row><row><cell>Vertical front-porch</cell><cell>350µs</cell><cell>8974</cell></row><row><cell>Horizontal sync</cell><cell>3.77µs</cell><cell>9 6</cell></row><row><cell>Horizontal back-porch</cell><cell>1.89µs</cell><cell>4 8</cell></row><row><cell>Drawing 640 pixels</cell><cell>25.17µs</cell><cell></cell></row><row><cell>Horizontal front-porch</cell><cell>0.94µs</cell><cell>3 2</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">ACKNOWLEDGMENTS</head><p>This work was supported in part by the Center for Hybrid and Embedded Software Systems (CHESS) at UC Berkeley, which receives support from the National Science Foundation (NSF awards #0720882 (CSR-EHS: PRET) and #0720841 (CSR-CPS)), the U. S. Army Research Office (ARO #W911NF-07-2-0019), the U. S. Air Force Office of Scientific Research (MURI #FA9550-06-0312), the Air Force Research Lab (AFRL), the State of California Micro Program, and the following companies: Agilent, Bosch, HSBC, Lockheed-Martin, National Instruments, and Toyota.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://www.mrtc.mdh.se/projects/wcet/benchmarks.html" />
		<title level="m">Malardalen WCET project / Benchmarks</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Virtual Simple Architecture (VISA): Exceeding the Complexity Limit in Safe Real-Time Systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anantaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Seth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rotenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
			<biblScope unit="page" from="350" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An optimal memory allocation scheme for scratchpad-based embedded systems</title>
		<author>
			<persName><forename type="first">O</forename><surname>Avissar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Embedded Computing Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="6" to="26" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Increasing Energy Efficiency of Embedded systems by Application-Specific Memory Hierarchy Generation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Benini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Macii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Macii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Poncino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Design &amp; Test of Computers</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="74" to="85" />
			<date type="published" when="2000-06">April-June 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The ESTEREL synchronous programming language: design, semantics, implementation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gonthier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science of Computer Programming</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="87" to="152" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Chaos in computer performance</title>
		<author>
			<persName><forename type="first">H</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Temam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chaos: An Interdisciplinary Journal of Nonlinear Science</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2006">013110. Jan. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Schedulability analysis of periodic fixed priority systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Buttazzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1462" to="1473" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Processor support for temporal predictability-the SPEAR design example. Real-Time Systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Delvai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Puschner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Steininger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 15th Euromicro Conference</title>
		<meeting>15th Euromicro Conference</meeting>
		<imprint>
			<date type="published" when="2003">2003. 2003</date>
			<biblScope unit="page" from="169" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The case for the precision timed (PRET) machine</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Design Automation Conference</title>
		<meeting>the 44th Design Automation Conference<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-06">June 2007</date>
			<biblScope unit="page" from="264" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reliable and precise WCET determination for a real-life processor</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ferdinand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Heckmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Embedded Software (EMSOFT)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the International Conference on Embedded Software (EMSOFT)<address><addrLine>North Lake Tahoe, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-10">Oct. 2001</date>
			<biblScope unit="volume">2211</biblScope>
			<biblScope unit="page" from="469" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Multithreaded Soft Processor for SoPC Area Reduction</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Capalija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Vranesic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Annual IEEE Symposium on Field-Programmable Custom Computing Machines (FCCM&apos;06</title>
		<meeting>the 14th Annual IEEE Symposium on Field-Programmable Custom Computing Machines (FCCM&apos;06</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">00</biblScope>
			<biblScope unit="page" from="131" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">LEON3 Implementation of the Sparc V8</title>
		<ptr target="http://www.gaisler.com" />
		<imprint>
			<publisher>Gaisler Research</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Computer Architecture: A Quantitative Approach</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Henessey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Patterson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Morgan Kaufmann Publishers</publisher>
		</imprint>
	</monogr>
	<note>third edition</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Giotto: A time-triggered language for embedded programming</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Henzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Kirsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Workshop on Embedded Software (EMSOFT), volume LNCS 2211</title>
		<meeting>the First International Workshop on Embedded Software (EMSOFT), volume LNCS 2211<address><addrLine>Tahoe City, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A processor extension for cycle-accurate real-time software</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J H</forename><surname>Ip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IFIP International Conference on Embedded and Ubiquitous Computing (EUC)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the IFIP International Conference on Embedded and Ubiquitous Computing (EUC)<address><addrLine>Seoul, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-08">Aug. 2006</date>
			<biblScope unit="volume">4096</biblScope>
			<biblScope unit="page" from="449" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Time synchronization in a local area network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Johannessen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Control Systems Magazine</title>
		<imprint>
			<biblScope unit="page" from="61" to="69" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">TTP -A Protocol for Fault-Tolerant Real-Time Systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kopetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Grünsteidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="23" />
			<date type="published" when="1994-01">Jan. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improving pipelined soft processors with multithreading</title>
		<author>
			<persName><forename type="first">M</forename><surname>Labrecque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Steffan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Field Programmable Logic and Applications (FPL)</title>
		<meeting><address><addrLine>Amsterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-08">August 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Game Programming for the Propeller Powered HYDRA</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lamothe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Parallax, Inc</publisher>
			<pubPlace>Rocklin, California</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Pipeline interleaved programmable DSP&apos;s: Architecture</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Messerschmitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1320" to="1333" />
			<date type="published" when="1987-09">Sept. 1987</date>
		</imprint>
	</monogr>
	<note>ASSP-</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An Esterel processor with full preemption support and its worst case reaction time analysis</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lukoschus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Von Hanxleden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 International Conference on Compilers, Architectures and Synthesis for Embedded Systems</title>
		<meeting>the 2005 International Conference on Compilers, Architectures and Synthesis for Embedded Systems</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="225" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Software-based instruction caching for embedded processors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)<address><addrLine>San Jose, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-10">Oct. 2006</date>
			<biblScope unit="page" from="293" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Open SystemC Initiative (OSCI)</title>
		<ptr target="http://www.systemc.org" />
	</analytic>
	<monogr>
		<title level="m">SystemC Simulation Library</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The case for the reduced instruction set computer</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Ditzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="25" to="33" />
			<date type="published" when="1980-10">Oct. 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">REMIC: design of a reactive embedded microprocessor core</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Salcic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Roop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Biglari-Abhari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 conference on Asia South Pacific design automation</title>
		<meeting>the 2005 conference on Asia South Pacific design automation</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="977" to="981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">JOP: A Java Optimized Processor</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schoeberl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Java Technologies for Real-time and Embedded Systems (JTRES 2003)</title>
		<meeting><address><addrLine>Catania, Sicily, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-11">November, 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The Raw microprocessor: A computational fabric for software circuits and general purpose programs</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="25" to="35" />
			<date type="published" when="2002-04">March/April 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Design for Timing Predictability</title>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wilhelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Real-Time Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="177" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Supporting demanding hard-real-time systems with STI</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Welch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">O</forename><surname>Kanaujia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seetharam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Thirumalai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1188" to="1202" />
			<date type="published" when="2005-10">Oct. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
