<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicting Intervention Approval in Clinical Trials through Multi-Document Summarization</title>
				<funder ref="#_JUJy7mR">
					<orgName type="full">ERA</orgName>
				</funder>
				<funder ref="#_ZwJb98E">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-04-01">1 Apr 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Georgios</forename><surname>Katsimpras</surname></persName>
							<email>gkatsibras@iit.demokritos.gr</email>
							<affiliation key="aff0">
								<orgName type="institution">NCSR Demokritos</orgName>
								<address>
									<settlement>Athens</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Georgios</forename><surname>Paliouras</surname></persName>
							<email>paliourg@iit.demokritos.gr</email>
							<affiliation key="aff0">
								<orgName type="institution">NCSR Demokritos</orgName>
								<address>
									<settlement>Athens</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Predicting Intervention Approval in Clinical Trials through Multi-Document Summarization</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-04-01">1 Apr 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2204.00290v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Clinical trials offer a fundamental opportunity to discover new treatments and advance the medical knowledge. However, the uncertainty of the outcome of a trial can lead to unforeseen costs and setbacks. In this study, we propose a new method to predict the effectiveness of an intervention in a clinical trial. Our method relies on generating an informative summary from multiple documents available in the literature about the intervention under study. Specifically, our method first gathers all the abstracts of PubMed articles related to the intervention. Then, an evidence sentence, which conveys information about the effectiveness of the intervention, is extracted automatically from each abstract. Based on the set of evidence sentences extracted from the abstracts, a short summary about the intervention is constructed. Finally, the produced summaries are used to train a BERT-based classifier, in order to infer the effectiveness of an intervention. To evaluate our proposed method, we introduce a new dataset which is a collection of clinical trials together with their associated PubMed articles. Our experiments demonstrate the effectiveness of producing short informative summaries and using them to predict the effectiveness of an intervention.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Clinical Trials (CT) present the basic evidencebased clinical research tool for assessing the effectiveness of health interventions. Nevertheless, only a small number of interventions make it successfully through the process of clinical testing. Approximately, 39%-64% of interventions actually advance to the next step of each phase of clinical trials <ref type="bibr" target="#b7">(DiMasi et al., 2010)</ref>. The uncertainty of a CT outcome could lead to increased costs, prolonged drug development and ineffective treatment for the participants. At the same time, the volume of published scientific literature is rapidly growing and offers the opportunity to explore a valuable knowledge. Therefore, there is a need to develop new tools which can i) integrate such information and ii) enhance the process of intervention approval in CT.</p><p>Predicting the approval of an intervention, a task that describes the ability of a system to predict whether an intervention will reach the final stage of clinical testing, is a topic that has been studied before <ref type="bibr" target="#b11">(Gayvert et al., 2016;</ref><ref type="bibr" target="#b26">Lo et al., 2018)</ref>. The majority of these studies use various traditional machine learning methods and rely on structured data from various sources, including biomedical, chemical or drug databases <ref type="bibr" target="#b28">(Munos et al., 2020;</ref><ref type="bibr" target="#b15">Heinemann et al., 2016)</ref>. However, only a few studies take into account the textual information that is available online, and mostly in a supplementary manner <ref type="bibr" target="#b10">(Follett et al., 2019;</ref><ref type="bibr" target="#b12">Geletta et al., 2019)</ref>. In fact, employing natural language processing (NLP) techniques to address the outcome prediction task has been hardly explored.</p><p>Recognising this lack of related studies, the work presented here addresses the task of predicting intervention approval with the use of NLP. Particularly, we relied on generating concise and informative summaries from multiple texts that are relevant to the intervention under evaluation. In a sense, we built an intervention-specific narrative which combines key information from multiple inter-connected documents. The benefit of using multiple articles to generate summaries is that they can cover the inherently multi-faceted nature of an intervention's clinical background.</p><p>More precisely, given an intervention, our system retrieves all PubMed abstracts that are relevant to the intervention and refer to a clinical study. It then extracts the evidence sentences from each abstract using a BERT-based evidence sentence classifier, in a similar fashion to <ref type="bibr" target="#b6">(DeYoung et al., 2020)</ref>. This set of evidence sentences, which captures the consolidated narrative about the intervention, can grow gradually, as new articles become available. Thus, further analysis is necessary in order to select the most important information. Using the set of evidence sentences for each intervention, we generate short summaries by leveraging the power of language models (BERT or BART). The resulted summaries are then fed to a BERT-based binary sequence classifier which makes a prediction about the likely approval or not of the intervention.</p><p>Overall, the main contributions of the paper are the following:</p><p>? We propose a new approach for predicting the approval of an intervention which is based on a three-step NLP pipeline.</p><p>? We provide a new dataset for the task of intervention approval prediction that consists of 704 interventions and 15,800 PubMed articles in total.</p><p>? We confirm through experimentation the effectiveness of the proposed approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Intervention Success Prediction The prediction of intervention approval belongs to a broader category of medical prediction tasks. Relevant work includes clinical trial outcome prediction <ref type="bibr" target="#b28">(Munos et al., 2020;</ref><ref type="bibr" target="#b33">Tong et al., 2019;</ref><ref type="bibr" target="#b16">Hong et al., 2020)</ref>, drug approval <ref type="bibr" target="#b11">(Gayvert et al., 2016;</ref><ref type="bibr" target="#b26">Lo et al., 2018;</ref><ref type="bibr" target="#b32">Siah et al., 2021;</ref><ref type="bibr" target="#b15">Heinemann et al., 2016)</ref>, clinical trial termination <ref type="bibr" target="#b10">(Follett et al., 2019;</ref><ref type="bibr" target="#b12">Geletta et al., 2019;</ref><ref type="bibr" target="#b8">Elkin and Zhu, 2021)</ref>, predicting phase transition <ref type="bibr" target="#b14">(Hegge et al., 2020;</ref><ref type="bibr" target="#b31">Qi and Tang, 2019)</ref>. All these studies rely either on specific types of structured data or on combining structured data with limited unstructured data.</p><p>Differently from this line of work, the authors of <ref type="bibr" target="#b20">(Lehman et al., 2019)</ref> proposed an approach that employs NLP to infer the relation between an intervention and the outcome of a specific clinical trial. Their method is based on extracting evidence sentences from unstructured text. An extension of this work suggests the use of BERT-based language models for the same task <ref type="bibr" target="#b6">(DeYoung et al., 2020)</ref>. Another closely related study <ref type="bibr" target="#b17">(Jin et al., 2020)</ref>, performs a large-scale pre-training on unstructured text data to infer the outcome of a clinical trial. Our approach builds upon this related work, aiming to incorporate information from multiple articles. This extension is motivated by the assumption that the inter-connected clinical knowledge, coming from multiple sources can provide a more holistic picture of the intervention, facilitating more precise analysis and accurate prediction.</p><p>Although all these prior efforts tackle, more or less, the problem of intervention approval, none of them attempted to predict the effectiveness of an intervention using summarization methods.</p><p>Summarization The goal of summarization is to produce a concise and informative summary of a given text. There are two main categories of approaches: i) extractive, which tackles summarization by selecting the most salient sentences from the text without changing them, and ii) abstractive, which attempts to generate out-of-text words or phrases instead of extracting existing sentences. Early systems were primarily extractive and relied on sentence scoring, selection and ranking <ref type="bibr" target="#b0">(Allahyari et al., 2017)</ref>. However, both extractive and abstractive approaches have advanced significantly due to the novel neural network architectures, such as Transformers <ref type="bibr" target="#b34">(Vaswani et al., 2017)</ref>. The Transformers architecture is utilized by the BERT <ref type="bibr" target="#b4">(Devlin et al., 2018)</ref> and BART <ref type="bibr" target="#b21">(Lewis et al., 2019)</ref> language models which are used by the state-of-the art solutions for multiple NLP tasks, including summarization. Although most of the summarization literature focuses on single-document approaches, there is also a line of work that applies summarization on a set of documents, i.e. multi-document summarization <ref type="bibr" target="#b27">(Ma et al., 2020)</ref>. Such approaches are of particular relevance to our work, as we aim to summarize a set of sentences about a particular intervention.</p><p>Summarization in the Medical Domain Summarization has been used to address various problems in the field of medicine. These include electronic health record summarization <ref type="bibr" target="#b22">(Liang et al., 2019)</ref>, medical report generation <ref type="bibr" target="#b38">(Zhang et al., 2019;</ref><ref type="bibr" target="#b24">Liu et al., 2021)</ref>, medical facts generation <ref type="bibr" target="#b36">(Wallace et al., 2021;</ref><ref type="bibr" target="#b35">Wadden et al., 2020)</ref> and medical question answering <ref type="bibr" target="#b3">(Demner-Fushman and Lin, 2006;</ref><ref type="bibr" target="#b29">Nentidis et al., 2021)</ref>.</p><p>Our work is inspired by recent work on multidocument summarization of medical studies <ref type="bibr" target="#b5">(DeYoung et al., 2021)</ref>. Apart from introducing a new summarization dataset of medical articles, that work also proposed a method to generate abstractive summaries from multiple documents. Their model is based on the BART language model, appropriately modified to handle multiple texts. Our model differs in the way it handles the input texts. Instead of concatenating all texts into a single representative document, we order them chronologically and split them into equal-size chunks. Doing so, we expect the clinical studies that were conducted during a similar time period, to reside in the same chunk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task Overview</head><p>According to the U.S. Food and Drug Administration (FDA), a CT addresses one of five phases of clinical assessment: Early Phase 1 (former Phase 0), Phase 1, Phase 2, Phase 3 and Phase 4. Each phase is defined by the study's objective, the interventions under evaluation, the number of participants, and other characteristics<ref type="foot" target="#foot_0">1</ref> . Notably, Phase 4 clinical trials take place after FDA has approved a drug for marketing. Therefore, we can assume that a CT in Phase 4 assesses effective intervention. On this basis, our task is to predict whether an intervention will advance to the final stage of clinical testing (Phase 4), as shown in Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>We model the task of predicting the success or failure of an intervention as a binary classification task. All data relevant to Phase 4 are omitted from the training stage. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head><p>In this work, we introduce a new dataset<ref type="foot" target="#foot_1">2</ref> for the task of predicting intervention approval. The dataset is a collection of structured and unstructured data in English derived from clinicaltrials.gov and PubMed during May-June 2021.</p><p>As a first step in the construction of the dataset, we retrieve all available CT studies from clinicaltrials.gov that satisfy some criteria. Then, we associate each CT with PubMed articles based on the CT study identifier. Following some cleaning process (i.e. deduplication and entity resolution) we generate the final dataset.</p><p>Clinical Trials Studies At the time of writing, more than 350,000 studies were available online at clinicaltrials.gov. We focused on cancer related clinical testing and we retrieved approximately 85,000 studies related to this topic using a list of associated keywords<ref type="foot" target="#foot_2">3</ref> .</p><p>From this set, we were interested in interventional clinical trials and specifically in two categories that indicate the status of the trial: i) "Completed", meaning that the trial has ended normally, and ii) "Terminated", meaning that the trial has stopped early and will not start again. The resulting set of studies contains 34,517 completed and 6,872 terminated trials.</p><p>Interventions Dataset Using the selected CTs, we associated each intervention with its corresponding trials. Therefore, a clinical trial record was formed for each intervention. Then, we selected all interventions that are assessed in at least one Phase 4 CT to form our positive target class (i.e. approval). Likewise, we built our negative target class (i.e. termination) using interventions that led to a trial termination. In total, our dataset contains 404 approved and 300 terminated interventions.</p><p>For each intervention, we collect all articles from PubMed that are explicitly related to one of the CTs of the intervention. To achieve this, we combine two approaches. First, we search for eligible articles (or links to articles) in the corresponding structured results of clinicaltrials.gov. Secondly, we use the CT unique identifiers to query the PubMed database. Then, the selected PubMed articles are associated with the intervention. This way an intervention is linked with multiple studies that are inter-connected, and thus an intervention-specific narrative is developed. In our dataset, an intervention is associated on average with 22.4 pubmed articles, though for terminated interventions this number is just 1.4. This is because terminated interventions are usually not assessed in many CTs. Overall, our dataset contains 15,800 pubmed articles. The details of the dataset are presented in Table <ref type="table" target="#tab_0">1</ref>.</p><p>In addition, we attempted to evaluate 4 our approach on a previously used dataset <ref type="bibr" target="#b11">(Gayvert et al., 2016)</ref>, which consists of 884 (784 approved, 100 terminated) drugs along with a set of 43 features, including molecular properties, target-based properties and drug-likeness scores.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Methodology</head><p>In Figure <ref type="figure" target="#fig_1">2</ref>, we illustrate the proposed approach, which consists of three main steps. Initially, we use the abstracts of the intervention's clinical trial record to extract evidence sentences. These sentences are then used to generate a short summary that contains information about the efficacy of the intervention. The summary is then processed by a BERT-based sequence classifier to make the final decision about the intervention. Each of the three steps is detailed in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evidence Sentences</head><p>Identifying evidence bearing sentences in an article for a given intervention is an essential step in our approach. Differently from other sentences in an article, evidence sentences contain information about the effectiveness of the intervention (Figure <ref type="figure" target="#fig_2">3</ref>). Therefore, it is crucial that our model has the ability to discriminate between evidence and nonevidence sentences.</p><p>First, all abstracts related to the given intervention are broken into sentences. The sentences of each abstract are then processed one-by-one by a BERT-based classifier that estimates the probability of each sentences containing evidence about the effectiveness of the intervention. For the classifier, we selected a version of the PubMedBERT <ref type="bibr" target="#b13">(Gu et al., 2020)</ref> model, which is pre-trained only on abstracts from PubMed. We tested several models, including BioBERT <ref type="bibr" target="#b19">(Lee et al., 2020)</ref>, clinical-BERT <ref type="bibr" target="#b1">(Alsentzer et al., 2019)</ref> and RoBERTa <ref type="bibr" target="#b25">(Liu et al., 2019)</ref>, but PubMedBERT performed the best in our task. On top of PubMedBERT, we trained a linear classification layer, followed by a Softmax, using the dataset from <ref type="bibr" target="#b6">(DeYoung et al., 2020)</ref>. This dataset is a corpus especially curated for the task of evidence extraction and consists of more than 10,000 annotations. The classifier is trained with annotated evidence sentences (i.e. positive samples) and a random sample of non-evidence sentences (i.e. negative samples). Regarding the ratio of positive to negative samples, cross-validation on the training set showed 1:4 to be a reasonable choice. The evaluation of the different BERT-based models was done based on the same data splits (train, test and validation) as in <ref type="bibr" target="#b6">(DeYoung et al., 2020)</ref>. Once scored by the classifier, the highest scoring sentence is selected from each abstract. Therefore, for each intervention we extract as many sentences as the number of abstracts in its clinical record.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Short Summaries</head><p>To generate short and informative summaries we explore both extractive and abstractive approaches.</p><p>Extractive Summaries were based on the evidence sentences extracted in the previous step. Specifically, we re-rank them and choose the top k (k = 5) to compose our final summary. The model we use here is the same BERT-based model as in Section 5.1.</p><p>Abstractive Considering that an intervention is linked to multiple abstracts and thus to multiple evidence sentences, we first order all evidence sentences chronologically and combine them into a single text. Then, we split them to equal chunks<ref type="foot" target="#foot_3">5</ref> and each chunk then is fed to a BART-based model to produce the final summary.</p><p>BART has been shown to lead to state-ofthe-art performance on multiple datasets <ref type="bibr" target="#b9">(Fabbri et al., 2021)</ref>. Specifically, we used the pre-trained distilBART-cnn-12-6 model which is trained on the CNN summarization corpus <ref type="bibr" target="#b23">(Lins et al., 2019)</ref>. Since abstractive summarization produces out-oftext phrases, it needs to be fine-tuned with domain knowledge. In our case, we fine-tuned the BART model with the MS2 dataset <ref type="bibr" target="#b5">(DeYoung et al., 2021)</ref>, which contains more than 470K articles and 20K summaries of medical studies.</p><p>We limited the length of the output summary to 140 words. For the extractive setting, in case the top k sentences exceeded this limit, we removed the extra words. For the abstractive setting we iteratively summarized and concatenated the chunks for each intervention until the expected number of 140 words was accomplished.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Inferring Efficacy</head><p>We model the task of inferring the approval of an intervention as a binary classification task. In our approach, each intervention is represented by a short summary. For the classification of the summaries, we used again a PubMedBERT model. On top of it, we trained a linear classification layer, followed by a sigmoid, using the summaries generated in the previous step: Our positive training instances were the summaries of interventions that have been approved, and correspondingly, the negative ones were the summaries of interventions that have been terminated. Hence, the model decides on the approval of the interventions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Technical set-up</head><p>All models were pre-trained and fine-tuned for the corresponding task. The maximum sequence size was 512 and 1024 for BERT-based and BARTbased models respectively. The Adam optimizer (Kingma and Ba, 2015) was used to minimize the cross-entropy losses with learning rate 2e-5 and epsilon value 1e-8 for all models. We trained all models for 5 epochs, with batch sizes of 32, except the abstractive summarizer for which the batch size was decreased to 4 due to RAM memory limitations of our system. The implementation was done using the HuggingFace library <ref type="bibr" target="#b37">(Wolf et al., 2020)</ref> and Pytorch <ref type="bibr" target="#b30">(Paszke et al., 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Analysis</head><p>We followed different training approaches for the different trainable components of our pipeline. For the evidence sentence selection and the abstractive summarization models we split the data into development and test and then split the development set further into training (90%) and validation (10%). We kept the model that performed best on the validation set and evaluated it on the held-out test set of each task respectively, averaged over three random data splits. Considering the small size of the interventions dataset, we applied a 10-fold cross validation for the final classification task. For this task, we report macro averages of the evaluation metrics over the ten folds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Ablation Study</head><p>Our experimentation started with a comparison of different variants and choices that were available for the various modules of our approach.</p><p>Evidence Classifier Coming early in the pipeline, the performance of the evidence classifier can play a significant role in downstream tasks. The chosen approach relied on domain-specific BERT models. As domain-specific training that can affect the performance of BERT-based models, we conducted a comparison between different variants of BERT. The results in Table 2 demonstrate that the performance of the models is comparable, with all models obtaining scores over 90% in terms of F1 and AUC. PubMedBERT model achieved the best scores and was used in the rest of the experiments. <ref type="bibr">BioBERT .928 .938 .933 .957 ClinicalBERT .913 .925 .919 .945 RoBERTa .905 .919 .912 .931 PubMedBERT .931 .956 .943 .969</ref> Table <ref type="table">2</ref>: The results of the domain-specific BERT variants that were used for the evidence classifier. All models were trained with negative sampling ratio 1:4. The results denote the averages over three random train-test splits.</p><formula xml:id="formula_0">Model P R F1 AUC</formula><p>Summarization Adequacy We assess the performance of the summarization methods on the MS2 dataset which is a collection of summaries extracted from medical studies. The task of the summarizers is to produce texts that approximate the target summaries. We measure the performance of the summarization methods using ROUGE and the results are presented in Table <ref type="table" target="#tab_1">3</ref>. As expected, the abstractive method achieves higher scores, as it has more flexibility in forming summaries. We also observed that domain-specific training improves performance. The abstractive no model is a generic BART model without fine-tuning in the domain. Comparing its performance to the abstractive model, which was fine-tuned on a small sample of the MS2 dataset that was excluded from the evaluation process, we notice a statistically significant improvement. Abstractive methods seem to provide better summaries, however, whether these are more useful than the extractive summaries for our donwstream task is still to be determined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Predicting Intervention Efficiency</head><p>Having made the choices for the individual modules, we now turn to the ultimate task, which is the prediction of the efficiency of the intervention. We evaluate two variations of our proposed method; i) with abstractive summarization denoted as PIAS abs and ii) with extractive summarization denoted as PIAS ext . We compare their performance against two baselines:</p><p>? BS: This is a PubMedBERT model that is trained with a single evidence sentence per intervention (instead of a summary). The sentence is extracted from the most recent PubMed article relevant to the intervention.</p><p>? BN: This is similar to BS but instead of using a single sentence for each intervention it is trained with n evidence sentences extracted from n different articles (n = 3). The articles are selected randomly among the ones referring to the intervention.</p><p>The performance of all models is shown in Table <ref type="table" target="#tab_3">4</ref>. The proposed method outperforms the baselines independent of the summarization methods that is used. Interestingly, even selecting randomly selected evidence sentences seem to help, as BN achieved a higher performance than BS. Still, the use of summarization provides a significant boost over both baseline methods, validating the value of using short summaries to evaluate the efficiency of an intervention. Models that do not take advantage of the inter-connected documents suffer a significant drop in performance. Thus, this result justifies the design of the proposed method.</p><p>We can also observe that the best performance of the proposed method is achieved when using the extractive summarization method. Extractive summaries have demonstrated low ROUGE scores in Section 6.1. Still, they can properly capture the properties involved in the data for the classification task. On the other hand, although the abstractive summarizer achieved better ROUGE scores, it seems that the generated summaries cannot discriminate the target classes (approved or terminated) as well as the extractive ones. This indicates that the quality of the summary, in terms of the ROUGE score, is not decisive in the classification of the intervention.  model is slightly better at predicting the approval of an intervention rather than its termination. This can be explained by the fact that the approved interventions are associated with a considerably larger number of articles than the terminated ones. This leads to richer summaries for the approved interventions and thus to a more informed decision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Predicting Phase Transition</head><p>Early prediction of approval To build our models, we considered all the available data from Phase 1, Phase 2 and Phase 3. However, predicting the success of an intervention at the earliest phase possible is compelling. Therefore, we examine the ability of our model in making early predictions. More precisely, we evaluate PIAS ext model on the following three transitions: Phase 1 to Approval, Phase 2 to Approval and Phase 3 to Approval.</p><p>To perform this experiment, we select the interventions that have CTs in various stages and there is least one article for each phase. In total, this subset contains 249 interventions <ref type="bibr">(193 approved and 56 terminated)</ref>. Then, we use 80% for training and 20% for testing. For each transition, we train our model only with training instances from the corresponding phase. In Table <ref type="table" target="#tab_5">6</ref>, we report the macro average scores over ten random splits of the data.  The results indicate that prediction of approval, while at Phase 1 is very hard, but the transition from Phase 2 and Phase 3 to approval can be predicted with considerable success. The large gap in performance between Phase 1 and Phase 2, 3 transitions is explained by the lack of clinical evidence in early phases.</p><p>Phase to Phase Another interesting and challenging task is to predict the transition of an intervention to the next phase of the clinical trial process. In this experiment, we want to predict Phase 1 to Phase 2 and Phase 2 to Phase 3 transitions. For each transition, we use data only from the former phase for training (e.g. for Phase 2 to Phase 3 transition we use data from Phase 2) for both target classes. Again, we use 80% for training and 20% for testing and present the average scores over ten random splits.  Table <ref type="table" target="#tab_6">7</ref> shows the results for the two transitions, which are comparable to the overall predictive performance of the model. Considering the small size of the datasets used in both phase transition tasks, these results can serve only as an indication of how our model behaves. Further analysis and experiments should be conducted for a more thorough evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Explainability of Predictions</head><p>It is clinically very valuable to identify the factors that contribute most to a particular decision of the classifier. Interestingly, the summaries generated from our models can also serve that purpose very well.</p><p>Table <ref type="table">8</ref> illustrates some examples of interventions along with their abstractive and extractive summaries as produced by our pipeline. For the first intervention, pertuzumab, it is notable that both summaries report a improved median progression-free survival which somewhat explains the prediction. For the second intervention, taxane, the summaries mention the greater incidence of serious adverse events and lower median overall survival, which counts against the approval of the intervention. We also notice that many numerical entities are randomly placed or changed in Intervention PIAS abs PIAS ext pertuzumab the primary endpoint of the study is progressionfree survival. median progression-free survival was 12.4 months in the control group, as compared with 18.5months in the pertuzumab group. median survival was &lt;dig&gt; months, 12.3 months, and 12.5 months, respectively, in the p=0?0141 group and p =0?0% in the qtl group, respectively. the p &lt;dig) group had a significantly improved pathological complete response rate compared with the group without complete response. p=dig&gt; month and qtl were the most significantly different groups in both groups. p =dig&gt; Disease-free survival results were consistent with progression-free survival results and were 81% (95% CI 72-88) for group A, 84% (72-91) for group B, 80% (70-86) for group C, and 75% (64-83) for group D. Patients who achieved total pathological complete Three patients [1.5%; 95% confidence interval (CI) 0.31% to 4.34%] in cohort A experienced four New York No evidence of DDIs for pertuzumab on trastuzumab, trastuzumab on pertuzumab, or pertuzumab on chemotherapy PK was observed. The median progression-free survival (PFS) among patients who received NAT was 15.8 months compared with CNS ORR was 11% (95% CI, 3 to 25), with four partial responses (median duration of response, 4.6 months). taxane the most common serious adverse events were anaemia, upper gastrointestinal haemorrhage, pneumonia, and pneumonia in the trastuzumab emtansine 24 mg/kg weekly group compared with pneumonia, febrile neutropenia, and anaemia in the taxane group. median overall survival was 11.8 months with trastzumab 2.4 mg/ kg weekly and 10.0 months with taxane.2) with taxanes.3) with t-dm1 was not associated with superior os or superior os versus taxane in any subgroup.5-10% of the patients with high body weight and low baseline trast</p><p>The most common serious adverse events were anaemia (eight 4), upper gastrointestinal haemorrhage (eight 4), pneumonia (seven 3), gastric haemorrhage (six 3), and gastrointestinal haemorrhage (five 2) in the trastuzumab emtansine 24 mg/kg weekly group compared with pneumonia (four 4), febrile neutropenia (four 4), anaemia (three 3), and neutropenia (three 3) in the taxane group. Median overall survival was 11.8 months (95 confidence interval ci, 9.3-16.3) with trastuzumab emtansine 2.4 mg/kg weekly and 10.0 months (95 ci, 7.1-18.2) with taxane (unstratified hazard ratio 0.94, 95 ci, 0.52-1.72).</p><p>Table <ref type="table">8</ref>: Examples of generated summaries from our models. These summaries can be used to explain the predictions of the classifier. The second column displays the prediction of the classifier for the specific intervention; denotes approval and denotes termination.</p><p>the abstractive summary. This contributes to the tendency of the abstractive methods to generate "hallucinated" evidence, as observed in the literature <ref type="bibr" target="#b2">(Cao et al., 2018)</ref>. However, the abstractive summaries look more readable. A more exhaustive analysis, including also a human evaluation, is needed to assess the ultimate explainability of these summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>Predicting intervention approval in clinical trials is a major challenge with significant impact in healthcare. In this paper, we have proposed a new pipeline to address this problem, based on stateof-the-art NLP techniques. The proposed method consists of three steps. First, it identifies evidence sentences from multiple abstracts related to an intervention. Then, these sentences are used to produce short summaries. Finally, a classifier is trained on the generated summaries in order to predict the approval or not of an intervention. Moreover, we introduced a new dataset for this task which contains 704 interventions associated with 15,800 abstracts. This data was used to evaluate our pipeline against other baseline models. The experimental results verified the effectiveness of our approach in predicting the approval of an intervention and the contribution of each step of the proposed pipeline to the final result. Further evaluation on predicting phase transitions, showed that our model can assist in all stages of a clinical trial. Besides, the generated multi-document summaries can be naturally used to explain the predictions of the model.</p><p>There are multiple ways to extend this work. In terms of multi-document summarization, there is room to explore more advanced summarization models, quality and performance metrics as well as better explainability assessment. In the bigger picture, we shall also consider to expand the dataset by extending its size and incorporating different types of resources (e.g. drug interaction networks). Finally, we are interested in enhancing the proposed method to incorporate temporal information associated with the CTs to maintain the history of clinical changes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The phases of a clinical trial.</figDesc><graphic url="image-1.png" coords="3,70.87,436.69,218.27,51.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overview of the proposed approach for classifying an intervention.</figDesc><graphic url="image-2.png" coords="4,70.87,70.87,453.54,168.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Evidence sentence identification. The evidence sentences constitute the positive instances whereas the non-evidence sentences the negative ones.</figDesc><graphic url="image-3.png" coords="4,306.43,589.43,217.70,113.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The details of the interventions dataset. |I|, |A| and avg denote the number of interventions, the number of articles and the average number of articles per intervention respectively.</figDesc><table><row><cell>Type</cell><cell>|I|</cell><cell>|A|</cell><cell>avg</cell></row><row><cell>Approved</cell><cell cols="3">404 15,379 38.1</cell></row><row><cell cols="2">Terminated 300</cell><cell>421</cell><cell>1.4</cell></row><row><cell>Total</cell><cell cols="3">704 15,800 22.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>Evaluation of summarization methods on the MS2 dataset. The abstractive no refers to the generic BART model without any fine-tuning in the domain.</figDesc><table><row><cell></cell><cell>R-1</cell><cell>R-2</cell><cell>R-L</cell></row><row><cell cols="4">abstractive no 24.85 4.34 15.48</cell></row><row><cell>abstractive</cell><cell cols="3">39.38 11.98 20.13</cell></row><row><cell>extractive</cell><cell cols="3">19.24 3.22 13.19</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>The classification results of all models. The reported precision, recall and f1 scores the macro averages over ten folds.Analyzing further the performance of our best model, PIAS ext , we report macro average scores for each target class in Table5. We notice that the</figDesc><table><row><cell>class</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>positive (approved)</cell><cell cols="3">.808 .819 .815</cell></row><row><cell cols="4">negative (terminated) .778 .765 .772</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>The performance of our best model, i.e. PIAS ext , for each target class. The scores denote macro averages over ten folds.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>The performance of our best model, i.e. PIAS ext , in predicting phase-to-approval transitions. The scores denote the averages over ten random runs.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>The performance of our best model, i.e. PIAS ext , in predicting phase-to-phase transitions. The scores denote the averages over ten random runs.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://clinicaltrials.gov/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://github.com/nneinn/ct_intervention_approval</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The complete list of the keywords used is: cancer, neoplasm, tumor, oncology, malignancy, neoplasia, neoplastic syndrome, neoplastic disease, neoplastic growth and malignant growth</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>A chunk has length equal to the maximum input length of the BART model (1024).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank the anonymous reviewers for their valuable and constructive comments on this research. This works was partially supported by the <rs type="funder">ERA</rs> <rs type="projectName">PerMed</rs> project <rs type="grantNumber">P4-LUCAT</rs> (<rs type="projectName">Personalized Medicine for Lung Cancer Treatment:Using Big Data-Driven Approaches For Decision Support</rs>) <rs type="grantNumber">ERAPERMED2019-163</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_JUJy7mR">
					<idno type="grant-number">P4-LUCAT</idno>
					<orgName type="project" subtype="full">PerMed</orgName>
				</org>
				<org type="funded-project" xml:id="_ZwJb98E">
					<idno type="grant-number">ERAPERMED2019-163</idno>
					<orgName type="project" subtype="full">Personalized Medicine for Lung Cancer Treatment:Using Big Data-Driven Approaches For Decision Support</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Results on Proctor Dataset</head><p>To further evaluate our method, we attempted a comparison with the method presented in <ref type="bibr" target="#b11">(Gayvert et al., 2016)</ref> using their data. The data contains a list of approved and terminated drugs together with various features. Using this dataset, we experienced two issues that made the comparison incomparable: i) For many drugs we could not find relevant articles in PubMed. The original dataset contains 828 drugs whereas we managed to collect information only for 537. Thus, the scores of our method are not directly comparable to the ones reported in <ref type="bibr" target="#b11">(Gayvert et al., 2016)</ref> ii) Four important features that were used in <ref type="bibr" target="#b11">(Gayvert et al., 2016)</ref> are missing in the dataset. Therefore, the reproduction of the exact model is not possible.</p><p>Despite these facts, we performed a comparison of the methods for the subset that we collected:</p><p>? RF 1 : This model reports the scores from <ref type="bibr" target="#b11">(Gayvert et al., 2016)</ref>.</p><p>? RF 2 : This is a Random Forest model similar to the original one, but it is trained only with the available features.</p><p>The overall performances of all models are depicted in Table <ref type="table">9</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Text summarization techniques: a brief survey</title>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Allahyari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seyedamin</forename><surname>Pouriyeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Assefi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saeid</forename><surname>Safaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><forename type="middle">D</forename><surname>Trippe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">B</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krys</forename><surname>Kochut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advanced Computer Science and Applications</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Emily</forename><surname>Alsentzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">R</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willie</forename><surname>Boag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Hung</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Mcdermott</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.03323</idno>
		<title level="m">Publicly available clinical bert embeddings</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Faithful to the original: Fact aware neural abstractive summarization</title>
		<author>
			<persName><forename type="first">Ziqiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Answer extraction, semantic clustering, and extractive summarization for clinical question answering</title>
		<author>
			<persName><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="841" to="848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Jay</forename><surname>Deyoung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madeleine</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bailey</forename><surname>Kuehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2104.06486</idno>
		<title level="m">Multidocument summarization of medical studies</title>
		<meeting><address><addrLine>Ms</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Jay</forename><surname>Deyoung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iain</forename><forename type="middle">J</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Byron</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.04177</idno>
		<title level="m">Evidence inference 2.0: More data, better models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Trends in risks associated with new drug development: success rates for investigational drugs</title>
		<author>
			<persName><forename type="first">Lanna</forename><surname>Joseph A Dimasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abraham</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Seckler</surname></persName>
		</author>
		<author>
			<persName><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical Pharmacology &amp; Therapeutics</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="272" to="277" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Predictive modeling of clinical trial terminations using feature engineering and embedding learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Magdalyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingquan</forename><surname>Elkin</surname></persName>
		</author>
		<author>
			<persName><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Summeval: Re-evaluating summarization evaluation</title>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Alexander R Fabbri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Kry?ci?ski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="391" to="409" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Quantifying risk associated with clinical trial termination: a text mining approach</title>
		<author>
			<persName><forename type="first">Lendie</forename><surname>Follett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Geletta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcia</forename><surname>Laugerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="516" to="525" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A data-driven approach to predicting successes and failures of clinical trials</title>
		<author>
			<persName><forename type="first">Kaitlyn</forename><forename type="middle">M</forename><surname>Gayvert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><forename type="middle">S</forename><surname>Madhukar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Elemento</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell chemical biology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1294" to="1301" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation in predicting clinical trial terminations</title>
		<author>
			<persName><forename type="first">Simon</forename><surname>Geletta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lendie</forename><surname>Follett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcia</forename><surname>Laugerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC medical informatics and decision making</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Domainspecific language model pretraining for biomedical natural language processing</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Tinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naoto</forename><surname>Usuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.15779</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Predicting success of phase iii trials in oncology</title>
		<author>
			<persName><forename type="first">Stephan</forename><forename type="middle">J</forename><surname>Hegge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><forename type="middle">Erik</forename><surname>Thunecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Krings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonard</forename><surname>Ruedin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><forename type="middle">Saputra</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><surname>Paul Von Buenau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>medRxiv</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reflection of successful anticancer drug development processes in the literature</title>
		<author>
			<persName><forename type="first">Fabian</forename><surname>Heinemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torsten</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Meisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Bundschus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Leser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Drug discovery today</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1740" to="1744" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Predicting successes and failures of clinical trials with an ensemble ls-svr</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jooyong</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Woo</forename><surname>Chan Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changha</forename><surname>Hwang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>medRxiv</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Predicting clinical trial results by implicit evidence integration</title>
		<author>
			<persName><forename type="first">Qiao</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mosha</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaozhong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP 2020 -2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<title level="m">Adam: A method for stochastic optimization. 3rd International Conference on Learning Representations, ICLR 2015 -Conference Track Proceedings</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Biobert: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wonjin</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghyeon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunkyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">So</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1234" to="1240" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Inferring which medical treatments work from reports of clinical trials</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Deyoung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Byron</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL HLT 2019 -2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies -Proceedings of the Conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal ; Abdelrahman Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ves</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.13461</idno>
		<imprint>
			<date type="published" when="2019">Marjan Ghazvininejad,. 2019</date>
			<pubPlace>Bart</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A novel system for extractive clinical note summarization using ehr data</title>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ching-Huei</forename><surname>Tsou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananya</forename><surname>Poddar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Clinical Natural Language Processing Workshop</title>
		<meeting>the 2nd Clinical Natural Language Processing Workshop</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="46" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The cnn-corpus: A large textual corpus for single-document extractive summarization</title>
		<author>
			<persName><forename type="first">Hilario</forename><surname>Rafael Dueire Lins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luciano</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamilson</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Batista</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Tenorio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rinaldo</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Lima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">J</forename><surname>De Fran?a Pereira E Silva</surname></persName>
		</author>
		<author>
			<persName><surname>Simske</surname></persName>
		</author>
		<idno type="DOI">10.1145/3342558.3345388</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM Symposium on Document Engineering 2019, DocEng &apos;19</title>
		<meeting>ACM Symposium on Document Engineering 2019, DocEng &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Competence-based multimodal curriculum learning for medical report generation</title>
		<author>
			<persName><forename type="first">Fenglin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shen</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3001" to="3012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Machine learning with statistical imputation for predicting drug approvals</title>
		<author>
			<persName><forename type="first">Kien</forename><forename type="middle">Wei</forename><surname>Andrew W Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi</forename><forename type="middle">Heem</forename><surname>Siah</surname></persName>
		</author>
		<author>
			<persName><surname>Wong</surname></persName>
		</author>
		<idno>SSRN 2973611</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Multidocument summarization via deep learning techniques: A survey</title>
		<author>
			<persName><forename type="first">Congbo</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><forename type="middle">Emma</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><surname>Sheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.04843</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Improving the prediction of clinical success using machine learning</title>
		<author>
			<persName><forename type="first">Bernard</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Niederreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Riccaboni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Overview of bioasq 2021: The ninth bioasq challenge on large-scale biomedical semantic indexing and question answering</title>
		<author>
			<persName><forename type="first">Anastasios</forename><surname>Nentidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Katsimpras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eirini</forename><surname>Vandorou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Gasco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Krallinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Paliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="239" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Predicting phase 3 clinical trial results by modeling phase 2 clinical trial subject level data using deep learning</title>
		<author>
			<persName><forename type="first">Youran</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Tang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Machine Learning for Healthcare Conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="288" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Predicting drug approvals: The novartis data science and artificial intelligence challenge</title>
		<author>
			<persName><forename type="first">Kien</forename><surname>Wei Siah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Ballerstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bj?rn</forename><surname>Holzhauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianmeng</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mettler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Wandel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Zhou</surname></persName>
		</author>
		<idno>SSRN 3796530</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Machine learning-based modeling of big clinical trials data for adverse outcome prediction: A case study of death events</title>
		<author>
			<persName><forename type="first">Ling</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ron</forename><surname>Cisler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Cantor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="269" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Fact or fiction: Verifying scientific claims</title>
		<author>
			<persName><forename type="first">David</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanchuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><forename type="middle">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madeleine</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP 2020 -2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Generating (factual?) narrative summaries of rcts: Experiments with neural multi-document summarization</title>
		<author>
			<persName><forename type="first">Sayantan</forename><surname>Byron C Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iain</forename><forename type="middle">J</forename><surname>Soboczenski</surname></persName>
		</author>
		<author>
			<persName><surname>Marshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMIA Annual Symposium Proceedings</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="page">605</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.6</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Merck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">Bao</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Curtis</forename><forename type="middle">P</forename><surname>Langlotz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.02541</idno>
		<title level="m">Optimizing the factual correctness of a summary: A study of summarizing radiology reports</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
