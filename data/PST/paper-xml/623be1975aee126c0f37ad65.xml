<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dynamically Refined Regularization for Improving Cross-corpora Hate Speech Detection</title>
				<funder ref="#_PEdQsbG">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder ref="#_m9NQ67J">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tulika</forename><surname>Bose</surname></persName>
							<email>tulika.bose@loria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universite de Lorraine</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<postCode>F-54000</postCode>
									<settlement>Nancy</settlement>
									<region>Inria, LORIA</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
							<email>n.aletras@sheffield.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Irina</forename><surname>Illina</surname></persName>
							<email>illina@loria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universite de Lorraine</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<postCode>F-54000</postCode>
									<settlement>Nancy</settlement>
									<region>Inria, LORIA</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dominique</forename><surname>Fohr</surname></persName>
							<email>dominique.fohr@loria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universite de Lorraine</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<postCode>F-54000</postCode>
									<settlement>Nancy</settlement>
									<region>Inria, LORIA</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dynamically Refined Regularization for Improving Cross-corpora Hate Speech Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Warning: this paper contains content that may be offensive and distressing.</p><p>Hate speech classifiers exhibit substantial performance degradation when evaluated on datasets different from the source. This is due to learning spurious correlations between words that are not necessarily relevant to hateful language, and hate speech labels from the training corpus. Previous work has attempted to mitigate this problem by regularizing specific terms from pre-defined static dictionaries. While this has been demonstrated to improve the generalizability of classifiers, the coverage of such methods is limited and the dictionaries require regular manual updates from human experts. In this paper, we propose to automatically identify and reduce spurious correlations using attribution methods with dynamic refinement of the list of terms that need to be regularized during training. Our approach is flexible and improves the cross-corpora performance over previous work independently and in combination with pre-defined dictionaries. 1 1 Code is available here: https://github.com/ tbose20/D-Ref</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The relative sparsity of hateful content in the real world requires crawling of many of the standard hate speech corpora through keyword-based sampling <ref type="bibr" target="#b25">(Poletto et al., 2021)</ref>, rather than random sampling. Thus, hate speech classifiers <ref type="bibr" target="#b9">(D'Sa et al., 2020;</ref><ref type="bibr" target="#b24">Mozafari et al., 2019;</ref><ref type="bibr" target="#b2">Badjatiya et al., 2017)</ref> often learn spurious correlations from the training corpus <ref type="bibr">(Wiegand et al., 2019)</ref> leading to a substantial performance degradation when evaluated on a corpus with a different distribution <ref type="bibr">(Yin and Zubiaga, 2021;</ref><ref type="bibr" target="#b5">Bose et al., 2021;</ref><ref type="bibr" target="#b11">Florio et al., 2020;</ref><ref type="bibr" target="#b1">Arango et al., 2019;</ref><ref type="bibr">Swamy et al., 2019;</ref><ref type="bibr" target="#b15">Karan and ?najder, 2018)</ref>.</p><p>Recent work has proposed regularization mechanisms to penalize spurious correlations by attempt- ing to explain model predictions using feature attribution methods <ref type="bibr" target="#b28">(Ross et al., 2017;</ref><ref type="bibr" target="#b26">Rieger et al., 2020;</ref><ref type="bibr" target="#b0">Adebayo et al., 2020)</ref>. These methods assign importance scores to input tokens that contribute more towards a particular prediction (Lundberg and Lee, 2017). For instance, <ref type="bibr" target="#b20">Liu and Avci (2019)</ref> penalize the attributions assigned to tokens contained in a manually curated dictionary consisting of group identifiers (e.g. women, jews) that are often known to be targets of hate. <ref type="bibr" target="#b16">Kennedy et al. (2020)</ref> extract group identifiers manually from the top tokens indicated by a bag-of-words logistic regression model trained on the source corpus. However, regularizing only group identifiers limits the coverage of such approaches, and may not capture other forms of corpus-specific correlations learned by the classifier limiting its performance on a new corpus. Moreover, such manually curated lists may not always remain up-to-date because new terms emerge frequently <ref type="bibr" target="#b13">(Grieve et al., 2018)</ref>. While <ref type="bibr">Yao et al. (2021)</ref> do not use such lists for refining models in different target-domains, their method still requires input from human annotators.</p><p>In this paper, we hypothesize that the classification errors in a small annotated subset from the target can reveal spurious correlations between tokens and hate speech labels learned from the source (see Table <ref type="table" target="#tab_0">1</ref>). To this end, we propose Dynamic Model Refinement <ref type="bibr">(D-Ref)</ref>, a new method to identify and penalize spurious tokens using feature attribution methods. We demonstrate that D-Ref improves the overall cross-corpora performance independently and in combination with pre-defined dictionaries. In this section, we describe the general theoretical framework of the proposed approach. We assume that during training our hate speech classification model has access to the source training corpus D train S and a small validation set D val T from a target corpus with different distribution, following a similar setting to <ref type="bibr" target="#b23">Maharana and Bansal (2020)</ref>. Our Dynamic Model Refinement (D-Ref) approach consists of 2 recurring steps across epochs: (i) we first extract a set of spurious tokens using D val T at the end of every epoch; and (ii) then we penalize the extracted tokens during the next epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Extraction of Spurious Tokens</head><p>Global token-ranking in source corpus: We first begin with identifying the tokens from D train S that are highly correlated with hate/non-hate labels. These tokens are suitable candidates for causing source-specific spurious correlations, restricting generalizability to a new corpus.</p><p>For that purpose, at the end of every training epoch </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instance-level local ranking in target corpus:</head><p>We hypothesize that tokens highly correlated with hate/non-hate classes in the source, but also causing mis-classifications in the target, should most likely contribute to spurious source-specific correlations, and may not be important for hate speech labels. Thus, we identify the tokens that cause misclassifications in D val T , and then obtain a list of spurious tokens dynamically after every epoch ep i .</p><p>We rank the tokens in the target instances from D val T based on their loc-atr j tok , starting from the highest attributed token per instance j to the lowest. The top k tokens in j is given by tok</p><formula xml:id="formula_0">j top k = top k [argsort(loc-atr j tok )],</formula><p>where k is a hyper-parameter in D val T . We treat the two error cases of False Positives (FP) and False Negatives (FN) separately. Here the hate class is considered as the positive class.</p><p>Since the tokens responsible for FP may also be important for the True Positives (TP), we only extract those that have high attributions for FP, but not for TP. Further, another filtering step is applied, where only the tokens common to the top N from the ranked gl-hate are extracted. This results in discarding the tokens that may not be globally correlated with a class with respect to the source model. So tok</p><formula xml:id="formula_1">F P = [tok ? tok j F P top k &amp; tok ? tok j T P top k ] ? top N (gl-hate) ? instances j in D val</formula><p>T . Similarly, top k tokens corresponding to FN instances are extracted, wherein those common to TN are discarded, and subsequent filtering based on the gl-nhate is performed, i.e.</p><formula xml:id="formula_2">tok F N = [tok ? tok j F N top k &amp; tok ? tok j T N top k ] ? top N (gl-nhate) ? j.</formula><p>This step thus yields a list of possible spurious tokens at the end of ep i , S ep i = [tok F P , tok F N ] ep i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Penalizing the Extracted Spurious Tokens</head><p>In this step, we attempt to reduce the importance assigned, by the source model, to the extracted spurious tokens by penalizing the terms in S ep i during the next epoch ep i+1 . We propose three different ways for token penalization:</p><p>Tok-mask: In this case, we simply mask the tokens from S ep i present in D train S after every ep i and then train the source model during ep i+1 .</p><p>Reg: Since token masking might eliminate substantial information, we regularize the model using S ep i . The attributions assigned to these terms are pushed towards zero by the following learning objective on D train S :</p><formula xml:id="formula_3">L = L + ?L atr (t) ; t ? S ep i ; L atr = t?Sep i ? (t) 2 (2)</formula><p>where L is the classification loss and L atr is the attribution loss. Here ? (t) is the attribution score for the token t. Intuitively, this should reduce the importance of tokens contributing to source-specific patterns and encourage learning more general information. Both losses are computed over D train S .</p><p>Comb: We finally combine S ep i with the predefined group identifiers from <ref type="bibr" target="#b20">Liu and Avci (2019)</ref> and <ref type="bibr" target="#b16">Kennedy et al. (2020)</ref> to perform regularization using Equation <ref type="formula">2</ref>.</p><p>We surmise that repeating these steps at the end of every epoch should reduce the source-specific correlations while the source model gets trained. We use three different attribution methods:</p><p>(i) Scaled Attention (???) <ref type="bibr" target="#b31">(Serrano and Smith, 2019</ref>): Here attention weights ? i are scaled with their corresponding gradients ?? i = ? ? ?? i , where ? is the predicted label. <ref type="bibr" target="#b31">Serrano and Smith (2019)</ref> show that combining an attention weight with its gradient can better indicate token importance for model predictions, compared to only using the attention weights.</p><p>(ii) Integrated Gradients (IG) <ref type="bibr">(Sundararajan et al., 2017)</ref>: This method is based on the notion that the gradient of a prediction function with respect to input can indicate the sensitivity of the prediction for each input dimension. As such, it aggregates the gradients along a path from an uninformative reference input (e.g. zero embedding vector) towards the actual input such that the predictions change from uncertainty to certainty.</p><p>(iii) Deep Learning Important FeaTures (DeepLIFT/DL) <ref type="bibr" target="#b32">(Shrikumar et al., 2017)</ref>: This aims to explain the difference in the output from a reference output in terms of the difference of the input and a reference input. Given a target output neuron t, a reference activation t 0 of t, and ?t = t -t 0 , it computes the contribution scores C ?x i ?t of each input neuron x i that are necessary and sufficient to compute t, such that n i=1 C ?x i ?t = ?t. The reference input could be the zero embedding vector.  <ref type="bibr">(54.4% hate; train: 32497, val: 1016, test: 4062)</ref>. We reduce the size of available D val T in Dynamic by randomly sampling 25% of the validation set (4064). We remove URLs, split hashtags into words using the CrazyTokenizer<ref type="foot" target="#foot_1">3</ref> , remove infrequent Twitter handles, punctuation marks and numbers, and convert text into lower-case. See Appendix A for a detailed discussion on the corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental</head><p>Baselines We compare D-Ref with the following baselines: (i) BERT <ref type="bibr">Van-FT (Devlin et al., 2019)</ref>: vanilla fine-tuning on D train S without regularization; (ii) Convolutional Neural Network with regularization of pre-defined group identifier terms using IG for feature attribution <ref type="bibr" target="#b20">(Liu and Avci, 2019)</ref>; (iii) BERT using two variations for regularization: (a) all the mentioned group identifiers, (b) group identifiers extracted from the top features of a bagof-words logistic regression trained on each individual corpus <ref type="bibr" target="#b16">(Kennedy et al., 2020)</ref> <ref type="foot" target="#foot_2">4</ref> ; (iv) ?<ref type="foot" target="#foot_0">2</ref> -test with one degree of freedom and Yate's correction <ref type="bibr" target="#b17">(Kilgarriff, 2001)</ref> to extract tokens tok from D train S that reject the null hypothesis with 95% confidence. The null hypothesis states that in terms of tok, both D train S and D val T are random samples of the same larger population. We, then, regularize the attribution scores<ref type="foot" target="#foot_3">5</ref> assigned to these terms, with BERT. (v) Pre-def: BERT with regularizing the combined pre-defined group identifiers from (ii) and (iii).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model training</head><p>We use pre-trained BERT <ref type="bibr" target="#b7">(Devlin et al., 2019)</ref> for our approach. We train all the models over D train S from the source and evaluate over D test T from the target. The best model for all the baselines and D-Ref are selected by tuning over D val T . See Appendix B on hyper-parameter tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Cross-corpora Predictive Performance</head><p>Table <ref type="table" target="#tab_2">2</ref> presents macro-F1 scores across five random initializations of each experiment using six cross-corpora pairs. We observe that overall, all feature-attribution methods with D-  <ref type="bibr" target="#b8">(Dror et al., 2018;</ref><ref type="bibr" target="#b10">Efron and Tibshirani, 1993)</ref>, 95% confidence interval.</p><p>that although the terms obtained through the ? 2 test from the source indicate differences across domains, they may not necessarily be important for the prediction of hate/ non-hate labels by the source model, and may not contribute to source-specific spurious correlations. We find that D-Ref-Reg with IG and DL achieves better average macro-F1 of 58.9 and 58.4 respectively, compared to the corresponding Pre-def (IG) and Pre-Def (DL) that obtain an average of 57.6. D-Ref-Reg (???) provides an average macro-F1 of 58.7, comparable to Pre-def (???) with 58.8. However, D-Ref-Reg achieves significantly improved scores in more cases, as compared to Predef using all the attribution methods, i.e. 4/6 cases (???), 3/6 cases (IG) and 3/6 cases (DL) with D-Ref-Reg, compared to 3/6 (???), 1/6 (IG) and none (DL) with Pre-def. D-Ref-Tok-mask exhibits improvements on average (???: 57.8, IG: 58.2, DL: 57.8) over , demonstrating the effectiveness of the token extraction mechanism of D-Ref. Finally, D-Ref-Comb displays the best overall performance, with the highest average score of 59. We attribute this improvement from D-Ref to its increased coverage with dynamic token extraction, and reduction of spurious source-specific correlations, while the baselines only penalize the group identifiers. A dynamic approach also corrects the model during training before it can get fully biased towards these tokens. Finally, it can incorporate the pre-defined lists along with the extracted tokens, and further improve the performance. (iv) HATN (Hierarchical Attention Transfer Network) <ref type="bibr" target="#b18">(Li et al., 2018</ref><ref type="bibr" target="#b19">(Li et al., , 2017) )</ref> This approach uses attention and a domain adversarial pivot extraction mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Domain-Adaptation Approaches</head><p>(v) Sarwar and Murdock ( <ref type="formula">2021</ref>): This adopts a data-augmentation strategy leveraging a negative emotion dataset <ref type="bibr" target="#b12">(Go et al., 2009)</ref>  T from target for model selection for all the above methods.</p><p>Table <ref type="table">3</ref> shows the results on comparing against other DA approaches. We note that the average performance of all the other DA approaches in this task is lower than Van-MLM-FT, as discussed in our previous work <ref type="bibr" target="#b5">(Bose et al., 2021)</ref>. ? 2 -test, on an average, fails to surpass the Vanilla baseline. Besides, the DA approach proposed for cross-domain hatespeech detection by Sarwar and Murdock (2021) also yields an overall drop in performance. They perform data-augmentation by replacing relevant words from an external negative emotion dataset with tagged hateful terms from the target domain. We find that a major portion of the augmented instances lack meaning, and this negatively impacts the adaptation. However, across all feature attribution methods, D-Ref-Reg improves the crosscorpora performance compared to Van-MLM-FT and the DA approaches, with average macro-F1 of 59.6 (???), 59.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Qualitative Analysis</head><p>Table <ref type="table" target="#tab_5">4</ref> shows the change in attributions for some instances in D test T from Dynamic that were misclassified by Van-FT but correctly classified by our D-Ref-Reg (IG). Van-FT wrongly attributes higher importance to 'f*cking' and 's*cks' for the hate class in the first example, and 'blacks' and 'queers' for non-hate in the second due to source-specific correlations. However, D-Ref-Reg (IG), extracts and penalizes abusive tokens like {s*ck, a**hole, d*ck} for the former causing FP and {africans, dark, queer} for the latter causing FN. Our approach not only penalizes the exact tokens, but also those with similar meaning (e.g. 'blacks' is contextually close to 'dark', 'africans'), giving more importance to the context around the spurious tokens. See Appendix C for the token-lists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We proposed a dynamic approach for automatic token extraction with regularization of the source model such that the spurious source specific correlations are reduced. Our approach shows consistent cross-corpora performance improvements both independently and in combination with pre-defined tokens. Future work includes applying our method on other cross-domain text classification tasks and exploring how explanation faithfulness can be improved in out-of-domain settings <ref type="bibr" target="#b6">(Chrysostomou and Aletras, 2022)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Data Description</head><p>While HatEval and Waseem are sampled from Twitter, Dynamic is generated using a human-andmodel-in-the-loop process. These corpora have been collected across different time frames, and hence they involve different topics of discussion, which are also determined to a large extent by the keywords used for sampling. As such, the problem of dataset bias with spurious correlations are induced with such focused sampling procedures <ref type="bibr">(Wiegand et al., 2019)</ref> used in Waseem and HatEval.</p><p>For instance, in Waseem, a large amount of tweets, available at the time of our experiments, consist of hate tweets directed against women, which results in False Positives for instances from other corpora that contain women related terms. We observed that most of the racist tweets were already removed and were unavailable for experiments. HatEval, on the other hand, has a mix of tweets directed against women and immigrants, and hence it demonstrates decent performance when evaluated over Waseem that consists of sexist tweets. On the contrary, Dynamic contains annotator-generated tweets that includes challenging perturbations. For instance, it includes non-hate instances like 'It's wonderful having gay people around here', 'I hate the concept of hate', 'Tea is f*cking disgusting', which can easily fool a classifier learned on biased datasets, and result in classifying these instances as hateful. Moreover, this corpus covers different targets of hate. As such, when Dynamic is used as the target corpus, the spurious correlations learned by the source classifier become relatively well-visible, which are captured and penalized by D-Ref while the source model gets trained. The data used in the work are publicly available, and download links are provided in the respective original articles, which are referenced in this paper. However, in the case of Waseem, where only tweet IDs are provided, some tweets might be unavailable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Implementation Details</head><p>We leverage the pretrained BERT-base model<ref type="foot" target="#foot_4">6</ref> for our experiments. We use a batch size of 8, learning rate of 1 ? 10 -5 and Adam optimizer with decoupled weight decay regularization <ref type="bibr" target="#b21">(Loshchilov and Hutter, 2019)</ref> for Van-FT, Van-MLM-FT, D-Ref and Pre-def. For Integrated Gradients, following <ref type="bibr" target="#b20">Liu and Avci (2019)</ref>, the interpolated embeddings are treated as constants while back-propagating the loss from the regularization term. An all zero embedding vector is used as the baseline input for both Integrated Gradients and DeepLIFT. We use the original code, as provided by the respective authors, for all the prior-arts. For Pre-Def, we combined the pre-defined lists from <ref type="bibr" target="#b16">Kennedy et al. (2020)</ref> and <ref type="bibr" target="#b20">Liu and Avci (2019)</ref> and regularized their attribution scores over BERT with ???, IG, and DL as feature attribution methods.</p><p>We implement the data-augmentation approach proposed by Sarwar and Murdock (2021) ourselves due to the absence of an available implementation.</p><p>Following the description present in the paper, we prepare the training data for the sequence tagger by labeling all the terms in the hateful instances from the source corpus that are also present in the lexicon from hatebase.org 7 . However, we do not tokenize the lexicon obtained from hatebase.org while searching for the corresponding matching terms in the source corpus. We convert the lexicon into lower-case and look for the exact match in the source corpus.</p><p>For D-Ref, we set the value of top N tokens used from ranked {glist-hate, glist-nhate} as 500. The values of k ? top {10%, 20%, 30%, 40%} of the instance-length in D-Ref, and ? in both D-Ref and Pre-def are selected through hyper-parameter tuning over D val T using a random seed. For ??? and DeepLIFT, ? ? {0. <ref type="bibr">1,</ref><ref type="bibr">0.5,</ref><ref type="bibr">1,</ref><ref type="bibr">10,</ref><ref type="bibr">20,</ref><ref type="bibr">30,</ref><ref type="bibr">40,</ref><ref type="bibr">50,</ref><ref type="bibr">60} and for IG,</ref><ref type="bibr">? ? {1,</ref><ref type="bibr">10,</ref><ref type="bibr">20,</ref><ref type="bibr">30,</ref><ref type="bibr">40,</ref><ref type="bibr">50,</ref><ref type="bibr">60}.</ref> We run supervised fine-tuning on D train S for 6 epochs with all the BERT models (prior-arts and D-Ref). We select the models (prior-arts and D-Ref) by tuning over D val T from the target corpus, with respect to macro-F1 scores. Table <ref type="table" target="#tab_7">5</ref> presents the macro-F1 scores obtained on the validation set for D-Ref and the prior arts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Tokens extracted in different epochs</head><p>The list of error-causing tokens for False Positives (FP) and False Negatives (FN) in D val T , extracted for the cases presented in Section 3.4, is given below. We underline the tokens present in the visualization examples (both Table <ref type="table" target="#tab_5">4</ref>  Since, the Waseem dataset is made available as tweet IDs, we observed that it mostly contains sexist comments, while most of the racist content must have been removed before we could crawl it. Hence, the tokens related to race mostly occur in non-hate contexts causing FN.</p><p>Even though some error-causing tokens remain in the list until the end, their overall effect should be reduced as the regularization is performed throughout the training procedure, which causes improvement in macro F1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D In-corpus performance</head><p>We present the in-corpus performance, i.e. the performance on the source corpus in terms of macro-F1 scores, obtained when the source model is refined for the corresponding target corpus using D-Ref-Reg, in Table <ref type="table" target="#tab_8">6</ref>. For D-Ref-Reg, the model is</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>arXiv:2203.12536v1 [cs.CL] 23 Mar 2022 2 Dynamic Model Refinement (D-Ref)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>ep i , we first obtain the global class-specific ranked list of tokens from D train S . This is achieved by computing global attributions per token tok and class c (gl-atr c tok ) from its attribution per instance j (loc-atr j tok ) averaged across all training instances classified as c by the source model trained until ep i : gl-atr c tok = |D train S | j=1 1 ?j =c loc-atr j tok ?occurrence of tok in j |D train S | j=1 1 ?j =c #(occurrence of tok in j) (1) Here c ? {hate, non-hate}, ? is the predicted class and 1 is the indicator function. Prior to this, loc-atr j tok are individually normalized using sigmoid to obtain values in a closed range. Rarely occurring tokens and stop-words are not considered for the global ranking. The gl-atr c tok values are sorted from the highest globally attributed token to the lowest, which yields two ranked token-lists [gl-hate, gl-nhate] ep i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>We further compare D-Ref-Reg with various Domain Adaptation (DA) methods. However, such methods typically leverage the unlabeled train set from the target domain (D train T ). We first continue pre-training BERT model on D train T following Rietzler et al. (2020). Then, we perform supervised fine-tuning and regularization on D train S using D-Ref-Reg (Masked Language Model + D-Ref-Reg). We compare against the following methods: (i) BERT Van-MLM-FT : MLM training of BERT on D train T and supervised fine-tuning on D train S . (ii) BERT PERL (Pivot-based Encoder Representation of Language) (Ben-David et al., 2020): This performs pivot based fine-tuning using the MLM objective of BERT by masking and predicting the pivot terms present in the combination of D train S and the unlabeled D train T . Here pivots are terms that are frequently present in the unlabeled data of both the source and target corpora, and are predictive of the source labels.(iii) BERT-AAD (Adversarial Adaptation with Distillation)<ref type="bibr" target="#b29">(Ryu and Lee, 2020)</ref>, This is a domain adversarial approach with BERT where a target encoder is adapted with an adversarial objective that leverages D train S and D train T .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>comparison, we initialize (v) and (vi) with the MLM trained BERT on D train T , while the other methods already make use of D train T for adaptation. We use D val</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>8 (IG), and 60.8 (DL), compared to 58.1 from Van-MLM-FT. Since D-Ref-Reg and Van-MLM-FT use identical MLM pre-training on D train T , the improvements can be attributed to the dynamic token extraction of our method. More generally, when the larger set of target domain unannotated instances D train T are unavailable, D-Ref can identify and correct spurious correlations on source using a small amount of annotated instances from the target D val T , as demonstrated in Section 3.2. When sufficient number of unannotated instances from the target corpus are available, D-Ref can yield further cross-corpora improvements by leveraging the unannotated target instances with the MLM pre-training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Spurious correlations learned by the source classifier between the shaded tokens and the hate label.</figDesc><table><row><cell>Target corpus utterances</cell><cell>Actual</cell><cell>Predicted</cell></row><row><cell>Genocide is never ok</cell><cell>non-hate</cell><cell>hate</cell></row><row><cell>Women are goddesses</cell><cell>non-hate</cell><cell>hate</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Setup Data We use three standard hate speech corpora: HatEval (Basile et al., 2019), Waseem (Waseem and Hovy, 2016) and Dynamic (Vidgen et al., 2021). Following previous work by Wiegand et al. (2019); Swamy et al. (2019), we consider the detection of hate vs non-hate, where the hate class covers all forms of hate. We split Waseem (26.8% hate) into train (80%; 8720), val (10%; 1090) and test (10%; 1090) sets as no standard splits are provided. We use the original splits for HatEval (42.1% hate; train: 8993 2 , val: 1000; test: 3000) and Dynamic</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc> on source ?target pairs (H : HatEval, D : Dynamic, W : Waseem). Bold denotes the best performing approach in each column for every feature attribution method. * denotes statistical significance compared to Van-FT with paired bootstrap</figDesc><table><row><cell>Ref yield im-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>, for cross-domain hate-speech detection. They construct a weakly labeled augmented dataset by training a sequence</figDesc><table><row><cell>Approaches</cell><cell>H ?D</cell><cell>D ?H</cell><cell>H ?W</cell><cell>W ?H</cell><cell>D ?W</cell><cell>W ?D</cell><cell>Average</cell></row><row><cell>BERT Van-MLM-FT</cell><cell>56.6?1.3</cell><cell>66.2?1.2</cell><cell>70.0?2.5</cell><cell>50.9?2.1</cell><cell>61.4?2.4</cell><cell>43.5?1.9</cell><cell>58.1</cell></row><row><cell>BERT PERL</cell><cell>54.1?0.7</cell><cell>60.0?0.6</cell><cell>60.1?2.0</cell><cell>55.2*?0.7</cell><cell>55.5?1.0</cell><cell>37.8?1.2</cell><cell>53.8</cell></row><row><cell>BERT-AAD</cell><cell>56.6?1.3</cell><cell>53.9?3.5</cell><cell>68.8?2.5</cell><cell>50.7?1.4</cell><cell>48.3?4.7</cell><cell>53.0*?1.7</cell><cell>55.2</cell></row><row><cell>HATN</cell><cell>48.4?1.6</cell><cell>59.1?0.4</cell><cell>59.7?2.9</cell><cell>51.4?1.8</cell><cell>60.0?2.6</cell><cell>45.4?2.7</cell><cell>54.0</cell></row><row><cell>MLM + Sarwar and Murdock (2021)</cell><cell>55.0?1.9</cell><cell>66.2?2.0</cell><cell>68.8?1.1</cell><cell>48.2?3.1</cell><cell>57.9?1.3</cell><cell>36.2?1.1</cell><cell>55.4</cell></row><row><cell>MLM + ? 2 -test</cell><cell>57.9?1.6</cell><cell>67.1?1.7</cell><cell>69.8?0.8</cell><cell>48.2?3.1</cell><cell>60.4?2.8</cell><cell>44.1?3.4</cell><cell>57.9</cell></row><row><cell>MLM + D-Ref-Reg (???)</cell><cell>57.6?1.9</cell><cell>66.2?1.2</cell><cell>70.7?1.2</cell><cell>52.5*?4.0</cell><cell>62.8?1.4</cell><cell>48.0*?4.3</cell><cell>59.6</cell></row><row><cell>MLM + D-Ref-Reg (IG)</cell><cell>58.6*?1.2</cell><cell>66.8?0.5</cell><cell>70.1?1.5</cell><cell>52.1?3.0</cell><cell>62.5?3.0</cell><cell>48.9*?4.4</cell><cell>59.8</cell></row><row><cell>MLM + D-Ref-Reg (DL)</cell><cell>58.8*?2.2</cell><cell>66.7?0.6</cell><cell>70.5?1.3</cell><cell>52.4*?3.5</cell><cell>64.7*?2.1</cell><cell>51.5*?4.9</cell><cell>60.8</cell></row><row><cell cols="8">Table 3: Comparison of DA approaches with D-Ref + MLM. Macro-F1 (?std-dev) on different source ?target</cell></row><row><cell cols="8">pairs. H : HatEval, D : Dynamic, W : Waseem. * denotes the significantly improved scores w.r.t. Van-MLM-FT.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Change in attributions with D-Ref-Reg (IG).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Mukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017. Axiomatic attribution for deep networks. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, pages 3319-3328. PMLR.</figDesc><table><row><cell>Steve Durairaj Swamy, Anupam Jamatia, and Bj?rn</cell></row><row><cell>Gamb?ck. 2019. Studying generalisability across</cell></row><row><cell>abusive language detection datasets. In Proceedings</cell></row><row><cell>of the 23rd Conference on Computational Natural</cell></row><row><cell>Language Learning (CoNLL), pages 940-950, Hong</cell></row><row><cell>Kong, China. Association for Computational Linguis-</cell></row><row><cell>tics.</cell></row><row><cell>Bertie Vidgen, Tristan Thrush, Zeerak Waseem, and</cell></row><row><cell>Douwe Kiela. 2021. Learning from the worst: Dy-</cell></row><row><cell>namically generated datasets to improve online hate</cell></row><row><cell>detection. In Proceedings of the 59th Annual Meet-</cell></row><row><cell>ing of the Association for Computational Linguistics</cell></row><row><cell>and the 11th International Joint Conference on Nat-</cell></row><row><cell>ural Language Processing (Volume 1: Long Papers),</cell></row><row><cell>pages 1667-1682, Online. Association for Computa-</cell></row><row><cell>tional Linguistics.</cell></row><row><cell>Zeerak Waseem and Dirk Hovy. 2016. Hateful sym-</cell></row><row><cell>bols or hateful people? predictive features for hate</cell></row><row><cell>speech detection on Twitter. In Proceedings of</cell></row><row><cell>the NAACL Student Research Workshop, pages 88-</cell></row><row><cell>93, San Diego, California. Association for Computa-</cell></row><row><cell>tional Linguistics.</cell></row><row><cell>Michael Wiegand, Josef Ruppenhofer, and Thomas</cell></row><row><cell>Kleinbauer. 2019. Detection of Abusive Language:</cell></row><row><cell>the Problem of Biased Datasets. In Proceedings of</cell></row><row><cell>the 2019 Conference of the North American Chap-</cell></row><row><cell>ter of the Association for Computational Linguistics:</cell></row><row><cell>Human Language Technologies, Volume 1 (Long and</cell></row><row><cell>Short Papers), pages 602-608, Minneapolis, Min-</cell></row><row><cell>nesota. Association for Computational Linguistics.</cell></row><row><cell>Huihan Yao, Ying Chen, Qinyuan Ye, Xisen Jin, and</cell></row><row><cell>Xiang Ren. 2021. Refining language models with</cell></row><row><cell>compositional explanations. Advances in Neural In-</cell></row><row><cell>formation Processing Systems, 34.</cell></row><row><cell>Wenjie Yin and Arkaitz Zubiaga. 2021. Towards gener-</cell></row><row><cell>alisable hate speech detection: a review on obstacles</cell></row><row><cell>and solutions. ArXiv preprint, abs/2102.08886.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>in Section 3.4 and below) and ones similar in meaning to them. Validation set (D val T ) macro F1 (?std-dev) on source ?target pairs (H : HatEval, D : Dynamic, W : Waseem). In-corpus performance on source (left of arrows) while refining the source model for the target (right of arrows)</figDesc><table><row><cell>HatEval ?Dynamic</cell></row><row><cell>? Epoch 1: FP: {idiots, conservative, countries,</cell></row><row><cell>p*ssy, bloody, americans, move, a**hole,</cell></row><row><cell>hating, beings, feminist, africans, resources,</cell></row><row><cell>d*ck, resist, females, attacks, dude, anger }</cell></row><row><cell>FN: {hitler, plague, ##urs, crisis, rescue, fund-</cell></row><row><cell>ing, gorgeous, treason, journalist, lawyers,</cell></row><row><cell>agenda, roles, principles, bloody, intern}</cell></row><row><cell>? Epoch 2: FP: {race, hating, flights, sheep,</cell></row><row><cell>females, ignorant, feminist, resist, attacks,</cell></row><row><cell>d*ck, kill, boat, countries, p*ssy, refugee,</cell></row><row><cell>bloody} FN: {president, foreigners, illegal,</cell></row><row><cell>betrayal, lgbt, riots, gorgeous, treason, joking,</cell></row><row><cell>chris, intelligent, arguments, humans}</cell></row><row><cell>7 https://hatebase/org/</cell></row></table><note><p>? Epoch 2: FP: {##ists, her, sex, worse, feminist, ##nt, outraged} FN: {welcome, caused, cancer. drag, ##bi, pressure, parent, nazis, troll, cast, trash, ruins, lesbian, attacking, chi-nese}</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>In-corpus macro F1 (?std-dev), i.e. the source corpus performance, obtained after refining the source model for the target corpus (present at the right hand side of the arrows) using D-Ref-Reg. H : HatEval, D : Dynamic, W : Waseem. For D-Ref-Reg, model-selection and early-stopping is done over the validation set from the target corpus.? Epoch 3: FP: {female, ##ja, might, men, feminist} FN: {quoting, govt, referring, nazis, troll, lesbian, rogue, date, chinese, typically} ? Epoch 4: FP: {communism, her, openly, intelligent, many, barbie, chicks, females, ar-guing} FN: {date, suggest, ##lat, referring, police, chinese, cancer, voice, native, lesbian} ? Epoch 5: FP: {term, f*ck, ##ng, woman, ##ist, feminist, females, prison} FN: {removed, educate, freaking, queer, wow, ending, referring, dye, ##wat, issues, africans, vast, chinese, dark} ? Epoch 6: FP: {whore, her, ##ots, role, sweden, pay, d*ck, trump, feminist, females, american, arguing} FN: {bat, everyday, freak, argument, movement, chinese, tho, feature, lesbian} A hate comment in Dynamic test set for the above case, wrongly classified as non-hate by Van-FT and correctly classified as hate with D-Ref-Reg (IG), is given below. Darker the shade, higher is the attribution:</figDesc><table><row><cell></cell><cell cols="2">Don't get me wrong I don't hate</cell></row><row><cell>Van-FT:</cell><cell cols="2">asians, but I definitely don't like</cell></row><row><cell></cell><cell cols="2">them</cell></row><row><cell></cell><cell></cell><cell>Don't get me wrong I don't hate</cell></row><row><cell cols="2">D-Ref-Reg:</cell><cell>asians, but I definitely don't like</cell></row><row><cell></cell><cell></cell><cell>them</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>We remove the instances that contain only URLs, reducing the train instances from 9000 to 8993.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>3 https://redditscore.readthedocs.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>io4  We use Sampling and Occlusion(Jin et al.,  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>2020).5  We use DL as it yields comparable or higher overall improvements taking Table2 and Table 3 together.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>https://github.com/huggingface/ transformers</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported partly by the french <rs type="projectName">PIA</rs> project "<rs type="projectName">Lorraine Universit? d'Excellence"</rs>, reference <rs type="grantNumber">ANR-15-IDEX-04-LUE</rs>. Experiments presented in this article were carried out using the Grid'5000 testbed, supported by a scientific interest group hosted by Inria and including <rs type="funder">CNRS, RE-NATER</rs> and several Universities as well as other organizations (see https://www.grid5000. fr). We thank the anonymous reviewers for their valuable feedback and suggestions. We would also like to thank <rs type="person">George Chrysostomou</rs> for his help and suggestions regarding the work during informal discussions.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_m9NQ67J">
					<orgName type="project" subtype="full">PIA</orgName>
				</org>
				<org type="funded-project" xml:id="_PEdQsbG">
					<idno type="grant-number">ANR-15-IDEX-04-LUE</idno>
					<orgName type="project" subtype="full">Lorraine Universit? d&apos;Excellence&quot;</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethical Considerations</head><p>The approach proposed in the paper is aimed at supporting robust and accurate detection of online hate speech. The datasets used in the work are publicly available and referenced appropriately. The dataset creators have presented, in detail, the data collection process and annotation guidelines in peer-reviewed articles. The offensive terms presented, as examples, are only intended for better analysis of the models for research purposes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Pre-defined group identifiers</head><p>The combined list of pre-defined group identifiers from <ref type="bibr" target="#b20">Liu and Avci (2019)</ref> and <ref type="bibr" target="#b16">Kennedy et al. (2020)</ref> are given below: {lesbian, gay, bisexual, trans, cis, queer, lgbt, lgbtq, straight, heterosexual, male, female, nonbinary, african, african american, european, hispanic, latino, latina, latinx, canadian, american, asian, indian, middle eastern, chinese, japanese, <ref type="bibr">christian, buddhist, catholic, protestant, sikh, taoist, old, older, young, younger, teenage, millenial, middle aged, elderly, blind, deaf, paralyzed, muslim, jew, jews, white, islam, blacks, muslims, women, whites, gay, black, democrat, islamic, allah, jewish, lesbian, transgender, race, brown, woman, mexican, religion, homosexual, homosexuality, africans}</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Computational Efficiency</head><p>We present the per epoch training time for D-Ref-Reg with different source corpora in Table <ref type="table">7</ref>. The training times of D-Ref-Reg (???) are less than 2 times of that with <ref type="bibr">Van-FT. With D-Ref-Reg (DL)</ref>, the training time is approximately 4.5 times of that with Van-FT. This demonstrates the computational efficiency of our approach. In the case of D-Ref-Reg (IG), the computation time is indeed high. This occurs due to the aggregation of gradients using a path integral and computing gradients over gradients, as also discussed in <ref type="bibr" target="#b16">Kennedy et al. (2020)</ref>; <ref type="bibr" target="#b20">Liu and Avci (2019)</ref>. However, our approach is not dependent on any particular feature attribution method, as demonstrated with our experiments.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Debugging tests for model explanations</title>
		<author>
			<persName><forename type="first">Julius</forename><surname>Adebayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Muelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilaria</forename><surname>Liccardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Been</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020. 2020</date>
		</imprint>
	</monogr>
	<note>December 6-12, 2020, virtual</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hate speech detection is not as easy as you may think: A closer look at model validation</title>
		<author>
			<persName><forename type="first">Aym?</forename><surname>Arango</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>P?rez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbara</forename><surname>Poblete</surname></persName>
		</author>
		<idno type="DOI">10.1145/3331184.3331262</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-07-21">2019. July 21-25, 2019</date>
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
	<note>SIGIR 2019</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep learning for hate speech detection in tweets</title>
		<author>
			<persName><forename type="first">Pinkesh</forename><surname>Badjatiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashank</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
		<idno type="DOI">10.1145/3041021.3054223</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web Companion, WWW &apos;17 Companion</title>
		<meeting>the 26th International Conference on World Wide Web Companion, WWW &apos;17 Companion<address><addrLine>Republic and Canton of Geneva</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="759" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multilingual detection of hate speech against immigrants and women in Twitter</title>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Valerio Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elisabetta</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debora</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viviana</forename><surname>Nozza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName><surname>Manuel Rangel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuela</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName><surname>Sanguinetti</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S19-2007</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019. SemEval-2019 task 5</date>
			<biblScope unit="page" from="54" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">PERL: Pivot-based domain adaptation for pre-trained deep contextualized embedding models</title>
		<author>
			<persName><forename type="first">Eyal</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carmel</forename><surname>Rabinovitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00328</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="504" to="521" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation in cross-corpora abusive language detection</title>
		<author>
			<persName><forename type="first">Tulika</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irina</forename><surname>Illina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominique</forename><surname>Fohr</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.socialnlp-1.10</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Workshop on Natural Language Processing for Social Media</title>
		<meeting>the Ninth International Workshop on Natural Language Processing for Social Media</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="113" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An empirical study on explanations in out-of-domain settings</title>
		<author>
			<persName><forename type="first">George</forename><surname>Chrysostomou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The hitchhiker&apos;s guide to testing statistical significance in natural language processing</title>
		<author>
			<persName><forename type="first">Rotem</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gili</forename><surname>Baumer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1128</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Segev Shlomov, and Roi Reichart</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1383" to="1392" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Towards non-toxic landscapes: Automatic toxic comment detection using DNN</title>
		<author>
			<persName><forename type="first">Ashwin</forename><surname>Geet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D'</forename><surname>Sa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irina</forename><surname>Illina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominique</forename><surname>Fohr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the Second Workshop on Trolling, Aggression and Cyberbullying<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="21" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An Introduction to the Bootstrap. Number 57 in Monographs on Statistics and Applied Probability</title>
		<author>
			<persName><forename type="first">Bradley</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chapman &amp; Hall/CRC</title>
		<meeting><address><addrLine>Boca Raton, Florida, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Time of your hate: The challenge of time in hate speech detection on social media</title>
		<author>
			<persName><forename type="first">Komal</forename><surname>Florio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Polignano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierpaolo</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viviana</forename><surname>Patti</surname></persName>
		</author>
		<idno type="DOI">10.3390/app10124180</idno>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Twitter sentiment classification using distant supervision. Processing</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richa</forename><surname>Bhayani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mapping lexical innovation on american social media</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Grieve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diansheng</forename><surname>Nini</surname></persName>
		</author>
		<author>
			<persName><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of English Linguistics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="293" to="319" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Towards hierarchical importance attribution: Explaining compositional semantics for neural sequence models</title>
		<author>
			<persName><forename type="first">Xisen</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyi</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations, ICLR 2020</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26">2020. April 26-30, 2020</date>
		</imprint>
	</monogr>
	<note>Xiangyang Xue, and Xiang Ren</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cross-domain detection of abusive language online</title>
		<author>
			<persName><forename type="first">Mladen</forename><surname>Karan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>?najder</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5117</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Abusive Language Online (ALW2)</title>
		<meeting>the 2nd Workshop on Abusive Language Online (ALW2)<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="132" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Contextualizing hate speech classifiers with post-hoc explanation</title>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xisen</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aida</forename><forename type="middle">Mostafazadeh</forename><surname>Davani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morteza</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.483</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5435" to="5442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Comparing corpora</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Kilgarriff</surname></persName>
		</author>
		<idno type="DOI">10.1075/ijcl.6.1.05kil</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Corpus Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="133" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hierarchical attention transfer network for cross-domain sentiment classification</title>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018-02-02">2018. February 2-7, 2018</date>
			<biblScope unit="page" from="5852" to="5859" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">End-to-end adversarial memory network for cross-domain sentiment classification</title>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2017/311</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJ-CAI 2017</title>
		<meeting>the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJ-CAI 2017<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08-19">2017. August 19-25, 2017</date>
			<biblScope unit="page" from="2237" to="2243" />
		</imprint>
	</monogr>
	<note>ijcai.org</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Incorporating priors with feature attribution on text classification</title>
		<author>
			<persName><forename type="first">Frederick</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Besim</forename><surname>Avci</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1631</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6274" to="6283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06">2019. May 6-9, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A unified approach to interpreting model predictions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su-In</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">2017. 2017. December 4-9, 2017</date>
			<biblScope unit="page" from="4765" to="4774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adversarial augmentation policy search for domain and crosslingual generalization in reading comprehension</title>
		<author>
			<persName><forename type="first">Adyasha</forename><surname>Maharana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.333</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3723" to="3738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A bert-based transfer learning approach for hate speech detection in online social media</title>
		<author>
			<persName><forename type="first">Marzieh</forename><surname>Mozafari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reza</forename><surname>Farahbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noel</forename><surname>Crespi</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-36687-2_77</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Complex Networks and Their Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="928" to="940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Resources and benchmark corpora for hate speech detection: a systematic review</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Poletto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuela</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viviana</forename><surname>Patti</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10579-020-09502-8</idno>
	</analytic>
	<monogr>
		<title level="j">Lang. Resour. Evaluation</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="477" to="523" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Interpretations are useful: Penalizing explanations to align neural networks with prior knowledge</title>
		<author>
			<persName><forename type="first">Laura</forename><surname>Rieger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandan</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">James</forename><surname>Murdoch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Yu</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning, ICML 2020</title>
		<meeting>the 37th International Conference on Machine Learning, ICML 2020</meeting>
		<imprint>
			<date type="published" when="2020-07-18">2020. 18 July 2020</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="8116" to="8126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Adapt or get left behind: Domain adaptation through BERT language model finetuning for aspect-target sentiment classification</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Rietzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Stabinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Opitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Engl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4933" to="4941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Right for the right reasons: Training differentiable models by constraining their explanations</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Slavin Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">C</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Finale</forename><surname>Doshi-Velez</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2017/371</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Sixth International Joint Conference on Artificial Intelligence<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08-19">2017. 2017. August 19-25, 2017</date>
			<biblScope unit="page" from="2662" to="2670" />
		</imprint>
	</monogr>
	<note>ijcai.org</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Knowledge distillation for bert unsupervised domain adaptation</title>
		<author>
			<persName><forename type="first">Minho</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<idno>ArXiv, abs/2010.11478</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Unsupervised domain adaptation for hate speech detection using a data augmentation approach</title>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vanessa</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><surname>Murdock</surname></persName>
		</author>
		<idno>abs/2107.12866</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Is attention interpretable?</title>
		<author>
			<persName><forename type="first">Sofia</forename><surname>Serrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1282</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2931" to="2951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning important features through propagating activation differences</title>
		<author>
			<persName><forename type="first">Avanti</forename><surname>Shrikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peyton</forename><surname>Greenside</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anshul</forename><surname>Kundaje</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning, ICML 2017</title>
		<meeting>the 34th International Conference on Machine Learning, ICML 2017<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06-11">2017. 6-11 August 2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="3145" to="3153" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
