<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Geodesic Active Regions: A New Framework to Deal with Frame Partition Problems in Computer Vision 1</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nikos</forename><surname>Paragios</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Siemens Corporate Research</orgName>
								<address>
									<addrLine>755 College Road East</addrLine>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<country>New Jersey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rachid</forename><surname>Deriche</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">I.N.R.I.A. (Robot Vis)</orgName>
								<address>
									<addrLine>2004 Route des Lucioles</addrLine>
									<postCode>06902</postCode>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Geodesic Active Regions: A New Framework to Deal with Frame Partition Problems in Computer Vision 1</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">82084D3327CD65521B59910850C151AC</idno>
					<idno type="DOI">10.1006/jvci.2001.0475</idno>
					<note type="submission">Received February 25, 2000; accepted July 25, 2000 Sophia Antipolis from October 1, 1996 to November 1, 1999 and was funded in part under the VIRGO research network</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a novel variational framework for dealing with frame partition problems in computer vision by the propagation of curves. This framework integrates boundary-and region-based frame partition modules under a curve-based objective function, which aims at finding a set of minimal length curves that preserve three main properties: (i) they are regular and smooth, (ii) they are attracted by the boundary points (boundary-based information), (iii) and they create a partition that is optimal according to the expected region properties of the different hypotheses (region-based information). The defined objective function is minimized using a gradient descent method. According to the obtained motion equations, the set of initial curves is propagated toward the best partition under the influence of boundary-and region-based forces, and is constrained by a regularity force. The changes of topology are naturally handled thanks to the level set implementation. Furthermore, a coupled multiphase propagation that imposes the idea of mutually exclusive propagating curves and increases the robustness as well as the convergence rate is proposed. The proposed framework has been validated using three important applications in computer vision, the tasks of image and supervised texture segmentation in low-level vision and the task of motion estimation and tracking in motion analysis. C 2002 Elsevier Science (USA) 1 This work has been carried out during the appointment (doctoral research) of the first author with the Computer Vision and Robotics Group (RobotVis) of I.N.R.I.A.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>During the past 20 years a wide variety of mathematical and computational frameworks for dealing with computer vision problems has been proposed. Their classification is not an easy task. Most of them are based on the fact that many of the computer vision applications turn out to be frame partition problems (image segmentation, motion estimation and tracking, depth recovery, and 3-D reconstruction). According to this assumption, the goal is to decompose the image domain into regions with "homogeneous properties." This "homogeneity" is related to the nature of the examined application.</p><p>However, feature-based frame partition is performed using two basic image processing techniques: boundary-based methods (which are often referred to as edge-based) rely on the generation of a strength image and the extraction of prominent edges, while regionbased methods rely on the homogeneity of spatially localized features and properties.</p><p>• Early approaches for boundary-based frame partition solutions have used local filtering techniques such as edge detection operators. A step further was the use of snake/ balloons models <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12]</ref>, which can provide a closed curve as a compromise between regularity of the curve and important boundary features. Recently, the geodesic active contour model, which combined with the level set theory <ref type="bibr" target="#b16">[17]</ref> refers to a very elegant and powerful frame partition tool, has been introduced <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b12">13]</ref>.</p><p>• Region-based methods are more suitable approaches for dealing with frame partition problems and can be roughly classified into two categories: region-growing techniques <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">26]</ref> and the Markov random fields-based approaches <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>. The region-growing methods are based on split-and-merge procedures using "feature-based" homogeneity tests. Another powerful region-based tool, which has been widely investigated for frame partitioning, is the Markov random fields (MRF) <ref type="bibr" target="#b10">[11]</ref>.</p><p>• Finally, there has been a significant effort to integrate boundary-based with region-based frame partition approaches <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26]</ref>.</p><p>More recently, many researchers started to pay attention to novel ways of analyzing, formulating, and solving computer vision problems via variational methods including several frame partition problems <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16]</ref>.</p><p>Here, we will present a unified approach, namely, the Geodesic Active Region <ref type="bibr" target="#b17">[18]</ref> model, in computer vision that incorporates boundary and region information sources under a curve-based minimization framework to deal with frame partition problems. This framework assumes that (i) The considered application refers to a frame partition problem of the image domain into N classes (the number of classes is not fixed).</p><p>(ii) Some information regarding the real boundaries between the different frame regions (one for each class) is available or can be estimated in the context of the specific application.</p><p>(iii) Some information regarding the expected properties of each class is also available or can be estimated in the context of the specific application (e.g., intensity, motion, etc.).</p><p>Then the desirable frame partition (set of image regions) is obtained by minimizing a curve-based objective function. This function aims at finding a set of regular curves (one for each class) attracted by pixels with important boundary information. At the same time the proposed model aims at finding a set of curves that define regions that preserve the expected properties of the associated class. This function is minimized with respect to the different region boundaries (multiple curves) using a gradient descent method, where the obtained motion equations for the curves propagations are implemented using the level set methods <ref type="bibr" target="#b16">[17]</ref>. Moreover, the level set equations are coupled by demanding a nonoverlapping set of curves since each pixel of the image cannot belong to more than one region. The resulting model deals automatically with the changes of topology, thereby allowing either several subregions with the same class properties to be the output of a single initial curve or a single curve to be the output of multiple initial curves. Various experimental results on different computer vision tasks demonstrate the performance of the proposed framework.</p><p>The reminder of this paper is organized as follows. In Section 2, the most closely work related with the proposed approach is presented, while in Section 3 the main contribution of this paper, namely the Geodesic Active Region model, is introduced. Then the coupling between the different curves propagations that imposes the concept of mutually exclusive propagations is presented in Section 4. Three applications are used for the validation of the proposed framework in Section 5. Finally, conclusions and discussion appear in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Caselles et al. <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> and Kichenassamy et al. <ref type="bibr" target="#b12">[13]</ref> have proposed the geodesic active contour model for image segmentation as a geometric alternative for snakes, which might be considered as an "extension" of the classic snake since it overcomes an important number of handicaps implied by the snake model. A geometry-based model with similar properties was proposed in <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15]</ref>.</p><p>According to this framework the optiomal frame partition is obtained by finding the set of minimal length geodesic curves that are attracted by the real region boundaries. Moreover, the same authors have proposed the implementation of the obtained motion equation using the level set methods, resulting in a paradigm that can deal automatically with topological changes. Summarizing, the geodesic active contour model is a more elaborated simple scheme for boundary-based frame partition applications that is compared favorably with the classical snake model. However, this model also encounters some weak points: (i) It only makes use of very local information (like the snake model) and is very sensitive to local minima. (ii) Due to the fact that the geodesic active contour relies on a nonparameterized curve and evolves the initial curve toward one direction (constrained by the curvature effect), it demands a specific initialization step, where the this curve should be completely exterior or interior to the real object boundaries.</p><p>Many efforts have been made to overcome these shortcomings by introducing some region-based features to snake-based partition methods with the objective of making them free from the initial conditions and more robust.</p><p>Chakraborty et al. <ref type="bibr" target="#b5">[6]</ref> proposed a model for medical image segmentation that integrates edge-and region-based information within a deformable boundary-finding framework. This framework introduces a prior knowledge about the shape form (the final contour should be close to this shape), a boundary term that propagates the curve toward high gradient values points (edges), and a region term that incorporates some region-based information into the boundary-finding framework. However, according to it the boundaries are parameterized using Fourier descriptors, which present some important limitations with respect to the shapes that they can describe. Additionally, the region information is expressed via intensity homogeneity, which limits the model applicability, even if it is not a strong constraint. Moreover, due the Lagrangian implementation of the curve propagation, the topological changes cannot be handled naturally. Furthermore, this approach requires a presegmentation map. Finally, some of the probabilistic assumptions that have been done to determine the model may not be valid if the current boundary is far away from the true boundary. Thus, the model is sensitive to the initial conditions. However, this is a pioneering effort that combines successfully boundary-and region-based information within a snake minimization framework.</p><p>Zhu and Yuille <ref type="bibr" target="#b25">[26]</ref> proposed a statistical variational approach for image/texture segmentation that combines the geometrical features of a snake/balloon model and the statistical techniques of region growing. In this approach, although a snake/balloon model is employed for the segmentation process, the boundary-based information is not used since the snake/balloon model is employed only to impose a regularity constraint to the segmentation process. Besides, due to the implementation of the curve propagation using a Lagrangian approach, the changes of topological are not naturally handled. However, this approach solves this problem by introducing a region-growing step. Hence, regions (curves) that have common boundaries are merged if the entropy of the resulting region is inferior to the sum of the regions entropies before merging. This step cannot deal with the "splitting" topology change.</p><p>More recently, Chan and Vese <ref type="bibr" target="#b6">[7]</ref>, Samson et al. <ref type="bibr" target="#b22">[23]</ref>, and Yezzi et al. <ref type="bibr" target="#b23">[24]</ref> have proposed different level set variational frameworks for image segmentation/classification. The work of <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b23">24]</ref> is constrained to bimodal and three-modal image segmentation while the work of <ref type="bibr" target="#b22">[23]</ref> is based on the propagation of mutually exclusive curves <ref type="bibr" target="#b24">[25]</ref> and is constrained to supervised image classification with a predetermined number of regions. However, these frameworks do not make any use of any boundary-based information and are very sensitive to the initial conditions since statistics are generated and dynamically updated over regions dynamically. Furthermore, they are constrained to bi-modal/three-modal or supervised image segmentation/classification cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">GEODESIC ACTIVE REGIONS</head><p>The Geodesic Active Region model was initially introduced <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21]</ref> for supervised texture segmentation, has been extended to deal with the unsupervised image segmentation case <ref type="bibr" target="#b21">[22]</ref>, and has been successfully exploited <ref type="bibr" target="#b19">[20]</ref> to provide an elegant solution to the motion estimation and the tracking problem.</p><p>In order to facilitate the introduction of the new model, the bimodal case will be considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Notation</head><p>Let us make some definitions as well as some assumptions regarding the a priori knowledge that are going to be used to introduce the Geodesic Active Region model:</p><formula xml:id="formula_0">• Let I be the input image composed of two classes (h A , h B ). • Let P(R) = {R A , R B }</formula><p>be a partition of the image domain into two nonoverlapping region (Fig. <ref type="figure" target="#fig_0">1a</ref>).</p><p>• Let ∂P(R) = {∂R A , ∂R B } be the boundaries of the P(R) partition. • Let us make the assumption that some knowledge regarding the expected positions of real region boundaries is available, the boundary probabilities p b,A (), p b,B () (the b stands for boundary) that measure the likelihood of a given pixel being at the real boundaries of the considered classes (h A , h B ) (Fig. <ref type="figure" target="#fig_0">1b</ref>).</p><p>• Finally, let us also make the assumption that some knowledge regarding the expected region properties of the classes h A , h B is available, the region probabilities p r,A (), p r,B () (the r stands for region) that measure the likelihood of a given pixel preserving the expected region properties of the considered classes (h A , h B ) (Fig. <ref type="figure" target="#fig_0">1c,</ref><ref type="figure" target="#fig_0">1d</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Setting the Boundary Module</head><p>The frame partition task can be viewed initially as the problem of accurately extracting the boundaries of the regions R A and R B . This can be done using the geodesic active contour framework, thus minimizing</p><formula xml:id="formula_1">E(∂R) = X ∈{A,B} 1 0 g    p b,X (I (∂R X (c x ))) X boundary probability    X boundary attraction |∂ ṘX (c x )| X regularity dc x .</formula><p>(1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Setting the Region Module</head><p>At the same time, the examined problem is equivalent to creating a consistent frame partition between the observed data, the associated hypothesis, and their expected properties. This partitions can be viewed as an optimization problem with respect to the a posteriori frame partition probability, given the observation set.</p><p>Let [ p S (P(R) | I )] be the a posteriori frame partition density function with respect to the different partitions P(R) given the input image I . This density function is given by the Bayes rule as</p><formula xml:id="formula_2">p S (P(R) | I ) = p(I | P(R)) p(I ) p(P(R)),</formula><p>where</p><formula xml:id="formula_3">• p(I | P(R))</formula><p>is the a posteriori segmentation probability for the image I , given the partition P(R),</p><p>• p(P(R)) is the probability of the partition P(R) among the space of all possible partitions of the image domain, and</p><p>• p(I ) is the probability of having as input the image I among the space of all possible images.</p><p>If we assume that all the partitions are a priori equally possible [ p(P(R))</p><formula xml:id="formula_4">= 1 Z ],</formula><p>where Z is the number of possible partitions, then we can ignore the constant terms p(I ), p(P(R)) and we can rewrite the density function as</p><formula xml:id="formula_5">p S (P(R) | I ) = p(I | {R A , R B }).</formula><p>Besides, we can consider that there is no correlation between the regions labeling, and the region probabilities depend only on their observation set (within the region)</p><formula xml:id="formula_6">p S (P(R) | I ) = p([I | R A ] ∩ [I | R B ]) = p(I | R A ) p(I | R B ),</formula><p>where p(I | R A ) is the a posterior probability for the region R A given the corresponding image intensities (resp.</p><formula xml:id="formula_7">p(I | R B )).</formula><p>Besides, if we assume that the pixels within each region are independent, which is a widely used assumption, then we can replace the region probability by the joint probability among the region pixels,</p><formula xml:id="formula_8">p(I | R X ) = s∈R X p X (I (s)),<label>(2)</label></formula><p>where X ∈ {A, B}.</p><p>Taking all these into account, the a posteriori segmentation probability for a partition P(R) given the observed image I is determined by</p><formula xml:id="formula_9">p S (P(R) | I ) = s∈R A p A (I (s)) s∈R B p B (I (s)).</formula><p>The maximization of the a posteriori segmentation probability is equivalent to the minimization of the [-log()] function of this probability,</p><formula xml:id="formula_10">E(∂P(R)) = - R A log    p A (I (x, y)) h A probability    dx dy R A fitting measurement - R B log    p B (I (x, y)) h B probability    dx dy R B fitting measurement . (3)</formula><p>Let us now try to interpret this region-based term:</p><p>• Suppose that a pixel s is well classified and the true case is h A : then this pixel appears to the R A fitting measurement. The corresponding probability for the true case [ p r,A (I (s))] is higher than that for the opposite case [ p r,B (I (s))], resulting in a minimum contribution in the objective function [-log( p r,A (I (s)))].</p><p>• On the other hand if this pixel is badly classified, then it appears for example to the R A fitting measurement while the true case is h B . It is obvious to see that this pixel will penalize the objective function more than the penalization introduced by the true case.</p><p>Summarizing, this region-based energy term is defined using the partition determined by the curve and aims at maximizing the a posteriori segmentation probability given the input image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Geodesic Active Region Objective Function</head><p>Then the two different frame partition modules are integrated by defining the Geodesic Active Region objective function as</p><formula xml:id="formula_11">E(∂R) = - X ∈{A,B} R X fitting measurement α R X log    p r,X (I (x, y)) h X probability    dx dy X Region Term + X ∈{A,B} (1 -α) 1 0 X boundary attraction g    p b,X (I (∂R X (c x ))) X boundary probability    X regularity |∂ ṘX (c x )| dc x X Boundary Term , (<label>4</label></formula><formula xml:id="formula_12">)</formula><p>where α is a positive constant that balances the contributions of the two terms [0</p><formula xml:id="formula_13">≤ α ≤ 1].</formula><p>The interpretation of the defined objective function is the following.</p><p>A set of curves is demanded that:</p><p>i. [Boundary Term] are regular (Eq. ( <ref type="formula" target="#formula_11">4</ref>): regularity), of minimal length, and attracted by the real regions boundaries (Eq. ( <ref type="formula" target="#formula_11">4</ref>): boundary attraction).</p><p>ii. [Region Term] define a partition of the image that maximizes the a posteriori frame partition probability.</p><p>The minimization of the objective function is performed using a gradient descent method.</p><formula xml:id="formula_14">If u A = (x A , y A ) is a point of the initial curve ∂R A (resp. u B = (x B , y B</formula><p>)) and we compute the Euler-Lagrange equations using the Stokes theorem <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b25">26]</ref>, then we should deform the curves (∂R A , ∂R N ) using the equations</p><formula xml:id="formula_15">                                       ∂u A ∂t = A region-based force α log      h B probability p r,B (I (u A )) p r,A (I (u A )) h A probability      N A (u A ) + (1 -α)(g( p b,A (I (u A )))K A (u A ) -∇g( p b,A (I (u A ))) • N A (u A )) A boundary-based force N A (u A ) ∂u B ∂t = α log p r,A (I (u B )) p r,B (I (u B )) N B (u B ) + (1 -α)(g( p b,B (I (u B )))K B (u B ) -∇g( p b,B (I (u B ))) • N B (u B ))N B (u B ).<label>(5)</label></formula><p>The obtained PDE motion equations have two kind of forces acting on the propagating curves, both in the direction of the normal.</p><p>• Region force: This force aims at shrinking or expanding the curve to the direction that maximizes the a posteriori frame partition probability. Let us now try to interpret this force for a given curve pixel u A by reminding that this pixel is associated with the h A class:</p><p>-If the true state of u A is h B , then the conditional density function that accounts for this class [ p r,B (I (u A ))] should support the true case [ p r,B (I (u A )) &gt; p r,A (I (u A ))], resulting in a positive force that aims at shrinking the curve to pass through this pixel.</p><formula xml:id="formula_16">p r,B (I (u A )) &gt; p r,A (I (u A )) ⇒ p r,B (I (u A )) p r,A (I (u B )) &gt; 1 ⇒ log p r,B (I (u A )) p r,A (I (u A )) &gt; 0 ⇒ α log p r,B (I (u A )) p r,A (I (u A )) &gt; 0.</formula><p>-On the other hand, if the true state of u A is the h A , then this force aims at expanding the curve to include this pixel.</p><p>However, it is important to note that the region-based forces have opposite sign in the motion equations of the classes {h A , h B }.</p><p>• The boundary force contains information regarding the boundaries of the different regions and is composed of two subterms, one that shrinks or expands the curve constrained by the curvature effect toward the object boundaries and one that attracts the curve to the objects boundaries (refinement term).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Model Generalization</head><p>The main assumption that has been made to provide the proposed framework relies on the fact that all partitions are equally probable. Generally, this assumption is not valid, but this does not constrain the proposed model since the same framework can be recovered by replacing the a posteriori frame partition probability with the joint probability. It is important to note that the maximization of the joint segmentation probability is a widely used optimization criterion.</p><p>The proposed model can be generalized very easily by assuming for a specific application the existence of functions that capture the boundary and the region properties of the different regions. Thus, if we consider: </p><formula xml:id="formula_17">• A frame partition problem with N classes, • A set of functions [b i : R × R → R, i ∈ [1, N ]] that "captures</formula><formula xml:id="formula_18">E(∂R)= N i=1 α R i fitting measurement R i r i (I (x, y)) dx dy i Region Term + N i = 1 (1 -α) 1 0 i boundary attraction b i (I (∂R i (c i ))) i regularity |∂ Ṙi (c i )| dc i Boundary Term . (6)</formula><p>The minimization of the generalized objective function is performed using a gradient descent method and leads to a system of N motion equations (one for each class/curve) given by</p><formula xml:id="formula_19">       ∀i ∈ [1, N ] ∂u i ∂t = α(r i (u i ) -r o i (u i ))N i (u i ) i region force + (1 -α)(b i (u i )K i (u i ) -∇b i (u i ) • N i (u i ))</formula><p>i boundary force N i (u i ), <ref type="bibr" target="#b6">(7)</ref> where the assumption that the pixel u i lies between the regions R i and R o i has been made implicitly. According to the above equations a given curve is propagated along its normal direction under the influence of two forces:</p><p>• A region-based force that moves the curves toward the direction that creates the optimal frame partition (according to "region properties") result using the observation set and the expected properties of the different classes, and</p><p>• A boundary-based force that shrinks the curve under the influence of a regularity constraint (curvature effect) toward the different region boundaries (according to the "boundary properties").</p><p>Then the proposed framework is employed as follows: Initially a set of random curves is used to initialize the region positions. Then each region is deformed according to the corresponding motion (Eq. ( <ref type="formula">7</ref>)) toward the final frame partition. The interaction between the regions' positions is obtained through the region-based force since for a given pixel that is attributed to two different regions, forces, with opposite signs appear to the corresponding motion (PDE) equations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Level Set Methods</head><p>The obtained motion equations can be implemented using a difference approximation scheme (Lagrangian approach). However, for this approach the evolving model is not capable of dealing with topological changes of the moving front. This can be avoided by introducing the pioneering work of Osher and Sethian <ref type="bibr" target="#b16">[17]</ref>, the level set theory where the central idea is to represent the moving front ∂R(c, t) as the zero-level set φ(∂R(c, t), t) = 0 of a function φ. This representation of ∂R(c, t) is implicit, parameter-free, and intrinsic. Additionally, it is topology-free since different topologies of the zero level set do not imply different topologies of φ. It can be shown easily that if the moving front evolves according to</p><formula xml:id="formula_20">∂ ∂t ∂R(c, t) = F(∂R(c, t))N</formula><p>for a given function F, then the embedding function φ deforms according to</p><formula xml:id="formula_21">∂ ∂t φ(c, t) = F(c)|∇φ(c, t)|.</formula><p>For this level set representation, it is proved that the solution is independent of the embedding function φ, which in most of the cases is initialized as a signed distance function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FIG. 2. Geodesic Active Regions:</head><p>A new framework to deal with frame partition problems in computer vision. The proposed framework is used for image segmentation where independence from the initial conditions and the ability to deal with topological changes are demonstrated. Thus, the system of motion equations that drives the curve propagation for the Generalized Geodesic Active Region framework is transformed into a system of multiple-surfaces evolution given by</p><formula xml:id="formula_22">                     ∀i ∈ [1, N ] ∂φ i ∂t (u) = α(r i (u) -r o i (u))|∇φ i (u)| i region force + (1 -α) b i (u)K i (u) + ∇b i (u) • ∇φ i (u) |∇φ i (u)| i boundary force |∇φ i (u)|.<label>(8)</label></formula><p>In order to demonstrate the proposed model, the task of image segmentation is considered for a synthetic frame composed of two classes (Fig. <ref type="figure">2</ref>).</p><p>• The first [h B ] refers to the background and is composed from pixels with intensities that follow a Gaussian distribution with a mean value equal to 150 and a standard deviation equal to 10 [ p B () ∼ G(150, 10)].</p><p>• The second [h A ] refers to a region composed of four components, and pixels with intensities that follow Gaussian distribution with a mean value equal to 90 and a standard deviation equal to 10 [ p A () ∼ G(90, 10)].</p><p>For this case, the boundary information is determined using a Gaussian edge detector, applied to the norm of the gradient values space. The curve evolution for the class h A with respect to three different initialization steps is illustrated in Fig. <ref type="figure">2</ref>.</p><p>Besides, to demonstrate the independence of the proposed framework from the initial conditions, we show the evolution of the energy terms over time for class A. Thus, in Fig. <ref type="figure" target="#fig_2">3</ref> the boundary-based energy term, the region-based energy term, and the corresponding values of the total energy for the first two initialization steps (Fig. <ref type="figure">2a,</ref><ref type="figure">2b</ref>) are shown. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">MUTUALLY EXCLUSIVE PROPAGATING CURVES</head><p>The use of the level set methods provides a very elegant tool for propagating curves where their position is recovered by seeking for the zero level set crossing points. Moreover, the state of a given pixel with respect to a region hypothesis can be easily determined since if it belongs to the region, then the corresponding level set value is negative. On the other hand if it does not belong to it, then the corresponding value is positive. Additionally, since we consider signed distance functions for the level set implementation, a step further can be done by estimating the distance of the given pixel from each curve. This information is valuable during the multiphase curve propagation cases where the overlapping between the different curves is prohibited.</p><p>However, the overlapping between the different curves is almost an inevitable situation at least during the initialization step. Moreover, the case where an image pixel has not been attributed to any hypothesis may occur. Let us now assume that a pixel is attributed initially to two different regions (there are two level set functions with negative values at it). Then a constraint that discourages a situation of this nature can be easily introduced by adding an artificial force (always in the normal direction) that penalizes pixels with multiple labels (they are attributed to multiple regions) to the corresponding level set motion equations. Moreover, a similar force can be introduced to discourage situations where pixels are not attributed to any regions. Inspired by the work in <ref type="bibr" target="#b24">[25]</ref>, this can be done by modifying the motion equations (Eq. ( <ref type="formula">7</ref>)) as</p><formula xml:id="formula_23">                         ∀i ∈ [1, N ] ∂φ i ∂t (u) = β (r i (u) -r o i (u))|∇φ i (u)| i region force + γ j∈[1,N ] H i (i, φ j (s))|∇φ i (u)| i coupling force + δ b i (u)K i (u)|∇φ i (u)| + ∇b i (u) • ∇φ i (u) |∇φ i (u)| i boundary force</formula><p>, where β, γ , δ are positive constants [β + γ + δ = 1], and the function H i ( j, φ()) is given by</p><formula xml:id="formula_24">H i (m, φ n (s)) = 0, if m = i -sign(φ j (u)), if m = i.</formula><p>Let us now interpret the new artificial force that has been added to the motion equation i, for a given pixel u:</p><p>Expanding effect. If this pixel does not belong to any region (the corresponding level set values at s are positive for all level set functions), then the new force is negative, is equal to f c = -(N -1)|∇φ i |, and aims at expanding the region R i to occupy this pixel (appearance of nonattributed pixels is discouraged).</p><p>Shrinking effect. On the other hand, if this pixel has been already attributed to another region [R k ], then the corresponding level set function [φ k ] will contribute with a positive force that aims at shrinking locally the region R i (the overlapping is discouraged).</p><p>To summarize, this coupling force for a given class i is negative (expanding) to a considered pixel u if it is attributed to any region. On the other hand this force is positive (shrinking) if u is already attributed to another region j.</p><p>Although the selection of the function [H i (φ())] seems to be proper, it introduces some problems. First, the not-attributed pixels are penalized with a manner similar to those that have been attributed to multiple regions. Second, their distance values of a given pixel from the other curves are not considered and hence valuable information is lost. Finally, the defined coupling function is discontinuous, which is a not desirable property since it creates stability problems during the level set evolution.</p><p>To summarize, the coupling function must be redefined by taking into account the following considerations: i. A pixel that is already attributed to a region j and is far away from ∂R j should strongly discourage the evolution of the level set φ i () to include this pixel in R i (the coupling force should be in terms of absolute value proportional to the distance from the region boundaries).</p><p>ii. On the other hand, a pixel that belongs to the region R j and is close to its boundaries (small level set value φ j ()) can be reached or be liberated by ∂R j during the next few iterations, and hence, the coupling force in i propagation because of the j level set function (region) should be less powerful and "tolerate" a temporal overlapping. Thus, inspired by the properties of the trigonometric functions, the following function that is going to be used as basis for the new coupling force (Fig. <ref type="figure">(4)</ref>) is defined</p><formula xml:id="formula_25">H a (x) = -      +1, if x &gt; a -1, if x &lt; -a 1 tan(1) tan(x/a), if |x| ≤ a<label>(9)</label></formula><p>with a ∈ R + . Then the coupling force is defined as</p><formula xml:id="formula_26">H i ( j, φ j (u)) =      0, if j = i H a (φ j (u)), if j = i and φ j (u) ≥ 0 1 N -1 H a (φ j (s)), if j = i and ∩ N {k=1,k =i} φ k (u) &gt; 0 . (<label>10</label></formula><formula xml:id="formula_27">)</formula><p>FIG. <ref type="figure">4</ref>. The trigonometric basis of the level set coupling function.</p><p>To interpret this force via the new function, a level set function [φ i ()] and a pixel location [u] are considered, i. If u is already attributed to another region, then there is any hypothesis j for which φ j (u) ≤ 0, which will contribute with a positive value (shrinking effect) to the coupling force that is proportional to the distance of this pixel from the boundaries of R j .</p><p>ii. A similar interpretation can be done if this pixel is not attributed to any region (expanding effect). However, for this case the coupling force must be normalized because it is not appropriate to penalize with the same way the situation of overlapping and the case in which the given pixel is not attributed to one of the regions. At the same time this force is plausible if and only if this pixel is not attributed to any region [∩ N {k=1,k =i} φ k (u) &gt; 0]. More details on the interpretation/justification of the above selection can be found in <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b21">22]</ref>. Another related approach dealing with the ideas of mutual exclusiveness, introduced in <ref type="bibr" target="#b24">[25]</ref>, can also be found in <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">APPLICATIONS</head><p>The proposed framework has been used as basis to provide original solutions to three important applications in computer vision, the tasks of image and supervised texture segmentation in low-level vision, and the task of motion estimation and tracking in low-level vision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Image Segmentation</head><p>In <ref type="bibr" target="#b21">[22]</ref>, a two-stage approach for image segmentation has been proposed that is exploited directly from the Geodesic Active Region model and incorporates boundary and region information sources. The first stage refers to a modeling phase where the observed histogram is approximated using a mixture of Gaussian components. This analysis denotes the regions number as well as their statistics, since a Gaussian component is associated with each region.</p><p>Then the segmentation is performed by employing the Geodesic Active Region model. The different region boundaries are determined using a probabilistic module by seeking for local discontinuities on the statistical space that is associated with the image features. This information is combined with the region one, which is expressed directly from conditional probabilities, resulting in a geodesic active region-based segmentation framework. The defined objective function is minimized with respect to the different region boundaries (multiple curves) using a gradient descent method, where the obtained equations are implemented using the level set theory. Moreover, the evolutions of the level set functions are coupled by demanding a nonoverlapping set of curves since each pixel of the image cannot belong to more than one region. The resulting model deals automatically with the changes of topology, thereby allowing either several subregions with the same intensity properties to be the output of a single initial curve, or a single curve to be the output of multiple initial curves.</p><p>Some experimental results obtained with proposed framework are shown in Fig. <ref type="figure" target="#fig_3">5</ref>, while more details can be found in <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Supervised Texture Segmentation</head><p>In <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21]</ref> a new paradigm for supervised texture segmentation has been proposed. This framework is composed of a learning and a segmentation phase.</p><p>Initially, an off-line step is performed that creates multicomponent probabilistic texture descriptors for the given set of texture patterns, where the multimodal data are derived using a set of filter operators. The texture analysis/modeling phase consists of three steps. A set of optimally selected predefined filters (mainly Gabor) is applied to each texture pattern (learning). Then each filter response is modeled statistically using a multicomponent conditional probability density function (modeling). These conditional probabilities are assumed to be Gaussian mixtures with two or three components. Based on this analysis, each data vector from the multimodal filter response space has an associated tuple of probabilities that express the probability that this vector belongs to a given texture pattern. Furthermore, the different filter operators are associated with some reliability measurements (validating). These measurements are estimated according to their discrimination power. The discrimination power of a filter operator is inversely proportional to the misclassification error of this operator during the learning phase. Now, given the input image, we apply the same operators and derive an observation set that is coherent with the texture descriptors. Then, for each pixel we estimate the probability of being on the boundaries between two different texture regions. Since we deal with multimodal data, a probability vector is obtained. The components of this vector (e.g., boundary probabilities) are combined to a single frame using some reliability measurements and provide the boundary-based texture information. Besides, using the texture descriptors and the observation set we determine the region-based information that is derived from the most probable temporal texture assignment. Then, the segmentation problem is stated under the Geodesic Active Region model, which aims at finding the best minimal length geodesic curves that preserve high boundary probabilities, and creates regions with maximum a posteriori segmentation probability with respect to the associated texture hypothesis. The defined objective function is minimized using a gradient-descent where the initial curves are propagated by means of velocities that contain three terms: one that shrinks or expands the curve toward the region boundaries, one that supports the homogeneity of the interior curve region given the associated texture hypothesis, and one that expresses the expected curve spatial properties i.e., smoothness, regularity). These motion equations are implemented using the level set methods, where a coupled multiphase propagation is considered to impose the idea of mutually exclusive propagating curves.</p><p>Some experimental results obtained with the proposed framework are shown in Fig. <ref type="figure" target="#fig_4">6</ref>, while more details can be found in <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Motion Estimation and Tracking</head><p>In <ref type="bibr" target="#b19">[20]</ref> a general motion estimation and tracking framework is proposed derived from the Geodesic Active Region model that i. Deals simultaneously with the motion estimation and tracking problem, ii. Makes use in a generic form of different boundary-and region-based tracking modules,</p><p>iii. Deals with the case of nonrigid as well as occluding moving objects, and vi. Can be easily extended to cases involving a mobile observer. Thus, within this framework the motion estimation and the tracking problem are coupled, resulting in a two-direction multimodule front propagation tracking system, where the motion parameters and the exact object position are simultaneously recovered.</p><p>To summarize, the motion estimation and the tracking problems are reformulated within the Geodesic Active Region framework, where boundary-and region-based modules are involved. The boundary-based information is determined using a combination of a gradient and a probabilistic edge detector while the region-based one uses three different modules: a motion detection/segmentation, an intensity-based, and a visual consistency module. The observed difference density function (histogram) is analyzed as a mixture density of Gaussian or Laplacian elements that correspond to the static pixels (background) and the mobile pixels (objects). The output of this statistical modeling phase is used to define the Motion Detection Module. Besides using some knowledge regarding the background as well as the moving intensity properties (it is acquired during the process) we define the intensity-based tracking module. Finally, given the current curve position, an affine motion model that creates a visual consistency between the object intensities in the current and those in the previous frame is estimated. The designed objective function is minimized with respect to the curve position as well as to the motion parameters using a gradient descent method. The obtained partial differential motion equations (PDEs) that deform the initial curves are composed of boundary, intensity, and motion-based forces and are constrained by a regularity force. These PDEs are implemented using the level set theory while an incremental method is used to update the estimates of the motion parameters. To deal with occlusions, a multiphase curve propagation is also considered that couples the propagation of curves with respect to the different objects.</p><p>Some experimental results obtained with the proposed framework are shown in Fig. <ref type="figure" target="#fig_5">7</ref>, while more details can be found in <ref type="bibr" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">DISCUSSION, SUMMARY</head><p>To summarize, in this paper a new energy minimization-based variational framework for dealing with frame partition problems is proposed. This framework, namely, the Geodesic Active Region, lies on a very flexible model that integrates boundry-and region-based information modules under a generic objective function. The optimization of this framework leads to the curve propagation theory, where a set of initial curves is propagated toward the regions' boundaries being constrained by internal forces, while at the same time it is used to determine a coherent partition of the image domain according to some region-based properties. Moreover, we have proposed the implementation of the curve propagation using the level set methods, a very elegant tool that enables a large number of nice properties, and makes the propagation of curves easier. These methods combined with the proposed model give a paradigm with a large applicability set, free from the initial conditions and of extreme power.</p><p>This paradigm was introduced for a very general frame partition case, and it can be used for a variety of computer vision applications, those that can be reformulated as frame partition problems. The efficiency and the performance of the proposed framework have been validated using three important applications in computer vision, the tasks of image and supervised texture segmentation in low-level vision and the task of motion estimation and tracking in motion analysis.</p><p>The main contributions of this paper consists of</p><p>• A curve-based variational framework capable of dealing with frame partition problems that integrates boundary-and region-based information modules,</p><p>• The connection between the minimization procedure of the objective function with the curve propagation theory, and</p><p>• The implementation of this framework using the level set theory, resulting in a model of extreme power and free from the initial conditions.</p><p>As for the future directions of this work, the incorporation into the model of a term that accounts for some shape prior knowledge with respect to the expected frame partition map (self-constrained geodesic active regions) and the extension of the use of the proposed framework to deal with application in three dimensions are challenges.</p><p>Various experimental results (in MPEG format), including those shown in this article, can be found at http://www.inria.fr/robotvis/personnel/der/demos.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIG. 1 .</head><label>1</label><figDesc>FIG. 1. Geodesic Active Region Model: (a) the input, (b) the boundary-based information, (c) the regionbased information corresponding to hypothesis h A (the information is proportional to the frame intensities), and (d) the region-based information corresponding to hypothesis h B (the information is proportional to the frame intensities).</figDesc><graphic coords="5,35.33,47.43,324.48,87.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>" the boundary features of the different classes (for the real boundary pixels this function returns minima values), and • A set of functions [r i : R × R → R, i ∈ [1, N ]] that "captures" the region features of the different classes (for the real class pixels this function returns minima values), then the geodesic active region framework consists of minimizing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIG. 3 .</head><label>3</label><figDesc>FIG. 3. Evolution of the Geodesic Active Region Energy for the Fig. 2 example. (a) The evolution of the boundary energy term, (b) the evolution of the region energy term, and (c) the evolution of the total energy. The different colors of the plotted function correspond to the different initial curve conditions: the red color refers to Fig. 2a, while the blue color to Fig. 2b.</figDesc><graphic coords="11,37.33,48.35,320.16,124.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FIG. 5 .</head><label>5</label><figDesc>FIG. 5. Geodesic Active Regions for image segmentation. A medical image that is composed of four classes that are multicomponent (each class contains more than one connected regions) is considered. (1) Curve propagation for Class 1, (2) curve propagation for Class 2, (3) curve propagation for Class 3, and (4) curve propagation for Class 4.</figDesc><graphic coords="14,21.69,48.39,349.92,287.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>FIG. 6 .</head><label>6</label><figDesc>FIG.6. Geodesic Active Regions for supervised texture segmentation. Demonstration of a real image where the goal is to distinguish the region of interest (zebra) from the other texture regions (the interior curve area corresponds to the zebra). Two different initialization steps are demonstrated.</figDesc><graphic coords="16,36.69,47.83,319.68,328.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>FIG. 7 .</head><label>7</label><figDesc>FIG. 7. Geodesic Active Regions for motion estimation and tracking. Soccer sequence: (a) Initial curve, (b) final curve, and (c) motion estimation.</figDesc><graphic coords="17,29.83,47.95,335.04,336.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="13,53.33,47.99,288.48,229.92" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Seeded region growing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="641" to="647" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A multiscale random field model for bayesian image segmentation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bouman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="162" to="177" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A geometric model for active contours</title>
		<author>
			<persName><forename type="first">V</forename><surname>Caselles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Catte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dibos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Math</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Geodesic active contours</title>
		<author>
			<persName><forename type="first">V</forename><surname>Caselles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<meeting><address><addrLine>Boston, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Geodesic active contours</title>
		<author>
			<persName><forename type="first">V</forename><surname>Caselles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="61" to="79" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deformable boundary finding in medical images by integrating gradient and region information</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Staib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Duncan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="859" to="870" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An active contour model without edges</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Scale-Space Theories in Computer Vision</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="141" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">On active contour models and balloons, CVGIP: Image Understand</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bayes smoothing algorithms for segmentation of binary images modeled by markov random fields</title>
		<author>
			<persName><forename type="first">H</forename><surname>Derin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cristi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1186" to="1191" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A common framework for image segmentation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="227" to="243" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Snakes: Active contour models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="321" to="332" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Gradient flows and geometric active contour models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kichenassamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Olver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tannenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yezzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Internat. Conf. Comput. Vision</title>
		<meeting><address><addrLine>Boston, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="810" to="815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A multiscale algorithm for image segmentation by variational framework</title>
		<author>
			<persName><forename type="first">G</forename><surname>Koepfler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Numer. Anal</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="282" to="299" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Shape modeling with front propagation: A level set approach</title>
		<author>
			<persName><forename type="first">R</forename><surname>Malladi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sethian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="158" to="175" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Aptimal approximations by piecewise smooth functions and variational methods</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Pure Appl. Math</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="577" to="685" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fronts propagating with curvature-dependent speed: Algorithms based on the Hamilton-Jacobi formulation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sethian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Phys</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="12" to="49" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
		<ptr target="http://www.sop.inria.fr/robotvis/personnel/nparagio/papers/thesis.ps.gz" />
		<title level="m">Geodesic Active Regions and Level Set Methods: Contributions and Applications in Artificial Vision</title>
		<imprint>
			<date type="published" when="2000-01">Jan. 2000</date>
		</imprint>
		<respStmt>
			<orgName>School of Computer Engineering, University of Nice/Sophia Antipolis</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Geodesic active regions for texture segmentation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deriche</surname></persName>
		</author>
		<idno>3440</idno>
		<ptr target="http://www.inria.fr/RRRT/RR-3440.html" />
	</analytic>
	<monogr>
		<title level="j">INRIA</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<pubPlace>France</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Geodesic active regions for motion estimation and tracking</title>
		<author>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deriche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="688" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Geodesic active regions for supervised texture segmentation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deriche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="926" to="932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Coupled geodesic active regions for image segmentation: A level set approach</title>
		<author>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deriche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference in Computer Vision</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="224" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A level set model for image classification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Samson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Blanc-Feraud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zerubia</surname></persName>
		</author>
		<ptr target="http://www.inria.fr/RRRT/RR-3662.html" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Scale-Space Theories in Computer Vision</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="306" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A statistical approach to snakes for bimodal and trimodal imagery</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yezzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="898" to="903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A variational level set approach to multiphase motion</title>
		<author>
			<persName><forename type="first">H.-K</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Merriman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Phys</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page" from="179" to="195" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Region competition: Unifying snakes, region growing, and Bayes/MDL for multiband image segmentation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="884" to="900" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">He is currently a research director at INRIA Sophia-Antipolis in the Computer Vision and Robotics Group. His research interests are in computer vision and image processing and include partial differential equations applied to image processing and computer vision, low-level vision, motion analysis and visual tracking, calibration and stereo, image sequence analysis. More generally, he is very interested by the application of mathematics to computer vision and image processing. He has authored and co-authored over 100 scientific papers</title>
		<ptr target="http://www.inria.fr/robotvis/personnel/der/der-eng.html" />
	</analytic>
	<monogr>
		<title level="m">RACHID DERICHE graduated from the Ecole Nationale Supérieure des Télécommunications, Paris, in 1979 and received the Ph.D. in mathematics from the University of</title>
		<title level="s">France) in 2000 and his M.Sc. and B.Sc. (</title>
		<meeting><address><addrLine>Princeton, New Jersey; Paris IX, Dauphine</addrLine></address></meeting>
		<imprint>
			<publisher>NIKOS PARAGIOS received his Ph.D</publisher>
			<date type="published" when="1982">1982</date>
		</imprint>
		<respStmt>
			<orgName>University of Nice, Sophia Antipolis</orgName>
		</respStmt>
	</monogr>
	<note>highest honors) in computer science from the University of Crete (Greece) in 1996 and 1994, respectively. He worked as a research assistant at the Institute of Computer Science (FORTH) from 1994 to 1996 (Greece) and at the Computer Vision and Robotics Group (RobotVis) of the French Institute for Research in Computer Science and Control (I.N.R.I.A.) from 1996 to 1999. As of November 1999 he is a fulltime researcher at the Imaging and Visualization Department of Siemens Corporate Research. To find out more about his research and some selected publications take a look at his web page under the address</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
