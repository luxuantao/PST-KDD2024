<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Declarative Networking: Language, Execution and Optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Thau</forename><surname>Loo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tyson</forename><surname>Condie</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Minos</forename><surname>Garofalakis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><forename type="middle">E</forename><surname>Gay</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Petros</forename><surname>Maniatis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Raghu</forename><surname>Ramakrishnan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Timothy</forename><surname>Roscoe</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ion</forename><surname>Stoica</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">U</forename><forename type="middle">C</forename><surname>Berkeley</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Intel</forename><surname>Research</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Declarative Networking: Language, Execution and Optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B5ED9D2296FFE10949D08F97E099EF68</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The networking and distributed systems communities have recently explored a variety of new network architectures, both for applicationlevel overlay networks, and as prototypes for a next-generation Internet architecture. In this context, we have investigated declarative networking: the use of a distributed recursive query engine as a powerful vehicle for accelerating innovation in network architectures <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b33">33]</ref>. Declarative networking represents a significant new application area for database research on recursive query processing. In this paper, we address fundamental database issues in this domain. First, we motivate and formally define the Network Datalog (NDlog) language for declarative network specifications. Second, we introduce and prove correct relaxed versions of the traditional semi-naïve query evaluation technique, to overcome fundamental problems of the traditional technique in an asynchronous distributed setting. Third, we consider the dynamics of network state, and formalize the "eventual consistency" of our programs even when bursts of updates can arrive in the midst of query execution. Fourth, we present a number of query optimization opportunities that arise in the declarative networking context, including applications of traditional techniques as well as new optimizations. Last, we present evaluation results of the above ideas implemented in our P2 declarative networking system, running on 100 machines over the Emulab network testbed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The database literature has a rich tradition of research on recursive query languages and processing. This work has influenced commercial database systems to a certain extent. However, recursion is still considered an esoteric feature by most practitioners, and research in the area has had limited practical impact. Even within the database research community, there is longstanding controversy over the practical relevance of recursive queries, going back at least to the Laguna Beach Report <ref type="bibr" target="#b7">[7]</ref>, and continuing into relatively recent textbooks <ref type="bibr" target="#b35">[35]</ref>.</p><p>In more recent work, we have made the case that recursive query technology has a natural application in the design of Internet infrastructure. We presented an approach called declarative networking that enables declarative specification and deployment of distributed protocols and algorithms via distributed recursive queries over network graphs <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b33">33]</ref>. We recently described how we implemented and deployed this concept in a system called P2 <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b33">33]</ref>. Our high-level goal is to provide a software environment that can accelerate the process of specifying, implementing, experimenting with and evolving designs for network architectures.</p><p>Declarative networking is part of a larger effort to revisit the current Internet Architecture, which is considered by many researchers to be fundamentally ill-suited to handle today's network uses and abuses <ref type="bibr" target="#b13">[13]</ref>. While radical new architectures are being proposed for a "clean slate" design, there are also many efforts to develop application-level "overlay" networks on top of the current Internet, to prototype and roll out new network services in an evolutionary fashion <ref type="bibr" target="#b26">[26]</ref>. Whether one is a proponent of revolution or evolution in this context, there is agreement that we are entering a period of significant flux in network services, protocols and architectures.</p><p>In such an environment, innovation can be better focused and accelerated by having the right software tools at hand. Declarative query approaches appear to be one of the most promising avenues for dealing with the complexity of prototyping, deploying and evolving new network architectures. The forwarding tables in network routing nodes can be regarded as a view over changing ground state (network links, nodes, load, operator policies, etc.), and this view is kept correct by the maintenance of distributed queries over this state. These queries are necessarily recursive, maintaining facts about arbitrarily long multi-hop paths over a network of single-hop links.</p><p>Our initial forays into declarative networking have been promising. First, in declarative routing <ref type="bibr" target="#b24">[24]</ref>, we demonstrated that recursive queries can be used to express a variety of well-known wired and wireless routing protocols in a compact and clean fashion, typically in a handful of lines of program code. We also showed that the declarative approach can expose fundamental connections: for example, the query specifications for two well-known protocolsone for wired networks and one for wireless -differ only in the order of two predicates in a single rule body. Moreover, higher-level routing concepts (e.g., QoS constraints) can be achieved via simple modifications to the queries. Second, in declarative overlays <ref type="bibr" target="#b23">[23]</ref>, we extended our framework to support more complex applicationlevel overlay networks such as multicast overlays and distributed hash tables (DHTs). We demonstrated a working implementation of the Chord <ref type="bibr" target="#b34">[34]</ref> overlay lookup network specified in 47 Datalog-like rules, versus thousands of lines of C++ for the original version.</p><p>Our declarative approach to networking promises not only flexibility and compactness of specification, but also the potential to statically check network protocols for security and correctness properties <ref type="bibr" target="#b11">[11]</ref>. In addition, dynamic runtime checks to test distributed properties of the network can easily be expressed as declarative queries, providing a uniform framework for network specification, monitoring and debugging <ref type="bibr" target="#b33">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">The Database Research Agenda</head><p>In our earlier declarative networking proposals, we focused primarily on addressing problems in networking and distributed systems. In doing so, we set aside important and challenging questions of language semantics, distributed execution strategies, and correctness under network dynamics, all of which are essential for the practical realization of declarative networks.</p><p>In this paper, we explore several of these research issues from the database perspective. We implemented our ideas in the P2 system, and present evaluations of many of our optimizations in realistic large-scale distributed experiments. Specifically, the main contributions of this paper are as follows:</p><p>• We motivate and formally define the NDlog language for declarative network specification. NDlog is a subset of Datalog that makes explicit the link graph of the network and the partitioning of data across nodes. As part of NDlog, we introduce the concept of link-restricted rules, which guarantees that all rules can be rewritten to be executed locally at individual nodes, and all communication for each rewritten rule only involves sending messages along links (Section 2).</p><p>• We introduce and prove correct relaxed versions of the seminaïve execution strategy called buffered semi-naïve and pipelined semi-naïve evaluation. These techniques overcome fundamental problems of semi-naïve evaluation in an asynchronous distributed setting, and should be of independent interest outside the context of declarative networking: they significantly increase the flexibility of semi-naïve evaluation to order the derivation of facts (Section 3).</p><p>• In the declarative network setting, transactional isolation of updates from concurrent queries is not useful; network protocols must incorporate concurrent updates about the state of the network while they run. We address this by formalizing the typical distributed systems notion of "eventual consistency" in our context of derived data. Using techniques from materialized recursive view maintenance, we incorporate updates to base facts during query execution, and still ensure welldefined eventual consistency semantics. This is of independent interest beyond the network setting when handling updates and long-running recursive queries (Section 4).</p><p>• We present a number of query optimization opportunities that arise in the declarative networking context, including applications of traditional techniques (e.g., aggregate selections and magic-sets rewriting), as well as new optimizations for work-sharing, caching, and cost-based optimizations based on graph statistics. Again, many of these ideas can be applied outside the context of declarative networking or distributed implementations (Section 5).</p><p>• We present evaluation results from a distributed deployment involving 100 machines connected by the Emulab <ref type="bibr" target="#b10">[10]</ref> network testbed, running prototypes of our optimization techniques implemented as modifications to the P2 declarative overlay system (Section 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">DATA AND QUERY MODEL</head><p>We first provide a short review of Datalog, following the conventions in Ramakrishnan and Ullman's survey <ref type="bibr" target="#b28">[28]</ref>. A Datalog program consists of a set of declarative rules and a query. A Datalog rule has the form p :-q 1 , q 2 , ..., q n ., which can be read informally as "q 1 and q 2 and ... and q n implies p". p is the head of the rule, and q 1 , q 2 , ..., q n is a list of literals that constitutes the body of the rule. Literals are either predicates applied to fields (variables and constants), or function symbols applied to fields. The rules can refer to each other in a cyclic fashion to express recursion. The order in which the rules are presented in a program is semantically immaterial. The commas separating the predicates in a rule are logical conjuncts (AND); the order in which predicates appear in a rule body also has no semantic significance (though implementations typically employ a left-to-right execution strategy). The query specifies the output of interest.</p><p>The predicates in the body and head of Datalog rules are relations, and we will refer to them interchangeably as predicates, relations, or tables. Each relation has a primary key, which consists of a set of fields that uniquely identifies each tuple within the relation. We allow the primary key to be specified for stored ("extensional") relations; in the absence of other information, the primary key is the full set of attributes in the relation.</p><p>The names of predicates, function symbols and constants begin with a lower-case letter, while variable names begin with an uppercase letter. Most implementations of Datalog enhance it with a limited set of function calls (which start with "f " in our syntax), including boolean predicates, arithmetic computations and simple list manipulation (e.g., the f concatPath function in our first example). Aggregate constructs are represented as functions with field variables within angle brackets (&lt;&gt;). For most of our discussion, we will not consider negated predicates; we will return to the topic of negation as part of our future work (Section 8).</p><p>As an example, the following program computes the shortest paths between all pairs of nodes in a graph. The program has four rules (which for convenience we label R1-R4), and takes as input a stored ("extensional") relation link(src, dst, cost). R1 and R2 are used to derive "paths" in the graph, represented as tuples in the derived ("intensional") relation path(src, dst, nextHop, pathVector, . . .). The src and dst fields represent the endpoints of the path; the pathVector is a string encoding the full path. We discuss nextHop later. Given the path relation, Rule R4 computes the shortest paths as the derived relation shortestPath(src, dst, pathVector, cost). R3 derives the relation spCost(src, dst, mincost) that computes the minimum cost for each (src,dst) group for all input paths. The rule Query specifies shortestPath tuples as the result tuples. R2 is a linear rule, since there is only one recursive literal in the body. Rules with more than one recursive literal in the body are non-linear. Rule R1 produces one-hop paths from existing link tuples, and Rule R2 recursively produces path tuples of increasing cost by matching the destination fields of existing links to the source fields of previously computed paths. The matching is expressed using the repeated "Z" variable in link(S, Z,C 1 ) and path(Z, D, Z 2 , P 2 ,C 2 ) of rule R2. Intuitively, rule R2 says that if there is a link from node S to node Z, and there is a path from node Z to node D, then there is a path from node S to node D via Z. In the presence of path cycles, the query never terminates, as R1 and R2 will generate paths of ever increasing lengths. However, this can be fixed with a well-known query rewrite (Section 5.1.1) when costs are positive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Network Datalog</head><p>In this section, we introduce the data and query model that we propose for declarative networking. The language we present is Network Datalog (NDlog), a restricted variant of traditional Datalog intended to be computed in distributed fashion on physical network graphs. In describing our model, we use the NDlog query shown in Figure <ref type="figure" target="#fig_1">1</ref>, which performs distributed computation of shortest paths.</p><p>One of the novelties of our setting, from a database perspective, is that data is distributed and relations may be partitioned across sites. To ease the generation of efficient query plans in such a system, NDlog gives the query writer explicit control on data placement and movement. Specifically, NDlog uses a special data type, SP1: path(@S,@D,@D,P,C) :-#link (@S,@D,C), . P = f concatPath(link(@S,@D,C), nil). SP2: path(@S,@D,@Z,P,C) :-#link (@S,@Z,C 1 ), .</p><p>path(@Z,@D,@Z 2 ,P 2 ,C 2 ), C = C 1 + C 2 , . P = f concatPath(link(@S,@Z,C 1 ),P 2 ). SP3: spCost(@S,@D,min&lt;C&gt;) :-path(@S,@D,@Z,P,C). SP4: shortestPath(@S,@D,P,C) :-spCost(@S,@D,C), .</p><p>path(@S,@D,@Z,P,C). Query: shortestPath(@S,@D,P,C). address, to specify a network location. Names of address variables and constants are prepended with "@". More formally, we have the following definition: Definition 1 A location specifier is an attribute of type address in a predicate that indicates the network storage location of each tuple.</p><p>As a matter of notation, we require the location specifier to be the first field in all predicates, and we highlight it in bold for clarity. For example, the location specifier of link(@S,@D,C) is @S.</p><p>Another novelty of our setting is that we assume a network graph that is not fully connected, i.e., a node can communicate directly with only a subset of nodes in the system. This allows us to model the physical connectivity of a typical autonomous system in the Internet, where each node is connected to relatively few other nodes. In contrast, both traditional parallel query processors and more recent distributed query engines, such as PIER <ref type="bibr" target="#b17">[17]</ref>, assume a fully connected network graph, where messages can be sent directly from any node to any other node in the system. Parallel systems achieve this by engineering (and provisioning) the interconnection network, while PIER uses overlay routing to connect any two nodes.</p><p>To express the constraint that a node can send data only to another node with which it is physically connected, we introduce the concept of link relation, which is defined as follows:</p><p>Definition 2 A link relation is a stored ("extensional") relation link(@src, @dst, ...) representing the connectivity information of the network being queried.</p><p>The first two fields of each link table entry contain the source and destination addresses of a network link respectively, followed by an arbitrary number of other fields (typically metrics) describing the link. In this paper, we constrain all links to be bidirectional, i.e., if there is a network edge from a node to its neighbor, the reverse must be true<ref type="foot" target="#foot_0">1</ref> . In all our example queries, we utilize only one link table. In practice, there can be multiple such tables used by different rules.</p><p>Given that we will be executing queries across network links, it is useful to identify queries that do not require communication: Definition 3 Local rules are rules that have the same location specifier in each predicate, including the head.</p><p>Local rules can be executed without any distributed logic. Rules SP1, SP3 and SP4 are local. SP2 is a non-local rule since the link and path body predicates are stored at different locations.</p><p>In NDlog, the evaluation of a rule must depend only on communication along the physical links. To this end, we introduce the following: Definition 4 A link literal is a link relation that appears in the body of a rule prepended with the "#" symbol.</p><p>Given the preceding definitions, we are ready to define a simple syntactic constraint on the rules to ensure that communication takes place only along the physical links: Definition 5 A link-restricted rule is either a local rule, or a rule with the following properties:</p><p>• There is exactly one link literal in the body</p><p>• All other literals (including the head predicate) have their location specifier set to either the first (source) or second (destination) field of the link literal.</p><p>This syntactic constraint precisely captures the requirement that we be able to operate directly on a network whose link connectivity is not a full mesh. Further, as we demonstrate in Section 3, linkrestriction also guarantees that all programs with only link-restricted rules can be rewritten into a canonical form where every rule body can be evaluated on a single node. In addition, all communication for each rewritten rule only involves sending messages along links. The following is an example of a link-restricted rule: p(@D,...) :-#link (@S,@D,...),p 1 (@S,...),p 2 (@S,...), ..., p n (@S,...).</p><p>The rule body of this example is executed at @S and the resulting p tuples are sent to @D, preserving the communication constraints along links. Note that this example's body predicates all have the same location specifier: @S, the source of the link. In contrast, rule SP2 of Figure <ref type="figure" target="#fig_1">1</ref> is link-restricted but has some relations whose location specifier is the source, and others whose location specifier is the destination; this needs to be rewritten as described in Section 3.</p><p>Given these preliminaries, we are now ready to present our language NDlog: Definition 6 A Network Datalog (NDlog) program is a Datalog program that satisfies the following syntactic constraints:</p><p>1. Location specificity: Each predicate has a location specifier as its first attribute 2. Address type safety: A variable that appears once in a rule as an address type must not appear elsewhere in the rule as a non-address type. 3. Stored link relations: Link relations never appear in the head of a rule with a non-empty body (i.e., they are stored, not derived). 4. Link-restriction: Any non-local rules in the program are link-restricted by some link relation.</p><p>Since NDlog is a subset of Datalog, the semantics of a valid NDlog program are exactly those of Datalog.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Shortest Path Example</head><p>To illustrate NDlog, we step through an execution of the shortestpath query above to illustrate derivation and communication of tuples as the query is computed. We make use of the example network in Figure <ref type="figure" target="#fig_3">2</ref>. Our discussion is necessarily informal since we have not yet presented our distributed implementation strategies; in the next section, we show in greater detail the steps required to generate the execution plan. Here, we focus on a high-level understanding of the data movement in the network during query processing.</p><p>We will describe communication in iterations, where at each iteration, each network node generates paths of increasing hop count, and then propagates these paths to neighbor nodes along links. In the 1 st iteration, all nodes initialize their local path tables to 1-hop paths using SP1. In the 2 nd iteration, using SP2, each node takes the input paths generated in the previous iteration, and computes 2-hop paths, which are then propagated to its neighbors. For example, <ref type="figure">path(a,</ref><ref type="figure">d,</ref><ref type="figure">b,</ref><ref type="figure">[a,</ref><ref type="figure">b,</ref><ref type="figure">d],</ref><ref type="figure" target="#fig_7">6</ref>) is generated at node b using path(b, d, d, [b, d], 1) from the 1 st iteration, and propagated to node a. In addition to storing the entire path vector, each path tuple also contains the nextHop attribute, which indicates for each path the next hop to route the message in the network. In fact, many network protocols propagate only the nextHop and avoid sending the entire path vector. <ref type="figure">p(a,</ref><ref type="figure">b,</ref><ref type="figure">b,</ref><ref type="figure">[a,</ref><ref type="figure">b],</ref><ref type="figure" target="#fig_6">5)  p(a,</ref><ref type="figure">c,</ref><ref type="figure">c,</ref><ref type="figure">[a,</ref><ref type="figure">c</ref>  <ref type="figure">p(b,</ref><ref type="figure">d,</ref><ref type="figure">d,</ref><ref type="figure">[b,</ref><ref type="figure">d],</ref><ref type="figure" target="#fig_4">1)   p(a,</ref><ref type="figure">d,</ref><ref type="figure">b,</ref><ref type="figure">[a,</ref><ref type="figure">b,</ref><ref type="figure">d],</ref><ref type="figure" target="#fig_7">6)   p(a,</ref><ref type="figure">b,</ref><ref type="figure">c,</ref><ref type="figure">[a,</ref><ref type="figure">c</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>only show newly derived tuples at each iteration. For simplicity, we show only the derived paths along the solid lines even though the network connectivity is bidirectional (dashed lines).</head><p>As paths are being computed, the shortest paths are also incrementally computed. For example, node a computes path(a, b, b, [a, b], 5) using rule SP1, and then sets its shortest path to shortestPath(a, b, [a, b], 5) using rule SP4. In the next iteration, node a receives path(a, b, c, [a, c, b], 2) from node c which has lower cost compared to the previous shortest cost of 5, and hence a new shortestPath(a, b, [a, b], 2) replaces the previous value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Expressiveness</head><p>In previous work <ref type="bibr" target="#b24">[24]</ref> we argued that executing a shortest path distributed Datalog query closely resembles the distributed computation of the well-known path vector <ref type="bibr" target="#b25">[25]</ref> protocol. In proposals for declarative networks <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b24">24]</ref>, Datalog-like programs were used for a variety of networking tasks, including standard routing protocols such as distance vector <ref type="bibr" target="#b25">[25]</ref> and dynamic source routing <ref type="bibr" target="#b20">[20]</ref>, and more complex networks such as multicast trees and the Chord network <ref type="bibr" target="#b34">[34]</ref>. We note that NDlog is flexible enough for expressing most of these programs efficiently, and provides the advantages of having clear semantics as described above (something that is not available in the original language for P2 described in <ref type="bibr" target="#b23">[23]</ref>) and a clearly defined link-restricted implementation as described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXECUTION PLAN GENERATION</head><p>Having illustrated the intended execution of an example program, we now describe the steps required to automatically generate an execution plan from a NDlog program. We first focus on generating an execution plan in a centralized implementation, before extending the techniques to the network scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Centralized Plan Generation</head><p>In generating the centralized plan, we utilize the well-known seminaïve fixpoint <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b4">4]</ref> evaluation mechanism that ensures no redundant evaluations. As a quick review, in semi-naïve (SN) evaluation, input tuples computed in the previous iteration of a recursive rule execution are used as input in the current iteration to compute new tuples. Any new tuples that are generated for the first time in the current iteration are then used as input to the next iteration. This is repeated until a fixpoint is achieved (i.e., no new tuples are produced).</p><p>The semi-naïve rewritten rule for rule SP2 is shown below:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SP2-1:</head><p>path new (@S,@D,@Z,P,C) :-#link (@S,@Z,C 1 ), .</p><p>path old (@Z,@D,@Z 2 ,P 2 ,C 2 ), C = C 1 + C 2 , . P = f concatPath(link(@S,@Z,C 1 ),P 2 ).</p><p>Figure <ref type="figure">3</ref> shows the dataflow realization for rule SP2-1 using the conventions of P2. We will briefly explain how the semi-naïve evaluation is achieved here. Each semi-naïve rule is implemented as a rule strand. Each strand consists of a number of relational operators. The example strand receives new path old tuples generated in the previous iteration to generate new paths ( path new ) which are then inserted into the path table (with duplicate elimination) for further processing in the next iteration.</p><p>In Algorithm 1, we show the pseudocode for a centralized P2 implementation of multiple semi-naïve rule strands where each rule has the form p new p old k refers to p k tuples generated for the first time in the previous iteration. p old k refers to all p k tuples generated before the previous iteration.</p><formula xml:id="formula_0">Algorithm 1 Semi-naïve (SN) Evaluation in P2 while ∃B k .size &gt; 0 ∀B k where B k .size &gt; 0, p old k ← B k . f lush() execute all rule strands foreach recursive predicate p j p old j ← p old j ∪ p old j B j ← p new j -p old j p j ← p old j ∪ B j p new j ← / 0</formula><p>In the algorithm, B k denotes the buffer for p k tuples generated in the previous iteration ( p old k ). Initially, p k , p old k , p old k and p new k are empty. As a base case, we execute all the rules to generate the initial p k tuples, which are inserted into the corresponding B k buffers. Each subsequent iteration of the while loop consists of flushing all existing p old k tuples from B k and executing all rule strands to generate p new j tuples, which are used to update p old j , B j and p j accordingly. Note that only new p j tuples generated in the current iteration are inserted into B j for use in the next iteration. Fixpoint is reached when all buffers are empty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Distributed Plan Generation</head><p>In the distributed implementation of the shortest-path query, nonlocal rules whose body predicates have different location specifiers cannot be executed at a single node, since the tuples that must be joined are situated at different nodes in the network. A rule localization rewrite step ensures that all tuples to be joined are at the same node. This allows a rule body to be locally computable.</p><p>(#link.@S,path.@Z,path.@D,f_concatPath (#link(@S,@Z,C), path.P), #link.C+path.C) as path(@ S ,@D,@Z,P,C) path(@ Z,@D,@Z 2 ,P,C) #Link.Z=path.Z path.@S #link(@ S,@Z,C) #link.@Z project Consider rule SP2 from Section 2 where the link and path predicates have different location specifiers. These two predicates are joined by a common "@Z" address field. Figure <ref type="figure" target="#fig_5">4</ref> shows the corresponding logical query plan depicting the distributed join. The clouds represent an "exchange"-like operator <ref type="bibr" target="#b14">[14]</ref> that forwards tuples from one network node to another; clouds are labeled with the link attribute that determines the tuple's recipient. The first cloud (#link.@Z) sends link tuples to the neighbor nodes indicated by their destination address fields, to join with matching path tuples stored by their source address fields. The second cloud (path.@S) transmits for further processing new path tuples computed from the join, setting the recipient according to the source address field. Based on the above distributed join, rule SP2 can be rewritten into the following two rules. Note that all predicates in the body of SP2a have the same location specifiers; the same is true of SP2b.</p><p>SP2a: linkD(@Z,@S,C) :-#link (@S,@Z,C). SP2b: path(@S,@D,@Z,P,C) :-#link (@Z,@S,C 3 ),linkD(@Z,@S,C 1 ), .</p><p>path(@Z,@D,@Z 2 ,P 2 ,C 2 ), .</p><formula xml:id="formula_1">C = C 1 + C 2 , . P = f concatPath(linkD(@Z,@S,C 1 ),P 2 ).</formula><p>The rewrite is achievable because the link and path predicates, although at different locations, share a common join address field. In Algorithm 2, we summarize the general rewrite technique for an input set of link-restricted rules R. In the pseudocode, for simplicity, we assume that the location specifiers of all the body predicates are sorted (@S followed by @D); this can be done as a preprocessing step. The algorithm as presented here assumes that all links are bidirectional, and may add a #link (@D,@S) to a rewritten rule to allow for backward propagation of messages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Rule Localization Rewrite proc RuleLocalization(R)</head><p>while ∃ rule r ∈ R: h(@L, ...) : -#link (@S,@D,...), p 1 (@S,..),..,p i (@S,...), p i+1 (@D,...),..,p n (@D,..) R.remove(r) R.add(hS(@S, @D, ..) : -#link (@S,@D,..),..,p i (@S,..).) R.add(hD(@D, @S, ..) : -hS(@S, @D, ..).) if @L = @D then R.add(h(@D,..) :-hD(@D,@S,..), p i+1 (@D,..),..,p n (@D,..).) else R.add(h(@S,..) :-#link (@D,@S),hD(@D,@S..), p i+1 (@D,..),..,p n (@D,..).) The equivalence statement in the above claim can be easily shown, by examining the simple factoring of each removed rule into two parts. The remainder of the claim can be verified syntactically in the added rules.</p><p>Returning to our example, after rule localization we perform the semi-naïve rewrite, and then generate the rule strands shown in Figure <ref type="figure" target="#fig_6">5</ref>. Unlike the centralized strand in Figure <ref type="figure">3</ref>, there are now three rule strands. The extra two strands (SP2a@S and SP2b-2@Z) are used as follows. Rule strand SP2a@S sends all existing links to the destination address field as linkD tuples. Rule strand SP2b-2@Z takes the new linkD tuples it received via the network and performs a join operation with the local path table to generate new paths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Relaxing Semi-naïve Evaluation</head><p>In our distributed implementation, the execution of rule strands can depend on tuples arriving via the network, and can also result in new tuples being sent over the network. Traditional semi-naïve evaluation completely evaluates all rules on a given set of facts, i.e., completes the iteration, before considering any new facts. In a distributed execution environment where messages can be delayed or lost, the completion of an iteration in the traditional sense can only be detected by a consensus computation across multiple nodes, which is expensive; further, the requirement that many nodes complete the iteration together (a "barrier synchronization" in parallel computing terminology) limits parallelism significantly by restricting the rate of progress to that of the slowest node.</p><p>We address this by making the notion of iteration local to a node. New facts might be generated through local rule execution, or might be received from another node while a local iteration is in progress. We propose and prove correct two variations of semi-naïve iteration to handle this situation: buffered semi-naïve (BSN) and pipelined semi-naive (PSN). Both approaches extend SN to work in an asynchronous distributed setting, while generating the same results as SN evaluation. We further prove that these techniques avoid duplicate inferences, which may result in generating network messages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Buffered Semi-naïve</head><p>Buffered semi-naïve (BSN) is the standard SN algorithm described in Figure <ref type="figure" target="#fig_1">1</ref> with the following modifications: A node can start a local SN iteration at any time its local B k buffers are non-empty. Tuples arriving over the network while an iteration is in progress are buffered for processing in the next iteration.</p><p>By relaxing the need to run an iteration to global completion, BSN relaxes SN substantially, by allowing a tuple from a traditional SN iteration to be buffered arbitrarily, and handled in some future iteration of our choice. Consequently, BSN may generate fewer tuples per iteration, but all results will eventually be generated. Since BSN uses the basic SN algorithm, the proof of correctness is straightforward and we omit it for brevity.</p><p>The flexibility offered by BSN on when to process a tuple could also be valuable outside the network setting, e.g., a disk-based hash join could accumulate certain tuples across iterations, spill them to disk in value-based partitions, and process them in value batches, rather than in order of iteration number. Similar arguments for buffering apply to other query processing tricks: achieving locality in Btree lookups, improving run-lengths in tournament sorts, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Pipelined Semi-naïve</head><p>As an alternative to BSN, pipelined semi-naïve (PSN) relaxes semi-naïve evaluation to the extreme of processing each tuple as it is received. This provides opportunities for additional optimizations on a per-tuple basis, at the potential cost of set-oriented local processing. New tuples that are generated from the semi-naïve rules, as well as tuples received from other nodes, are used immediately to compute new tuples without waiting for the current (local) iteration to complete.</p><formula xml:id="formula_2">Algorithm 3 Pipelined Semi-naïve (PSN) Evaluation while ∃Q k .size &gt; 0 t old,i k ← Q k .dequeueTuple() foreach rule strand execution p new,i+1 j : -p 1 , .., p k-1 ,t old,i k , p k+1 , .., p n , b 1 , b 2 , ..., b m foreach t new,i+1 j ∈ p new,i+1 j if t new,i+1 j / ∈ p j then p j ← p j ∪ t new,i+1 j Q j .enqueueTuple(t new,i+1 j )</formula><p>Algorithm 3 shows the pseudocode for PSN. Each tuple, denoted t, has a superscript (old/new, i) where i is its corresponding iteration number in SN evaluation. Each processing step in PSN consists of dequeuing a tuple t old,i k from Q k and then using it as input into all corresponding rule strands. Each resulting t new,i+1 j tuple is pipelined, stored in its respective p j table (if a copy is not already there), and enqueued into Q j for further processing. Note that in a distributed implementation, Q j can be a queue on another node, and the node that receives the new tuple can immediately process the tuple after the enqueue into Q j . For example, the dataflow in Figure <ref type="figure" target="#fig_6">5</ref> is based on a distributed implementation of PSN, where incoming path and linkD tuples received via the network are stored locally, and enqueued for processing in the corresponding rule strands.</p><p>To fully pipeline evaluation, we have also removed the distinctions between p old j and p j in the rules. Instead, a timestamp (or monotonically increasing sequence number) is added to each tuple at arrival, and the join operator matches each tuple only with tuples that have the same or older timestamp. This allows processing of tuples immediately upon arrival, and is natural for network message handling. This represents an alternative "book-keeping" strategy to the rewriting used in SN to ensure no repeated inferences. Note that the timestamp only needs to be assigned locally, since all the rules are localized.</p><p>While PSN enables fully pipeline evaluation, it is worth noting that PSN can allow just as much buffering as BSN with the additional flexibility of full pipelining.</p><p>In Appendix A, we prove that PSN generates the same results as SN, and does not repeat any inferences. Let FP S (p) and FP P (p) denote the result set for p for using SN and PSN respectively. We show that: Theorem 1: FP S (p) = FP P (p) Theorem 2: There are no repeated inferences in computing FP P (p).</p><p>In order to compute rules with aggregation (such as SP3), we utilize incremental fixpoint evaluation techniques <ref type="bibr" target="#b27">[27]</ref> that are amenable to pipelined query processing. These techniques can compute monotonic aggregates such as min, max and count incrementally based on the current aggregate and each new input tuple. We omit the details for lack of space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">SEMANTICS IN A DYNAMIC NETWORK</head><p>In practice, the state of the network is constantly changing during query execution. In contrast to transactional databases, changes to network state are not isolated from queries while they are running. Instead, as in network protocols, queries are expected to perform dynamic recomputations to reflect the most current state of the network. To better understand the semantics in a dynamic network, we consider the following two degrees of dynamism: Continuous Update Model: In this model, we assume that updates occur very frequently -at a period that is shorter than the expected time for a typical query to reach a fixpoint. Hence, the query results never fully reflect the state of the network. Bursty Update Model: In this idealized (but still fairly realistic model), updates are allowed to happen during query processing. However, we make the assumption that after a burst of updates, the network eventually quiesces (does not change) for a time long enough to allow all the queries in the system to reach a fixpoint.</p><p>In our analysis, we focus on the bursty model, since it is amenable to analysis; our results on that model provide some intuition as to the behavior in the continuous update model. Our goal in the bursty model is to achieve a variant of the typical distributed systems notion of eventual consistency, customized to the particulars of NDlog: we wish to ensure that the eventual state of the quiescent system corresponds to what would be achieved by rerunning the queries from scratch in that state. We briefly sketch the ideas here, and follow up with details in the remainder of the section.</p><p>To ensure well-defined semantics, we use techniques from materialized view maintenance <ref type="bibr" target="#b15">[15]</ref>, and consider three types of changes: Insertion: The insertion of a new tuple at any stage of processing can be naturally handled by (pipelined) semi-naïve evaluation. Deletion: The deletion of a base tuple leads to the deletion of any tuples that were derived from that base tuple. Deletions are carried out incrementally via (pipelined) semi-naïve evaluation by incrementally deriving all tuples that are to be deleted. Update: An update is treated as a deletion followed by an insertion. An update to a base tuple may itself result in derivation of more updates that are propagated via (pipelined) semi-naïve evaluation.</p><p>The use of pipelined semi-naïve evaluation in the discussion can be replaced with buffered semi-naïve without changing our analysis. Since some tuples may have multiple derivations, we use the count algorithm <ref type="bibr" target="#b15">[15]</ref> for keeping track of the number of derivations for each tuple, and only delete a tuple when the count is 0.</p><p>In dealing with queries with aggregates, we apply techniques for incremental computation of aggregates <ref type="bibr" target="#b27">[27]</ref> in the presence of updates. The arrival of new tuples may invalidate existing aggregates, and incremental recomputations are cheaper than computing the entire aggregate from scratch. For example, the re-evaluation cost for min and max aggregates are shown to be O(log n) time and O(n) space for the min and max aggregates <ref type="bibr" target="#b27">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Centralized Semantics</head><p>We first provide an intuitive example for the centralized case. Figure <ref type="figure" target="#fig_7">6</ref> shows a derivation tree for path(e, e, a, [e, a, b, e], 7) based on the shortest-path query. The leaves in the tree are the link base tuples. The root and the intermediate nodes are tuples recursively derived from the children inputs by applying either rules SP1 and SP2. When updates occur to the base tuples, changes are propagated up the tree to the root. For example, when the cost of #link(a, b, 5) is updated from 5 to 1, path(a, b, e, [a, b, e], 2) and path(e, a, [e, a, b, e], 3) are re-derived and replace the previous tuples. Similarly, the deletion of link(b, e, 1) leads to the deletion of path(b, e, e, [b, e], 1), path(a, b, e, [a, b, e], 2), and then path(e, a, e, [e, a, b, e], 3).</p><p>Let FP p be the set of tuples derived using PSN under the bursty model, and FFP p be the set of tuples that would be computed by PSN if starting from the quiesced state. In Appendix B, we prove the following theorem: Theorem 3: FP p = FFP p in a centralized setting.</p><p>The proof requires that all changes (inserts, deletes, updates) are applied in the same order in which they arrive. This is guaranteed by the FIFO queue of PSN and the use of timestamps. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Distributed Semantics</head><p>In order for incremental evaluation to work in a distributed environment, it is essential that along any link in the network, there is a FIFO ordering of messages. That is, along any link literal #link (s,d), facts derived at node s should arrive at node d in the same order in which they are derived (and vice versa). This guarantees that updates can be applied in order. Using the same definition of FP p and FFP p as before, assuming the link FIFO ordering, in Appendix B, we prove the following theorem: Theorem 4: FP p = FFP p in a distributed setting with FIFO links.</p><p>The drawback of enforcing network link FIFO is that it increases the complexity and lowers the performance of the underlying network. The alternative adopted by network protocols is to maintain all tuples as soft state. In the soft state storage model, all data (base and derived tuples) has an explicit "time to live" (TTL), and facts (in our case base tuples) must be explicitly reinserted with their latest values and a new TTL or they are deleted. Reinsertion of base tuples leads to recomputation of query results, which in a quiescent network, leads to eventual consistency through the reinsertion of the facts from the quiescent state. The drawbacks of soft state are well known: recomputation can be expensive, and if done only periodically, the time to react to failures is a half-period on average. However, soft state is often favored in networking implementations because in a very simple manner it provides eventually correct semantics in the face of reordered messages, node disconnection, and other unpredictable occurrences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">QUERY OPTIMIZATIONS</head><p>We proceed to discuss a set of query optimization opportunities that arise in the declarative networking context. These include applications of traditional Datalog optimizations, as well as new techniques for multi-query optimization, result caching, and cost-based optimizations based on graph statistics. Some of these techniquesin particular the use of traditional Datalog optimizations and cachingwere proposed in our previous work <ref type="bibr" target="#b24">[24]</ref>. We present extensions to our basic techniques, as well as new avenues for optimization.</p><p>Compared to the relatively solid foundation of the previous discussion, our approach here is more speculative: we open up a number of broad issues, and in Section 6 we provide a taste of the potential benefits of most of them via a full-fledged implementation running on a sizable network testbed. However our intention here is not to "close the book" on any of these issues; much as in traditional database query optimization and execution, we expect that our techniques here for declarative networking will lead to significant work in a series of more focused investigations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Traditional Datalog Optimizations</head><p>We first explore the applicability of three traditional Datalog optimization techniques: aggregate selections, magic sets and predicate reordering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Aggregate Selections</head><p>A naïve execution of the shortest-path query computes all possible paths, even those paths that do not contribute to the eventual shortest paths. This inefficiency can be avoided with a query optimization technique known as aggregate selections <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b36">36]</ref>.</p><p>Aggregate selections are useful when the running state of a monotonic AGG function can be used to prune query evaluation. For example, by applying aggregate selections to the shortest-path query, each node only needs to propagate the most current shortest paths for each destination to neighbors. This propagation can be done whenever a shorter path is derived. A potential problem with this approach is that the propagation of new shortest paths may be unnecessarily aggressive, resulting in wasted communication. As an enhancement, in the periodic aggregate selections scheme, a node buffers up new paths received from neighbors, recomputes any new shortest paths incrementally, and then propagates the new shortest paths periodically. The periodic technique has the potential for reducing network bandwidth consumption, at the expense of increasing convergence time. It is useful for queries whose input tuples tend to arrive over the network out of order in terms of the monotonic aggregate -e.g., computing "shortest" paths for metrics that are not correlated with the network delays that dictate the arrival of the tuples during execution.</p><p>In addition, aggregate selections are necessary for the termination of some queries, as alluded to previously in Section 2. For example, with aggregate selections, even if paths with cycles are permitted, the shortest-path query will terminate, avoiding cyclic paths of increasing lengths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Magic Sets and Predicate Reordering</head><p>The shortest-path query in our example computes all-pairs shortest paths. This leads to unnecessary overhead when only a subset of paths limited by sources and/or destinations is queried. This problem can be alleviated by applying two optimization techniques: magic-sets rewriting and predicate reordering. Magic-Sets Rewriting: To limit query computation to the relevant portion of the network, we use a query rewrite technique, called magic sets rewriting <ref type="bibr" target="#b5">[5]</ref>. The Magic Sets method is closely related to methods such as Alexander <ref type="bibr" target="#b30">[30]</ref> and QSQ <ref type="bibr" target="#b22">[22]</ref>. Rather than review Magic Sets here, we illustrate its use in an example: by modifying SP1 from the shortest-path query, the following computes only paths limited to destinations in the magicDst table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>#include(SP2,SP3,SP4)</head><p>SP1-D: path(@S,@D,@D,P,C) :-magicDst(@D),#link(@S,@D,C), . P = f concatPath(link(@S,@D,C), nil). Query: shortestPath(@S,@D,P,C).</p><p>Rule SP1-D initializes 1-hop paths for destinations whose magicDst(@D) is present in the magicDst table. This ensures that rule SP2 only propagates paths to selected destinations based on the magicDst table. The shortest paths are then computed as before using rules SP3 and SP4. Predicate Reordering: The use of magic sets in the previous query is not useful for pruning paths from sources. This is because paths are derived in a "Bottom-Up" (BU) fashion starting from destination nodes, where the derived paths are shipped "backwards" along neighbor links from destinations to sources. Interestingly, switching the search strategy can be done simply by reordering the path and #link predicates. This has the effect of turning SP2 from a right-recursive to a left-recursive rule. Together with the use of magic sets, the following magic-shortest-path query allows filtering on both sources and destinations: SP1-SD: pathDst(@D,@S,@D,P,C) :-magicSrc(@S), #link (@S,@D,C), . P = f concatPath(link(@S,@D,C), nil). SP2-SD: pathDst(@D,@S,@Z,P,C) :-pathDst(@Z,@S,@Z 1 ,P 1 ,C 1 ), .</p><p>#link (@Z,@D,C 2 ), C := C 1 + C 2 , . P = f concatPath(P 1 ,link(@Z,@D,C 2 )). SP3-SD: spCost(@D,@S,min&lt;C&gt;) :-magicDst(@D), .</p><p>pathDst(@D,@S,@Z,P,C). SP4-SD: shortestPath(@D,@S,P,C) :-spCost(@D,@S,C), .</p><p>pathDst(@D,@S,@Z,P,C).</p><p>The query computes 1-hop paths starting from each magicSrc using rule SP1-SD. Rule SP2-SD then recursively computes new paths by following all reachable links, and stores these paths as pathDst( dst, src, prevHop, pathVector, cost) tuples at each destination. Rules SP3-SD and SP4-SD then filter relevant paths based on magicDst, and compute the shortest paths, which can then be propagated along the shortest paths back to the source node. In fact, executing the query in this "Top-Down" (TD) fashion resembles a network protocol called dynamic source routing <ref type="bibr" target="#b20">[20]</ref> which is proposed for ad-hoc wireless environments, where the high rate of change in the network makes such targeted path discovery more efficient compared to computing all-pairs shortest paths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Multi-Query Optimizations</head><p>In a distributed setting, it is likely that many related queries will be concurrently executed independently by different nodes. A key requirement for scalability is the ability to share common query computations (e.g., pairwise shortest paths) among a potentially large number of queries. We outline two basic strategies for multi-query sharing in this environment: query-result caching and opportunistic message sharing. Query-Result Caching. Consider the magic-shortest-path query where node a computes shortestPath( <ref type="figure">a,</ref><ref type="figure">d,</ref><ref type="figure">[a,</ref><ref type="figure">b,</ref><ref type="figure">d],</ref><ref type="figure" target="#fig_7">6</ref>) to node d. This cached value can be reused by all queries for destination d that pass through a, e.g., the path from e to d. Currently, our implementation generates the cache internally, building a cache of all the query results (in this case shortestPath tuples) as they are sent back on the reverse path to the source node. Since the subpaths of shortest paths are optimal, these can also be cached as an enhancement. As ongoing work, we are exploring techniques for declaratively specifying the cache, and evaluating caching policies. Opportunistic Message Sharing. In the previous example, we consider how different nodes (src/dst) can share their work in running the same query logic with different constants. Sharing across different queries is a more difficult problem, since it is non-trivial to detect query containment in general <ref type="bibr">[9]</ref>. However, we observe that in many cases, there can be correlation in the message patterns even for different queries. One example arises when different queries request "shortest" paths based on different metrics, such as latency, reliability and bandwidth; path tuples being propagated for these separate queries may be identical modulo the metric attribute being optimized.</p><p>A strategy that we have implemented is opportunistic message sharing, where multiple outgoing tuples that share common attribute values are essentially joined into one tuple if they are outbound to the same destination and share several common attributes; they can be re-partitioned at the receiving end. This achieves the effects of jointly rewriting the queries in a fashion, but on an opportunistic basis: derivations are done in this combined fashion only in cases that are spatiotemporally convenient during processing. In order to improve the odds of achieving this sharing, outbound tuples may be buffered for a time and combined in batch before being sent.</p><p>As an alternative to this opportunistic sharing at the network level, one can achieve explicit sharing at a logical level, e.g., using correlated aggregate selections for pruning different paths based on a combination of metrics. For example, consider running two queries: one that computes shortest latency paths, and another that computes max-bandwidth paths. We can rewrite these as a single query by checking two aggregate selections, i.e., only prune paths that satisfy both aggregate selections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Cost-Based Rewrites</head><p>Currently, queries are executed using a left-(BU) or right-recursive (TD) query expression (Section 5.1.2). Our main goal during query execution is network efficiency (i.e., reducing the burden on the underlying network), which, typically, also implies faster query convergence. It is not difficult to see that neither BU nor TD execution is universally superior under different network/query settings. Even in the simple case of a shortest-path discovery query shortestPath(@S, @D, P,C) between two given nodes (@S, @D), minimizing message overhead implies that our query processor should prefer a strategy that restricts execution to "sparser" regions of the network (e.g., doing a TD exploration from a sparsely-connected source @S).</p><p>We argue that cost-based query optimization techniques are needed to guarantee effective query execution plans. While such techniques have long been studied in the context of relational database systems, optimizing distributed recursive queries for network efficiency raises several novel challenges that we are exploring in our ongoing work. In the remainder of this section, we briefly discuss some of our preliminary ideas in this area and their ties with work in network protocols. The Neighborhood Function Statistic. As with traditional query optimization, cost-based techniques must rely on appropriate statistics for the underlying execution environment that can drive the optimizer's choices. One such key statistic for network efficiency is the local neighborhood function N(). Formally, N(X, r) is the number of distinct network nodes within r hops of node X. The neighborhood function is a natural generalization of the size of the transitive closure (i.e., reachability set) of a node, that can be estimated locally (e.g., through other recursive queries running in the background/periodically). N(X, r) can also be efficiently approximated through approximate-counting techniques using small (logsize) messages <ref type="bibr" target="#b31">[31]</ref>. To see the relevance of N() for our queryoptimization problem, consider our example shortestPath(@s, @d, P, C) query, and let dist(s, d) denote the distance of s, d in the network. A TD search would explore the network starting from node s, and (modulo network batching) result in a total of N(s, dist(s, d)) messages (since it reaches all nodes within a radius of dist(s, d) from s). Note that each node only forwards the query message once, even though it may receive it along multiple paths. Similarly, the cost for a BU query execution is N(d, dist(s, d)). However, neither of these strategies is necessarily optimal in terms of message cost. The optimal strategy is actually a hybrid scheme that "splits" the search radius dist(s, d) between s and d to minimize the overall messages; that is, it first finds r s and r d such that:</p><p>(r s , r d ) = arg min</p><formula xml:id="formula_3">r s +r d =dist(s,d) { N(s, r s ) + N(d, r d ) },</formula><p>and then runs concurrent TD and BU searches from nodes s and d (with radii r s and r d , respectively). At the end of this process, both the TD and the BU search have intersected in at least one network node, which can easily assemble the shortest (s, d) path. The above search strategy can be easily implemented as a rewrite using simple NDlog rules. While the above optimization problem is trivially solvable in O(dist(s, d)) time, generalizing this hybrid-rewrite scheme to the case of multiple sources and destinations raises difficult algorithmic challenges. And, of course, adapting such cost-based optimization algorithms to work in the distributed, dynamic setting poses systems challenges. Finally, note that neighborhood-function information can also provide a valuable indicator for the utility of a node as a result cache (Section 5.2) during query processing.</p><p>Adaptive Network Routing Protocols. While we do not evaluate the above concepts in our experiments below, we note that the networking literature has considered adaptive routing protocols that strongly resemble our use of hybrid rewrites; hence, we believe this is an important area for future investigation and generalization. One interesting example is the class of Zone-Routing Protocols (ZRP) <ref type="bibr" target="#b16">[16]</ref>. A ZRP algorithm works by each node precomputing k-hop-radius shortest paths to neighboring nodes (in its "zone") using a BU strategy. Then, a shortest-path route from a source to destination is computed in a TD fashion, using essentially the magic-shortest-path query described above, utilizing any precomputed shortest paths along the way. Each node sets its zone radius k adaptively based on the density and rate of change of links in its neighborhood; in fact, recent work <ref type="bibr" target="#b29">[29]</ref> on adjusting the zone radius for ZRP-like routing uses exactly the neighborhood-function statistic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPERIMENTS</head><p>We have prototyped our language, execution model, and some of our optimizations as modifications to the P2 system. Our prototype takes as input NDlog programs, performs rule localization, and generates a dataflow graph consisting of P2 elements. Each element is a node in the dataflow graph, and performs tasks such as queuing, network processing and traditional relational operations like joins and aggregations.</p><p>The generated execution plan is structurally similar to Figure <ref type="figure" target="#fig_6">5</ref>, where there are rule strands comprising chains of elements. Each rule strand takes as input a queue, corresponding to new tuples for each strand. Our current implementation uses the PSN algorithm at the tuple granularity. A new tuple is dequeued and processed by the rule strand to generate new tuples which are then enqueued at the same node or sent as a network message for further processing at another node.</p><p>Beyond validating our language and implementation, the main goal of our evaluation is to verify the effectiveness of several of the proposed optimizations. In evaluating our system, the main metrics that we use are: Convergence time: The time taken for the query execution to generate all the query results. Communication overhead: The number of bytes transferred for each query. We consider both aggregate communication overhead (MB), as well as per-node bandwidth (kBps).</p><p>In summary, we find: 1. The aggregate selections optimization reduces communication overhead. Using periodic aggregate selections reduces this overhead further. 2. The use of magic sets and predicate reordering reduces communication overhead when only a limited number of paths are queried. 3. Multi-query sharing techniques such as query result caching and opportunistic result caching demonstrate the potential to reduce communication overhead when there are several concurrent queries. 4. On a network with bursty updates, incremental query evaluation techniques can recompute paths at a fraction of the cost of recomputing the queries from scratch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Setup</head><p>Our experiments are conducted by running our modified P2 on 100 nodes on the Emulab <ref type="bibr" target="#b10">[10]</ref> testbed. This testbed emulates realistic latency and bandwidth constraints seen on the Internet, yet provides repeatable experiments under a controlled environment. As input to the Emulab testbed, we use transit-stub topologies generated using GT-ITM <ref type="bibr" target="#b1">[1]</ref>, a package that is widely used to model Internet topologies. Our topology has four transit nodes, eight nodes per stub and three stubs per transit node. Latency between transit nodes is 50 ms, latency between transit nodes and their stub nodes is 10 ms, and latency between any two nodes in the same stub is 2 ms. The link capacity is set to 10 Mbps.</p><p>We construct an overlay network over the base GT-ITM topology where each node is assigned to one of the stub nodes. Each overlay node runs P2 on one Emulab machine, and picks four randomly selected neighbors. Each node has four link tuples, one for each neighbor. Each link tuple has metrics that include latency (based on the underlying GT-ITM topology), reliability (link loss correlated with latency), and a randomly generated value.</p><p>We base our workload primarily on routing protocols <ref type="bibr" target="#b24">[24]</ref>, and benchmark four variants of the same shortest-path query, differing in the link metric each seeks to minimize. On all our graphs, we label these queries by their link metric: Hop-Count, Latency, Reliability and Random, respectively. Note that Random serves as our stress case: we expect it to have the worst performance among all queries, because aggregate selections are less likely to be effective when the aggregate metric is uncorrelated with the network latency, which determines tuple arrival order during query execution.   We first investigate the effectiveness of aggregate selections for different queries. Figure <ref type="figure" target="#fig_9">7</ref> shows the per-node bandwidth usage against time for the four queries. Figure <ref type="figure" target="#fig_10">8</ref> shows the percentage of eventual best paths completed against time. Our results show that Hop-Count converges the most quickly in 4.4 seconds, followed by Latency and Reliability in 4.9 seconds and 4.8 seconds respectively. Random has the worst convergence time of 5.8 seconds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Aggregate Selections</head><p>During query execution, the communication overhead incurred by all four queries shows a similar trend (Figure <ref type="figure" target="#fig_9">7</ref>). Initially, the communication overhead increases as more and more paths (of increasing length) are derived. After it peaks at around 19kBps per-node, the communication overhead decreases, as fewer and fewer optimal paths are left to be derived. In terms of aggregate communication overhead, Random incurs the most overhead (4.1 MB), while Hop-Count, Latency and Reliability use 2.6 MB, 3.1 MB and 3.2 MB, respectively. The relatively poor performance of Random is due to the lack of correlation between the metric and network latency, leading to a greater tendency for out-of-order arrival of path tuples that results in less effective use of aggregate selections. The results in Figures 9 and 10 illustrate the effectiveness of the periodic aggregate selections approach, as described in Section 5.1.1. In particular, this approach reduces the bandwidth usage of Hop-Count, Latency, Reliability and Random by 17%, 12%, 16% and 29%, respectively. Random not only shows the greatest reduction in communication overhead, its convergence time also reduces from 5.8 seconds to 5 seconds.  Next, we study the effectiveness of combining the use of magic sets and predicate reordering for lowering communication overhead when the queries are constrained by randomly chosen sources and destinations. Our workload consists of queries that request sourceto-destination paths based on the Hop-Count metric. For each query, we execute the magic-shortest-path query (Section 5.1.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Magic Sets and Predicate Reordering</head><p>Figure <ref type="figure" target="#fig_12">11</ref> shows the aggregate communication overhead as the number of queries increases. The No-MS line represents our baseline, and shows the communication overhead in the absence of rewrites (this essentially reduces to computing all-pairs least-hop-count). The MS line shows the communication overhead when running the optimized query with no sharing across queries. When there are few queries, the communication overhead of MS is significantly lower than that of NO-MS. As the number of queries increases, the communication overhead of MS increases linearly, exceeding No-MS after 170 queries.</p><p>In addition, Figure <ref type="figure" target="#fig_12">11</ref> also illustrates the effectiveness of caching (Section 5.2). The MSC line shows the aggregate communication overhead for magic sets with caching. For fewer than 170 queries, there is some overhead associated with caching. This is due to false positive cache hits, where a cache result does not contribute to computing shortest paths. However, as the number of queries increases, the overall cache hit rate improves, resulting in a dramatic reduction of bandwidth. When limiting the choice of destination nodes to 30% (MSC-30%) and 10% (MSC-10%), the communication overhead levels of at 1.8 MB, and 1 MB, respectively. The smaller the set of requested destinations, the higher the cache hit rate, and the greater the opportunity for sharing across different queries. These results are consistent with the results obtained by Loo et al. <ref type="bibr" target="#b24">[24]</ref> in a similar experiment, using the PIER <ref type="bibr" target="#b17">[17]</ref> simulator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Opportunistic Message Sharing</head><p>We study the impact of performing opportunistic message sharing across concurrent queries that have some correlation in the messages being sent. Figure <ref type="figure" target="#fig_13">12</ref> shows per-node bandwidth usage for running the queries on different metrics concurrently. To facilitate sharing, we delay each outbound tuple by 300ms in anticipation of possible sharing opportunities. The Latency, Reliability and Random lines show the bandwidth usage of each query individually. The No-Share line shows the total aggregate bandwidth of these three queries without sharing. The Share line shows the aggregate bandwidth usage with sharing. Our results clearly demonstrate the potential effectiveness of message sharing, which reduces the peak of the per-node communication overhead from 27 kBps to 16 kBps, and the total communication overhead by 34%. In our final experiment, we examine the overhead of incrementally maintaining query results in a dynamic network. We run the queries over a period of time, and subject the network to burst updates as described in Section 4. Each update burst involves randomly selecting 10% of all links, and then updating the cost metric by up to 10%. We use the shortest-path random metric since it is the most demanding in terms of bandwidth usage and convergence time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Incremental Query Evaluation</head><p>Figure <ref type="figure" target="#fig_4">13</ref> plots the per-node communication overhead, when applying a batch of updates every 10 seconds. Two points are worth noting. First, the time it takes the query to converge after a burst of updates is well within the 5 second convergence time of running the query from scratch (Figure <ref type="figure" target="#fig_4">10</ref>). This is reflected in the communication overhead, which increases sharply after a burst of updates is applied, but then disappears long before the next burst of updates (Figure <ref type="figure" target="#fig_4">13</ref>). Second, each burst peaks at 6kBps, which is only 32% of the peak bandwidth and 26% of the aggregate bandwidth of the original computation. Our results clearly demonstrate the usefulness of performing incremental query evaluation in response to changes in the network, as opposed to recomputing the queries from scratch.</p><p>We repeat our experiment on a more demanding update workload (Figure <ref type="figure" target="#fig_5">14</ref>), where we interleave update intervals that are 2 seconds and 8 seconds, the former interval being less than the from-scratch convergence time of 5 seconds. We observe that despite the fact that bursts are sometimes occurring faster than queries can run, bandwidth usage is similar to the less demanding update workload. When the update interval is 2 seconds, we notice periods of sustained bandwidth usage, however the peak usage remains at 6 kBps as before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">ADDITIONAL RELATED WORK</head><p>We mentioned most of the related work in the context of our discussion above. Here, we briefly mention some other related efforts.</p><p>We are not alone in our renewed enthusiasm for applications of recursive queries. There are other contemporary examples from outside the traditional database "market", including software analysis <ref type="bibr" target="#b37">[37]</ref>, trust management <ref type="bibr" target="#b6">[6]</ref> and diagnosis of distributed systems <ref type="bibr" target="#b2">[2]</ref>. Our concept of link-restricted rules is similar in spirit to d3log <ref type="bibr" target="#b19">[19]</ref>, a query language based on Datalog proposed for dynamic site discovery along web topologies.</p><p>Much research in the parallel execution of recursive queries <ref type="bibr" target="#b8">[8]</ref> has focused on high throughput within a cluster. In contrast, our strategies and optimizations are geared towards bandwidth efficiency and fast convergence in a distributed setting. Instead of hash-based partitioning schemes that assume full connectivity among nodes, we are required to perform query execution only along physical network links and deal with network changes during query execution. There is also previous empirical work on the performance of parallel pipelined execution of recursive queries <ref type="bibr" target="#b32">[32]</ref>. Our results extend that work by providing new, provably correct pipelining variants of semi-naïve evaluation.</p><p>In terms of distributed systems, the closest analog is the recent work by Abiteboul et al. <ref type="bibr" target="#b2">[2]</ref>. They adapt the QSQ <ref type="bibr" target="#b22">[22]</ref> technique to a distributed domain in order to diagnose distributed systems. An important limitation of their approach is that they do not consider partitioning of relations across sites as we do; they assume each relation is stored in its entirety in one network location. Further, they assume full connectivity and do not consider updates concurrent with query processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSION</head><p>Our goal in this paper was twofold: to provide a solid database foundation for recent developments in declarative networking, and to open a number of database research directions in the area. We believe that our contributions here are significant on both fronts.</p><p>We started with the concept of link-restricted rules, which capture syntactically in NDlog the notion that query messages are constrained to travel along direct links between nodes in a network. This in turn led to successive refinements of semi-naïve evaluation that deal efficiently with the asynchrony and delays intrinsic to a widearea networking environment. We introduced techniques to incorporate updates immediately during execution, capturing the reactive nature of typical network protocols while offering meaningful semantic guarantees. We also discussed a number of query optimization techniques, and their applicability to the networking domain. Finally, we presented evaluation results from a distributed deployment involving 100 machines on the Emulab <ref type="bibr" target="#b10">[10]</ref> network testbed, running prototypes of our optimization techniques implemented as modifications to the P2 system.</p><p>Our ongoing research is proceeding in several directions. First, we are exploring a complete query optimization architecture, as well as specific techniques beyond those of Section 5: additions to the cost-based optimizations of Section 5.3 including the possibility of using random walks driven by statistics on graph expansion; adaptive query processing techniques to react to network dynamism; and multi-query optimizations motivated by more complex overlay networks. Second, we plan to incorporate negation into our model and implementation <ref type="bibr" target="#b18">[18]</ref>, which raises interesting challenges for pipelining and dynamic data. Third, a key selling point of declarative languages in the networking community is the promise of static program checks for desirable network protocol properties; we are considering techniques from the Datalog literature in this regard (e.g., <ref type="bibr" target="#b21">[21]</ref>) and expect that the particulars of link-restricted rules can be of use as well. Finally, we intend to aggressively pursue these ideas in the context of serious networking applications, e.g., overlay networks like distributed hash tables, application-level multicast protocols, and virtual private networks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>R1:</head><label></label><figDesc>path(S,D,D,P,C) :-link(S,D,C), P = f concatPath(link(S,D,C), nil). R2: path(S,D,Z,P,C) :-link(S,Z,C 1 ), path(Z,D,Z 2 ,P 2 ,C 2 ), . C = C 1 + C 2 , P = f concatPath(link(S,Z,C 1 ),P 2 ). R3: spCost(S,D,min&lt;C&gt;) :-path(S,D,Z,P,C). R4: shortestPath(S,D,P,C) :-spCost(S,D,C), path(S,D,Z,P,C). Query: shortestPath(S,D,P,C).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Shortest-Path Query in NDlog .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Nodes in the network are running the shortest-path query. We</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>j:-p old 1 ,</head><label>1</label><figDesc>..., p old k-1 , p old k ,p k+1 ,...,p n , b 1 , b 2 , ..., b m ; 2 p 1 , ..., p n are recursive predicates and b 1 , ...b m are base predicates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Logical Query Plan for rule SP2 from Section 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Rule strands for the distributed version of SP2 after localization in P2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Derivation tree for derived path tuple from a to e. The left diagram shows updating the tree due to a change in base tuple #link(a, b, 5), and the right diagram shows the deletion of #link(b, e, 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Per-node Bandwidth (kBps).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Query results over time (seconds).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 :Figure 10 :</head><label>910</label><figDesc>Figure 9: Per-node Bandwidth (kBps).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Aggregate communication overhead (MB) with and without magic sets and caching.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Per-node Bandwidth (kBps) for message sharing (300 ms delay).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 13 :Figure 14 :</head><label>1314</label><figDesc>Figure 13: Per-node Bandwidth (kBps) for periodic link updates on latency metric (10s update interval).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Rule strand for rule SP2-1 in P2. Output paths that are generated from the strand are "wrapped back" as input into the same strand.</head><label></label><figDesc></figDesc><table><row><cell>Input paths</cell><cell>path</cell><cell>path old</cell><cell>Buffer</cell><cell>path old</cell><cell>SP2-1</cell><cell>Join path old .Z=link.Z</cell><cell>Project path new</cell><cell>Output paths</cell></row></table><note><p><p><p><p>2 </p>These rules are logically equivalent to rules of the form p new j :p 1 , p 2 ,...,p k-1 , p old k ,p k+1 ,...,p n , b 1 , b 2 , ..., b m , and have the advantage of avoiding redundant inferences within each iteration.</p>link</p>Figure 3:</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In practice, some networks may not have symmetric links. Our framework can be extended to handle this, but generalizing the discussion in that manner complicates our presentation and is out of the scope of this paper.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We have been pleased in this work to see that the enthusiasm in the networking community for declarative languages can provide more than just a well-motivated application area for recursive queries; it appears to spark a host of new database research challenges in what was considered a very mature area. We are optimistic about the potential for additional significant results in this domain, in terms both of theoretical work and systems challenges.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. PROOFS FOR PIPELINED SEMI-NA ÏVE</head><p>For the purposes of the proof of Theorem 1, we assume that there is a unique derivation for each tuple t. </p><p>∈ p old k in the i th iteration of the SN algorithm. This will result in the rule being used to generate t in the i th iteration. Hence, t i ∈ FP i S . If there are multiple derivations for the same tuple, we can apply the same proof above for Theorem 1 using the following modified PSN: if there are two derivations t i and t j ( j &gt; i) for the same tuple, the modified PSN algorithm guarantees that t i is generated by enqueuing t i even if t j was previously generated. Note that the modified PSN algorithm leads to repeated inferences, but generates the same results as PSN.</p><p>Theorem 2 There are no repeated inferences in computing FP P (p).</p><p>Proof: For linear rules, the theorem is trivially true since we only add a new derived tuple into the PSN queue if it does not exist previously. This guarantees that each invocation of the rule is unique For non-linear rules, we continue from Theorem 1's proof. Let ts(t) be the sequence number or timestamp of derived tuple t. Following the proof for Lemma 1, only the k th rule, where ts(t i-1 k ) = max(ts(t i-1 1 ),ts(t i-1 2 ), ...,ts(t i-1 n )) will be used to generate t i 0 at the inductive step, ensuring no repeated inferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. PROOFS FOR BURSTY UPDATES</head><p>Let E be the set of all extensional tuples that appear during the execution of a program. Let D be the set of all tuples that can be derived from E (we assume E ⊆ D for simplicity). A tuple t ∈ D derived by the rule t:-t 1 ,t 2 , ...,t n has a corresponding tree fragment, with parent t and children t j . The derivation tree for D is built by assembling the tree fragments for all possible derivations of tuples in D. We distinguish the multiple tree fragments for multiple derivations of t, but to simplify notation, we use t,t 1 , . . . to name tree nodes. Leaves of this tree are elements of E. A series of insertions and deletions to the extensional relations is modeled as a sequence of values t(0), . . . ,t( j) for each t ∈ E, where 1 means present and 0 means absent. Similarly, for all tree nodes t, we remember the sequence of values (presence or absence) assigned to t by the PSN algorithm after each child change. We write t(∞) to represent the value of t once the network has quiesced.</p><p>Let t be a tree node whose children are t 1 ,t 2 , ...,t n .</p><p>Claim 3 Along any tree edge t k → t, value changes are applied in the order in which t k 's change. This property is guaranteed by PSN's FIFO queue.</p><p>Lemma 3 t(∞) is derived using t 1 (∞), . . . ,t n (∞).</p><p>Proof: (By induction) t(0) is computed from the initial values of its children. Assume inductively that t( j -1) is derived based on the ( j -1) th change in its children. If child t k changes, t( j) is rederived, and based on Claim 3, reflects the latest value of t k . Hence, t(∞) is derived from the last value of all its children. Let FP p be the set of tuples derived using PSN under the bursty model, and FFP p be the set of tuples that would be computed by PSN if starting from the quiesced state. Theorem 3 FP p = FFP p in a centralized setting.</p><p>Proof: We write t(ω) for the values derived by PSN when its starting state is e(∞) for e ∈ E. If ∀t ∈ D's derivation tree, t(ω) = t(∞) then FP p = FFP p . We prove this by induction on the height of tuples in the derivation tree. We define D i to be all nodes of D's derivation tree at height i, with D 0 = E.</p><p>In the base case, ∀t ∈ D 0 , t(∞) = t(ω) by definition of the base tuple values. In the inductive step, we assume that ∀ j &lt; i, ∀t ∈ D j , t(∞) = t(ω). Consider t ∈ D i . Based on Lemma 3, t(∞) will be derived from the t k (∞) values of its children, which by induction are equal to t k (ω). Hence t(∞) = t(ω).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Claim 4</head><p>As long as all network links obey FIFO for transmitted messages, Claim 3 is true for any children of t that are generated using link-restricted Datalog rules. Theorem 4 FP p = FFP p in a distributed setting.</p><p>Proof: With Claim 4, the proof is similar to that of Theorem 3.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gt-Itm</surname></persName>
		</author>
		<ptr target="http://www.cc.gatech.edu/projects/gtitm/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Abiteboul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Abrams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Haar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Milo</surname></persName>
		</author>
		<title level="m">Diagnosis of Asynchronous Discrete Event Systems -Datalog to the Rescue! In ACM PODS</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Generalization of the Differential Approach to Recursive Query Evaluation</title>
		<author>
			<persName><forename type="first">I</forename><surname>Balbin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamohanarao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Logic Prog</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="259" to="262" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Naive Evaluation of Recursively Defined Relations</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bancilhon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">On Knowledge Base Management Systems: Integrating AI and DB Technologies</title>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Magic Sets and Other Strange Ways to Implement Logic Programs</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bancilhon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sagiv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Cassandra: Distributed Access Control Policies with Tunable Expressiveness</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sewell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Dayal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Dewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gawlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Lockemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Neuhold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Reuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Rowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Schek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schrefl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Directions in DBMS Research. SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="26" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A survey of parallel execution strategies for transitive closure and logic programs. Distributed and Parallel Databases</title>
		<author>
			<persName><forename type="first">F</forename><surname>Cacace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ceri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A W</forename><surname>Houtsma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="337" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Decidable Containment of Recursive Queries</title>
		<author>
			<persName><forename type="first">D</forename><surname>Calvanese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Giacomo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Vardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDT</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<ptr target="http://www.emulab.net" />
		<title level="m">Emulab</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Correctness properties for Internet routing</title>
		<author>
			<persName><forename type="first">N</forename><surname>Feamster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Allerton Conference on Communication, Control, and Computing</title>
		<imprint>
			<date type="published" when="2005-09">Sept. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pushing Extrema Aggregates to Optimize Logic Queries</title>
		<author>
			<persName><forename type="first">F</forename><surname>Furfaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganguly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zaniolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf.Sys</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="321" to="343" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Overcoming barriers to disruptive innovation in networking</title>
		<imprint>
			<date type="published" when="2005-01">Jan. 2005</date>
		</imprint>
		<respStmt>
			<orgName>NSF Workshop</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Report of</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Encapsulation of Parallelism in the Volcano Query Processing System</title>
		<author>
			<persName><forename type="first">G</forename><surname>Graefe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Maintaining Views Incrementally</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Mumick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Subrahmanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A New Routing Protocol for the Reconfigurable Wireless Networks</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Haas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. on Universal Personal Communications</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Architecture of PIER: an Internet-Scale Query Processor</title>
		<author>
			<persName><forename type="first">R</forename><surname>Huebsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Loo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maniatis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roscoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Yumerefendi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Assigning an Appropriate Meaning to Database Logic with Negation</title>
		<author>
			<persName><forename type="first">Jeffery</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computers as Our Better Partners</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="216" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dynamically Distributed Query Evaluation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dynamic Source Routing in Ad Hoc Wireless Networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Maltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mobile Computing</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">353</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Framework for Testing Safety and Effective Computability</title>
		<author>
			<persName><forename type="first">R</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shmueli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comp. Sys. Sci</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="100" to="124" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Recursive Axioms in Deductive Database: The Query-Subquery Approach</title>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Vieille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1st International Conference on Expert Database Systems</title>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Implementing Declarative Overlays</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Loo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Condie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maniatis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roscoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">20th ACM Symposium on Operating Systems Principles (SOSP)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Declarative Routing: Extensible Routing with Declarative Queries</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Loo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Computer Networks: A Systems Approach</title>
		<author>
			<persName><forename type="first">L</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Davie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Morgan-KaufMann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Overcoming the Internet Impasse Through Virtualization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HotNets-III</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Efficient Incremental Evaluation of Queries with Aggregation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sudarshan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Survey of Research on Deductive Database Systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Logic Programming</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="149" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">SHARP: A Hybrid Adaptive Routing Protocol for Mobile Ad Hoc Networks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ramasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Sirer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MobiHoc</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Alexander Method -A Technique for the Processing of Recursive Axioms in Deductive Databases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rohmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lescoeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kerisit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Generation Computing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="522" to="528" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">ANF: A Fast and Scalable Tool for Data Mining in Massive Graphs</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="102" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An Experimental Performance Study of a pipelined recursive query processing strategy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E C</forename><surname>Hull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Databases for Parallel and Distributed Systems</title>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Distributed Monitoring and Forensics in Overlay Networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maniatis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roscoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Druschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurosys</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Chord: A scalable peer-to-peer lookup service for internet applications</title>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Karger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Kaashoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<title level="m">Readings in Database Systems, Third Edition</title>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Aggregation and Relevance in Deductive Databases</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sudarshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Cloning-Based Context-Sensitive Pointer Alias Analysis Using Binary Decision Diagrams</title>
		<author>
			<persName><forename type="first">J</forename><surname>Whaley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
