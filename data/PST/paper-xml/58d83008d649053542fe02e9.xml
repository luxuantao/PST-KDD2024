<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The 2016 Signal Separation Evaluation Campaign</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Antoine</forename><surname>Liutkus</surname></persName>
							<email>antoine.liutkus@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="department">Speech Processing Team</orgName>
								<orgName type="institution">Inria</orgName>
								<address>
									<settlement>Villers-lès-Nancy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff8">
								<orgName type="laboratory" key="lab1">CNRS/TIMC-IMAG</orgName>
								<orgName type="laboratory" key="lab2">UMR 5525</orgName>
								<address>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabian-Robert</forename><surname>Stöter</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">International Audio Laboratories Erlangen</orgName>
								<address>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zafar</forename><surname>Rafii</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Gracenote, Applied Research</orgName>
								<address>
									<settlement>Emeryville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daichi</forename><surname>Kitamura</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">SOKENDAI</orgName>
								<orgName type="institution" key="instit2">The Graduate University for Advanced Studies)</orgName>
								<address>
									<settlement>Kanagawa</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bertrand</forename><surname>Rivet</surname></persName>
							<affiliation key="aff4">
								<orgName type="laboratory">GIPSA-lab</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit3">Grenoble INP</orgName>
								<address>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nobutaka</forename><surname>Ito</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">NTT Communication Science Laboratories</orgName>
								<orgName type="institution" key="instit2">NTT Corporation</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nobutaka</forename><surname>Ono</surname></persName>
							<affiliation key="aff6">
								<orgName type="institution">National Institute of Informatics</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Julie</forename><surname>Fontecave</surname></persName>
							<affiliation key="aff7">
								<orgName type="institution">UJF-Grenoble</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The 2016 Signal Separation Evaluation Campaign</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CA7F5EB1152E4A13B30AEBD0A60A9ACD</idno>
					<idno type="DOI">10.1007/978-3-319-53547-0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we report the results of the 2016 communitybased Signal Separation Evaluation Campaign (SiSEC 2016). This edition comprises four tasks. Three focus on the separation of speech and music audio recordings, while one concerns biomedical signals. We summarize these tasks and the performance of the submitted systems, as well as provide a small discussion concerning future trends of SiSEC.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Evaluating source separation algorithms is a challenging topic on its own, as well as finding appropriate datasets on which to train and evaluate various separation systems. In this respect, the Signal Separation Evaluation Campaign (SiSEC) has played an important role. SiSEC was held about every year-and-half since 2008, in conjunction with the LVA/ICA conference. Its purpose is two-fold.</p><p>The primary objective of SiSEC is to regularly report the progress of the source separation community, in order to serve as a reference for a comparison of as many methods as possible on the topic of source separation. This involves adapting both the evaluations and the metrics to current trends in the field.</p><p>The second important objective of SiSEC is then to provide data the community can use for the design and evaluation of new methods, even outside the scope of the campaign itself. These efforts lead to a significant, although moderate, impact of SiSEC in the community as depicted on Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>For the objective evaluation of source separation, two options are now widely accepted and used for SiSEC'2016. First, the BSS Eval toolbox <ref type="bibr" target="#b2">[3]</ref> features the signal to distortion ratio (SDR), the source image to spatial distortion ratio (ISR), the signal to interference ratio (SIR), and signal to artifacts ratio (SAR) metrics. All are given in dB and are better with better separation. Second, the PEASS toolbox <ref type="bibr" target="#b3">[4]</ref> was used in some tasks for providing four perceptually-motivated criteria: the overall perceptual score (OPS), the target-related perceptual score (TPS), the interference-related perceptual score (IPS), and the artifact-related perceptual score (APS).</p><p>This sixth SiSEC features the same UND and BGN tasks as proposed last year and summarized in Sects. 2 and 3, respectively. The BIO task presented in Sect. 4 is new. Finally, the MUS task presented in Sect. 5 features new data and accompanying software.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">UND: Underdetermined-Speech and Music Mixtures</head><p>The datasets for the UND task are the same as those described in detail in <ref type="bibr" target="#b0">[1]</ref>. The results presented here include those found in previous editions, as well as a new contribution <ref type="bibr" target="#b13">[14]</ref>, that utilizes both generalized cross correlation (GCC, <ref type="bibr" target="#b20">[21]</ref>) and nonnegative matrix factorization (NMF, <ref type="bibr" target="#b21">[22]</ref>). GCC was used previously for sound source localization in reverberant environments <ref type="bibr" target="#b22">[23]</ref>. NMF is a well-known mathematical framework for many applications, especially in the source separation task. For the acoustic signals, NMF can extract some spectral patterns (bases) and their activations (time-varying gains), and the source separation is achieved by clustering the bases into each source. Wood et al. combined GCC with NMF to localize individual bases over time, such that they may be attributed to individual sources. Computations of Wood's algorithm were between 6 and 7 min per mixture on a dual 2.8 GHz Intel Xeon E5462 quad-core processor with 16 GB of RAM.</p><p>From the comparison of the results on Table <ref type="table" target="#tab_0">1</ref>, Wood's algorithm could not outperform the best ever performance on this dataset. Other results for microphone spacings of 5 cm and 1 m with reverberation times of 130 ms and 250 ms may be found on the SiSEC 2016 website<ref type="foot" target="#foot_0">1</ref> . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BGN: Two-Channel Mixtures of Speech and Real-World Background Noise</head><p>Just like for the UND task, we proposed the same dataset for the task 'twochannel mixtures of speech and real-world background noise (BGN)' as in SiSEC 2013 <ref type="bibr" target="#b0">[1]</ref>. Three algorithms were submitted to the BGN task this year, as shown in Table <ref type="table" target="#tab_1">2</ref>. Duong's method <ref type="bibr" target="#b23">[24]</ref> is based on NMF with pre-trained speech and noise spectral dictionaries. Liu's method performs Time Difference of Arrival (TDOA) clustering based on GCC-PHAT. Wood's method <ref type="bibr" target="#b13">[14]</ref> first applies NMF to the magnitude spectrograms of the mixture signals with channels concatenated in time. Each dictionary atom is then attributed to either the speech or the noise according to its spatial origin.</p><p>Considering the results in Table <ref type="table" target="#tab_1">2</ref>, we can see that all methods present some advantages. Whereas Duong's method <ref type="bibr" target="#b23">[24]</ref> clearly shows a significant superiority on BSS Eval metrics, this is much less clear when analyzing the PEASS perceptual scores. Wood's method <ref type="bibr" target="#b13">[14]</ref> indeed gives the best OPS and IPS scores, suggesting a better overall and interference-related perceptual quality of estimates. Now analyzing APS scores, Liu's method consistently gives results with few annoying artifacts. From all these facts and contradictions, we see the limitations of objective metrics and it seems clear that a real perceptual evaluation would be needed to draw further conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">BIO: Separation of Biomedical Signals</head><p>Phonocardiography (PCG) is the recording of the sounds generated by the heart. It allows to evaluate some vital functions of the heart. However, the raw recordings of the PCG are not always directly exploitable because of ambient interference (e.g., speech, cough, gastric noise, etc.). Consequently, it is necessary to denoise the raw PCG before their interpretation. An example of clean PCG is plotted on Fig. <ref type="figure" target="#fig_1">2</ref>. The aim of this challenge is to extract the heart activity from raw PCG recordings with a single microphone maintained by a belt on the skin, in front of the heart. 16 sessions have been recorded from 3 healthy participants in different conditions. The quality of the separation process has been evaluated by the BSS Eval toolbox. The SDR, SIR and SAR indexes were computed on sliding windows of 1 s with an overlap of 0.5 s. The performance was only retained for the indexes related to the heart sounds.</p><p>Two participants have submitted their results on this specific task:</p><p>-The first participant (Part. 1) proposed a method based on the alignment of Empirical Mode Decomposition (EMD) and Lempel-Ziv complexity measure to extract the denoised signal. -The second participant (Part. 2) proposed method based the decomposition of the signal using an ensemble empirical mode decomposition (EEMD) and the selection of some IMFs to filter the signal. Finally, the estimated signal is post-processed to reject additional peaks based on the characteristics of PCG signals.</p><p>The results achieved by the submitted methods are plotted on Fig. <ref type="figure" target="#fig_2">3</ref> that shows the distribution of SDR, SIR and SAR for the two participants as well as the noisy data. The red line is the median, the edges of the box are the 25th and 75th percentiles, the whiskers extend to the most extreme values and outliers are plotted by a red cross. In term of SIR, i.e., rejection of noise, Part. 2 is slightly better than Part. 1: the average SIR improvements are of 10.4 dB and 9.6 dB, respectively, while the average SIR on the noisy data is -3 dB. On the contrary, the Part. 2's method leads to better results based on SDR and SAR than the Part. 1's one: an average gain in SDR of 5.7 dB and 1.4 dB, and an average SAR of 5.5 dB and 0.5 dB. It is interesting to see that the two participants proposed methods based on empirical mode decomposition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">MUS: Professionally-Produced Music Recordings</head><p>The MUS task attempts at evaluating the performance of music separation methods. In SiSEC 2015 <ref type="bibr" target="#b1">[2]</ref>, a new dataset was introduced for this task, comprising 100 full-track songs of different musical styles and genres, divided into development and test subsets. This year, this dataset was further heavily remastered so that for each track, it now features a set of four semi-professionally engineered stereo source images (bass, drums, vocals, and other), summing up to realistic mixtures. This corpus was called the Demixing Secret Database (DSD100), as a reference to the'Mixing Secrets' Free Multitrack Download Library it was build from<ref type="foot" target="#foot_1">2</ref> . The duration of the songs ranges from 2 min and 22 s to 7 min and 20 s, with an average duration of 4 min and 10 s.</p><p>Additionally, an accompanying software toolbox was developed in Matlab and Python that permits the straightforward processing of the DSD100 dataset. This software is open source and was publicly broadcasted so as to allow the participants to run the evaluation themselves <ref type="foot" target="#foot_2">3</ref> .</p><p>Similarly to the previous SiSEC editions, MUS was the task attracting the most participants, with 24 systems evaluated. Due to page constraints, we may not detail each method, but encourage the interested reader to refer to SiSEC'2016 website and to the references given therein.</p><p>Among the systems evaluated, 10 are blind methods: CHA <ref type="bibr" target="#b4">[5]</ref>, DUR <ref type="bibr" target="#b5">[6]</ref>, KAM <ref type="bibr" target="#b7">[8]</ref>, OZE <ref type="bibr" target="#b9">[10]</ref>, RAF <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref>, HUA <ref type="bibr" target="#b6">[7]</ref>, JEO <ref type="bibr" target="#b27">[28]</ref>. Then, 14 are supervised methods exploiting variants of deep neural networks: GRA <ref type="bibr" target="#b26">[27]</ref>, KON <ref type="bibr" target="#b28">[29]</ref>, UHL <ref type="bibr" target="#b25">[26]</ref>, NUG <ref type="bibr" target="#b8">[9]</ref>, and the methods proposed by F.-R. Stöter (STO), consisting of variants of <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref> with various representations. Finally, the evaluation also features the scores of Ideal Binary Mask (IBM), computed for left and right channels independently. Due to space constraints again, Fig. <ref type="figure">4</ref> shows the box plots for the SDR of the vocals only, over the whole DSD100 dataset and excluding those few 30 s excerpts for which the IBM method was badly behaved (yielding nan values for its SDR). More results may be found online. For the first time in SiSEC, 30 s excerpts of all separated results may also be found in the webpage dedicated to the results<ref type="foot" target="#foot_3">4</ref> . The striking fact is that most proposed supervised systems considerably outperform blind methods, a trend that is also noticeable on other SIR, SAR metrics. Also, systems like <ref type="bibr" target="#b25">[26]</ref> which use additional augmentation data, seem to generalise better, resulting in a smaller gap between Dev and Test.</p><formula xml:id="formula_0">G R A 2 H U A K O N G R A 3 D U R R A F 1 R A F 2 C H A O Z E K A M 2 R A F 3 K A M 1 J E O 1 S T O 2 J E O 2 S T O 1 N U G 3 N U G 4 N U G 2 N U G 1 U H L 1 U H L 2 U H L 3 I B M</formula><p>A Friedman test revealed a significant effect of separation method on SDR (Dev: χ 2 = 1083.23, p &lt; 0.0001, Test: χ 2 = 1004.29, p &lt; 0.0001). Inspired by recent studies <ref type="bibr" target="#b29">[30]</ref>, we also tested for each pair of method whether the difference in performance was significant. A post-hoc pairwise comparison test (Wilcoxon signed-rank test, two-tailed, Bonferroni corrected) is depicted in Fig. <ref type="figure">5</ref>.</p><p>From these pair-wise comparisons, it turns out that state-of-the art music separation systems ought to feature multichannel modelling (introduced in NUG) and data augmentation (UHL). As depicted by the best scores obtained by UHL3, performing a fusion of different systems is also a promising idea.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we reported the different tasks and their results for SiSEC'2016. This edition enjoyed a good participation on the long-run tasks, as well as several novelties. Among those, a new task on biomedical signal processing was proposed this year, as well as important improvements concerning the music separation dataset and accompaniment software.</p><p>In the recent years, we witnessed a very strong increase of interest in supervised methods for separation. A corresponding objective of SiSEC is to make it easier for machine learning practitioners to adapt learning algorithms to the task of source separation, widening the audience of this fascinating topic.</p><p>In the future, we plan to continue in this direction and focus on two important moves for SiSEC: first, the problem of quality assessment appears as largely unsolved and SiSEC should play a role in this respect. Second, facilitating reproducibility and comparison of research is a challenge when methods involve largescale machine learning systems. SiSEC will shortly host and broadcast separation results of various techniques along datasets to promote easy comparison with state of the art.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The number of papers referring to SiSEC. (source: Google Scholar)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Phonocardiography signals</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. BIO tasks, results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig. 4. Results for the SDR of vocals on MUS task for Dev and Test.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Results for the UND task for convolutive mixtures averaged over sources: liverecorded data with 1 m microphone spacing and 250 ms reverberation time in dataset "test"</figDesc><table><row><cell>System</cell><cell cols="4">2mic/3src (female)</cell><cell cols="4">2mic/4src (female)</cell><cell cols="3">2mic/3src (male)</cell><cell></cell><cell cols="2">2mic/4src (male)</cell></row><row><cell></cell><cell cols="14">SDR ISR SIR SAR SDR ISR SIR SAR SDR ISR SIR SAR SDR ISR SIR SAR</cell></row><row><cell></cell><cell cols="14">OPS TPS IPS APS OPS TPS IPS APS OPS TPS IPS APS OPS TPS IPS APS</cell></row><row><cell>Wood [14]</cell><cell>3.2</cell><cell>6.7</cell><cell>4.7</cell><cell>6.8</cell><cell>2.2</cell><cell></cell><cell cols="2">5.0 2.8 4.8</cell><cell>3.1</cell><cell>6.5</cell><cell>4.3</cell><cell>6.6</cell><cell>2.5</cell><cell>5.2 3.1 4.8</cell></row><row><cell cols="2">(SiSEC 2016) 10.6</cell><cell>8.6</cell><cell cols="6">9.0 23.3 27.4 43.7 35.3 47.1</cell><cell>9.7</cell><cell>8.8</cell><cell cols="4">9.9 24.2 29.6 47.9 41.7 44.5</cell></row><row><cell>Nguyen</cell><cell cols="2">6.1 9.9</cell><cell>9.3</cell><cell>9.6</cell><cell>4.0</cell><cell></cell><cell cols="2">7.5 7.1 7.1</cell><cell cols="2">5.9 10.1</cell><cell>9.8</cell><cell>8.2</cell><cell>2.5</cell><cell>5.8 4.1 5.4</cell></row><row><cell cols="15">(SiSEC 2015) 37.1 63.0 48.2 59.0 34.7 60.3 47.6 49.9 40.0 65.8 53.1 53.7 31.8 50.8 43.1 48.0</cell></row><row><cell>Cho [15]</cell><cell>5.5</cell><cell>9.5</cell><cell>8.1</cell><cell>9.4</cell><cell cols="5">4.3 7.8 6.8 7.5 5.5</cell><cell>9.5</cell><cell>8.2</cell><cell cols="2">9.1 3.2</cell><cell>6.6 4.7 6.2</cell></row><row><cell cols="15">(SiSEC 2013) 35.6 62.9 43.4 59.0 33.3 59.0 38.3 52.3 36.0 61.5 44.8 58.7 35.1 57.0 42.8 50.8</cell></row><row><cell>Adiloglu [16]</cell><cell>3.0</cell><cell>7.0</cell><cell>5.5</cell><cell>8.1</cell><cell>0.7</cell><cell></cell><cell cols="2">4.3 0.9 4.8</cell><cell>3.4</cell><cell>7.1</cell><cell>5.8</cell><cell>8.4</cell><cell>1.5</cell><cell>5.0 2.1 5.2</cell></row><row><cell cols="15">(SiSEC 2013) 28.4 53.7 35.2 60.8 29.2 46.4 29.4 53.3 26.4 51.4 31.8 63.0 32.7 52.2 36.1 56.1</cell></row><row><cell cols="2">Hirasawa [17] 2.2</cell><cell>4.2</cell><cell>4.3</cell><cell>4.0</cell><cell>1.2</cell><cell></cell><cell cols="2">3.2 0.9 2.6</cell><cell>1.7</cell><cell>3.8</cell><cell>2.8</cell><cell>3.6</cell><cell>0.9</cell><cell>3.0 0.4 1.9</cell></row><row><cell cols="15">(SiSEC 2011) 22.6 32.6 46.8 38.1 19.5 23.6 41.6 32.8 24.6 36.1 44.0 41.2 20.2 26.3 41.6 34.5</cell></row><row><cell>Iso [18]</cell><cell>6.1</cell><cell>9.8</cell><cell cols="3">8.7 10.9 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>5.5</cell><cell>9.4</cell><cell>8.5</cell><cell cols="2">9.1 -</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="6">(SiSEC 2011) 30.4 59.6 45.1 64.8 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="5">30.9 54.5 35.0 59.8 -</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Cho [19]</cell><cell>3.2</cell><cell>7.4</cell><cell>4.4</cell><cell>8.1</cell><cell>0.0</cell><cell></cell><cell cols="2">3.1 -0.7 5.8</cell><cell cols="2">4.2 8.8</cell><cell>6.7</cell><cell>8.0</cell><cell>0.9</cell><cell>4.2 1.2 5.2</cell></row><row><cell cols="15">(SiSEC 2011) 22.0 27.8 20.8 43.6 21.7 24.7 20.0 40.5 37.4 63.3 46.4 55.5 25.2 32.4 25.0 46.4</cell></row><row><cell cols="2">Nesta (1) [20] 4.3</cell><cell>6.5</cell><cell>7.9</cell><cell>8.4</cell><cell>2.8</cell><cell></cell><cell cols="3">5.2 5.3 6.2 4.9</cell><cell>7.5</cell><cell>9.1</cell><cell cols="2">7.5 3.5</cell><cell>5.9 6.6 5.1</cell></row><row><cell>Ozerov [10]</cell><cell>3.6</cell><cell>8.2</cell><cell>7.4</cell><cell>7.4</cell><cell>1.5</cell><cell></cell><cell cols="2">5.1 2.5 4.7</cell><cell cols="3">6.0 10.4 9.9</cell><cell>8.8</cell><cell>2.2</cell><cell>5.9 3.8 5.4</cell></row></table><note><p>(SiSEC 2011) 38.1 63.1 52.0 56.3 35.5 54.7 49.5 45.8 41.2 63.5 55.0 52.5 35.7 56.3 53.6 42.2 Nesta (2) [20] 6.0 10.2 10.4 10.2 3.4 6.9 6.3 7.2 6.2 10.3 10.4 8.6 4.7 8.3 8.3 6.3 (SiSEC 2011) 37.3 60.8 50.5 60.2 33.6 49.5 45.0 50.1 39.8 60.1 52.1 55.2 35.7 54.5 51.1 49.6 (SiSEC 2011) 36.0 63.5 48.1 56.2 30.6 47.5 38.1 49.5 39.6 61.3 51.7 58.2 37.4 55.9 50.3 51.7</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Results for the BGN task</figDesc><table><row><cell>systems</cell><cell cols="2">criteria dev</cell><cell></cell><cell></cell><cell>test</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Ca1 Sq1 Su1</cell><cell cols="2">Ca1 Ca2 Sq1</cell><cell>Sq2 Su1</cell><cell>Su2</cell></row><row><cell cols="5">(a) Single-channel source estimation</cell><cell></cell><cell></cell></row><row><cell cols="2">Duong [24] SDR</cell><cell cols="2">5.6 9.3</cell><cell>4.1</cell><cell>3.7</cell><cell>4.3 10.1</cell><cell>11.6 5.3</cell><cell>4.2</cell></row><row><cell></cell><cell>SIR</cell><cell cols="3">14.9 15.4 12.1</cell><cell cols="2">13.2 15.0 17.9</cell><cell>18.2 19.3</cell><cell>9.3</cell></row><row><cell></cell><cell>SAR</cell><cell cols="3">6.3 10.7 5.3</cell><cell>4.8</cell><cell>4.9 11.1</cell><cell>12.7 5.5</cell><cell>6.6</cell></row><row><cell>Liu</cell><cell>SDR</cell><cell cols="4">1.9 -3.0 -10.6 1.6</cell><cell cols="2">2.7 -4.4 1.9</cell><cell>-12.6 -1.2</cell></row><row><cell></cell><cell>SIR</cell><cell cols="4">4.0 -2.9 -9.7 4.5</cell><cell cols="2">7.7 -4.3 2.4</cell><cell>-12.2 0.1</cell></row><row><cell></cell><cell>SAR</cell><cell cols="3">7.5 16.4 6.9</cell><cell>6.5</cell><cell>5.5 18.8</cell><cell>16.9 10.3</cell><cell>8.0</cell></row><row><cell cols="7">(b) Multichannel source image estimation (target source)</cell></row><row><cell>systems</cell><cell cols="2">criteria dev</cell><cell></cell><cell></cell><cell>test</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Ca1 Sq1 Su1</cell><cell cols="2">Ca1 Ca2 Sq1</cell><cell>Sq2 Su1</cell><cell>Su2</cell></row><row><cell cols="2">Duong [24] SDR</cell><cell>9.4</cell><cell>6.9</cell><cell cols="3">4.7 9.6 11.0 9.3</cell><cell>10.2</cell><cell>9.8 7.0</cell></row><row><cell></cell><cell>ISR</cell><cell cols="2">23.1 18.0</cell><cell cols="3">17.5 23.4 22.6 15.1</cell><cell>18.7</cell><cell>18.5 19.7</cell></row><row><cell></cell><cell>SIR</cell><cell>10.5</cell><cell>9.8</cell><cell cols="3">5.4 10.7 12.3 15.6</cell><cell>13.7</cell><cell>12.1 7.4</cell></row><row><cell></cell><cell>SAR</cell><cell cols="2">16.9 10.3</cell><cell cols="3">11.7 17.6 18.3 11.6</cell><cell>13.5</cell><cell>14.2 19.0</cell></row><row><cell></cell><cell>OPS</cell><cell cols="2">14.3 24.1</cell><cell cols="3">11.3 10.1 11.5 25.3</cell><cell>16.4</cell><cell>26.0 11.8</cell></row><row><cell></cell><cell>TPS</cell><cell cols="2">71.8 65.9</cell><cell cols="3">72.4 56.2 58.3 49.2</cell><cell>51.9</cell><cell>73.1 45.3</cell></row><row><cell></cell><cell>IPS</cell><cell cols="2">11.3 18.2</cell><cell cols="3">5.1 17.3 17.3 49.9</cell><cell>47.0</cell><cell>18.0 29.8</cell></row><row><cell></cell><cell>APS</cell><cell cols="2">78.0 66.8</cell><cell cols="3">75.1 82.6 81.9 56.1</cell><cell>78.8</cell><cell>57.8 76.0</cell></row><row><cell>Liu</cell><cell>SDR</cell><cell cols="6">-1.0 -8.5 -12.8 -1.9 0.1 -11.0 -5.6 -16.7 -5.6</cell></row><row><cell></cell><cell>ISR</cell><cell>4.1</cell><cell>1.9</cell><cell cols="2">3.8 2.1</cell><cell>2.4 0.6</cell><cell>0.3</cell><cell>2.1 1.4</cell></row><row><cell></cell><cell>SIR</cell><cell cols="4">4.9 -2.9 -8.0 5.7</cell><cell>9.1 -4.4</cell><cell>2.2 -11.9 1.1</cell></row><row><cell></cell><cell>SAR</cell><cell cols="2">19.7 15.1</cell><cell cols="3">7.6 19.3 20.7 17.6</cell><cell>15.9</cell><cell>11.0 13.9</cell></row><row><cell></cell><cell>OPS</cell><cell cols="2">9.5 14.2</cell><cell cols="2">21.1 10.6</cell><cell>8.9 14.2</cell><cell>17.2</cell><cell>31.3 12.6</cell></row><row><cell></cell><cell>TPS</cell><cell cols="2">42.3 38.8</cell><cell cols="3">49.5 45.0 43.2 48.3</cell><cell>56.1</cell><cell>62.5 51.0</cell></row><row><cell></cell><cell>IPS</cell><cell cols="2">16.8 18.9</cell><cell cols="3">15.7 37.0 23.2 47.6</cell><cell>62.5</cell><cell>35.1 50.3</cell></row><row><cell></cell><cell>APS</cell><cell cols="2">77.1 70.2</cell><cell cols="3">60.1 78.6 79.3 76.0</cell><cell>78.6</cell><cell>50.3 80.1</cell></row><row><cell cols="2">Wood [14] SDR</cell><cell>3.0</cell><cell>1.9</cell><cell cols="2">0.2 2.9</cell><cell>3.1 -0.7</cell><cell>2.5</cell><cell>-2.6 2.7</cell></row><row><cell></cell><cell>ISR</cell><cell>3.7</cell><cell>7.5</cell><cell cols="2">2.5 3.7</cell><cell>3.7 12.7</cell><cell>16.0</cell><cell>3.0 5.5</cell></row><row><cell></cell><cell>SIR</cell><cell>9.4</cell><cell>2.4</cell><cell cols="3">-2.6 9.0 12.4 -0.5</cell><cell>3.3</cell><cell>-6.4 3.8</cell></row><row><cell></cell><cell>SAR</cell><cell>5.0</cell><cell>4.0</cell><cell cols="2">1.3 5.3</cell><cell>5.2 6.3</cell><cell>8.3</cell><cell>0.3 4.5</cell></row><row><cell></cell><cell>OPS</cell><cell cols="2">33.7 38.6</cell><cell cols="3">25.9 36.6 35.4 45.1</cell><cell>57.7</cell><cell>26.0 44.1</cell></row><row><cell></cell><cell>TPS</cell><cell cols="2">40.5 57.6</cell><cell cols="3">24.4 45.4 42.8 60.2</cell><cell>64.6</cell><cell>20.6 57.2</cell></row><row><cell></cell><cell>IPS</cell><cell cols="2">60.7 60.5</cell><cell cols="3">47.6 66.1 64.5 69.2</cell><cell>74.6</cell><cell>55.4 67.6</cell></row><row><cell></cell><cell>APS</cell><cell cols="2">39.0 43.3</cell><cell cols="3">31.7 41.0 39.5 47.9</cell><cell>61.4</cell><cell>28.0 48.9</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://sisec.inria.fr.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>www.cambridge-mt.com/ms-mtk.htm.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>More info at github.com/faroit/dsdtools.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>sisec17.audiolabs-erlangen.de.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The 2013 signal separation evaluation campaign</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Koldovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Miyabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MLSP</title>
		<meeting>MLSP</meeting>
		<imprint>
			<date type="published" when="2013-09">September 2013</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The 2015 signal separation evaluation campaign</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Rafii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kitamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-22482-4_45</idno>
	</analytic>
	<monogr>
		<title level="m">LVA/ICA 2015</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Yeredor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Koldovský</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Tichavský</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9237</biblScope>
			<biblScope unit="page" from="387" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Performance measurement in blind audio source separation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Griboval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Févotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1462" to="1469" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Subjective and objective quality assessment of audio source separation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Emiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Harlander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Hohmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2046" to="2057" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Vocal activity informed singing voice separation with the iKala dataset</title>
		<author>
			<persName><forename type="first">T-S</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T-C</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z-C</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H-W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2015-04">April 2015</date>
			<biblScope unit="page" from="718" to="722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A musically motivated mid-level representation for pitch estimation and musical audio source separation</title>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Durrieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Richard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Top. Sig. Process</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1180" to="1191" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Singing-voice separation from monaural recordings using robust principal component analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hasegawa-Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2012-03">March 2012</date>
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Scalable audio separation with light kernel additive modelling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Rafii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Daudet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2015-04">April 2015</date>
			<biblScope unit="page" from="76" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multichannel music separation with deep neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nugraha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of EUSIPCO</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A general flexible framework for the handling of prior information in audio source separation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ozerov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bimbot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1118" to="1133" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">REpeating pattern extraction technique (REPET): a simple method for music/voice separation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Rafii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pardo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="82" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adaptive filtering for music/voice separation exploiting the repeating musical structure</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Rafii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Richard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2012-03">March 2012</date>
			<biblScope unit="page" from="53" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Music/voice separation using the similarity matrix</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Rafii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pardo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISMIR</title>
		<meeting>ISMIR</meeting>
		<imprint>
			<date type="published" when="2012-10">October 2012</date>
			<biblScope unit="page" from="583" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Blind speech separation with GCC-NMF</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rouat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Underdetermined convolutive BSS: Bayes risk minimization based on a mixture of super-Gaussian posterior approximation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Audio Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="828" to="839" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Variational Bayesian inference for source separation and robust feature extraction</title>
		<author>
			<persName><forename type="first">K</forename><surname>Adiloglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-00726146" />
	</analytic>
	<monogr>
		<title level="j">INRIA</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A GMM sound source model for blind speech separation in under-determined conditions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hirasawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yasuraoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ogata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Okuno</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-28551-6_55</idno>
	</analytic>
	<monogr>
		<title level="m">LVA/ICA 2012</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Theis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Cichocki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Yeredor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Zibulevsky</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7191</biblScope>
			<biblScope unit="page" from="446" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Blind source separation of mixed speech in a high reverberation environment</title>
		<author>
			<persName><forename type="first">K</forename><surname>Iso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Makino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nakatani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sawada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Hands-free Speech Communication and Microphone Arrays</title>
		<meeting>Hands-free Speech Communication and Microphone Arrays</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="36" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Underdetermined convolutive blind source separation using a novel mixing matrix estimation and MMSE-based source estimation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE MLSP</title>
		<meeting>IEEE MLSP</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Convolutive underdetermined source separation through weighted interleaved ICA and spatio-temporal source correlation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nesta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Omologo</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-28551-6_28</idno>
	</analytic>
	<monogr>
		<title level="m">LVA/ICA 2012</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Theis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Cichocki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Yeredor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Zibulevsky</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7191</biblScope>
			<biblScope unit="page" from="222" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The generalized correlation method for estimation of time delay</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Knapp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Carter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acousti. Speech Sig. Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="320" to="327" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning the parts of objects by non-negative matrix factorization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">401</biblScope>
			<biblScope unit="page" from="788" to="791" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multi-source TDOA estimation in reverberant audio using angular spectra and clustering</title>
		<author>
			<persName><forename type="first">C</forename><surname>Blandin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ozerov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sig. Process</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1950" to="1960" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Speech enhancement based on nonnegative matrix factorization with mixed group sparsity constraint</title>
		<author>
			<persName><forename type="first">H.-T</forename><forename type="middle">T</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-C</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Q K</forename><surname>Duong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM International Symposium on Information and Communication Technology</title>
		<meeting>ACM International Symposium on Information and Communication Technology</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="247" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Common fate model for unison source separation</title>
		<author>
			<persName><forename type="first">F.-R</forename><surname>Stöter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Edler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Magron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of ICASSP</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Improving Music Source Separation Based On Deep Neural Networks Through Data Augmentation and Network Blending</title>
		<author>
			<persName><forename type="first">S</forename><surname>Uhlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Porcu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Giron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Enenkl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mitsufuji</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Submitted to ICASSP</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Single-channel audio source separation using deep neural network ensembles</title>
		<author>
			<persName><forename type="first">E</forename><surname>Grais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Roma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Plumbley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AES 140</title>
		<meeting>AES 140</meeting>
		<imprint>
			<date type="published" when="2016-05">May 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Singing voice separation using RPCA with weighted l1-norm</title>
		<author>
			<persName><forename type="first">I.-Y</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LVA/ICA</title>
		<meeting>LVA/ICA</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Joint optimization of masks and deep recurrent neural networks for monaural source separation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hasegawa-Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Audio Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2136" to="2147" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Evaluation of audio source separation models using hypothesis-driven non-parametric statistical methods</title>
		<author>
			<persName><forename type="first">A</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Roma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hummersone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Plumbley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of EUSIPCO</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
