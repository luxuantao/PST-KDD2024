<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Abnormal event detection in crowded scenes using sparse representation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012-12-03">3 December 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yang</forename><surname>Cong</surname></persName>
							<email>congyang81@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Robotics</orgName>
								<orgName type="institution" key="instit1">Shenyang Institute of Automation</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of EEE</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
							<email>jsyuan@ntu.edu.sg</email>
							<affiliation key="aff1">
								<orgName type="department">Department of EEE</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ji</forename><surname>Liu</surname></persName>
							<email>ji-liu@cs.wisc.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Sciences</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Abnormal event detection in crowded scenes using sparse representation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2012-12-03">3 December 2012</date>
						</imprint>
					</monogr>
					<idno type="MD5">C5B37D6B90DEF2A3E8FA4B524AC45401</idno>
					<idno type="DOI">10.1016/j.patcog.2012.11.021</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Sparse representation Abnormal event Crowd analysis Video surveillance</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose to detect abnormal events via a sparse reconstruction over the normal bases. Given a collection of normal training examples, e.g., an image sequence or a collection of local spatio-temporal patches, we propose the sparse reconstruction cost (SRC) over the normal dictionary to measure the normalness of the testing sample. By introducing the prior weight of each basis during sparse reconstruction, the proposed SRC is more robust compared to other outlier detection criteria. To condense the over-completed normal bases into a compact dictionary, a novel dictionary selection method with group sparsity constraint is designed, which can be solved by standard convex optimization. Observing that the group sparsity also implies a low rank structure, we reformulate the problem using matrix decomposition, which can handle large scale training samples by reducing the memory requirement at each iteration from Oðk</p><p>where k is the number of samples. We use the columnwise coordinate descent to solve the matrix decomposition represented formulation, which empirically leads to a similar solution to the group sparsity formulation. By designing different types of spatio-temporal basis, our method can detect both local and global abnormal events. Meanwhile, as it does not rely on object detection and tracking, it can be applied to crowded video scenes. By updating the dictionary incrementally, our method can be easily extended to online event detection. Experiments on three benchmark datasets and the comparison to the state-of-the-art methods validate the advantages of our method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Anomaly detection, also named as outlier detection, refers to detecting patterns in a given dataset that do not conform to an established normal behavior, which is applicable in a variety of applications, such as intrusion detection, fraud detection, fault detection, system health monitoring, event detection in sensor networks, and detecting eco-system disturbances. The Oxford English Dictionary defines abnormal as: deviating from the ordinary type, especially in a way that is undesirable or prejudicial; contrary to the normal rule or system; unusual, irregular, aberrant We focus on the detection of abnormal events in crowded scenes. According to the definition above, the abnormal events can be identified as irregular events from normal ones. Depending on the scale of interests, previous work in abnormal video event detection, such as <ref type="bibr" target="#b36">[39,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b25">27,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b6">7]</ref>, can be categorized into two classes, as shown in Fig. <ref type="figure" target="#fig_0">1</ref> (each ellipse stands for a moving pedestrian): i. Local abnormal event (LAE): the behavior of an individual is different from its neighbors. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>(a), the motion pattern of the red one is different from its neighbors, thus is a spatial abnormal event. ii. Global abnormal event (GAE): the group behavior of the global scene is abnormal. Fig. <ref type="figure" target="#fig_0">1</ref>(b) shows an abnormal scene, where the pedestrians suddenly scattered due to an abnormal event, e.g., an explosion.</p><p>Since the intention of each specific application is different, there is no unified definition for both local abnormal events and global abnormal event detection. Let us clarify the abnormal event detection firstly. Given the training set D ¼ fx 1 ,x 2 , . . . ,x N g, where N is the number of training samples; x i A R d is a training data (d is the feature dimension), it stands for a general object which can be a pixel, an image patch, mixture dynamic texture, motion context in our paper, etc. Suppose we have a test sample yA R d , abnormal event detection is to design a measurement/ function to determine whether y is normal or not. That is f : y/fnormal,abnormalg: To achieve this, two key issues need to be properly addressed, event representation and anomaly measurement.</p><p>For abnormal event representation, binary features based on background model are adopted in <ref type="bibr" target="#b36">[39,</ref><ref type="bibr" target="#b2">3]</ref>. Some other methods consider the spatial-temporal information, such as Histogram of Optical Flow (HOF) <ref type="bibr" target="#b0">[1]</ref>, spatial-temporal gradient <ref type="bibr" target="#b15">[17]</ref>, social force model <ref type="bibr" target="#b25">[27]</ref>, chaotic invariant <ref type="bibr" target="#b31">[34]</ref>, mixtures of dynamic textures <ref type="bibr" target="#b21">[23]</ref>. There are also saliency feature <ref type="bibr" target="#b12">[14]</ref> and graphbased nonlinear dimensionality reduction method <ref type="bibr" target="#b28">[30]</ref>. Moreover, the co-occurrence matrix is often used to describe the spatial relationship.</p><p>For anomaly measurement, to address this one-class learning problem, most conventional algorithms <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b15">17,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b25">27]</ref> intend to detect testing sample with lower probability as anomaly by fitting a probability model over the training data. There are several statistics models, such as Gaussian model, Gaussian Mixture Model (GMM) or Mixture Principle Component Analysis (MPPCA) <ref type="bibr" target="#b14">[16]</ref>, Hidden Markov Model (HMM) <ref type="bibr" target="#b15">[17]</ref>, Markov Random Field (MRF) <ref type="bibr" target="#b2">[3]</ref> or spatio-temporal MRF <ref type="bibr" target="#b14">[16]</ref>, Latent Dirichlet Allocation (LDA) <ref type="bibr" target="#b31">[34]</ref>. Normalization Cut is used in <ref type="bibr" target="#b36">[39]</ref> to discriminate the abnormal clusters from normal clusters. The procedure is to first fit some of stochastic probability model as mentioned above using the training dataset D, and then calculate the posterior probability of y given the model:</p><formula xml:id="formula_1">f ¼ normal pðy9DÞ Z y, abnormal pðy9DÞ o y, (<label>ð2Þ</label></formula><p>where y is the threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Motivation and contribution</head><p>High-dimensional feature is usually preferred to better represent the event. However, to fit a good probability model, the required number of training data increases exponentially approximate Oðd 2 Þ with the feature dimension d, it is unrealistic to collect enough training data for density estimation in practice. Thus, for most state-of-the-art methods, there is an unsolved problem between event representation using high-dimensional feature and model complexity. For example, for our global abnormal detection, there are only 400 training samples with the dimension of 320. With such a limited number of training samples, it is difficult to even fit a Gaussian model robustly. We notice that sparse representation is suitable to represent high-dimensional samples using less training data. This motivates us to detect abnormal events via a sparse reconstruction from normal ones. Given an input test sample y A R m , we reconstruct it by a sparse linear combination of an over-complete normal (positive) bases set F ¼ R mÂD , where mo D, as</p><formula xml:id="formula_2">x n ¼ arg min x 1 2 JyÀFxJ 2 2 þ lJxJ 1 ,<label>ð3Þ</label></formula><p>where x n is the reconstruction coefficients. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>(a), a normal event (the up one) is likely to generate sparse reconstruction coefficients x n , while an abnormal event (the bottom one) is dissimilar to any of the normal basis, thus generates a dense representation. To quantify the normalness, we propose a novel sparse reconstruction cost (SRC) based on the L 1 minimization, as</p><formula xml:id="formula_3">SRC ¼ 1 2 JyÀFx n J 2 2 þ lJx n J 1 :<label>ð4Þ</label></formula><p>As shown in Fig. <ref type="figure" target="#fig_1">2</ref>(b), for the frame-level abnormal event detection, the normal frame has a small reconstruction cost, while the abnormal frame usually generates a large reconstruction cost. Therefore, the SRC can be adopted as an anomaly measurement for such a one-class classification problem.</p><p>To handle both LAE and GAE, the definition of training basis y can be quite flexible, e.g., an image patch, a spatio-temporal video subvolume, or a normal image frame. It thus provides a general way of representing different types of abnormal events. Moreover, we propose a new dictionary selection method to reduce the size of the basis of F for an efficient reconstruction of y.</p><p>The weight of each new training sample is also learned to indicate its normalness, i.e., the occurrence frequency. These weights form a weight matrix W which serves as a prior term in the L 1 minimization.</p><p>We evaluate our method in three different abnormal event detection datasets, including the UMN dataset [31], the UCSD dataset <ref type="bibr" target="#b21">[23]</ref>, and the subway dataset <ref type="bibr" target="#b0">[1]</ref>. The main contributions are as below: i. For anomaly measurement, we propose a novel criterion, Sparse Reconstruction Cost (SRC), to detect abnormal event, which outperforms the existing criterion, e.g., Sparsity Concentration Index in <ref type="bibr" target="#b30">[33]</ref>. The Weighted Orthogonal Matching Pursuit (WOMP) is also adopted to solve the weighted L 1 minimization in a more efficient way. ii. To increase computational efficiency, a novel dictionary selection model based on group sparsity has been designed to generate a minimal size of bases set and prune noise training samples. Moreover, the lower rank constraint is considered to handle the large scale problem caused by large scale training samples. iii. By using different types of basis, we provide a unified solution to detect both local and global abnormal events in crowded scene. Our method can also be extended to online event detection by an incremental self-update mechanism. The rest of this paper is organized as follows: Section 2 gives the related work. Section 3 provides an overview of our algorithm. Section 4 presents the implementation details of our algorithm, including basis definition, dictionary selection, weighted L 1 minimization and self-update procedure. For dictionary selection, we compare the large scale version with the traditional one <ref type="bibr" target="#b6">[7]</ref> in Section 5. Then, Section 6 reports our experimental results and comparisons with state-of-the-art methods to justify the performance of our algorithm. Finally, Section 7 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Much progresses in video surveillance have been achieved in recent years for some key areas, such as background model <ref type="bibr" target="#b27">[29]</ref>, object tracking <ref type="bibr" target="#b1">[2]</ref>, pedestrian detection <ref type="bibr" target="#b7">[8]</ref>, action recognition <ref type="bibr" target="#b33">[36]</ref>, crowd counting <ref type="bibr" target="#b5">[6]</ref> and traffic monitoring <ref type="bibr" target="#b29">[32]</ref>. Abnormal event detection, as a key application in video surveillance, has also provoked great interests. Depending on the specific scene, the abnormal event detection can be classified into those in crowded scenes and uncrowded scenes.</p><p>For uncrowded scenario, as the foreground objects can be extracted easily from the background, binary features based on background model are usually adopted, such as Normalized Cut clustering by Zhong et al. <ref type="bibr" target="#b36">[39]</ref> and 3D spatio-temporal foreground mask feature fused using Markov Random Field by Benezeth et al. <ref type="bibr" target="#b2">[3]</ref>. Due to the object template can be initialized in the uncrowded scene, there are also some trajectory-based approaches by tracking the objects, such as <ref type="bibr" target="#b29">[32,</ref><ref type="bibr" target="#b10">12,</ref><ref type="bibr" target="#b26">28,</ref><ref type="bibr" target="#b13">15]</ref>. They use frame-difference for object localization and then generate the object trajectories by tracking. These methods can obtain satisfied results on traffic monitoring, however, may fail in the crowded scene, since they cannot get a good object trajectories.</p><p>For crowded scenes, as there are so many objects or events occurring simultaneously in the clutter background, e.g., the subway station, it is difficult to separate each of objects or events and represent the overall object or event in global view. Therefore, most of the state-of-the-art methods use the local features for abnormal event representation, by considering the spatiotemporal information and extracting motion or gray-level sift-like features from local 2D patches or local 3D bricks, such as Histogram of optical flow, 3D gradient. Next the co-occurrence matrices are often chosen to describe the context information. For example, Adam et al. <ref type="bibr" target="#b0">[1]</ref> use histograms to measure the probability of optical flow in local patch. Kratz et al. <ref type="bibr" target="#b15">[17]</ref> extract spatio-temporal gradient to fit Gaussian model of each 3D brick, and then use HMM to detect abnormal events in densely crowded subway. Andrade et al. <ref type="bibr" target="#b9">[10]</ref> use unsupervised feature extraction to encode normal crowd behavior. The saliency features are extracted and associated using a Bayesian model to detect surprising (abnormal) events in video <ref type="bibr" target="#b12">[14]</ref>. Kim et al. <ref type="bibr" target="#b14">[16]</ref> model local optical flow with MPPCA and enforce consistency by Markov Random Field. In <ref type="bibr" target="#b28">[30]</ref>, a graph-based nonlinear dimensionality reduction method using motion cues is applied for abnormality detection. Mahadevan et al. <ref type="bibr" target="#b21">[23]</ref> model the normal crowd behavior by mixtures of dynamic textures. Mehran et al. <ref type="bibr" target="#b25">[27]</ref> present a new way to formulate the abnormal crowd behavior by adopting the social force model <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b32">35]</ref>. They first extract particle advection based on optical flow, then compute the social force and combine with a Latent Dirichlet Allocation (LDA) model for anomaly detection; however, their algorithm can just detect the global behavior in full image scale and cannot localize the subpart abnormal region. In <ref type="bibr" target="#b31">[34]</ref>, they define a chaotic invariant to describe the event. Another interesting work is about irregularities detection by Boiman and Irani <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, in which they extract 3D bricks as the descriptor and use dynamic programming as inference algorithm to detect the anomaly. Since this method searches the current feature from all the features in the past, it is time-consuming.</p><p>On the other hand, researchers have revealed that many neurons are selective for a variety of specific stimuli, e.g., color, texture, primitive, and this phenomenon broadly exists in both low-level and mid-level human vision <ref type="bibr" target="#b24">[26,</ref><ref type="bibr" target="#b23">25]</ref>. Therefore, sparse representation <ref type="bibr" target="#b24">[26,</ref><ref type="bibr" target="#b23">25,</ref><ref type="bibr" target="#b16">18]</ref> is generated accordingly, which calls for modeling data vectors as a linear combination of a few elements from an overcomplete dictionary. Depending on the sparse reconstruction coefficients, sparse representation has also been used for many matching and classification applications in computer vision domain, such as object tracking <ref type="bibr" target="#b22">[24]</ref>, object or face recognition <ref type="bibr" target="#b20">[22]</ref>, image inpainting <ref type="bibr" target="#b18">[20]</ref>. In comparison with conventional sparse representation, where the bases in dictionary are selected manually or generated by a dictionary learning model, we propose a large scale dictionary selection model using low rank constraint, which can retain the original property of the data. Next, we propose a unified solution for abnormal event detection using sparse reconstruction cost (SRC) <ref type="bibr" target="#b6">[7]</ref>. A similar work in <ref type="bibr" target="#b35">[38]</ref> also applies sparse representation for abnormal event detection. However, it does not address the large-scale dictionary selection problem, and cannot handle both LAE and GAE simultaneously as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Overview of our method</head><p>To detect both LAE and GAE, we propose a general solution using sparse representation, as illustrated in Fig. <ref type="figure">3</ref>. The flowchart of our algorithm is shown in Fig. <ref type="figure" target="#fig_2">4</ref>.</p><p>For training, only normal videos are required. To detect abnormal events from normal training samples, we collect the feature from training video frames to generate the normal feature pool B, where each sample in B is normal feature. Different features are designed for LAE or GAE (Section 4.1). As the normal feature pool B is redundant and contains noisy features, an optimal subset B 0 with minimal size is selected from B as training dictionary (we call each feature of the selected dictionary as basis), and the weight of each basis of the dictionary is also initialized (Section 4.2).</p><p>For testing, we also extract the same feature as in training, then each testing sample y can be a sparse linear combination of the training dictionary by weighted L 1 minimization, and whether y is to normal or not (e.g., the green/red point in Fig. <ref type="figure">3</ref>) is determined by the linear reconstruction cost (SRC) (Section 4.3), i.e., normal feature can be efficiently spare represented by training dictionary with lower cost, on the contrary, the abnormal basis will be constructed with greater cost or even cannot be constructed, as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. Moreover, our system can also self-update incrementally, which will be explained in Section 4.4. The algorithm is shown in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Implementation of our method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Multi-scale HOF and basis definition</head><p>We propose a new feature descriptor called Multi-scale histogram of optical flow (MHOF), and for event representation, all the types of basis are concatenated by MHOF with various spatial or</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Normal Sample Abnormal Sample</head><p>Training Sample (Normal)</p><p>Selected Training Sample (Normal) Fig. <ref type="figure">3</ref>. The illustration of our algorithm. Each point stands for a high dimensional feature point. The green or red point indicates the normal or abnormal testing sample, respectively. As most events are normal, the green points are dense and red points are sparse. For initialization the dictionary, some redundant light blue points are given as training features; after dictionary selection, an optimal subset of representatives (dark blue point) are selected as basis to constitute the normal dictionary, where its size indicates the weight: the larger, the more normal. Then, the abnormal event detection is to measure the sparsity reconstruction cost (SRC) of a testing sample (green and red points) over the normal dictionary (dark blue points). (For interpretation of the references to color in this figure caption, the reader is referred to the web version of this article.) temporal structures. After estimating the motion field by optical flow <ref type="bibr" target="#b17">[19]</ref>, we partition the image into a few basic units, i.e., 2D image patches or spatio-temporal 3D bricks, then extract MHOF from each unit. For each pixel (x,y) of the unit, we quantize it into the MHOF as Eq. ( <ref type="formula" target="#formula_4">5</ref>). In our implementation, the MHOF has K ¼16 bins as shown in Fig. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Basis Extraction</head><note type="other">Online</note><formula xml:id="formula_4">8 &gt; &gt; &gt; &lt; &gt; &gt; &gt; :<label>ð5Þ</label></formula><p>where rðx,yÞ and yðx,yÞ are the motion energy and motion direction of motion vector at (x,y), respectively. Therefore, our MHOF not only describes the motion information as traditional HOF, but also preserves the spatial contextual information. Actually depending on the specific applications, we can define much more scales MHOF, but for us, two scales are enough.</p><p>To handle different abnormal events, LAE or GAE, we propose several type of bases with different spatio-temporal structures, whose representations by the normalized MHOF are illustrated in Fig. <ref type="figure" target="#fig_3">5</ref>. For GAE, we select the spatial basis that can cover the whole frame. For LAE, we extract temporal or spatio-temporal basis that contain spatio-temporal contextual information, like the 3D Markov random field <ref type="bibr" target="#b14">[16]</ref>, and spatial topology structure can replace co-occurrence matrix. In general, our design of the local and global features is very flexible and other alternatives are certainly possible. Moreover, several features can be concatenated to build a more advanced description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Large scale dictionary selection using sparsity consistency</head><p>In this section, we address the problem of how to select the dictionary given an initial candidate feature pool as B ¼ ½b 1 , b 2 , . . . ,b k A R mÂk , where each column vector b i A R m denotes a normal feature. Our goal is to find an optimal subset to form the dictionary B 0 ¼ ½b i 1 ,b i 2 , . . . ,b in A R mÂn where i 1 ,i 2 , . . . ,i n A f1,2, . . . ,kg, such that the set B can be well reconstructed by B 0 and the size of B 0 is as small as possible. A simple idea is to pick up candidates randomly or uniformly to build the dictionary. Apparently, this cannot make full use of all candidates in B. Also it is risky to miss important candidates or include the noisy ones, which will greatly affect the reconstruction. To solve this problem, we present a principled method to select the dictionary. Our idea is that we should select an optimal subset of B as the dictionary, such that the rest of the candidates can be well reconstructed using it. More formally, we formulate the problem as follows:</p><formula xml:id="formula_5">min X : 1 2 JBÀBXJ 2 F þlJXJ 1 ,<label>ð6Þ</label></formula><p>where X A R kÂk ; the Frobenius norm JXJ F is defined as</p><formula xml:id="formula_6">JXJ F :¼ ð P i,j X 2 ij Þ 1=2</formula><p>; and the L 1 norm is defined as JXJ 1 :¼ P i,j 9X ij 9. However, this tends to generate a solution of X close to an identity matrix I, which leads the first term of Eq. ( <ref type="formula" target="#formula_5">6</ref>) to zero and is also very sparse. Thus, we need to require the consistency of the sparsity on the solution, i.e., the solution needs to contain some ''0'' rows, which means that the corresponding features in B are not selected to reconstruct any data samples.</p><p>Thus, in <ref type="bibr" target="#b6">[7]</ref>, we change the L 1 norm constraint in Eq. ( <ref type="formula" target="#formula_5">6</ref>) into the L 2,1 norm, and propose the followed optimization problem to select the dictionary: min</p><formula xml:id="formula_7">X : 1 2 JBÀBXJ 2 F þlJXJ 2,1 ,<label>ð7Þ</label></formula><p>where JXJ 2,1 :¼</p><formula xml:id="formula_8">P k i ¼ 1 JX iÁ J 2</formula><p>, and X iÁ denotes the ith row of X. The regularization term enforces the group sparsity on the variable X and the optimal solution usually contains zero rows, i.e., the dictionary B 0 is constituted by selecting bases with JX iÁ J 2 a 0. The larger the value of l is, the more zero rows X has. One can select the bases from the optimal X n to build dictionary, i.e., the nonzero rows correspond to the selected bases. The L 2,1 norm is indeed a general version of the L 1 norm since if X is a vector, then</p><formula xml:id="formula_9">JXJ 2,1 ¼ JXJ 1 . In addition, JXJ 2,1 is equivalent to JxJ 1 by construct- ing a new vector x A R k with x i ¼ JX iÁ J 2 .</formula><p>From this angle, it is not hard to understand that Eq. ( <ref type="formula" target="#formula_5">6</ref>) leads to a sparse solution for X, i.e., X is sparse in terms of rows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Improvement</head><p>This model in Eq. ( <ref type="formula" target="#formula_7">7</ref>) looks pretty nice, but may lead to a memory problem when the number of samples is huge, since X requires k 2 units to save. When the value of k increases for the large scale problem, X cannot be loaded into the memory at one time, then Eq. ( <ref type="formula" target="#formula_7">7</ref>) would be inefficient. In order to handle the large scale problem in practical applications, we decompose X as X ¼ ab T where aAR kÂr and bAR kÂr (r can be much smaller than k). Since the expected solution of X n should contain many zero rows, which implies that it is also a low rank matrix, this decomposition X ¼ ab T does not lose the generality. Typically, r can be given a number less than k, i.e., r 5 k. Thus, the memory cost in this decomposition is much less than k 2 .</p><p>As we still desire a solution with multiple zero rows, the group sparsity constraint can be enforced on a. Apparently, the zero rows of X can be indicated by those of a. Now we can reformulate Eq. ( <ref type="formula" target="#formula_7">7</ref>) into a large scale version as follows:</p><formula xml:id="formula_10">min a,b : 1 2 JBab T ÀBJ 2 F þ lJaJ 2,1 :<label>ð8Þ</label></formula><p>However, it is not enough because the optimal a n would be infinitely close to 0 and the optimal b n would be unbounded. To fix this problem, we only need one constraint on b such that b is bounded. Here, we can simply use the constraint JbJ 1 r1 and formulate the completed version as follows:</p><formula xml:id="formula_11">min a,b : 1 2 JBab T ÀBJ 2 F þ lJaJ 2,1 s:t: : JbJ 1,1 r1,<label>ð9Þ</label></formula><p>where JbJ 1,1 :¼ max i,j 9b ij 9. Note this problem is a nonconvex optimization problem, which can only guarantee a solution in the stationary point. The followed paragraph introduces the algorithm to solve this problem. Since there are two variables, we use the coordinate descent method to optimize a and b, iteratively, i.e., fixing a to optimize b and fixing b to optimize a, alternatively.</p><p>Optimize a: While fixing b, we aim to solve the following subproblem:</p><formula xml:id="formula_12">min a : FðaÞ ¼ 1 2 JBab T ÀBJ 2 F þlJaJ 2,1 :<label>ð10Þ</label></formula><p>This is a convex but nonsmooth optimization problem, as in our previous work <ref type="bibr" target="#b6">[7]</ref>. Denote f 0 ðaÞ as the smooth part 1 2 JBab T ÀBJ 2 F . We employ the proximal method to solve it by the following updating procedure:</p><formula xml:id="formula_13">a k þ 1 ¼ arg min a : p a k ,L ðaÞ :¼ f 0 ða k Þþ/,f 0 ða k Þ,aÀa k S þ L<label>2</label></formula><formula xml:id="formula_14">JaÀa k J 2 þ lJaJ 2,1 ,<label>ð11Þ</label></formula><p>where L is the Lipschitz constant (or a larger number) and</p><formula xml:id="formula_15">,f 0 ða k Þ can be computed by B T Bða k b T ÀIÞb T . The closed form of a k þ 1 is</formula><p>given by Dl L ða k À,f 0 ða k Þ=LÞ due to the following theorem: Theorem 1:</p><formula xml:id="formula_16">arg min X p Z,L ðXÞ ¼ D l=L ZÀ 1 L rf 0 ðZÞ ,<label>ð12Þ</label></formula><p>where </p><formula xml:id="formula_17">D t ðÁÞ : M A R kÂk /N A R kÂk N iÁ ¼ 0, JM iÁ J rt; ð1Àt=JM iÁ JÞM iÁ otherwise: (<label>ð13Þ</label></formula><p>To optimize b we employ the idea ''columnwise coordinate descent'' in <ref type="bibr" target="#b19">[21]</ref>: each column of b can be optimized simultaneously while fixing other columns:</p><formula xml:id="formula_19">min b Ái : 1 2 JBab T ÀBJ 2 F 1<label>2</label></formula><formula xml:id="formula_20">JðBaÞ Ái b T Ái À BÀ X j a i ðBaÞ Áj b T Áj 0 @ 1 A J 2 F s:t: : Jb Ái J 1 r 1:<label>ð15Þ</label></formula><p>The optimal b n iÁ can be computed by</p><formula xml:id="formula_21">b n Ái ¼ sgnðZÞ minðZ,1Þ,<label>ð16Þ</label></formula><p>where Z ¼ ðBÀ</p><formula xml:id="formula_22">P j a i ðBaÞ Áj b T Áj Þ T ðBaÞ Ái =JðBaÞ Ái J 2 .</formula><p>The operator '''' is defined by ða bÞ i ¼ a i b i . Although we can update each column of b multiple times when optimize b, the practical results indicate that updating only once is usually enough.</p><p>We summarize the algorithm in Algorithm 1.</p><p>Algorithm 1. Large Scale Dictionary Selection (LSDS). This section details how to determine a testing sample y to be normal or not. As we mentioned in the previous subsection, the features of a normal frame can be linearly constructed by only a few bases in the dictionary B 0 while an abnormal frame cannot. A natural idea is to pursue a sparse representation and then use the reconstruction cost to judge the testing sample. In order to advance the accuracy of prediction, two more factors are considered here:</p><formula xml:id="formula_23">Input: a 0 A R nÂr ,b 0 A R nÂr ,l 40,K,L,r Output: a K A R nÂr ,b K A R nÂr 1: for k ¼ 0,1,2, . . . ,KÀ1 do 2: Update a k þ 1 ¼ D l=L ða k Àrf 0 ða k Þ=LÞ 3: for i ¼ 0,1,2, . . . ,n do 4: Update ðb k þ 1 Þ Ái ¼ sgnðZÞ minðZ,1Þ Z ¼ BÀ P iÀ1 j ¼ 1 ðBa k þ 1 Þ Áj ðb k þ 1 Þ T Áj À P n j ¼ i þ 1 ða k þ 1 Þ Áj ðb k Þ T</formula><p>In practice, the deformation or any un-predicted situation may happen to the video. Motivated by <ref type="bibr" target="#b30">[33]</ref>, we extend the dictionary from B 0 to F ¼ ½B 0 ,I mÂm A R mÂD , and</p><formula xml:id="formula_24">D ¼ n þ m.</formula><p>If a basis in the dictionary appears frequently in the training dataset, then the cost to use it in the reconstruction should be lower, since it is a normal basis with high probability. Therefore, we design a weight matrix W ¼ diag½w 1 ,w 2 , . . . ,w n , 1, . . . ,1 A R DÂD to capture this prior information. Each w i A ½0,1 corresponds to the cost of the ith feature. For the artificial feature set I mÂm in our new dictionary F, the cost for each feature is set to 1. The way to dynamically update W will be introduced in the following section. Now, we are ready to formulate this sparse reforestation problem:</p><formula xml:id="formula_25">x n ¼ arg min x 1 2 JyÀFxJ 2 2 þ l 1 JWxJ 1 ,<label>ð17Þ</label></formula><p>where x ¼ ½x 0 ,e 0 T , x 0 A R n , and e 0 A R m . Given a testing sample y, we design a Sparsity Reconstruction Cost (SRC) using the minimal objective function value of Eq. ( <ref type="formula" target="#formula_25">17</ref>) to detect its abnormality:</p><formula xml:id="formula_26">S w ¼ 1 2 JyÀFx n J 2 2 þ l 1 JWx n J 1 :<label>ð18Þ</label></formula><p>A high SRC value implies a high reconstruction cost and a high probability of being an abnormal sample. In fact, the SRC function also can be equivalently mapped to the framework of Bayesian decision like in <ref type="bibr" target="#b11">[13]</ref>. From a Bayesian view, the normal sample is the point with a higher probability, on the contrary the abnormal (outlier) sample is the point with a lower probability. We can estimate the normal sample by maximizing the posteriori as follows:</p><formula xml:id="formula_27">x % ¼ arg max x pðx9y,F,WÞ ¼ argmax x pðy9x,F,WÞpðx9F,WÞ ¼ argmax x pðy9x,FÞpðx9WÞ ¼ argmin x À½log pðy9x,FÞþlog<label>pðx9WÞ</label></formula><formula xml:id="formula_28">¼ arg min x ð 1 2 JyÀFxJ 2 2 þ l 1 JWxJ 1 Þ,<label>ð19Þ</label></formula><p>where the first term is the likelihood pðy9x,FÞpexpðÀ </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Optimization</head><p>In our previous work <ref type="bibr" target="#b6">[7]</ref>, Eq. ( <ref type="formula" target="#formula_25">17</ref>) can be solved by quadratic programming using the interior-point method, which uses conjugate gradients algorithm to compute the optimized direction. However, as solving Eq. ( <ref type="formula" target="#formula_25">17</ref>) is time consuming for abnormal event detection, we need to a more efficient algorithm. To achieve this, the greedy algorithm for least squares regression in <ref type="bibr" target="#b34">[37]</ref>, called orthogonal matching pursuit (OMP) in signal processing community, is a good choice. Motivated by OMP <ref type="bibr" target="#b34">[37]</ref>, we design a Weighted Orthogonal Matching Pursuit (WOMP) model in our case. The improvement is that we change the second term of Eq. ( <ref type="formula" target="#formula_25">17</ref>) by adding a weighted factor. The algorithm is shown in Algorithm 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3. Weighted Orthogonal Matching Pursuit (WOMP).</head><p>Input: FAR mÂD , yA R m , W A R DÂD , and E40</p><formula xml:id="formula_29">Output: x % , k, F 1: Normalize bj ¼ b j =Jb j J 2 2: K¼0, F ¼ | and x ¼ 0 3: while ðJFxÀyJ 2 =JyJ 2 4 EÞ do 4: k ¼ k þ 1 5: i ¼ arg max i w ii J xT i ðFxÀyÞJ 6: Let F ¼ fig [ F 7: Let x ¼ ðF T F F F Þ À1 F T F y 8: end while 9: x % ¼ x</formula><p>Typically, we set E ¼ 0:05, which measures the reconstruction accuracy; F returns the support set; and x % is the pursuited parameter vector. Thus, we can use either weighted L1 minimization in <ref type="bibr" target="#b6">[7]</ref> or the improved version of WOMP in Algorithm 3 to solve Eq. ( <ref type="formula" target="#formula_25">17</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Update weight and dictionary</head><p>For the normal sample y, we selectively update weight W and dictionary F by choosing the top K bases with largest positive coefficient of x n 0 A R n , and we define the top k set as S k ¼ ½s 1 , . . . ,s k .</p><p>As we have mentioned above, the contribution of each basis to the L 1 minimization reconstruction is not identical. In order to measure such a contribution, we use W to assign each basis a weight, that is the basis with higher weight, should be used frequently and of course more similarity to normal event and vice verse. Define W ¼ ½w 1 ,w 2 , . . . ,w K . We initialize W from matrix X of dictionary selection, that is</p><formula xml:id="formula_30">b 0 i ¼ JX iÁ J 2 , w 0 i ¼ 1À b 0 i Jb 0 J 1 ,<label>ð20Þ</label></formula><p>where b i denotes the accumulate coefficients of each basis, and w i A ½0,1 (the smaller the value of w i , the more like a normal sample it is). The top k bases in W can be updated as follows:</p><formula xml:id="formula_31">b t þ 1 i ¼ b t i þ x n i , fi A S k g, w t þ 1 i ¼ 1À b t þ 1 i Jb t þ 1 J 1 ,<label>ð21Þ</label></formula><p>where S k is the index set of the top k features in W.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Comparison dictionary selection model: LSDL vs. convex model [7]</head><p>Based on the same dictionary selection model in Eq. ( <ref type="formula" target="#formula_7">7</ref>), we have two optimization schemes, namely the large scale version in Eq. ( <ref type="formula" target="#formula_11">9</ref>) and the traditional one in Eq. ( <ref type="formula" target="#formula_7">7</ref>) <ref type="bibr" target="#b6">[7]</ref>. The main difference between them is the memory cost, i.e., X ¼ ab relates to 2ðk Â rÞ,r 5n and B relates to k Â n, which is crucial especially when n is large. If they have similar performance, i.e., they can select similar dictionary from the same testing samples, the traditional version can be replaced by the large scale version directly. Therefore, we compare our new large scale version with our previous work in <ref type="bibr" target="#b6">[7]</ref> using synthesized data.</p><p>The experiment is setup in the following. Suppose the dimension of each sample as m, we first randomly generate n 1 bases, which can be considered as ground truth; then we randomly linearly combine them to generate new n 2 samples; finally, we normalize them and have total of n ¼ n 1 þ n 2 samples. The accuracy is the number of bases selected in the proportion of n 1 ground truth. If the result of our large scale version is similar to <ref type="bibr" target="#b6">[7]</ref>, we can consider they have competitive performance. Moreover, in comparison with <ref type="bibr" target="#b6">[7]</ref>, the large scale version needs less memory cost and can also work well when n increases.</p><p>The simulation results are as shown in Fig. <ref type="figure" target="#fig_6">6</ref> and some statistic results are provided in Table <ref type="table" target="#tab_2">1</ref>. Thus, without considering the size of B, we can conclude that both of Eqs. ( <ref type="formula" target="#formula_7">7</ref>) and ( <ref type="formula" target="#formula_11">9</ref>) have nearly the same performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>In this section, we systematically apply our proposed algorithm to several published datasets to justify the effectiveness. The UMN dataset <ref type="bibr" target="#b25">[27]</ref> is used to test the Global Abnormal Event (GAE) detection; and the UCSD dataset <ref type="bibr" target="#b21">[23,</ref><ref type="bibr">11]</ref> and Subway datasets <ref type="bibr" target="#b0">[1]</ref> are applied to Local Abnormal Event (LAE) detection. Moreover, we re-annotate Subway dataset in a bounding box level ground truth, where each box contains one abnormal event. For evaluation, three different level measurements are applied, which are Pixel-level, Frame-level and Event-level measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Dataset</head><p>UMN dataset: The UMN dataset <ref type="bibr" target="#b25">[27]</ref> consists of three different scenes of crowded escape events, and the total frame number is 7740 (1450, 4415 and 2145 for scenes 1-3, respectively) with a 320 Â 240 resolution. The normal events are pedestrians walking randomly on the square or in the mall, and the abnormal events are human spread running at the same time. There are total of 11 abnormal events in the whole video set.</p><p>UCSD dataset: The UCSD dataset <ref type="bibr" target="#b21">[23,</ref><ref type="bibr">11]</ref> includes two subdatasets, Ped1 and Ped2. The crowd density varies from sparse to very crowded. The training sets are all normal events and contain only pedestrians. The abnormal events in testing set are either (1) the circulation of nonpedestrian entities in the walkways or (2) anomalous pedestrian motion patterns. Commonly occurring anomalies include bikes, skaters, small cars, and people walking across a walkway or in the grass that surrounds it. Due to Ped2 sub-dataset has no pixel-level ground truth, in this paper we mainly focus on Ped1. For Ped1, the training set includes 34 normal video clips and the testing set contains 36 video clips in which some of the frames have one or more anomalies presents (a subset of 10 clips in testing set are provided with pixel-level binary masks to identify the regions containing abnormal events). For each clip, there are about 200 frames with the resolution 158 Â 238, The total number of anomalies frames ( % 3400) is a little bit smaller than that of normal frames ( % 5000).</p><p>Subway dataset: The subway dataset is provided by Adam et al. <ref type="bibr" target="#b0">[1]</ref>, including two videos: ''entrance gate'' (1 h 36 min long with 144 249 frames) and ''exit gate'' (43 min long with 64 900 frames).</p><p>In our experiments, we resized the frames from 512 Â 384 to 320 Â 240. The abnormal events mainly include wrong direction events and no-payment events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Evaluation criterion</head><p>Three criteria in different levels are applied for evaluation, which are Pixel-level, Frame-level and Event-level.</p><p>Pixel-level: To test localization accuracy, detections are compared to pixel-level ground truth masks, on a subset of 10 clips. The procedure is similar to that described above. If at least 40% of the truly anomalous pixels are detected, the frame is considered detected correctly, and counted as a false positive otherwise.</p><p>Frame-level: If a frame contains at least one abnormal pixel, it is considered as a detection. These detections are compared to the frame-level ground truth annotation of each frame. Note that this evaluation does not verify whether the detection coincides with the actual location of the anomaly. It is therefore possible for some portion true positive detections to be ''lucky'' co-occurrences of erroneous detections and abnormal events.</p><p>Event-level: Usually, an abnormal event will last for several consecutive frames, if more than one frames are detected as abnormal and the position is localized exactly, it is considered as a detection. Note that this evaluation does not need all the abnormal frames are detected.</p><p>The Receiver Operating Characteristic (ROC) curve is used to measure the accuracy for multiple threshold values. The ROC is consisted of true positive rate (TPR) and false positive rate (FPR), of which TPR determines a classifier or a diagnostic test performance on classifying positive instances correctly among all positive samples available during the test, and FPR, on the other hand, defines how many incorrect positive results occur among all negative samples available during the test. These measures are given by the formulas in the following equation:</p><formula xml:id="formula_32">TPR ¼ True positive True positive þ False negative , FPR ¼ False positive False positive þTrue negative ,<label>ð22Þ</label></formula><p>where True positive (TP) is the correctly labeled abnormal events; False negative (FN) is incorrectly labeled normal events; False positive (FP) is incorrectly labeled abnormal events; and True</p><p>Table <ref type="table" target="#tab_2">1</ref> The comparison of our proposed method with traditional model <ref type="bibr" target="#b6">[7]</ref> for dictionary selection using synthesized dataset. Sparse (Weight) Fig. <ref type="figure">7</ref>. The ROCs for the detection of abnormal frames in the UMN dataset. We compare different evaluation measurements for abnormal event detection, namely weighted SRC with Large Scale Dictionary Selection (LSDS) model, weighted SRC, SRC without Weight, sparse with concentration function and sparse with entropy measurement, and also the other two methods, social force <ref type="bibr" target="#b25">[27]</ref> and optical flow <ref type="bibr" target="#b25">[27]</ref>. Our method outperforms the others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Index</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2</head><p>The comparison of our proposed method with the state-of-the-art methods for detection of the abnormal events in the UMN dataset. We can see that our method with or without LSDS get similar results, but LSDS can be also used in the case that the size of training data is bigger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method AUC</head><p>Chaotic Invariants <ref type="bibr" target="#b31">[34]</ref> 0.99 Social Force <ref type="bibr" target="#b25">[27]</ref> 0.96 Optical flow <ref type="bibr" target="#b25">[27]</ref> 0 negative (TN) is correctly labeled abnormal events. For pixel-level and frame-level, we choice different thresholds and compute the TPR and FPR accordingly to generate the ROC curve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Global abnormal event detection</head><p>For the UMN dataset <ref type="bibr" target="#b25">[27]</ref>, we initialize the training dictionary from the first 400 frames of each scene, and leave the others for testing. The type A basis in Fig. <ref type="figure" target="#fig_3">5</ref>(B), i.e., spatial basis, is used here. We split each image into 4 Â 5 blocks, and extract the MHOF from each block. We then concatenate them to build a basis with a dimension m¼320. Because the abnormal events cannot occur only in one frame, a temporal smooth is applied.</p><p>The results are shown in Fig. <ref type="figure" target="#fig_7">8</ref>. The normal/abnormal results are annotated as red/green color in the indicated bars, respectively. In Fig. <ref type="figure">7</ref> shown to compare our SRC to three other measurements, which are:</p><p>i. SRC with W as an identity matrix in Eq. ( <ref type="formula" target="#formula_26">18</ref>), where</p><formula xml:id="formula_33">S ¼ 1 2 JyÀFx n J 2 2 þ l 1 Jx n J 1 .</formula><p>ii. The entropy used as a metric by formulating the sparse coefficient as a probability distribution: S E ¼ À P i p i log p i , where pðiÞ ¼ 9xðiÞ9=JxJ 1 . Thus sparse coefficients will lead to a small entropy value. iii. Concentration function similar to <ref type="bibr" target="#b30">[33]</ref>, S S ¼ T k ðxÞ=JxJ 1 , where T k ðxÞ is the sum of the k largest positive coefficients of x (the greater the S s , the more likely a normal testing sample).</p><p>Moreover, Table <ref type="table">2</ref> provides the quantitative comparisons to the state-of-the-art methods. The AUC of our method without using LSDS and using LSDS are similar, which are from 0.964 to 0.995 and from 0.971 to 0.9955, respectively; and both of them outperform <ref type="bibr" target="#b25">[27]</ref> and are comparable to <ref type="bibr" target="#b31">[34]</ref>. However, our method is a more general solution, because it covers both LAE and GAE. Moreover, Nearest Neighbor (NN) method can also be used in high dimensional space by comparing the distances between the testing sample and each training sample. The AUC of NN is 0.93, which is lower than that of our method. This demonstrates the robustness of our sparse representation method over NN method.  Examples of abnormal detections using (i) the MDT approach <ref type="bibr" target="#b21">[23]</ref>, (ii) the SF-MPPCA approach <ref type="bibr" target="#b21">[23]</ref>, (iii) our approach without Large Scale Dictionary Selection (LSDS) and (iv) our approach with LSDS, where our approach with or without LSDS get similar results. For MDT, its results are not accurate, which contain many background regions; and for SF-MPPCA, it completely misses the skater in (b), the person running in (c) and the biker in (d); moreover, both MDT and SF-MPPCA miss the person walking on the grass in (c). In contrast, our approach using sparse representation can outperform the state-of-the-art methods and obtain satisfactory results. From each localization, we estimate a dictionary and use it to determine whether a testing sample is normal or not. A spatiotemporal smooth is adopted here for eliminating noise, which can be seen as a simplified version of spatio-temporal Markov Random Filed <ref type="bibr" target="#b14">[16]</ref>.</p><p>Some testing results are shown in Fig. <ref type="figure" target="#fig_9">9</ref>, where both our approach with and without LSDS get satisfied results and outperform the state-of-the-art. Our approach can detect abnormal events such as bikers, skaters, small cars, etc. In Fig. <ref type="figure" target="#fig_10">10</ref>, we compare our method with MDT, Social force and MPPCA in <ref type="bibr" target="#b21">[23]</ref> by using pixel-level and frame-level measurements defined in <ref type="bibr" target="#b21">[23]</ref>. It shows that our ROC curve is better than others, and our approach with or without LSDS get similar results. In Table <ref type="table" target="#tab_6">3</ref>, the performance is evaluated using different criteria: for the Equal Error Rate (EER), our method using LSDS is 20%, which is higher than our method without using LSDS but lower than other methods 25% <ref type="bibr" target="#b21">[23]</ref>; for Rate of Detection (RD), ours using LSDS is the same as our previous version 46% and higher than the stateof-the-art methods 45% <ref type="bibr" target="#b21">[23]</ref>; and for Area Under Curve (AUC), ours make a bit improvement from 46.1% to 48.7%, and both of them outperforms other methods, e.g., 44.1% <ref type="bibr" target="#b21">[23]</ref>. Therefore, it demonstrates that our algorithm outperforms the state-of-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.2.">Subway dataset</head><p>For the subway dataset <ref type="bibr" target="#b0">[1]</ref>, we resized the frames from 512 Â 384 to 320 Â 240 and divided the new frames into 15 Â 15 local patches with 6 pixel overlaps. For event representation, the type B basis in Fig. <ref type="figure" target="#fig_3">5</ref> is adopted with the dimension of m ¼ 16 Â 5 ¼ 80. The first 10 min video is collected for estimating an optimal dictionary. The patch-level ROC curves of both two datasets are presented in Fig. <ref type="figure" target="#fig_13">13</ref>, where the positive detection and false positive correspond to each individual patch, and the AUCs are about 80% and 83%.</p><p>The detected results are shown in Fig. <ref type="figure" target="#fig_11">11</ref>. In additional to wrong direction events, the no-payment events are also detected, which are very similar to the normal ''checking in'' action. The event-level evaluation is shown in Table <ref type="table" target="#tab_5">4</ref>, which are divided into two parts depending on different groundtruth definitions. Only our method can detect all the wrong direction events accurately. Moreover, in contrast to <ref type="bibr" target="#b0">[1]</ref>, our approach can also keep a higher accuracy for no-payment events, because the designed temporal basis contains the temporal causality context. For the measurement of false alarm, our method is also the lowest one.</p><p>For these three dataset of GAE and LAE, we find that our improved version using LSDS gets similar result as our previous one <ref type="bibr" target="#b6">[7]</ref>, this is because both of them select the most efficient bases to construct the dictionary and use them for sparse reconstruction. However, our LSDS can handle large scale training data, which is crucial in practical applications. All experiments are run on the computer with 2 GB RAM and 2.6 GHz CPU. The average computation time is 0.8 s/frames for GAE, 3.8 s/frame for UCSD dataset, and 4.6 s/frame for the Subway dataset.</p><p>6.5. Comparison: L 2,1 norm vs. Frobenius norm Some readers may ask why we use group sparsity, and whether sparsity is really effective or not. To answer these questions, we define a similar dictionary selection model using   Frobenius norm to compare with our dictionary selection model using group sparsity, i.e., L 2,1 , as below:</p><formula xml:id="formula_34">F s ¼ argmin X 1 2 JBÀBXJ 2 F þ l 2 JXJ 2 F ,<label>ð23Þ</label></formula><p>where X A R kÂk and B A R mÂk . To pursuit X, we can get a closeform solution as Eq. ( <ref type="formula" target="#formula_35">24</ref>), which can be proved in Appendix B:</p><formula xml:id="formula_35">X ¼ ðB T B þ l 2 IÞ À1 B T B:<label>ð24Þ</label></formula><p>Now, let us compare our dictionary selection model using group sparsity with the Frobenius norm version in Eq. ( <ref type="formula" target="#formula_34">23</ref>) using synthesized data. The original feature set B with each column as an independently feature is collected from three Gaussian models, where the mean and covariance matrix of each Gaussian model is randomly generated. Then we randomly sample each Gaussian model to generate B. In detail here, each feature dimension is m¼50, and we randomly sample 300 features from each Gaussian model, so that we totally have 900 candidate features. Then we set l ¼ l 2 and give them different values to compare the results. A demo result is shown in Fig. <ref type="figure" target="#fig_4">12</ref> (l ¼ l 2 ¼ 40), obviously, the result of group sparsity in Fig. <ref type="figure" target="#fig_4">12(a</ref>) is sparse, we can easily select features of B with score JX iÁ J 2 2 4 0 as dictionary; however, in Fig. <ref type="figure" target="#fig_4">12</ref>(b), as we use Frobenius norm, nearly the score of all the features are greater than zero, which makes it hard to select the dictionary. In Fig. <ref type="figure" target="#fig_4">12(c</ref>) and (d), we rerank the score, the result of our group sparsity model using L 2,1 norm automatically select about 250 features from 900 features as dictionary, and in contrast the result of dictionary selection model using Frobenius norm cannot work well. Fig. <ref type="figure" target="#fig_4">12</ref> is only one of our experiments, in other cases, the results are also similar, thus we can conclude that our dictionary selection model using group sparsity, L 2,1 , is effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>In this paper, we propose a new criterion, sparse reconstruction cost (SRC), for abnormal event detection in the crowded scene. Whether a testing sample is abnormal or not is determined by its sparse reconstruction cost, through a weighted linear reconstruction of the over-completed normal bases. Our proposed dictionary selection method supports a robust estimation of the dictionary with minimal size; and with the help of the low rank constraint, it can not only deal with large scale training samples, but also require less memory cost than our previous work <ref type="bibr" target="#b6">[7]</ref>. Thanks to the flexibility in designing the basis, our method can easily handle both local abnormal events (LAE) and global abnormal events (GAE). By incrementally updating the dictionary, our method also supports online event detection. The experiments on three benchmark datasets show favorable results when compared with the state-of-the-art methods. In fact, our algorithm provides a general solution for outlier detection; and can also be applied to other applications, such as event/action recognition.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The illustration of local and global abnormal events: each ellipse stands for a moving pedestrian. (a) Local Abnormal Event (LAE): the behavior of the red pedestrian is different from its neighbors. (b) Global Abnormal Event (GAE): the group behavior is abnormal. (For interpretation of the references to color in this figure caption, the reader is referred to the web version of this article.)</figDesc><graphic coords="2,130.88,93.89,159.91,92.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a) Top left: the normal sample; top right: the sparse reconstruction coefficients; bottom left: the abnormal sample; bottom right: the dense reconstruction coefficients. (b) Frame-level Sparsity Reconstruction Cost (SRC): the red/green color corresponds to abnormal/normal frame, respectively. It shows that the S w of abnormal frame is greater than normal ones, and we can identify abnormal events accordingly. (For interpretation of the references to color in this figure caption, the reader is referred to the web version of this article.)</figDesc><graphic coords="3,122.43,58.64,360.36,321.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The flowchart of our proposed algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. (A) The Multi-scale HOF is extracted from a basic unit (2D image patch or 3D brick) with 16 bins. (B) The selection of flexible spatio-temporal basis for sparse representation, such as types A, B and C, described by a concatenation of MHOF from the basic units. For GAE, we can use type A; for LAE, we can use type B or C.</figDesc><graphic coords="5,50.48,59.09,219.26,154.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>2 F</head><label>2</label><figDesc>Appendix A gives the derivation to this theorem. Note that one can fix b and optimize a for multiple times, but the practical experiments indicate that one time is optimal. Optimize b: While fixing a to solve b, this subproblem is min b s:t: : JbJ 1 r1:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Áj 5 : end for 6: end for 4 . 3 .</head><label>543</label><figDesc>Anomaly measurement: weighted L 1 minimization and abnormal detection</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.<ref type="bibr" target="#b5">6</ref>. The comparison of different dictionary selection models. The dimension of each basis is m¼100, n 1 ¼ 50 and n¼ 250. The first n 1 ¼ 50 samples are the basis as ground truth, the other n 2 ¼ 200 samples are testing samples. (a) is the result of traditional model<ref type="bibr" target="#b6">[7]</ref> and (b) is the result of our large scale dictionary model. We can see that most bases are selected from testing samples successfully for both (a) and (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig.8. The qualitative results of the global abnormal event detection using our method with LSDS for three sample videos from UMN dataset, which is similar to Fig.3in<ref type="bibr" target="#b6">[7]</ref>. The top row represents the result for a video in the dataset. The ground truth bar and the detection result bar represent the labels of each frame for that video, and green color denotes the normal frames and red corresponds to abnormal frames. (For interpretation of the references to color in this figure caption, the reader is referred to the web version of this article.)</figDesc><graphic coords="9,122.54,160.31,360.07,541.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>6. 4 .</head><label>4</label><figDesc>Local abnormal event detection 6.4.1. UCSD Ped1 dataset For the UCSD Ped1 dataset, we split each image into local patches of size 7 Â 7 with 4 pixel overlaps. For event representation, we select type C basis in Fig. 5 for incorporating both local spatial and temporal information, with the dimension m ¼ 7 Â 16 ¼ 102.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. Examples of abnormal detections using (i) the MDT approach<ref type="bibr" target="#b21">[23]</ref>, (ii) the SF-MPPCA approach<ref type="bibr" target="#b21">[23]</ref>, (iii) our approach without Large Scale Dictionary Selection (LSDS) and (iv) our approach with LSDS, where our approach with or without LSDS get similar results. For MDT, its results are not accurate, which contain many background regions; and for SF-MPPCA, it completely misses the skater in (b), the person running in (c) and the biker in (d); moreover, both MDT and SF-MPPCA miss the person walking on the grass in (c). In contrast, our approach using sparse representation can outperform the state-of-the-art methods and obtain satisfactory results.</figDesc><graphic coords="10,67.22,245.44,451.44,292.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. The result of UCSD Ped1 dataset. (a) Frame-level ROC for Ped1 Dataset, (b) Pixel-level ROC for Ped1 Dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Example abnormal event detected by our algorithm. The top row and bottom row are from exit and entrance video set, respectively, and red masks contained into the yellow rectangle indicate where the abnormal is detected, including wrong direction (A-F) and no-payments (G-H). (For interpretation of the references to color in this figure caption, the reader is referred to the web version of this article.)</figDesc><graphic coords="11,107.36,550.19,402.20,163.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>F þ lJXJ 2 Fig. 12 .</head><label>212</label><figDesc>Fig.12. We compare the dictionary selection model using L 2,1 norm with Frobenius norm. The result using group sparsity, i.e., L 2,1 norm, is sparse and effective. (a) Coefficients of dictionary selection using L 2,1 norm. (b) Coefficients of dictionary selection using Frobenius norm. (c) Rerank the coefficients of dictionary selection using L 2,1 norm. (d) Rerank the coefficients of dictionary selection using Frobenius norm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 13 .</head><label>13</label><figDesc>Fig.<ref type="bibr" target="#b11">13</ref>. The frame-level ROC curve for both subway entrance and exit datasets.</figDesc><graphic coords="12,37.59,302.28,241.56,145.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>1 2</head><label>1</label><figDesc>JyÀFxJ 2 2 Þ, and the second term pðx; WÞpexpðÀl 1 JWxJ 1 Þ is the prior distribution. This is consistent with our SRC function, as the abnormal samples correspond to smaller pðy9x,FÞ, which results in greater SRC values.</figDesc><table><row><cell>6:</cell><cell>Select top K bases coefficients of x n</cell></row><row><cell>7:</cell><cell>Update W t 'W tÀ1</cell></row><row><cell cols="2">8: end if</cell></row><row><cell cols="2">9: end for</cell></row><row><cell></cell><cell>Algorithm 2. Abnormal Event Detection Framework.</cell></row><row><cell></cell><cell>Input: Training dictionary F, basis weight matrix W 0 ,</cell></row></table><note><p><p><p><p><p>sequential input testing sample Y A ½y 1 ,y 2 , . . . ,y T Output: W 1: for t ¼ 1, . . . ,T do 2: Pursuit the coefficient x n by L 1 minimization: 3:</p>x n ¼ argmin x 1 2 Jy t ÀFxJ 2 2 þ JW tÀ1 xJ 1 4: Calculate SRC function S t</p>w by Eq. (</p>18</p>) 5: if y is normal then</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4</head><label>4</label><figDesc>Comparison of accuracy for both subway videos. The first number in the slash (/) denotes the entrance gate result; the second is for the exit gate result. Due to different groundtruth annotations<ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">16]</ref>, the table is classified into two parts. Nevertheless, our method more accurate and has low false alarms rate than the state-of-the-art methods.</figDesc><table><row><cell>Methods</cell><cell>Wrong direction</cell><cell>No-pay</cell><cell>Total</cell><cell>False alarm</cell></row><row><cell>Ground truth [1]</cell><cell>21/9</cell><cell>10/-</cell><cell>31/9</cell><cell>-/-</cell></row><row><cell>Adam [1]</cell><cell>17/9</cell><cell>-/-</cell><cell>17/9</cell><cell>4/2</cell></row><row><cell>Ours</cell><cell>21/9</cell><cell>6 /-</cell><cell>27/9</cell><cell>4 /0</cell></row><row><cell>Ground truth [16]</cell><cell>26/9</cell><cell>13/3</cell><cell>39/12</cell><cell>-/-</cell></row><row><cell>Kim [16]</cell><cell>24/9</cell><cell>8/3</cell><cell>32/12</cell><cell>6/3</cell></row><row><cell>Zhao [38]</cell><cell>25/9</cell><cell>9/3</cell><cell>34/12</cell><cell>5/2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3</head><label>3</label><figDesc>The statistical result of UCSD Ped1 dataset. Quantitative comparison of our method with<ref type="bibr" target="#b21">[23]</ref>: EER is equal error rate, RD is rate of detection, and AUC is the area under ROC.</figDesc><table><row><cell>Methods</cell><cell>EER (%)</cell><cell>RD (%)</cell><cell>AUC (%)</cell></row><row><cell>SF [23]</cell><cell>31</cell><cell>21</cell><cell>17.9</cell></row><row><cell>MPPCA [23]</cell><cell>40</cell><cell>18</cell><cell>20.5</cell></row><row><cell>SF-MPPCA [23]</cell><cell>32</cell><cell>18</cell><cell>21.3</cell></row><row><cell>MDT [23]</cell><cell>25</cell><cell>45</cell><cell>44.1</cell></row><row><cell>Adam [1]</cell><cell>38</cell><cell>24</cell><cell>13.3</cell></row><row><cell>Sparse</cell><cell>19</cell><cell>46</cell><cell>46.1</cell></row><row><cell>Sparse þ LSDS</cell><cell>20</cell><cell>46</cell><cell>48.7</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Y. Cong et al. / Pattern Recognition 46 (2013) 1851-1864</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by the Nanyang Assistant Professorship (M4080134), JSPS-NTU joint project (M4080882), Natural Science Foundation of China (61105013), and National Science and Technology Pillar Program (2012BAI14B03). Part of this work was done when Yang Cong was a research fellow at NTU.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A</head><p>We prove Theorem 1 here, where the optimization problem min X : p Z,L ðXÞ can be equivalently written as min</p><p>Since the L 2 norm is self-dual, the problem above can be rewritten by introducing a dual variable Y A R kÂk : min</p><p>The second equation is obtained by swapping ''max'' and ''min''. Since the function is convex with respect to X and concave with respect to Y, this swapping does not change the problem by the Von Neumann minimax theorem. Letting X ¼ ZÀð1=LÞrf 0 ðZÞÀ ðl=LÞY, we obtain an equivalent problem from the last equation above max</p><p>Using the same substitution as above,</p><p>rf 0 ðZÞ , ðA:4Þ</p><p>we change it into a problem in terms of the original variable X as</p><p>Therefore, the optimal solution of the first problem in Eq. (A.5) is equivalent to the last problem in Eq. (A.5). Actually, each row of X can be optimized independently in the last problem. Considering each row of X, respectively, we can get the closed form as arg min</p><p>As Frobenius norm can be considered as a kind of L 2 norm, it can be rewritten as JXJ 2 F ¼ trðX T XÞ, where trðAÞ ¼ P i A ii is the trace of matrix A. Thus, we can rewrite Eq. (23) as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ðB:1Þ</head><p>where B A R mÂk and X A R kÂk . In order to solve this equation, we derivative it, @F s @X ¼ 0: ðB:2Þ</p><p>Obviously, this is a convex optimization, and the quadratic optimization can be used to solve it. As @ trðABÞ trðAÞ ¼ @trðBAÞ trðAÞ ¼ B: ðB:3Þ</p><p>We have @ trððBÀBXÞ T ðBÀBXÞÞ þ l 2 trðX T XÞ @X ¼ 0, ðB:4Þ @ trðB T BÀB T BXÀX T B T B þ X T B T BXÞþl 2 trðX T XÞ @X ¼ 0: ðB:5Þ So, we can get</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ðB:7Þ</head><p>where I A R kÂk is an identity matrix. Usually, l 2 40, so ðB T B þ l 2 IÞ is a full rank matrix and has an inverse matrix, therefore we have a close-form solution of X for Eq. ( <ref type="formula">23</ref>) as</p><p>ðB:8Þ</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robust real-time unusual event detection using multiple fixed-location monitors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shimshoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Reinitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="555" to="560" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ensemble tracking</title>
		<author>
			<persName><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="261" to="271" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Abnormal events detection based on spatio-temporal co-occurrences</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benezeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jodoin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rosenberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Detecting irregularities in images and in video</title>
		<author>
			<persName><forename type="first">O</forename><surname>Boiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Detecting irregularities in images and in video</title>
		<author>
			<persName><forename type="first">O</forename><surname>Boiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="31" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Flow mosaicking: real-time pedestrian counting without scene-specific learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="1093" to="1100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sparse reconstruction cost for abnormal event detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="3449" to="3456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Social force model for pedestrian dynamics</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Helbing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page">4282</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Modelling crowd scenes for event detection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ernesto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Andrade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Fisher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>ICPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A system for learning statistical motion patterns</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maybank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1450" to="1464" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Sparse representation for signal classification</title>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Aviyente</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A principled approach to detecting surprising events in video</title>
		<author>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Anomalous video event detection using spatiotemporal context</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tsaftaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="323" to="333" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Observe locally, infer globally: a space-time MRF for detecting abnormal activities with incremental updates</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Anomaly detection in extremely crowded scenes using spatio-temporal motion pattern models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nishino</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient sparse coding algorithms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Battle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">801</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Human-assisted motion annotation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Tensor completion for estimating missing values in visual data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Musialski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wonka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sparse non-negative tensor factorization using columnwise coordinate descent</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wonka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="649" to="656" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Segmentation of multivariate mixed data via lossy data coding and compression</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Derksen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1546" to="1562" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Anomaly detection in crowded scenes</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bhalodia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="1975" to="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Robust visual tracking using l1 minimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<editor>ICCV, IEEE</editor>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1436" to="1443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sparse coding with an overcomplete basis set: a strategy employed by v1?</title>
		<author>
			<persName><forename type="first">B</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="3311" to="3325" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Emergence of simple-cell receptive field properties by learning a sparse code for natural images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Olshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="issue">6583</biblScope>
			<biblScope unit="page" from="607" to="609" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Abnormal crowd behavior detection using social force model</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Ramin Mehran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Oyama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Floor fields for tracking in high density crowd scenes</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Saad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Adaptive background mixture models for real-time tracking</title>
		<author>
			<persName><forename type="first">C</forename><surname>Stauffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Grimson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Event monitoring via local motion abnormality detection in non-linear subspace</title>
		<author>
			<persName><forename type="first">I</forename><surname>Tziakos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cavallaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="1881" to="1891" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised activity perception in crowded and complicated scenes using hierarchical Bayesian models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Grimson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="539" to="555" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Robust face recognition via sparse representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Chaotic invariants of Lagrangian particle trajectories for anomaly detection in crowded scenes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Modeling crowd turbulence by many-particle simulation</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">46105</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Discriminative subvolume search for efficient action detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On the consistency of feature selection using greedy least squares regression</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="555" to="568" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Online detection of unusual events in videos via dynamic sparse coding</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Detecting unusual activity in video</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Visontai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">D. degree from State Key Laboratory of Robotics</title>
	</analytic>
	<monogr>
		<title level="m">) from 2009 to 2011, respectively. Now, he is an Associate Researcher of the Chinese Academy of Sciences. His current research interests include compute vision, pattern recognition, multimedia, and robot navigation</title>
		<meeting><address><addrLine>Shenyang, China; Shanghai</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Yang Cong received the B.Sc. degree from Northeast University ; National University of Singapore (NUS) and Nanyang Technological University (NTU</orgName>
		</respStmt>
	</monogr>
	<note>2004, and the Ph</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">award from the Electrical Engineering and Computer Science Department at Northwestern University. Ji Liu received his master degree in Computer Science at the Arizona State University, and bachelor degree in Automation at the University of Science and Technology of China</title>
	</analytic>
	<monogr>
		<title level="m">Yuan was a recipient of the Doctoral Spotlight Award from the IEEE Conference on Computer Vision and Pattern Recognition (CVPR&apos;09), a recipient of the elite Nanyang Assistant Professorship from Nanyang Technological University, and a recipient of the Outstanding</title>
		<meeting><address><addrLine>Wuhan, China; Singapore; Singapore</addrLine></address></meeting>
		<imprint/>
		<respStmt>
			<orgName>Junsong Yuan received the Ph.D. and M.Eng degrees from Northwestern University, Chicago, IL, and National University of Singapore, respectively ; Huazhong University of Science and Technology ; Nanyang Assistant Professor at Nanyang Technological University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
	<note>His current research interests include computer vision, video data mining and content analysis, and multimedia search. Now he is a Ph.D. student in the Department of Computer Sciences at the University of Wisconsin-Madison. His research interests include optimization, machine learning and the application in computer vision and graphics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
