<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large-scale rice mapping under different years based on time-series Sentinel-1 images using deep semantic segmentation model</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-02-26">26 February 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Pengliang</forename><surname>Wei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Applied Remote Sensing and Information Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<postCode>310058</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">College of Environmental Resource Sciences</orgName>
								<orgName type="laboratory">Key Laboratory of Environment Remediation and Ecological Health</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<postCode>310058</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dengfeng</forename><surname>Chai</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Earth Sciences</orgName>
								<orgName type="laboratory">Key Laboratory of Geoscience Big Data and Deep Resource of Zhejiang Province</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<postCode>310027</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tao</forename><surname>Lin</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">College of Biosystems Engineering and Food Science</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<postCode>310058</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chao</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Applied Remote Sensing and Information Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<postCode>310058</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">College of Environmental Resource Sciences</orgName>
								<orgName type="laboratory">Key Laboratory of Environment Remediation and Ecological Health</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<postCode>310058</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Meiqi</forename><surname>Du</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Applied Remote Sensing and Information Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<postCode>310058</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">College of Environmental Resource Sciences</orgName>
								<orgName type="laboratory">Key Laboratory of Environment Remediation and Ecological Health</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<postCode>310058</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jingfeng</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Applied Remote Sensing and Information Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<postCode>310058</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">College of Environmental Resource Sciences</orgName>
								<orgName type="laboratory">Key Laboratory of Environment Remediation and Ecological Health</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<postCode>310058</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Institute of Applied Remote Sensing and Information Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<postCode>310058</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Large-scale rice mapping under different years based on time-series Sentinel-1 images using deep semantic segmentation model</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-02-26">26 February 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1016/j.isprsjprs.2021.02.011</idno>
					<note type="submission">Received 23 September 2020; Received in revised form 10 February 2021; Accepted 11 February 2021</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Sentinel-1 images Multi-temporal Rice mapping Large-scale Deep semantic segmentation</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Identifying spatial distribution of crop planting in large-scale is one of the most significant applications of remote sensing imagery. As an active remote sensing system, synthetic aperture radar (SAR) provides high-resolution polarimetric information of land covers. Nowadays, it is possible to carry out continuous multi-temporal analysis of crops in large-scales since an increased number of spaceborne SAR systems has been launched. This paper formulates rice mapping as a semantic segmentation problem and proposes to use deep learning techniques to exploit the phenological similarity of rice production to identify the rice distribution in large-scales. The study area (i.e., about 58504 km 2 ) located in Arkansas River Basin is selected to develop an adapted U-Net for largescale rice mapping. The Sentinel-1 data in previous years (i.e., data collected in 2017 and 2018) are used to train and fine-tune the network, and current season data (i.e., data collected in 2019) is selected to test the robustness of the network. Experimental results show that the proposed method achieves the state-of-the-art performance as it benefits from the spatial characteristics and phenological similarity of rice. The experiments of rice extraction in different planting pattern regions and extracted features visual projection are conducted to explain the features mined by the adapted U-Net. Furthermore, the advantages of temporal generalization in large-scale are validated by the comparison between space migration and time migration, which indicates that the difference of rice in different years is smaller than that of rice in different spaces. Finally, the issues for operational implementation are discussed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Rice mapping is an important task in remote sensing as rice feeds nearly half of the world's population. Timely spatial distribution of rice planting in large-scales is a kind of basic information for many tasks such as crop growing condition monitoring, yield prediction and so on <ref type="bibr" target="#b38">(Matsuda et al., 2001;</ref><ref type="bibr" target="#b62">Son et al., 2013;</ref><ref type="bibr" target="#b63">Soontranon et al., 2015;</ref><ref type="bibr" target="#b82">Zhou et al., 2017)</ref>. In the past decades, crop classification has attracted more and more attention in the field of space remote sensing, and the scope of crop mapping gradually changed from small-scale to large-scales <ref type="bibr" target="#b80">(Zhang et al., 2016;</ref><ref type="bibr" target="#b5">Cai et al., 2018;</ref><ref type="bibr" target="#b18">Griffiths et al., 2019;</ref><ref type="bibr" target="#b74">Yang et al., 2019)</ref>, which means a leap from theoretical methods to applications. Currently, large-scale crop mapping is mainly based on optical data sets, such as MODIS <ref type="bibr" target="#b69">(Wang et al., 2012;</ref><ref type="bibr" target="#b77">Zhang et al., 2017)</ref>, Landsat <ref type="bibr" target="#b15">(Dong et al., 2016;</ref><ref type="bibr" target="#b43">Oliphant et al., 2019;</ref><ref type="bibr" target="#b50">Qiu et al., 2017;</ref><ref type="bibr" target="#b66">Teluguntla et al., 2018)</ref> and Sentinel-2 <ref type="bibr">(Liu et al., 2020)</ref>. Although some of these methods effectively increase the temporal resolution of the data by using multi-source data <ref type="bibr" target="#b49">(Phuong and Yuei-An, 2015)</ref>, there is still a problem of missing data due to weather conditions. Especially for rice mapping, precisely because of the particularity of the rice growing environment, the rice growing area is frequently cloud covered during the critical discrimination period (i. e., transplanting period), which make it difficult to obtain effective continuous-time optical remote sensing images and limit the rice recognition accuracies <ref type="bibr" target="#b36">(Mandal et al., 2018;</ref><ref type="bibr" target="#b60">Singha et al., 2019)</ref>. With the development of remote sensing technology, the emergence of synthetic aperture radar (SAR), which has all-weather and all-time imaging capacity, has effectively overcome the above issue <ref type="bibr" target="#b2">(Bargiel, 2017;</ref><ref type="bibr" target="#b20">Guo et al., 2018;</ref><ref type="bibr" target="#b72">Xie et al., 2019;</ref><ref type="bibr" target="#b55">Schlund and Erasmi, 2020)</ref>. Moreover, an increasing number of SAR images are being generated as the number of space-borne SAR in orbits increases, and there are some typical SAR systems have been widely used in the civilian applications, such as Cband RADARSAT-2 <ref type="bibr" target="#b65">(Staples et al., 2017;</ref><ref type="bibr" target="#b25">Jia et al., 2013)</ref> and Sentinel-1 <ref type="bibr" target="#b79">(Zhang et al., 2019;</ref><ref type="bibr" target="#b12">Chen et al., 2020)</ref>, L-band ALOS/PALSAR-2 <ref type="bibr" target="#b58">(Shimada et al., 2017)</ref>, X-band TerraSAR-X/Tandem-X <ref type="bibr" target="#b9">(Chen et al., 2017)</ref>. Therefore, it is feasible to adopt multi-temporal SAR images for accurate crop mapping and other applications based on these on-orbit systems <ref type="bibr" target="#b61">(Skriver et al., 2011)</ref>.</p><p>It is challenging to collect high-quality training samples and train a reliable model for crop mapping in large-scales. Currently, although a number of small-scales crop classification models have been proposed for SAR images <ref type="bibr" target="#b37">(Mascolo et al., 2016;</ref><ref type="bibr" target="#b20">Guo et al., 2018;</ref><ref type="bibr" target="#b22">Hariharan et al., 2018)</ref>, these models cannot be directly expanded to the large-scales since these algorithms were proposed for specific regions with limited crop types and training datasets. Consequently, for most of the researches devoted to large-scale mapping based on SAR data, traditional classification models were selected, and trained using the highly reliable sample sets <ref type="bibr" target="#b39">(Matton et al., 2015;</ref><ref type="bibr" target="#b28">Kussul et al., 2016;</ref><ref type="bibr" target="#b29">Kussul et al., 2018;</ref><ref type="bibr" target="#b14">Dingle Robertson et al., 2020)</ref>. Generally, the classifiers for large-scale mapping can be divided into two categories: (1) algorithms based on the threshold; (2) algorithms based on machine learning. Some of them are listed in Table <ref type="table" target="#tab_0">1</ref>. The seasonal pattern differences of temporal signature of backscattering characteristics between different crops are analyzed in the former methods, and then the seasonal pattern similarity of the same crops or the threshold method is used to achieve the purpose of crop classification. Random Forest (RF) and Support Vector Machine (SVM) classifiers are usually used in the latter one, and the general step is to use various polarization scattering parameters as input features, and then a pixel or object-based model is built to classify the crop types.</p><p>In addition, more and more researchers tend to use machine learning algorithms for large-scale crop mapping as time goes on. Although crop classification benefit from these methods, they have their limitations and disadvantages, described as follows.</p><p>First, global spatial information in an image are not utilized in the above crop classification algorithms, instead, only a small local window around the target pixel is involved in the classification of a pixel. Second, phenological similarity of images in different years is not explored to identify the rice distribution as only images in one-year are input for classification. Third, all these per-pixel based methods (i.e., traditional machine learning algorithms) are performed pixel by pixel. The computation efficiency may be very low when complex computation is involved in each pixel classification.</p><p>In recent years, there is an expansion in using convolutional neural networks (CNNs) as a new classifier <ref type="bibr" target="#b26">(Kulkarni, 2018;</ref><ref type="bibr" target="#b24">Hossain et al., 2019)</ref>. Originally, it was developed to classify an image or a window into one of some classes <ref type="bibr" target="#b32">(Lecun et al., 1998;</ref><ref type="bibr" target="#b30">Krizhevsky et al., 2012;</ref><ref type="bibr" target="#b59">Simonyan and Zisserman, 2014)</ref>, and has been widely applied in remote sensing community <ref type="bibr" target="#b75">(Yuan et al., 2020)</ref>. Generally, two main CNNsbased methods are used to achieve crop classification: (1) Patch-based CNNs; (2) Deep semantic segmentation models. Some of them are listed in Table <ref type="table" target="#tab_1">2</ref>. The CNNs have been well applied in crop mapping. For the patch-based CNNs, two schemata have been developed to deliver pixelwise classification required by rice mapping. First, a window around each pixel is cropped to input to CNNs for classification. Second, neighboring pixels are grouped into a sub-image to be input to CNNs for further classification. Although CNNs are powerful classifiers, its performance is limited by the above manner of classification as different sub-images (or blocks) are classified independently and global features cannot be extracted from a small local sub-image. Moreover, the above  schema is very inefficient as many (same as the number of pixels) subimages need to be classified, which resulting a low calculation efficiency for large-scales crop mapping, and unsuitable for practical application. For deep semantic segmentation models, fully convolutional neural networks have been developed to deliver a pixel-level classification for an input image, which is normally formulated as semantic segmentation problem <ref type="bibr" target="#b53">(Ronneberger et al., 2015;</ref><ref type="bibr" target="#b1">Badrinarayanan et al., 2017;</ref><ref type="bibr">Chen et al., 2018)</ref>, and perform well in computer vision tasks <ref type="bibr" target="#b52">(Ren et al., 2015;</ref><ref type="bibr" target="#b54">Rui et al., 2018)</ref>. Compared with the patch-based CNNs, not only the global features of the image can be learned by deep semantic segmentation models, but also the end-to-end classification, which greatly improves the calculation efficiency. Among various DCNNs based on deep semantic segmentation networks, U-Net <ref type="bibr" target="#b53">(Ronneberger et al., 2015)</ref> performs well in segmenting different biomedical images with fewer samples, and has also been widely applied in remote sensing community in recent years <ref type="bibr" target="#b44">(Pan et al., 2020)</ref>. However, there are fewer studies to explore the potential of SAR data for large-scale crop mapping and the phenological similarities of the same crops between different years using the deep CNNs (DCNNs), mostly focused on the application of optical data and the research of model spatial migration ability instead.</p><p>This paper presents a work on identifying rice distribution in the Arkansas River Basin using the multi-temporal Sentinel-1 images in the framework of semantic segmentation. First, rice mapping is formulated as a problem of semantic segmentation. Spatial and polarization characteristics from entire multi-temporal data sets are exploited to segment Sentinel-1 images. Second, correlation among multi-temporal data is exploited for semantic segmentation, as the input is a multi-channel image, which is an integration of multi-temporal images. Third, U-Net is adapted to segment the input image and generate a map of rice distribution. Furthermore, in order to use the phenological characteristics of rice to identify its distribution information in advance, the historical data with different years are used to train and fine-tune the deep learning network, respectively. Various experiments based on multitemporal Sentinel-1 data sets are conducted to evaluate the proposed method.</p><p>This study mainly investigates the following research questions (RQ): (RQ1) How well does the adapted U-Net perform with different polarization channels and temporal resolution through pixel-by-pixel evaluation for large-scale rice mapping? (RQ2) What features are learned from the adapted U-Net and theirs advantages compared with the original input features? (RQ3) What is the optimal methodology of model migration for the current season rice mapping in large-scales?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Study area and datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Study area</head><p>The fertile land of Arkansas River Basin (89</p><formula xml:id="formula_0">• 50 ′ 46 ′′ W ~ 91 • 17 ′ 39 ′′ W, 33 • 4 ′ 22 ′′ N ~ 36 • 58 ′ 10 ′′ N)</formula><p>is the main source of rice production in the United States. Its daily average maximum temperature in summer is 34.2 ℃, daily average minimum temperature in winter is minus 3 ℃ and annual rainfall is 1220 mm. The main crops in the Arkansas River Basin also includes cotton, corn, soybean, and so on. Therefore, the main rice growing area in Arkansas River Basin (i.e., about 412 km × 142 km, ≈ 58504 km 2 ) is selected as the study area to explore the temporal generalization ability of deep learning network models constructed based on crop phenological characteristics. The location of the study area is shown in Fig. <ref type="figure" target="#fig_0">1</ref>, and the specific pixel count of rice in the study area in different years from Cropland Data Layer (CDL, https://na ssgeodata.gmu.edu/CropScape/) are listed in Table <ref type="table">3</ref>.</p><p>The method of rice cultivation in the study area is direct seeding in land. A large amount of water is injected into the paddy field after sowing. Moreover, intermittent irrigation is also required during its tillering stage. The growing cycle of the main crops in the experimental area is from April to September in each year, and the specific crop calendar of the main crops in the study area is shown in Fig. <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Sentinel-1 data sets</head><p>The Sentinel-1 images covering the major rice planting areas of Arkansas River Basin, are selected and downloaded from (https://search .asf.alaska.edu/). The image acquisition dates are from April to September in 2017, 2018 and 2019, covering the whole growing stages of main crops (i.e., planting, emerging, heading and maturing) in each year. The study area is covered by three Sentinel-1 image tiles (i.e., blue boxes in the Fig. <ref type="figure" target="#fig_0">1</ref>). VV (vertical transmit, and vertical receive) and VH (vertical transmit, and horizontal receive) polarization channels are provided by the Sentinel-1 image of IW mode. The multi-temporal Level-1 Ground Range Detected (GRD) products are processed to backscatter coefficient (σ • ) in decibels (dB), and projected to ground range using the Albers Equal Area Conic. The Sentinel-1 datasets are preprocessed in SNAP software using these steps: (1) apply orbit file; (2) thermal noise removal; (3) radiometric calibration; (4) multi-looking, to convert the pixel spacing from 10 m to 30 m; (5) terrain corrections using SRTM; (6) Co-registration, the procedures are composed of two steps: coarse coregistration by geolocation with the orbit and system parameters, and fine co-registration by cross-correlation information between multitemporal Sentinel-1 images <ref type="bibr" target="#b70">(Wang et al., 2009)</ref>. ( <ref type="formula">7</ref>) speckle filter, multi-temporal filter with averaged structure Lee filter presented in <ref type="bibr" target="#b6">(Caves et al., 2011)</ref> is used to suppress the speckle noise to reduce the influence of coherence of radar transmission/reception. (8) SAR mosaic, in order to facilitate subsequent processing, the three multi-temporal data sets covering the study area are mosaicked.</p><p>The specific data acquisition dates are shown in Table <ref type="table" target="#tab_3">4</ref>, for the data Table <ref type="table">3</ref> The rice in the study area with different years. sets with a temporal resolution of 24 days, the first row dates are selected to be the starting dates, and total 8 time-series mosaic images are used in each year. For the data sets with a temporal resolution of 12 days, the data corresponding to all dates in Table <ref type="table" target="#tab_3">4</ref> are used in each year (i.e., the 13 time-series mosaic images). The time interval from April to May is larger than the later period, since there is no data for May 10 in 2017 and April 18 in 2019.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Reference data sets</head><p>For the ground truth data sets, USDA's CDL, which can be downloaded from the CropScape website portal, is used as the reference map to generate the training, validation and test datasets. The CDL map is generated from Landsat Thematic Mapper imagery, and ground surveys conducted by related departments, such as National Land Cover Dataset, and Common Land Unit. CDL's space resolution is 30 m and the corresponding projection plane is the Albers Equal Area Conic. More than 100 crop types are provided in the CDL, and it has a high mapping accuracy for the major crops. In recent years, some scholars have used the datasets to carry out research on crop mapping and proved its reliability <ref type="bibr" target="#b73">(Xu et al., 2020;</ref><ref type="bibr" target="#b21">Hao et al., 2020)</ref>. Hence, CDL data sets, which corresponded to the selected Sentinel-1 data sets, from 2017, 2018 and 2019 are collected as the reference data, and the crops covered in the study area are summarized as rice and non-rice. The optical image from Google earth, Sentinel-1 VH mosaic, and the reference map of the study area are shown in Fig. <ref type="figure" target="#fig_2">3</ref>.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Structure of training, validation and test samples</head><p>In order to make fully use of the temporal correlation between multitemporal data, the multi-channel input is formed according to the acquisition time sequence of the multi-temporal images, as illustrated in Fig. <ref type="figure" target="#fig_4">4</ref>. In addition, mainly because that the size of the DCNNs increases greatly with larger input image, it is impossible to directly classify entire Sentinel-1 mosaic images using a standard desktop computer with limited GPU memory. Therefore, as shown in Fig. <ref type="figure" target="#fig_4">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Rice mapping based on deep learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Rice mapping via semantic segmentation</head><p>Deep CNNs are employed to explore both the spatial and polarization characteristics from the whole multi-temporal data sets to achieve semantic segmentation. It results in an improved accuracy of rice mapping. As illustrated in Fig. <ref type="figure" target="#fig_6">5</ref>, features at 5 different levels can be extracted from the multi-temporal image through the encoder of the left part, then 2 confidence maps can be obtained by magnifying these downsampled features through the decoder of the right part, and their resolution is the same as the input image. Finally, each pixel in the image is assigned to the category with the highest confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">DCNN architecture</head><p>The employed DCNN for semantic segmentation is an encoderdecoder network adapted from U-Net <ref type="bibr" target="#b53">(Ronneberger et al., 2015)</ref>. The architecture of the adapted U-Net is illustrated in Fig. <ref type="figure" target="#fig_7">6</ref>. As shown in the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5</head><p>The number of 512 × 512 images in each data set. The input image is stored in the input layer. It is a 512 × 512 × c volume, where c is the number of channels. For the combination of VV and VH polarization channels, c = 16 when the image temporal resolution is 24 days (i.e., 8 time-series images); c = 26 when the image temporal resolution is 12 days (i.e., 13 time-series images).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">DCNN training</head><p>The network presented in the above subsection consists of convolution, deconvolution and transposed convolution layers. The weights and biases for each filter in the above layers are free. Such free parameters need to be trained using the training and validation data sets. It is achieved by optimizing these parameters such that the predicted label maps are as close as possible to their corresponding true label maps.</p><p>Training deep networks is time-consuming, and the training speed can be accelerated by specifying a high learning rate. However, this may cause the gradient of the network to explode or grow uncontrollably, hindering the success of network training. Consequently, in order to train the network stably with a higher learning rates and in the presence of outliers, in the process of training, the gradient is rescaled based on a threshold (i.e., Norm-based gradient clipping) to keep the direction of the gradient unchanged <ref type="bibr" target="#b3">(Bishop, 2006;</ref><ref type="bibr" target="#b46">Pascanu et al., 2012;</ref><ref type="bibr" target="#b40">Murphy, 2012)</ref>. Moreover, a regularization term has been added to the weights of the loss function to further avoid overfitting, and the specific mathematical expression is formulated as follows:</p><formula xml:id="formula_1">E R (θ) = E(θ) + λΩ(w)</formula><p>(1)</p><formula xml:id="formula_2">Ω(w) = 1 2 w T w (2)</formula><p>where, E(θ) is the loss function, w is the weight vector, λ is the regularization factor (coefficient) which is set to 0.0001, Ω(w) is the regularization function. In addition, the gradient threshold is set to 0.05, the gradient is scaled so that the norm equals gradient threshold when the norm of the gradient of a learnable parameter is higher than gradient threshold.</p><p>Then, the Stochastic Gradient Descent-Momentum (SGDM) schema <ref type="bibr" target="#b40">(Murphy, 2012)</ref> is used to update the parameters involved in the network, the specific mathematical expression can be formulated as follows:  where, ℓ is the iteration number, α is the learning rate which is set to 0.05, θ is the parameter vector, γ determines the contribution of the previous gradient step to the current iteration, which is set to 0.9.</p><formula xml:id="formula_3">θ ℓ+1 = θ ℓ − α⋅dθ + γ(θ ℓ − θ ℓ− 1 ) (3)</formula><p>All the parameters are determined when the network training is completed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Rice mapping</head><p>As described in Section 3.1, rice mapping is achieved via semantic segmentation of an input image. Once the network training is completed, all parameters are available for use. It facilitates inference via a forward pass through the well-trained network: a 512 × 512 given Sentinel-1 image is imported to the input layer, and then convolved layer-by-layer, and finally reaches the output layer storing per pixel class scores, which leads to a class-label map.</p><p>An example is presented in Fig. <ref type="figure" target="#fig_8">7</ref>. Left and middle are two confidence maps stored in the output layer. Each pixel value indicates the probability of the underlying pixel being rice or not. By comparing the two confidences, the one with high probability is selected as the final class. A final rice map (right) is derived by selecting a class for each pixel. The rice map of the entire study area is seamed from a set of 512 × 512 label maps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Evaluation parameters for quantitative analysis</head><p>The evaluation is based on a pixel-by-pixel comparison between the mapping results and CDL maps, and the scores including user's accuracy, producer's accuracy, overall accuracy, Kappa coefficient and F1 score <ref type="bibr" target="#b16">(Foga et al., 2017)</ref>.</p><p>In addition, quantitative analysis is carried out to illustrate the separability between rice and other crops based on backscattering characteristics. The separability indices include Bhattacharyya distance, divergence, Jeffries-Matusita (JM) and transform separability, among which, JM distance has been proven to be more effective <ref type="bibr" target="#b68">(Ullah et al., 2012;</ref><ref type="bibr">Liu et al., 2020)</ref>. It is defined as follows:</p><formula xml:id="formula_4">J = 2⋅(1 − e − B ) (4) B = 1 8 (m 1 − m 2 ) 2 2 δ 2 1 + δ 2 2 + 1 2 In[ δ 2 1 + δ 2 2 2δ 1 δ 2 ] (<label>5</label></formula><formula xml:id="formula_5">)</formula><p>where, B represents the Bhattacharyya distance on a certain feature dimension. δ 2 i is the variance of class i, i = 1,2; m i represents the mean value of feature of class i. The value range of JM distance is [0, 2], the two classes can be completely distinguished when it equals to 2, and they are completely confused when it equals to 0 <ref type="bibr" target="#b64">(Sousa et al., 2003)</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results</head><p>In this section, the scattering characteristics of crops is analyzed to verify the feasibility of modeling based on crop phenological characteristics, and then the multi-temporal Sentinel-1 images with different polarization channels and temporal resolutions are used to validate the model generalization based on rice phenology and investigate the performances of the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">The polarization characteristics of rice and other crops</head><p>The growing period is composed of seeding, stem elongation, heading, and maturing. In order to illustrate the feasibility of backscattering characteristics for rice mapping, and the feasibility of model temporal generalization using crop phenological characteristics, this section first analyzes the differences of backscattering coefficient between rice and other crops in the same year, and then explores the similarity of rice in different years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">The differences of polarization characteristics between rice and other crops</head><p>In this experiment, in order to verify the backscattering characteristics can be used to distinguish rice from other crops, 10,000 sample points are randomly selected for each main crops (i.e., rice, cotton, corn and soybean) in the study area. Then, the average values of the backscattering coefficients corresponded to each category in each year are computed and the differences between different crops in 2017 are plotted in Fig. <ref type="figure" target="#fig_9">8</ref>.</p><p>It can be seen from Fig. <ref type="figure" target="#fig_9">8</ref> that the regardless of the VV or VH polarization channels, from a radiometric perspective rice can be differentiated to some extent from other crops, but not clearly. For the VH polarization channel, the backscattering coefficient of rice in this ecosystem is always lower than that one of the other crops mainly for two reasons: 1) the water coverage at beginning of the crop season, and 2) the lower biomass during the vegetative period. As we expected, the change trend of the rice's overall backscatter coefficient decreases first, mainly because that the paddy field irrigated after sowing, then, the backscatter coefficient gradually increases after emergence and eventually stabilizes before harvesting, which is consistent with the change of rice growth cycle in the study area. Similar conclusions can be drawn for VV polarization channels. In addition, there are similar trends in cotton, the main reason is that cotton is covered with a film at the beginning of planting, and the film also causes specular reflection, which results in a decreases (i.e., similar to that of rice) of backscattering coefficient in its early growth stages.</p><p>Furthermore, the JM distance is calculated on 10,000 homogeneous sample windows (i.e., with the size of 5 × 5) for both VV and VH channels at each acquisition time, then the average value of these JM distances is used to be the final indicator of separability. The specific JM distances between rice and other crops in each year are shown in Table <ref type="table" target="#tab_4">6</ref>, from which it can be seen that there will be a certain degree of mixing phenomenon since the maximum JM distance between rice and other crops is around 1.3 (The value range of JM is 0 ~ 2, the two classes can be completely distinguished when it equals to 2). The main reason is that the calculation of JM is just based on the temporal signature, but ignoring the potential characteristics of multi-temporal data. These potential characteristics including multi-scale spatial features, texture features and so on, which can be captured by the DCNNs. Consequently, it is expected that the proposed frame-work can improve the separability between rice and non-rice by extracting the potential characteristics in the time-series Sentinel-1 images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">The trend of polarization characteristics in different growth years of rice</head><p>In the case of phenological characteristics of rice, the images from VH and VV polarization channels are used to validate the similarity of rice in different years, respectively. Similarly, the average value of the backscattering coefficients corresponded to 10,000 rice points randomly selected from each year is computed and plotted in Fig. <ref type="figure" target="#fig_10">9</ref>, from which we can draw the same conclusion as the previous section for the change of rice growth cycle in each year. Although the temporal signature of the backscattering coefficient of rice are very closed between different years, there are still slight differences. The main reason may be that the annual rice planting time in the study area is not exactly the same and may be affected by natural disasters, so it shows differences in the time-varying trend of the backscatter coefficients. For instance, the study area  experienced severe flooding during late May and early June 2019, as reported from the NASA Disasters Program (https://maps.disasters.nasa. gov/arcgis/apps/MapSeries/index.html?appid = 23ae6d01282047-d6ae0f6e5d84f91d70). Consequently, the change of the rice temporal signature in the early stage of 2019 is different from that of 2017 and 2018. (i.e., The second time point to the fourth time point in the Fig. <ref type="figure" target="#fig_10">9</ref>). Furthermore, the specific JM distances of rice between different years are calculated using the same method as above (i.e., Calculated based on homogeneous sample windows), and listed in Table <ref type="table" target="#tab_5">7</ref>. Consistent with the temporal signature, the JM distances of rice between 2019 and other years (i.e., 2017 or 2018) are slightly higher than that between 2017 and 2018. Although there are differences, the distance expressed in JM is still relatively closed to 0. Overall, the backscattering characteristics can be used to be the input of DCNNs to further explore the phenological characteristics of rice in different years under actual natural conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Rice mapping results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Results of U-Net for different polarization channels</head><p>(RQ1) Considering the universality of rapid large-scale rice mapping, we explore the optimal input of the adapted U-Net using the original single-polarization channel (i.e., VV or VH) and dual-polarization channel (i.e., VV + VH), respectively.</p><p>Sentinel-1 data sets with a temporal resolution of 24 days are used to be the input of U-Net model in this section. The corresponding evaluation parameters of the test data sets (i.e., data collected in 2019) for U-Net are listed at the bottom three rows of Table <ref type="table" target="#tab_6">8</ref>. We can see that the mapping result of the VH polarization channel for rice is better than that of the VV polarization channel, which is the same as the conclusion of the relevant literatures <ref type="bibr" target="#b41">(Nguyen et al., 2016)</ref>. When the VV polarization channel are replaced by the VH polarization channel, the user's accuracy, overall accuracy, Kappa coefficient and F1score are improved by 18%, 6%, 0.16 and 0.12, respectively. The mapping result of rice reaches the highest when both the VH and VV channels are used as the input of the adapted U-Net model, and the corresponding producer's accuracy, user's accuracy, overall accuracy, Kappa coefficient and F1 score of the test set have reached 86.44%, 74.01%, 90.60%, 0.74 and 0.80, respectively.</p><p>Consequently, in the follow-up experiments, the VV + VH is selected to be the input of the networks in order to achieve better rice mapping results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">U-Net vs other networks using the images with different temporal resolutions</head><p>(RQ1) In order to verify that the adapted U-Net has better robustness for large-scale rice mapping, we compare U-Net with traditional machine learning algorithm (i.e., RF), and other DCNNs, such as SegNet <ref type="bibr" target="#b1">(Badrinarayanan et al., 2017)</ref>, DeepLab <ref type="bibr">(Chen et al., 2018)</ref> and FCN <ref type="bibr" target="#b35">(Long et al., 2015)</ref>. These DCNN models are widely used for semantic segmentation in the computer vision tasks. The combination of the two polarization channels (i.e., VV + VH) of multi-temporal Sentinel-1 images with different temporal resolutions (i.e., 24 and 12 days) are selected as the inputs of these models.</p><p>The validation (i.e., data collected in 2018) and test (i.e., data collected in 2019) results based on different network structures using 24-day interval images are listed in Table <ref type="table" target="#tab_6">8</ref>. By comparing the results, we found that the rice mapping results of the RF classifier are the worst. The temporal generalization ability of the model shows weak performance, its rice user's accuracy, the Kappa coefficient, and F1 in the test data set are only 45.02%, 0.47 and 0.59, which are decreased by 24%, 0.21 and 0.17 compared with those of the validation data sets. However, it is interesting to see that RF achieves equal/ better PA (i.e., producer's accuracy) compared with U-Net, but worse UA (i.e., user's accuracy), the main reason is that only the time series information of a single pixel is utilized by RF classifier. As reported in Fig. <ref type="figure" target="#fig_9">8</ref> and Table <ref type="table" target="#tab_4">6</ref>, there will be a mixing phenomenon between rice and other crops, when only the original features based on single pixel are used to express crops, and it will lead to high PA, but low UA. Among the results of DCNNs, as reported in Table <ref type="table" target="#tab_6">8</ref>, the adapted U-Net network performs as good as DeepLab, and outperforms both of the FCN and SegNet models, and by comparing the comprehensive evaluation parameters of the validation data sets and test data sets, the adapted U-Net, DeepLab and SegNet models have better stability for rice mapping. However, there are still many classification errors for these models. Mainly because of the large image temporal resolution (i.e., 24 days), which results in a large difference in the change of rice phenological characteristics between different years, and further makes the lower rice mapping results in the current season. Therefore, in order to improve the accuracy and stability of the rice mapping based on the adapted U-Net model, it is necessary to increase the frequency of image acquisition. In addition, the results of RF classifier are no longer listed in the following experiments due to its weak performance in temporal generalization.</p><p>Consequently, the data sets corresponding to all of the dates (i.e., 12day interval images) listed in Table <ref type="table" target="#tab_3">4</ref> are used to train these deep networks, and identify the rice distribution in 2019. Furthermore, we add the results of Long-short term memory (LSTM) model <ref type="bibr" target="#b17">(Gers et al., 2003;</ref><ref type="bibr" target="#b57">Shi et al., 2015)</ref>, which was originally applied to speech recognition problems to process the long time series data. Mainly because that the LSTM is modeled by time series features, some scholars have applied it to crop classification and achieved state-of-the-art results <ref type="bibr" target="#b83">(Zhou, et al., 2019)</ref>. Similarly, for LSTM model, the pixel points collected from 2017 and 2018 are selected to be training data sets and validation data sets, and the pixel points collected from 2019 are selected to be the test data sets. The results based on different network structures using 12-day interval images are listed in Table <ref type="table" target="#tab_7">9</ref>.</p><p>As reported in Table <ref type="table" target="#tab_7">9</ref>, regardless of the validation set or the test set, the accuracies of all DCNNs are significantly improved compared with the results based on the 24-day interval images. The rice mapping results of DCNNs are higher than those of the LSTM model, since multi-level spatial and polarization characteristics covering different regions of the input image are captured by the DCNNs. Among the DCNNs, for the mapping results of the validation data sets, the adapted U-Net performs as good as the SegNet and DeepLab models, and their corresponding Kappa coefficient and F1 are over 0.85. For the mapping results of the test data sets, the results of the adapted U-Net network are the highest, and its overall accuracy, Kappa coefficient and F1 score have reached 94.41%, 0.84 and 0.87. Particularly, the difference between producer's accuracy and user's accuracy is the smallest for the results of test data sets based on adapted U-Net, which is just 0.03%. At the same time, the difference between the validation and the test results of adapted U-Net is smallest among these models, which further proves that the adapted U-Net has better stability for rice mapping in large-scales under different years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Computational complexity analysis</head><p>The DCNNs require a much shorter test time than RF and LSTM in the experiment of rice mapping in large-scales, as shown in Fig. <ref type="figure" target="#fig_0">10</ref>. The prediction processes of RF and LSTM models are up to 92.9 and 133.9 min, respectively, which are much longer than FCN (0.8 min), SegNet (1.8 min), DeepLab (1.9 min) and adapted U-Net (1.2 min). Mainly because that different pixels are sequentially input into the cost function and classified independently, and the final category information is output in turn, the number of cycles of this process is equal to the total number of pixels in the image, which results in a low computational efficiency.</p><p>Among the DCNNs, the time required for prediction process of FCN model is the shortest, mainly because that the structure of the network is relatively simple, after the downsampling is executed, only the final downsampling result is directly enlarged to the original image size, while the deep abstract features and the shallow low-level features are not combined. However, since the deep convolutional layer of the FCN is based on the improvement of the fully connected layer, it contains more parameters (130 M) than other DCNNs. On the contrary, DeepLab reduces the parameters of the network by using the residual convolution module, and it (20 M) contains fewer parameters than SegNet (29 M) and adapted U-Net (31 M). However, the depth of DeepLab is deeper than other DCNNs, which results in a longer time-consuming for the corresponding prediction process. In general, the much shorter test time demonstrates the higher applicability of DCNNs than per pixel-based methods (i.e., RF and LSTM) for large-scales mapping. The extraction errors of different years corresponded to two types of rice planting pattern regions (i.e., regular and irregular rice planting areas with the size of 200 × 200) are selected for comparative analysis, as shown in Fig. <ref type="figure" target="#fig_12">11</ref>. For the regular rice planting area (i.e., Fig. <ref type="figure" target="#fig_13">11 (a)</ref>), although there are differences in the distribution of rice in the year of 2017, 2018 and 2019, the overall planting of rice has always been uniform (i.e., small changes in planting areas and regular farming).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Understanding of the features learned by the adapted U-Net model</head><p>From the extraction errors it can be seen that compared with LSTM, the DCNNs can extract rice distribution information more stable for the same regular rice planting area over time. The reason is that LSTM only relies on the time series information of a single pixel point and ignores the spatial relationship between pixel points. Consequently, there will be more inaccurate in extraction of rice distribution for LSTM model, when the difference of actual rice growing cycle (i.e., difference of planting time, and caused by damages) between the prediction year and the training year is obvious. Among DCNNs, the results extracted by   The main reason is that the adapted U-Net performs a total of four times of upsampling for the input data, and uses concatenation in the same stage, instead of directly supervising and loss back propagation on deep high-level semantic features, so as to ensure that the finally restored feature map incorporates more shallow low-level feature, at the same time, the features of different scales are merged, and the multi-scale prediction can be performed. Four times of up-sampling also makes the segmentation map recover more refined information. However, due to the influence of mixed pixels at the boundaries between different fields, errors still inevitably appear in the classification results of boundary. In addition, the multi-temporal data is input into the network as multi-channel data. Consequently, while extracting multi-scale spatial features, the adapted U-Net also explores the correlation between multi-temporal data.</p><p>Furthermore, crop-specific spatial heterogeneity from complicated original multi-temporal Sentinel-1 data and the data processed by the deep learning models are analyzed using the t-distributed stochastic neighbor embedding (t-SNE) <ref type="bibr" target="#b13">(Maaten and Hinton, 2008)</ref>, which is similar to the principle of clustering. The original features and the features extracted by the network are high-dimensional features, which are not easy to directly measure the differences between the two types of feature sets. Then, 10,000 pixel points each of rice and non-rice are randomly selected in each year, the original features and extracted features corresponding to these points are nonlinearly projected to a 2-D plane for visualization using t-SNE. As reported in Fig. <ref type="figure" target="#fig_15">12</ref>, the features extracted by the adapted U-Net model show better separability between different classes than raw input features, after being projected into a 2-D plane by t-SNE. Samples from the same classes are better grouped based on learned features than raw input features, particularly from rice. A large number of rice (red) and non-rice (blue) samples located in direct vicinity to each other based on the original features, while the learned features of rice and non-rice samples are better separated. Moreover, the degree of aggregation of the same type of features learned by the adapted U-Net is higher than that of the features extracted by LSTM. As reported in Fig. <ref type="figure" target="#fig_16">13</ref>, whether for LSTM or adapted U-Net, the learned features of rice in different years are more evenly overlapped after the projection, which means that both models have extracted similar characteristics of rice in different years. Similarly, the feature learned by adapted U-Net has a higher degree of aggregation of rice expression in different years. It is indicated that the features extracted by the adapted U-Net contained much more useful information than raw input features for rice mapping.</p><p>In summary, the adapted U-Net shows better robustness for rice extraction in regions with different rice planting patterns over time. Both of the spatial feature (i.e., object-based feature) and similarity of the temporal characteristics (i.e., pixel-based feature) can be captured from the multi-temporal datasets by the adapted U-Net.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Comparison between space migration and time migration</head><p>(RQ3) Furthermore, the comparison between time migration in large-scale based on historical data sets and space migration based on current season data sets is analyzed to obtain the optimize model migration methodology, which can provide a basis on time-space migration for global rice mapping.</p><p>The study area is divided into three sites longitudinally, and full cross-validation is conducted by rotating sites 01, 02 and 03 in turns as the training site. The specific process is described in Fig. <ref type="figure" target="#fig_17">14</ref>. One of the sites is selected as the training site (i.e., training and validation datasets), and other two sites are used as the spatial transfer sites (i.e., test datasets). Data of the training site from 2019 is fed into different models for training, and then the rice spatial distribution of the other sites in 2019 is predicted. For the temporal generalization, the process is the same as described in section 2.4.</p><p>The specific results are shown in Fig. <ref type="figure" target="#fig_18">15</ref>, from which it can be seen that no matter which method is used, the rice prediction accuracies of Site 03 is the lowest when the model is trained in Site 01, and the situation is the same when the training and prediction positions in reverse. Particularly, when Site 02 is used as the training data sets, the rice mapping accuracy of Site 01 and Site 03 is improved compared with the former. The main reason for this phenomenon is that the rice distributed in different latitudes have different phenological characteristics, which leads to the poor spatial migration performance of the model as the latitude changes. Regardless of methods, the results based on the above mentioned temporal generalization model are the highest for each site, which means that the difference of rice in different years is smaller than that of rice in different spaces, and the phenological characteristics of rice have been well learned by the models. Generally, the adapted U-Net outperforms other models in space migration, and the space-time migration of the model between regions with closed latitudes has less effective on the model performance, which can be used to provide technical support for the application of global rice mapping in the future.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and discussion</head><p>This paper proposes a DCNN-based method for rice mapping in largescales under different years. It is formulated as semantic segmentation problem. The spatial and temporal features (multi-temporal images are integrated into a multi-channel image) acquired from large regions are used to identify pixels as rice or non-rice. The DCNN model for the above task is adapted from the U-Net. In order to take advantage of the phenological characteristics of rice in different years, the images of 2017, 2018 and 2019 are collected for training, validation, test respectively. The proposed method for rice mapping performs well in largescales since the multi-level features and the phenological characteristics of rice are well exploited by the adapted U-Net. Furthermore, the characteristic difference of rice in different years is smaller than that of rice in different spaces, and the mobility of the model gets worse as the latitude changes.</p><p>Although DCNNs have the above advantages for rice mapping, there are two main limitations need to be resolved for practical operation. First, the accuracies in the scattered rice planting areas are low since the model training suffers from the imbalance in rice samples and non-rice samples. It can be impaired by replacing the original loss function of the network with a focal loss function that reduces the weight of a large number of simple negative samples. Second, it is unclear that the trained model is universal enough for operational worldwide rice mapping. This issue can be addressed by collecting varied rice and non-rice reference datasets, exploring different time series lengths (i.e., assuming that only time series data before and after the transplanting period are selected) for different seasonality rice universal mapping. A model trained using a wide range of samples can achieve better performance. When the samples in some regions are not enough to train a robust model, it is possible to employ transfer learning techniques to transfer an existing model to this target region with the help of a small number of samples. However, some issues need to be investigated in the near future to demonstrate such possibility.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Location of the study area. The blue boxes represent the coverage of three Sentinel-1 image tiles. The Red box is the study area. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</figDesc><graphic url="image-4.png" coords="3,45.47,55.42,235.30,223.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Crop calendar of the main crops covered in the study area.</figDesc><graphic url="image-5.png" coords="4,113.39,55.40,368.50,166.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Experimental site located in Arkansas River Basin (90 • 51 ′ 58.8 ′′ W, 34 • 52 ′ 42.2 ′′ N). (a) Optical image of the study area. (b) Sentinel-1 VH mosaic. (c) Ground truth of the study area in 2017.</figDesc><graphic url="image-6.png" coords="4,70.87,492.45,453.60,224.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>, each Sentinel-1 image is cropped into a set of small images with size of 512 × 512 × c, c is the number of the image channels composed by the multitemporal data sets. Consistent with the computer vision community, the 512 × 512 × c image sets are divided into three categories: training, validation, and test sets. The Sentinel-1 images from 2017 covering the study area are selected as the training data sets, and a 512 × 512 sliding window is slipped across the entire image, with intervals of 130 and 100 pixels in rows and columns, this results in 4386 512 × 512 training samples for the Sentinel-1 mosaic image. The Sentinel-1 images from 2018 covering the study area are selected as the validation data sets, and a 512 × 512 sliding window is slipped across the entire image, with intervals of both 200 pixels in rows and columns, this results in 1474 512 × 512 validation samples for the Sentinel-1 mosaic image. The Sentinel-1 mosaic image from 2019 is selected to be the test set. The specific number of each datasets is listed in Table 5. The training data sets are used to train the DCNNs. Validation data sets are used to finetune parameters in the DCNNs. Test data sets are only used to evaluate the rice mapping results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Acquisition of sample images. (a) Composition of multi-channel data. (b) Illustration of sliding window. (c) Sample image cropped by sliding window.</figDesc><graphic url="image-7.png" coords="5,99.21,55.44,396.86,364.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>figure, an image is input to the net, it flows along the (left) contracting path and then the right expansive path. The left and right parts are encoder and decoder respectively, which are widely used in fully convolutional neural network for semantic segmentation. The different types of layers are common in DCNNs developed for semantic segmentation. Please refer<ref type="bibr" target="#b53">(Ronneberger et al., 2015;</ref><ref type="bibr" target="#b7">Chai et al., 2019)</ref> for details about the layers. The output layer has the same resolution as the input layer since an unpooling is introduced to zoom in the feature map, which is zoomed out by each pooling.The input image is stored in the input layer. It is a 512 × 512 × c volume, where c is the number of channels. For the combination of VV and VH polarization channels, c = 16 when the image temporal resolution is 24 days (i.e., 8 time-series images); c = 26 when the image temporal resolution is 12 days (i.e., 13 time-series images).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Schematic diagram of semantic segmentation for rice mapping. The intermediate feature maps represent extracted features at different levels. Only 10 instead of the all channels are displayed for each feature map. All the features are normalized to [0, 255].</figDesc><graphic url="image-8.png" coords="6,49.61,55.41,496.08,110.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The process of image identification.</figDesc><graphic url="image-9.png" coords="6,106.24,213.82,382.75,230.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Class confidence maps and class label map. (a) The confidence map of rice. (b) The confidence map of non-rice. (c) The final label map. In the confidence map, the brighter area, the higher confidence.</figDesc><graphic url="image-10.png" coords="7,85.04,55.45,425.23,131.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Differences of backscattering coefficients between different crops in 2017. (a) Differences between different crops based on VH channel. (b) Differences between different crops based on VV channel. The shaded areas refer to the standard deviation calculated from the sample points.</figDesc><graphic url="image-11.png" coords="7,313.17,234.76,237.89,455.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Differences of rice between different years. (a) Differences of rice between different years based on VH channel. (b) Differences of rice between different years based on VV channel. The shaded areas refer to the standard deviation calculated from the sample points.</figDesc><graphic url="image-12.png" coords="8,314.48,55.44,235.30,434.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>(</head><label></label><figDesc>RQ2) In order to express the features learned by the deep learning model, the rice extraction experiments in different planting pattern regions and extracted features visual projection experiments are conducted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Errors from different years in the same rice planting areas. (a) and (b) represent the errors of uniform and irregular rice planting areas, respectively. The first row represents the ground truth maps of the same area in different years (From left to are 2017, 2018 and 2019, respectively). The second to six rows are the rice extraction errors of LSTM, FCN, SegNet, DeepLab and U-Net for the same areas in different years.</figDesc><graphic url="image-13.png" coords="11,99.21,55.40,396.86,588.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. (continued).</figDesc><graphic url="image-14.png" coords="12,99.21,55.40,396.86,600.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>P.Wei et al.   almost no rice in this area in 2017 and 2018, scattered rice planting areas clearly appeared in 2019. From the extraction errors, it can be seen that the adapted U-Net shows more stable performance in rice extraction in different years than other networks for irregular rice planting areas.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Feature visualization of multi-temporal Sentinel-1 data by t-SNE based on different models for rice and non-rice in the year of 2017, 2018 and 2019. The axes represent the spatial coordinates of the high-dimensional features projected onto a 2-D plane.</figDesc><graphic url="image-15.png" coords="13,77.95,55.44,439.34,511.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Feature visualization of multi-temporal Sentinel-1 data by t-SNE for rice in different years. The axes represent the spatial coordinates of the highdimensional features projected onto a 2-D plane.</figDesc><graphic url="image-16.png" coords="14,85.04,55.43,425.23,170.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. The process of the model space migration.</figDesc><graphic url="image-17.png" coords="14,99.21,267.70,396.86,126.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. The results of Experiment A. (a) Training in Site 02 or 03, testing in Site 01; (b) Training in Site 01 or 03, testing in Site 02; (c) Training in Site 01 or 02, testing in Site 03. Purple, blue and red represents the models are trained in Site 01, 02 and 03, respectively. Green represents the above mentioned models based on large-scale temporal generalization. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</figDesc><graphic url="image-18.png" coords="15,123.31,55.44,348.62,612.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Existing researches on large-scale crop mapping using SAR data sets. Similarity of temporal signature (σ VV , σ VH and σ VH /σ VV ) Δσ=(σ HH *σ VV ) T1 -(σ HH *σ VV ) T2 , T1 and T2 are represent the different date, σ HH and σ VV are represent the backscatter coefficient of HH and VV polarization channels. SVM (Support Vector Machine), RF (Random Forest).</figDesc><table><row><cell>Categories</cell><cell>Reference</cell><cell>Data sets</cell><cell>Methology</cell><cell>Study area</cell></row><row><cell>Threshold</cell><cell>Bouvet et al., 2009</cell><cell>Advanced SAR (ASAR)</cell><cell>Threshold based on σ HH /σ VV</cell><cell>An Giang, Vietnam</cell></row><row><cell></cell><cell>Chen and Li, 2008</cell><cell>ASRA</cell><cell>Threshold based on Δσ</cell><cell>Fuzhou, China</cell></row><row><cell></cell><cell>Hoang et al., 2016</cell><cell>Radarsat-2</cell><cell>Threshold based on σ HH</cell><cell>Cau River Basin, Vietnam</cell></row><row><cell></cell><cell>Mandal et al., 2018</cell><cell>Sentinel-1</cell><cell>Threshold based on σ VV and σ VH</cell><cell>West Bengal, India</cell></row><row><cell></cell><cell>Arias et al., 2018</cell><cell>Sentinel-1</cell><cell></cell><cell>Navarre, Spain</cell></row><row><cell>Machine learning</cell><cell>Hoang et al., 2016</cell><cell>Radarsat-2</cell><cell>SVM</cell><cell>Cau River Basin, Vietnam</cell></row><row><cell></cell><cell>Lasko et al., 2018</cell><cell>Sentinel-1</cell><cell>RF</cell><cell>Hanoi, Vietnam</cell></row><row><cell></cell><cell>Phan et al., 2019</cell><cell>Sentinel-1</cell><cell>SVM</cell><cell>Red River Delta, Vietnam</cell></row><row><cell></cell><cell>Singha et al., 2019</cell><cell>Sentinel-1</cell><cell>RF</cell><cell>Bangladesh and Northeast India</cell></row><row><cell></cell><cell>Peng et al., 2019</cell><cell>Radarsat-2</cell><cell>RF</cell><cell>Meishan, China</cell></row><row><cell></cell><cell>Brinkhoff et al., 2019</cell><cell>Sentinel-1 and 2</cell><cell>SVM</cell><cell>Riverina region, Australia</cell></row><row><cell></cell><cell>Tian et al., 2019</cell><cell>Sentinel-1 and 2</cell><cell>RF</cell><cell>Hebei, China</cell></row><row><cell></cell><cell>Liu et al., 2020</cell><cell>Sentinel-1 and 2, and Landsat-8</cell><cell>Classification and regression tree</cell><cell>Qinghai, China</cell></row><row><cell>Note:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Existing deep learning researches on remote sensing community.</figDesc><table><row><cell>Categories</cell><cell>Reference</cell><cell>Data sets</cell><cell>Application</cell><cell>Size of study area</cell></row><row><cell>Patch-based CNNs Deep semantic segmentation models</cell><cell>Kussul et al., 2017 Sharma et al., 2017 Chen and Tao, 2018 Zhang et al., 2018 Zhou et al., 2018 Zhao et al., 2019 Gu et al., 2019 Parente et al., 2019</cell><cell>Sentinel-1 and Landsat-8 Landsat-8 AIRSAR and UAV SAR Landsat-8 Sentinel-2 Sentinel-1 Sentinel-1 and 2, and GF-3 Sentinel-2 and Landsat-8</cell><cell>Crop mapping Land cover classification Crop mapping Crop mapping Crop mapping Crop mapping Crop mapping Land-use and land-cover classification</cell><cell>28000 km 2 771 km 2 110 km 2 258 km 2 1022 km 2 10752 km 2 1200 km 2 18000 km 2</cell></row><row><cell></cell><cell>Chai et al., 2019 Ning et al., 2019 Wei et al., 2019 Pan et al., 2020</cell><cell>Landsat-7 and 8 Radarsat-2 Sentinel-1 Worldview-2</cell><cell>Cloud detection Crop mapping Crop mapping Urban village classification</cell><cell>/ 7134 km 2 3400 km 2 ≤137.38 km 2</cell></row><row><cell></cell><cell>Chai et al., 2020 Zhang et al., 2020</cell><cell>Aerial optical image (Vaihingen and Potsdam) GF-1 and 2, and ZY-3</cell><cell>aerial optical image interpretation Cropland</cell><cell>/ 940000 km 2</cell></row><row><cell></cell><cell>Qiu et al., 2020</cell><cell>Sentinel-2</cell><cell>mapping Settlement mapping</cell><cell>58800 km 2</cell></row></table><note>P.Wei et al.   </note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>Data acquisition dates (Month/date).</figDesc><table><row><cell>2017</cell><cell>2018</cell><cell>2019</cell></row><row><cell>4/4</cell><cell>3/30</cell><cell>4/6</cell></row><row><cell>4/28</cell><cell>4/23</cell><cell>4/30</cell></row><row><cell>5/22</cell><cell>5/17</cell><cell>5/24</cell></row><row><cell>6/3</cell><cell>5/29</cell><cell>6/5</cell></row><row><cell>6/15</cell><cell>6/10</cell><cell>6/17</cell></row><row><cell>6/27</cell><cell>6/22</cell><cell>6/29</cell></row><row><cell>7/9</cell><cell>7/4</cell><cell>7/11</cell></row><row><cell>7/21</cell><cell>7/16</cell><cell>7/23</cell></row><row><cell>8/2</cell><cell>7/28</cell><cell>8/4</cell></row><row><cell>8/14</cell><cell>8/9</cell><cell>8/16</cell></row><row><cell>8/26</cell><cell>8/21</cell><cell>8/28</cell></row><row><cell>9/7</cell><cell>9/2</cell><cell>9/9</cell></row><row><cell>9/19</cell><cell>9/14</cell><cell>9/21</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6</head><label>6</label><figDesc>JM distances between rice and other crops in different year.</figDesc><table><row><cell>Year</cell><cell>Corn</cell><cell>Cotton</cell><cell>Soybean</cell></row><row><cell>2017</cell><cell>1.2027</cell><cell>1.0948</cell><cell>1.3663</cell></row><row><cell>2018</cell><cell>1.1284</cell><cell>1.1611</cell><cell>1.2995</cell></row><row><cell>2019</cell><cell>1.2095</cell><cell>1.2514</cell><cell>1.2525</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7</head><label>7</label><figDesc>JM distances of rice between different year.</figDesc><table><row><cell></cell><cell>2017</cell><cell>2018</cell><cell>2019</cell></row><row><cell>2017</cell><cell>\</cell><cell>0.0357</cell><cell>0.0586</cell></row><row><cell>2018</cell><cell>0.0357</cell><cell>\</cell><cell>0.0594</cell></row><row><cell>2019</cell><cell>0.0586</cell><cell>0.0594</cell><cell>\</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8</head><label>8</label><figDesc>Comparison of rice mapping results based on different network structures using 24-day interval images.</figDesc><table><row><cell>P. Wei et al.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Input</cell><cell>Network</cell><cell>Year of data sets</cell><cell>Rice</cell><cell>Rice (User%)</cell><cell>Overall accuracy/%</cell><cell>Kappa</cell><cell>F1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(Producer/%)</cell><cell></cell><cell></cell><cell>coefficient</cell><cell></cell></row><row><cell></cell><cell>RF</cell><cell></cell><cell>84.92</cell><cell>69.82</cell><cell>83.79</cell><cell>0.68</cell><cell>0.76</cell></row><row><cell></cell><cell>FCN</cell><cell></cell><cell>76.54</cell><cell>83.89</cell><cell>90.18</cell><cell>0.74</cell><cell>0.80</cell></row><row><cell></cell><cell>SegNet</cell><cell>2018 (Validation)</cell><cell>75.23</cell><cell>86.22</cell><cell>90.46</cell><cell>0.74</cell><cell>0.80</cell></row><row><cell></cell><cell>DeepLab</cell><cell></cell><cell>77.37</cell><cell>87.03</cell><cell>91.13</cell><cell>0.76</cell><cell>0.83</cell></row><row><cell>VV + VH</cell><cell>U-Net RF</cell><cell></cell><cell>86.18 87.69</cell><cell>80.06 45.02</cell><cell>91.08 78.05</cell><cell>0.77 0.47</cell><cell>0.83 0.59</cell></row><row><cell></cell><cell>FCN</cell><cell></cell><cell>79.10</cell><cell>74.72</cell><cell>89.72</cell><cell>0.70</cell><cell>0.77</cell></row><row><cell></cell><cell>SegNet</cell><cell></cell><cell>71.70</cell><cell>87.35</cell><cell>91.35</cell><cell>0.73</cell><cell>0.78</cell></row><row><cell></cell><cell>DeepLab</cell><cell>2019 (Test)</cell><cell>77.11</cell><cell>83.84</cell><cell>91.64</cell><cell>0.75</cell><cell>0.80</cell></row><row><cell></cell><cell>U-Net</cell><cell></cell><cell>86.44</cell><cell>74.01</cell><cell>90.60</cell><cell>0.74</cell><cell>0.80</cell></row><row><cell>VV VH</cell><cell>U-Net</cell><cell></cell><cell>73.74 75.92</cell><cell>54.10 72.91</cell><cell>82.21 88.76</cell><cell>0.51 0.67</cell><cell>0.62 0.74</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 9</head><label>9</label><figDesc>Comparison of rice mapping results based on different network structures using 12-day interval images. Prediction time of six models for rice mapping in large-scales.</figDesc><table><row><cell>Year</cell><cell>Method</cell><cell>Input</cell><cell>Rice</cell><cell></cell><cell>Rice</cell><cell></cell><cell cols="3">Overall accuracy/%</cell><cell>Kappa coefficient</cell><cell>F1</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">(Producer/%)</cell><cell cols="2">(User/%)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>LSTM</cell><cell></cell><cell>90.32</cell><cell></cell><cell cols="2">75.69</cell><cell>90.39</cell><cell></cell><cell>0.76</cell><cell>0.82</cell></row><row><cell></cell><cell>FCN</cell><cell></cell><cell>86.66</cell><cell></cell><cell cols="2">85.93</cell><cell>92.90</cell><cell></cell><cell>0.82</cell><cell>0.86</cell></row><row><cell>2018 (Validation)</cell><cell>SegNet</cell><cell></cell><cell>92.76</cell><cell></cell><cell cols="2">87.91</cell><cell>94.83</cell><cell></cell><cell>0.87</cell><cell>0.90</cell></row><row><cell></cell><cell>DeepLab</cell><cell></cell><cell>93.25</cell><cell></cell><cell cols="2">86.89</cell><cell>94.63</cell><cell></cell><cell>0.86</cell><cell>0.90</cell></row><row><cell></cell><cell>U-Net LSTM</cell><cell>VV + VH</cell><cell>91.45 89.49</cell><cell></cell><cell cols="2">89.93 66.52</cell><cell>95.11 88.48</cell><cell></cell><cell>0.87 0.69</cell><cell>0.91 0.76</cell></row><row><cell></cell><cell>FCN</cell><cell></cell><cell>80.99</cell><cell></cell><cell cols="2">83.24</cell><cell>92.21</cell><cell></cell><cell>0.77</cell><cell>0.82</cell></row><row><cell>2019 (Test)</cell><cell>SegNet</cell><cell></cell><cell>90.04</cell><cell></cell><cell cols="2">79.10</cell><cell>92.67</cell><cell></cell><cell>0.79</cell><cell>0.84</cell></row><row><cell></cell><cell>DeepLab</cell><cell></cell><cell>89.57</cell><cell></cell><cell cols="2">81.98</cell><cell>93.40</cell><cell></cell><cell>0.81</cell><cell>0.85</cell></row><row><cell></cell><cell>U-Net</cell><cell></cell><cell>87.43</cell><cell></cell><cell cols="2">87.46</cell><cell>94.41</cell><cell></cell><cell>0.84</cell><cell>0.87</cell></row><row><cell></cell><cell cols="2">adapted U-Net</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>DeepLab</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Model type</cell><cell>FCN SegNet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>LSTM</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>RF</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>20</cell><cell>40</cell><cell>60</cell><cell>80</cell><cell>100</cell><cell>120</cell><cell>140</cell><cell>160</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Test time (minute)</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Fig. 10.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>P.Wei et al.   </note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">P.Wei et al.   </note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by the National Key R&amp;D Program of China (No. 2016YFD0300603-5 and 2017YFD0300402-3). It was also funded by Eramus+Programme of the European Union (No. 598838-EPP-1-2018-EL-EPPKA2-CBHE-JP).</p></div>
			</div>


			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of competing interest</head><p>The authors declare no conflict of interest.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Crop type mapping based on sentinel-1 backscatter time series</title>
		<author>
			<persName><forename type="first">M</forename><surname>Arias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Campo-Bescós</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Álvarez-Mozos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IGARSS 2018-2018 IEEE International Geoscience and Remote Sensing Symposium</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="6623" to="6626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SegNet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2481" to="2495" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A new method for crop classification combining time series of radar images and crop phenology information</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bargiel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">198</biblScope>
			<biblScope unit="page" from="369" to="383" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Monitoring of the rice cropping system in the Mekong Delta using ENVISAT/ASAR dual polarization data</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M ;</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bouvet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Toan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lamdao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">47</biblScope>
			<biblScope unit="page" from="517" to="526" />
			<date type="published" when="2006">2006. 2009</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>Pattern recognition and machine learning</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Land cover classification of nine perennial crops using Sentinel-1 and -2 data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brinkhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vardanega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Robson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Remote Sens. 12, 96</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A highperformance and in-season classification system of field-level crop types using timeseries Landsat data and a machine learning approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Seifert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wardlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">210</biblScope>
			<biblScope unit="page" from="35" to="47" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Aerial image semantic segmentation using DCNN predicted distance maps</title>
		<author>
			<persName><forename type="first">R</forename><surname>Caves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Padda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Newsam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J. Photogramm. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">161</biblScope>
			<biblScope unit="page" from="309" to="322" />
			<date type="published" when="2011">2011. 2020</date>
		</imprint>
	</monogr>
	<note>Data analysis-Multi-temporal filtering</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cloud and cloud shadow detection in Landsat imagery based on deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Newsam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">225</biblScope>
			<biblScope unit="page" from="307" to="316" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rice recognition using multi-temporal and dual polarized synthetic aperture radar images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Colloquium on Computing Communication Control and Management</title>
		<imprint>
			<biblScope unit="page" from="96" to="100" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Monitoring rice growth in Southern China using TerraSAR-X dual polarization data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">P</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Agro-Geoinformatics</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="834" to="848" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">PolSAR image classification using polarimetric-feature-driven deep convolutional neural network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="627" to="631" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Characterizing marsh wetlands in the Great Lakes Basin with Cband InSAR observations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Banks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Behnamian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Montpetit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pasher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Duffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bernard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Remote Sens. Environ. 242, 111750</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Synthetic aperture radar (SAR) image processing for operational space-based agriculture mapping</title>
		<author>
			<persName><forename type="first">L</forename><surname>Dingle Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mcnairn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>De Abelleyra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Verón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Cosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="7112" to="7144" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mapping paddy rice planting area in northeastern Asia with Landsat 8 images, phenology-based algorithm and Google Earth Engine</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Menarguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Thau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Biradar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="142" to="154" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Cloud detection algorithm comparison and validation for operational Landsat data products</title>
		<author>
			<persName><forename type="first">S</forename><surname>Foga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Scaramuzza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Dilley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joseph Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Laue</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="379" to="390" />
		</imprint>
	</monogr>
	<note>Remote Sens. Environ. 194</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning precise timing with lstm recurrent networks</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="115" to="143" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Intra-annual reflectance composites from Sentinel-2 and Landsat for national-scale crop and land cover mapping</title>
		<author>
			<persName><forename type="first">P</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nendel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hostert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="page" from="135" to="151" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Crop classification based on deep learning in northeast china using SAR and optical imagery</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SAR in Big Data Era (BIGSARDATA)</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Crop classification based on differential characteristics of H/α scattering parameters for multitemporal quad-and dual-polarization SAR images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6111" to="6123" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Transfer learning for crop classification with cropland data layer data (CDL) as training samples</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Total Environ</title>
		<imprint>
			<biblScope unit="volume">733</biblScope>
			<biblScope unit="page">138869</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A novel phenology based feature subset selection technique using random forest for multitemporal PolSAR crop classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mandal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tirodkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Lopez-Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="4244" to="4258" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rice mapping using radarsat-2 dual-and quad-pol data in a complex land-use watershed: Cau River Basin (Vietnam)</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bernier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Duchesne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3082" to="3096" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic fruit classification using deep learning for industrial applications</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Al-Hammadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Muhammad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Informatics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1027" to="1034" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Methane emissions monitoring of rice fields using RADARSAT-2 data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Geoscience and Remote Sensing Symposium</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3223" to="3226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Crop disease detection using deep learning</title>
		<author>
			<persName><forename type="first">O</forename><surname>Kulkarni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth International Conference on Computing Communication Control and Automation (ICCUBEA)</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep learning classification of land cover and crop types using remote sensing data</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kussul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lavreniuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skakun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shelestov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="778" to="782" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Parcel-based crop classification in ukraine using landsat-8 data and sentinel-1A data</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kussul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lemoine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Gallego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Skakun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lavreniuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Shelestov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2500" to="2508" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Crop inventory at regional scale in Ukraine: developing in season and end of season crop maps with multi-temporal optical and SAR satellite imagery</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kussul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mykola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shelestov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skakun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European J. Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="627" to="636" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>NIPS Curran Associates Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Mapping double and single crop paddy rice with Sentinel-1A at varying spatial scales and polarizations in Hanoi, Vietnam</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lasko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Vadrevu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Justice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="498" to="512" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Mapping cropping intensity in China using time series Landsat and Sentinel-2 images and Google Earth Engine</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020a</date>
		</imprint>
	</monogr>
	<note>Remote Sens. Environ. 239, 111624</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Largescale crop mapping from multisource remote sensing images in google earth engine</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J Sel. Top. Appl. Earth Obs. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="414" to="427" />
			<date type="published" when="2020">2020b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Fully convolutional networks for semantic segmentation. Computer Vision and Pattern Recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Sen4Rice: A processing chain for differentiating early and late transplanted rice using timeseries Sentinel-1 SAR data with google earth engine</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mandal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Siqueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1947" to="1951" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A complete procedure for crop phenology estimation with PolSAR data based on the complex wishart classifier</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mascolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Lopez-Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vicente-Guijalba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nunziata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Migliaccio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mazzarella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="6505" to="6515" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Estimation of plant growth in rice field based on remote sensing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Matsuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Maruyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yamashita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IFAC Proc</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">28</biblScope>
			<biblScope unit="page" from="95" to="100" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An automated method for annual cropland mapping along the season for various globally-distributed agrosystems using high spatial and temporal resolution time series</title>
		<author>
			<persName><forename type="first">N</forename><surname>Matton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Canto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Waldner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Valero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Morin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Inglada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bontemps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Koetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Defourny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="13208" to="13232" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Machine learning: a probabilistic perspective</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, Massachusetts</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mapping rice extent and cropping scheme in the Mekong Delta using Sentinel-1A data</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gruber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1209" to="1218" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Extraction of rice-planted area based on MobileUnet model and Radarsat-2 data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SAR in Big Data Era (BIGSARDATA)</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Mapping cropland extent of Southeast and Northeast Asia using multi-year time-series Landsat 30-m data using a random forest classifier on the Google Earth Engine Cloud</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Oliphant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Thenkabail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Teluguntla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Gumma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Congalton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yadav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Appl. Earth Obs. Geoinf</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="110" to="124" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Deep learning segmentation and classification for urban village using a Worldview satellite image based on U-Net</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Remote Sens. 12, 1574</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Next generation mapping: Combining deep learning, cloud computing, and big remote sensing data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Parente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Taquary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Ferreira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Remote Sens. 11, 2881</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">On the difficulty of training Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>arXiv Learn</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Random forest classification of rice planting area using multi-temporal polarimetric Radarsat-2 data. International Geoscience and Remote Sensing Symposium</title>
		<author>
			<persName><forename type="first">W</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2411" to="2414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Rapid assessment of flood inundation and damaged rice area in Red River Delta from Sentinel 1A imagery</title>
		<author>
			<persName><forename type="first">A</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Q</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019. 2034</date>
		</imprint>
	</monogr>
	<note>Remote Sens. 11</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Object-based flood mapping and affected rice field estimation with Landsat 8 OLI and MODIS data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Phuong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yuei-An</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="5077" to="5097" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Automatic and adaptive paddy rice mapping using Landsat images: Case study in Songnen Plain in Northeast China</title>
		<author>
			<persName><forename type="first">B</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Total Environ</title>
		<imprint>
			<biblScope unit="volume">598</biblScope>
			<biblScope unit="page" from="581" to="592" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A framework for largescale mapping of human settlement extent from Sentinel-2 images via fully convolutional neural ne-tworks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Geiß</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H.-K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J. Photogramm. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="page" from="152" to="170" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Faster R-CNN: towards real-time object detection with region proposal networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">U-Net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Computing and Computer Assisted Intervention</title>
		<imprint>
			<biblScope unit="page" from="234" to="241" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Fusion of images and point clouds for the semantic segmentation of large-scale 3D scenes based on deep learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J. Photogramm. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="85" to="96" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Sentinel-1 time series data for monitoring the phenology of winter wheat</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schlund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Erasmi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Remote Sens. Environ. 246, 111814</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A patch-based convolutional neural network for remote sensing image classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="19" to="28" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Woo</surname></persName>
		</author>
		<title level="m">Convolutional LSTM network: A machine learning approach for precipitation nowcasting. Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="802" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Regenerated ALOS-2/PALSAR-2 global mosaics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shimada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Itoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Motooka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Geoscience and Remote Sensing Symposium</title>
		<imprint>
			<biblScope unit="page" from="2454" to="2457" />
			<date type="published" when="2014">2017. 2016. 2014. 2015. 2017</date>
		</imprint>
	</monogr>
	<note>for forest observations</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition. Computer Vision and Pattern Recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">High resolution paddy rice maps in cloudprone Bangladesh and Northeast India using Sentinel-1 data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Singha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Scientific data</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Crop classification using short-revisit multitemporal SAR data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Skriver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mattia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Satalino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Balenzano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R N</forename><surname>Pauwels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E C</forename><surname>Verhoest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davidson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="423" to="431" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Satellite-based investigation of flood-affected rice cultivation areas in Chao Phraya River Delta Thailand</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J. Photogramm. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="77" to="88" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Rice crop calendar based on phenology analysis from time-series images</title>
		<author>
			<persName><forename type="first">N</forename><surname>Soontranon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Srestasathiern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rakwatin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th International Conference on Electrical Engineering/Electronics. Computer Telecommunications and Information Technology (ECTI-CON)</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Evaluating the performance of multitemporal image compositing algorithms for burned area analysis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M O</forename><surname>Sousa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M C</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M N</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1219" to="1236" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Detection and validation of forest distubances using radarsat 2 data</title>
		<author>
			<persName><forename type="first">G</forename><surname>Staples</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gravelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Goodenough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5798" to="5801" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A 30-m landsat-derived cropland extent product of Australia and China using random forest machine learning algorithm on Google Earth Engine cloud computing platform</title>
		<author>
			<persName><forename type="first">P</forename><surname>Teluguntla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Thenkabail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliphant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Gumma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Congalton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J. Photogramm. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page" from="325" to="340" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Efficient Identification of Corn Cultivation Area with Multitemporal Synthetic Aperture Radar and Optical Images in the Google Earth Engine Cloud Platform</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Remote Sens. 11, 629</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Using a genetic algorithm as an optimal band selector in the mid and thermal infrared (2.5-14 μm) to discriminate vegetation species</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Groen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schlerf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Skidmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vaiphasa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="8755" to="8769" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Rice heading date retrieval based on multitemporal MODIS data and polynomial fitting</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">U I</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1905" to="1916" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">An image co-registration method for wide-swath and high-resolution spaceborne InSAR</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian-Pacific Conference on Synthetic Aperture Radar</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1031" to="1033" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Multi-Temporal SAR data large-scale crop mapping based on U-Net model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">68</biblScope>
		</imprint>
	</monogr>
	<note>Remote Sens. 11</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">On the Use of Neumann decomposition for crop classification using multi-temporal Radarsat-2 polarimetric SAR data</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Lopezsanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Remote Sens. 11, 776</note>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">DeepCropMapping: A multi-temporal deep learning approach with improved spatial generalizability for dynamic corn and soybean mapping</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Remote Sens. Environ. 247, 111946</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Large-scale crop mapping based on machine learning and parallel computation with grids</title>
		<author>
			<persName><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Remote Sens. 11, 1500</note>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Deep learning in environmental remote sensing: Achievements and c-hallenges</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020. 111716</date>
		</imprint>
	</monogr>
	<note>Remote Sens. Environ. 241</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">A generalized approach based on convolutional neural networks for large area cropland mapping at very high re-solution</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Remote Sens. Environ. 247, 111912</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Spatiotemporal patterns of paddy rice croplands in China and Indi-a from</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Biradar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Menarguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ji-N</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Total Environ</title>
		<imprint>
			<biblScope unit="volume">579</biblScope>
			<biblScope unit="page" from="82" to="92" />
			<date type="published" when="2000">2017. 2000 to 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Mapping Paddy Rice Using a Convolutional Neural Network (CNN) with Landsat 8 Datasets in the Dongting Lake Area</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<pubPlace>China</pubPlace>
		</imprint>
	</monogr>
	<note>Remote Sens. 10, 1840</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">An implicit radar convolutional burn index for burnt area mapping with Sentinel-1 C-band SAR data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nascetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J. Photogramm. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="page" from="50" to="62" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Crop classification based on feature band set construction and object-oriented approach using hyperspectral images</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4117" to="4128" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Evaluation of three deep learning models for early crop classification using Sentinel-1A imagery time series-A case study in Zhanjiang China</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Remote Sens. 11, 2673</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Predicting grain yield in rice using multi-temporal vegetation indices from UAV-based multispectral and digital imagery</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">K</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J. Photogramm. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="page" from="246" to="255" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Long-short-term-memory-based crop classification using high-resolution optical images and multi-temporal SAR data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Giscience Remote Sens</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1170" to="1191" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Crops classification from Sentinel-2A multi-spectral remote sensing images based on convolutional neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Geoscience and Remote Sensing Symposium</title>
				<meeting><address><addrLine>In</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="5300" to="5303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">P</forename><surname>Wei</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
