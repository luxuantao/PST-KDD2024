<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Keystroke-Level Model for Advanced Mobile Phone Interaction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Paul</forename><surname>Holleis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Friederike</forename><surname>Otto</surname></persName>
							<email>friederike.otto@ifi.lmu.de</email>
						</author>
						<author>
							<persName><forename type="first">Heinrich</forename><surname>Hußmann</surname></persName>
							<email>heinrich.hussmann@ifi.lmu.de</email>
						</author>
						<author>
							<persName><forename type="first">Albrecht</forename><surname>Schmidt</surname></persName>
							<email>albrecht.schmidt@acm.org</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Research Group Embedded Interaction</orgName>
								<orgName type="institution">University of Munich</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Media Informatics Group</orgName>
								<orgName type="institution">University of Munich</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Sankt Augustin B-IT</orgName>
								<orgName type="institution" key="instit1">Fraunhofer IAIS</orgName>
								<orgName type="institution" key="instit2">University of Bonn</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<address>
									<settlement>San Jose</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Keystroke-Level Model for Advanced Mobile Phone Interaction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">18D025270AE6F7899EE0E0FE6DC80EAB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Keystroke-Level Model (KLM)</term>
					<term>user performance</term>
					<term>design decisions</term>
					<term>real world interaction</term>
					<term>mobile phone interaction H.1.2 User/Machine Systems: Human factors. H.5.2 User Interfaces: Evaluation/methodology</term>
					<term>Interaction styles</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The design of applications using mobile devices needs a different quality assessment than those known for desktop applications. Of the many aspects that have to be taken into account, one important criterion is the average time users need to complete a task. For interactions with the mouse, keyboard or touch screens, there exist models that predict interaction times like Fitts' law or the Keystroke-Level Model (KLM). This paper shows parallels to these models for advanced interactions with mobile phones targeted at pervasive services, including near field communication as well as built-in cameras and sensors. Applications can be evaluated with respect to user performance time without having a prototype running on the phone. To accomplish that, we extend the known KLM by identifying basic interaction elements for mobile phones and give estimates for expert user performance derived from several user tests.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Experience has shown that it is essential to assess designs and applications early in the development phase. The phone company NYNEX probably saved millions of dollars <ref type="bibr" target="#b14">[14]</ref> because the Keystroke-Level Model (KLM) was used to find out that the interaction performance of a newly designed workstation would have been worse than the existing system. This was possible without having to actually build and test the new system at all.</p><p>Even though time to completion of a task is only one aspect of a promising application, it is an important factor for a large set of applications ranging from small games to reservation systems, from sub tasks of larger systems to support and search systems. This is especially the case for applications designed as side tasks or that exploit people's precious and short amount of spare time, e.g., between two tasks or while waiting for a meeting or the bus. These fundamentally rely on quick and hassle-free interactions. In addition to games and entertainment, mobile phones are increasingly used to enhance productivity and throughput in various fields like security or ticket sale.</p><p>In this paper we focus on time/performance predictions for the evolving domain of mobile phone interactions building upon KLM. This choice is motivated by the large number of publications in the CHI environment using KLM in a variety of emerging application domains. Many projects in cognitive modelling such as ACT-R <ref type="bibr" target="#b1">[2]</ref> rely on such data in ongoing research areas like in-vehicle interfaces. We adopt and define a set of operators giving sound and study-based estimates of performance measures for each of them. Developers of mobile applications, which possibly include identification tags and smart objects, can then describe tasks as a sequence of these operators and predict user interaction times without even needing to create prototypes. Table <ref type="table" target="#tab_4">2</ref> shows an annotated excerpt of a model resulting from the new mobile phone KLM developed in this paper.</p><p>As an additional application area, we propose crossplatform evaluation as ongoing work in our lab. It is easy to enhance any type of prototype like a paper or interactive HTML/Flash prototype to generate a KLM of a given task sequence. Our model estimates execution time of those tasks on, e.g., a mobile phone without the need to have a single line of code actually running on a phone.</p><p>Although it sometimes seen as a drawback of such models that these assume nearly error-free expert user interaction, KLM has revealed remarkably precise prediction results in several projects (e.g. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b37">37]</ref>). Even in cases where experimental studies indicated that estimates in fact were considerably off the actual values, the estimated difference between two examined designs still proved to be a strong basis for making a choice between them (e.g. <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b28">28]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BACKGROUND</head><p>Modelling user tasks and processes in general attained much attention from researchers, not only in the last decades. The pioneering work of Card, Moran and Newell introduced the GOMS (Goals, Operators, Methods, Selection rules) model in 1980 <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>. It is often cited as one of the most mature engineering models of human performance. The GOMS elements enable designers to model expert user behaviour during a given task and therefore to analyse user complexity for interactive systems including cognitive information processing activities. Of course, even with certain extensions developed later, this family of models can only account for a small subset of aspects that decide whether a product is successful or not. However, many empirical studies have confirmed that it suffices to support justified choices between similar approaches to the same problem (e.g., <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b20">20]</ref>).</p><p>In its beginning, GOMS was targeted mainly at text editing tasks on office desktop computers. For that purpose, the Keystroke-Level Model (KLM, <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b21">21]</ref>), a tailored instance of GOMS, was developed. A task can be described using operators that model unit tasks like key presses, pointing, hand switches between mouse and keyboard, mental acts, system response times and others. With a set of user studies the authors were able to give estimates for the duration of these actions and evaluate those estimates.</p><p>Several projects (e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b37">37]</ref>) successfully used and validated those values in various application areas. Others slightly adjusted or added one or more operators for a specific application setting (e.g., <ref type="bibr" target="#b25">[25]</ref>). Variants of GOMS have been applied to many different application domains: phone operators <ref type="bibr" target="#b14">[14]</ref>, visual and auditory perception (John, <ref type="bibr" target="#b19">[19]</ref>), a tool selection technique for tablet computers <ref type="bibr" target="#b16">[16]</ref> (Hinckley et al., CHI'06), and several others mentioned below and in <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK</head><p>In this paper, we are building upon KLM, revisiting the timing specifications for existing operators and extending it with new operators necessary to describe interaction with mobile phones. The number of possible types of mobile phone interaction have increased and achieved much attention from various sources in the last years. However, most research on performance measures for phone users has yet been limited to the input of text for short messages: An initial work by Dunlop and Crossan <ref type="bibr" target="#b8">[9]</ref>, shows KLM operator sequences for three different text entry methods (traditional, predictive, and word completion). However, the authors adopted the original operator values used for desktop interaction which proved to be imprecise in this new environment. This is improved in How and Kan <ref type="bibr" target="#b17">[17]</ref> where the presented model is more fine-grained. They define 13 operators that more directly map onto the phone keyboard interface according to the different input methods (multi-tab etc.). New times are gathered from video taped sessions with a small set of subjects and a message typing task. In a complementary approach pursued in 2004 by Pavlovych and Stuerzlinger <ref type="bibr" target="#b29">[29]</ref>, non-perfect users are considered using the cognitive load operator to model input verification. Although we do not focus on text messages, our model supports this view using Micro Attention Shifts explained later. <ref type="bibr" target="#b29">[29]</ref> also compares several existing variants of the KLM and evaluates them with actual times from user studies. The authors conclude that the models give only rough approximations to real user behaviour for text input. However, the models can correctly predict which input methods are faster than others (e.g., predictive over multitap). There is also work reporting on time measurements for key presses and the mental act operator for text input in different languages (e.g. Myung for Korean <ref type="bibr" target="#b28">[28]</ref>).</p><p>In addition to text input, Mori et al. <ref type="bibr" target="#b26">[26]</ref> studied how the time values of the original KLM operators apply to mobile phone menu navigation and conclude that the operator values fit quite well and suggest only minor modifications.</p><p>There is to our knowledge no published research yet that includes new mobile interaction techniques in its model. A beginning is indicated in Luo and John <ref type="bibr" target="#b24">[24]</ref> and its followup (Teo and John <ref type="bibr" target="#b37">[37]</ref>, 2006) where the authors show that the method can be soundly applied to handheld devices using stylus-based interfaces. They also present a tool they developed to automatically generate KLM models from storyboard descriptions and state that they plan to apply such research to novel interfaces like speech or gestures.</p><p>After a short treatment of mobile phone interaction types we first briefly describe the set of new, adapted and adopted parameters of our model and then present the studies that led to updated time values. Their results are summarised and an evaluation of the values is described. We close the paper with a discussion of the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mobile Phone Interactions</head><p>Mobile phones have mainly been used to make phone calls, send text messages, and sometimes as calendar. However, other uses are becoming more and more popular. Taking pictures, surfing the web, storing data, and playing music as well as videos are some of them. Additionally, researchers started to use it as universal remote control (e.g., Myers <ref type="bibr" target="#b27">[27]</ref>) and suggest further interactions with the world (see Figure <ref type="figure" target="#fig_0">1</ref>). This adds several new interaction styles that have not yet been treated by any interaction model. In <ref type="bibr" target="#b32">[32]</ref>, Rukzio et al. define physical mobile interactions as being interactions between a user, a mobile device, and a smart object in the real world. The user interacts with the mobile device and the mobile device interacts with the smart object. This allows the implementation of systems envisioned, e.g., in <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b33">33]</ref> and allows bridges to be built between the physical and virtual worlds using devices that many people carry with them, c.f. Want et al. <ref type="bibr" target="#b40">[40]</ref>.</p><p>Although many people still think that mobile phone applications include games and entertainment only, phones are increasingly used to enhance productivity. In Japan, for example, it is common to buy tickets for public transport with the phone. Security personnel can use a tag reading mobile device to quickly log the places they have checked.</p><p>Up to now there is no user performance model available for physical mobile interactions. Rukzio et al. <ref type="bibr" target="#b32">[32]</ref> studied general preferences of people to use a specific physical mobile interaction method (touching, pointing and scanning). They also show that timing is an issue for users. However, no quantitative performance numbers have been measured and only individual opinions of subjects are given. Ballagas et al. <ref type="bibr" target="#b2">[3]</ref> describe, explore and categorise a multitude of interaction types with mobile phones but do not give any timings or comparisons in that respect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interaction Types and Technology</head><p>Besides number entry and menu selection there are several ways physical mobile interactions can be implemented. <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b2">[3]</ref> give an overview of current technology for physical selection (visual patterns, electromagnetic and infrared methods) and compare them according to several characteristics like transfer rate and operating range. In <ref type="bibr" target="#b38">[38]</ref> and <ref type="bibr" target="#b39">[39]</ref>, as well as in <ref type="bibr" target="#b32">[32]</ref>, projects are described using prototypical implementations of three basic physical selection techniques, Touching (using RFID <ref type="bibr" target="#b40">[40]</ref>, Near Field Communication <ref type="bibr" target="#b32">[32]</ref>, or proximity sensors <ref type="bibr" target="#b38">[38]</ref>), Pointing (visual codes like Semacodes and QR Codes <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b31">31]</ref>, laser pointer and light sensors <ref type="bibr" target="#b38">[38]</ref>, IrDA (Deutsche Post: Mobilepoint), or object recognition <ref type="bibr" target="#b9">[10]</ref>), and Scanning (WLAN, GPS, Bluetooth <ref type="bibr" target="#b32">[32]</ref>).</p><p>Another interaction method we investigated is performing gestures. The underlying technology is based on tracking the phone by an external camera, using the phone's camera <ref type="bibr" target="#b3">[4]</ref>, or reading built-in sensors (found, e.g., in the Nokia Fun Shell or the Samsung SGH-E760 and S4000 phones).</p><p>We keep the revised KLM as general as possible to be able to offer operators to model most of these types of actions and give accurate estimates for some special cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MODEL PARAMETERS</head><p>In this section we show differences and similarities between the KLM used for desktop interaction and the new KLM for mobile phone interactions. The original KLM defines 6 operators and assigns time values to each of them: Keystroke (K, key and button presses), Pointing (P, mouse movements), Drawing (D(n ,l ) D D , straight lines drawings with the mouse), Homing (H, hand movement between keyboard and mouse), Mental Act (M, pauses needed for reflection, choice, etc), and System Response Time (R(t), user waits for the system). Some operators have to be added to describe interactions that do not exist in the standard desktop metaphor. Others have to be examined closely to ensure that the original timing specifications are still applicable or to be able to derive new values. Others again are not applicable to the phone setting at all. The execution time of a task in the new model is then given by <ref type="figure">F,</ref><ref type="figure">G,</ref><ref type="figure">H,</ref><ref type="figure">I,</ref><ref type="figure">K,</ref><ref type="figure">M,</ref><ref type="figure">P,</ref><ref type="figure">R,</ref><ref type="figure">S</ref>  </p><formula xml:id="formula_0">op X D X d n T strong op slight op OP op op execute ⋅ ⋅ + ⋅ + = ∑ ∈ ) ( where = OP {A,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>New Operators</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Macro Attention Shift (S Macro )</head><p>One major difference from desktop to phone interaction is that the attention of users may be split between the phone and the real world surrounding them (Figure <ref type="figure" target="#fig_2">3</ref>). Thus, a Macro Attention Shift operator models the time needed to shift the focus between the contents on the screen of the mobile device to an object (e.g., a poster) in the real world and vice versa. The original KLM does not need to consider this case since it assumes that the whole interaction session takes place on one single screen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Micro Attention Shift (S Micro )</head><p>S Micro models the time needed to look from the display to the keypad and hotkey regions and vice versa (Figure <ref type="figure" target="#fig_3">2</ref>). Although this can also happen in the desktop setting, this has not been mentioned in the original KLM. A possible explanation is the expert user assumption: users were not expected to need to look at the keyboard at all and therefore the time was incorporated into the Keystroke operator. This is different on mobile phones since the mapping of the keys is considerably more complex. Even experienced users tend to spend some time to confirm their input. Thus, the Micro Attention Shift operator allows a much more fine grained control over user interaction. It can also model uncertainty when, e.g., entering critical data like credit card numbers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distraction (X)</head><p>Since interactions with mobile phones take place in the real world, people are likely to be distracted from their main task by approaching people, passing cars, conversations, etc. This is accounted for by the Distraction operator. In contrast to all other operators, distraction is modelled as a multiplicative factor modifying the times of other operators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Action (A(t))</head><p>This general operator models the time needed to execute a certain complex action with the phone that cannot sensibly be subdivided into smaller tasks and modelled with a combination of other operators. Possible actions include touching RFID tags, or focus to take a picture of a marker or other objects. The time for this operator highly depends on the type of action and, similar to the response time operator R(t), this must be input to the model (indicated by the (t) notation). We give values for some typical actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gesture (G)</head><p>This operator models the time needed when using a system that recognises mobile phone gestures like rotating, shaking, or drawing numbers in the air.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Finger Movement (F)</head><p>This operator models the time needed for a user to move a finger from one place (especially key or button) to another one on the device. It will in most models be subsumed in the Keystroke operator but allows designers a more finegrained modelling, e.g., for predicted repeated key presses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initial Act (I)</head><p>In the KLM for the desktop, it is generally assumed that users are already sitting in front of their keyboard, mouse and monitor, ready to initiate the next task. The phone introduces a completely different setting since people have to carry out some preparations (e.g., locating it in a bag) before being able to use it in most circumstances. The value depends on whether the interaction was initiated by the user or externally, e.g., by an incoming call.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adapted Operators</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Keystroke or Button Press (K)</head><p>Card et al. <ref type="bibr" target="#b6">[7]</ref> originally define the Keystroke operator K to be the average time needed to push a button. It is to be measured by dividing the time needed for a longer sequence of button presses by the number of these presses. Even though KLM is targeted at expert users, immediate corrections of incorrectly pressed buttons (e.g., by hitting backspace) have explicitly been allowed and incorporated.</p><p>There are 4 factors influencing the value of K in our setting. Distances between buttons are much smaller on a phone than on a standard keyboard which removes the need for head and larger eye movements and indicates a smaller value for K. However, buttons are in general harder to spot and to press and people use only one or two fingers to type (in contrast to up to ten fingers for keyboard input). Finally, all but the most experienced users check and validate their input at some points needing some Micro Attention Shifts.</p><p>The last three aspects suggest a higher value.</p><p>For text input, we concentrate on multi-tap which, based on figures presented from industry in a panel at MobileHCI 2006, is still used by about every second user. In addition, multi-tap proves useful for comparisons with previous research. Variants like T9, which can also be easily modelled by KLM, are often seen as too complex and do not work well for names or addresses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pointing (P)</head><p>Pointing has originally been defined to model the time used to move a cursor to a target area using the mouse. This is in general not applicable for mobile phone applications except in rare applications in which a cursor can be controlled using the joystick or special buttons. Such interactions can be modelled using appropriate Keystrokes since they are not based on Fitts' Law as is the original interpretation of P.</p><p>For larger screens or handheld devices using stylus input, we refer to Luo and John <ref type="bibr" target="#b24">[24]</ref> who updated the values for Pointing for touch and stylus use. In our context, this models the time needed to move the phone from one place to another possibly to perform some Action at that point (which itself is not included in the pointing action and has to be represented by an A following the P). This operation is similarly based on Fitts' Law as the original operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Homing (H)</head><p>In the original KLM, this modelled the movement of the hand from the keyboard to the mouse or back. For mobile phone interactions, this is not relevant. However, the action of moving the phone from a position where one can read the screen to one's ear or back is an analogous motion and similarly important. Therefore, we use the Homing operator whenever the user changes from listening and speaking to reading the screen or vice versa. In this setting H can be expected to be somewhat smaller but close to Pointing P.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unchanged Operators</head><p>Mental Act (M)</p><p>The Mental Act operator "is based on the fact that when reasonably experienced users are engaged in routine operation of a computer, there are pauses in the stream of actions that are about a second long and that are associated with routine acts such as remembering a filename or finding something on the screen" (Kieras <ref type="bibr" target="#b21">[21]</ref>). It can be adopted as defined, and existing usage guidelines, e.g. from <ref type="bibr" target="#b21">[21]</ref>, can be used. Since we use new operators, we give additional guidelines in a later section on the Mental Act operator.</p><p>Most studies adopted the original choice of M = 1.35 seconds for their applications (e.g., <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b18">18]</ref>). <ref type="bibr" target="#b26">[26]</ref> and <ref type="bibr" target="#b28">[28]</ref> propose a smaller value of 0.38 and 0.57 seconds. However, these values were taken from much specialised applications. Myung <ref type="bibr" target="#b28">[28]</ref>, e.g., examined Korean text input only. For general settings, a higher average value can be assumed. Larger values than the original value are reported in Manes et al. <ref type="bibr" target="#b25">[25]</ref> which mainly result from studying an explicit scenario (a car navigation system) and users who do not have the routine of expert users assumed by KLM. Current cognitive architectures like ACT-R <ref type="bibr" target="#b1">[2]</ref> confirm the original value. We also found no evidence to justify a change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Response Time (R(t) or W(t))</head><p>The Response Time operator models the time the system needs to react to user input as long as it blocks the user from executing further actions. It can be adopted as defined and must be input to the model (hence the (t) notation) since it is highly variable and dependent on the application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Not Applicable Operator</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Drawing (D(n D ,l D ))</head><p>The Drawing operator models manual drawings of n D straight line segments with a total length of l D cm with the mouse. This is not applicable in our setting. However, this might change with possible applications for drag and drop operations done with the phone in some future systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USER STUDIES FOR TIME MEASUREMENTS</head><p>To be able to use the model in practice and to predict the time required for certain complex tasks based on the model, the duration of a single application of an operator must be known. In 7 studies we acquired data to estimate the times. We recruited volunteers of various backgrounds (about 50% students) on a study by study basis (between 9 and 19 participants per study) and did not see any differences caused by gender with, altogether, 41% female participants.</p><p>Before conducting each of the studies, questionnaires were given to the users to clarify their experience with mobile phones in general and more specifically the mobile phone interaction technique under observation. We also aimed to adhere to the expert user assumption by running one or several training sessions with each user. Participants had to repeat the same or similar tasks until they and we were confident that they will to make only minimal errors. Erroneous trials were discarded. All but one studies were executed in various, every day, non-laboratory situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initial Act (I), Homing (H)</head><p>Without preparation or creating specific situation, we observed people in everyday settings receiving and answering phone calls and specifically asked them to pull out their mobile phone and execute a phone call. We taped all these actions and extracted timing information from 11 people, aged 25-54 with an average of 34.6 years, 4 female, all used to standard mobile phone interaction.</p><p>The found value for the Initial Act operator depends on whether the interaction was initiated by the users themselves (leading to a median value of I = 5.32 seconds) or externally, e.g., by an incoming call (median I = 3.89 seconds) <ref type="foot" target="#foot_1">1</ref> . Those values are highly diverse, however, since people have extremely different ways to store the phone (trouser pocket, handbag, pocket attached to the belt). A best-case study in which the phone was placed in front of the users on the table who initiate the action themselves or expect a call gives a median of I = 1.18 seconds. Thus, if no assumptions can be made, we suggest an average value of I = 4.61 seconds. For repeated or expected interaction the I = 1.18 seconds estimate should be used.</p><p>In the same study we measured times needed to switch from a phone position where the screen can be read to one close to the ear and back (Homing). The times of all people under observation were very similar and we extracted a median of H = 0.95 seconds. As expected this is only slightly smaller than the found value of Pointing P = 1.00 second described below. To model the fact that people have to refocus on the phone's screen and continue their interrupted action, we strongly suggest that a Mental Act operator be placed after a Homing away from the ear as specified in the heuristics given in the section about the Mental Act operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pointing (P), Action (A(t))</head><p>To measure execution times for Pointing and Action, we needed an application where such interactions occur quite often. In some countries like Japan, visual markers and near field communication (NFC) are already very wide-spread technologies in the public <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">11]</ref>. This is not yet the case in Europe. Therefore, in conjunction with other projects run in our lab (e.g., <ref type="bibr" target="#b34">[34]</ref>), we prepared a movie poster acting as user interface for several interaction methods. Users can select and use different services by, e.g., touching NFC tags or taking pictures of visual markers. We asked users to follow the brief instructions on the poster and let them buy tickets for their favourite movies in a theatre close to them.</p><p>From the videotaped footage we were able to extract timing measurements regarding the movement (P) and alignment (A(t)) of the phone to the NFC tag, and the approach (P) and focus (A(t)) of the phone to take a picture of a marker.</p><p>The user study was carried out with 9 persons, aged 22-46, with an average of 28.6 years, 2 female. From a set of 64 error free video taped actions, we deduced Pointing P = 1.00 second. The 37 NFC interactions showed that aiming at the NFC tag itself did not need any separate action besides the phone movement and we define A NFC = 0.</p><p>The remaining 27 photographs of visual markers led to a value of A picture = 1.23 seconds for correct positioning and focussing (note that this does not include Pointing).</p><p>Note also that the time needed by the system to recognise the tag or interpret the marker and initiate the appropriate action is not included in the Pointing or Action operator but must be modelled by with the Response Time operator R(t).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Macro Attention Shift (S Macro )</head><p>Using a careful frame-by-frame manual analysis of the video tapes from the study presented in the last section, we counted the number and determined the duration of head and eye movements that indicate an attention switch from the phone to the poster and vice versa. We extracted a total of 121 attention shifts. The times of the shifts in one direction do not differ significantly at all from those in the other direction (t=0.57, p&gt;0.56). Thus, we propose a common value of S Macro = 0.36 seconds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Micro Attention Shift (S Micro )</head><p>Mobile phones in general suggest a split into three regions: display, hot keys, and keypad (Figure <ref type="figure" target="#fig_3">2</ref>). Finding out when and to which section people looked proved to be infeasible with conventional video taping. Therefore we used an eye gaze tracker from Eye Response Technologies that samples images with a sufficient rate of 60Hz. The participants had to run three pre-set tasks that included writing a text message (mainly text input), changing the ring-tone (mainly menu navigation), and setting the time of the alarm-clock (menu navigation and number input). All 10 people (aged 24-34 with an average of 27.5 years, 6 female) were allowed to use their own mobile phone and we ran several sessions to ensure error free interaction. We then automatically calculated the number and time of gaze position changes between the regions from the logged data.</p><p>Figure <ref type="figure" target="#fig_4">4</ref> shows data overlaid on some phones. We counted more than 1500 shifts between the three regions and found the following values: display ↔ hotkeys 0.12 seconds, display ↔ keypad 0.14 seconds, and keypad ↔ hotkeys 0.04 seconds. If no distinction should or can be made between the single sections of the phone, we suggest using the median of all values of S Micro = 0.14 seconds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gesture (G)</head><p>To measure gesture input, we used a Samsung SGH-E760 phone with built-in acceleration sensors and a few games and standard applications that can be controlled using simple gestures (Figure <ref type="figure" target="#fig_5">5</ref>). The times for each gesture was extracted from videos of 6 different types of gestures, each done by 10 people (aged 23-33 with an average of 26.3 years, 5 female). Since the possible gestures were quite similar in type and time, the measurements resulted in one value for all gestures and we set G = 0.80 seconds. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Keystroke (K)</head><p>Keystrokes were measured with a small J2ME program that logs timestamps of key presses and releases into a file on the mobile phone (using the File API on a Nokia N90). We invited 19 people, aged 25-40 with an average of 27.8 years, 9 female. Each person entered two mobile phone numbers of their own choice. All of them used the widespread one-hand thumb entry method. During the study we observed that no errors were made.</p><p>The Nokia N90 phone features a standard 12 button keypad.</p><p>The average of the whole interaction times is 4.63 seconds and the time per keystroke was calculated to be K = 0.39 seconds. For the five most experienced users we got a value of K = 0.33 seconds per keystroke.</p><p>Another interesting value we measured is the mere physical action of pressing and releasing a key. It was measured by the key logger to be 0.13 seconds (the most experienced users were only 10 milliseconds faster) and will be used to calculate Finger Movement time in the next section.</p><p>We measured standard keypad input separately from the hotkeys, although we did not take additional special hotkeys into account that can be found on several phone models on the side or top of the phone. For the hotkeys of the N90 (4 buttons and a 5 button joystick), K = 0.16 seconds were measured as a median. The smaller value can be easily explained with the smaller distance between buttons and the larger average size as well as the more direct and known semantic mapping of the buttons.</p><p>The findings are close to those of other research. Mori et al. <ref type="bibr" target="#b26">[26]</ref> for example measured 0.39 seconds. The original KLM suggests values between 0.08 and 1.20 with 0.28 seconds for a user with average routine on a standard sized desktop QWERTY keyboard. An average value for typing random characters is also mentioned. This better resembles text input on mobile phones. The suggested value of 0.50 seconds again comes quite close to our estimate.</p><p>These values are meant for individual button presses or number input only. Several projects already verified and improved Keystroke-Level Modelling of more complex variants of text entry. The results are quite diverse: Dunlop and Crossan <ref type="bibr" target="#b8">[9]</ref> predict a value of 2.01 and 1.84 seconds on average for multi-tap and predictive text input, respectively. How and Kan <ref type="bibr" target="#b17">[17]</ref> specify 1.32 and 1.00 for the same techniques, assuming an average SMS length of 60 characters. Silfverberg et al. <ref type="bibr" target="#b36">[36]</ref> also examined multi-tap and predictive text input and give values of 0.57 and 0.30 seconds for optimal expert use. The comparatively very small values result from only modelling the pointing component with the help of Fitts' Law, neglecting the time needed to find and actually press the buttons as well as verification. Pavlovych and Stuerzlinger <ref type="bibr" target="#b29">[29]</ref> calculate values ranging from 2.04 to 1.58 seconds for different input methods and suggest how those times should be adjusted for different states of routine.</p><p>These results might indicate that KLM does not work too well in this respect. However, James and Reischel show in <ref type="bibr" target="#b18">[18]</ref> that although the predicted times can differ from actual performance times, relative relations between different designs prove to be correct and significant. Because of the rich set of publications in that area, we have not conducted detailed studies for text entry. Some values were taken from the study for the Distraction operator described later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Finger Movement (F)</head><p>From our observations during the tests for the Keystroke parameter we can report that most users verified less than every second number they typed. This means that the average total time needed to enter a 11 digit number was actually composed of 11 physical key presses, on average 4 Micro Attention Shifts, and 10 Finger Movements. Since we know the values of the other operators, we can calculate F to be 0.24 seconds for all but the 5 quickest users. According to our experience, full experts tend to only check their typing once during writing. Modelling that behaviour for the 5 quickest users results in the median value of F = 0.22. To additionally verify those assumptions, we ran an extra 10 tests using a mobile phone with a blinded display eliminating the use of Micro Attention Shifts. The upshot of this study was a median of F = 0.23 seconds. These results from the 323 key strokes done in the tests make it a very stable parameter. Figure <ref type="figure" target="#fig_6">6</ref> shows movement paths of three sample phone numbers types in the tests.</p><p>The value is also very close to what others like Silfverberg et al. <ref type="bibr" target="#b36">[36]</ref> found who measured 0.27 seconds with the thumb and 0.31 seconds using the slower two-handed index finger input. In <ref type="bibr" target="#b26">[26]</ref>, Mori et al. specify 0.19 seconds for F.</p><p>When movements occur in the hotkey region only (as is the case for menu navigation sequences and when starting an application), F is smaller. Our studies indicate that the time drops to F = 0.16 seconds on average. Depending on the interaction, designers can choose which value fits better or use an average according to an assumed ratio of key uses. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Parameters</head><p>Some parameters cannot be measured in a single specific setting. The system response time, for example, differs strongly depending on the phone model, the application running on it, and the action invoked. Also, the influence of mental preparation and the appropriate placement of the Mental Act operator has always been a complex issue in KLM models. Kieras <ref type="bibr" target="#b21">[21]</ref> gives several suggestions and heuristics specifying where and in what quantity the operator should be placed that also apply to the model as used in this paper. Another parameter that belongs to the same category is the new Distraction operator D. It has not been treated in previous research on task models but we found that it has a considerable impact on time performance and there is a whole set of applications especially in the area of mobile interactions that are influenced by distractive and disruptive factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Response Time (R(t) or W(t))</head><p>As already discussed, information on system response times is supposed to be input to the model since these are highly diverse. We can, however, support the assumption of Silfverberg, MacKenzie and Korhonen <ref type="bibr" target="#b36">[36]</ref> that key presses in general have immediate feedback. Menu browsing and selection was also running in negligible amounts of time on the phones we investigated. Starting applications needed anything between 0 and 6 seconds. For our setting, we only explicitly give values for the special cases when tags are detected (NFC) or pictures taken.</p><p>Our 10 tests with a Nokia 3220 with a built-in NFC reader showed that the processing of a tag takes on average R NFC = 2.58 seconds. Using a Nokia N71, measurements for visual marker processing resulted in R marker = 2.22 seconds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distraction (X)</head><p>Interactions in the real world have to take into consideration various events that divert the concentration on the task at hand. This includes approaching people, passing cars, traffic lights, conversations, etc. Situations in which it is known that such distractions occur frequently (like at a bus stop) can be modelled with the Distraction operator.</p><p>People cope with such situations in different ways. They use their peripheral view, make quick glances, or introduce pauses. Initial tests showed that the behaviour also depends on the type of task. Thus, distraction can not be easily modelled as certain specific actions. Through our tests we found that it is more appropriate to model distraction as a multiplicative factor rather than an additive operator.</p><p>Although the type and consequences of distractions can be manifold, several studies of distraction and multi-tasking, e.g., by D. D. Salvucci <ref type="bibr" target="#b35">[35]</ref>, proved feasible in cognitive modelling. We give a simplified and rough but nevertheless justified idea how a task is probably slowed down by common side activities.</p><p>We ran three experiments, each with the same 10 people, aged 24-33, with an average of 26.7 years, 3 female. Subjects had to write a short message (about 90 characters) on their own phone in 3 different settings: a silent room (experiment 1), standing on a busy street (experiment 2) and walking along and crossing that street (experiment 3).</p><p>To obviate the possibility of sequence effects, we varied the order in which the participants conducted those trials. They also freely chose the contents of the message to write.</p><p>Typing speed of the participants varied considerably (0.76 to 3.49 characters per second in experiment 1). However, relative changes in the performance of each user are quite consistent. Experiments 2 and 3 revealed in an analysis of variance that the expected increase in time demand for distracted tasks is relevant well beyond the 5% level (t=2.23, p&lt;0.03 and t=3.28, p&lt;0.01). The results suggest to add X Slight = 6% of the modelled time to the whole interaction if there is an anticipated slight distraction and X Strong = 21% for distractions that force persons to deviate from their task in a more rigorous or regular fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mental Act (M)</head><p>As said earlier, we found no reason to change the value of M = 1.35 seconds from the original KLM. However, since we added and slightly changed the interpretation of some operators, we update the heuristics from Kieras <ref type="bibr" target="#b21">[21]</ref> to place M's: Use rule 0 to place M's and then cycle through rules 1 to 5 for each M to see whether it should be deleted. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PARAMETER VALUES OVERVIEW</head><p>Table <ref type="table" target="#tab_2">1</ref> shows the results of the studies. The median of each operator is given in the "Time" column. If applicable, the other two columns contain the 1 st and 3 rd quartiles, respectively. All times are specified in seconds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EVALUATION</head><p>To validate the values we found for the mobile phone KLM we set up a scenario, modelled it with our parameters and compared it to actual, observed timing data. The scenario was based on a ticket service for public transportation in Munich, Germany. The tasks included the download of a service from a poster augmented with NFC tags. The interaction device was a Nokia 3220 with built-in NFC reader. People had to order a ticket to a pre-defined target for three persons and write a text message to a friend about the expected time of arrival. In order to illustrate the applicability of the modelling approach, two different ways of accomplishing the main task were implemented: Using a form input on the phone's web browser, and using the NFC capabilities of the phone.</p><p>The participants were either routinely working with the used technology or trained before the study. None of them had taken part in any of the earlier studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>KLM Prediction</head><p>KLM predicts 122.77 seconds for the first variant of the scenario using direct input and browsing with a total of 110 operators. The model of the NFC version of the scenario uses 198 operators and predicts 174.84 seconds. Distractions were neither observed nor modelled. Table <ref type="table" target="#tab_4">2</ref> shows some excerpts of the latter model. The prediction was calculated independently of and before the validation based on a detailed analysis of the scenario and the heuristics given in an earlier section.  This means that the deviations of the KLM predictions to each data sample are in the small range of -15% to +8%.</p><p>The measured averages actually deviate only 5% and 3%, respectively. Furthermore, the speed loss of 30% of the NFC implementation predicted by the KLM is confirmed by the study with a measured average decrease of 31%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUMMARY AND DISCUSSION</head><p>We introduced a Keystroke-Level Model (KLM) that can be applied to most interactions currently available for mobile phones including advanced interactions involving identification tags or gestures. We described considerations and several user tests to get sound estimates of time values for the operators of that model. We also presented detailed explanations and guidelines for the use of these operators to enable application designers and teams to quickly model such interactions and compare different designs ahead of any implementation efforts.</p><p>It is evident that average users handle complex interaction styles differently and with different speed. It can also be hard to get into a routine for tasks that are new to a user even after several repetitions. This may render the expert user assumption difficult to support. The complexity of the interactions adds to this problem. However, our experience and evaluation show that for a set of interaction methods known to its users through at least sporadic use, estimates given by the mobile phone KLM are very good indeed. Especially when target users are young and 'hip' people or professional workers, it is very likely that these learn and adapt quickly and reach a state of experience that can be modelled close enough to make sound predictions.</p><p>We presented models of two different implementations of a real world scenario that also indicate that well grounded design decisions can be reached purely based on the model predictions. Nevertheless, we strongly encourage other researchers to expand our initial set of studies and examine our results through additional measurements and scenarios.</p><p>The collection of introduced operators is necessary to apply KLM to interactions such as those described in this paper.</p><p>According to the experiences in our lab and after reviewing relevant publications, we conclude that this set also suffices to capture the interactions possible with mobile phones at the current state of the art. Of course, time will inevitably bring different and additional types of interactions in the future for which new operators might have to be defined. Others might need adjustments when new or radically more time consuming variants are introduced (like complex gestures). It can also happen that some interactions become considerably easier (for example by getting rid of the need to accurately aim and focus for visual marker recognition). Nevertheless, after having conducted our tests, we are very positive that those changes are easy to integrate into the model and predictions can be made that lead to an early and valuable basis for design decisions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A sample of physical mobile phone interactions: using tags and taking pictures (of visual markers).</figDesc><graphic coords="2,455.70,630.30,91.80,68.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Micro , S Macro } is the set of available operators and n op , d op , D op are the numbers of occurrences of the operator op in the model without distraction, with slight, and with strong distraction, respectively. Distractions are modeled with the X operator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Attention shift (S Macro ) between the mobile phone and objects in the real world.</figDesc><graphic coords="3,322.74,347.82,110.88,83.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Regions of a standard mobile phone: keypad, hotkeys, and display. The S Micro operator measures eye movements between those regions.</figDesc><graphic coords="3,345.00,612.30,184.74,73.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Eye gaze positions during a task, overlaid over the phone in use. Left: write a text message. Right: set alarm time.</figDesc><graphic coords="6,66.48,409.56,94.62,139.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The Samsung SGH-E760 phone and some possible gestures recognised by the built-in acceleration sensor system.</figDesc><graphic coords="6,365.94,181.14,63.89,55.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Approximate finger movements (F) occurred while typing three different phone numbers on the Nokia N90.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Rule 0 Place M's in front of all K's, H's, S Macro 's and G's. Rule 1</head><label></label><figDesc>If an operator following an M is anticipated in the operator before M, delete the M (e.g.,</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>PMK becomes PK). Rule 2 If</head><label></label><figDesc>If a K is a redundant terminator (e.g., the selection key for entering submenus), then delete the M in front of it. Rule 4 Delete the M in front of a H which describes the movement from the reading to the listening position. Rule 5 If unsure, emphasise more the number than the placement of the occurrences of the M operator.</figDesc><table /><note><p>a string of MKs belongs to a cognitive unit (e.g., writing a known number), then delete all M's but the first. Rule 3</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 : Overview of the proposed times for all operators. Names of newly defined operators are set in bold.</head><label>1</label><figDesc></figDesc><table><row><cell cols="2">Operator</cell><cell cols="3">Time Quartile 1 Quartile 3</cell></row><row><cell></cell><cell>picture/marker</cell><cell>1.23</cell><cell>0.61</cell><cell>1.44</cell></row><row><cell>A, Action</cell><cell>NFC</cell><cell>0.00</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>in general</cell><cell cols="3">variable, input to model</cell></row><row><cell>D, Drawing</cell><cell></cell><cell></cell><cell>not applicable</cell><cell></cell></row><row><cell cols="2">F, Finger Movement</cell><cell>0.23</cell><cell>0.20</cell><cell>0.29</cell></row><row><cell>G, Gestures</cell><cell></cell><cell>0.80</cell><cell>0.73</cell><cell>0.87</cell></row><row><cell>H, Homing</cell><cell></cell><cell>0.95</cell><cell>0.81</cell><cell>1.00</cell></row><row><cell></cell><cell>externally</cell><cell>5.32</cell><cell>3.98</cell><cell>7.51</cell></row><row><cell>I, Initial Act</cell><cell>internally i optimal setting d</cell><cell>1.18 3.89</cell><cell>1.10 2.23</cell><cell>1.26 4.89</cell></row><row><cell></cell><cell>no assumptions</cell><cell>4.61</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>keypad average</cell><cell>0.39</cell><cell>0.37</cell><cell>0.48</cell></row><row><cell>K, Keystroke</cell><cell>keypad quick</cell><cell>0.33</cell><cell>0.32</cell><cell>0.37</cell></row><row><cell></cell><cell>hot Key</cell><cell>0.16</cell><cell>0.15</cell><cell>0.20</cell></row><row><cell>M, Mental Act</cell><cell></cell><cell>1.35</cell><cell>-</cell><cell>-</cell></row><row><cell>P, Pointing</cell><cell></cell><cell>1.00</cell><cell>0.84</cell><cell>1.20</cell></row><row><cell>R, System</cell><cell>NFC</cell><cell>2.58</cell><cell>2.46</cell><cell>2.80</cell></row><row><cell>Response</cell><cell>visual marker</cell><cell>2.22</cell><cell>2.09</cell><cell>2.82</cell></row><row><cell>Time</cell><cell>general</cell><cell cols="3">variable, input to model</cell></row><row><cell cols="2">S Macro Macro Attention Shift ,</cell><cell>0.36</cell><cell>0.28</cell><cell>0.44</cell></row><row><cell>S Micro ,</cell><cell>keypad ↔ display</cell><cell>0.14</cell><cell>0.14</cell><cell>0.19</cell></row><row><cell>Micro</cell><cell>hotkey ↔ display</cell><cell>0.12</cell><cell>0.02</cell><cell>0.14</cell></row><row><cell>Attention Shift</cell><cell>keypad ↔ hotkey in general</cell><cell>0.04 0.14</cell><cell>0.02 0.10</cell><cell>0.12 0.16</cell></row><row><cell>X,</cell><cell>slight</cell><cell>6 %</cell><cell>3 %</cell><cell>13 %</cell></row><row><cell>Distraction</cell><cell>strong</cell><cell>21 %</cell><cell>11 %</cell><cell>25 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 : Selected sequences from the proposed mobile phone Keystroke-Level Model of a scenario based on NFC tags. Empirical Validation</head><label>2</label><figDesc>Both alternatives of the scenario have been completed by 9 people (aged 23-34 with an average of 27.6 years, 3 female). The times needed for the first version ranged from 106 to 133 seconds with an average of 117 seconds (σ=9.38). The values are remarkably close to the predicted value of roughly 123 seconds. The upshots of the second, NFC version of the scenario are similar in magnitude: The average duration of the task was 170 seconds (times ranged between 147 and 190 seconds, σ=13.72) which is also very close to the KLM estimate of 175 seconds.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>April 28-May 3, 2007 • San Jose, CA, USA</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>If not explicitly stated otherwise, we present the median of the measured values and list 1 st and 3 rd quartiles in Tab . le 1</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Realising Physical Selection for Mobile Devices</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ailisto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Plomp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pohjanheimo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Strömmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PI&apos;03</title>
		<meeting>PI&apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="38" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Atomic Components of Thought</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lebiere</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Lawrence Erlbaum Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The Smart Phone: A Ubiquitous Input Device</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ballagas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Borchers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rohs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Sheridan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Pervasive Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="70" to="77" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sweep and Point and Shoot: Phonecam-based Interactions for Large Public Displays</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ballagas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rohs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Sheridan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts CHI&apos;05</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1200" to="1203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Keystroke Level Analysis of Email Message Organization</title>
		<author>
			<persName><forename type="first">O</forename><surname>Bälter</surname></persName>
		</author>
		<idno type="DOI">10.1145/332040.332413</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;00</title>
		<meeting>CHI&apos;00</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Here Comes the Wallet Phone</title>
		<author>
			<persName><forename type="first">J</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Spectrum</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Keystroke-Level Model for User Performance Time with Interactive Systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<idno type="DOI">10.1145/358886.358895</idno>
	</analytic>
	<monogr>
		<title level="j">Comm. ACM</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="7" to="396" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The Psychology of Human-Computer Interaction</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Moran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Lawrence Erlbaum Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Predictive Text Entry Methods for Mobile Phones</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Dunlop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Crossan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Personal Technologies</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">PhoneGuide: Museum Guidance Supported by On-device Object Recognition on Mobile Phones</title>
		<author>
			<persName><forename type="first">P</forename><surname>Föckler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zeidler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Brombach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bruns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bimber</surname></persName>
		</author>
		<idno type="DOI">10.1145/1149488.1149490</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. MUM&apos;05</title>
		<meeting>MUM&apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m">CHI 2007 Proceedings • Models of Mobile Interaction</title>
		<meeting><address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-05-03">April 28-May 3, 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Fowler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">QR Codes: In Japan, Billboards Take Code-crazy Ads to New Heights</title>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Designing Minimal Documentation Using a GOMS Model: a Usability Evaluation of an Engineering Approach</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Elkerton</surname></persName>
		</author>
		<idno type="DOI">10.1145/97243.97261</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;90</title>
		<meeting>CHI&apos;90</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="99" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Validation of the GOMS Model Methodology in the Development of a Specialized, Commercial Software Application</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kieras</surname></persName>
		</author>
		<idno type="DOI">10.1145/191666.191782</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;94</title>
		<meeting>CHI&apos;94</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="351" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Precis of Project Ernestine or an Overview of a Validation of GOMS</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Atwood</surname></persName>
		</author>
		<idno type="DOI">10.1145/142750.142821</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;92</title>
		<meeting>CHI&apos;92</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<biblScope unit="page" from="307" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Keystroke Level Analysis of a Graphics Application: Manual Map Digitizing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Haunold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;94</title>
		<meeting>CHI&apos;94</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="337" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Springboard: Multiple Modes in one Spring-loaded Control</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hinckley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Guimbretière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sarin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cutrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;06</title>
		<meeting>CHI&apos;06</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="181" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Optimizing Predictive Text Entry for Short Message Service on Mobile Phones</title>
		<author>
			<persName><forename type="first">Y</forename><surname>How</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Kan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. HCII&apos;05</title>
		<meeting>HCII&apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Text Input for Mobile Devices: Comparing Model Prediction to Actual Performance</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Reischel</surname></persName>
		</author>
		<idno type="DOI">10.1145/365024.365300</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;01</title>
		<meeting>CHI&apos;01</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="365" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Extensions of GOMS Analyses to Expert Performance Requiring Perception of Dynamic Visual and Auditory Information</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>John</surname></persName>
		</author>
		<idno type="DOI">10.1145/97243.97262</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;90</title>
		<meeting>CHI&apos;90</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="107" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A GOMS Analysis of a Graphic Machine-paced, Highly Interactive Task</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Vera</surname></persName>
		</author>
		<idno type="DOI">10.1145/142750.142805</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;92</title>
		<meeting>CHI&apos;92</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="251" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Using the Keystroke-Level Model to Estimate Execution Times. The University of Michigan</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kieras</surname></persName>
		</author>
		<ptr target="http://www.pitt.edu/~cmlewis/KSM.pdf" />
		<imprint>
			<date type="published" when="1993">2006. 1993</date>
		</imprint>
	</monogr>
	<note>Unpublished Report, Online Version as of August</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">T</forename><surname>Kindberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Caswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Debaty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gopal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Frid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schettino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Serra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Spasojevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">People, Places, Things: Web Presence for the Real World. Mobile Networks and Applications</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="365" to="376" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Validation of a Keystroke-Level Model for a Text Entry System Used by People with Disabilities</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Koester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Levine</surname></persName>
		</author>
		<idno type="DOI">10.1145/191028.191061</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. Assets&apos;94</title>
		<meeting>Assets&apos;94</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Predicting Task Execution Time on Handheld Devices Using the Keystroke-Level Model</title>
		<author>
			<persName><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>John</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI&apos;05</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1605" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Prediction of Destination Entry and Retrieval Times Using Keystroke-Level Models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Manes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hunter</surname></persName>
		</author>
		<idno>UMTRI-96- 37</idno>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>The University of Michigan Transportation</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Task Operation Prediction Time Computation Based on GOMS-KLM Improved for the Cellular Phone and the Verification of that Validity</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Matsunobe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yamaoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ADC&apos;03</title>
		<meeting>ADC&apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mobile Devices for Control</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LNCS 2411</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Keystroke-Level Analysis of Korean Text Entry Methods on Mobile Phones</title>
		<author>
			<persName><forename type="first">Myung</forename><forename type="middle">R</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.ijhcs.2003.10.002</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="5" to="6" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Model for Non-expert Text Entry Speed on 12-button Phone Keypads</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pavlovych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Stuerzlinger</surname></persName>
		</author>
		<idno type="DOI">10.1145/985692.985737</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;04</title>
		<meeting>CHI&apos;04</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="351" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The World Through the Computer: Computer Augmented Interaction with Real World Environments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rekimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nagao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST&apos;95</title>
		<meeting>UIST&apos;95</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Using Camera-equipped Mobile Phones for Interacting with Real-world Objects. Advances in Pervasive Computing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rohs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gfeller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Austrian Computer Society (OCG</publisher>
			<biblScope unit="page" from="265" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An Experimental Comparison of Physical Mobile Interaction Techniques: Touching, Pointing and Scanning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rukzio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Leichtenstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Callaghan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Holleis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Ubicomp&apos;06</title>
		<meeting>Ubicomp&apos;06</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mobile Service Interaction with the Web of Things</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rukzio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Paolucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Berndt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hamard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICT&apos;06</title>
		<meeting>ICT&apos;06</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Physical Posters as Gateways to Context-aware Services for Mobile Devices</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rukzio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hussmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WMCSA&apos;04</title>
		<meeting>WMCSA&apos;04</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Modeling Driver Distraction from Cognitive Tasks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Salvucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CogSci</title>
		<meeting>CogSci</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="792" to="797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Predicting Text Entry Speed on Mobile Phones</title>
		<author>
			<persName><forename type="first">M</forename><surname>Silfverberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Mackenzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;00</title>
		<meeting>CHI&apos;00</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Comparisons of Keystroke-Level Model Predictions to Observed Data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Teo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>John</surname></persName>
		</author>
		<idno type="DOI">10.1145/1125451.1125713</idno>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts CHI&apos;06</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1421" to="1426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A User Interaction Paradigm for Physical Browsing and Near-object Control Based on Tags</title>
		<author>
			<persName><forename type="first">P</forename><surname>Välkkynen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Plomp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tuomisto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cluitmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ailisto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Seppä</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PI&apos;03</title>
		<meeting>PI&apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="38" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Physical Browsing Research</title>
		<author>
			<persName><forename type="first">P</forename><surname>Välkkynen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tuomisto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PERMID&apos;05</title>
		<meeting>PERMID&apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="35" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Bridging Physical and Virtual Worlds with Electronic Tags</title>
		<author>
			<persName><forename type="first">R</forename><surname>Want</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Fishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gujar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Harrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;99</title>
		<meeting>CHI&apos;99</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="370" to="377" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
