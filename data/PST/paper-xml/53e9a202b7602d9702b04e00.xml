<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gradient Histogram Estimation and Preservation for Texture Enhanced Image Denoising</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<email>cslzhang@comp.polyu.edu.hk</email>
						</author>
						<author>
							<persName><forename type="first">Chunwei</forename><surname>Song</surname></persName>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">David</forename><surname>Zhang</surname></persName>
							<email>csdzhang@comp.polyu.edu.hk</email>
						</author>
						<author>
							<persName><forename type="first">Huijun</forename><surname>Gao</surname></persName>
							<email>huijungao@gmail.com</email>
						</author>
						<author>
							<persName><roleName>Dr</roleName><forename type="first">Wohlberg</forename><forename type="middle">W</forename><surname>Brendt</surname></persName>
						</author>
						<author>
							<persName><surname>Zuo</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<postCode>150001</postCode>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">School of Astronautics</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<postCode>150001</postCode>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">Research Institute of Intelligent Control and Sys-tems</orgName>
								<orgName type="institution" key="instit2">Harbin Institute of Technology</orgName>
								<address>
									<postCode>150001</postCode>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">with King Abdulaziz University</orgName>
								<address>
									<postCode>22254</postCode>
									<settlement>Jeddah</settlement>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Gradient Histogram Estimation and Preservation for Texture Enhanced Image Denoising</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">60BC428477AEF58FB97C7FDC3AF37EDE</idno>
					<idno type="DOI">10.1109/TIP.2014.2316423</idno>
					<note type="submission">received August 6, 2013; revised January 1, 2014 and March 31, 2014; accepted April 1, 2014. Date of publication April 10, 2014; date of current version May 1, 2014.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Image denoising</term>
					<term>histogram specification</term>
					<term>non-local similarity</term>
					<term>sparse representation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Natural image statistics plays an important role in image denoising, and various natural image priors, including gradient-based, sparse representation-based, and nonlocal selfsimilarity-based ones, have been widely studied and exploited for noise removal. In spite of the great success of many denoising algorithms, they tend to smooth the fine scale image textures when removing noise, degrading the image visual quality. To address this problem, in this paper, we propose a texture enhanced image denoising method by enforcing the gradient histogram of the denoised image to be close to a reference gradient histogram of the original image. Given the reference gradient histogram, a novel gradient histogram preservation (GHP) algorithm is developed to enhance the texture structures while removing noise. Two region-based variants of GHP are proposed for the denoising of images consisting of regions with different textures. An algorithm is also developed to effectively estimate the reference gradient histogram from the noisy observation of the unknown image. Our experimental results demonstrate that the proposed GHP algorithm can well preserve the texture appearance in the denoised images, making them look more natural.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>still active topic in image processing and low level vision. One widely used data observation model <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b10">[11]</ref> is y = x + v, where v is additive white Gaussian noise (AWGN). One popular approach to image denoising is the variational method, where an energy functional is minimized to search the desired estimation of x from its noisy observation y. The energy functional usually involves two terms: a data fidelity term which depends on the image degeneration process and a regularization term which models the prior of clean natural images <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b11">[12]</ref>. The statistical modeling of natural image priors is crucial to the success of image denoising.</p><p>Motivated by the fact that natural image gradients and wavelet transform coefficients have a heavy-tailed distribution, sparsity priors are widely used in image denoising <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>. The well-known total variation minimization methods actually assume Laplacian distribution of image gradients <ref type="bibr" target="#b3">[4]</ref>. The sparse Laplacian distribution is also used to model the high-pass filter responses and wavelet/curvelet transform coefficients <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. By representing image patches as a sparse linear combination of the atoms in an over-complete redundant dictionary, which can be analytically designed or learned from natural images, sparse coding has proved to be very effective in image denoising via l 0 -norm or l 1 -norm minimization <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>. Another popular prior is the nonlocal self-similarity (NSS) prior <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b49">[50]</ref>; that is, in natural images there are often many similar patches (i.e., nonlocal neighbors) to a given patch, which may be spatially far from it. The connection between NSS and the sparsity prior is discussed in <ref type="bibr" target="#b10">[11]</ref> and <ref type="bibr" target="#b11">[12]</ref>. The joint use of sparsity prior and NSS prior has led to state-of-the-art image denoising results <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b13">[14]</ref>. In spite of the great success of many denoising algorithms, however, they often fail to preserve the image fine scale texture structures <ref type="bibr" target="#b22">[23]</ref>, degrading much the image visual quality (please refer to Fig. <ref type="figure" target="#fig_0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>for example).</head><p>With the rapid development of digital imaging technology, now the acquired images can contain tens of megapixels. On one hand, more fine scale texture features of the scene will be captured; on the other hand, the captured high definition image is more prone to noise because the smaller size of each pixel makes the exposure less sufficient. Unfortunately, suppressing noise and preserving textures are difficult to achieve simultaneously, and this has been one of the most challenging problems in natural image denoising. Unlike large scale edges, the fine scale textures are much more complex and are hard to characterize by using a sparse model. Texture regions in an image are homogeneous and are composed of similar local patterns, which can be characterized by using local descriptors or textons <ref type="bibr" target="#b42">[43]</ref>. Cognitive studies <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref> Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>Examples of denoised images and their gradient histograms. (a) A cropped image with hair textures; (b) denoised image by the SAPCA-BM3D method <ref type="bibr" target="#b10">[11]</ref>; (c) denoised image by the proposed texture enhanced image denoising via gradient histogram preservation (GHP); (d) the gradient histograms of the denoised images. One can see that the proposed GHP method can recover more texture details than other methods, and the gradient histogram of the denoised image by GHP is also closer to the gradient histogram of ground truth image.</p><p>have revealed that the first-order statistics, e.g., histograms, are the most significant descriptors for texture discrimination. Considering these facts, histogram of local features has been widely used in texture analysis <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b16">[17]</ref>. Meanwhile, image gradients are crucial to the perception and analysis of natural images <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>. All these motivate us to use the histogram of image gradient to design new image denoising models.</p><p>With the above considerations, in this paper we propose a novel gradient histogram preservation (GHP) method for texture enhanced image denoising. From the given noisy image y, we estimate the gradient histogram of original image x. Taking this estimated histogram, denoted by h r , as a reference, we search an estimate of x such that its gradient histogram is close to h r . As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, the proposed GHP based denoising method can well enhance the image texture regions, which are often over-smoothed by other denoising methods. The major contributions of this paper are summarized as follows: Studies on natural image priors aim to find suitable models to describe the characteristics or statistics (e.g., distribution) of images in some domain. One representative class of image priors is the gradient prior based on the observation that natural images have a heavy-tailed distribution of gradients. The use of gradient prior can be traced back to 1990s when Rudin et al. <ref type="bibr" target="#b3">[4]</ref> proposed a total variation (TV) model for image denoising, where the gradients are actually modeled as Laplacian distribution. Another well-known prior model, the mixture of Gaussians, can also be used to approximate the distribution of image gradient <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b21">[22]</ref>. In addition, hyper-Laplacian model can more accurately characterize the heavytailed distribution of gradients, and has been widely applied to various image restoration tasks <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b22">[23]</ref>- <ref type="bibr" target="#b24">[25]</ref>.</p><p>The image gradient prior is a kind of local sparsity prior, i.e., the gradient distribution is sparse. More generally, the local sparsity prior can be well applied to high-pass filter responses, wavelet/curvelet transform coefficients, or the coding coefficients over a redundant dictionary. In <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b5">[6]</ref>, Gaussian scale mixtures are used to characterize the marginal and joint distributions of wavelet transform coefficients. In <ref type="bibr" target="#b25">[26]</ref> and <ref type="bibr" target="#b26">[27]</ref>, the Student t-distributions are used for both basis filter learning and filter response modeling. By assuming that an image patch can be represented as a sparse linear combination of the atoms in an over-complete dictionary, a number of dictionary learning (DL) methods (e.g., analysis and synthesis K-SVD <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b27">[28]</ref>, task driven DL <ref type="bibr" target="#b28">[29]</ref>, and adaptive sparse domain selection <ref type="bibr" target="#b7">[8]</ref> have been proposed and applied to image denoising and other image restoration tasks.</p><p>Based on the fact that a similar patch to the given patch may not be spatially close to it, another line of research is to model the similarity between image patches, i.e., the image nonlocal self-similarity (NSS) priors. The seminal work of nonlocal means denoising <ref type="bibr" target="#b8">[9]</ref> has motivated a wide range of studies on NSS, and has led to a flurry of NSS based state- of-the-art denoising methods, e.g., BM3D <ref type="bibr" target="#b10">[11]</ref>, LSSC <ref type="bibr" target="#b11">[12]</ref>, and EPLL <ref type="bibr" target="#b29">[30]</ref>, etc. While most of the NSS based methods find similar patches on the original scale, recent studies have shown that NSS across different scales can also benefit image denoising <ref type="bibr" target="#b51">[52]</ref>. Under the NSS framework, Levin et al. <ref type="bibr" target="#b30">[31]</ref> investigated the inherent limit of denoising algorithms, and their empirical validation showed that the existing methods might still be improved by 1 dB.</p><p>Different image priors characterize different and complementary aspects of natural image statistics, and thus it is possible to combine multiple priors to improve the denoising performance. For example, Dong et al. <ref type="bibr" target="#b12">[13]</ref> unified both image local sparsity and nonlocal similarity priors via clusteringbased sparse representation. Recently, Jancsary et al. <ref type="bibr" target="#b31">[32]</ref> proposed a method called regression tree fields (RTF) to integrate different priors.</p><p>However, many existing image denoising algorithms, including those local sparsity and NSS based ones, tend to wipe out the image fine scale textures while removing noise. As we discussed in Section I, considering the randomness and homogeneousness of image texture regions, we propose to use the histogram of gradient to describe image texture and design a novel image denoising algorithm with gradient histogram preservation. In <ref type="bibr" target="#b22">[23]</ref> and <ref type="bibr" target="#b23">[24]</ref>, Cho et al. used hyper-Laplacian distribution to model gradient, and proposed a content-aware prior for image deblurring by setting different shape parameters of gradient distribution in different image regions. By matching the gradient distribution prior, Cho et al. <ref type="bibr" target="#b22">[23]</ref> found that the deblurred images can have more detailed textures as well as better visual quality. However, in <ref type="bibr" target="#b22">[23]</ref> and <ref type="bibr" target="#b23">[24]</ref> the estimation of desired gradient distribution is rather heuristic, and the iterative distribution reweighting algorithm is very complex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. THE TEXTURE ENHANCED IMAGE DENOISING FRAMEWORK</head><p>The noisy observation y of an unknown clean image x is usually modeled as</p><formula xml:id="formula_0">y = x + v, (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where v is the additive white Gaussian noise (AWGN) with zero mean and standard deviation σ . The goal of image denoising is to estimate the desired image x from y. One popular approach to image denoising is the variational method, in which the denoised image is obtained by</p><formula xml:id="formula_2">x = arg min x 1 2σ 2 y -x 2 + λ • R(x) ,<label>(2)</label></formula><p>where R(x) denotes some regularization term and λ is a positive constant. The specific form of R(x) depends on the employed image priors.</p><p>One common problem of image denoising methods is that the image fine scale details such as texture structures will be over-smoothed. An over-smoothed image will have much weaker gradients than the original image. Intuitively, a good estimation of x without smoothing too much the textures should have a similar gradient distribution to that of x. With this motivation, we propose a gradient histogram preservation (GHP) model for texture enhanced image denoising, whose framework is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>.</p><p>Suppose that we have an estimation of the gradient histogram of x, denote by h r . In order to make the gradient histogram of denoised image x nearly the same as the reference histogram h r , we propose the following GHP based image denoising model:</p><formula xml:id="formula_3">x = arg min x,F 1 2σ 2 y-x 2 +λR(x)+μ F(∇x)-∇x 2 , s.t. h F = h r , (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>where F denotes an odd function which is monotonically non-descending, h F denotes the histogram of the transformed gradient image |F (∇x)|, ∇ denotes the gradient operator, and μ is a positive constant. The proposed GHP algorithm adopts the alternating optimization strategy. Given F, we can fix ∇x 0 = F(∇x), and update x. Given x, we can update F by the histogram specification based shrinkage operator which will be introduced in Section IV. Thus, by introducing F, we can easily incorporate the gradient histogram constraint with any existing image regularizer R(x).</p><p>Another issue in the GHP model is how to find the reference histogram h r of unknown image x. In practice, we need to estimate h r based on the noisy observation y. In Section V, we will propose a regularized deconvolution model and an associated iterative deconvolution algorithm to estimate h r from the given noisy image. Once the reference histogram h r is obtained, the GHP algorithm is then applied for texture enhanced image denoising.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DENOISING WITH GRADIENT HISTOGRAM PRESERVATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The Denoising Model</head><p>The proposed denoising method is a patch based method. Let x i = R i x be a patch extracted at position i , i = 1, 2, . . . , N, where R i is the patch extraction operator and N is the number of pixels in the image. Given a dictionary D, we sparsely encode the patch x i over D, resulting in a sparse coding vector α i . Once the coding vectors of all image patches are obtained, the whole image x can be reconstructed by <ref type="bibr" target="#b6">[7]</ref>:</p><formula xml:id="formula_5">x = D • α N i=1 R T i R i -1 N i=1 R T i Dα i , (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>where α is the concatenation of all α i . Good priors of natural images are crucial to the success of an image denoising algorithm. A proper integration of different priors could further improve the denoising performance. For example, the methods in <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b13">[14]</ref>, and <ref type="bibr" target="#b31">[32]</ref> integrate image local sparsity prior with nonlocal NSS prior, and they have shown promising denoising results. In the proposed GHP model, we adopt the following sparse nonlocal regularization term proposed in the nonlocally centralized sparse representation (NCSR) model <ref type="bibr" target="#b13">[14]</ref>:</p><formula xml:id="formula_7">R(x) = i α i -β i 1 , s.t. x = D • α, (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>where β i is defined as the weighted average of α q i :</p><formula xml:id="formula_9">β i = q w q i α q i ,<label>(6)</label></formula><p>and α q i is the coding vector of the qth nearest patch (denoted by x q i ) to x i . The weight is defined as</p><formula xml:id="formula_10">w q i = 1 W exp -1 h xi - xq i 2 (</formula><p>xi and xq i denote the current estimates of x i and x q i , respectively), where h is a predefined constant and W is the normalization factor. More detailed explanations on NCSR can be found in <ref type="bibr" target="#b13">[14]</ref>.</p><p>By incorporating the above R(x) into Eq. ( <ref type="formula" target="#formula_3">3</ref>), the proposed GHP model can be formulated as:</p><formula xml:id="formula_11">x = arg min x,F × 1 2σ 2 y-x 2 +λ i α i -β i 1 +μ F(∇x)-∇x 2 s.t. x = D • α, h F = h r . (<label>7</label></formula><formula xml:id="formula_12">)</formula><p>From the GHP model with sparse nonlocal regularization in Eq. ( <ref type="formula" target="#formula_11">7</ref>), one can see that if the histogram regularization parameter μ is high, the function F (∇x) will be close to ∇x.</p><p>Since the histogram h F of |F (∇x)| is required to be the same as h r , the histogram of ∇x will be similar to h r , leading to the desired gradient histogram preserved image denoising. In the next subsection, we will see that there is an efficient iterative histogram specification algorithm to solve the model in Eq. ( <ref type="formula" target="#formula_11">7</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Iterative Histogram Specification Algorithm</head><p>The proposed GHP model in Eq. ( <ref type="formula" target="#formula_11">7</ref>) can be solved by using the variable splitting (VS) method, which has been widely adopted in image restoration <ref type="bibr" target="#b39">[40]</ref>- <ref type="bibr" target="#b41">[42]</ref>. By introducing a variable g = F(∇x), we adopt an alternating minimization strategy to update x and g alternatively. Given g = F(∇x), we update x (i.e., α) by solving the following sub-problem:</p><formula xml:id="formula_13">min x 1 2σ 2 y -x 2 + λ i α i -β i 1 + μ g -∇x 2 s.t.x = D • α. (<label>8</label></formula><formula xml:id="formula_14">)</formula><p>We use the method in <ref type="bibr" target="#b13">[14]</ref> to construct the dictionary D adaptively. Based on the current estimation of image x, we cluster its patches into K clusters, and for each cluster, a PCA dictionary is learned. Then for each given patch, we first check which cluster it belongs to, and then use the PCA dictionary of this cluster as D. Although in Eq. ( <ref type="formula" target="#formula_13">8</ref>) the l 1 -norm regularization is imposed on α i -β i 1 rather than α i 1 , by introducing a new variable ϑ i = α i -β i , we can use the iterative shrinkage/thresholding method <ref type="bibr" target="#b32">[33]</ref> to update ϑ i and then update α i = ϑ i + β i . This strategy is also used in <ref type="bibr" target="#b13">[14]</ref> to solve the problem with this regularization term, and thus here we omit the detailed deduction process.</p><p>To get the solution to the sub-problem in Eq. ( <ref type="formula" target="#formula_13">8</ref>), we first use a gradient descent method to update x: <ref type="bibr" target="#b8">(9)</ref> where δ is a pre-specified constant. Then, the coding coefficients α i are updated by</p><formula xml:id="formula_15">x (k+1/2) = x (k) +δ 1 2σ 2 (y-x (k) )+μ∇ T g -∇x (k) ,</formula><formula xml:id="formula_16">α (k+1/2) i = D T R i x (k+1/2) . (<label>10</label></formula><formula xml:id="formula_17">)</formula><p>By using Eq. ( <ref type="formula" target="#formula_9">6</ref>) to obtain β i , we further update α i by</p><formula xml:id="formula_18">α (k+1) i = S λ/d α (k+1/2) i -β i + β i ,<label>(11)</label></formula><p>where S λ/d is the soft-thresholding operator, and d is a constant to guarantee the convexity of the surrogate function <ref type="bibr" target="#b32">[33]</ref>. Finally, we update x (k+1) by</p><formula xml:id="formula_19">x (k+1) = D • α (k+1) N i=1 R T i R i -1 N i=1 R T i Dα (k+1) i . (<label>12</label></formula><formula xml:id="formula_20">)</formula><p>Once the estimate of image x is given, we can update F by solving the following sub-problem:</p><formula xml:id="formula_21">min g,F g -∇x 2 s.t. h F = h r , g = F(∇x). (<label>13</label></formula><formula xml:id="formula_22">)</formula><p>Considering the equality constraint g = F(∇x), we can substitute g in g -∇x 2 with F(∇x), and the sub-problem becomes</p><formula xml:id="formula_23">min F F(∇x) -∇x 2 s.t. h F = h r . (<label>14</label></formula><formula xml:id="formula_24">)</formula><p>To solve this sub-problem, by introducing d 0 = |∇x|, the standard histogram specification operator <ref type="bibr" target="#b33">[34]</ref> can be used to obtain the only feasible monotonic non-parametric transform T which makes the histogram of T (d 0 ) the same as h r . Note that (xy) 2 ≤ ((-x)y) 2 if the signs of x and y are the same. Since F (|∇x|) = T (|∇x|), to minimizing the squared error F (∇x) -∇x 2 , we should require that the sign of F (∇x) is the same as that of ∇x. Thus, we define F (∇x) as</p><formula xml:id="formula_25">F (∇x) = sgn (∇x) T (|∇x|) . (<label>15</label></formula><formula xml:id="formula_26">)</formula><p>Given F (∇x), we then let g = F (∇x).</p><p>The proposed iterative histogram specification (IHS) based GHP algorithm is summarized in Algorithm 1. It should be noted that, for any gradient based image denoising model, we can easily adapt the proposed GHP to it by simply modifying the gradient term and adding an extra histogram specification operation.</p><p>The GHP model in Eq. ( <ref type="formula" target="#formula_11">7</ref>) is nonconvex, and thus the proposed algorithm cannot be guaranteed to converge to a global optimum. However, it is empirically found that our GHP algorithm converges rapidly. Fig. <ref type="figure">3</ref> shows an example convergence curve of the proposed GHP algorithm on image Bear (in Fig. <ref type="figure" target="#fig_1">2</ref>). One can see that GHP converges within 15 20 iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Region-Based GHP</head><p>The histogram constraint in Eq. ( <ref type="formula" target="#formula_11">7</ref>) is global. If the image consists of different regions with different textures, GHP </p><formula xml:id="formula_27">F k (i, j )∈ k F k (∇x) i j -(∇x) i j 2 s.t. h F k = h r,k . (<label>16</label></formula><formula xml:id="formula_28">)</formula><p>We define an indicator function</p><formula xml:id="formula_29">1 c (i, j ) = 1, if(i, j ) ∈ k 0, else.<label>(17)</label></formula><p>The F (∇x) for S-GHP/B-GHP can then be defined as</p><formula xml:id="formula_30">F(∇x) = k F k (∇x)1 k .<label>(18)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. REFERENCE GRADIENT HISTOGRAM ESTIMATION</head><p>To apply the model in Eq. ( <ref type="formula" target="#formula_11">7</ref>), we need to know the reference gradient histogram h r of original image x. In this section, we propose a regularized deconvolution model to estimate the histogram h r . Assuming that the pixels in gradient image ∇x are independent and identically distributed (i.i.d.), we can view them as the samples of a scalar variable, denoted by x. Then the normalized histogram of ∇x can be regarded as a discrete approximation of the probability density function (PDF) of x. For the AWGN v, we can readily model its elements as the samples of an i.i.d. variable, denoted by v. Since v ∼ N 0, σ 2 and let ε = ∇v, ε can then be well approximated by the i.i.d. Gaussian with PDF <ref type="bibr" target="#b37">[38]</ref> </p><formula xml:id="formula_31">p ε = 1 2 √ πσ exp - ε 2 4σ 2 . (<label>19</label></formula><formula xml:id="formula_32">)</formula><p>Since y = x + v, we have ∇y = ∇x + ∇v. It is ready to model ∇y as an i.i.d. variable, denoted by y, and we have y = x + ε. Let p x be the PDF of x, and p y be the PDF of y. Since x and ε are independent, the joint PDF p (x, ε) is</p><formula xml:id="formula_33">p(x, ε) = p x × p ε . (<label>20</label></formula><formula xml:id="formula_34">)</formula><p>Then the PDF p y is</p><formula xml:id="formula_35">p y (y = t) = a p x (x = a) × p ε (ε = (t -a)) da. (<label>21</label></formula><formula xml:id="formula_36">)</formula><p>If we use the normalized histogram h x and h y to approximate p x and p y , we can rewrite Eq. ( <ref type="formula" target="#formula_35">21</ref>) in the discrete domain as:</p><formula xml:id="formula_37">h y = h x ⊗ h ε ,<label>(22)</label></formula><p>where ⊗ denotes the convolution operator. Note that h ε can be obtained by discretizing p ε , and h y can be computed directly from the noisy observation y.</p><p>Obviously, the estimation of h x can be generally modeled as a deconvolution problem:</p><formula xml:id="formula_38">h r = arg min h x h y -h x ⊗ h ε 2 + c • R (h x ) , (<label>23</label></formula><formula xml:id="formula_39">)</formula><p>where c is a constant and R(h x ) is some regularization term based on the prior information of natural image's gradient histogram. We consider two kinds of constraints on h x . First, it has been shown that p x (i.e., the continuous counterpart of h x ) can be approximated by hyper-Laplacian distribution <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>. Considering that the real h x might deviate from the hyper-Laplacian distribution to some extent, we only require that h x should be close to the hyper-Laplacian distribution:</p><formula xml:id="formula_40">p x ≈ C • exp -κ|x| γ , (<label>24</label></formula><formula xml:id="formula_41">)</formula><p>where C is the normalization factor, γ and κ are the two parameters of the hyper-Laplacian distribution. More specifically, we let κ ∈ [0.001, 3] and γ ∈ [0.02, 1.5]. Second, each element of h x should be nonnegative. Based on these two constraints, gradient histogram estimation can be formulated as the following regularized deconvolution problem:</p><formula xml:id="formula_42">h r = arg min h x ,C,κ,γ h y -h x ⊗ h ε 2 +c h x -C • exp(-κ|x| γ ) 2 , s.t. h x ≥ 0, (<label>25</label></formula><formula xml:id="formula_43">)</formula><p>which can be re-written as:</p><formula xml:id="formula_44">h r = argmin h x ,h x ,C,κ,γ ⎧ ⎪ ⎨ ⎪ ⎩ h y -h x ⊗ h ε 2 + c h x -C • exp(-κ|x| γ ) 2 + η h x -h x 2 ⎫ ⎪ ⎬ ⎪ ⎭ s.t. h x ≥ 0. (<label>26</label></formula><formula xml:id="formula_45">)</formula><p>We iteratively update h x , h x , C, γ , and κ alternatively. Let</p><formula xml:id="formula_46">h 0 = C • exp(-κ|x| γ ), h x is updated by h x = F FT (h ε ) • F FT (h y ) + cF F T (h 0 ) + ηF FT (h x ) F FT (h ε ) • F FT (h ε ) + c + η , (<label>27</label></formula><formula xml:id="formula_47">)</formula><p>where "•" denotes the element-wise multiplication, " * * " denotes the element-wise division, and " * " denotes the complex conjugate operator. h x is updated by</p><formula xml:id="formula_48">h x (i ) = max (h x (i ), 0). (<label>28</label></formula><formula xml:id="formula_49">)</formula><p>C is updated by</p><formula xml:id="formula_50">C = i exp(-κ|i | γ ) i h x (i ) . (<label>29</label></formula><formula xml:id="formula_51">)</formula><p>γ and κ are updated based on gradient decent</p><formula xml:id="formula_52">κ (t +1) = κ (t ) + τ i C|i | γ exp(-κ (t ) |i | γ ) × C • exp(-κ (t ) |i | γ -h x (i ) , (<label>30</label></formula><formula xml:id="formula_53">)</formula><formula xml:id="formula_54">γ (t +1) = γ (t ) + ρ |i =0| Cκ (t ) |i | γ ln |i | exp(-κ (t ) |i | γ )• C • exp(-κ (t ) |i | γ -h x (i ) . (<label>31</label></formula><formula xml:id="formula_55">)</formula><p>Fig. <ref type="figure" target="#fig_4">5</ref> shows an example of reference gradient histogram estimation. It can be seen that our method can obtain a good estimation of h x . For region based B-GHP and S-GHP, the regularized deconvolution method can be directly applied to each region to estimate the corresponding reference gradient histogram.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EXPERIMENTAL RESULTS</head><p>To verify the performance of the proposed GHP based image denoising method, we apply it to ten natural images with various texture structures, whose scenes are shown in Fig. <ref type="figure" target="#fig_5">6</ref>. All the test images are gray-scale images with gray level ranging from 0 to 255. We first discuss the parameter setting in our GHP algorithm, and then compare the performance of global based GHP and its region based variants, i.e., B-GHP and S-GHP. Finally, experiments are conducted to validate its performance in comparison with the state-of-the-art denoising algorithms. In the following experiments we set the AWGN standard deviation from 20 to 40 with step length 5.<ref type="foot" target="#foot_0">1</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Parameter Setting</head><p>There are 4 parameters in our GHP algorithm and 4 parameters in the reference histogram estimation algorithm. All these parameters are fixed in our experiments.</p><p>1) Parameters in the GHP Algorithm: The proposed GHP algorithm has two model parameters: λ, and μ. We use the same strategy as in the original NCSR model <ref type="bibr" target="#b13">[14]</ref> to determine the value of λ. The parameter μ is introduced to balance the nonlocally centralized sparse representation term and the histogram preservation term. If μ is is set very large, GHP can ensure that the gradient histogram of the denoising result is the same as the reference histogram. Considering that in practice the reference histogram is estimated from the noisy image and there are certain estimation errors, μ cannot be set too big. We empirically set μ to 5 based on our experimental experience.</p><p>The GHP algorithm involves two more algorithm parameters: δ and d. Following <ref type="bibr" target="#b13">[14]</ref>, when the noise standard deviation is less than 30, we set δ to 0.23; when else we set δ to 0.26. Based on <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b32">[33]</ref>, to guarantee the convexity of the surrogate function, d should be larger than the spectral norm of dictionary D. Since in our algorithm D is an adaptively selected orthogonal PCA dictionary, any d ≥ 1 will be fine. According to <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b32">[33]</ref> we choose a little higher d (d = 3) for numerical stability of the algorithm.</p><p>In summary, compared with NCSR, GHP only introduces one extra model parameter μ, and we set it to 5 by experience in all the experiments.</p><p>2) Parameters in Reference Histogram Estimation: Our reference histogram estimation method involves two model parameters, i.e., c and η. Image gradients are generally assumed to follow hyper-Laplacian distributions <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. We choose a relatively large c value, i.e., c = 10, to ensure that the estimated histogram should be close to a hyper-Laplacian distribution. The parameter η is introduced to ensure the nonnegative property of the estimated histogram, and a large η value should be set to guarantee that the estimated histogram is non-negative. Thus we also choose a large η value, i.e., η = 10, in the implementation.</p><p>There are also two algorithm parameters, τ and ρ, in our reference histogram estimation method. τ and ρ denote the step sizes in the gradient descent algorithm to update κ and γ , respectively. If the step size is sufficiently small, the gradient descent algorithm would converge to a local optimum <ref type="bibr" target="#b52">[53]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE I THE K-L DIVERGENCE BETWEEN THE ESTIMATED AND GROUND-TRUTH GRADIENT HISTOGRAMS</head><p>Thus we set two smaller values to τ and ρ, i.e., τ = 0.01 and ρ = 0.01.</p><p>In Fig. <ref type="figure" target="#fig_4">5</ref>, we have shown an example of gradient histogram estimation, and it can be seen that the estimated gradient histogram is very close to the ground-truth. Table I lists the K-L divergence between the estimated and the ground-truth (obtained using the noiseless image) gradient histograms for the ten test images with different standard deviations of noise.</p><p>From Table <ref type="table">I</ref>, one can see that the average K-L divergence is less than 0.1 and the standard deviation is less than 0.08, indicating that the proposed gradient histogram estimation method can obtain satisfactory estimation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparison Between the Three GHP Variants</head><p>By setting the AWGN standard deviation σ ∈ {20, 25, 30, 35, 40}, we evaluate the three variants of the proposed method, i.e., GHP, B-GHP, and S-GHP, in terms of PSNR and the perceptual quality index SSIM <ref type="bibr" target="#b38">[39]</ref>. To evaluate if the proposed reference gradient histogram estimation method is effective for the final noise removal performance, we couple GHP with both the estimated gradient histogram and the ground truth gradient histogram and compare the outputs. Table <ref type="table" target="#tab_0">II</ref> lists the PSNR and SSIM values on the ten test images. One can see that GHP achieves similar PSNR/SSIM values by using the estimated gradient histogram and the ground truth gradient histogram.</p><p>We then compare the performance of GHP, B-GHP and S-GHP on the ten test images. The PSNR and SSIM indices are also listed in Table <ref type="table" target="#tab_0">III</ref>. One can see that the regionbased GHP methods, i.e., B-GHP and S-GHP, generally achieve better results than GHP in terms of both PSNR and SSIM. Fig. <ref type="figure" target="#fig_6">7</ref> shows an example of the denoising outputs by GHP, B-GHP, and S-GHP on test image 6. Since natural images often consist of regions with different textures and GHP uses the global gradient histogram for texture enhanced denoising, sometimes false textures can be generated in the less textured areas GHP. By simply partitioning the image into regular blocks, the block based B-GHP can reduce the possibility of generating false textures. By segmenting the image into texture homogeneous regions,  <ref type="table" target="#tab_0">III</ref> THE PSNR (dB) AND SSIM RESULTS OF GHP, B-GHP, AND S-GHP S-GHP can further achieve better denoising results than B-GHP in terms of PSNR/SSIM measures and subjective visual quality, as demonstrated in Fig. <ref type="figure" target="#fig_6">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparison With the State-of-the-Arts</head><p>We then compare S-GHP with some state-of-the-art denoising methods, including shape-adaptive PCA based BM3D (SAPCA-BM3D) <ref type="bibr" target="#b10">[11]</ref>, the learned simultaneously sparse coding (LSSC) <ref type="bibr" target="#b11">[12]</ref> and the NCSR <ref type="bibr" target="#b13">[14]</ref> methods. The codes of all the competing methods are provided by the authors and we used the recommended parameters by the authors.</p><p>On a PC with two Intel CPUs (1.86 GHz) and 2GB RAM, under Matlab 2011a programming environment, GHP spends 2383s to process a 512 × 512 image, which is similar to B-GHP (2388s), S-GHP (2386s) and NCSR (2445s) but is much faster than LSSC (4287s). SAPCA-BM3D spends 420s to process a 512 × 512 image but it should be noted that SAPCA-BM3D is mainly implemented by C programming language.</p><p>The quantitative experimental results by competing methods are shown in Tables IV. One can see that the proposed S-GHP method has similar PSNR/SSIM measures to SAPCA-BM3D, LSSC and NCSR. Nonetheless, the goal of our GHP method </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE IV</head><p>THE PSNR (dB) AND SSIM VALUES OF SAPCA-BM3D (BM3D), LSSC, NCSR AND S-GHP is to preserve and enhance the image texture structures, and we further compare the visual quality of the denoised images by these methods. Fig. <ref type="figure" target="#fig_7">8</ref> shows the denoising results of noisy image 7 with noise standard deviation σ = 30. In this image, there are different texture regions, such as sky, tree, water and building. We can see that SAPCA-BM3D, LSSC and NCSR smooth too much the textures in tree, water and building areas, while LSSC introduces some artifacts in the smooth sky area. Though these methods have good PSNR and even SSIM indices, the denoised images by them look somewhat unnatural. In contrast, S-GHP preserves much better the fine textures in areas of tree and water, making the denoised image look more natural and visually pleasant. It should also be noted that, the better visual quality in areas of tree and water of S-GHP might not always result in higher PSNR or SSIM values on the close-ups.</p><p>Fig. <ref type="figure" target="#fig_8">9</ref> shows the denoising results of image 1 with noise standard deviation σ = 30. This image consists of texture regions like cloud, tree, and water. We can see that SAPCA-BM3D, LSSC and NCSR tend to over-smooth the  textures in tree and water areas. In contrast, S-GHP preserves much better the fine texture in tree and water areas, while making the cloud area look more natural.</p><p>Due to the limit of space, we do not show the full denoised images in the main paper. However, examples of full denoised images are given in the supplementary file. Similar conclusions can be made; that is, S-GHP obtains more natural denoising results and preserves better the fine textures. We also evaluated the denoising performance of competing methods under lower (i.e., σ = 5, 10, 15) and higher noise standard deviations (i.e., σ = 50, 80, 100). Please refer to the supplementary file for the detailed results. In terms of average PSNR and SSIM, S-GHP is comparable to SAPCA-BM3D, LSSC and NCSR. In terms of visual quality, when the noise standard deviation is high, S-GHP can preserve better the textures and strong edges than the competing methods. When the noise standard deviation is low, S-GHP can preserve better image fine textures.</p><p>The proposed S-GHP method has similar overall PSNR/SSIM results to the state-of-the-arts and it leads to better visual quality of the denoised images. In terms of visual quality, it improves much the textured areas. However, the improvement in visual quality may not result in PSNR and SSIM improvements. S-GHP enforces the statistical distribution of image gradients to be close to the reference histogram, but it cannot guarantee that the restored image will be close to the real image in terms of PSNR or SSIM. Using image 6 with AWGN of standard deviation 30 as an example, we calculate the local PSNR maps (with a sliding window of size 41 × 41) for the denoised images by SAPCA-BM3D and S-GHP. Denote by p B M3D and p G H P the two local PSNR maps of SAPCA-BM3D and S-GHP, respectively. In Fig. <ref type="figure" target="#fig_9">10</ref>, we show the original image, the denoised images by SAPCA-BM3D and S-GHP, and the difference map (p B M3Dp G H P ). The white values indicate the areas where p B M3D is higher than p G H P , while the dark values indicate the areas where p G H P is higher than p B M3D . One can see that, in terms of PSNR, S-GHP outperforms SAPCA-BM3D in many smooth areas, while SAPCA-BM3D outperforms S-GHP in many textured areas. However, the denoised image by S-GHP has better visual quality than the one by SAPCA-BM3D in most textured and smooth areas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Subjective Evaluation</head><p>How to evaluate the perceptual quality of an image is a very challenging problem. Though many image quality assessment (IQA) indices (e.g., SSIM <ref type="bibr" target="#b38">[39]</ref> and FSIM <ref type="bibr" target="#b50">[51]</ref>) have been developed and they can well predict the perceptual quality of images with a single type of distortion such as noise corruption, Gaussian blur and compression artifacts, they are still far from satisfying to faithfully evaluate the subjective quality of denoised images, whose distortion is much more complex. This is also why the denoised images by our methods have better visual quality, but their SSIM indices are similar to the denoised images by other methods.</p><p>In this subsection, we adopted the strategy in <ref type="bibr" target="#b22">[23]</ref> to compare the subjective quality of denoised images obtained by different methods. For each of the ten test images and on each noise standard deviation <ref type="bibr">(20, 25, 30, 35 and 40)</ref>, 15 student volunteers<ref type="foot" target="#foot_1">2</ref> were asked to compare the denoising results between S-GHP and SAPCA-BM3D, LSSC and NCSR, respectively. In each test, the volunteers were shown two denoised images on LCD monitor: one (denoted by A) is obtained by S-GHP and the other one (denoted by B) is obtained by the competing method. The volunteers were asked to make one of the following decisions: A is visually better than B (labeled by 1), B is visually better than A (labeled by -1), and there is nearly no visual difference between A and B (labeled by 0). Then for each pair of competing methods (i.e., S-GHP vs. SAPCA-BM3D, S-GHP vs. LSSC, S-GHP vs. NCSR), we have 10 (test images) × 5 (noise standard deviations) × 15 (volunteers) = 750 test outputs (1, -1, or 0). In Fig. <ref type="figure" target="#fig_10">11</ref>, we plot the distributions of the subjective evaluation outputs for each pair of competing methods. One can see that S-GHP is always the more favored method in terms of subjective evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>In this paper, we presented a novel gradient histogram preservation (GHP) model for texture-enhanced image denoising, and further introduce two region-based GHP variants, i.e., B-GHP and S-GHP. A simple but theoretically solid model and the associated algorithm were presented to estimate the reference gradient histogram from the noisy image, and an efficient iterative histogram specification algorithm was developed to implement the GHP model. By pushing the gradient histogram of the denoised image toward the reference histogram, GHP achieves promising results in enhancing the texture structure while removing random noise. The experimental results demonstrated the effectiveness of GHP in texture enhanced image denoising. GHP leads to similar PSNR/SSIM measures to the state-of-the-art denoising methods such as SAPCA-BM3D, LSSC and NCSR; however, it leads to more natural and visually pleasant denoising results by better preserving the image texture areas. Most of the state-of-the-art denoising algorithms are based on the local sparsity and nonlocal selfsimilarity priors of natural images. Unlike them, the gradient histogram used in our GHP method is a kind of global prior, which is adaptively estimated from the given noisy image.</p><p>One limitation of GHP is that it cannot be directly applied to non-additive noise removal, such as multiplicative Poisson noise and signal-dependent noise <ref type="bibr" target="#b46">[47]</ref>. Thus, it would be interesting and valuable to study more general models and algorithms for non-additive noise removal with texture enhancement. One strategy is to transform the noisy image into an image with additive white Gaussian noise (AWGN) and then apply GHP. For example, for image with Poisson noise, Anscombe root transformation <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b48">[49]</ref> can be used to transform it into an image with AWGN.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 1 )</head><label>1</label><figDesc>A novel texture enhanced image denoising framework is proposed, which preserves the gradient histogram of the original image. The existing image priors can be easily incorporated into the proposed framework to improve the quality of denoised images. (2) Using histogram specification, a gradient histogram preservation algorithm is developed to ensure that the gradient histogram of denoised image is close to the reference histogram, resulting in a simple yet effective GHP based denoising algorithm. (3) By incorporating the hyper-Laplacian and nonnegative constraints, a regularized deconvolution model and an iterative deconvolution algorithm are presented to estimate the image gradient histogram from the given noisy image. The rest of the paper is organized as follows. Section II provides a brief survey of the related work. Section III introduces the gradient histogram estimation and preservation framework. Section IV presents the proposed denoising model and the iterative histogram specification algorithm, while Section V describes the regularized deconvolution model and algorithm for gradient histogram estimation. Section VI presents the experimental results. Finally, Section VII concludes this paper. II. RELATED WORK Image denoising methods can be grouped into two categories: model-based methods and learning-based methods. Most denoising methods reconstruct the clean image by exploiting some image and noise prior models, and belong to the first category. Learning-based methods attempt to learn a mapping function from the noisy image to the clean image [19], and have been receiving considerable research interests [20], [21]. Here we briefly review those model-based denoising methods related to our work from a viewpoint of natural image priors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Flowchart of the proposed texture enhanced image denoising framework.</figDesc><graphic coords="3,326.51,177.17,104.78,70.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1 Fig. 3 .</head><label>13</label><figDesc>Fig. 3. The convergence curve of the proposed GHP algorithm on image Bear.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Two image partition schemes. (a) The noisy image is partitioned into K homogeneous regions by k-means clustering. (b) The noisy image is partitioned into √ K × √ K blocks.</figDesc><graphic coords="5,327.95,58.49,106.10,96.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. An example of reference gradient histogram estimation. (a) Real and simulated AWGN gradient histograms (noise standard deviation σ = 30); (b) real and simulated gradient histograms of noisy image; and (c) real and estimated gradient histograms of the clean image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Ten test images. From left to right and top to bottom, they are labeled as 1 to 10.</figDesc><graphic coords="7,57.47,58.13,233.06,99.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. (a) The noisy test image 6 (noise standard deviation σ = 35). From (b) to (e): the zoom-in denoising results by GHP, B-GHP and S-GHP, and the ground truth.</figDesc><graphic coords="9,107.99,203.81,126.38,126.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Denoising results on image 7. (a) Noisy image with AWGN of standard deviation 30; cropped and zoom-in denoised images by (b) SAPCA-BM3D [11], (c) LSSC [12], (d) NCSR [14], and (e) S-GHP; (f) ground truth. The PSNR and SSIM values are shown in the close-ups.</figDesc><graphic coords="10,107.99,385.85,126.74,126.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Denoising results on image 1. (a) Noisy image with AWGN of standard deviation 30; cropped and zoom-in denoised images by (b) SAPCA-BM3D [11], (c) LSSC [12], (d) NCSR [14], and (e) S-GHP; (f) ground truth. The PSNR and SSIM values are shown in the close-ups.</figDesc><graphic coords="10,107.99,528.41,126.38,126.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. From left to right and from top to bottom: original image, the difference PSNR map (p B M3Dp G H P ), the denoised images by SAPCA-BM3D and S-GHP.</figDesc><graphic coords="11,125.99,215.69,177.86,152.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. The distributions of subjective evaluation outputs. (a) S-GHP vs. SAPCA-BM3D; (b) S-GHP vs. LSSC; (c) S-GHP vs. NCSR.</figDesc><graphic coords="12,60.47,58.49,165.26,108.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE II THE</head><label>II</label><figDesc>PSNR (dB) AND SSIM RESULTS OF GHP WITH THE ESTIMATED GRADIENT HISTOGRAM (GHP-E)AND WITH THE GROUND TRUTH GRADIENT HISTOGRAM (GHP-G) TABLE</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We also evaluated the denoising performance of S-GHP under lower and higher noise standard deviations, i.e., σ = 5, 10, 15, and σ = 50, 80, 100. The detailed results can be found in the supplementary file.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Among the 15 volunteers,</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>have experience on image restoration and 1 has experience on image quality assessment.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>The authors would like to thank the associate editor and the anonymous reviewers for their constructive suggestions.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Science Foundation of China under Contract 61271093, in part by the Hong Kong Scholar Program, in part by the Program of Ministry of Education for New Century Excellent Talents in University under Grant NCET-12-0150, and in part by the HK RGC General Research Fund under Grant PolyU 5313/12E.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Removing camera shake from a single photograph</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="787" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Image and depth from a conventional camera with a coded aperture</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast image deconvolution using hyper-Laplacian priors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1033" to="1041" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Nonlinear total variation based noise removal algorithms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fatemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. D</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="259" to="268" />
			<date type="published" when="1992-11">Nov. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Scale mixtures of Gaussians and the statistics of natural images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="855" to="861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image denoising using a scale mixture of Gaussians in the wavelet domain</title>
		<author>
			<persName><forename type="first">J</forename><surname>Portilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Strela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1338" to="1351" />
			<date type="published" when="2003-11">Nov. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Image denoising via sparse and redundant representations over learned dictionaries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image deblurring and superresolution by adaptive sparse domain selection and adaptive regularization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1838" to="1857" />
			<date type="published" when="2011-07">Jul. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A review of image denoising methods, with a new one</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Model. Simul</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="490" to="530" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3D transform-domain collaborative filtering</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007-08">Aug. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">From local kernel to nonlocal multiple-model image denoising</title>
		<author>
			<persName><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Astola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2010-01">Jan. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Non-local sparse models for image restoration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2009-10">Sep./Oct. 2009</date>
			<biblScope unit="page" from="2272" to="2279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Centralized sparse representation for image restoration</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2011-11">Nov. 2011</date>
			<biblScope unit="page" from="1259" to="1266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Nonlocally centralized sparse representation for image restoration</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1620" to="1630" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multiresolution histograms and their use for recognition</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hadjidemetriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Grossberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE. Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="831" to="847" />
			<date type="published" when="2004-07">Jul. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A statistical approach to texture classification from single images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="61" to="81" />
			<date type="published" when="2005-04">Apr. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Classifying images of materials: Achieving viewpoint and illumination independence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="255" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Texture enhanced image denoising via gradient histogram preservation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. CVPR</title>
		<meeting>Int. Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1203" to="1210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Efficient approximation of neural filters for removing quantum noise from images</title>
		<author>
			<persName><forename type="first">K</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Horiba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sugie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1787" to="1799" />
			<date type="published" when="2002-07">Jul. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Natural image denoising with convolutional networks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="769" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Image denoising: Can plain neural networks compete with BM3D?</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. CVPR</title>
		<meeting>Int. Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2012-06">Jun. 2012</date>
			<biblScope unit="page" from="2392" to="2399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Efficient marginal likelihood optimization in blind deconvolution</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. CVPR</title>
		<meeting>Int. Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2011-06">Jun. 2011</date>
			<biblScope unit="page" from="2657" to="2664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Image restoration by matching gradient distributions</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE. Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="683" to="694" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A content-aware image prior</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. CVPR</title>
		<meeting>Int. Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2010-06">Jun. 2010</date>
			<biblScope unit="page" from="169" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Image deblurring and denoising using color priors</title>
		<author>
			<persName><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. CVPR</title>
		<meeting>Int. Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2009-06">Jun. 2009</date>
			<biblScope unit="page" from="1550" to="1557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning sparse topographic representations with products of student-t distributions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2002-12">Dec. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fields of experts: A framework for learning image priors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. CVPR</title>
		<meeting>Int. Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2005-06">Jun. 2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="860" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Analysis K-SVD: A dictionarylearning algorithm for the analysis sparse model</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="661" to="677" />
			<date type="published" when="2013-02">Feb. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Task-driven dictionary learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE. Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="791" to="804" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">From learning models of natural image patches to whole image restoration</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2011-11">Nov. 2011</date>
			<biblScope unit="page" from="479" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Patch complexity, finite pixel correlations and optimal denoising</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 12th ECCV</title>
		<meeting>12th ECCV</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="73" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Loss-specific training of nonparametric image restoration models: A new state of the art</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jancsary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 12th ECCV</title>
		<meeting>12th ECCV</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="112" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An iterative thresholding algorithm for linear inverse problems with a sparsity constraint</title>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Defriese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">De</forename><surname>Mol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Pure Appl. Math</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1413" to="1457" />
			<date type="published" when="2004-11">Nov. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Woods</surname></persName>
		</author>
		<title level="m">Digital Image Processing</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Publishing House Electron. Ind</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Layered graph matching with composite cluster sampling</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE. Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1426" to="1442" />
			<date type="published" when="2010-08">Aug. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Object categorization with sketch representation and generalized samples</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3648" to="3660" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Adaptive histogram equalization and its variations</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Pizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Graph. Image Process</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="355" to="368" />
			<date type="published" when="1987-09">Sep. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Handbook of the Normal Distribution</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Read</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>Marcel Dekker</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Image quality assessment: From error visibility to structural similarity</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multiplicative noise removal using variable splitting and constrained optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1720" to="1730" />
			<date type="published" when="2010-07">Jul. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Fast image recovery using variable splitting and constrained optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Afonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2345" to="2356" />
			<date type="published" when="2010-09">Sep. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">An augmented Lagrangian approach to the constrained optimization formulation of imaging inverse problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Afonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="681" to="695" />
			<date type="published" when="2011-03">Mar. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Textons, the elements of texture perception, and their interactions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Julesz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="page" from="91" to="97" />
			<date type="published" when="1981-03">Mar. 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A spectral histogram model for texton modeling and texture discrimination</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="2617" to="2634" />
			<date type="published" when="2002-10">Oct. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The role of edges in object recognition by pigeons</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Peissig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Wasserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Biederman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1353" to="1374" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The role of image understanding in contour detection</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2012-06">Jun. 2012</date>
			<biblScope unit="page" from="622" to="629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Wavelets, ridgelets, and curvelets for Poisson noise removal</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Fadili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Starck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1093" to="1108" />
			<date type="published" when="2008-07">Jul. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The transformation of Poisson, binomial and negativebinomial data</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Anscombe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="246" to="254" />
			<date type="published" when="1948-12">Dec. 1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Optimal inversion of the Anscombe transformation in low-count Poisson image denoising</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mäkitalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="99" to="109" />
			<date type="published" when="2011-01">Jan. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Two-stage image denoising by principal component analysis with local pixel grouping</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1531" to="1549" />
			<date type="published" when="2010-04">Apr. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">FSIM: A feature similarity index for image quality assessment</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2378" to="2386" />
			<date type="published" when="2011-08">Aug. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Separating signal from noise using patch recurrence across scales</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zontak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mosseri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2013-06">Jun. 2013</date>
			<biblScope unit="page" from="1195" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Practical Mathematical Optimization: An Introduction to Basic Optimization Theory and Classical and New Gradient-Based Algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Snyman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
