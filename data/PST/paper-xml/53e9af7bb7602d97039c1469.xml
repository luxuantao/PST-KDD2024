<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gender Classification using Local Directional Pattern (LDP)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Taskeed</forename><surname>Jabid</surname></persName>
							<email>taskeed@khu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering Department</orgName>
								<orgName type="institution">Kyung Hee University Youngin</orgName>
								<address>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Md</forename><forename type="middle">Hasanul</forename><surname>Kabir</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Engineering Department</orgName>
								<orgName type="institution">Kyung Hee University Youngin</orgName>
								<address>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Oksam</forename><surname>Chae</surname></persName>
							<email>oschae@khu.ac.kr</email>
							<affiliation key="aff2">
								<orgName type="department">Computer Engineering Department</orgName>
								<orgName type="institution">Kyung Hee University Youngin</orgName>
								<address>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Gender Classification using Local Directional Pattern (LDP)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4C2A1F898135A151F2F48E7C71C01DA7</idno>
					<idno type="DOI">10.1109/ICPR.2010.373</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Gender Classification</term>
					<term>local directional pattern</term>
					<term>texture analysis</term>
					<term>face image analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present a novel texture descriptor Local Directional Pattern (LDP) to represent facial image for gender classification. The face area is divided into small regions, from which LDP histograms are extracted and concatenated into a single vector to efficiently represent the face image. The classification is performed by using support vector machines (SVMs), which had been shown to be superior to traditional pattern classifiers in gender classification problem. Experimental results show the superiority of the proposed method on the images collected from FERET face database and achieved 95.05% accuracy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Human behavior and social interactions is greatly depends on gender of the person with whom he/she intend to interact. Fortunately human being has a unique capability of classify gender analyzing merely ones face that has a unique characteristic of conveying identity, emotions, age and a lot of other intrinsic information. In recent year, computer vision and pattern recognition systems played an important role in our daily life and as an application of computer vision; human computer interaction system can be more user-friendly and can act as more human-like when it considers the user's gender <ref type="bibr" target="#b0">[1]</ref>. Image/video indexing and retrieval, passive demographic data collections, vision based human monitoring, human-robot interaction are some other prominent application where gender classification can play a vital role.</p><p>Gender classification based on facial image analysis is difficult mainly because of the inherent variability of human face due to different image formation process in terms of image quality and photometry, geometry, occlusion etc. Some surveys addressed these challenges and possible solution in with respect to face recognition <ref type="bibr" target="#b1">[2]</ref> and facial expression recognition <ref type="bibr" target="#b2">[3]</ref> is also presented in details. Mäkinen and Raisamowe provides guidelines to carry out classification experiments <ref type="bibr" target="#b3">[4]</ref> and also present a systematic study on gender classification with automatically detected and aligned faces <ref type="bibr" target="#b4">[5]</ref>.</p><p>Mainly two types of gender classification methods are available: appearance-base approach and geometrical feature base approach <ref type="bibr" target="#b0">[1]</ref>. In appearance based approach whole face image is used to generate the feature vector. Geometrical approach need to localize different facial components such as eye, eyebrows, nose etc. before extracting facial features. Features are generated from position and/or appearances of these facial components. This geometric feature requires extra computation prior to feature extraction to localize face components and also any error while localizing these localization may lead to significant performance drops.</p><p>Recently a more generic local appearance based approach also proposed where instead of considering the whole face at once this approach divide the input face image into blocks, without considering any salient region, from which facial feature are extracted. This method becomes much popular due to its robustness in environmental change and also it independent from the location of facial components. Following this, Ahonen et al. <ref type="bibr" target="#b5">[6]</ref> recently proposed Local Binary Pattern (LBP) which later on applied to analyze face image in different application including gender classification using face image <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>.</p><p>LBP provides an invariant description in presence of monotonic illumination variation on face image, however, suffer much in non-monotonic illumination variation, random noise, and change in pose, age, expression. This paper describes Local Directional Pattern (LDP) which already proved to be a robust feature in face recognition <ref type="bibr" target="#b8">[9]</ref> and here it demonstrates better performance in gender classification. This LDP descriptor considers the edge response values in different directions instead of pixel intensities, hence provides more consistency in the presence of noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. LOCAL BINARY PATTERN (LBP)</head><p>The LBP operator, a gray-scale invariant texture primitive, has gained significant popularity for describing texture of an image <ref type="bibr" target="#b9">[10]</ref>. It labels each pixel of an image by thresholding its P-neighbor values with the center value and converts the result into a binary number by using <ref type="bibr" target="#b0">(1)</ref>.</p><formula xml:id="formula_0">LBP P,R (x c , y c ) = P -1 p=0 s(g p -g c ) × 2 p (1) s(x) = 1 x ≥ 0 0 x &lt; 0<label>(2)</label></formula><p>where g c denotes the gray value of the center pixel (x c , y c ) and g p are gray values of P equally spaced pixels on the circumference of a circle with radius R.</p><p>The values of neighbors that do not fall exactly on pixels are estimated by bilinear interpolation. In practice, (1) means that the signs of the differences in a neighborhood are interpreted as a P-bit binary number, resulting in 2 P distinct values for the binary pattern. This individual pattern value is capable to describe the texture information at the center pixel g c . The process is demonstrated with the fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>One of the variations of this original LBP code is known as uniform pattern. This uniform pattern introduced from the observation of Ojala et al. <ref type="bibr" target="#b9">[10]</ref> where they find that in significant image area certain local binary patterns appear more frequently. These patterns are named as "uniform" as they contain very few transitions from 0 to 1 or 1 to 0 in circular bit sequence. Sun et al. <ref type="bibr" target="#b10">[11]</ref> used variant of LBP patterns which have at most two transitions (LBP u2 ) for their gender classification task using FERET database. This variant of LBP is still sensitive to random noise and nonmonotonic illumination variation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. LOCAL DIRECTIONAL PATTERN (LDP)</head><p>LBP operator tries to encode the micro-level information of edges, spots and other local features in an image using information of intensity changes around pixels. Some researches have replaced the intensity value at a pixel position with its gradient magnitude and calculated the LBP code trivially by following the same approach as that of intensity value. However, they only encode the relative change of gradient magnitude in surrounding positions and do not encode its own gradient magnitude or direction information. Motivated by this finding, we proposed a LDP code which computes the edge response values in different directions and encodes the texture.</p><p>The proposed Local Directional Pattern (LDP) is an eight bit binary code assigned to each pixel of an input image. This pattern is calculated by comparing the relative edge response value of a pixel in different directions. For this purpose, we calculate eight directional edge response value of a particular pixel using Kirsch masks in eight different orientations (M 0 -M 7 ) centered on its own position. These masks are shown in the fig. <ref type="figure">2</ref>. Applying eight masks, we obtain eight edge response value m 0 , m 1 , ..., m 7 , each representing the edge significance in its respective direction. The response values are not equally important in all directions. The presence of corner or edge show high response values in particular directions. We are interested to know the k most prominent directions in order to generate the LDP. Hence, we find the top k values |m j | and set them to 1. The other (8k) bit of 8-bit LDP pattern is set to 0. LDP code generation using three prominent edges response is shown in fig. <ref type="figure">3</ref>.</p><p>We showed that LDP feature encodes the texture by using ranking some of the most significant responses in different directions. In presence of noise it is most unlikely that higher significant edge responses will change its relative position. Rather even if relative position of magnitude changes for some directions, it is most likely occurs in lesser significant direction. Hence the LDP code produces more stable pattern in presence of noise. For instance, fig. <ref type="figure" target="#fig_3">4</ref> shows an original image and the corresponding image after adding Gaussian white noise. After addition of noise, 5th bit of LBP changed from 1 to 0, thus LBP pattern changed from uniform to a non-uniform code. Since gradients are more stable than gray value, LDP pattern provides the same pattern value even presence of that noise and non-monotonic illumination changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. LDP BASED GENDER CLASSIFICATION</head><p>The LDP feature which is robust against different variations like non-monotonic changes in illumination and in random noise is used to represent face in the application of gender classification. This section presents how to use this  proposed LDP operator to represent the appearance of face image and use that representation to identify the gender of that person.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Face Representation using LDP</head><p>There are three steps to represent the face using LDP feature from raw face image. First, the LDP operator is applied on the face image to get LDP image. Second, histogram is extracted from each local region of LDP image to build the local representation of the face. Third, all the histograms are concatenated into one feature vector to build the global representation. Proposed LDP histogram based face representation is illustrated in Fig. <ref type="figure" target="#fig_4">5</ref>.</p><p>1) Generating LDP Face Image: At the beginning face image is represented using LDP operator, the LDP operator is applied in the raw face image using the equation ( <ref type="formula">3</ref>). In our experiment we use k = 3 to generate the LDP code. Fig. <ref type="figure" target="#fig_6">6</ref> shows an example of LDP image generated from raw face image.</p><p>2   detail information of an image, such as, edges, spot, corner and other local texture features. But histogram computed over the whole face image encodes only the occurrences of the micro-patterns without any knowledge about their locations. In order to incorporate some degree of location information, we divide face images into n number of small regions R 0 ; R 1 ; ...; R n and extracted the LDP histograms H Ri from each region R i . These n LDP histograms are concatenated to get a spatially combined LDP histogram which plays the role of a global face feature for the given face image. The process can be visualized with fig. <ref type="figure" target="#fig_7">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Classification with Support Vector Machine (SVM) using LDP feature</head><p>Face feature generated using LDP descriptor is used to classify the face either into male face or into female with support vector machine (SVM). SVM is a well founded statistical learning theory that has been successfully applied in various classification tasks in computer vision <ref type="bibr" target="#b11">[12]</ref>. SVM performs an implicit mapping of data into a higher dimensional feature space and finds a linear separating hyper-plane with maximal margin to separate the data in this higher dimensional space. Given a training set of labeled examples T = { (s i , l i ), i = 1, 2, ..., L} where s i ∈ R p , and</p><formula xml:id="formula_1">l i ∈ {-1, 1}, a new test data x is classified by equation 3 f (x) = sign L i=1 α i l i K(x i , x) + b (3)</formula><p>where α i are Lagrange multipliers of dual optimization problem, b is a bias or threshold parameter, and K is a kernel function. The training sample x i with α i &gt; 0 is called the support vectors, and the separating hyper-plane maximizes the margin with respect to these support vectors. Given a non-linear mapping function Φ that transforms the input data to the higher dimensional feature space, kernels have the form of K(x i , x j ) = Φ(x i ), Φ(x j ) . Among the various kernels found in literature, linear, polynomial and radial basis function (RBF) kernels are the most frequently used ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL RESULT</head><p>The performance of gender classification using proposed LDP feature is evaluated with images from the FERET <ref type="bibr" target="#b12">[13]</ref> database. The FERET database consists of a total of 14,051 gray-scale images representing 1,199 individuals. The images contain variations in lighting, facial expressions, pose angle, aging effects etc. In this work, we collect 2000 mug-shot face images out of which 1100 faces are male and rest 900 are female face. In our study, 512x768 pixel face images are cropped and normalized to 100x100 pixels based on the ground truth positions of the two eyes and mouth. In our setup, every image is partitioned into NxN sub-blocks to generate spatially combined LDP histogram feature vector as discussed in section 4. Our experiments shows increasing the number of blocks can enhance the performance. However it increases the length of feature vector and requires extra bit of processing. The classification performance in respect to different number of blocks is shown with Table <ref type="table" target="#tab_0">I</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>This paper describes a new local face feature based on LDP code for gender classification. The LDP codes are computed from the edge response values which are insensitive to noise and illumination variations and hence provide robust feature to represent facial appearance. Meanwhile the high generalization ability of support vector machines allows for learning and classifying gender from a large set faces and present higher classification accuracy. Inspired by the psychophysical findings which state that facial movements can provide valuable information to face analysis <ref type="bibr" target="#b13">[14]</ref>, in future we plan to explore the sequence images and incorporate temporal information with LDP descriptor.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The basic LBP operator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2010</head><label></label><figDesc>International Conference on Pattern Recognition 1051-4651/10 $26.00 © 2010 IEEE DOI 10.1109/ICPR.2010.373 2154 2010 International Conference on Pattern Recognition</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Figure 2. Kirsch edge response masks in eight directions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>LBPFigure 4 .</head><label>4</label><figDesc>Figure 4. Robustness of LDP vs. LBP (a) Original Image with LBP and LDP code, (b) Noisy Image with changed LBP and LDP value.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Flowchart of face representation using LDP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>) Histogram of LDP: After encoding an image with the LDP operator we get an encoded image I L (x, y). We use k = 3 which generates distinct values in our encoded image. So histogram H of this LDP labeled image I L (x, y) is a 56 bin histogram and can be defined 3) Concatenated LDP Histogram: Each face is represented by a LDP histogram. LDP histogram contains fine</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Left: Original face image, Right: LDP image.</figDesc><graphic coords="3,357.41,73.01,68.35,68.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Spatially combined histogram feature.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table I CLASSIFICATION</head><label>I</label><figDesc>ACCURACY WITH DIFFERENT BLOCK.</figDesc><table><row><cell>Number</cell><cell>Feature</cell><cell cols="3">Classification Accuracy</cell></row><row><cell>of Block</cell><cell>Length</cell><cell>Overall</cell><cell>Male</cell><cell>Female</cell></row><row><cell>5x5</cell><cell>1400</cell><cell cols="3">92.75% 92.81% 92.66%</cell></row><row><cell>10x10</cell><cell>5600</cell><cell cols="3">95.05% 94.81% 95.33%</cell></row><row><cell>20x20</cell><cell>22400</cell><cell>94.95%</cell><cell cols="2">95.00% 94.88%</cell></row><row><cell></cell><cell></cell><cell>Table II</cell><cell></cell><cell></cell></row><row><cell cols="5">CLASSIFICATION ACCURACY WITH OTHER METHOD.</cell></row><row><cell>Methods</cell><cell></cell><cell cols="3">Classification Accuracy</cell></row><row><cell cols="2">(Feature + Classifier)</cell><cell>Overall</cell><cell>Male</cell><cell>Female</cell></row><row><cell cols="4">LBP + Chi-square [11] 81.90% 82.27%</cell><cell>81.44%</cell></row><row><cell cols="2">LBP + Adaboost [11]</cell><cell cols="3">92.25% 92.00% 92.55%</cell></row><row><cell cols="2">Proposed LDP + SVM</cell><cell cols="2">95.05% 94.81%</cell><cell>95.33%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>. Performance of the proposed method in comparison other state of the art methods including LBP method is shown in Table V which demonstrate superiority of proposed LDP feature over LBP and other feature in gender classification domain.</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Appearance-based gender classification with gaussian processes</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Bang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letter</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="618" to="626" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Face recognition: A literature survey</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Survey</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="399" to="458" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automatic facial expression analysis: a survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fasel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luettin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="259" to="275" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An experimental comparison of gender classification methods</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mäkinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raisamo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogniong Letter</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1544" to="1556" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evaluation of gender classification methods with automatically detected and aligned faces</title>
		<author>
			<persName><forename type="first">E</forename><surname>Makinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raisamo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="541" to="547" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Face description with local binary patterns: application to face recognition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ahonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2037" to="2041" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multi-view gender classification using local binary patterns and support vector machines</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Symposium on Neural Networks</title>
		<meeting>International Symposium on Neural Networks</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="202" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improving lbp features for gender classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Wavelet Analysis and Pattern Recognition</title>
		<meeting>International Conference on Wavelet Analysis and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="373" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Local directional pattern (LDP) for face recognition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jabid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Kabir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Chae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Consumer Electronics</title>
		<meeting>the IEEE International Conference on Consumer Electronics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="329" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transaction on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="971" to="987" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Gender classification based on boosting local binary pattern</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Symposium on Neural Networks</title>
		<meeting>International Symposium on Neural Networks</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="194" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="273" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The feret database and evaluation procedure for face recognition algorithms</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wechsler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="295" to="306" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Combining appearance and motion for face and gender recognition from videos</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2818" to="2827" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
