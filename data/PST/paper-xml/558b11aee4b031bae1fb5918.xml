<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Subgradient Methods and Consensus Algorithms for Solving Convex Optimization Problems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Björn</forename><surname>Johansson</surname></persName>
							<email>bjorn.johansson@ee.kth.se.</email>
						</author>
						<author>
							<persName><forename type="first">Tamás</forename><surname>Keviczky</surname></persName>
							<email>t.keviczky@tudelft.nl</email>
						</author>
						<author>
							<persName><forename type="first">Mikael</forename><surname>Johansson</surname></persName>
							<email>mikaelj@ee.kth.se.</email>
						</author>
						<author>
							<persName><forename type="first">Karl</forename><forename type="middle">Henrik</forename><surname>Johansson</surname></persName>
							<email>kallej@ee.kth.se.</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Royal Institute of Technology (KTH)</orgName>
								<address>
									<addrLine>100 44 Stockholm</addrLine>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Delft Center for Systems and Control</orgName>
								<orgName type="institution">Delft University of Technology</orgName>
								<address>
									<postCode>2628 CD</postCode>
									<settlement>Delft</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Subgradient Methods and Consensus Algorithms for Solving Convex Optimization Problems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6D759DD27149238FB1A9BF84D70E0A1D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we propose a subgradient method for solving coupled optimization problems in a distributed way given restrictions on the communication topology. The iterative procedure maintains local variables at each node and relies on local subgradient updates in combination with a consensus process. The local subgradient steps are applied simultaneously as opposed to the standard sequential or cyclic procedure. We study convergence properties of the proposed scheme using results from consensus theory and approximate subgradient methods. The framework is illustrated on an optimal distributed finite-time rendezvous problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Large-scale networked systems are becoming ubiquitous and increasingly complex to manage. If the desired behavior of the networked system can be formulated as an optimization problem, then complexity issues can be mitigated by solving the resulting optimization problem with distributed algorithms. We will develop such a distributed algorithm.</p><p>Several important problems in applications such as resource allocation in computer networks [1], [2], estimation in sensor networks <ref type="bibr" target="#b2">[3]</ref>, and the rendezvous problem in multiagent systems <ref type="bibr" target="#b3">[4]</ref>, can be posed as coupled optimization problems. In these problems, each node or agent in the network is associated with a component of the objective function, which depends on a network-wide decision variable.</p><p>Coupled optimization problems can be solved using a variety of distributed algorithms. A classical way is to use dual relaxation, i.e., the constraints are enforced using a pricing scheme. Another method is to iteratively refine an estimate of the optimizer using incremental subgradient methods, where the estimate typically is passed around in the network following a logical ring. In this paper, we combine consensus negotiations with a subgradient method, which is similar in flavor to the approach proposed in [5], but with different properties and analysis. In our approach, the communication topology is explicitly respected, and the algorithm only requires communication between neighboring nodes.</p><p>In Section II, we present our problem formulation as well as notation and connections with the existing literature. Then, in Section III, we introduce the algorithm and supporting lemmas. We then continue with a convergence analysis of B. Johansson, M. Johansson and K.H. Johansson are with the ACCESS Linnaeus Centre, School of Electrical Engineering,</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>the algorithm in Section IV. Furthermore, the properties of the algorithm is explored using a numerical example in Section V. Finally, we conclude the paper with a discussion in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROBLEM FORMULATION</head><p>In this paper we consider the following optimization problem</p><formula xml:id="formula_0">minimize x f (x) = N i=1 f i (x) subject to x ∈ X ,<label>(1)</label></formula><p>where f i : R M → R are convex functions and X is a nonempty, closed, and convex subset of R M . Let f ⋆ denote the optimal value of (1) and let x ⋆ denote an optimizer of (1). We will assume that in general f is nondifferentiable. Our interest in studying this class of optimization problems is motivated by optimal control problems for finite-time rendezvous of multiple dynamical agents <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b5">[6]</ref>, resource allocation in computer networks <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, and estimation in sensor networks <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Preliminaries</head><p>We will make use of the following definitions and assumptions in the paper.</p><p>Definition 1: A vector g ∈ R M is a subgradient of a convex function f : R M → R at a point x ∈ R M if f (y) ≥ f (x) + g ⊺ (y -x), ∀y ∈ R M .</p><p>(</p><formula xml:id="formula_1">)<label>2</label></formula><p>Definition 2: The set of all subgradients of a convex function f at x ∈ R M is called the subdifferential of f at x, and is denoted by ∂f (x):</p><formula xml:id="formula_2">∂f (x)= g ∈ R M |f (y) ≥ f (x) + g ⊺ (y -x), ∀y ∈ R M . (3)</formula><p>Definition 3: The ǫ-subdifferential set of a convex function f at x is the collection of ǫ-subgradients: <ref type="bibr" target="#b3">(4)</ref> with ǫ ≥ 0.</p><formula xml:id="formula_3">∂ ǫ f (x) = g∈ R M |f (y) ≥ f (x) + g ⊺ (y -x) -ǫ, ∀y ∈ R M ,</formula><p>We will use • to denote the 2-norm of a vector x, i.e., x = √ x ⊺ x, and the induced 2-norm of a matrix W , i.e., W = sup x =0 W x</p><p>x . Assumption 1 (Subgradient Boundedness): There exists a scalar C for all i = 1, . . . , N such that g i (x) ≤ C, ∀g i (x) ∈ ∂f i (x), ∀x ∈ X .</p><p>(5)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proceedings of the 47th IEEE Conference on Decision and Control</head><p>Cancun, Mexico, Dec. 9-11, 2008</p><p>ThTA12.5</p><p>978-1-4244-3124-3/08/$25.00 ©2008 IEEE</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Subgradient Methods</head><p>A popular method for solving problems of the type (1) is the subgradient method, which consists of the following iterative procedure</p><formula xml:id="formula_4">x k+1 = P X x k + α k N i=1 g i (x k ) ,<label>(6)</label></formula><p>where g i (x k ) is a subgradient of f i at x k , α k is a positive stepsize, and P X denotes projection on the set X ⊂ R M . References <ref type="bibr" target="#b6">[7]</ref> and <ref type="bibr" target="#b7">[8]</ref> contain excellent introductions and overviews of the theory and use of subgradient methods, as well as their convergence rate properties.</p><p>The subgradient method can be implemented in an incremental fashion as proposed in <ref type="bibr" target="#b7">[8]</ref>. This entails changing the variable x k incrementally through N steps, in each iteration using only the subgradient corresponding to a single component function f i . The advantage of this method from a computational aspect is that it can be performed in a distributed way by assigning each component function to a processing unit or "agent", which performs the local incremental update on the variable x. This means that x k needs to be "passed around" between the agents, which perform a subgradient update using only a single subgradient corresponding to the agent's component function. This incremental subgradient scheme has advantages over the standard one in terms of convergence rate and distribution of computations. However, in its usual form the incremental updates are performed in a sequential manner, which assumes that the variable x k passes through all agents either in a cyclic or randomized sequence. Implementation of such a communication scheme can sometimes be problematic in practice.</p><p>A more realistic distribution of the computations would allow a much wider class of information exchange topologies, which might even be time-varying or suffer from delays.</p><p>Notice that we can think of the computing agents mentioned above as each having a copy of the decision variable x, which they maintain locally and update based on the value obtained from the previous subiteration (the preceding agent in the update sequence) and the local subgradient of the component function evaluated at this value. Under appropriate assumptions and using a properly chosen diminishing stepsize, the subgradient iterations converge asymptotically to an optimizer x ⋆ of the problem. This means that eventually all "local" versions of the decision variable converge to the same value. This resembles to some extent agreement or consensus problems in multi-agent systems, which has a long history and has received renewed interest in the recent literature <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Consensus algorithms</head><p>The consensus problem considers conditions under which using a certain message-passing protocol, the local variables of each agent will converge to the same value. However, this value does not generally represent an optimizer of a problem of interest, and is typically a function of the initial values held by the agents and the information exchange policy.</p><p>A wide variety of results exist related to the convergence of local variables to a common value using various information exchange procedures among multiple agents <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b10">[11]</ref>. It is thus interesting to investigate whether the convergence properties of certain consensus algorithms can be combined with subgradient iterations in order to optimize problems of type (1) using a wider variety of communication topologies than what the standard incremental subgradient method allows.</p><p>For our investigations we will consider the following consensus algorithm in discrete-time:</p><formula xml:id="formula_5">y k+1 = W y k ,<label>(7)</label></formula><p>where the i-th element of vector y k , denoted by [y k ] i , corresponds to agent i. Furthermore, we associate an undirected graph G = (V, E) with the optimization problem <ref type="bibr" target="#b0">(1)</ref>, where V = {1, ..., N } and E ⊆ V × V . The interpretation is that if (i, j) ∈ E, then agent i can communicate with agent j. The information exchange among agents is represented by the matrix W , for which we make the following assumptions. Assumption 2 (Consensus Matrix Properties):</p><formula xml:id="formula_6">The weight matrix W ∈ R N ×N fulfills [W ] ij = 0, if (i, j) / ∈ E and i = j, W = W ⊺ , W 1 N = 1 N , ρ W - 1 N 1 ⊺ N N ≤ γ &lt; 1,</formula><p>where ρ(•) is the spectral radius and 1 N ∈ R N is the column vector with all elements equal to one. The matrix W can for example be chosen as the socalled Perron matrix of the communication graph G with parameter ε. It is defined as W = I -εL(G), where L(G) represents the Laplacian matrix of the communication graph. If G with maximum degree ∆ is strongly connected with 0 &lt; ε &lt; 1/∆, then the limit lim k→∞ W k exists and a consensus is asymptotically reached for all initial states. Furthermore, the consensus value will be the average of the initial states:</p><formula xml:id="formula_7">[y ∞ ] j = 1 N N i=1 [y 0 ] i ,</formula><p>for all j = 1, ..., N . For more details, see, e.g, <ref type="bibr" target="#b8">[9]</ref>; for other ways of choosing W that fulfills Assumption 2, see, e.g, <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SUBGRADIENT ALGORITHM WITH CONSENSUS ITERATIONS</head><p>We propose to combine the subgradient iterations of ( <ref type="formula" target="#formula_4">6</ref>) with a number of consensus iterations <ref type="bibr" target="#b6">(7)</ref> in the following way:</p><formula xml:id="formula_8">x i k+1 = P X N j=1 [W ϕ ] ij x j k -α k g j (x j k ) ,<label>(8)</label></formula><p>where g j (x j k ) ∈ ∂f j (x j k ) and [W ϕ ] ij denotes the element of W ϕ in the i-th row and j-th column. Agents maintain their local variable x i k and perform the update procedure of (8) in parallel. First, they exchange information with neighboring agents for ϕ number of consensus iterations. More specifically, <ref type="bibr" target="#b7">(8)</ref> implies that each agent i runs ϕ number of consensus iterations with its neighbors, defined by <ref type="bibr" target="#b6">(7)</ref>, for each row in the local vector x i k . Then, all agents implement the component subgradient update locally. The 47th IEEE CDC, Cancun, Mexico, Dec. <ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr">2008</ref> ThTA12.5</p><p>total number of iterations in the algorithm up to step k is therefore kϕ. For a more compact notation we define</p><formula xml:id="formula_9">u i k = x i k -α k g i (x i k )<label>(9)</label></formula><p>and</p><formula xml:id="formula_10">v i k = N j=1 [W ϕ ] ij u j k , i = 1, ..., N.<label>(10)</label></formula><p>Let us assume for the moment that in each subgradient iteration ϕ → ∞, and the consensus updates converge to the average of the initial values (this holds if W fufills Assumption 2). Then, for all i = 1, . . . , N and</p><formula xml:id="formula_11">x i 0 ∈ R M , lim ϕ→∞ N j=1 [W ϕ ] ij u j 0 = 1 N N j=1</formula><p>x j 0 -α 0 g j (x j 0 ) .</p><p>Let us denote the initial state of the projected consensus variable with</p><formula xml:id="formula_12">x1 = P X 1 N N j=1</formula><p>x j 0 -α 0 g j (x j 0 ) .</p><p>In the next iteration, each agent will possess the same value x1 , thus the local subgradients g j will be evaluated at the same point. The update procedure in <ref type="bibr" target="#b7">(8)</ref> for k ≥ 1 will thus be equivalent to</p><formula xml:id="formula_13">xk+1 = P X 1 N N j=1 xk -α k g j (x k ) = P X xk -α k 1 N N j=1 (g j (x k )) .<label>(11)</label></formula><p>This is the same process as the standard subgradient method of (6) performed on the consensus variable xk with a stepsize of α k /N . Convergence analysis of this scheme can be done following the procedure in for example <ref type="bibr" target="#b6">[7]</ref> or <ref type="bibr" target="#b7">[8]</ref>.</p><p>We are interested however in a more realistic scenario, where the consensus iterations are performed only for a finite number of ϕ steps. We intend to analyze such a scheme with the use of properly chosen approximate subgradients and the approximation error of the average consensus process achieved in a finite number of steps. Finally, we assume that the stepsize in ( <ref type="formula" target="#formula_8">8</ref>) is constant, α k = α, which makes the algorithm easily implementable.</p><p>The following three lemmas will be instrumental in the convergence analysis of the proposed scheme in Section IV. We will denote the average value of the local variables at time</p><formula xml:id="formula_14">k with xk = 1 N N i=1 x i k and vk = 1 N N i=1 v i k .</formula><p>The following inequalities serve to characterize the Euclidean distance of agent variables from each other and from their average. Lemma 1:</p><formula xml:id="formula_15">1) If x i k -x j k ≤ β for all i, j = 1, ..., N , then x j k -xk = x j k -1 N N i=1 x i k ≤ N -1 N β. 2) If x i k -xk ≤ β for all i = 1, ..., N , then x i k -x j k ≤ 2β. Proof: 1) x j k -xk = 1 N N x j k - N i=1 x i k ≤ 1 N N i=1,i =j x i k -x j k ≤ N -1 N β. 2) x i k -x j k ≤ x i k -x + x j k -x ≤ 2β. Lemma 2: If y k+1 = W ϕ y k , with W fulfilling Assump- tion 2, and [y k ] i -[y k ] j ≤ σ for all i, j = 1, ..., N , then [y k+1 ] i -[y k+1 ] j ≤ 2γ ϕ N σ for all i, j = 1, ..., N . Proof: Let us write y k as y k = ȳk + a k with ȳk = 1 N 1 ⊺ N y k /N and N i=1 [a k ] i = 0. The results of Lemma 1 show that [a k ] i ≤ σ for all i. Furthermore, y k+1 = W ϕ (ȳ k + a k ) = ȳk + W ϕ (a k -0 N ). Now we have, [y k+1 -ȳk ] i ≤ y k+1 -ȳk = W ϕ (a k -0 N ) = W ϕ - 1 N 1 ⊺ N N a k ≤ W ϕ - 1 N 1 ⊺ N N ϕ a k ≤ W - 1 N 1 ⊺ N N ϕ a k ≤ γ ϕ a k ≤ γ ϕ N σ,</formula><p>where we used that W -</p><formula xml:id="formula_16">1N 1 ⊺ N N = ρ W - 1N 1 ⊺ N N</formula><p>, which holds for symmetric matrices. Finally, from the above discussion and Lemma 1, we have [y k+1 ] i -[y k+1 ] j ≤ 2γ ϕ N σ for all i, j = 1, ..., N .</p><p>The following lemma establishes a lower bound on the number of consensus steps that will ensure that the local variables will remain in a ball of radius β of their average, from one iteration to the next.</p><p>Lemma 3: Let {x 1 k , ..., x N k } ∞ k=0 be generated by ( <ref type="formula" target="#formula_8">8</ref>) under Assumptions 1 and 2. If v i k -vk ≤ β for all i and ϕ ≥ log(β) -log(4M N (β + αC)) / log(γ), then v i k+1 -vk+1 ≤ β for all i.</p><p>Proof: Using Lemma 1, the closeness condition means that v i k -v j k ≤ 2β for all i, j = 1, ..., N , which implies that v i k -v j k l ≤ 2β for all i, j = 1, ..., N and l = 1, ..., M . We can now decide the distance between the iterates before the consensus step.</p><formula xml:id="formula_17">u i k+1 l -u j k+1 l (12a) = P X [v i k ] -αg i (P X [v i k ]) -P X [v j k ] + αg j (P X [v j k ]) l ≤ v i k -v j k l + 2αC ≤ 2(β + αC),<label>(12b)</label></formula><p>where we used the non-expansive property of the projection on a convex set. Furthermore, we have</p><formula xml:id="formula_18">v i k+1 -v j k+1 = N n=1 [W ϕ ] in u n k+1 - N n=1 [W ϕ ] jn u n k+1 ≤ M l=1 N n=1 [W ϕ ] in u n k+1 - N n=1 [W ϕ ] jn u n k+1 l .</formula><p>Consider now one of the terms in the sum above and notice 47th IEEE CDC, Cancun, Mexico, Dec. 9-11, 2008 ThTA12.5</p><formula xml:id="formula_19">that N n=1 [W ϕ ] in u n k+1 - N n=1 [W ϕ ] jn u n k+1 l = N n=1 [W ϕ ] in u n k+1 l - N n=1 [W ϕ ] jn u n k+1 l = [W ϕ y k ] i -[W ϕ y k ] j , with y k = u 1 k+1 l ... u N k+1 l</formula><p>⊺ . Using Lemma 2 and (12), which states that</p><formula xml:id="formula_20">[y k ] i -[y k ] j ≤ 2(β + αC), we obtain [W ϕ y k ] i -[W ϕ y k ] j ≤ 4γ ϕ N (β + αC).</formula><p>Combining the above results yields</p><formula xml:id="formula_21">v i k+1 -v j k+1 ≤ 4γ ϕ M N (β + αC), and v i k+1 -v j k+1 ≤ β is fulfilled if ϕ is set to ϕ ≥ log(β) -log(4M N (β + αC)) log(γ) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONVERGENCE ANALYSIS</head><p>We will prove convergence of the algorithm in two cases: Firstly, convergence is proved when the feasible set is the space R M , i.e., the unconstrained optimization problem. Secondly, with an additional assumption on the objective functions, convergence is proved for a general convex feasible set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Unconstrained Case</head><p>In the following, we will analyze the unconstrained case and we make the following assumption.</p><p>Assumption 3: The feasible set of ( <ref type="formula" target="#formula_0">1</ref>) is X = R M . We need the following Lemma which allows us to interpret the algorithm as an ǫ-subgradient algorithm.</p><p>Lemma 4: Under Assumptions 1 and 2 and if</p><formula xml:id="formula_22">x i k -xk ≤ β for all i = 1, ..., N , then g i (x i k ) ∈ ∂ ǫ f i (x k ) and N i=1 g i (x i k ) ∈ ∂ N ǫ f (x k )</formula><p>, with ǫ = 2βC. Proof: Using the definition (2) and the bound (5) on the subgradient leads to</p><formula xml:id="formula_23">f i (x i k ) ≥ f i (x k ) + g i (x k ) ⊺ (x i k -xk ) ≥ f i (x k ) -g i (x k ) x i k -xk ≥ f i (x k ) -Cβ.</formula><p>For any y ∈ X , using the subgradient inequality leads to</p><formula xml:id="formula_24">f i (y) ≥ f i (x i k ) + g i (x i k ) ⊺ (y -x i k ) ≥ f i (x k ) + g i (x i k ) ⊺ (y -x i k ) -Cβ ≥ f i (x k ) + g i (x i k ) ⊺ (y -xk + xk -x i k ) -Cβ ≥ f i (x k ) + g i (x i k ) ⊺ (y -xk ) -2Cβ.</formula><p>Using the definition of an ǫ-subdifferential (4), this implies</p><formula xml:id="formula_25">g i (x i k ) ∈ ∂ 2βC f i (x k ). Summation of terms yields f (y) ≥ f (x k ) + N i=1 g i (x i k ) ⊺ (y -xk ) -N 2βC.</formula><p>Based on Definition 3, this implies</p><formula xml:id="formula_26">N i=1 g i (x i k ) ∈ ∂ N 2βC f (x k ).</formula><p>Now we are ready for the convergence theorem for the unconstrained case.</p><p>Theorem 1: Under Assumptions 1, 2, and 3, with the sequence {x 1 k , ..., x N k } ∞ k=0 generated by ( <ref type="formula" target="#formula_8">8</ref>) with ϕ ≥ log(β)-log(4N M (β+αC)) / log(γ) and x i 0 -x0 ≤ β, we have:</p><formula xml:id="formula_27">If f ⋆ = -∞, then lim inf k→∞ f (x i k ) = -∞, ∀i = 1, ..., N. If f ⋆ &gt; -∞, then lim inf k→∞ f (x i k ) ≤ f ⋆ + αN C 2 /2 + 3N Cβ, ∀i = 1, ..., N. Proof: From Lemma 3, we know that x i k -xk ≤ β for all i = 1, .., N and all k ≥ 0, since x i k = v i k . Furthermore, from Lemma 4, we know that N i=1 g i (x i k ) ∈ ∂ 2N βC f (x k</formula><p>) for all k ≥ 0. Hence, from the definitions of xk and x i k in combination with the results above, we have </p><formula xml:id="formula_28">xk+1 = 1 N N i=1 N j=1 [W ϕ ] ij x j k -αg j (x j k ) = = 1 N N j=1 x j k -αg j (x j k ) = xk + α N h(x k ), with h(x k ) ∈ ∂ 2N βC f (x k ) and h(x k ) ≤ N C.</formula><formula xml:id="formula_29">f (x k ) = -∞, if f ⋆ = -∞ and lim inf k→∞ f (x k ) ≤ f ⋆ +α(N C) 2 /(2N )+2N Cβ, if f ⋆ &gt; -∞.</formula><p>By noting that</p><formula xml:id="formula_30">f (x i k ) ≤ f (x k ) + N Cβ, ∀i = 1, ..., N, k ≥ 0,</formula><p>we have the desired result. Remark 1: We can get lim inf k→∞ f (x i k ) to be arbitrarily close to f ⋆ , by choosing the constants α and β arbitrarily small. Note that the number of required consensus negotiations (ϕ) to reach a fixed β does not depend on k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Constrained Case</head><p>To show convergence in the constrained case, we need the following additional assumption on the functions f i .</p><p>Assumption 4: There exist ζ &gt; 0 and τ &gt; 0 such that for all x ∈ X , g i (x) ∈ ∂f i (x), and ν ∈ R M with ν ≤ τ , the following holds:</p><formula xml:id="formula_31">g i (x) + ν ∈ ∂ ζ f i (x).</formula><p>As mentioned before, this is an additional assumption compared to what is needed for the unconstrained case. However, if X is a compact set, e.g., x ∈ X ⇒ x ≤ η, then Assumption 4 is fulfilled for convex functions and arbitrarily 47th IEEE CDC, Cancun, Mexico, Dec. <ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr">2008</ref> ThTA12.5</p><p>small (but fixed) ζ as long as τ is sufficiently small. To see this, consider x, w ∈ X , then</p><formula xml:id="formula_32">f i (w) ≥ f i (x) + g i (x) ⊺ (w -x) = f i (x) + (g i (x) + ν -ν) ⊺ (w -x) ≥ f i (x) + (g i (x) + ν) ⊺ (w -x) -ν ( x + w ) ≥ f i (x) + (g i (x) + ν) ⊺ (w -x) -2τ η, which fulfills Assumption 4 if τ ≤ ζ/(2η). Another example is when f (x) = ψx ⊺ x, then Assumption 4 is fulfilled if τ ≤ 2 √</formula><p>ζψ (without X necessarily being a compact set). In our further developments we need to keep track of the difference xk+1 -P X [v k ], and to this end, we define y k and z k as</p><formula xml:id="formula_33">y k = P X [v k-1 ] and z k = xk -y k .<label>(17)</label></formula><p>Furthermore, we need the following Lemma, which is similar to Lemma 4. Lemma 5: Under Assumptions 1, 2, and 4 and if</p><formula xml:id="formula_34">v i k-1 -vk-1 ≤ β for all i and ν ∈ R M with ν ≤ τ , then (g i (x i k ) + ν) ∈ ∂ ǫ f i (y k ) and N i=1 (g i (x i k ) + ν) ∈ ∂ N ǫ f i (y k ) with ǫ = β(6C + 3τ ) + ζ.</formula><p>Proof: The proof idea relies on the iterates being close to each other. Using the assumptions and the non-expansive property of projection on a convex set we can bound the distance z k as follows</p><formula xml:id="formula_35">z k = 1 N N i=1 P X v i k-1 -P X [v k-1 ] ≤ 1 N N i=1 v i k-1 -vk-1 ≤ β.</formula><p>Using the definition (2), the bound on the subgradient (5), the bound above, and Lemma 1 we obtain</p><formula xml:id="formula_36">f i (x i k ) ≥ f i (y k ) + g i (y k ) ⊺ (x i k -y k ) ≥ f i (y k ) -g i (y k ) x i k -y k ≥ f i (y k ) -C( x i k -xk + z k ) ≥ f i (y k ) -C3β,</formula><p>where we used</p><formula xml:id="formula_37">x i k -y k = x i k -x k +z k and v i k -vk ≤ β ⇒ v i k -v j k ≤ 2β ⇒ x i k -x j k ≤ 2β ⇒ x i k -xk ≤ 2β.</formula><p>For any y ∈ X , using Assumption 4 and the previous arguments, we get</p><formula xml:id="formula_38">f i (y) ≥ f i (x i k ) + (g i (x i k ) + ν) ⊺ (y -x i k ) -ζ ≥ f i (y k ) + (g i (x i k ) + ν) ⊺ (y -x i ) -(3Cβ + ζ) = f i (y k ) + (g i (x i k ) + ν) ⊺ (y -y k + y k -x i k ) -(3Cβ + ζ) ≥ f i (y k ) + (g i (x i k ) + ν) ⊺ (y -y k ) -(β(6C + 3τ ) + ζ).</formula><p>Using the definition of an ǫ-subdifferential (4), this implies</p><formula xml:id="formula_39">(g i (x i k ) + ν) ∈ ∂ (β(6C+3τ )+ζ) f i (y k ). Summation of terms yields f (y) ≥ f (y k )+ N i=1 (g i (x i k ) + ν) ⊺ (y -y k ) -N (β(6C + τ ) + ζ).</formula><p>Based on Definition 3, this implies</p><formula xml:id="formula_40">N i=1 (g i (x i k ) + ν) ∈ ∂ N (β(6C+3τ )+ζ) f (y k ).</formula><p>We are now ready for the convergence theorem, which is based on the idea of interpreting <ref type="bibr" target="#b7">(8)</ref> as an approximate subgradient algorithm.</p><p>Theorem 2: Under Assumptions 1; 2; and 4, with the sequence {x 1 k , ..., x N k } ∞ k=0 generated by <ref type="bibr" target="#b7">(8)</ref> with ϕ ≥ log(β) -log(4N M (β + αC)) / log(γ) ; v i 0 -v0 ≤ β; and β/α ≤ τ , we have:</p><formula xml:id="formula_41">If f ⋆ = -∞, then lim inf k→∞ f (x i k ) = -∞, ∀i = 1, ..., N. If f ⋆ &gt; -∞, then lim inf k→∞ f (x i k ) ≤ f ⋆ + αN (C + τ ) 2 /2+ N (β(9C + 3τ ) + ζ), ∀i = 1, ..., N.</formula><p>Proof: From the definition of y k we have,</p><formula xml:id="formula_42">y k+1 = P X 1 N N i=1 v i k = P X 1 N N i=1 x i k -αg i (x i k ) = P X y k + z k -α N N i=1 g i (x i k ) = P X y k -α N N i=1 g i (x i k ) -z k α .</formula><p>From Lemma 3, we know that v i k -vk ≤ β for all i = 1, .., N and all k ≥ 0. Furthermore, from Lemma 5, we know that N i=1 (g i (x i k ) -z k /α) ∈ ∂ N (β(6C+3τ )+ζ) f (y k ) for all k ≥ 1, since z k /α ≤ β/α ≤ τ by assumption. In addition, we know that N i=1 (g i (x i k )-z k /α) ≤ N (C+τ ). Hence, y k is updated according to an approximate subgradient method and from <ref type="bibr" target="#b11">[12,</ref><ref type="bibr">Proposition 4</ref>.1] we have</p><formula xml:id="formula_43">lim inf k→∞ f (y k ) = -∞, if f ⋆ = -∞ and lim inf k→∞ f (y k ) ≤ f ⋆ + α(N (C + τ )) 2 /(2N )+ N (β(6C + 3τ ) + ζ), if f ⋆ &gt; -∞.</formula><p>Finally, we have</p><formula xml:id="formula_44">f (x i k ) ≤ f (y k ) + N β3C ≤ f ⋆ + αN (C + τ ) 2 /2+ N (β(9C + 3τ ) + ζ), ∀i = 1, ..., N, k ≥ 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark 2:</head><p>The assumption β ≤ ατ in Theorem 2 may seem restrictive, but it can be fulfilled with a fixed number of consensus negotiations according to Lemma 3.</p><p>Remark 3: The initial conditions in Theorem 1 and Theorem 2, x i 0 -x0 ≤ β and v i 0 -v0 ≤ β, respectively, can be fulfilled with sufficiently many consensus negotiations before starting the algorithm. Another simple alternative is to set x i 0 = x j 0 , ∀i, j and v i 0 = v j 0 , ∀i, j, respectively.</p><p>47th IEEE CDC, Cancun, Mexico, Dec. 9-11, 2008 ThTA12.5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. NUMERICAL EXAMPLE</head><p>The proposed subgradient algorithm in combination with consensus iterates as shown in <ref type="bibr" target="#b7">(8)</ref> has been implemented to solve a distributed finite-time optimal rendezvous problem involving three agents moving in a plane with double integrator dynamics. A more detailed problem description can be found in <ref type="bibr" target="#b3">[4]</ref>. Each agent maintains a local version of the optimization variable x i k (the rendezvous position) and performs the local subgradient update with a diminishing stepsize according to <ref type="bibr" target="#b7">(8)</ref>. The consensus updates are performed with the following matrix W : </p><p>Figure <ref type="figure" target="#fig_1">1</ref> illustrates the convergence of the local optimization variable for one of the agents to the globally optimal rendezvous location. The evolution of the local variable for the other agents is very similar. The different curves overlaid in the graph correspond to different choices of the consensus iteration limit (i.e., the maximum number ϕ of consensus steps performed). This illustrates how increased communication in terms of the number of consensus iterations with neighboring agents leads to better convergence rate. As we increase ϕ we expect to approach the convergence rate of the standard subgradient method given in <ref type="bibr" target="#b5">(6)</ref>. The main advantage of our proposed scheme is that the subgradient updates are performed in parallel using information from neighboring agents and there is no need for a central processing unit to whom each agent should communicate its local subgradient. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSIONS AND FUTURE WORK</head><p>In this paper we have described an iterative subgradientbased method for solving coupled optimization problems in a distributed way given restrictions on the communication topology. In order to allow great flexibility in the information exchange architecture and distribute calculations, we combined the local subgradient updates with a consensus process. This means that computing agents can work in parallel with each other and use localized information exchange. The generality of results in consensus theory promises relatively easy extensions of the presented method to situations where the interconnection topology might be time-varying, delayed and the local updates are performed asynchronously. Research on the speed of convergence in consensus protocols has an immediate and clear use in our framework.</p><p>For analysis purposes, we used results from consensus theory and employed approximate subgradient methods to study convergence properties of the proposed scheme. A connection is established between the number of consensus steps and the resulting level of optimality obtained by the subgradient updates. We have illustrated the effect of choosing different consensus iteration limits in an optimal distributed finite-time rendezvous problem.</p><p>A different version of ( <ref type="formula" target="#formula_8">8</ref>) is also conceivable as</p><formula xml:id="formula_46">x i k+1 =P X N j=1 [W ϕ ] ij x j k -α k g i N j=1 [W ϕ ] ij x j k ,</formula><p>where in each update first a consensus is reached on the local variables (at least approximately), and then the corresponding local subgradient updates are calculated and applied. We expect that a similar line of analysis shown in this paper can be performed for such a variation of the original scenario. We are currently exploring different choices of the stepsize, e.g., diminishing stepsizes, and we believe that other results from approximate subgradient methods can be used. Finally, we are also looking into how the different parameters should be tuned, i.e., should we decrease the stepsize or increase the number of negotiations to get closer to optimality?</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1.Convergence plots for increasing number of consensus iterations (ϕ).</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Layering as optimization decomposition: A mathematical theory of network architectures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Calderbank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Doyle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="255" to="312" />
			<date type="published" when="2007-01">Jan. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mathematical decomposition techniques for distributed cross-layer optimization of data networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Soldati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Selected Areas in Communications</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1535" to="1547" />
			<date type="published" when="2006-08">Aug. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Generalized consensus computation in networked systems with erasure links</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rabbat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bucklew</surname></persName>
		</author>
		<editor>IEEE SPAWC</editor>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On decentralized negotiation of optimal consensus</title>
		<author>
			<persName><forename type="first">B</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Speranzon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="page" from="1175" to="1179" />
			<date type="published" when="2008-07">Jul. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the rate of convergence of distributed asynchronous subgradient methods for multi-agent optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ozdaglar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE CDC</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A study on distributed model predictive consensus</title>
		<author>
			<persName><forename type="first">T</forename><surname>Keviczky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IFAC World Congress</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convergence of approximate and incremental subgradient methods for convex optimization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Kiwiel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="807" to="840" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Ozdaglar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Convex Analysis and Optimization</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Consensus and cooperation in networked multi-agent systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Olfati-Saber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Fax</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="215" to="233" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Convergence rates in distributed consensus and averaging</title>
		<author>
			<persName><forename type="first">A</forename><surname>Olshevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CDC</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast linear iterations for distributed averaging</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Systems &amp; Control Letters</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="78" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Subgradient methods for convex minimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIT</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><surname>Ieee Cdc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mexico</forename><surname>Cancun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">Dec. 9-11, 2008 ThTA12.5</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
