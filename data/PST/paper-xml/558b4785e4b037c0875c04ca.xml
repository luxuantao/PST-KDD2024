<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Low-Resolution Face Recognition via Coupled Locality Preserving Mappings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Hong</forename><surname>Chang</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Xilin</forename><surname>Chen</surname></persName>
						</author>
						<title level="a" type="main">Low-Resolution Face Recognition via Coupled Locality Preserving Mappings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5FFB39CC62EC0A3D18EBFCB2B798EF78</idno>
					<idno type="DOI">10.1109/LSP.2009.2031705</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Coupled locality preserving mappings</term>
					<term>face recognition</term>
					<term>low-resolution</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Practical face recognition systems are sometimes confronted with low-resolution face images. Traditional two-step methods solve this problem through employing super-resolution (SR). However, these methods usually have limited performance because the target of SR is not absolutely consistent with that of face recognition. Moreover, time-consuming sophisticated SR algorithms are not suitable for real-time applications. To avoid these limitations, we propose a novel approach for LR face recognition without any SR preprocessing. Our method based on coupled mappings (CMs), projects the face images with different resolutions into a unified feature space which favors the task of classification. These CMs are learned through optimizing the objective function to minimize the difference between the correspondences (i.e., low-resolution image and its high-resolution counterpart). Inspired by locality preserving methods for dimensionality reduction, we introduce a penalty weighting matrix into our objective function. Our method significantly improves the recognition performance. Finally, we conduct experiments on publicly available databases to verify the efficacy of our algorithm.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>T HE performance of a real-world face recognition system usually declines when the input face images are degraded seriously, such as low-resolution (LR) with size of only 12 12 pixels. This is a critical problem for surveillance circumstances. Compared with high-resolution (HR) images, these LR images lose some discriminative details across different persons.</p><p>Intuitively, recovering the lost information of LR face images first is a promising solution for achieving better performance. In fact, most existing "two-step" methods of LR face recognition employ a preprocessing of SR as the first step. Subsequently, the super-resolved face images are passed to the second step for recognition. During the past decade, many SR methods are proposed to predict the corresponding HR image from a single LR image <ref type="bibr" target="#b6">[7]</ref> or multiple LR ones <ref type="bibr" target="#b5">[6]</ref>. Most real-world systems select the rapid and simple interpolation methods, e.g., bilinear, cubic, and spline. Recently, learning-based super-resolution (LSR) methods <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b11">[12]</ref> attract more attention because of their outstanding performance. Freeman et al. <ref type="bibr" target="#b6">[7]</ref> propose a patch-wise Markov network learned from the training set as the SR prediction model. Baker and Kanade <ref type="bibr" target="#b3">[4]</ref> propose "face hallucination" to infer the HR face image from an input LR one based on face priors. Liu et al. <ref type="bibr" target="#b11">[12]</ref> propose to integrate a holistic model and a local model for SR reconstruction. Chang et al. <ref type="bibr" target="#b4">[5]</ref> propose a method based on LLE <ref type="bibr" target="#b15">[16]</ref> which has fairly good performance. The following LSR methods are proposed based on the early works mentioned above.</p><p>Recently, some algorithms attempt to avoid explicit SR in the image domain. The approach performs SR reconstruction in the eigenface domain has been investigated in <ref type="bibr" target="#b7">[8]</ref>. The researchers propose a video-based LR face recognition approach with implicit SR <ref type="bibr" target="#b0">[1]</ref>. More recently, P. Hennings-Yeomans et al. <ref type="bibr" target="#b9">[10]</ref> propose a joint objective function that integrates the aims of super-resolution and face recognition. Compared with two-step methods, this method improves the recognition rate. However, the speed of this algorithm is slow, even for the speed-up version, because the optimization procedure needs to be executed for each test image with regard to each enrollment. In this letter, we focus on the problem of single LR face recognition.</p><p>To overcome the limitations of previous methods, we propose a new efficient method for LR face recognition without any SR preprocessing. According to the aim of recognition, we learn the coupled projections to map the face images with different resolutions into a unified feature space and carry out the recognition step in the new space. An overview of our method is shown in Fig. <ref type="figure" target="#fig_1">1</ref>. Inspired by the works of <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b10">[11]</ref>, we involve the objective of preserving the local structure of the original space into our optimization to achieve better performance. With proper constraints, the formulated optimization problem could be solved in an analytical close-form. These good characteristics make our procedure efficient and effective in both offline training phase and online testing phase. The efficacy of our method will be illustrated in the experiments on the FERET.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. LOW-RESOLUTION FACE RECOGNITION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Statement</head><p>Under many cases, the task of LR face recognition may reduce to find a proper distance measure between a LR face image and a HR one, i.e., . Here, , and , represent the feature vectors of the LR query images in the probe set and the HR ones enrolled in the gallery set. Obviously, some common distances (e.g., Euclidean distance) can not be calculated directly since the dimensions of LR and HR features are not equal (i.e.,</p><p>). To solve this problem, the traditional two-step methods employ super-resolution functions to project the LR image into the target HR space, and then calculate the distance in the HR space as:</p><p>(1)</p><p>In ( <ref type="formula">1</ref>), denotes the SR functions, where is the HR estimate for the LR image . Obviously, the performance of the first SR step is very important for the two-step method. Unfortunately, most existing SR methods are not in the most proper way to improve the performance of the subsequent recognition step.</p><p>Different from previous methods, our approach attempts to project the data points in the original HR and LR feature spaces into a unified feature space by coupled mappings: one for LR feature vectors, ; the other for HR ones, . represents the dimensionality of the new feature space. Then, we can measure the distance by <ref type="bibr" target="#b1">(2)</ref> Note that the two-step methods can be seen as a special case of our algorithm with settings of , and . Now the key problem of our method becomes to pursue the ideal unified feature space. For face recognition, we expect that the projection of each LR image and the corresponding HR projected image should be as close as possible in the new feature space. This principle could be formulated by the following objective function:</p><p>(3) indicates the number of the training images. To minimize the above objective function, we can get coupled mappings.</p><p>More specifically, we consider two matrices and with sizes of and to specify the mapping functions as and , respectively. In this context, (3) could be reformulated as <ref type="bibr" target="#b3">(4)</ref> In the following Section II-B, we derive the analytical solution for this minimization problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Optimization Solution</head><p>Using some deductions of linear algebra <ref type="bibr" target="#b1">[2]</ref>, we can rewrite the objective function (4) into a new form as ( <ref type="formula">5</ref>), shown at the bottom of the page. Here, is the matrix trace operator. The training set in the original LR and HR feature spaces is denoted as and , respectively.</p><p>Furthermore, the objective function is rewritten as</p><formula xml:id="formula_0">(6)</formula><p>Let , and , where is the identity matrix. Consequently, we obtain a concise form as <ref type="bibr" target="#b6">(7)</ref> Finally, we add the constraints to achieve scaling and translation invariance, and solve the optimization problem by minimizing <ref type="bibr" target="#b7">(8)</ref> where is the vector of ones with entries. Let and ; the solution to the optimization problem with respect to could be given by the second to st smallest generalized eigenvectors of , where both sizes of matrices and are . A more efficient solution for this eigendecomposition problem is proposed in the following. Let us expand to obtain two linear equations as follows:</p><p>(9) <ref type="bibr" target="#b9">(10)</ref> Consequently, from (10), we get . Obviously the computational complexity of is lower than . After is calculated, could be computed by <ref type="bibr" target="#b10">(11)</ref> directly. From the formulations above, we can see that our objective agrees with canonical correlation analysis (CCA) <ref type="bibr" target="#b8">[9]</ref>, which is a powerful tool in multivariate analysis.</p><p>Note that, since is not always invertible (e.g., ), we need to perform a regularization operation, say . is set to a small positive value that is smaller than the smallest nonzero eigenvalue (such as</p><p>). The same regularization is adopted for .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Coupled Locality Preserving Mappings</head><p>Inspired by the works of <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b10">[11]</ref>, we introduce the locality preserving objective into our minimization criterion as follows: <ref type="bibr" target="#b12">(13)</ref> Similar with the work of <ref type="bibr" target="#b14">[15]</ref>, the penalty weighting matrix (with size of ) serves to preserve the local relationship between data points in the original feature spaces.</p><p>is defined on the neighborhoods of the data points as follows: otherwise <ref type="bibr" target="#b13">(14)</ref> Here, is the parameter specifying the width of Gaussian function, which is set to where is a scale parameter.</p><p>contains the indices of nearest neighbors of . In this letter, we select the neighborhood system defined in the HR feature space, because HR feature is considered to have more discriminative information <ref type="bibr" target="#b9">[10]</ref>.</p><p>Then ( <ref type="formula">13</ref>) could be written in matrix form as <ref type="bibr" target="#b14">(15)</ref> Here, the matrices and are defined based on the weight matrix as and , respectively. The off diagonal entries in the two matrices are all zeroes.</p><p>Similar deduction with ( <ref type="formula">5</ref>) to <ref type="bibr" target="#b6">(7)</ref>, we obtain  where is the identity matrix with size of , and 1 is the vector of ones with entries. Similarly, let and , the solution to the optimization problem with respect to could be given by the 2-nd to st smallest generalized eigenvectors of . Note that, this formulation can not be solved in the efficient way as described from ( <ref type="formula">9</ref>) to <ref type="bibr" target="#b11">(12)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Our Algorithm</head><p>After the coupled mapping matrices are computed, our method projects the LR query images and the HR enrollments into a new unified feature space and performs face recognition. The proposed method of the LR face recognition has two phases. One is the offline phase which includes learning the coupled mappings and performing transformations on enrolled HR images. The other is online phase which consists of query LR image transformation and feature matching. In Table <ref type="table" target="#tab_0">I</ref>, we summarize our method of LR face recognition.</p><p>From the algorithm, we can see that our approach does not involve any SR or optimization process in the online recognition phase. Therefore, our method is more suitable for real-time systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENTS</head><p>We carry out our experiments on the FERET <ref type="bibr" target="#b13">[14]</ref> face database. The training set has 1002 frontal face images from 429 persons. We evaluate our method based on the standard gallery (1196 images) and the probe set "fafb" (1195 images). In all experiments, the HR face images with size of 72 72 pixels are aligned with the positions of two eyes. The LR images with size of 12 12 pixels are generated by the operation of smoothing and downsampling.</p><p>In our experiments, we compare our methods with (with PCA features) <ref type="bibr" target="#b9">[10]</ref> and several two-step algorithms, which include HR-PCA/LDA (using the HR query images), Spline-PCA/LDA (first restoring the LR query images by spline interpolation), and LSR-PCA/LDA (first restoring the LR query images by LSR <ref type="bibr" target="#b4">[5]</ref> with five neighbors and patch size of 8 8 pixels). There are some super-resolved face examples shown in Fig. <ref type="figure" target="#fig_4">2(c</ref>). In the experiments, the distribution of each pixel is adjusted to mean zero, variance one. In our algorithm based on CLPMs, we set . In Fig. <ref type="figure" target="#fig_4">2(a)</ref>, the recognition rate with different feature dimensionalities are drawn. Our methods based on coupled mappings (CMs) with 144-D features and coupled locality preserving mappings (CLPMs) with 80-D features achieve the recognition rate of 78.2% and 90.1%, respectively. On the other hand, the rates achieved by Spline-PCA and LSR-PCA with 400-D features are 61.8% and 62.5%. The rates of Spline-LDA and LSR-LDA with 150-D features are only 75.8% and 79.1% and still lower than the proposed CLPMs.</p><p>According to the dimensionality selected above, we plot the cumulative recognition results of the different in Fig. <ref type="figure" target="#fig_4">2(b</ref>). From the results, we see that our method outperform the methods of LR face recognition involved in comparison, several two-step methods and . Specially, the result of the proposed CLPMs is even close to that of HR-LDA. Besides, we show the results of CLPMs using different numbers of the nearest neighbors in Fig. <ref type="figure" target="#fig_4">2(b)</ref>. We can see that the proposed algorithm achieves the best performance when , and the recognition rate descends as ascends. Because there are only two or four images in most classes in the training set of FERET, when , our semi-supervised learning in CPLMs must involve the wrong neighbor information. In this case, the performance declines.</p><p>In Fig. <ref type="figure" target="#fig_4">2</ref>(d), we list the mean time requirements for recognizing per query face image on a 3.4 GHz CPU. We can see that our method runs as fast as face recognition using HR face images directly. Meanwhile, the two-step methods are slower than the proposed method because of the expensive preprocessing SR.</p><p>is also time-consuming because of its optimization scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSIONS</head><p>In this letter, we propose a novel approach to solve the problem of the LR face recognition. Different from the traditional two-step methods, our algorithm projects the face images with different resolutions into a unified feature space through coupled mappings. Under the aim of recognition, we propose a minimization objective function w.r.t. the coupled mappings to guarantee the discriminative ability in the new space. Our timesaving method, without any SR, is more suitable for real-time applications. The experimental results on FERET show that our methods can achieve satisfactory performance. Besides, it is worth noting that it is straightforward to extend our method to incorporate supervised information (such as class labels) and to employ nonlinear mappings by kernel techniques.</p><p>The performance of real-world LR face recognition will be degraded by the factors of noise, geometric distortion and so on. Considering these factors with LR simultaneously and using more stable features (i.e., Gabor wavelets) instead of original intensity features in our method will be pursued in future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Manuscript received March 26, 2009; revised July 27, 2009. First published September 04, 2009; current version published October 07, 2009. This work was performed at the Institute of Computing Technology (ICT) and supported by Natural Science Foundation of China under Contracts 60803084, 60872124, and U0835005, and also by the National Basic Research Program of China (973 Program) under Contract 2009CB320902. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Deniz Erdogmus. B. Li is with the School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China. (e-mail: bli@jdl.ac.cn). H. Chang, S. Shan and X. Chen are with the Key Laboratory of Intelligent Information Processing, and the Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China (e-mail: hchang@jdl.ac.cn; sgshan@jdl.ac.cn; xlchen@jdl.ac.cn) Color versions of one or more of the figures in this paper are available online at http://ieeexplore.ieee.org. Digital Object Identifier 10.1109/LSP.2009.2031705</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of our method via coupled locality preserving mappings.</figDesc><graphic coords="2,47.22,66.46,232.00,125.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>is still a generalized eigendecomposition problem with eigenvalue and the corresponding eigenvector . The sizes of matrices and are</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a) Recognition results with different dimensionalities. (b) Cumulative recognition results. (c) Super-resolution examples. From top to bottom: LR image, spline interpolation result, LSR [5] result, and original HR face image. (d) Time requirements.</figDesc><graphic coords="4,43.14,66.66,504.00,126.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I LOW</head><label>I</label><figDesc>-RESOLUTION FACE RECOGNITION BASED ON CMS/CLPMS</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A manifold approach to face recognition from low quality video across illumination and pose using implicit super-resolution</title>
		<author>
			<persName><forename type="first">O</forename><surname>Arandjelovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Computer Vision</title>
		<meeting>IEEE Int. Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Johnson</surname></persName>
		</author>
		<title level="m">Matrix Analysis</title>
		<meeting><address><addrLine>Cambridge, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps for dimensionality reduction and data representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1373" to="1396" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hallucinating faces</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Automatic Face and Gesture Recognition</title>
		<meeting>Int. Conf. Automatic Face and Gesture Recognition</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="83" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Super-resolution through neighbor embedding</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="275" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Super-resolution reconstruction of image sequences</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Feuer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="817" to="834" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning low-level vision</title>
		<author>
			<persName><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pasztor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Carmichael</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="25" to="47" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Eigenface-domain super-resolution for face recognition</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gunturk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Batur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Altunbasak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mersereau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="597" to="606" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Relations between two sets of variates</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hotelling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="312" to="377" />
			<date type="published" when="1936">1936</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Simultaneous super-resolution and feature extraction for recognition of low-resolution faces</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hennings-Yeomans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Locality preserving projections</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances of Neural Information Processing Systems</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A two-step approach to hallucinating faces: Global parametric model and local nonparametric model</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="192" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Limits of learning-based superresolution algorithms</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Computer Vision</title>
		<meeting>IEEE Int. Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The feret evaluation methodology for face-recognition algorithms</title>
		<author>
			<persName><forename type="first">P</forename><surname>Philips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pauss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rivzvi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="137" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Locality preserving CCA with applications to data visualization and pose estimation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="531" to="543" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Nonlinear dimensionality reduction by locally linear embedding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
