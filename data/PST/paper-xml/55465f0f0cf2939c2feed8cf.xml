<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Convex 1-D Total Variation Denoising with Non-convex Regularization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ivan</forename><forename type="middle">W</forename><surname>Selesnick</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ankit</forename><surname>Parekh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ä°lker</forename><surname>Bayram</surname></persName>
						</author>
						<title level="a" type="main">Convex 1-D Total Variation Denoising with Non-convex Regularization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0434DD64B1003A0A0C0DB7A8C06B519E</idno>
					<idno type="DOI">10.1109/LSP.2014.2349356</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Convex optimization</term>
					<term>non-convex regularization</term>
					<term>sparse optimization</term>
					<term>total variation denoising</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Total variation (TV) denoising is an effective noise suppression method when the derivative of the underlying signal is known to be sparse. TV denoising is defined in terms of a convex optimization problem involving a quadratic data fidelity term and a convex regularization term. A non-convex regularizer can promote sparsity more strongly, but generally leads to a non-convex optimization problem with non-optimal local minima. This letter proposes the use of a non-convex regularizer constrained so that the total objective function to be minimized maintains its convexity. Conditions for a non-convex regularizer are given that ensure the total TV denoising objective function is convex. An efficient algorithm is given for the resulting problem.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>T OTAL VARIATION (TV) is a widely used regularizer in sparse signal and image processing <ref type="bibr" target="#b6">[6]</ref>, <ref type="bibr" target="#b20">[20]</ref>; especially when it is known the signal to be recovered has a sparse derivative (or sparse gradients), i.e., when the signal is piecewise constant (PWC). One-dimensional signals of this form arise, for example, in geoscience, astrophysics, and biophysics <ref type="bibr" target="#b11">[11]</ref>.</p><p>TV denoising is defined in terms of a convex optimization problem involving a quadratic data fidelity term and a convex regularization term. Interestingly, for 1-D TV denoising, the exact solution can be obtained using very fast direct algorithms that terminate in a finite number of steps <ref type="bibr" target="#b5">[5]</ref>, <ref type="bibr" target="#b7">[7]</ref>, <ref type="bibr" target="#b12">[12]</ref>.</p><p>In this letter, we consider a modification of the 1-D TV denoising problem where the non-smooth convex regularizer is replaced by a non-convex one. This modification is motivated by the fact that non-convex regularizers can better recover flat signal regions <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b15">[15]</ref>- <ref type="bibr" target="#b17">[17]</ref>. The mathematical properties of the solutions to non-convex regularized signal restoration problems are discussed by Nikolova <ref type="bibr" target="#b15">[15]</ref>- <ref type="bibr" target="#b17">[17]</ref>.</p><p>Generally, the use of a non-convex regularizer (as opposed to a convex one) leads to the formulation of the signal recovery problem as a non-convex optimization problem. In turn, spurious (non-optimal) local minima exist in which iterative optimization algorithms may become entrapped. In addition, the solution to a non-convex problem can be highly sensitive to small changes in the data: an infinitesimal change in the data may lead to a large change in the output, as is the case with the hard threshold function. This sensitivity also complicates the selection of an appropriate value of the regularization parameter. Therefore, we consider the question of how to maintain the convexity of the TV denoising objective function when the regularizer is taken to be non-convex.</p><p>This letter provides a condition on a non-convex regularizer for 1-D TV denoising that ensures the total objective function (comprising data fidelity and regularization terms) is strictly convex. A fast iterative algorithm is described to perform convex TV denoising with a non-convex regularizer set accordingly. Results of the proposed algorithm are compared with standard 1-D TV denoising on simulated data.</p><p>The idea of specifying non-convex penalties in the formulation of convex optimization problems for linear inverse problems was proposed by Blake and Zimmerman <ref type="bibr" target="#b1">[2]</ref> and by Nikolova <ref type="bibr" target="#b13">[13]</ref>, <ref type="bibr" target="#b14">[14]</ref>, <ref type="bibr" target="#b17">[17]</ref>. This approach has recently been considered in <ref type="bibr" target="#b22">[22]</ref> where the convexity condition is cast as a semidefinite program (SDP), in <ref type="bibr" target="#b0">[1]</ref> which considers a non-convex extension of fused-lasso, and in <ref type="bibr" target="#b2">[3]</ref> which addresses translation-invariant group-sparse denoising.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROBLEM FORMULATION Let</head><p>be a piecewise constant signal observed in additive noise. Consider the objective function ,</p><p>where is a regularization parameter, is a sparsity promoting penalty function (regularizer), and is the matrix</p><formula xml:id="formula_1">. . . . . .<label>(2)</label></formula><p>The notation represents component of vector . One-dimensional total variation (TV) denoising is defined as minimizing with respect to ,</p><p>where is taken to be . In this case, is strictly convex on and hence its minimizer is unique. However, it has been shown in the literature that non-convex penalties have advantages in comparison with convex penalties, in terms of more accurately recovering signals with flat regions <ref type="bibr" target="#b15">[15]</ref>- <ref type="bibr" target="#b17">[17]</ref>.</p><p>Here, we consider how to set a non-convex penalty function to promote sparsity of while keeping strictly convex. Then, the minimizer will be unique, the denoising process will be continuous/stable (i.e., infinitesimal changes in do not produce large changes in ), and convex optimization techniques can be used to reliably obtain the minimizer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Non-Convex Penalty Functions</head><p>We assume is continuous, symmetric, twice differentiable on , increasing on , and concave on . Examples of such are the logarithmic penalty <ref type="bibr" target="#b3">(4)</ref> and the arctangent penalty <ref type="bibr" target="#b22">[22]</ref> (5)</p><p>For later, we note for both penalties, that</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. CONVEXITY CONDITION</head><p>To find a condition on ensuring in ( <ref type="formula" target="#formula_0">1</ref>) is strictly convex, we write as <ref type="bibr" target="#b7">(7)</ref> where (8) <ref type="bibr" target="#b9">(9)</ref> Note that if both and are strictly convex, then is strictly convex. Hence, it suffices to find such that and are strictly convex. Due to the similarity of and , it suffices to find such that is strictly convex. We write as where is linear in . We write <ref type="bibr" target="#b10">(10)</ref> where is defined as <ref type="bibr" target="#b11">(11)</ref> For the purpose of analyzing the convexity of , the linear function can be disregarded. Hence, if is strictly convex on , then , being a sum of strictly convex functions, will be strictly convex on .</p><p>To find a condition on so as to ensure is strictly convex, we define as <ref type="bibr" target="#b12">(12)</ref> Then is strictly convex if and only if is strictly convex. From <ref type="bibr" target="#b11">(11)</ref>, we write (13) <ref type="bibr" target="#b14">(14)</ref> where is linear in . Since we are concerned with the convexity of , the linear function can be disregarded, as above.</p><p>The function is strictly convex if and only if , defined as , is strictly convex. By Theorem 6.4 of <ref type="bibr" target="#b10">[10]</ref>,</p><p>is strictly convex if it has a strictly increasing right-derivative. By assumption, is twice differentiable on ; hence, is strictly convex if and only if <ref type="bibr" target="#b15">(15)</ref> and for all <ref type="bibr" target="#b16">(16)</ref> In fact, from the assumptions on as stated in Sec. II-A, condition (15) already follows. (If is increasing on and twice differentiable on , then . If also is symmetric, then .) Condition ( <ref type="formula">16</ref>) is the positivity of the second derivative of with respect to . We write the condition as <ref type="bibr" target="#b17">(17)</ref> which constitutes a constraint on the non-convexity of . For various standard penalties, including (4) and ( <ref type="formula">5</ref>), the second derivative is most negative at . For such penalties, condition (17) can be written <ref type="bibr" target="#b18">(18)</ref> For the logarithmic and arctangent penalties, (4) and ( <ref type="formula">5</ref>), parameterized by , we use <ref type="bibr" target="#b6">(6)</ref>  Hence, the condition can be written as <ref type="bibr" target="#b21">(21)</ref> Let be a matrix of size such that . It can be taken to be the discrete anti-derivative (cumulative summation operator), defined by <ref type="bibr" target="#b22">(22)</ref> Then it follows from ( <ref type="formula">21</ref>) that ( <ref type="formula">23</ref>) Condition ( <ref type="formula">23</ref>) can be used to validate the optimality of a candidate and to gauge the convergence of an algorithm minimizing . The condition (23) implies that the points (24) lie on the graph of , as illustrated in Fig. <ref type="figure" target="#fig_2">2 below.</ref> V. ALGORITHM Following the procedure in <ref type="bibr" target="#b8">[8]</ref>, we use the majorization-minimization (MM) approach to derive a fast-converging algorithm. A majorizer of is given by , As noted in <ref type="bibr" target="#b8">[8]</ref>, as the algorithm converges to a solution for which is sparse, elements of go to infinity. To avoid the numerical problems related to this, as in <ref type="bibr" target="#b8">[8]</ref>, we use the matrix inverse lemma to write (31)</p><p>The iteration (30) can then be written as <ref type="bibr">(32)</ref> We initialize the iteration with . Note that the system matrix in (32) is tridiagonal; hence, the iteration can be implemented with very high computational efficiency using a fast solver <ref type="bibr" target="#b19">[19,</ref><ref type="bibr">Sect 2.4</ref>]. Due to MM, each iteration monotonically decreases the cost function value. We have found that 20 iterations of (32) are usually sufficient.</p><p>Note that in (25) is undefined for . Hence if for some iteration and some index , then the majorizer is undefined. This manifests itself as a 'division-byzero' error in (28). Due to the use of the matrix inverse lemma, this becomes a 'multiplication-by-zero' and causes no numerical problem in the algorithm (32). However, it complicates the proof of convergence of the algorithm. We do not prove its convergence. We remark (i) in practice, convergence is not adversely affected by this issue, (ii) optimality can be verified using (23), and (iii) this issue has been discussed in the literature <ref type="bibr" target="#b8">[8]</ref>, <ref type="bibr" target="#b9">[9]</ref>, <ref type="bibr" target="#b18">[18]</ref> where it was found not to impede the convergence of affected algorithms in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EXAMPLES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Example 1</head><p>Total variation denoising with convex and non-convex regularization is illustrated in Fig. <ref type="figure" target="#fig_1">1</ref>. The noisy data is obtained using additive white Gaussian noise (AWGN) (</p><p>) on a PWC signal, , of length ('blocks' generated by the Wavelab function,</p><p>). For both convex  and non-convex cases, we set , consistent with the range suggested in <ref type="bibr" target="#b7">[7]</ref> for standard (convex) TV denoising. We set the non-convexity parameter to its maximal value, . We use 20 iterations of (32). The improvement of non-convex regularization is reflected in the lower RMSE of 0.25 compared to 0.32. For further comparison, Fig. <ref type="figure" target="#fig_1">1</ref> shows the error, , for both convex and non-convex regularized solutions. The convex solution underestimates the true first-order difference signal more so than the non-convex one.</p><p>The optimality of the non-convex solution acquired using iteration (32) is validated using (23). The condition is graphically illustrated as a scatter plot in Fig. <ref type="figure" target="#fig_2">2</ref>. The preponderance of points on the vertical line, , reflects the sparsity of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Example 2</head><p>In this example, we consider the relative performance of convex and non-convex regularized TV denoising as a function of noise power. We generate random realizations of PWC signals. Each realization is of length 1000 and has 15 step-edges. The step-edges are uniformly distributed over the duration of the signal. The amplitudes of the steps are uniformly distributed in . We corrupt each realization with AWGN, . TV denoising is applied to each noise-corrupted realization using and as above. Fig. <ref type="figure" target="#fig_3">3</ref> illustrates the RMSE as a function of . It can be seen that non-convex regularization offers the most improvement at low noise levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>TV denoising is a basic method for the estimation of PWC signals in noise. This letter gives a modification of the standard TV denoising problem where the regularizer is non-convex yet constrained so that the total objective function is convex. The improvement is not as dramatic as that offered by non-convex regularization without such a constraint-see <ref type="bibr" target="#b16">[16]</ref> for examples. However, due to the convexity, the solution is reliably obtained via convex optimization, the solution depends continuously on the data, and the regularization parameter can be set as in the convex case (e.g., <ref type="bibr" target="#b7">[7]</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>(</head><label></label><figDesc>See, for example, Fig.11in<ref type="bibr" target="#b21">[21]</ref>.) Hence, a majorizer of in (on .Using (27) in the MM update iteration,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Total variation denoising with convex and non-convex penalties.</figDesc><graphic coords="3,306.00,63.12,241.02,411.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Optimality condition (23) for Example 1.</figDesc><graphic coords="4,49.02,64.14,232.98,141.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Example 2. RMSE as a function of noise level for randomly generated PWC signals of length 1000. Non-convex penalties yield a lower RMSE than convex penalties.</figDesc><graphic coords="4,43.98,241.14,241.18,133.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Manuscript received June 19, 2014; revised August 03, 2014; accepted August 10, 2014. Date of publication August 20, 2014; date of current version August 28, 2014. This work was supported by the National Science Foundation under Grant CCF-1018020. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Xiao-Ping Zhang.</figDesc><table><row><cell>This paper has supplementary downloadable material, available at http://iee-</cell></row><row><cell>explore.ieee.org, provided by the authors. The material includes software</cell></row><row><cell>(MATLAB) implementing the algorithm and examples.</cell></row><row><cell>Digital Object Identifier 10.1109/LSP.2014.2349356</cell></row></table><note><p><p>I. W. Selesnick and A. Parekh are with the Department of Electrical and Computer Engineering, New York University, Brooklyn, NY 11201 USA.</p>Ä°. Bayram is with Istanbul Technical University, Istanbul, Turkey.</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fused lasso with a nonconvex sparsity inducing penalty</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bayram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Selesnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoust., Speech, Signal Process. (ICASSP)</title>
		<meeting>IEEE Int. Conf. Acoust., Speech, Signal ess. (ICASSP)</meeting>
		<imprint>
			<date type="published" when="2014-05">May 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Visual Reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Group-sparse signal denoising: Non-convex regularization, convex optimization</title>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W</forename><surname>Selesnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="3464" to="3478" />
			<date type="published" when="2014-07">Jul. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A majorizeminimize subspace approach for image regularization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Chouzenoux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jezierska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pesquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Talbot</surname></persName>
		</author>
		<imprint>
			<publisher>SIAM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">J. Imag. Sci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="563" to="591" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A direct algorithm for 1-D total variation denoising</title>
		<author>
			<persName><forename type="first">L</forename><surname>Condat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1054" to="1057" />
			<date type="published" when="2013-11">Nov. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dual constrained TV-based regularization on graphs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Grady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Najman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Pesquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Talbot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imag. Sci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1246" to="1273" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Extensions of smoothing via taut strings</title>
		<author>
			<persName><forename type="first">L</forename><surname>DÃ¼mbgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kovac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electron. J. Statist</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="41" to="75" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Majorization-minimization algorithms for wavelet-based image restoration</title>
		<author>
			<persName><forename type="first">M</forename><surname>Figueiredo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nowak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2980" to="2991" />
			<date type="published" when="2007-12">Dec. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Convergence of a sparse representations algorithm applicable to real or complex data</title>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Fuchs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE. J. Sel. Topics Signal Process</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="598" to="605" />
			<date type="published" when="2007-12">Dec. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Hiriart-Urruty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
		<title level="m">Fundamentals of Convex Analysis</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generalized methods and solvers for noise removal from piecewise constant signals: Part I-background theory</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Roy. Soc. A</title>
		<imprint>
			<biblScope unit="volume">467</biblScope>
			<biblScope unit="page" from="3088" to="3114" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Locally adaptive regression splines</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mammen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van De Geer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="387" to="413" />
			<date type="published" when="1997-02">Feb. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Estimation of binary images by minimizing convex criteria</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nikolova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. Image Proc</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="108" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Markovian reconstruction using a GNC approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nikolova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1204" to="1220" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Local strong homogeneity of a regularized estimator</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nikolova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Appl. Math</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="633" to="658" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Energy minimization methods</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nikolova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Mathematical Methods in Imaging</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="138" to="186" />
		</imprint>
	</monogr>
	<note>ch. chapter 5</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast nonconvex nonsmooth minimization methods for image restoration and reconstruction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nikolova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-P</forename><surname>Tam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3073" to="3088" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adaptive total variation image deblurring: A majorization-minimization approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A T</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1683" to="1693" />
			<date type="published" when="2009-09">Sep. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Teukolsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Vetterling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Flannery</surname></persName>
		</author>
		<title level="m">Numerical Recipes in C: The Art of Scientific Computing</title>
		<meeting><address><addrLine>Cambridge, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Nonlinear total variation based noise removal algorithms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fatemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="259" to="268" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Penalty and shrinkage functions for sparse signal processing</title>
		<author>
			<persName><forename type="first">I</forename><surname>Selesnick</surname></persName>
		</author>
		<ptr target="http://cnx.org/content/m45134/1.1/" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sparse signal estimation by maximally sparse convex optimization</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W</forename><surname>Selesnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bayram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1078" to="1092" />
			<date type="published" when="2014-03">Mar. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
