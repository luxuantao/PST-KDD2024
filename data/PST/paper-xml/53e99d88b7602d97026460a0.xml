<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving TCP Congestion Control over Internets with Heterogeneous Transmission Media £</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Christina</forename><surname>Parsa</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering Department Baskin School of Engineering</orgName>
								<orgName type="institution">University of California Santa Cruz</orgName>
								<address>
									<postCode>95064</postCode>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improving TCP Congestion Control over Internets with Heterogeneous Transmission Media £</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2489C3BD382DE18D8FFD3496BDB4F0CF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a new implementation of TCP that is better suited to today's Internet than TCP Reno or Tahoe. Our implementation of TCP, which we call TCP Santa Cruz, is designed to work with path asymmetries, out-of-order packet delivery, and networks with lossy links, limited bandwidth and dynamic changes in delay. The new congestion-control and error-recovery mechanisms in TCP Santa Cruz are based on: using estimates of delay along the forward path, rather than the round-trip delay; reaching a target operating point for the number of packets in the bottleneck of the connection, without congesting the network; and making resilient use of any acknowledgments received over a window, rather than increasing the congestion window by counting the number of returned acknowledgments. We compare TCP Santa Cruz with the Reno and Vegas implementations using the ns2 simulator. The simulation experiments show that TCP Santa Cruz achieves significantly higher throughput, smaller delays, and smaller delay variances than Reno and Vegas. TCP Santa Cruz is also shown to prevent the swings in the size of the congestion window that typify TCP Reno and Tahoe traffic, and to determine the direction of congestion in the network and isolate the forward throughput from events on the reverse path.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>½ ÁÒØÖÓ Ù Ø ÓÒ</head><p>Reliable end-to-end transmission of data is a much needed service for many of today's applications running over the Internet (e.g., WWW, file transfers, electronic mail, remote login), which makes TCP an essential component of today's Internet. However, it has been widely demonstrated that TCP exhibits poor performance over wireless networks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17]</ref> and networks that have even small degrees of path asymmetries <ref type="bibr" target="#b10">[11]</ref>. The performance problems of current TCP implementations (Reno and Tahoe) over internets of heterogeneous transmission media stem from inherent limitations in the error recovery and congestion-control mechanisms they use.</p><p>Traditional Reno and Tahoe TCP implementations perform one round-trip time estimate for each window of outstanding data. In addition, Karn's algorithm <ref type="bibr" target="#b8">[9]</ref> dictates that, after a packet loss, round-trip time (RTT) estimates for a retransmitted packet cannot be used in the TCP RTT estimation. The unfortunate side-effect of this approach is that no estimates are made during periods of congestion -precisely the time when they would be the most useful.</p><p>£ This work was supported in part at UCSC by the Office of Naval Research (ONR) under Grant N00014-99-1-0167.</p><p>Without accurate RTT estimates during congestion, a TCP sender may retransmit prematurely or after undue delays. Because all prior approaches are unable to perform RTT estimates during periods of congestion, a timer-backoff strategy (in which the timeout value is essentially doubled after every timeout and retransmission) is used to avoid premature retransmissions.</p><p>Reno and Tahoe TCP implementations and many proposed alternative solutions <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20]</ref> use packet loss as a primary indication of congestion; a TCP sender increases its window size, until packet losses occur along the path to the TCP receiver. This poses a major problem in wireless networks, where bandwidth is a very scarce resource. Furthermore, the periodic and wide fluctuation of window size typical of Reno and Tahoe TCP implementations causes high fluctuations in delay and therefore high delay variance at the endpoints of the connection -a side effect that is unacceptable for delay-sensitive applications.</p><p>Today's applications over the Internet are likely to operate over paths that either exhibit a high degree of asymmetry or which appear asymmetric due to significant load differences between the forward and reverse data paths. Under such conditions, controlling congestion based on acknowledgment (ACK) counting as in TCP Reno and Tahoe results in significant underutilization of the higher capacity forward link due to loss of ACKs on the slower reverse link <ref type="bibr" target="#b10">[11]</ref>. ACK losses also lead to very bursty data traffic on the forward path. For this reason, a better congestion control algorithm is needed that is resilient to ACK losses.</p><p>In this paper, we propose TCP Santa Cruz, which is a new implementation of TCP implementable as a TCP option by utilizing the extra 40 bytes available in the options field of the TCP header. TCP Santa Cruz detects not only the initial stages of congestion, but can also identify the direction of congestion, i.e., it determines if congestion is developing in the forward path and then isolates the forward throughput from events such as congestion on the reverse path. The direction of congestion is determined by estimating the relative delay that one packet experiences with respect to another; this relative delay is the foundation of our congestion control algorithm. Our approach is significantly different from rate-controlled congestion control approaches, e.g., TCP Vegas <ref type="bibr" target="#b1">[2]</ref>, as well as those that use an increasing round-trip time (RTT) estimate as the primary indication of congestion <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21]</ref>, in that TCP Santa Cruz does not use RTT estimates in any way for congestion control. This represents a fundamental improvement over the latter approaches, because RTT measurements do not permit the sender to differentiate between delay variations due to increases or decreases in the forward or reverse paths of a connection.</p><p>TCP Santa Cruz provides a better error-recovery strategy than Reno and Tahoe do by providing a mechanism to perform RTT estimates for every packet transmitted, including retransmissions. This eliminates the need for Karn's algorithm and does not require any timer-backoff strategies, which can lead to long idle periods on the links. In addition, when multiple segments are lost per window we provide a mechanism to perform retransmissions without waiting for a TCP timeout. Section 2 discusses prior related work to improving TCP and compares those approaches to ours. Section 3 describes the algorithms that form our proposed TCP implementation and shows examples of their operation. Section 4 shows via simulation the performance improvements obtained with TCP Santa Cruz over the Reno and Vegas TCP implementations. Finally, Section 5 summarizes our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¾ ÈÖ Ú ÓÙ× ÏÓÖ</head><p>Congestion control for TCP is an area of active research; solutions to congestion control for TCP address the problem either at the intermediate routers in the network <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b5">6]</ref> or at the endpoints of the connection <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>.</p><p>Router-based support for TCP congestion control can be provided through RED gateways <ref type="bibr" target="#b5">[6]</ref>, a solution in which packets are dropped in a fair manner (based upon probabilities) once the router buffer reaches a predetermined size. As an alternative to dropping packets, an Explicit Congestion Notification (ECN) <ref type="bibr" target="#b7">[8]</ref> bit can be set in the packet header, prompting the source to slow down. Current TCP implementations do not support the ECN method. Kalampoukas et al. <ref type="bibr" target="#b12">[13]</ref> propose an approach that prevents TCP sources from growing their congestion window beyond the bandwidth delay product of the network by allowing the routers to modify the receiver's advertised window field of the TCP header in such a way that TCP does not overrun the intermediate buffers in the network.</p><p>End-to-end congestion control approaches can be separated into three categories: rate-control, packet round-trip time (RTT) measurements, and modification of the source or receiver to return additional information beyond what is specified in the standard TCP header <ref type="bibr" target="#b19">[20]</ref>. A problem with rate-control and relying upon RTT estimates is that variations of congestion along the reverse path cannot be identified and separated from events on the forward path. Therefore, an increase in RTT due to reverse-path congestion or even link asymmetry will affect the performance and accuracy of these algorithms. In the case of RTT monitoring, the window size could be decreased (due to an increased RTT measurement) resulting in decreased throughput; in the case of rate-based algorithms, the window could be increased in order to bump up throughput, resulting in increased congestion along the forward path.</p><p>Wang and Crowcroft's DUAL algorithm <ref type="bibr" target="#b20">[21]</ref> uses a congestion control scheme that interprets RTT variations as indications of delay through the network. The algorithm keeps track of the minimum and maximum delay observed to estimate the maximum queue size in the bottleneck routers and keep the window size such that the queues do not fill and thereby cause packet loss. An adjustment of ¦ ½ ÛÒ is made to the congestion window every other roundtrip time whenever the observed RTT deviates from the mean of the highest and lowest RTT ever observed. RFC 1323 <ref type="bibr" target="#b6">[7]</ref> uses the TCP Options to include a timestamp in every data packet from sender to receiver to obtain a more accurate RTT estimate. The receiver echoes this timestamp in each ACK packet and the round-trip time is calculated with a single subtraction. This approach encounters problems when delayed ACKs are used, because it is then unclear to which packet the timestamp belongs. RFC 1323 suggests that the receiver return the earliest timestamp so that the RTT estimate takes into account the delayed ACKs, as segment loss is assumed to be a sign of congestion, and the timestamp returned is from the sequence number which last advanced the window. When a hole is filled in the sequence space, the receiver returns the timestamp from the segment which filled hole. The downside of this approach is that it cannot provide accurate timestamps when segments are lost.</p><p>Two notable rate-control approaches are the Tri-S <ref type="bibr" target="#b21">[22]</ref> scheme and TCP Vegas <ref type="bibr" target="#b1">[2]</ref>. Wang and Crowcroft's Tri-S algorithm <ref type="bibr" target="#b21">[22]</ref> computes the achieved throughput by measuring the RTT for a given window size (which represents the amount of outstanding data in the network) and comparing the throughput when the window is increased by one segment. TCP Vegas has three main components: a retransmission mechanism, a congestion avoidance mechanism, and a modified slow-start algorithm. TCP Vegas provides faster retransmissions by examining a timestamp upon receipt of a duplicate ACK. The congestion avoidance mechanism is based upon a once per round-trip time comparison between the ideal (expected) throughput and the actual throughput. The ideal throughput is based upon the best RTT ever observed and the observed throughput is the throughput observed over a RTT period. The goal is to keep the actual throughput between two threshhold values, « and ¬, which represent too little and too much data in flight, respectively.</p><p>Because we are interested in solutions to TCP's performance problems applicable over different types of networks and links, our approach focuses on end-to-end solutions. However, our work is closely related to a method of bandwidth probing introduced by Keshav <ref type="bibr" target="#b9">[10]</ref>. In this approach, two back-to-back packets are transmitted through the network and the interarrival time of their ACK packets is measured to determine the bottleneck service rate (the conjecture is that the ACK spacing preserves the data packet spacing). This rate is then used to keep the bottleneck queue at a predetermined value. For the scheme to work, it is assumed that the routers are employing round-robin or some other fair service discipline. The approach does not work over heterogeneous networks, where the capacity of the reverse path could be orders of magnitude slower than the forward path because the data packet spacing is not preserved by the ACK packets. In addition, a receiver could employ a delayed ACK strategy, which is common in many TCP implementations, and congestion on the reverse path can interfere with ACK spacing and invalidate the measurements made by the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¿ Ì È Ë ÒØ ÖÙÞ ß ÈÖÓØÓ ÓÐ × Ö ÔØ ÓÒ</head><p>TCP Santa Cruz provides improvement over TCP Reno in two major areas : congestion control and error recovery. The congestion control algorithm introduced in TCP Santa Cruz determines when congestion exists or is developing on the forward data path -a condition which cannot be detected by a round-trip time estimate. This type of monitoring permits the detection of the incipient stages of congestion, allowing the congestion window to increase or decrease in response to early warning signs. In addition, TCP Santa Cruz uses relative delay calculations to isolate the forward throughput from any congestion that might be present along the reverse path.</p><p>The error recovery methods introduced in TCP Santa Cruz perform timely and efficient early retransmissions of lost packets, eliminate unnecessary retransmissions for correctly received packets when multiple losses occur within a window of data, and provide RTT estimates during periods of congestion and retransmission (i.e., eliminate the need for Karn's algorithm). The rest of this section describes these mechanisms.</p><formula xml:id="formula_0">¿º½ ÓÒ ×Ø ÓÒ ÓÒØÖÓÐ ¿º½º½ Ð Ñ Ò Ø Ò ÊÌÌ Ñ Ù ØÝ Ù× Ò Ö Ð¹ Ø Ú Ð Ý×</formula><p>Round-trip time measurements alone are not sufficient for determining whether congestion exists along the data path. Figure <ref type="figure">1</ref> shows an example of the ambiguity involved when only RTT measurements are considered. Congestion is indicated by a queue along the transmission path. The example shows the transmission of two data packets and the returning ACKs from the receiver. If only round-trip time (RTT) measurements were used, then measurements ÊÌÌ½ and ÊÌÌ¾</p><p>, could lead to an incorrect conclusion of developing congestion in the forward path for the second packet. The true cause of increased RTT for the second packet is congestion along the reverse path, not the data path. Our protocol solves this ambiguity by introducing the notion of the relative forward delay.</p><formula xml:id="formula_1">= -0.5 &lt; 0 D F 2,1 RTT 1 = 4 RTT 2 = 5 t=3.5 t=4 t=5 t=7 t=1 t=2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Example of RTT ambiguity</head><p>Relative delay is the increase and decrease in delay that packets experience with respect to each other as they propagate through the network. These measurements are the basis of our congestion control algorithm. The sender calculates the relative delay from a timestamp contained in every ACK packet that specifies the arrival time of the packet at the destination. From the relative delay measurement the sender can determine whether congestion is increasing or decreasing in either the forward or reverse path of the connection; furthermore, the sender can make this determination for every ACK packet it receives. This is impossible to accomplish using RTT measurements.</p><p>Figure <ref type="figure" target="#fig_0">2</ref> shows the transfer of two sequential packets transmitted from a source to a receiver and labeled #1 and #2. The sender maintains a table with the following two times for every packet: (a) the transmission time of the data packet at the source, and (b) the arrival time of the data packet at the receiver, as reported by the receiver in its ACK. From this information, the sender calculates the following time intervals for any two data packets and (where ): Ë , the time interval between the transmission of the packets; and Ê , the inter-arrival time of the data packets at the receiver. From these values, the relative forward delay, , can be obtained:</p><formula xml:id="formula_2">Ê Ë<label>(1)</label></formula><p>where represents the change in forward delay experienced by packet with respect to packet .  </p><formula xml:id="formula_3">i j j,i pkt #1 pkt #2 ACK #1 ACK #2 A S ACK #1 R j,i ACK #2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¼.</head><p>Finally, Figure <ref type="figure">3</ref>(d) illustrates out-of-order arrival at the receiver. In the latter case, the sender is able to determine the presence of multiple paths to the destination by the timestamps returned from the receiver. Although the example illustrates measurements based on two consecutive packets, TCP Santa Cruz does not require that the calculations be performed on two sequential packets; however, the granularity of the measurements depends on the ACK policy used. in size, decreasing in size, or maintaining their current state. The state diagram of Figure <ref type="figure">4</ref> shows how the computation of the relative forward delay, , allows the determination of the change in queue state. The goal in TCP Santa Cruz is to allow the network queues (specifically the bottleneck queue) to grow to a desired size; the specific algorithm to achieve this goal is described next.</p><p>The positive and negative relative delay values represent additional or less queueing in the network, respectively. Summing the relative delay measurements over a period of time provides an indication of the level of queueing at the bottleneck. If the sum of relative delays over an interval equals 0, it indicates that, with respect to the beginning of the interval, no additional congestion or queueing was present in the network at the end of the interval. Likewise, if we sum relative delays from the beginning of a session, and at any point the summation equals zero, we would know that all of the data for the session are contained in the links and not in the network queues (assuming the queues were initially empty).</p><p>The congestion control algorithm of TCP Santa Cruz operates by summing the relative delays from the beginning of a session, and then updating the measurements at discrete intervals, with each interval equal to the amount of time to transmit a windowful of data and receive the corresponding ACKs. Since the units of is time (seconds), the relative delay sum must then be translated into an equivalent number of packets (queued at the bottleneck) represented by this delay. In other words, the algorithm attempts to maintain the following condition:</p><formula xml:id="formula_4">ÒØ AEÓÔ ÒØ ½ • ÅÏ ½ (2)</formula><p>where ÒØ is the total number of packets queued at the bottleneck at time Ø ; AEÓÔ is the operating point (the desired number of packets, per session, to be queued at the bottleneck); ÅÏ ½ is the additional amount of queueing introduced over the previous window Ï ½; and ÒØ ½ ÅÏ ¼ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ì ÓÔ Ö Ø Ò ÔÓ ÒØ</head><p>The operating point, AEÓÔ, is the desired number of packets to reside in the bottleneck queue.</p><p>The value of AEÓÔ should be greater than zero; the intuition behind this decision is that an operating point equal to zero would lead to underutilization of the available bandwidth because the queues are always empty, i.e., no queueing is tolerated. Instead, the goal is to allow a small amount of queueing so that a packet is always available for forwarding over the bottleneck link. For example, if we choose AEÓÔ to be 1, then we expect a session to maintain 1 packet in the bottleneck queue, i.e., our ideal or desired congestion window would be one packet above the bandwidth delay product (BWDP) of the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ÌÖ Ò×Ð Ø Ò Ø Ö Ð Ø Ú Ð Ý</head><p>The relative delay gives an indication of the change in network queueing, but provides no information on the actual number of packets corresponding to this value. We translate the sum of relative delays into the equivalent number of queued packets by first calculating the average packet service time, Ô ØË (× Ô Ø), achieved by a session over an interval. This rate is of course limited by the bottleneck link.</p><p>Our model of the bottleneck link, depicted in Figure <ref type="figure" target="#fig_3">5</ref>, consists of two delay parameters: the queueing delay, É ; and the output service time, Ô ØË (the amount of time spent servicing a packet).</p><p>The queueing delay is variable and is controlled by the congestion control algorithm (by changing the sender's congestion window) and by network cross-traffic. The relative delay measurements provide some feedback about this value. The output rate of a FIFO queue will vary according to the number of sessions and the burstiness of the arrivals from competing sessions. The packet service rate is calculated as</p><formula xml:id="formula_5">Ô ØË Ê Ô Ø× Ö Ú<label>(3)</label></formula><p>where Ê is the difference in arrival time of any two packets as calculated from the timestamps returned by the receiver. Because Ô ØË changes during an interval, we calculate the average packet service time, Ô ØË, over the interval. Finally, we translate the sum of relative delays over the interval into the equivalent number of packets represented by the sum by dividing the relative delay summation by the average time to service a packet. This gives us the number of packets represented by the delay over an interval:</p><formula xml:id="formula_6">ÅÏ ½ È Ô ØË<label>(4)</label></formula><p>where are packet-pairs within window Ï ½. The total queueing in the system at the end of the interval is determined by Eq. 2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ù×Ø Ò Ø Û Ò ÓÛ</head><p>The TCP Santa Cruz congestion window is adjusted such that Eq. 2 is satisfied within a range of AEÓÔ ¦ AE, where AE is some fraction of a packet. Adjustments are made to the congestion window only at discrete intervals, i.e., in the time taken to empty a windowful of data from the network. Over this interval, ÅÏ ½ is calculated and at the end of the interval it is added to ÒØ ½ . If the result falls within the range of AEÓÔ ¦ AE, the congestion window is maintained at its current size. If, however, ÒØ falls below AEÓÔ AE, the system is not being pushed enough and the window is increased linearly during the next interval. If ÒØ rises above AEÓÔ • AE, then the system is being pushed too high above the desired operating point, and the congestion window is decreased linearly during the next interval.</p><p>In TCP Reno, the congestion control algorithm is driven by the arrival of ACKs at the source (the window is incremented by ½ ÛÒ for each ACK while in the congestion avoidance phase). This method of ACK counting causes Reno to perform poorly when ACKs are lost <ref type="bibr" target="#b10">[11]</ref>; unfortunately, ACK loss becomes a predominant feature in TCP over asymmetric networks <ref type="bibr" target="#b10">[11]</ref>. Given that the congestion control algorithm in TCP Santa Cruz makes adjustments to the congestion window based upon delays through the network and not on the arrival of ACKs in general, the algorithm is robust to ACK losses.</p><p>ËØ ÖØÙÔ Currently, the algorithm used by TCP Santa Cruz at startup is the slow start algorithm used by TCP Reno with two modifications. First, the initial congestion window, ÛÒ , is set to two segments instead of one so that initial values for can be calculated. Second, the algorithm may stop slow start before ××Ø Ö × ÛÒ if any relative delay measurement or ÒØ exceeds AEÓÔ ¾. Once stopped, slow start begins again only if a timeout occurs. During slow start, the congestion window doubles every round-trip time, leading to an exponential growth in the congestion window. One problem with slow start is that such rapid growth often leads to congestion in the data path <ref type="bibr" target="#b1">[2]</ref>. TCP-SC reduces this problem by ending slow start once any queue buildup is detected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¿º¾ ÖÖÓÖ Ê ÓÚ ÖÝ ¿º¾º½ ÁÑÔÖÓÚ ÊÌÌ ×Ø Ñ Ø</head><p>TCP Santa Cruz provides better RTT estimates over traditional TCP approaches by measuring the round-trip time (RTT) of every segment transmitted for which an ACK is received, including retransmissions. This eliminates the need for Karn's algorithm <ref type="bibr" target="#b8">[9]</ref> (in which RTT measurements are not made for retransmissions) and timer-backoff strategies (in which the timeout value is essentially doubled after every timeout and retransmission). To accomplish this, TCP Santa Cruz requires each returning ACK packet to indicate the precise packet that caused the ACK to be generated and the sender must keep a timestamp for each transmitted or retransmitted packet. Packets can be uniquely identified by specifying both a sequence number and a retransmission copy number. For example, the first transmission of packet 1 is specified as 1.1, the second transmission is labeled 1.2, and so forth. In this way, the sender can perform a new RTT estimate for every ACK it receives. Therefore, ACKs from the receiver are logically a triplet consisting of a cumulative ACK (indicating the sequence number of the highest in-order packet received so far), and the two-element sequence number of the packet generating the ACK (usually the most recently received packet). For example, ACK (5.7.2) specifies a cumulative ACK of 5, and that the ACK was generated by the second transmission of a packet with sequence number 7. As with traditional TCP implementations, we do not want the RTT estimate to be updated too quickly; therefore, a weighted average is computed for each new value received. We use the same algorithm as TCP Tahoe and Reno; however, the computation is performed for every ACK received, instead of once per RTT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¿º¾º¾ Ã Ï Ò ÓÛ</head><p>To assist in the identification and recovery of lost packets, the receiver in TCP Santa Cruz returns an ACK Window to the sender to indicate any holes in the received sequential stream. In the case of multiple losses per window, the ACK Window allows TCP-SC to retransmit all lost packets without waiting for a TCP timeout.</p><p>The ACK Window is similar to the bit vectors used in previous protocols, such as NETBLT <ref type="bibr" target="#b3">[4]</ref> and TCP-SACK <ref type="bibr" target="#b4">[5]</ref> <ref type="bibr" target="#b14">[15]</ref>. Unlike TCP-SACK, our approach provides a new mechanism whereby the receiver is able to report the status of every packet within the current transmission window. ½ The ACK Window is maintained as a vector in which each bit represents the receipt of a specified number of bytes beyond the cumulative ACK. The receiver determines an optimal granularity for bits in the vector and indicates this value to the sender via a one-byte field in the header. A maximum of 19 bytes are available for the ACK window to meet the 40-byte limit of the TCP option field in the TCP header. The granularity of the bits in the window is bounded by the receiver's advertised window and the 18 bytes available for the ACK window; this can accommodate a 64K window with each bit representing 450 bytes. Ideally, a bit in the vector would represent the MSS of the connection, or the typical packet size. Note this approach is meant for data intensive traffic, therefore bits represent at least 50 bytes of data. If there are no holes in the expected sequential stream at the receiver, then the ACK window is not generated.</p><p>Figure <ref type="figure" target="#fig_4">6</ref> shows the transmission of five packets, three of which are lost and shown in grey (1,3, and 5). The packets are of variable size and the length of each is indicated by a horizontal arrow. Each bit in the ACK window represents 50 bytes with a 1 if the bytes are present at the receiver and a 0 if they are missing. Once packet #1 is recovered, the receiver would generate a cumulative ACK of 1449 and the bit vector would indicate positive ACKs for bytes 1600 through 1849. There is some ambiguity for packets 3 and 4 since the ACK window shows that bytes 1550 -1599 are missing. The sender knows that this range includes packets 3 and 4 and is able to infer that packet 3 is lost and packet 4 has been received correctly. The sender maintains the information returned in the ACK Window, flushing it only when the window advances. This helps to prevent the unnecessary retransmission of correctly received packets following a timeout when the session enters slow start. ½ TCP-SACK is generally limited by the TCP options field to reporting only three unique segments of continuous data within a window.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¿º¾º¿ Ê ØÖ Ò×Ñ ×× ÓÒ ÈÓÐ Ý</head><p>Our retransmission strategy is motivated by such evidence as the Internet trace reports by Lin and Kung, which show that 85% of TCP timeouts are due to "non-trigger" <ref type="bibr" target="#b11">[12]</ref>. Non-trigger occurs when a packet is retransmitted by the sender without previous attempts, i.e., when three duplicate ACKs fail to arrive at the sender and therefore TCP's fast retransmission mechanism never happens. In this case, no retransmissions can occur until there is a timeout at the source. Therefore, a mechanism to quickly recover losses without necessarily waiting for three duplicate ACKs from the receiver is needed.</p><p>Given that TCP Santa Cruz has a much tighter estimate of the RTT time per packet and that the TCP Santa Cruz sender receives precise information on each packet correctly received (via the ACK Window), TCP Santa Cruz can determine when a packet has been dropped without waiting for TCP's Fast Retransmit algorithm. TCP Santa Cruz can quickly retransmit and recover a lost packet once any ACK for a subsequently transmitted packet is 'received and a time constraint is met. Any lost packet Ý, initially transmitted at time Ø is marked as a hole in the ACK window. Packet Ý can be retransmitted once the following constraint is met: as soon as an ACK arrives for any packet transmitted at time ØÜ (where ØÜ Ø ), and Ø ÙÖÖ ÒØ Ø Ê Ì Ì , where Ø ÙÖÖ ÒØ is the current time and ÊÌÌ is the estimated round-trip time of the connection. Therefore, any packet marked as unreceived in the ACK window can be a candidate for early retransmission. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¿º¿ ÈÖÓÔÓ× ÁÑÔÐ Ñ ÒØ Ø ÓÒ</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>È Ö ÓÖÑ Ò Ê ×ÙÐØ×</head><p>In this section we examine the performance of TCP Santa Cruz compared to TCP Vegas <ref type="bibr" target="#b2">[3]</ref> and TCP Reno <ref type="bibr" target="#b18">[19]</ref>. We first show performance results for a basic configuration with a single source and a bottleneck link, then a single source with cross-traffic on the reverse path, and finally performance over asymmetric links. We have measured performance for TCP Santa Cruz through simulations using the "ns" network simulator <ref type="bibr" target="#b15">[16]</ref>. The simulator contains implementations of TCP Reno and TCP Vegas. TCP Santa Cruz was implemented by modifying the existing TCP-Reno source code to include the new congestion avoidance and error-recovery schemes. Unless stated otherwise, data packets are of size 1Kbyte, the maximum window size, ÛÒ Ñ Ü for every TCP connection is 64 packets and the initial ssthresh is equal to ½ ¾ £ ÛÒ Ñ Ü. All simulations are an FTP transfer with a source that always has data to send; simulations are run for 10 seconds. In addition, the TCP clock granularity is ½¼¼Ñ× for all protocols.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>º½ × ÓØØÐ Ò ÓÒ¬ ÙÖ Ø ÓÒ</head><p>Our first experiment shows protocol performance over a simple network, depicted in Figure <ref type="figure" target="#fig_5">7</ref>, consisting of a TCP source sending 1Kbyte data packets to a receiver via two intermediate routers connected by a 1.5Mbps bottleneck link. The bandwidth delay product (BWDP) of this configuration is equal to 16.3Kbytes; therefore, in order to accommodate one windowful of data, the routers are set to hold 17 packets.  show the growth of TCP Reno's congestion window and the queue buildup at the bottleneck link. Once the congestion window grows beyond 17 packets (the BWDP of the connection) the bit pipe is full and the queue begins to fill. The routers begin to drop packets once the queue is full; eventually Reno notices the loss, retransmits, and cuts the congestion window in half. This produces see-saw oscillations in both the window size and the bottleneck queue length. These oscillations greatly increase not only delay, but also delay variance for the application. It is increasingly important for real-time and interactive applications to keep delay and delay variance to a minimum.</p><p>In contrast, Figures <ref type="figure" target="#fig_6">9 (a</ref>) and (b) show the evolution of the sender's congestion window and the queue buildup at the bottleneck for TCP Santa Cruz. These figures demonstrate the main strength of TCP Santa Cruz: adaptation of the congestion control algorithm to transmit at the bandwidth of the connection without congesting the network and without overflowing the bottleneck queues. In this example the threshold value of AEÓÔ, the desired additional number of packets in the network beyond the BWDP, is set to AEÓÔ ½ . Figure <ref type="figure" target="#fig_6">9</ref>(b) shows the queue length at the bottleneck link for TCP Santa Cruz reaches a steady-state value between 1 and 2 packets. We also see that the congestion window, depicted in Figure <ref type="figure" target="#fig_6">9</ref>(a) reaches a peak value of 18 packets, which is the sum of the BWDP (16.5) and AEÓÔ. The algorithm maintains this steady-state value for the duration of the connection.</p><p>Table <ref type="table" target="#tab_3">2</ref> compares the throughput, average delay and delay variance for Reno, Vegas and Santa Cruz. For TCP Santa Cruz we vary the amount of queueing tolerated in the network from AEÓÔ = 1 to 5 packets. All protocols achieve similar throughput, with Santa Cruz Ò performing slightly better than Reno. The reason Reno's throughput does not suffer is that most of the time the congestion window is well above the BWDP of the network so that packets are always queued up at the bottleneck and therefore available for transmission. What does suffer, however, is the delay experienced by packets transmitted through the network.</p><p>The minimum forward delay through the network is equal to 40 msec propagation delay plus 6.9 msec packet forwarding time,  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>º¾ ÌÖ AE ÓÒ Ê Ú Ö× Ä Ò</head><p>This section looks at how data flow on the forward path is affected by traffic and congestion on the reverse path. Figure <ref type="figure" target="#fig_7">10</ref> shows that, in addition to a TCP source from A to the Receiver, there is also a TCP Reno source from B to Router 1 in order to cause congestion on the reverse link. Figure <ref type="figure" target="#fig_8">11</ref> (a) shows that the congestion window growth for Reno source A is considerably slower compared to the case when no reverse traffic is present in Figure <ref type="figure">8(a)</ref>. Because Reno grows its window based on ACK counting, lost and delayed ACKs on the reverse path prevent Source A from filling the bit pipe as fast as it could normally do, resulting in low link utilization on the forward path. In addition, ACK losses also delay the detection of packet losses at the source, which is waiting for three duplicate ACKs to perform a retransmission. In contrast, Figure <ref type="figure" target="#fig_8">11</ref> (b) shows that the congestion window for TCP Santa Cruz (AEÓÔ = 5) is relatively unaffected by the Reno traffic on the reverse path and reaches the optimal window size of around 22 packets, demonstrating TCP Santa Cruz's ability to maintain a full data pipe along the forward path in the presence of congestion on the reverse path. Table <ref type="table" target="#tab_4">3</ref> shows the throughput and delay obtained for Reno, Santa Cruz and Vegas. Santa Cruz achieves up to a 68% improvement in throughput compared to Reno and a 78% improvement over Vegas. Because of the nearly constant window size, the variation delay with our algorithm is considerably lower than Reno. Vegas suffers from low throughput in this case because its algorithm is unable to maintain a good throughput estimate because of high variation in RTT measurements. Vegas exhibits low delay primarily due to its low utilization of the bottleneck link; this insures that packets are never queued at the bottleneck and therefore do not incur any additional queueing delay from source to destination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>º¿ ×ÝÑÑ ØÖ Ä Ò ×</head><p>In this section we investigate performance over networks that exhibit asymmetry, e.g., ADSL, HFC or combination networks, which  may have a high bandwidth cable downstream link and a slower telephone upstream link. TCP has been shown to perform poorly over asymmetric links <ref type="bibr" target="#b10">[11]</ref> primarily because of ACK loss, which causes burstiness at the source (the size of the bursts are proportional to the degree of asymmetry) and leads to buffer overflow along the higher bandwidth forward path; and also reduced throughput because of slow window growth at the source due to lost ACK packets. Lakshman et. al. <ref type="bibr" target="#b10">[11]</ref> define the normalized asymmetry of a path as the ratio of the transmission capacity of data packets on the forward path to ACK packets on the reverse path. This is an important measurement because it means the source puts out times as many data packets as the reverse link has capacity. Once the queues in the reverse path fill, only one ACK out of will make it back to the receiver. Each ACK that does arrive at the source then generates a burst of packets in the forward path. In addition, during congestion avoidance, the window growth will be slowed by ½ as compared to a symmetric connection.</p><p>Source Receiver 24Mbps, 3msec 320Kbps, 1msec</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 12. Simulation configuration for asymmetric links</head><p>The simulation configuration depicted in Figure <ref type="figure" target="#fig_0">12</ref> has been studied by Lakshman et. al. in detail and is used here to examine performance. In this configuration the forward buffer, 9 packets. Using 1 Kbyte data packets this results in a normalized asymmetry factor ¿ .</p><p>Figure <ref type="figure" target="#fig_9">13</ref> (a) shows the congestion window growth for Reno. Because of the burstiness of the connection due to ACK loss, there are several lost data packets per window of data, causing Reno to suffer timeouts every cycle (that is why the congestion window reduces to 1 packet). Figure <ref type="figure" target="#fig_9">13 (b)</ref> shows the development of the window with TCP Santa Cruz. In this case, the congestion window settles a few packets above the BWDP (equal to 31 packets) of the connection. ¾ During slow start there is an initial overshoot of the window size during one round-trip time delay, i.e., the final round before the algorithm picks up the growing queue, a burst of packets is sent, which ultimately overflows the buffer.</p><p>A comparison of the overall throughput and delay obtained by a Reno, Vegas and Santa Cruz (AEÓÔ ½ , AEÓÔ ¿ and AEÓÔ ) sources is shown below in Table <ref type="table" target="#tab_5">4</ref>. This table shows that Reno and Vegas are unable to achieve link utilization above 52%. Because of the burstiness of the data traffic, Santa Cruz needs an operating point of at least AEÓÔ ¿ in order to achieve high throughput. For AEÓÔ ¿ and AEÓÔ Santa Cruz is able to achieve 99% link utilization. The end-to-end delays for Reno are around twice that of Santa Cruz and the delay variance is seven orders of magnitude greater than Santa Cruz. Because Vegas has such low link utilization the queues are generally empty, thus there is a very low delay and no appreciable delay variance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ÓÒ ÐÙ× ÓÒ</head><p>We have presented TCP Santa Cruz, which implements a new approach to end-to-end congestion control and reliability, and that can be implemented as a TCP option. TCP Santa Cruz makes use of a simple timestamp returned from the receiver to estimate the level of queueing in the bottleneck link of a connection. The protocol successfully isolates the forward throughput of the connection from events on the reverse link by considering the changes in delay along the forward link only. We successfully decouple the growth of the congestion window from the number of returned ACKs (the approach taken by TCP), which makes the protocol resilient to ACK loss. The protocol provides quick and efficient error-recovery by identifying losses via an ACK window without waiting for three ¾ See Lakshman et. al. <ref type="bibr" target="#b10">[11]</ref> for a detailed analysis of the calculation of the BWDP. Simulation results show that TCP Santa Cruz provides high throughput and low end-to-end delay and delay variance over networks with a simple bottleneck link, networks with congestion in the reverse path of the connection, and networks which exhibit path asymmetry. We have shown that TCP Santa Cruz eliminates the oscillations in the congestion window, but still maintains high link utilization. As a result, it provides much lower delays than current TCP implementations. For the simple bottleneck configuration our protocol provides a 20% -45% improvement in end-to-end delay (depending on the value of AEÓÔ) and a delay variance three orders of magnitude lower than Reno. For experiments with congestion on the reverse path, TCP Santa Cruz provides an improvement in throughput of at least 47% -67% over both Reno and Vegas, as well as an improvement in end-to-end delay of 45% -59% over Reno with a reduction in delay variance of three orders of magnitude. When we examine networks with path asymmetry, Reno and Vegas achieve link utilization of only 52% and 33%, respectively, whereas Santa Cruz achieves 99% utilization. End-to-end delays for this configuration are also reduced by 42% -58% over Reno.</p><p>Our simulation experiments indicate that our end-to-end approach to congestion control and error recovery is very promising, and our current work focuses on evaluating the fairness of TCP Santa Cruz, its coexistence with other TCP implementations, and its performance over wireless networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>º Ê Ö Ò ×</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Transmission of 2 packets and corresponding relative delay measurements</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 3(c)  shows that the second packet has been delayed with respect to the first one when</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .Figure 4 .</head><label>34</label><figDesc>Figure 3. FORWARD PATH: (a)Equal delay (b)1st packet delayed (c)2nd packet delayed (d)non-FIFO arrival of packets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Bottleneck Link: Delay consists of two parts: É , the delay due to queueing and Ô ØË, the packet service time over the link.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. ACK window transmitted from receiver to sender. Packets 1, 3 and 5 are lost.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Basic bottleneck configurationFigures8 (a) and (b) show the growth of TCP Reno's congestion window and the queue buildup at the bottleneck link. Once the congestion window grows beyond 17 packets (the BWDP of the connection) the bit pipe is full and the queue begins to fill. The routers begin to drop packets once the queue is full; eventually Reno notices the loss, retransmits, and cuts the congestion window in half. This produces see-saw oscillations in both the window size and the bottleneck queue length. These oscillations greatly increase not only delay, but also delay variance for the application. It is increasingly important for real-time and interactive applications to keep delay and delay variance to a minimum.In contrast, Figures9 (a) and (b) show the evolution of the sender's congestion window and the queue buildup at the bottleneck for TCP Santa Cruz. These figures demonstrate the main strength of TCP Santa Cruz: adaptation of the congestion control algorithm to transmit at the bandwidth of the connection without congesting the network and without overflowing the bottleneck queues. In this</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 .</head><label>9</label><figDesc>Figure 8. TCP Reno: (a) congestion window (b) bottleneck queue</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. Traffic on the reverse link</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. Comparison of congestion window growth when TCP-Reno traffic is present on the reverse path: (a) Reno (b) TCP Santa Cruz n=5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 13 .</head><label>13</label><figDesc>Figure 13. Comparison of congestion window growth: (a) Reno (b) TCP Santa Cruz</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . TCP Santa Cruz options field description</head><label>1</label><figDesc>TCP Santa Cruz can be implemented as a TCP option containing the fields depicted in Table1. The TCP Santa Cruz option can vary in size from 11 to 40 bytes, depending on the size of the ACK window (see Section 3.2.2).</figDesc><table><row><cell>Field</cell><cell>Size</cell><cell>Description</cell></row><row><cell></cell><cell>(bytes)</cell><cell></cell></row><row><cell>Kind</cell><cell>1</cell><cell>kind of protocol</cell></row><row><cell>Length</cell><cell>1</cell><cell>length field</cell></row><row><cell>Data.copy</cell><cell>4 (bits)</cell><cell>retrans. number of data pkt</cell></row><row><cell>ACK.copy</cell><cell>4 (bits)</cell><cell>retrans. number of data pkt gen. ACK</cell></row><row><cell>ACK.sn</cell><cell>4</cell><cell>SN of data pkt generating ACK</cell></row><row><cell>Timestamp</cell><cell>4</cell><cell>arr. time of data pkt generating ACK</cell></row><row><cell>ACK Window Granularity</cell><cell>1</cell><cell>num. bytes represented by each bit</cell></row><row><cell>ACK Window</cell><cell>0 -18</cell><cell>holes in the receive stream</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>) bottleneck queue yielding</head><label></label><figDesc>a total minimum forward delay of approximately 47 msec. Reno is the clear loser in this case with not only the highest average delay, but also a high delay variation. Santa Cruz with AEÓÔ ½ provides the same average delay as Vegas, but a with lower delay deviation. As AEÓÔ increases, the delay in Santa Cruz also increases because more packets are allowed to sit in the bottleneck queue. Also, throughput is seen to grow with AEÓÔ because not only does the ×ÐÓÛ×Ø ÖØ period last longer, but the peak window size is reached earlier in the connection, leading to a faster transmission rate earlier in the transfer. In addition, with a larger AEÓÔ it is more likely that a packet is available in the queue awaiting transmission.</figDesc><table><row><cell></cell><cell cols="3">Comparison of Throughput and Average Delay</cell><cell></cell></row><row><cell>Protocol</cell><cell>Throughput</cell><cell>Utilization</cell><cell>Ave. delay</cell><cell>Delay variance</cell></row><row><cell></cell><cell>(Mbps)</cell><cell></cell><cell>(msec)</cell><cell>(msec)</cell></row><row><cell>Reno</cell><cell>1.45</cell><cell>0.97</cell><cell>99.4</cell><cell>2.06</cell></row><row><cell>SC n=1.5</cell><cell>1.42</cell><cell>0.94</cell><cell>55.1</cell><cell>0.0041</cell></row><row><cell>SC n=3</cell><cell>1.45</cell><cell>0.97</cell><cell>60.6</cell><cell>0.0063</cell></row><row><cell>SC n=5</cell><cell>1.47</cell><cell>0.98</cell><cell>79.2</cell><cell>0.0073</cell></row><row><cell>Vegas (1,3)</cell><cell>1.40</cell><cell>0.94</cell><cell>55.2</cell><cell>0.0077</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 . Throughput, delay and delay variance compar- isons for Reno, Vegas and Santa Cruz for basic bottle- neck configuration.</head><label>2</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 . Throughput, delay and delay variance compar- isons with traffic on the reverse link.</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell cols="3">Comparison of Throughput and Average Delay</cell><cell></cell></row><row><cell>Protocol</cell><cell>Throughput</cell><cell>Utilization</cell><cell>Ave. delay</cell><cell>Delay variance</cell></row><row><cell></cell><cell>(Mbps)</cell><cell></cell><cell>(msec)</cell><cell>(msec)</cell></row><row><cell>Reno</cell><cell>0.823</cell><cell>0.55</cell><cell>134.3</cell><cell>56.2</cell></row><row><cell>SC n=1.5</cell><cell>1.213</cell><cell>0.81</cell><cell>54.8</cell><cell>0.0034</cell></row><row><cell>SC n=3</cell><cell>1.312</cell><cell>0.87</cell><cell>60.6</cell><cell>0.0057</cell></row><row><cell>SC n=5</cell><cell>1.390</cell><cell>0.92</cell><cell>73.4</cell><cell>0.0080</cell></row><row><cell>Vegas (1,3)</cell><cell>0.778</cell><cell>0.52</cell><cell>49.5</cell><cell>0.0016</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 . Throughput, delay and delay variance over asymmetric links.</head><label>4</label><figDesc></figDesc><table><row><cell></cell><cell cols="3">Comparison of Throughput and Average Delay</cell><cell></cell></row><row><cell>Protocol</cell><cell>Throughput</cell><cell>Utilization</cell><cell>Ave. delay</cell><cell>Delay variance</cell></row><row><cell></cell><cell>(Mbps)</cell><cell></cell><cell>(msec)</cell><cell>( sec)</cell></row><row><cell>Reno</cell><cell>1.253</cell><cell>0.52</cell><cell>8.4</cell><cell>1400</cell></row><row><cell>SC n=1.5</cell><cell>1.275</cell><cell>0.53</cell><cell>3.5</cell><cell>0.0004</cell></row><row><cell>SC n=3</cell><cell>23.72</cell><cell>0.99</cell><cell>4.6</cell><cell>0.0003</cell></row><row><cell>SC n=5</cell><cell>23.73</cell><cell>0.99</cell><cell>4.8</cell><cell>0.0003</cell></row><row><cell>Vegas (1,3)</cell><cell>0.799</cell><cell>0.33</cell><cell>3.3</cell><cell>0.0000</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Improving reliable transport and handoff performance in cellular wireless networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Seshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Katz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995-12">Dec. 1995</date>
			<publisher>ACM Wireless Networks</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">TCP Vegas: New techniques for congestion detection and avoidance</title>
		<author>
			<persName><forename type="first">L</forename><surname>Brakmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>O'malley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCOMM&apos;94</title>
		<meeting>SIGCOMM&apos;94<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1994-08">Aug./Sept. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">TCP Vegas: End-to-end congestion avoidance on a global internet</title>
		<author>
			<persName><forename type="first">L</forename><surname>Brakmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Journal of Selected Areas in Communication</title>
		<imprint>
			<date type="published" when="1995-10">October, 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">NETBLT: A high throughput transfer protocol</title>
		<author>
			<persName><forename type="first">D</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCOMM</title>
		<meeting>SIGCOMM<address><addrLine>Stowe, Vermont</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1987-08">Aug. 1987</date>
			<biblScope unit="page" from="353" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Simulation-based comparisons of tahoe,reno, and SACK TCP</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Floyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Communication Review</title>
		<imprint>
			<date type="published" when="1996-07">July, 1996</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="5" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Random Early Detection gateways for congestion avoidance</title>
		<author>
			<persName><forename type="first">S</forename><surname>Floyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jacobson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Networking</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="397" to="413" />
			<date type="published" when="1993-08">Aug 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Rfc 1323 TCP extensions for high performance</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Braden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Borman</surname></persName>
		</author>
		<idno>1323</idno>
		<imprint>
			<date type="published" when="1992-05">May 1992</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">TCP and explicit congestion notification</title>
		<author>
			<persName><forename type="first">V</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Floyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Communication Review</title>
		<imprint>
			<date type="published" when="1994-10">October, 1994</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="8" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving round-trip time estimates in reliable transport protocols</title>
		<author>
			<persName><forename type="first">P</forename><surname>Karn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Partridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2" to="7" />
			<date type="published" when="1987-08">August 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Packet-pair flow control</title>
		<author>
			<persName><forename type="first">S</forename><surname>Keshav</surname></persName>
		</author>
		<ptr target="http://www.cs.cornell.edu/skeshav/papers.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Window-based error recovery and flow control with a slow acknowledgement channel: a study of TCP/IP performance</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lakshman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Madhow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Suter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE INFOCOM &apos;97</title>
		<meeting>IEEE INFOCOM &apos;97</meeting>
		<imprint>
			<date type="published" when="1997-04">Apr 1997</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1199" to="1209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">TCP fast recovery strategies: Analysis and improvements</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE INFOCOM &apos;98</title>
		<meeting>IEEE INFOCOM &apos;98</meeting>
		<imprint>
			<date type="published" when="1998-04">Apr. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Explicit window adaptation: a method to enhance TCP performance</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kalampoukas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE INFOCOM &apos;98</title>
		<meeting>IEEE INFOCOM &apos;98</meeting>
		<imprint>
			<date type="published" when="1998-04">Apr. 1998</date>
			<biblScope unit="page" from="242" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Forward acknowledgment: Refining TCP congestion control</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mathis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mahdavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCOMM&apos;96</title>
		<meeting>SIGCOMM&apos;96<address><addrLine>Stanford, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-09">Sept. 1996</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">TCP selective acknowledgment options</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mathis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mahdavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Floyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romanow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996-10">Oct. 1996. RFC 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Mccanne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Floyd</surname></persName>
		</author>
		<ptr target="http://www-nrg.ee.lbl.gov/ns/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving TCP performance over wireless networks at the link layer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Parsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Garcia-Luna-Aceves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Mobile Networks and Applications Journal</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Explicit loss indication and accurate RTO estimation for TCP error recovery using satellite links</title>
		<author>
			<persName><forename type="first">N</forename><surname>Samaraweera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fairhurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEE Proceedings -Communications</title>
		<imprint>
			<date type="published" when="1997-02">Feb., 1997</date>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page" from="47" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">TCP/IP Illustrated</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Stevens</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Addison-Wesley</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Total acknowledgements: a robust feedback mechanism for end-to-end congestion control</title>
		<author>
			<persName><forename type="first">J</forename><surname>Waldby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Madhow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lakshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sigmetrics &apos;98 Performance Evaluation Review</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Eliminating periodic packet losses in the 4.3-Tahoe BSD TCP congestion control algorithm</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Crowcroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Communication Review</title>
		<imprint>
			<date type="published" when="1992-04">April, 1992</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A new congestion control scheme: Slow start and search (Tri-S)</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Crowcroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="43" />
			<date type="published" when="1991-01">Jan., 1991</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
