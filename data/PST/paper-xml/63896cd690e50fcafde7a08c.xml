<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CL4CTR: A Contrastive Learning Framework for CTR Prediction</title>
				<funder ref="#_MBaDhCn #_QkqCwVp">
					<orgName type="full">National Natural Science Foundation of China</orgName>
					<orgName type="abbreviated">NSFC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-12-01">1 Dec 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fangye</forename><surname>Wang</surname></persName>
							<email>fywang18@fudan.edu.cn</email>
							<affiliation key="aff7">
								<orgName type="department">Also Shanghai Key Laboratory of Data Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yingxu</forename><surname>Wang</surname></persName>
							<email>yingxuwang20@fudan.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
							<affiliation key="aff7">
								<orgName type="department">Also Shanghai Key Laboratory of Data Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hansu</forename><surname>Gu</surname></persName>
							<email>hansug@acm.org</email>
						</author>
						<author>
							<persName><forename type="first">Tun</forename><surname>Lu</surname></persName>
							<email>lutun@fudan.edu.cn</email>
							<affiliation key="aff7">
								<orgName type="department">Also Shanghai Key Laboratory of Data Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
							<email>zhangpeng_@fudan.edu.cn</email>
							<affiliation key="aff7">
								<orgName type="department">Also Shanghai Key Laboratory of Data Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ning</forename><surname>Gu</surname></persName>
							<email>ninggu@fudan.edu.cn</email>
							<affiliation key="aff7">
								<orgName type="department">Also Shanghai Key Laboratory of Data Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research Asia Shanghai</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<address>
									<settlement>Seattle</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CL4CTR: A Contrastive Learning Framework for CTR Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-12-01">1 Dec 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3539597.3570372</idno>
					<idno type="arXiv">arXiv:2212.00522v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Contrastive Learning</term>
					<term>Representation Learning</term>
					<term>CTR Prediction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many Click-Through Rate (CTR) prediction works focused on designing advanced architectures to model complex feature interactions but neglected the importance of feature representation learning, e.g., adopting a plain embedding layer for each feature, which results in sub-optimal feature representations and thus inferior CTR prediction performance. For instance, low frequency features, which account for the majority of features in many CTR tasks, are less considered in standard supervised learning settings, leading to sub-optimal feature representations. In this paper, we introduce self-supervised learning to produce high-quality feature representations directly and propose a model-agnostic Contrastive Learning for CTR (CL4CTR) framework consisting of three selfsupervised learning signals to regularize the feature representation learning: contrastive loss, feature alignment, and field uniformity. The contrastive module first constructs positive feature pairs by data augmentation and then minimizes the distance between the representations of each positive feature pair by the contrastive loss. The feature alignment constraint forces the representations of features from the same field to be close, and the field uniformity constraint forces the representations of features from different fields to be distant. Extensive experiments verify that CL4CTR achieves the best performance on four datasets and has excellent effectiveness and compatibility with various representative baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>? Information systems ? Recommender systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>CTR prediction <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b42">43]</ref>, aiming to predict the probability of a given item being clicked, has been widely used in many applications, e.g., recommender systems <ref type="bibr" target="#b3">[4]</ref> and computational advertising <ref type="bibr" target="#b17">[18]</ref>. Recently, many methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b32">33]</ref> achieved huge success by modeling complex feature interactions (FI). Following recent works <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b32">33]</ref>, we categorize CTR prediction methods into two types: (1) traditional methods, such as logistic regression (LR) <ref type="bibr" target="#b26">[27]</ref> and FM-based models <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b25">26]</ref>, can only model low-order feature interactions; and (2) deep-learning based methods, such as xDeepFM <ref type="bibr" target="#b16">[17]</ref> and DCN-V2 <ref type="bibr" target="#b34">[35]</ref>, can further enhance the accuracy of CTR prediction by capturing high-order FI. In addition, many novel architectures (e.g., self-attention <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b27">28]</ref>, CIN <ref type="bibr" target="#b16">[17]</ref>, PIN <ref type="bibr" target="#b24">[25]</ref>) have been proposed and widely deployed to capture sophisticated arbitrary-order FI.</p><p>Although successful in performance, many existing CTR prediction methods suffer from an inherent problem: high frequency features have higher chances to be trained than low frequency features, causing the representations of low frequency features to be sub-optimal. In Figure <ref type="figure" target="#fig_0">1</ref>, we present the feature cumulative distributions of Frappe and ML-tag datasets. We can observe a clear "long tail" distribution of feature frequencies, e.g., bottom 80% of features appeared only 38 times or less in the ML-tag dataset. Since most CTR prediction models learn feature representations by the backpropagation <ref type="bibr" target="#b42">[43]</ref>, the low frequency features cannot be sufficiently trained due to less appearance, resulting in sub-optimal feature representations and thus sub-optimal CTR prediction performance.</p><p>Several prior works <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b41">42]</ref> have also realized the importance of feature representation learning and proposed to deploy a weight learning module (i.e., FEN <ref type="bibr" target="#b41">[42]</ref>, Dual-FEN <ref type="bibr" target="#b18">[19]</ref>) after the embedding layer which assigns weights for each feature to enhance their representations. However, the additional weighting modules will increase the model parameters and inference time. In addition, similar to FI-based methods, these methods only use the supervised learning signals to optimize feature representations from the plain embedding layer, which is not strong enough to produce accurate feature representations. Therefore, in this paper, we focus on directly learning accurate feature representations from the embedding layer without introducing additional weighting mechanisms, which is model-agnostic and has not been extensively studied.</p><p>In this paper, we seek to utilize self-supervised learning (SSL) to address the above issue, in which we design self-supervised learning signals as constraints to regularize the learned feature representations during the training process. As shown in Figure <ref type="figure">2</ref>, we propose a novel framework called Contrastive Learning for Click Through Rate Prediction (CL4CTR), which consists of three key modules: CTR prediction model, contrastive module, and align-ment&amp;uniformity constraints. In detail, the CTR prediction model aims to predict the probability of items being clicked by a user, which can be replaced with most existing CTR models in the CL4CTR framework. In the contrastive module, we design three key components: (1) a data augmentation unit aiming to generate two different views for the output embedding as positive training pairs, which includes three different permutation approaches: random mask, feature mask, and dimension mask; (2) a feature interaction encoder aiming to learn compact FI representations based on the perturbed embeddings from the data augmentation unit; and (3) a task-oriented contrastive loss, which is designed to minimize the distance between the positive training pairs. In addition, we introduce two constraints: feature alignment and field uniformity, to facilitate contrastive learning. Feature alignment forces the representations of features from the same field to be as close as possible, and field uniformity forces the representations of features from different fields to be as distant as possible.</p><p>Our major contributions are summarized as follows:</p><p>? We propose a model-agnostic contrastive learning framework -CL4CTR, which can directly improve the quality of feature representations in an end-to-end manner. ? Considering the unique characteristics of CTR prediction tasks, we design three self-supervised learning signals: contrastive loss, feature alignment constraint and field uniformity constraint to improve contrastive learning performance.</p><p>? Extensive experiments on four datasets demonstrate that simply applying CL4CTR into FM <ref type="bibr" target="#b25">[26]</ref> can outperform stateof-the-art methods. More importantly, CL4CTR shows high compatibility with existing methods, i.e., it can generally improve the performance of many representative baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Deep CTR Prediction</head><p>According to the main focuses, recent CTR prediction works can be divided into two categories: FI-based methods <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b42">43]</ref> and user interests modeling based methods <ref type="bibr" target="#b23">[24]</ref>. Since our CL4CTR framework can be generally applied in FI-based models, we briefly summarize the FI-based works in this section. Most FI-based CTR prediction methods follow the common design paradigm: embedding layer, FI layer, and prediction layer. Some classical methods can only model fixed-order or low-order feature interactions. For instance, FM-based methods <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b25">26]</ref> model all pairwise interactions by using factorized parameters. Due to the importance of FI in the CTR prediction, many works focus on how to design novel structures for the FI layer to capture more informative and complicated feature interactions. Wide&amp;Deep (WDL) <ref type="bibr" target="#b3">[4]</ref> jointly trains the wide linear unit and Deep Neural Network (DNN) to combine memorization and generalization. DeepFM <ref type="bibr" target="#b6">[7]</ref> comprises DNN and FM, and xDeepFM <ref type="bibr" target="#b16">[17]</ref> additional proposes Compressed Interaction Network (CIN) based DeepFM to model high-order feature interaction explicitly. DCN <ref type="bibr" target="#b33">[34]</ref> and DCN-V2 <ref type="bibr" target="#b34">[35]</ref> explicitly and automatically use a cross-vector/cross-matrix network to improve the accuracy and efficiency of the DNN model. Furthermore, attention mechanism is one of the most effective structure to improve the performance and has been widely adopted for different purposes, e.g., AFM <ref type="bibr" target="#b38">[39]</ref>, Autoint <ref type="bibr" target="#b27">[28]</ref>, InterCTR <ref type="bibr" target="#b15">[16]</ref>, DCAP <ref type="bibr" target="#b2">[3]</ref>. Notably, some works <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b41">42]</ref> attempt to improve the performance of CTR prediction by assigning different weights for features, in which they deploy a weight learning module to adjust the importance of feature representations after the embedding layer. However, these additional weighting modules may increase the model parameters and inference time. More importantly, these works only learn feature representations from a plain embedding layer, which is not strong enough to produce accurate feature representations as demonstrated in our experiments. The proposed CL4CTR can directly improve the quality of feature representations without requiring any additional modules after the embedding layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Self-supervised Learning</head><p>Recently, self-supervised learning has achieved remarkable success in learning powerful representations in many machine learning tasks <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b39">40]</ref>. Contrastive Learning is one of the mainstream methods in SSL, which learns representations by attracting the positive sample pairs and repulsing the negative sample pairs <ref type="bibr" target="#b7">[8]</ref>. Wang and Isola <ref type="bibr" target="#b35">[36]</ref> identify two key properties related to the success of contrastive learning, i.e., alignment and uniformity. Alignment favors encoders that assign similar features to similar samples. Uniformity prefers a feature distribution that preserves maximal information.</p><p>In CTR prediction tasks, contrastive learning has not been extensively studied. Guo et al. <ref type="bibr" target="#b7">[8]</ref> focus on sequential-based CTR tasks, which apply interest-level contrastive losses to enhance feature embeddings. Pan et al. <ref type="bibr" target="#b22">[23]</ref> propose an auxiliary AQCL loss that automatically leverages instance-instance similarity and instancecluster similarity to regularize feature representations under the cold-start scenarios. Unlike them, our CL4CTR focuses on FI-based CTR prediction models, which can enhance the quality of feature representations by designing three SSL signals: contrastive loss, feature alignment constraint, and field uniformity constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE CL4CTR FRAMEWORK 3.1 CTR Prediction</head><p>CTR prediction is a binary classification task <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b32">33]</ref>. Suppose a dataset for training CTR prediction model contains ? instances (x, ?), where ? ? {0, 1} (click or not) is the true label indicating user's click behaviors. Input instance x is usually multi-field tabular data record <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b19">20]</ref>, which contains ? different fields and ? features, as shown in Table <ref type="table" target="#tab_0">1</ref>. Recently, as shown in Figure <ref type="figure">2</ref>(a), many CTR prediction models follow the common design paradigm <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b36">37]</ref>: embedding layer, FI layer, and prediction layer.</p><p>Embedding layer. Generally, each input instance x ? is a sparse high-dimensional vector represented by a one-hot vector <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b32">33]</ref>. And embedding layer transforms the sparse high-dimensional features x ? into a dense low-dimensional embedding matrix E = [e 1 ; e 2 ; ...; e ? ] ? R ? ?? , where ? is the dimension size. Additionally, we use E = [E 1 , E 2 , ..., E ? ] ? R ??? to represent all feature representations, where E ? is the subset representation of the ? -th field ? ? {1, 2, ..., ? }. |E ? | is the number of features belonging to field ? , and ? = ? ? =1 |E ? |. Feature interaction layer. The FI layer usually contains various types of interaction operations to capture arbitrary-order feature interactions, such as MLP <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b6">7]</ref>, Cross Network <ref type="bibr" target="#b33">[34]</ref>, Cross Network2 <ref type="bibr" target="#b34">[35]</ref> and transformer layer <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b27">28]</ref>, etc. We refer to these structures as feature interaction encoders, represented by ? ? (?).</p><p>? ? (?) can generate a compact feature interaction representation h ? based on embedding matrix E.</p><p>Prediction layer. Finally, a prediction layer (usually a linear regression or MLP module) produces the final prediction probability ? ( ?? ) ? [0, 1] based on the compact representations h ? from the FI layer, where ? (?) = 1/(1 + exp(-?)) is the sigmoid function.</p><p>Finally, with the predicted label ?? and the true label ? ? , the commonly adopted loss function of CTR models is as follows:</p><formula xml:id="formula_0">L ??? = -1 ? ? ?=1 (? ? log (? (? ? )) + (1 -? ? ) log (1 -? (? ? ))) . (1)</formula><p>Contrastive learning. As shown in Figure <ref type="figure">2</ref>, in addition to the above components, we propose three contrastive learning signals: contrastive loss, feature alignment constraint and field uniformity constraint on top of the embedding layer to regularize the representation learning. Since these signals are not necessary during model inference, our method will not increase the inference time and the parameters of the underlying CTR prediction models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Contrastive Module</head><p>Inspired by the success of SSL, we seek to deploy contrastive learning in the CTR prediction tasks to generate high-quality feature representations. As illustrated in Figure <ref type="figure">2</ref>(b), the contrastive module consists of three major components: a data augmentation unit, a FI  <ref type="bibr" target="#b40">[41]</ref>. Different and well-designed augmentation approaches have been proposed and used to construct different views of the same input instance. For example, in the scenarios of sequential recommendation, three widely used augmentation methods are item masking, reordering, and cropping <ref type="bibr" target="#b40">[41]</ref>. However, these methods are designed to augment behavior sequences and are not appropriately deployed in FI-based CTR prediction models. Hence, we firstly propose three task-oriented augmentation approaches, which aim to perturb feature embeddings for FI-based models. As shown in Figure <ref type="figure">2</ref>(d), we use the function ? = g(E) to represent data augmentation process. Random Mask. Firstly, we introduce the random mask method, which is analogous to Dropout <ref type="bibr" target="#b10">[11]</ref>. This method randomly masks some elements in initial embedding E with a certain probability p. The random mask is generated as follows:</p><formula xml:id="formula_1">? = g ? (E) = E ? I, I ? Bernoulli(?) ? E ? ?? .<label>(2)</label></formula><p>Bernoulli(?) is the Bernoulli distribution, and I is a matrix of Bernoulli random variables each of which has probability ? of being 1. Feature Mask. Motivated by prior works <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b27">28]</ref>, we propose to mask the feature information in the initial embedding, where the feature mask can be generated as follows:</p><formula xml:id="formula_2">? = g ? (E) = [? 1 ; ?2 ; ...; ?? ], ?? = e ? , ? ? T [mask], ? ? T ,<label>(3)</label></formula><p>where we set a proportion ? of features T = (? 1 , ? 2 , ..., ? ? ? ) with the length ? ? = ?? * ? ?. ? ? is the index of feature in E. If one feature is masked, then the representation of this feature will be replaced with [mask], which is a zero vector. Dimension Mask. The dimensions of feature representations affect the effectiveness of deep learning models. Inspired by FED <ref type="bibr" target="#b43">[44]</ref>, which attempts to improve prediction performance by capturing dimension relations, we propose to perturb the initial embedding by replacing specific of dimensional information of feature representations, which can be described as follows:</p><formula xml:id="formula_3">? = g ? (E) = [?e 1 ; ?e 2 ; ...; ?e ? ], ? ? Bernoulli(?) ? R ? , (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>where ? is a vector of Bernoulli random variables, each of which has a probability ? of being 1.</p><p>During the training process, we select one of the above mask methods to generate two perturbed embedding ?1 and ?2 , where ?1 = g(E) and ?2 = g(E) in Figure <ref type="figure">2(b)</ref>. More analyses about the effectiveness of different mask methods are showed in Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Feature Interaction</head><p>Encoder. We utilize a shared FI encoder to extract feature interaction information from the two perturbed embeddings ?1 and ?2 as follows:</p><formula xml:id="formula_5">? 1 = ? ? ?? ( ?1 ), ? 2 = ? ? ?? ( ?2 ).</formula><p>(</p><formula xml:id="formula_6">)<label>5</label></formula><p>? ? ?? (?) represents FI encoder function, and ? 1 , ? 2 are two compressed representations generated from two perturbed embeddings. Notably, any FI encoder can be deployed in our CL4CTR, such as cross-network <ref type="bibr" target="#b34">[35]</ref>, self-attention <ref type="bibr" target="#b27">[28]</ref>, and bi-interaction <ref type="bibr" target="#b9">[10]</ref>, as described in Section 3.1. Specifically, we select the Transformer layer <ref type="bibr" target="#b29">[30]</ref> as our primary FI encoder, which is widely used to extract vector-level relationships between features <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b39">40]</ref>.</p><p>Additionally, we find that the dimensions of compressed representations (? 1 , ? 2 ) generated by some FI encoders (e.g., cross network <ref type="bibr" target="#b34">[35]</ref>, PIN <ref type="bibr" target="#b24">[25]</ref>) could be huge, e.g., over thousands when field F is large, which produce adversely impacts on the training stability. Hence, we utilize a projection function to reduce the dimensions of representations from FI encoder to D as follows:</p><formula xml:id="formula_7">?1 = ? 1 (? 1 ), ?2 = ? 2 (? 2 ).<label>(6)</label></formula><p>The projection function ? (?) is a single layer MLP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Contrastive Loss Function.</head><p>Finally, a contrastive loss function is applied to minimize the expected distance between the above two perturbed representations as follows:</p><formula xml:id="formula_8">L ?? = 1 ? ? ?=1 ??,1 -??,2 2 2 .<label>(7)</label></formula><p>B is the batch size and || ? || 2 2 denotes the ? 2 distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Feature Alignment and Field Uniformity</head><p>To ensure low frequency features and high-frequency features be trained equally, a naive way is to increase the frequency of low frequency features or reduce the frequency of high-frequency features during training. Inspired by previous works <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b35">36]</ref> in other areas (CV, NLP), which can achieve similar goal by introducing two critical properties, named the alignment and uniformity constraints, but they need to construct positive and negative sample pairs to optimize the two constraints. In CTR prediction tasks, we find that features in the same field are analogous to positive sample pairs, and features of different fields are analogous to negative sample pairs. Thus, we propose two new properties for contrastive learning in CTR prediction, named feature alignment and field uniformity, which can regularize feature representations during training process. Specifically, feature alignment pulls the representations of features from the same field to be as close as possible. In contrast, field uniformity pushes representations of features from different fields to be as distant as possible.</p><p>3.3.1 Feature Alignment. Firstly, we introduce the feature alignment constraint, which aims to minimize the distance between features from the same field. Intuitively, by adding a feature alignment constraint, the representations of features in the same field should be more closely distributed in the low-dimensional space. Formally, the loss function of feature alignment is as follows:</p><formula xml:id="formula_9">L ? = ? ?? ? =1 ?? e i ,e j ?E ? ?e i -e j ? 2 2 ,<label>(8)</label></formula><p>where e i and e j are two features from the same field, and E ? is the subset features of field ? .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Field</head><p>Uniformity. The relationships among different fields have not been extensively studied in existing CTR prediction methods. For instance, FFM <ref type="bibr" target="#b13">[14]</ref> learns field-aware representation for each feature, and NON <ref type="bibr" target="#b19">[20]</ref> extracts intra-field information, but their techniques cannot be directly applied in contrastive learning. Differently, we introduce field uniformity to optimize feature representation directly, which minimizes the similarity between features belonging to different fields. The loss function of field uniformity is formally defined as follows:</p><formula xml:id="formula_10">L ? = ?? e i ?E ? 1&lt;=? &lt;=? ?? e j ? (E-E ? )</formula><p>???(e i , e j ).</p><p>Similar to the other approaches <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b45">46]</ref>, we use cosine similarity to regularize negative sample pairs, i.e., ???(e i , e j ) = e i ? e j /?e i ??e j ?. Other similarity functions can also be used here. E -E ? contains all features except those from field ? .</p><p>In both feature alignment and field uniformity constraints, we find that low frequency features and high frequency features have equal chances to be considered. Therefore, the suboptimal representation issue for low frequency features can be largely alleviated when the two constraints are introduced during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Multi-task Training</head><p>To integrate the CL4CTR framework into the scenarios of CTR prediction, we adopt a multi-task training strategy to jointly optimize these three auxiliary SSL losses and the original CTR prediction loss in an end-to-end manner. Thus the final objective function can be formulated as follows:</p><formula xml:id="formula_12">L ????? = L ??? + ? ? L ?? + ? ? (L ? + L ? ),<label>(10)</label></formula><p>where ? and ? are the hyper-parameters to control the strengths of contrastive loss and feature alignment and field uniformity loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS 4.1 Experimental Setup</head><p>4.1.1 Datasets. We evaluate CL4CTR on four popular datasets:</p><p>Frappe<ref type="foot" target="#foot_0">1</ref> [10], ML-tag<ref type="foot" target="#foot_1">2</ref> [10], SafeDriver<ref type="foot" target="#foot_2">3</ref>  <ref type="bibr" target="#b11">[12]</ref> and ML-1M<ref type="foot" target="#foot_3">4</ref>  <ref type="bibr" target="#b2">[3]</ref>. The statistics of the four datasets are presented in Table <ref type="table" target="#tab_1">2</ref>. NFM <ref type="bibr" target="#b9">[10]</ref> and AFM <ref type="bibr" target="#b38">[39]</ref> have strictly split Frappe and ML-tag to training, validation, and testing by 7:2:1, and we directly follow their settings.</p><p>For SafeDriver and ML-1M, following <ref type="bibr" target="#b11">[12]</ref> and <ref type="bibr" target="#b2">[3]</ref>, we randomly split the instances by 8:1:1. Detailed descriptions of those datasets can be found in the links or references.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Compared Methods.</head><p>To evaluate the proposed CL4CTR framework, we compare its performance with four classes of representative CTR methods <ref type="bibr" target="#b20">[21]</ref>. 1) First-order method that is a weighted sum of raw features, including LR; 2) FM-based methods that consider second-order FI, including FM <ref type="bibr" target="#b25">[26]</ref>, FwFM <ref type="bibr" target="#b21">[22]</ref>, IFM <ref type="bibr" target="#b41">[42]</ref>,</p><p>and FmFM <ref type="bibr" target="#b28">[29]</ref>; 3) Approaches that model higher-order FI, including CrossNet <ref type="bibr" target="#b33">[34]</ref>, IPNN <ref type="bibr" target="#b24">[25]</ref>, OPNN <ref type="bibr" target="#b24">[25]</ref>, FINT <ref type="bibr" target="#b44">[45]</ref>, and DCAP [3]; 4) Ensemble methods or multi-tower structures, including WDL <ref type="bibr" target="#b3">[4]</ref>, DCN <ref type="bibr" target="#b33">[34]</ref>, DeepFM <ref type="bibr" target="#b6">[7]</ref>, xDeepFM <ref type="bibr" target="#b16">[17]</ref>, FiBi-NET <ref type="bibr" target="#b12">[13]</ref>, AutoInt+ <ref type="bibr" target="#b27">[28]</ref>, AFN+ <ref type="bibr" target="#b4">[5]</ref>, TFNET <ref type="bibr" target="#b37">[38]</ref>, FED <ref type="bibr" target="#b43">[44]</ref>, and DCN-V2 <ref type="bibr" target="#b34">[35]</ref>. The proposed CL4CTR framework is model-agnostic.</p><p>For simplicity, a base model M equipped with CL4CTR is represented as ??4?? ? M . We choose FM <ref type="bibr" target="#b25">[26]</ref> as the basic model to verify the effectiveness of CL4CTR, which only models second-order FI and has no additional parameters except for feature representations. Therefore, the performance boost of ??4?? ? ? ? directly reflects the quality of the feature representations. CL4CTR only helps the base CTR models training and does not add any operation or parameter to the inference process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Evaluation Metrics.</head><p>To evaluate the performance of all methods, we adopt the commonly-used AUC (Area Under ROC) and Logloss (cross entropy) as the metrics. Notably, a slightly higher AUC or a lower Logloss at 0.001-level can be considered significant for CTR prediction <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b34">35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Implementation Details.</head><p>For fair comparisons, we implement all the models with Pytorch<ref type="foot" target="#foot_4">5</ref> and optimize all models with Adam. The embedding size is set to 64 for Frappe and ML-tag and 20 for ML-1M and SafeDriver, respectively. Meanwhile, the batch size is fixed to 1024. the learning rate is 0.01 for SafeDriver and 0.001 for other datasets. As for the models including DNN in the prediction layer, we adopt the same structure {400,400,400,1}. All the activation functions are ReLU, and the dropout rate is 0.5. We perform early stopping according to AUC on the validation set to avoid overfitting. We also implement the Reduce-LR-On-Plateau scheduler to reduce the learning rate by a factor of 10 when the given metric stops improving within four continuous epochs. Each experiment is repeated 5 times, and the average results are reported. In CL4CTR, ? ? ?? (?) adopts three transformer layers. And we use hyper-parameters: ?=1, ?=0.01 in the final loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Overall Comparison</head><p>In this section, we compare the performances of ??4?? ? ? ? with the state-of-the-art (SOTA) CTR prediction models. Table <ref type="table" target="#tab_2">3</ref> shows the experimental results of all compared models over four datasets. It can be observed that LR and FM achieve the worst performance compared with other baselines, which indicates that shallow models are insufficient for CTR prediction. Other FM-based models improve FM by introducing field importance mechanism (e.g., FwFM <ref type="bibr" target="#b21">[22]</ref> and IFM <ref type="bibr" target="#b41">[42]</ref>) or deploying a novel field-pair matrix approach (e.g., FmFM <ref type="bibr" target="#b28">[29]</ref>). Generally, deep-learning based models (e.g., DeepFM <ref type="bibr" target="#b6">[7]</ref>, DCN <ref type="bibr" target="#b33">[34]</ref>, DCN-V2 <ref type="bibr" target="#b34">[35]</ref>), which combine highorder feature interactions with well-designed feature interaction structures, achieve better performance than FM.</p><p>??4?? ? ? ? consistently performs better than all baselines on all datasets. Furthermore, ??4?? ? ? ? significantly outperforms the strongest baseline DCN-V2 <ref type="bibr" target="#b34">[35]</ref> by 0.13%, 0.11%, 0.39% and 0.67% in terms of AUC (16.10%, 8.41%, 0.64% and 1.46% in terms of Logloss) on Frappe, ML-tag, ML-1M, and SafeDriver respectively. Additionally, we find that the improvements on Logloss are more remarkable than those on AUC, indicating that CL4CTR enables us to predict the true click probability effectively. Meanwhile, ??4?? ? ? ? shows </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablation Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Compatibility Analysis.</head><p>To verify the compatibility of CL4CTR, we deploy it into other SOTA models, such as DeepFM <ref type="bibr" target="#b6">[7]</ref>, Au-toint+ <ref type="bibr" target="#b27">[28]</ref>, and DCN-V2 <ref type="bibr" target="#b34">[35]</ref>. The results are shown in Table <ref type="table" target="#tab_3">4</ref>. Firstly, learning feature representation with CL4CTR can significantly improve the performance of CTR prediction. Applied with CL4CTR, the performance of base models is remarkably boosted, which confirms our hypothesis of improving the performance of CTR prediction models by improving the quality of the feature representations and demonstrates the effectiveness of CL4CTR. In addition, the experimental results show that learning high-quality feature representations is at least as important as designing advanced FI techniques. Modeling complex feature interactions can improve the performance of CTR models when these models leverage supervised signal for training, which explains why FI-based models outperform FM. However, after introducing self-supervised signals into CTR models for learning high-quality feature representations, FM can achieve the best performance compared with other models deployed with CL4CTR. The possible reason is that both supervised and self-supervised learning are directly and only optimizing the parameters in feature representations in FM without disturbing by other parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Data Augmentation Approaches.</head><p>To verify the effectiveness of our proposed data augmentation methods, we change the augmentation methods in the contrastive module and fix other settings for a fair comparison. Furthermore, we select different baseline models and deploy CL4CTR into them to compare their performance under this setting. Table <ref type="table" target="#tab_4">5</ref> shows the experimental results. The random mask method achieves the best performance in most cases. We think the random mask is more moderated than feature mask and dimension mask because it omits element information. Additionally, the FwFM model achieves the best performance with the feature mask method on Frappe; in contrast, it achieves the best performance with the dimension mask method on SafeDriver, demonstrating that our proposed augmentation methods are effective and can be used in different baseline models and datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">FI Encoder.</head><p>In the contrastive module, the FI encoder also affects the performance of CL4CTR, as different structures of the FI encoder extract different information. For instance, transformer layer can model high-order feature interactions in feature-level <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b27">28]</ref> explicitly, however, CrossNet2 <ref type="bibr" target="#b34">[35]</ref> focuses on modelling boundeddegree feature interactions in element-level explicitly. DNN is a common and widely used structure in most CTR models for modeling bit-level feature relationships implicitly. We select the above three representative structures as FI encoders and verify their performance. Notably, we adopt three layers structure as reported in their paper. Table <ref type="table" target="#tab_5">6</ref> shows the experimental results. It can be observed that CL4CTR can consistently improve the performance of these baseline models with different FI encoders. In addition, since different FI encoders extract different information based on specific base models and datasets, the performance of these models is different. However, CL4CTR with transformer layers  achieves the best performance in most cases since the transformer layer is a more effective solution than others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Loss Function.</head><p>In this section, we evaluate the effectiveness of self-supervised learning signals ( i.e., L ?? , L ? , L ? ) by eliminating them from CL4CTR respectively. We still regard L ? and L ? as a whole part. The experimental results are shown in Table <ref type="table" target="#tab_6">7</ref>.</p><p>Firstly, we can find that each self-supervised learning signal deployed in baseline models can improve their performance. In addition, by comparing the contrastive loss and alignment&amp;uniformity constraints individually, we conclude that they play different roles in different datasets and baseline models. Specifically, FM with L ? and L ? perform better than FM with L ?? ; in contrast, DCN with L ? and L ? perform worse than DCN with L ?? , which verifies our hypothesis. Furthermore, all experiments achieve the best performance when L ?? , L ? , and L ? are deployed simultaneously.</p><p>Compared with individual SSL signals, we find that training with all of them can always achieve the best performance. Furthermore, adopting L ? and L ? in FM consistently outperforms adopting L ?? in FM on two datasets evaluated by Logloss, which indicates that inducing feature alignment and field uniformity into CTR prediction models enables us to predict probabilities closer to the true label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Feature Frequency Analysis</head><p>To verify the effects of feature frequency on different models, we divide the test set of ML-tag according to feature frequency and calculate the corresponding Logloss, where ???????? represents the improvement over the base FM model after applying CL4CTR. Figure <ref type="figure" target="#fig_2">3</ref> shows the experimental results. Firstly, the low frequency features adversely affect the accuracy of the base model. Specifically, we show the performance of FM, three SOTA models (AFN+, DeepFM, DCN-V2), and ??4?? ? ? ? in different frequency ranges. It can be observed that all models perform the worst when the input subset contains low frequency features. With the increasing of feature frequency, the performance of all models improves consistently. When the feature frequency is over 20, the performance of all models becomes stable. Figure <ref type="figure" target="#fig_2">3</ref> confirms our hypothesis that only using the back-propagation to learn the representations of low frequency features with a single supervised signal cannot achieve optimal performance.</p><p>Secondly, CL4CTR can effectively alleviate the negative effects caused by low frequency features and keep achieving the best performance among different feature frequency ranges. By applying the alignment&amp;uniformity constraints, we ensure the low frequency features can be optimized in each back-propagation process with equal chances to high frequency features. Additionally, the contrastive module can also improve the quality of the representations of all features, including both low and high frequency features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Hyper-parameter Analysis</head><p>4.5.1 Impact of the Weights in the Loss Function. We further investigate the impact of different weights (? and ? in Equation <ref type="formula" target="#formula_12">10</ref>). We tune both ? and ? from {1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 0}. We keep other settings fixed for fair comparison. Figure <ref type="figure" target="#fig_3">4</ref> shows the experimental results. Additionally, the trend of Logloss is consistent with AUC on those two datasets.</p><p>Overall, CL4CTR achieves the best performance when ? is 1, and ? is 1e-2 for Frappe and ML-1M datasets. Specifically, the performance of CL4CTR deteriorates when ? is less than 1. In addition, when ? is over 1e-2 (i.e., 1 or 1e-1), the performance of CL4CTR is significantly reduced. Meanwhile, CL4CTR performs worse with lower ? and ? (lower right corners).</p><p>4.5.2 Mask Proportion. We change the mask proportion ? within the range (0, 1) with a step size of 0.1. Note that the mask proportion is only applied in L ?? . Figure <ref type="figure">5</ref> shows the results.</p><p>For models with L ?? , their performance shows similar trends on Frappe and ML-1M. When the mask proportion is around 0.4 or 0.5, ??4?? ? ? ? can achieve the best performance. Specifically, the model performance decreases slightly when smaller mask proportions (i.e., 0.1 to 0.3) are chosen. When mask proportion is over 0.5, the model performance decreases consistently, which is because the FI encoders only use a small percentage of information to produce valid interaction representations for calculating contrastive loss with higher mask proportions. We change the embedding size from 16 to 64 with a step of 16 in the embedding layer and show the experimental results in Figure <ref type="figure">6</ref>. It can be observed that the performance of ??4?? ? ? ? is improved substantially with the embedding sizes increasing. Meanwhile, CL4CTR can improve the performance of FM with all embedding sizes. Furthermore, compared with the embedding size of 64 in FM, ??4?? ? ? ? achieves better performance with a small size of 16. This means we can reduce the parameters while achieving better results by applying CL4CTR on FM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we propose a novel framework named Contrastive Learning for CTR prediction (CL4CTR), which directly improves the quality of feature representations, especially for low frequency features. In CL4CTR, we introduce a contrastive module to improve the quality and generalizability of the feature representations by fully utilizing the self-supervised signals from the features. Furthermore, considering the unique characteristics of CTR prediction tasks, we propose two constraints in contrastive learning: feature alignment and feature uniformity, which are used to regularize feature representations. The extensive experimental results demonstrate the excellent effectiveness and compatibility of our proposed CL4CTR on four public datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Cumulative distribution of feature frequencies. (38, 80.07%) indicates that features with feature frequencies less than or equal to 38 times account for 80.07% of all features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Perturbation g 1 Figure 2 :</head><label>12</label><figDesc>Figure 2: Architecture of the CL4CTR framework. CL4CTR including three components: (a) a basic CTR model; (b) a contrastive module; (c) alignment &amp; uniformity constraints. In contrastive module, we design (d) three embedding perturbation methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Improvement vs. feature frequency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Performance of ??4?? ? ? ? w.r.t. different weights assigned to three SSL signals: ? for L ? , ? for L ? and L ? .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Figure 5: Impact of random mask proportion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>An example of multi-field tabular data for CTR prediction. Each row represents an input instance and each column indicates a field. Moreover, each field contains multiple features, but each feature only belongs to one field. a contrastive loss function. In the data augmentation unit, we propose three different task-oriented posterior embedding augmentation techniques to generate positive training pairs, i.e., two different views of each feature embedding. Then we feed the two perturbed embeddings to the same FI encoder to generate two compressed feature representations. Finally, the contrastive loss is applied to minimize the distance between the two compressed feature representations.</figDesc><table><row><cell>user_id</cell><cell cols="6">item_id gender city daytime ... click</cell></row><row><cell cols="3">25c83c98 c5c50484 female</cell><cell>5</cell><cell>1</cell><cell>...</cell><cell>0</cell></row><row><cell cols="2">7e0ccccf 0b153874</cell><cell>male</cell><cell>10</cell><cell>5</cell><cell>...</cell><cell>1</cell></row><row><cell cols="2">de7995b8 e51ddf94</cell><cell>male</cell><cell>32</cell><cell>6</cell><cell>...</cell><cell>1</cell></row><row><cell cols="3">1f89b562 f0cf0024 female</cell><cell>4</cell><cell>2</cell><cell>...</cell><cell>1</cell></row><row><cell cols="3">1f89b562 a3397841 female</cell><cell>4</cell><cell>8</cell><cell>...</cell><cell>0</cell></row><row><cell>encoder, and</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>3.2.1 Data Augmentation via Output Perturbation. Data augmentation has shown great potential in improving the performance of feature representations in SSL</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Dataset statistics.</figDesc><table><row><cell>Datasets</cell><cell cols="6">Positive #Training #Validation #Test #Features #Fields</cell></row><row><cell>Frappe</cell><cell>33%</cell><cell>202K</cell><cell>58K</cell><cell>29K</cell><cell>5K</cell><cell>10</cell></row><row><cell>ML-tag</cell><cell>33%</cell><cell>1,404K</cell><cell>401K</cell><cell>201K</cell><cell>90K</cell><cell>3</cell></row><row><cell>ML-1M</cell><cell>57.5%</cell><cell>800K</cell><cell>100K</cell><cell>100K</cell><cell>10K</cell><cell>5</cell></row><row><cell>SafeDriver</cell><cell>3.64%</cell><cell>476K</cell><cell>59K</cell><cell>59K</cell><cell>600</cell><cell>57</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Overall accuracy comparison in the four datasets. ???? and ???????? indicate averaged performance boost compared with DCN-V2. RelaImp denotes the relative improvements compared with the strongest baseline. Bold scores are the best performance, while underlined scores are the second best. Improvements over baselines are statistically significant with p&lt;0.01.</figDesc><table><row><cell>Model</cell><cell>Datasets</cell><cell cols="2">Frappe</cell><cell cols="2">ML-tag</cell><cell cols="2">ML-1M</cell><cell cols="2">SafeDriver</cell><cell>????</cell><cell>????????</cell></row><row><cell>Class</cell><cell>Model</cell><cell>AUC</cell><cell>Logloss</cell><cell>AUC</cell><cell>Logloss</cell><cell>AUC</cell><cell>Logloss</cell><cell>AUC</cell><cell>Logloss</cell><cell>?</cell><cell>?</cell></row><row><cell>First-order</cell><cell>LR</cell><cell>0.9331</cell><cell>0.2894</cell><cell>0.9348</cell><cell>0.2960</cell><cell>0.7899</cell><cell>0.5417</cell><cell cols="3">0.6244 0.1622 -3.35%</cell><cell>0.0572</cell></row><row><cell></cell><cell>FM</cell><cell>0.9746</cell><cell>0.1856</cell><cell>0.9488</cell><cell>0.2595</cell><cell>0.8023</cell><cell>0.5332</cell><cell cols="3">0.6301 0.1538 -1.22%</cell><cell>0.0179</cell></row><row><cell>Second-Order</cell><cell>FwFM IFM</cell><cell>0.9756 0.9771</cell><cell>0.1784 0.1581</cell><cell>0.9582 0.9515</cell><cell>0.2531 0.2497</cell><cell>0.8046 0.8080</cell><cell>0.5281 0.5286</cell><cell cols="3">0.6335 0.1532 -0.74% 0.6353 0.1526 -0.70%</cell><cell>0.0131 0.0071</cell></row><row><cell></cell><cell>FmFM</cell><cell>0.9801</cell><cell>0.1682</cell><cell>0.9552</cell><cell>0.2493</cell><cell>0.8093</cell><cell>0.5264</cell><cell cols="3">0.6378 0.1518 -0.39%</cell><cell>0.0088</cell></row><row><cell></cell><cell>CrossNet</cell><cell>0.9800</cell><cell>0.1658</cell><cell>0.9549</cell><cell>0.2480</cell><cell>0.8114</cell><cell>0.5218</cell><cell cols="3">0.6336 0.1517 -0.50%</cell><cell>0.0067</cell></row><row><cell></cell><cell>IPNN</cell><cell>0.9809</cell><cell>0.1604</cell><cell>0.9607</cell><cell>0.2295</cell><cell>0.8110</cell><cell>0.5190</cell><cell cols="3">0.6373 0.1521 -0.19%</cell><cell>0.0001</cell></row><row><cell>High-Order</cell><cell>OPNN</cell><cell>0.9799</cell><cell>0.1683</cell><cell>0.9599</cell><cell>0.2421</cell><cell>0.8112</cell><cell>0.5185</cell><cell cols="3">0.6375 0.1519 -0.22%</cell><cell>0.0051</cell></row><row><cell></cell><cell>FINT</cell><cell>0.9807</cell><cell>0.1578</cell><cell>0.9557</cell><cell>0.2430</cell><cell>0.8123</cell><cell>0.5192</cell><cell cols="3">0.6349 0.1522 -0.38%</cell><cell>0.0029</cell></row><row><cell></cell><cell>DCAP</cell><cell>0.9801</cell><cell>0.1612</cell><cell>0.9560</cell><cell>0.2428</cell><cell>0.8130</cell><cell>0.5171</cell><cell cols="3">0.6390 0.1512 -0.20%</cell><cell>0.0030</cell></row><row><cell></cell><cell>WDL</cell><cell>0.9770</cell><cell>0.1783</cell><cell>0.9599</cell><cell>0.2660</cell><cell>0.8093</cell><cell>0.5226</cell><cell cols="3">0.6353 0.1525 -0.44%</cell><cell>0.0110</cell></row><row><cell></cell><cell>DCN</cell><cell>0.9788</cell><cell>0.1621</cell><cell>0.9550</cell><cell>0.2472</cell><cell>0.8125</cell><cell>0.5175</cell><cell cols="3">0.6379 0.1514 -0.32%</cell><cell>0.0044</cell></row><row><cell></cell><cell>DeepFM</cell><cell>0.9780</cell><cell>0.1732</cell><cell>0.9586</cell><cell>0.2551</cell><cell>0.8061</cell><cell>0.5259</cell><cell cols="3">0.6318 0.1529 -0.69%</cell><cell>0.0117</cell></row><row><cell></cell><cell>xDeepFM</cell><cell>0.9799</cell><cell>0.1750</cell><cell>0.9604</cell><cell>0.2472</cell><cell>0.8082</cell><cell>0.5244</cell><cell cols="3">0.6403 0.1515 -0.19%</cell><cell>0.0094</cell></row><row><cell>Ensemble</cell><cell>FiBiNET AutoInt+</cell><cell>0.9793 0.9783</cell><cell>0.1707 0.1762</cell><cell>0.9548 0.9535</cell><cell>0.2532 0.2562</cell><cell>0.8032 0.8099</cell><cell>0.5313 0.5219</cell><cell cols="3">0.6391 0.1505 -0.56% 0.6310 0.1516 -0.73%</cell><cell>0.0113 0.0114</cell></row><row><cell></cell><cell>AFN+</cell><cell>0.9786</cell><cell>0.1637</cell><cell>0.9561</cell><cell>0.2468</cell><cell>0.8041</cell><cell>0.5304</cell><cell cols="3">0.6374 0.1517 -0.58%</cell><cell>0.0080</cell></row><row><cell></cell><cell>TFNet</cell><cell>0.9798</cell><cell>0.1708</cell><cell>0.9527</cell><cell>0.2551</cell><cell>0.8099</cell><cell>0.5212</cell><cell cols="3">0.6387 0.1533 -0.41%</cell><cell>0.0100</cell></row><row><cell></cell><cell>FED</cell><cell>0.9791</cell><cell>0.1606</cell><cell>0.9557</cell><cell>0.2465</cell><cell>0.8128</cell><cell>0.5184</cell><cell cols="3">0.6369 0.1534 -0.33%</cell><cell>0.0046</cell></row><row><cell></cell><cell>DCN-V2</cell><cell>0.9803</cell><cell>0.1595</cell><cell>0.9610</cell><cell>0.2330</cell><cell>0.8132</cell><cell>0.5169</cell><cell cols="2">0.6406 0.1510</cell><cell>-</cell><cell>-</cell></row><row><cell>Ours</cell><cell cols="10">??4?? ? ? ? 0.9822 0.1324 0.9621 0.2102 0.8164 0.5136 0.6449 0.1483 0.34% RelaImp 0.13% 16.10% 0.11% 8.41% 0.39% 0.64% 0.67% 1.46% -</cell><cell>-0.0140 -</cell></row><row><cell cols="6">strong generalization ability on all datasets, where Table 3 shows the</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">averaged performance boost (?AUC and ?Logloss). Notably, most</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">SOTA CTR prediction models design complex networks to produce</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">advanced feature representations and useful feature interactions to</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">improve the performance. However, our CL4CTR only helps FM to</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">learn accurate feature representations from the embedding layer</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">with contrastive learning instead of introducing extra modules.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">The improvement of our CL4CTR verifies the necessity of learning</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">accurate feature representations in CTR prediction tasks.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Compatibility study of CL4CTR.</figDesc><table><row><cell>Model</cell><cell cols="2">Frappe AUC Logloss</cell><cell cols="2">ML-1M AUC Logloss</cell><cell cols="2">SafeDriver AUC Logloss</cell></row><row><cell>FM</cell><cell>0.9746</cell><cell>0.1856</cell><cell>0.8023</cell><cell>0.5332</cell><cell>0.6244</cell><cell>0.1622</cell></row><row><cell>??4?? ? ? ?</cell><cell cols="6">0.9822 0.1324 0.8164 0.5136 0.6449 0.1483</cell></row><row><cell>FwFM</cell><cell>0.9756</cell><cell>0.1784</cell><cell>0.8046</cell><cell>0.5281</cell><cell>0.6335</cell><cell>0.1532</cell></row><row><cell>??4?? ? ? ?? ?</cell><cell cols="6">0.9815 0.1532 0.8118 0.5192 0.6421 0.1487</cell></row><row><cell>DeepFM</cell><cell>0.9780</cell><cell>0.1732</cell><cell>0.8061</cell><cell>0.5259</cell><cell>0.6318</cell><cell>0.1529</cell></row><row><cell cols="7">??4?? ? ????? ? 0.9813 0.1677 0.8113 0.5194 0.6381 0.1504</cell></row><row><cell>Autoint+</cell><cell>0.9783</cell><cell>0.1762</cell><cell>0.8099</cell><cell>0.5219</cell><cell>0.6310</cell><cell>0.1516</cell></row><row><cell cols="7">??4?? ? ??????? + 0.9802 0.1684 0.8122 0.5174 0.6402 0.1506</cell></row><row><cell>DCN</cell><cell>0.9788</cell><cell>0.1621</cell><cell>0.8125</cell><cell>0.5170</cell><cell>0.6379</cell><cell>0.1514</cell></row><row><cell>??4?? ? ???</cell><cell cols="6">0.9808 0.1566 0.8164 0.5125 0.6415 0.1494</cell></row><row><cell>DCN-V2</cell><cell>0.9803</cell><cell>0.1595</cell><cell>0.8132</cell><cell>0.5169</cell><cell>0.6406</cell><cell>0.1510</cell></row><row><cell cols="7">??4?? ? ??? -? 2 0.9812 0.1549 0.8144 0.5153 0.6411 0.1497</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Impact of data augmentation methods.</figDesc><table><row><cell>Base model</cell><cell>Variants</cell><cell cols="2">Frappe AUC Logloss</cell><cell cols="2">SafeDriver AUC Logloss</cell></row><row><cell></cell><cell>Base</cell><cell>0.9746</cell><cell>0.1856</cell><cell>0.6244</cell><cell>0.1622</cell></row><row><cell>FM</cell><cell>Random Feature</cell><cell cols="4">0.9822 0.1324 0.6449 0.1483 0.9814 0.1328 0.6303 0.1539</cell></row><row><cell></cell><cell cols="2">Dimension 0.9816</cell><cell>0.1334</cell><cell>0.6404</cell><cell>0.1505</cell></row><row><cell></cell><cell>Base</cell><cell>0.9756</cell><cell>0.1784</cell><cell>0.6335</cell><cell>0.1532</cell></row><row><cell>FwFM</cell><cell>Random Feature</cell><cell cols="3">0.9815 0.9822 0.1513 0.6384 0.1532 0.6421</cell><cell>0.1487 0.1483</cell></row><row><cell></cell><cell cols="2">Dimension 0.9811</cell><cell cols="3">0.1465 0.6455 0.1508</cell></row><row><cell></cell><cell>Base</cell><cell>0.9780</cell><cell>0.1817</cell><cell>0.6318</cell><cell>0.1529</cell></row><row><cell>DeepFM</cell><cell>Random Feature</cell><cell cols="4">0.9813 0.1677 0.6381 0.1504 0.9798 0.1750 0.6341 0.1522</cell></row><row><cell></cell><cell cols="2">Dimension 0.9804</cell><cell>0.1697</cell><cell>0.6353</cell><cell>0.1514</cell></row><row><cell></cell><cell>Base</cell><cell>0.9788</cell><cell>0.1611</cell><cell>0.6379</cell><cell>0.1514</cell></row><row><cell>DCN</cell><cell>Random Feature</cell><cell cols="4">0.9808 0.1566 0.6415 0.1494 0.9804 0.1601 0.6409 0.1508</cell></row><row><cell></cell><cell cols="2">Dimension 0.9803</cell><cell>0.1573</cell><cell>0.6411</cell><cell>0.1504</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Impact of different FI encoder ? ? ?? (?).</figDesc><table><row><cell>Base</cell><cell>FI</cell><cell cols="2">Frappe</cell><cell cols="2">ML-1M</cell></row><row><cell>model</cell><cell>Encoder</cell><cell>AUC</cell><cell>Logloss</cell><cell>AUC</cell><cell>Logloss</cell></row><row><cell></cell><cell>Base</cell><cell>0.9746</cell><cell>0.1856</cell><cell>0.8023</cell><cell>0.5332</cell></row><row><cell>FM</cell><cell cols="5">DNN Transformer 0.9822 0.1324 0.8164 0.9804 0.1404 0.8177 0.5123 0.5136</cell></row><row><cell></cell><cell>CrossNet2</cell><cell>0.9801</cell><cell>0.1438</cell><cell>0.8170</cell><cell>0.5143</cell></row><row><cell></cell><cell>Base</cell><cell>0.9756</cell><cell>0.1784</cell><cell>0.8046</cell><cell>0.5281</cell></row><row><cell>FwFM</cell><cell cols="5">DNN Transformer 0.9815 0.9809 0.1504 0.8064 0.1532 0.8118 0.5192 0.5264</cell></row><row><cell></cell><cell>CrossNet2</cell><cell cols="2">0.9822 0.1675</cell><cell>0.8102</cell><cell>0.5231</cell></row><row><cell></cell><cell>Base</cell><cell>0.9780</cell><cell>0.1732</cell><cell>0.8061</cell><cell>0.5259</cell></row><row><cell>DeepFM</cell><cell cols="5">DNN Transformer 0.9813 0.1704 0.8113 0.5194 0.9804 0.1710 0.8101 0.5206</cell></row><row><cell></cell><cell>CrossNet2</cell><cell>0.9791</cell><cell>0.1719</cell><cell>0.8109</cell><cell>0.5202</cell></row><row><cell></cell><cell>Base</cell><cell>0.9803</cell><cell>0.1595</cell><cell>0.8132</cell><cell>0.5169</cell></row><row><cell>DCN-V2</cell><cell cols="5">DNN Transformer 0.9812 0.1549 0.8144 0.9807 0.1573 0.8151 0.5144 0.5153</cell></row><row><cell></cell><cell>CrossNet2</cell><cell>0.9804</cell><cell>0.1588</cell><cell>0.8141</cell><cell>0.5155</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Impact of SSL signals in the loss function. ?? + (L ? + L ? ) 0.9808 0.1566 0.8164 0.5125</figDesc><table><row><cell>Model</cell><cell>Loss Function</cell><cell>AUC</cell><cell cols="2">Frappe Logloss</cell><cell cols="2">ML-1M AUC Logloss</cell></row><row><cell></cell><cell>L ???</cell><cell cols="2">0.9746</cell><cell>0.1856</cell><cell>0.8023</cell><cell>0.5332</cell></row><row><cell>FM</cell><cell>+ L ?? + (L ? + L ? )</cell><cell cols="2">0.9794 0.9812</cell><cell>0.1485 0.1455</cell><cell>0.8102 0.8139</cell><cell>0.5230 0.5175</cell></row><row><cell></cell><cell cols="6">+ L ?? + (L ? + L ? ) 0.9822 0.1324 0.8164 0.5136</cell></row><row><cell></cell><cell>L ???</cell><cell cols="2">0.9756</cell><cell>0.1784</cell><cell>0.8046</cell><cell>0.5281</cell></row><row><cell>FwFM</cell><cell>+ L ?? + (L ? + L ? )</cell><cell cols="2">0.9785 0.9812</cell><cell>0.1553 0.1536</cell><cell>0.8109 0.8098</cell><cell>0.5229 0.5252</cell></row><row><cell></cell><cell cols="6">+ L ?? + (L ? + L ? ) 0.9815 0.1532 0.8118 0.5192</cell></row><row><cell></cell><cell>L ???</cell><cell cols="2">0.9780</cell><cell>0.1817</cell><cell>0.8061</cell><cell>0.5259</cell></row><row><cell>DeepFM</cell><cell>+ L ?? + (L ? + L ? )</cell><cell cols="2">0.9794 0.9784</cell><cell>0.1701 0.1791</cell><cell>0.8094 0.8103</cell><cell>0.5235 0.5214</cell></row><row><cell></cell><cell cols="6">+ L ?? + (L ? + L ? ) 0.9813 0.1677 0.8113 0.5194</cell></row><row><cell></cell><cell>L ???</cell><cell cols="2">0.9788</cell><cell>0.1611</cell><cell>0.8125</cell><cell>0.5170</cell></row><row><cell>DCN</cell><cell>+ L ?? + (L ? + L ? )</cell><cell cols="2">0.9802 0.9792</cell><cell>0.1585 0.1600</cell><cell>0.8138 0.8129</cell><cell>0.5150 0.5188</cell></row><row><cell></cell><cell>+ L</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://www.baltrunas.info/context-aware/frappe</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://grouplens.org/datasets/movielens/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://www.kaggle.com/c/porto-seguro-safe-driver-prediction</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://grouplens.org/datasets/movielens/1m/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>The code of CL4CTR is available here: https://github.com/cl4ctr/cl4ctr</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work was supported by the <rs type="funder">National Natural Science Foundation of China (NSFC)</rs> under Grants <rs type="grantNumber">62172106</rs> and <rs type="grantNumber">61932007</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_MBaDhCn">
					<idno type="grant-number">62172106</idno>
				</org>
				<org type="funding" xml:id="_QkqCwVp">
					<idno type="grant-number">61932007</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Enhancing explicit and implicit feature interactions via information sharing for parallel deep CTR models</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhirong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongkun</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3757" to="3766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">DCAP: Deep Cross Attentional Product Network for User Response Prediction</title>
		<author>
			<persName><forename type="first">Zekai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangtian</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Pless</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuzhen</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 30th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="221" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Wide &amp; deep learning for recommender systems</title>
		<author>
			<persName><forename type="first">Heng-Tze</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Levent</forename><surname>Koc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremiah</forename><surname>Harmsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrishi</forename><surname>Aradhye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glen</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Ispir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st workshop on deep learning for recommender systems</title>
		<meeting>the 1st workshop on deep learning for recommender systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="7" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adaptive factorization network: Learning adaptive-order feature interactions</title>
		<author>
			<persName><forename type="first">Weiyu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linpeng</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3609" to="3616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">SimCSE: Simple Contrastive Learning of Sentence Embeddings</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingcheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6894" to="6910" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">DeepFM: a factorization-machine based neural network for CTR prediction</title>
		<author>
			<persName><forename type="first">Huifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 26th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Miss: Multi-interest self-supervised learning framework for click-through rate prediction</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Can</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhicheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiarui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE 38th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="727" to="740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural factorization machines for sparse predictive analytics</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="355" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Improving neural networks by preventing coadaptation of feature detectors</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1207.0580</idno>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">GateNet: Gating-Enhanced Deep Network for Click-Through Rate Prediction</title>
		<author>
			<persName><forename type="first">Tongwen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyun</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junlin</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.03519</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">FiBiNET: combining feature importance and bilinear feature interaction for click-through rate prediction</title>
		<author>
			<persName><forename type="first">Tongwen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junlin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM Conference on Recommender Systems</title>
		<meeting>the 13th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="169" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fieldaware factorization machines for CTR prediction</title>
		<author>
			<persName><forename type="first">Yuchin</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Sheng</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM Conference on Recommender Systems</title>
		<meeting>the 10th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bootstrapping user and item representations for one-class collaborative filtering</title>
		<author>
			<persName><forename type="first">Dongha</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunjun</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chanyoung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="317" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Interpretable click-through rate prediction through hierarchical attention</title>
		<author>
			<persName><forename type="first">Zeyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Web Search and Data Mining</title>
		<meeting>the 13th International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="313" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">xdeepfm: Combining explicit and implicit feature interactions for recommender systems</title>
		<author>
			<persName><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongxia</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1754" to="1763" />
		</imprint>
	</monogr>
	<note>Xing Xie, and Guangzhong Sun</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Feature generation by convolutional neural network for click-through rate prediction</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingzhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinkai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzhou</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1119" to="1129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Dual Input-aware Factorization Machine for CTR Prediction</title>
		<author>
			<persName><forename type="first">Wantong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yantao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongzhe</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenhui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3139" to="3145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Network on network for tabular data classification in real-world applications</title>
		<author>
			<persName><forename type="first">Yuanfei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Wei</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuqiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyuan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2317" to="2326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A general method for automatic discovery of powerful interactions in click-through rate prediction</title>
		<author>
			<persName><forename type="first">Ze</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinnian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yumeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiancheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanchao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1298" to="1307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Field-weighted factorization machines for click-through rate prediction in display advertising</title>
		<author>
			<persName><forename type="first">Junwei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alfonso</forename><forename type="middle">Lobos</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenliang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengjun</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 World Wide Web Conference</title>
		<meeting>the 2018 World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1349" to="1357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiangchao</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunyang</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.13921</idno>
		<title level="m">Click-through Rate Prediction with Auto-Quantized Contrastive Learning</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">User behavior retrieval for click-through rate prediction</title>
		<author>
			<persName><forename type="first">Jiarui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiarui</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2347" to="2356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Product-based neural networks for user response prediction over multi-field categorical data</title>
		<author>
			<persName><forename type="first">Yanru</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bohui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minzhe</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Factorization machines with libfm</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology (TIST)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Predicting clicks: estimating the click-through rate for new ads</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ewa</forename><surname>Dominowska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Ragno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th international conference on World Wide Web</title>
		<meeting>the 16th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="521" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Autoint: Automatic feature interaction learning via selfattentive neural networks</title>
		<author>
			<persName><forename type="first">Weiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chence</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiping</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijian</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yewen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1161" to="1170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fm2: Field-matrixed factorization machines for recommender systems</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junwei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Flores</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021</title>
		<meeting>the Web Conference 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2828" to="2837" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Hieu Pham, and Quoc Le. 2021. Towards domain-agnostic contrastive learning</title>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenji</forename><surname>Kawaguchi</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="10530" to="10541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Understanding the behaviour of contrastive loss</title>
		<author>
			<persName><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaping</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2495" to="2504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Enhancing CTR Prediction with Context-Aware Feature Representation Learning</title>
		<author>
			<persName><forename type="first">Fangye</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingxu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hansu</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tun</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep &amp; cross network for ad click predictions</title>
		<author>
			<persName><forename type="first">Ruoxi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingliang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ADKDD&apos;17</title>
		<meeting>the ADKDD&apos;17</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Ruoxi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Shivanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">Z</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.13535</idno>
		<title level="m">DCN-M: Improved Deep &amp; Cross Network for Feature Cross Learning in Web-scale Learning to Rank Systems</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Understanding contrastive representation learning through alignment and uniformity on the hypersphere</title>
		<author>
			<persName><forename type="first">Tongzhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9929" to="9939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">MaskNet: introducing feature-wise multiplication to CTR ranking models by instance-guided mask</title>
		<author>
			<persName><forename type="first">Zhiqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyun</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junlin</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.07619</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">TFNet: Multi-Semantic Feature Interaction for CTR Prediction</title>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueli</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1885" to="1888" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>Hao Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Contrastive learning for sequential recommendation</title>
		<author>
			<persName><forename type="first">Xu</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiwen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiandong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bolin</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE 38th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">Junliang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongzhi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zi</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.15876</idno>
		<title level="m">Self-Supervised Learning for Recommender Systems: A Survey</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">An Input-aware Factorization Machine for Sparse Prediction</title>
		<author>
			<persName><forename type="first">Yantao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1466" to="1472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Ruiming Tang, and Xiuqiang He. 2021. Deep learning for click-through rate estimation</title>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiarui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Dimension Relation Modeling for Click-Through Rate Prediction</title>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changping</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongjun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weipeng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2333" to="2336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">FINT: Field-Aware Interaction Neural Network for Click-Through Rate Prediction</title>
		<author>
			<persName><forename type="first">Zhishan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guohui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kele</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3913" to="3917" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Xin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aixin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyan</forename><surname>Miao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.03019</idno>
		<title level="m">SelfCF: A Simple Framework for Self-supervised Collaborative Filtering</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
