<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automatic classification of sentences to support Evidence Based Medicine</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010-10-26">26 October 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Su</forename><forename type="middle">Nam</forename><surname>Kim</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">NICTA VRL</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<postCode>3010</postCode>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">David</forename><surname>Martinez</surname></persName>
							<email>david.martinez@nicta.com.au</email>
							<affiliation key="aff1">
								<orgName type="laboratory">NICTA VRL</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<postCode>3010</postCode>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lawrence</forename><surname>Cavedon</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">NICTA VRL</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<postCode>3010</postCode>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lars</forename><surname>Yencken</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">NICTA VRL</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<postCode>3010</postCode>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">From Fourth International Workshop on Data and Text Mining in Biomedical Informatics</orgName>
								<address>
									<postCode>2010</postCode>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automatic classification of sentences to support Evidence Based Medicine</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2010-10-26">26 October 2010</date>
						</imprint>
					</monogr>
					<idno type="MD5">C50F19B8283419A2E3160530E0F1A50C</idno>
					<idno type="DOI">10.1186/1471-2105-12-S2-S5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Kim et al</term>
					<term>Automatic classification of sentences to support Evidence Based Medicine</term>
					<term>BMC Bioinformatics 2011 12(Suppl 2): S5</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Aim: Given a set of pre-defined medical categories used in Evidence Based Medicine, we aim to automatically annotate sentences in medical abstracts with these labels. Method: We constructed a corpus of 1,000 medical abstracts annotated by hand with specified medical categories (e.g. Intervention, Outcome). We explored the use of various features based on lexical, semantic, structural, and sequential information in the data, using Conditional Random Fields (CRF) for classification. Results: For the classification tasks over all labels, our systems achieved micro-averaged f-scores of 80.9% and 66.9% over datasets of structured and unstructured abstracts respectively, using sequential features. In labeling only the key sentences, our systems produced f-scores of 89.3% and 74.0% over structured and unstructured abstracts respectively, using the same sequential features. The results over an external dataset were lower (f-scores of 63.1% for all labels, and 83.8% for key sentences). Conclusions: Of the features we used, the best for classifying any given sentence in an abstract were based on unigrams, section headings, and sequential information from preceding sentences. These features resulted in improved performance over a simple bag-of-words approach, and outperformed feature sets used in previous work.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Evidence Based Medicine (EBM) is an approach to clinical practice whereby medical decisions are informed by primary evidence, such as the results of randomized control trials (RCTs). Evidence-based practice requires efficient information access to such evidence, and also retrieval and analysis of documents relevant to a specified clinical topic. Evidence-based practitioners use specific criteria when judging whether an RCT is relevant to a given question. They generally follow the PICO criterion <ref type="bibr" target="#b0">[1]</ref>: Population (P) (i.e., participants in a study); Intervention (I); Comparison (C) (if appropriate); and Outcome (O) (of an Intervention). Variations and extensions of this classification have been proposed, such as the PECODR tagset <ref type="bibr" target="#b1">[2]</ref>. To better serve the information needs of the EBM community, we explore the use of classification techniques to identify relevant key sentences in a given document, and classify these against specified medical criteria. Such information could be leveraged in various ways: e.g., to improve search performance; to enable structured querying with specific categories; and to aid users in more quickly making judgements against specified PICO criteria.</p><p>In this paper, we build a classifier that performs two tasks. First, it identifies the key sentences in an abstract, filtering out those that do not provide the most relevant information. Second, it classifies sentences according to medical tags (based on the PICO criteria) used by our medical research partners. We project these two tasks into an (N+1)-way classification task, with N semantic labels for key sentences and 1 label (i.e. Other) for labeling non-key sentences. For this purpose, we have built a corpus of 1,000 medical abstracts, hand-annotated at the sentence level by domain experts, which we use to develop and evaluate our system.</p><p>A major difference of our approach from previous work is the combination of key-sentence identification and classification, whereas others (e.g., <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>) have separated these tasks and assumed that all sentences are relevant at the classification step. Many sentences in abstracts do not fall into any of the pre-defined categories (due to vagueness, diversion from the central topic, etc.), and the identification of such extraneous material is useful.</p><p>Our classification techniques use an extensive set of features, derived from context, semantic relations, structure and sequencing of the text. In particular, for sequence information we use features from previous sentences in the given abstract, and use predicted labels as features in a novel way. We employ Conditional Random Fields (CRF) <ref type="bibr" target="#b4">[5]</ref>, which are well suited for learning over sequential data (such as cohesive, structured text). In the following sections, we first describe related work in Section . In Section , we provide details of our experimental setup including the construction of the corpus, the learners, and features. We present our results and error analysis in Sections and respectively. We conclude and discuss future directions in Section .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related work</head><p>The generalised use of PICO and similar schemas by clinicians when performing search, and their improvement on performance in user studies <ref type="bibr" target="#b5">[6]</ref>, has fueled interest in the development of automatic aids for this task.</p><p>Demner-Fushman and Lin <ref type="bibr" target="#b6">[7]</ref> were the first to present automatic classifiers for PICO-elements. In their work, they used the MetaMap parser <ref type="bibr" target="#b7">[8]</ref>, hand-built rules, and statistical classifiers to identify sentences or phrases in abstracts relevant to each PICO element. Only for the element Outcome did they use a supervised classifier (Naive Bayes) with a large set of features, including n-grams, position, and semantic information from MetaMap. They trained this classifier over 275 hand-annotated abstracts, and reported accuracies in the range of 74%-93% depending on the type of abstract and the evaluation threshold. It is important to note that this is the only previous work in the literature that uses the Other tag as we do. Demner-Fushman and Lin <ref type="bibr" target="#b6">[7]</ref> also applied their final PICO classifiers to a novel weighting formula for medical information retrieval (IR), significantly improving the baseline for the task. In a related paper <ref type="bibr" target="#b8">[9]</ref>, the same authors applied PICO classification to the task of clustering medical results, showing that it improved information delivery. The main limitations of their classifiers were the small size of the annotated data, and the reliance on hand-crafted rules for some of the PICO classes. One drawback of their IR system was the use of parameters that were handassigned or estimated over a small dataset. More recently, Chung <ref type="bibr" target="#b3">[4]</ref> performed PICO classification by combining rhetorical roles with PICO elements, in order to achieve higher performance and alleviate the hand-annotation cost. Chung uses four rhetorical roles, namely Aim, Method, Results, and Conclusions; she requires that each sentence in an abstract fall into one of these roles. Chung then focuses on categorising one PICO class at a time, for a more fine-grained analysis. There are two limitations to this approach: (i) the overall classification performance across medical tags is not known; and (ii) sentences are forced to always have one semantic tag. We address these limitations by focusing directly on labels of interest for EBM, allowing sentences to be labeled as Other, and by allowing multiple labels per sentence when required. We believe that this is a more realistic setting than the one presented in previous work, and will provide better insight on the performance we should expect for this kind of task. This makes our approach not directly comparable to <ref type="bibr" target="#b3">[4]</ref>, but we are able to apply her technique and features and evaluate the performance of her system over medical labels only. We also extend her approach by adding new types of features.</p><p>Other work on sentence classification has focused on rhetorical role classification, which aims at identifying the roles of sentences in text (e.g. Motivation, Result, etc.). Training and test data for this task is easy to obtain from structured scientific abstracts, which provide section headings. This approach has been used in many supervised systems <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref>. With respect to feature representations, previous work has relied mostly on contextual features, such as n-grams and words in specific locations. Heuristics derived from sequential features of abstracts, such as relative location of sentences and section headings have recently been explored <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. In terms of finding suitable machine learners, well-known machine learning techniques have been applied to the tasks, including Naïve Bayes (NB) <ref type="bibr" target="#b6">[7]</ref>, Support Vector Machines (SVM) <ref type="bibr" target="#b3">[4]</ref>, Hidden Markov Models (HMM) <ref type="bibr" target="#b13">[14]</ref>, and Conditional Random Fields (CRF) <ref type="bibr" target="#b3">[4]</ref>. Also, <ref type="bibr" target="#b11">[12]</ref> proposed a probability-based learner inspired by the sequence of abstracts.</p><p>Recent work by <ref type="bibr" target="#b14">[15]</ref> has shown the difficulty of identifying PICO elements in text, and has proposed a location-based information retrieval weighting strategy, motivated by the distribution of PICO elements. The authors also applied a weighting model based on the PICO information from the query, obtaining significant improvements from both approaches. However, their annotation of PICO tags was based on open text, disregarding sentence boundaries, which led to agreement problems between the annotators. Further, their classifier was built using the section headings of structured abstracts (e.g. Patients, Outcome', etc.) without human supervision, which could introduce noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>In this section we describe the construction of the corpus, the classifiers and features, and the experimental setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data collection</head><p>We extracted 1,000 abstracts from MEDLINE for annotation. Our focus was on medical research, and in order to extract relevant abstracts we used queries from two institutions that develop systematic reviews of the literature: The Global Evidence Mapping Initiative (GEM) <ref type="bibr" target="#b15">[16]</ref>, and The Agency for Healthcare Research and Quality (AHRQ) <ref type="bibr">[17]</ref>. GEM focuses on traumatic brain injury and spinal cord injury, and they provided the results of hand-constructed queries targeting diverse aspects of this subdomain. We randomly extracted 500 abstracts from a list of 74,000 query results for our annotation.</p><p>In order to diversify the contents of the corpus, the remaining 500 abstracts were randomly sampled from a set of AHRQ queries covering different medical issues (e.g. "Systematic Review of the Literature Regarding the Diagnosis of Sleep Apnoea").</p><p>Some of the abstracts used in our experiments (376 out of 1,000) are structured, which means that they contain section headings (e.g. Aim, Method, etc.). These headings are helpful in capturing the rhetorical structure of the text, and we use them as features (when available). See the abstract of this paper you are reading for an example of a structured abstract, and Figure <ref type="figure" target="#fig_0">1</ref> for an example of an unstructured abstract.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Annotation</head><p>In order to define our tagset we first adopted the 7-way annotation scheme presented in <ref type="bibr" target="#b16">[18]</ref>. (We thank the authors for kindly providing a sample of their data for our work, as well as initial definitions for semantic tags.) After analysing this data, we decided to drop two of their categories ("Statistics" and "Supposition") because their work showed significant agreement problems on those classes. We also decided to add the category Study Design, based on feedback by medical experts at GEM on the utility of this category. Thus, our annotation categories are as follows:</p><p>• Background: Material that informs and may place the current study in perspective, e.g. work that preceded the current; information about disease prevalence; etc;</p><p>• Population: The group of individual persons, objects, or items comprising the study's sample, or from which the sample was taken for statistical measurement; • Intervention: The act of interfering with a condition to modify it or with a process to change its course (includes prevention);</p><p>• Outcome: The sentence(s) that best summarizes the consequences of an intervention;</p><p>• Study Design: The type of study that is described in the abstract;</p><p>• Other: Any sentence not falling into one of the other categories and presumed to provide little help with clinical decision making, i.e. non-key or irrelevant sentences.</p><p>The 1,000 abstracts were annotated by a medical student over 80 hours, with the continuous collaboration of a senior medical expert. Each sentence could be annotated with multiple classes. In order to make annotation easier, we built the "Annotex" tool, which provides an interface to the sentence-segmented corpus. A screenshot of the tool interface is shown in Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>In order to measure agreement, 60 of the abstracts were blindly annotated by one of the authors, and Cohen's kappa was calculated. The original annotation was not changed in any case. The averaged score over all classes was 0.62, which indicates "substantial agreement" <ref type="bibr" target="#b17">[19]</ref>. The kappa values for the different classes are given in Table <ref type="table" target="#tab_0">1</ref>. The table shows that most classes have good agreement scores, and only Study Design seems problematic. This annotated data is available for further research, and can be obtained by emailing the contact author.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conditional random fields</head><p>Our sentence-classifier uses Conditional Random Fields (CRFs) <ref type="bibr" target="#b4">[5]</ref> for the learning algorithm. CRFs provide a discriminative framework for building structured models to segment and label sequence data. CRFs are undirected graphical models in which each vertex represents a random variable whose distribution is to be inferred, and each edge represents a dependency between two random variables. In our case the sentences in an abstract are represented by vertices, and the edges represent the relationship between sentences. CRFs have the advantage that they both model sequential effects and support the use of a large number of features; they have also been shown to perform comparatively well in other sentence-classification tasks <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>.</p><p>In our implementation, we use the Mallet package <ref type="bibr" target="#b18">[20]</ref>, applying the Gaussian prior given in the default setting for all our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Features</head><p>We trained our classifier with four sets of features that we describe in turn; some of these features are novel for this kind of task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lexical information</head><p>Collocational information, such as surrounding bag-ofwords (BOW), is a simple and effective way to capture the semantic similarity between two texts. We extend this idea by also using bigrams, which consist of all consecutive pairs of terms present in the sentence. We also utilise the POS (Part-of-Speech) information of the tokens in the BOW and bigram representations-we used the CPAN module Lingua::EN::Tagger as our POStagger.</p><p>BOW features have been extensively used for sentence classification <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11]</ref>. More specifically, <ref type="bibr" target="#b3">[4]</ref> applied POS tags in the same way as we do. However bigrams have not previously been applied to this kind of task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic information</head><p>We extend our feature set by using the Metathesaurus from the Unified Medical Language System (UMLS) <ref type="bibr" target="#b19">[21]</ref>, which provides a set of ontologies for the biomedical domain with semantic relationships between terms (e.g. synonyms and hypernyms). We use this resource in two ways: (i) directly querying the thesaurus for each token in the input, and (ii) parsing each sentence with the MetaMap analyser <ref type="bibr" target="#b7">[8]</ref>. As a result we obtain Concept Unique Identifiers (CUIs), which map the text into the ontological concepts. This allows us to identify connections between different word forms of the same concept. For instance, the terms "disease" and "disorder" are listed under the same CUI in the UMLS, and this connection is potentially useful for measuring text similarity.</p><p>We use the extracted CUIs to define our main semantic features: Token-CUI and MetaMap-CUI. For the token approach, we expand this representation by extracting the synonym list for each CUI. We then use these new terms directly, or broken down into single terms (in case of multiword terms). This last feature is motivated by <ref type="bibr" target="#b20">[22]</ref>, who showed improved document classification results after breaking down multiwords for partial matches. In summary, we use the following four types of semantic features:</p><p>• Token-CUI: Concept identifiers (CUIs) extracted from direct queries.</p><p>• Token-Syn: Synonyms of each token in the sentence.</p><p>• Token-Syn-B: Synonyms in break-down form for each token.</p><p>• MetaMap-CUI: CUIs extracted from MetaMap. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structural information</head><p>Previous work has found that the position of a sentence in an abstract can be important for its semantic classification <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b10">11]</ref>. For example, we expect that sentences related to Aim or Motivation will tend to occur at the beginning of an abstract, while those related to Result, Discussion or Conclusion will appear closer to the end. Thus, one of our structural features reflects the position of sentences from the beginning of the abstract.</p><p>Our other structural feature is obtained from section headings (when available). Section heading capture the rhetorical structure of the text, with tags such as Conclusions. These headings split the abstract into thematic parts, and we rely on the heading tag as a feature to represent all the sentences below the given heading. We explore two types of heading-based features: (i) the heading string is used without modification; and (ii) we map each heading string into one of four main rhetorical rolesnamely, Aim, Method, Results, Conclusions which have been used previously <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b10">11]</ref>. We rely on regular expressions to identify section headings, and on manual mapping of the different forms into the four main roles. We apply the same high-precision regular expression as used in <ref type="bibr" target="#b2">[3]</ref>, and manually map the different types of headings into the four rhetorical roles. Apart from feature engineering, previous work has mapped section headings for the purpose of building annotated corpora <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b21">23]</ref>; however, we use these headings only for feature representation. Heading features are only available for structured abstracts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sequential information</head><p>Sequential features leverage dependencies between different sentences in the text. For example, sentences for a particular subtopic (e.g. Background) typically occur sequentially as a group, and do not tend to repeat in later context. In addition, a subtopic in the ith sentence can be understood by analysing subtopics in preceding sentences from the abstract.</p><p>In order to model these dependencies we designed two types of features: direct and indirect dependencies. Direct dependencies use the labels of previous sentences, which are obtained by relying on the CRF trained on other types of features. Indirect dependency features are simply obtained by attaching the features of previous sentences to the target one. Regarding the number of sentences, for direct features we explore the use of window-sizes of 1, 3, and all previous sentences; for indirect features we test the results with 1, 2, or 3 previous sentences.</p><p>Sequential features may seem redundant when using sequential classifiers, but previous work has demonstrated good performance for these features for related classification tasks. For example, <ref type="bibr" target="#b22">[24]</ref> used indirect features for dialogue act classification, while <ref type="bibr" target="#b23">[25]</ref> described a method for classifying semantic labels of posts in web forum data as well as determining the links between posts.</p><p>In the medical domain, previous classification work has applied indirect dependency features <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, but not direct dependency ones. To facilitate comparison with the results from <ref type="bibr" target="#b3">[4]</ref>, we will also experiment with windowed features, which are features drawn from the previous and following sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental setting</head><p>For our experiments we split the corpus of 1,000 abstracts into two sets: structured abstracts (S) and unstructured abstracts (U). The statistics of these two sets are given in Table <ref type="table" target="#tab_1">2</ref>. We also distinguish between two types of classification tasks: (1) 6-way to classify both key sentences with the semantic labels and nonkey sentences with Other; and (2) 5-way to label key sentences only. Most related work has ignored irrelevant sentences in abstracts, considering only those sentences mapped to categories of interest <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>; by performing 5way classification we can compare to some degree our performance to previous work.</p><p>Thus, we have four groups of experiments. Note that in all performance tables over our dataset the results will be shown over these four groups. For each dataset we use 10-fold cross-validation, and measure microaveraged precision, recall, and f-score. Precision is given for each class by the number of true positives divided by the total number of elements predicted as belonging to the class. To obtain recall we divide the true positives by the total number of elements that actually belong to the class in the test data. We calculate the micro-average for all classes by combining the results of each test instance, as opposed to averaging the results of the classes (macro-average). The f-score gives us the harmonic mean of precision and recall.</p><p>Finally, as an external corpus for evaluation, we use the small dataset from <ref type="bibr" target="#b16">[18]</ref> (kindly provided by the authors), which consists of 100 abstracts (51 of them structured). As discussed in Section , this dataset uses a slightly different tagset to the one we have been using. Hence, for our final experiments, the classes "Statistics", "Supposition", and Study Design were mapped into Other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>In this section, we first evaluate the performance of a benchmark system, which uses features that have been previously explored in the literature. We then analyse the different feature sets described earlier (lexical, semantic, structural, and sequential) in turn. Finally, we evaluate our system over an external dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmark system</head><p>As our benchmark system, we measure the performance of the system from <ref type="bibr" target="#b3">[4]</ref> over our dataset. We were able to partially replicate that system by using the same tool and parameters (Mallet), and similar features. The features consist of word features (unigrams with their POS), positional information, section headings, and windowed features (features from the previous and following sentence). The difference from the experiments described in <ref type="bibr" target="#b3">[4]</ref> is that we do not perform the term normalisation step, and we applied a different POS tagger.</p><p>The results given in Table <ref type="table" target="#tab_2">3</ref> compare the use of different sets of features over our dataset. We can see that recall tends to be lower than precision, but the differences are not large: this is due to the fact that most target sentences have unique labels. We henceforth use f-score to compare the different approaches. Regarding the type of data, we see that classification over the structured abstracts clearly outperforms classification over unstructured ones. Even without using section headings, structured abstracts are better suited to our classification task. As we would expect, the results for 5-way classification are much better than for 6-way classification. Overall, the best results are obtained by using all the features for structured data, and ignoring windowed features for unstructured data. We will compare the rest of our results to the best benchmark configurations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adding lexical and semantic information</head><p>We first evaluate the use of features independently in Table <ref type="table" target="#tab_3">4</ref>. The top section of the table presents the results of the lexical features, and we can see that unigrams perform better than bigrams, which suffer from data sparseness. The performance of semantic features (in the bottom section) is lower than for unigrams; the extra effort to extract these features does not pay off. The reasons for the low performances seem to be the sparseness of the terms found by token-querying, and the ambiguity in the MetaMap output. From our experiments we conclude that these semantic resources directly (without tuning or filtering) do not contribute positively to the task. Overall, the results using lexical and semantic features individually are lower than the benchmark.</p><p>The performance for selected combinations of features are given in Table <ref type="table" target="#tab_7">5</ref>; we focus on combinations using unigrams with POS, which seems to provide the most robust configuration over these feature types. Overall, we do not see any significant performance improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adding structural information</head><p>Table <ref type="table" target="#tab_4">6</ref> shows the performance after structural information is added to unigrams with POS. These features produce a significant gain over the lexical and semantic features, achieving higher performance than the benchmark system: performance over structured abstracts is close to 80% f-score for 6-way classification, and close to 90% f-score for 5-way classification. For unstructured abstracts, using the position feature results in significantly improved performance over the use of lexical and semantic features alone. This indicates the importance of structural information to our task.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adding sequential information</head><p>For sequential information, we use previous sentences to inform the classifier. Our motivation is to measure whether explicitly adding sequential features is able to improve over the standard use of CRF. We combine this information with a basic set (B) of features, consisting of the following: unigrams with POS, position and section headings (for structured abstracts only). Since the labels of these sentences are not known, we follow two approaches:</p><p>• Direct approach: we use predictions of the labels of previous sentences by classifying them with a base learner. As features for the base classifier we also use the basic set B described above.</p><p>• Indirect approach: we use the features of the previous sentences as indirect indicators of their label. For simplicity, we use unigrams with POS, and add these features to the target sentence representation.</p><p>The results for the indirect approach are given in Table <ref type="table" target="#tab_5">7</ref>, together with the benchmark system. These features do not improve results over structured abstracts, but there are clear gains over the unstructured set, as large as 2.9% for 6-way classification. Even though sequential features may seem redundant when applying a sequential classifier, the results over unstructured data show that the extra information contributes to improved performance. Since unstructured abstracts cannot benefit from the main structural features, we conclude that the indirect approach is an effective way to close the gap in performance between the two types of abstracts.</p><p>Our next experiment uses the predicted tags of previous sentences as features for the target sentence (direct approach). We show the results using different window sizes in Table <ref type="table" target="#tab_6">8</ref>. In this case the performance gains over unstructured abstracts are not so clear, and the gains over structured abstracts are minimal. This suggests that the effort to build this architecture does not lead to improved performance due to the accumulation of errors, and that the indirect approach is a better strategy.</p><p>For this feature set we also present the results by class. In Table <ref type="table" target="#tab_11">9</ref> we show the results for the best configurations from the direct and indirect experiments. The results illustrate that our Outcome and Background predictors are able to perform well, but the other classes exhibit lower f-score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation over external dataset</head><p>For external evaluation, we used the dataset from <ref type="bibr" target="#b16">[18]</ref> to evaluate our classifiers. In this case the class Study Design is mapped into Other, and we build classifiers for 4-way and 5-way classification. The results are given in Table <ref type="table" target="#tab_8">10</ref>. The performance for the 5-way classifier is low, and only for structured abstracts are we able to reach 60% f-score. The results are better for 4-way classification (without Other), where the performances over structured and unstructured abstracts are similar, in the 70%-80% range.</p><p>We also provide the results per class using our best classifiers; in Table <ref type="table" target="#tab_9">11</ref> we see that our Outcome predictions perform well, but not those for other classes. These scores demonstrate significant disagreement    between annotators for the classes Intervention, Background, and Population; further analysis would be required in order to find the reasons for these large discrepancies. <ref type="bibr" target="#b16">[18]</ref> also reported difficulty in obtaining high agreement in the annotation, with Outcome being the most reliable class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Error analysis</head><p>In this section we analyse the confusion matrices of different experiments to identify the main sources of error.</p><p>Table <ref type="table" target="#tab_10">12</ref> shows the confusion matrix for our best-performing system over structured abstracts in cross-validation for 6-way classification. Each cell i, j in the matrix represents the number of cases where the gold-standard class i has been predicted as j. We can see that the main sources of error are: the prediction of Outcome instead of Other (155 errors, 15% of the total); and the prediction of Other for Intervention (132 errors, 13% of the total). The matrix also illustrates the difficulty of classifying Intervention, which only obtains 41 correct predictions.</p><p>The confusion matrix for unstructured abstracts is shown in Table <ref type="table" target="#tab_2">13</ref>. We see that there is a higher proportion of errors, and that the main errors are different than for structured abstracts. In unstructured abstracts, the classes Background and Outcome are the most confused: 496 errors (23% of the total) when Outcome is the goldstandard label, and 272 errors (13% of the total) when Background is the goldstandard label. This seems to indicate that the structure from the abstracts is particularly helpful in avoiding these types of errors. The label Other is also responsible for a high proportion of errors, being confused with Outcome 245 times (12% of the total).</p><p>The results over our dataset show that the label Other is problematic. We manually analysed a sample of sentences annotated as Other, and found that a large proportion could be classified as special cases of the other labels. There were sentences referring to preparation for an intervention, or supporting treatments, that could be tagged as Intervention. Another group of sentences refers to the setting of the study (e.g., type of measurement applied), and these could be classified as a different label, or under Background. Finally, another set of sentences contain speculative content, which could be labelled as Outcome, or under a new label. Further study of these labels could provide insight for a more robust classifier. We also extracted the confusion matrix for the predictions when testing over the dataset from <ref type="bibr" target="#b16">[18]</ref>     (after training the classifier over our 1,000 abstracts). We show this information for 5-way classification in Table <ref type="table" target="#tab_3">14</ref>. We can see that most of the errors occur when our classifier predicts Background in place of the gold-standard class Other (74, 35% of the total). This indicates that the annotation of Background is particularly difficult, and the line between useful background knowledge and less relevant content is hard to define. The other main source of error is the prediction of Outcome in place of the gold-standard Other (53, 25% of the total). The matrix also shows the sparsity of the use of Intervention and Population, which only receive 8 and 13 correct predictions respectively. Finally, Table <ref type="table" target="#tab_7">15</ref> shows the confusion matrix for unstructured abstracts over the <ref type="bibr" target="#b16">[18]</ref> dataset. As for structured abstracts, the main source of error is the prediction of Background in place of the goldstandard Other (134 errors, 54% of the total), and the prediction of Outcome instead of Other (71 errors, 29% of the total).</p><p>The error analysis of the predictions over the external dataset illustrates that the annotators seem to have followed different guidelines. There is a large set of Other sentences in the external dataset that are misclassified, and this could be due to the tendency in the external data to annotate only the most salient sentences as evidence for a particular label, ignoring supporting sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>We have explored classification of sentences in abstracts with medical tags. Unlike previous work, we identify both irrelevant sentences and the semantic tags of relevant sentences using supervised techniques. We evaluated the performance of a variety of feature configurations over different sets of data, including an external corpus.</p><p>Our results for 5-way classification (which excludes the Other label) compare to the state of the art. The numbers are high for structured abstracts (89% f-score), but significantly lower for unstructured abstracts (74% fscore). However, for the latter we improve on the results of the benchmark system by 3.2% . The results for unstructured abstracts also demonstrate the difficulty of dealing with this kind of data, which has not been previously evaluated for this task. In the breakdown of the results per class, we see large differences in performance depending on the category, with Outcome showing strong performance, and Intervention and Study Design the weakest performance.</p><p>The 6-way classification task has not been previously explored using supervised approaches, and most work disregards irrelevant sentences. An exception is <ref type="bibr" target="#b6">[7]</ref>, which uses a small dataset for training an Outcome classifier, and utilises rule-based classifiers for the rest. In our experiments we can see that this is a very challenging task, particularly for unstructured abstracts, for which the f-score drops to 66.9%. Again, the application of our feature set is able to improve over the benchmark system, but the performance is much lower than for the 5-way task. We observed that sentences labelled as Other may have a large overlap with other labels, and further analysis of the annotation would be important in future work. Classification over the external dataset shows a drop in performance, and only for the category Outcome do we achieve good results. The cross-annotation of the other categories has proved problematic for the dataset from <ref type="bibr" target="#b16">[18]</ref>, and we need to further explore whether this is due to discrepancies in the annotations or the different domains of the training and test data.</p><p>With respect to the feature analysis, overall the bestperforming features we used for our task were those based on unigrams, section headings, and sequential information from preceding sentences. Use of these Table <ref type="table" target="#tab_3">14</ref> Confusion matrix when testing over dataset from <ref type="bibr" target="#b16">[18]</ref> for structured abstracts features led to clear improvement over the simple BOW approach, and outperform feature sets used in previous work.</p><p>For future work, our aim is to improve our performance over unstructured abstracts with the aid of information from structured abstracts. We also plan to further analyse the annotated corpus, and in particular the sentences annotated as Other, to develop a more robust system. Finally, we plan to apply our classifier to an external application, such as improving performance of information retrieval against PICO criteria.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>Figure 1 Annotex interface for the annotation of sentences.</figDesc><graphic coords="3,62.92,418.25,470.02,293.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Kappa values per class</figDesc><table><row><cell>Class</cell><cell>Kappa</cell></row><row><cell>Background</cell><cell>0.70</cell></row><row><cell>Intervention</cell><cell>0.61</cell></row><row><cell>Other</cell><cell>0.67</cell></row><row><cell>Outcome</cell><cell>0.71</cell></row><row><cell>Population</cell><cell>0.63</cell></row><row><cell>Study Design</cell><cell>0.41</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="3">Number of abstracts and sentences for</cell><cell></cell></row><row><cell cols="3">Structured (S) and Unstructured (U) abstract sets,</cell><cell></cell></row><row><cell cols="2">including number of sentences per class</cell><cell></cell><cell></cell></row><row><cell></cell><cell>All</cell><cell>S</cell><cell>U</cell></row><row><cell># Abstracts</cell><cell>1000</cell><cell>376</cell><cell>624</cell></row><row><cell># Sentences</cell><cell>10379</cell><cell>4774</cell><cell>5605</cell></row><row><cell>-Background</cell><cell>2557</cell><cell>669</cell><cell>1888</cell></row><row><cell>-Intervention</cell><cell>690</cell><cell>313</cell><cell>377</cell></row><row><cell>-Outcome</cell><cell>4523</cell><cell>2240</cell><cell>2283</cell></row><row><cell>-Population</cell><cell>812</cell><cell>369</cell><cell>443</cell></row><row><cell>-Study Design</cell><cell>233</cell><cell>149</cell><cell>84</cell></row><row><cell>-Other</cell><cell>1564</cell><cell>1034</cell><cell>530</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 F</head><label>3</label><figDesc>-scores for the benchmark system based on<ref type="bibr" target="#b3">[4]</ref>. 1.P: unigrams with POS, Pst: position, W: windowed features, Sec: section headings. Best results per column are given in bold</figDesc><table><row><cell>Feature</cell><cell></cell><cell></cell><cell>6-way</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">5-way</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>S</cell><cell></cell><cell></cell><cell>U</cell><cell></cell><cell></cell><cell>S</cell><cell></cell><cell></cell><cell>U</cell><cell></cell></row><row><cell></cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell></row><row><cell>1.P+Pst</cell><cell>75.11</cell><cell>71.49</cell><cell>73.26</cell><cell>66.24</cell><cell>61.93</cell><cell>64.01</cell><cell>86.38</cell><cell>81.07</cell><cell>83.64</cell><cell>73.63</cell><cell>68.33</cell><cell>70.88</cell></row><row><cell>1.P+Pst+W</cell><cell>72.40</cell><cell>68.91</cell><cell>70.62</cell><cell>64.14</cell><cell>59.96</cell><cell>61.98</cell><cell>85.07</cell><cell>79.84</cell><cell>82.37</cell><cell>72.61</cell><cell>67.39</cell><cell>69.90</cell></row><row><cell>1.P+Pst+Sec+W</cell><cell>79.45</cell><cell>75.62</cell><cell>77.48</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>90.37</cell><cell>84.81</cell><cell>87.50</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 F</head><label>4</label><figDesc>-scores using lexical and semantic Information for 6-way and 5-way classification</figDesc><table><row><cell>Feature</cell><cell>6-way</cell><cell></cell><cell>5-way</cell><cell></cell></row><row><cell></cell><cell>S</cell><cell>U</cell><cell>S</cell><cell>U</cell></row><row><cell>1.P</cell><cell>70.42</cell><cell>60.82</cell><cell>81.68</cell><cell>68.51</cell></row><row><cell>2.P</cell><cell>47.50</cell><cell>44.19</cell><cell>59.09</cell><cell>49.61</cell></row><row><cell>Token-CUI</cell><cell>66.19</cell><cell>59.47</cell><cell>78.26</cell><cell>65.57</cell></row><row><cell>Token-Syn</cell><cell>64.13</cell><cell>58.79</cell><cell>76.77</cell><cell>65.47</cell></row><row><cell>Token-Syn-B</cell><cell>65.25</cell><cell>59.94</cell><cell>77.43</cell><cell>66.22</cell></row><row><cell>MetaMap-CUI</cell><cell>56.08</cell><cell>52.23</cell><cell>64.58</cell><cell>56.58</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 F</head><label>6</label><figDesc>-scores using Structural Information</figDesc><table><row><cell>Feature</cell><cell>6-way</cell><cell></cell><cell>5-way</cell><cell></cell></row><row><cell></cell><cell>S</cell><cell>U</cell><cell>S</cell><cell>U</cell></row><row><cell>1.P+Pst</cell><cell>73.26</cell><cell>64.01</cell><cell>83.64</cell><cell>70.88</cell></row><row><cell>1.P+Sec</cell><cell>79.22</cell><cell>-</cell><cell>88.88</cell><cell>-</cell></row><row><cell>1.P+Sec M</cell><cell>76.95</cell><cell>-</cell><cell>87.48</cell><cell>-</cell></row><row><cell>1.P+Pst+Sec</cell><cell>79.67</cell><cell>-</cell><cell>89.19</cell><cell>-</cell></row><row><cell>1.P+Pst+Sec M</cell><cell>78.45</cell><cell>-</cell><cell>88.55</cell><cell>-</cell></row></table><note><p>1.P: Unigrams with POS, Pst: Position, Sec: Section heading, Sec M : Section heading with mapping. Best results per column are given in bold.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7 F</head><label>7</label><figDesc>-scores using 1 to 3 previous sentences (Indirect)</figDesc><table><row><cell>Feature</cell><cell>6-way</cell><cell></cell><cell></cell><cell>5-way</cell></row><row><cell></cell><cell>S</cell><cell>U</cell><cell>S</cell><cell>U</cell></row><row><cell>B+1 Prev. Sen.</cell><cell>79.09</cell><cell>65.06</cell><cell>88.33</cell><cell>71.80</cell></row><row><cell>B+2 Prev. Sen.</cell><cell>77.53</cell><cell>66.30</cell><cell>88.33</cell><cell>73.64</cell></row><row><cell>B+3 Prev. Sen.</cell><cell>76.75</cell><cell>66.94</cell><cell>88.03</cell><cell>74.03</cell></row><row><cell>B+Window</cell><cell>77.48</cell><cell>61.98</cell><cell>87.50</cell><cell>69.90</cell></row><row><cell cols="5">B: base features, Window: features in previous and posterior sentence. Best</cell></row><row><cell cols="3">performance per column is given in bold.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8 F</head><label>8</label><figDesc>-scores using previous labels (Direct)</figDesc><table><row><cell>Feature</cell><cell>6-way</cell><cell></cell><cell>5-way</cell><cell></cell></row><row><cell></cell><cell>S</cell><cell>U</cell><cell>S</cell><cell>U</cell></row><row><cell>B+1 Prev. Label</cell><cell>79.85</cell><cell>63.64</cell><cell>89.24</cell><cell>71.15</cell></row><row><cell>B+3 Prev Labels</cell><cell>80.88</cell><cell>63.57</cell><cell>89.32</cell><cell>71.54</cell></row><row><cell>B+All Prev Labels</cell><cell>79.48</cell><cell>64.66</cell><cell>88.11</cell><cell>71.50</cell></row></table><note><p>B: base features. Best performance per column is given in bold.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 F</head><label>5</label><figDesc>-scores of Combining Lexical and Semantic Information</figDesc><table><row><cell>Feature</cell><cell>6-way</cell><cell></cell><cell>5-way</cell><cell></cell></row><row><cell></cell><cell>S</cell><cell>U</cell><cell>S</cell><cell>U</cell></row><row><cell>1.P+2.P</cell><cell>67.87</cell><cell>60.53</cell><cell>81.10</cell><cell>68.47</cell></row><row><cell>1.P+T-CUI</cell><cell>67.83</cell><cell>61.01</cell><cell>79.94</cell><cell>67.41</cell></row><row><cell>1.P+T-Syn</cell><cell>66.13</cell><cell>59.79</cell><cell>78.26</cell><cell>67.39</cell></row><row><cell>1.P+T-Syn-B</cell><cell>67.03</cell><cell>61.24</cell><cell>79.09</cell><cell>68.51</cell></row><row><cell>1.P+T-CUI+T-Syn</cell><cell>65.89</cell><cell>60.23</cell><cell>77.85</cell><cell>66.82</cell></row><row><cell>1.P+T-CUI+T-Syn-B</cell><cell>66.82</cell><cell>61.28</cell><cell>78.90</cell><cell>68.27</cell></row><row><cell cols="5">1.P: unigrams with POS, 2.P: bigrams with POS, T: Token, CUI: UMLS tag, Syn:</cell></row><row><cell cols="5">expansion with synonyms, Syn-B: synonyms in break-down form. Best results</cell></row><row><cell cols="2">per column are given in bold.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 10 F</head><label>10</label><figDesc>-scores over dataset from<ref type="bibr" target="#b16">[18]</ref> </figDesc><table><row><cell>Feature</cell><cell>5-way</cell><cell></cell><cell>4-way</cell><cell></cell></row><row><cell></cell><cell>S</cell><cell>U</cell><cell>S</cell><cell>U</cell></row><row><cell></cell><cell cols="2">Lexical &amp; Structural</cell><cell></cell><cell></cell></row><row><cell>1.P</cell><cell>55.12</cell><cell>37.10</cell><cell>76.90</cell><cell>76.32</cell></row><row><cell>1.P+Pst</cell><cell>57.80</cell><cell>38.53</cell><cell>78.04</cell><cell>72.82</cell></row><row><cell>1.P+Pst+Sec</cell><cell>62.83</cell><cell>-</cell><cell>83.81</cell><cell>-</cell></row><row><cell></cell><cell cols="2">Sequential (indirect)</cell><cell></cell><cell></cell></row><row><cell>1.P+Pst+W</cell><cell>56.06</cell><cell>38.76</cell><cell>75.26</cell><cell>72.82</cell></row><row><cell>1.P+Pst+Sec+W</cell><cell>61.57</cell><cell>-</cell><cell>81.85</cell><cell>-</cell></row><row><cell>B+1 Prev. Sen.</cell><cell>62.36</cell><cell>41.38</cell><cell>83.84</cell><cell>75.20</cell></row><row><cell>B+2 Prev. Sen.</cell><cell>61.26</cell><cell>37.81</cell><cell>82.26</cell><cell>72.78</cell></row><row><cell>B+3 Prev. Sen.</cell><cell>60.16</cell><cell>37.81</cell><cell>82.20</cell><cell>75.27</cell></row><row><cell></cell><cell cols="2">Sequential (direct)</cell><cell></cell><cell></cell></row><row><cell>B+1 Prev. Label</cell><cell>63.15</cell><cell>37.57</cell><cell>81.93</cell><cell>79.21</cell></row><row><cell>B+3 Prev. Label</cell><cell>63.15</cell><cell>36.39</cell><cell>77.72</cell><cell>76.98</cell></row><row><cell>B+All Prev. Labels</cell><cell>62.05</cell><cell>37.10</cell><cell>82.67</cell><cell>78.26</cell></row></table><note><p>1.P: unigrams with POS, Pst: position, W: windowed features, Sec: section headings, B: base features. Best results per column are given in bold.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 11 F</head><label>11</label><figDesc>-scores per class over dataset from<ref type="bibr" target="#b16">[18]</ref> </figDesc><table><row><cell>Feature</cell><cell>5-way</cell><cell></cell><cell>4-way</cell><cell></cell></row><row><cell></cell><cell>S</cell><cell>U</cell><cell>S</cell><cell>U</cell></row><row><cell>Background</cell><cell>56.18</cell><cell>15.67</cell><cell>77.27</cell><cell>37.50</cell></row><row><cell>Intervention</cell><cell>15.38</cell><cell>28.57</cell><cell>28.17</cell><cell>8.33</cell></row><row><cell>Outcome</cell><cell>81.34</cell><cell>60.45</cell><cell>90.50</cell><cell>78.77</cell></row><row><cell>Population</cell><cell>35.62</cell><cell>28.07</cell><cell>42.86</cell><cell>28.57</cell></row><row><cell>Other</cell><cell>46.32</cell><cell>15.77</cell><cell>-</cell><cell>-</cell></row><row><cell cols="5">For each of the two tasks (5-way, 6-way) the best feature set is applied. Best</cell></row><row><cell cols="2">results per column are given in bold.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 12</head><label>12</label><figDesc>Confusion matrix over structured abstracts</figDesc><table><row><cell>Class</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Prediction</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>B</cell><cell>I</cell><cell>O</cell><cell>P</cell><cell>S</cell><cell>O t</cell></row><row><cell></cell><cell>B</cell><cell>561</cell><cell>4</cell><cell>43</cell><cell>8</cell><cell>2</cell><cell>51</cell></row><row><cell>G</cell><cell>I</cell><cell>27</cell><cell>41</cell><cell>48</cell><cell>60</cell><cell>5</cell><cell>132</cell></row><row><cell>o</cell><cell>O</cell><cell>6</cell><cell>1</cell><cell>2165</cell><cell>4</cell><cell>0</cell><cell>64</cell></row><row><cell>l</cell><cell>P</cell><cell>24</cell><cell>17</cell><cell>33</cell><cell>198</cell><cell>10</cell><cell>87</cell></row><row><cell>d</cell><cell>S</cell><cell>2 1</cell><cell>5</cell><cell>6</cell><cell>3 5</cell><cell>4 9</cell><cell>3 3</cell></row><row><cell></cell><cell>Ot</cell><cell>63</cell><cell>24</cell><cell>155</cell><cell>30</cell><cell>8</cell><cell>754</cell></row></table><note><p>B: Background, I: Intervention, O: Outcome, P: Population, S: Study Design, and Ot: Other.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 F</head><label>9</label><figDesc>-scores per class from systems based on sequential features (applying the best configurations for each data subset)</figDesc><table><row><cell>Feature</cell><cell>6-way</cell><cell></cell><cell>5-way</cell><cell></cell></row><row><cell></cell><cell>S</cell><cell>U</cell><cell>S</cell><cell>U</cell></row><row><cell>Background</cell><cell>81.84</cell><cell>68.46</cell><cell>87.92</cell><cell>74.67</cell></row><row><cell>Intervention</cell><cell>20.25</cell><cell>12.68</cell><cell>48.08</cell><cell>21.39</cell></row><row><cell>Outcome</cell><cell>92.32</cell><cell>72.94</cell><cell>96.03</cell><cell>80.51</cell></row><row><cell>Population</cell><cell>56.25</cell><cell>39.80</cell><cell>63.88</cell><cell>43.15</cell></row><row><cell>Study Design</cell><cell>43.95</cell><cell>4.40</cell><cell>47.44</cell><cell>8.60</cell></row><row><cell>Other</cell><cell>69.98</cell><cell>24.28</cell><cell>-</cell><cell>-</cell></row><row><cell cols="3">Best performance per column is given in bold.</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>1.P: unigrams with POS, 2.P: bigrams with POS, CUI: UMLS tag, Syn: expansion with synonyms, Syn-B: synonyms in break-down form. Best results per column are given in bold.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the medical researchers at The Global Evidence Mapping Initiative (GEM) for their help in understanding systematic reviews and the review process. We thank in particular Sarai Dee and Ornella Clavisi for their annotation work. We wish to thank Dina Demner-Fushman and her colleagues from the National Library of Medicine (NLM) for kindly providing an annotated dataset for our analysis and experimentation. Eric Huang built the Annotex tool that was used for the manual annotation. NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through the ICT Centre of Excellence program. This article has been published as part of BMC Bioinformatics Volume 12 Supplement 2, 2011: Fourth International Workshop on Data and Text Mining in Bioinformatics (DTMBio) 2010. The full contents of the supplement are available online at http://www.biomedcentral.com/1471-2105/12? issue=S2.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors declare that they have no competing interests.</p><p>Published: 29 March 2011</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The well-built clinical question: a key to evidence-based decisions</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nishikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Hayward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACP Journal Club</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="12" to="13" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The identification of clinically important elements within medical journal abstracts: Patient-population-problem, exposure-intervention, comparison, outcome, duration and results (PECODR)</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dawes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pluye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-N</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Informatics in Primary Care</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="16" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Identifying sections in scientific abstracts using conditional random fields</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hirohata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ishizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Joint Conference on Natural Language Processing Hyderabad</title>
		<meeting>the Third International Joint Conference on Natural Language Processing Hyderabad</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="381" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sentence retrieval for abstracts of randomized controlled trials</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Y</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Medical Informatics and Decision Making</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Introduction to conditional random fields for relational learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Introduction to Statistical Relational Learning</title>
		<imprint>
			<publisher>Lise Getoor and Ben Taskar</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="93" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Utilization of the PICO framework to improve searching pubmed for clinical questions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Schardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Keitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fontelo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Medical Informatics and Decision Making</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Answering clinical questions with knowledgebased and statistical techniques. Computational Linguistics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><forename type="middle">J</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="63" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMIA Annual Symposium Proceedings Washington DC</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semantic clustering of answers to clinical questions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMIA Annual Symposium Proceedings</title>
		<meeting><address><addrLine>Chicago, IL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="458" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Categorization of sentence types in medical abstracts</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mcknight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMIA Annual Symposium Proceedings Washington DC; 2003</title>
		<imprint>
			<biblScope unit="page" from="440" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using sectioning information for text retrieval: a case study with the medline abstracts</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shimbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2nd International Workshop on Active Mining Maebashi</title>
		<meeting>2nd International Workshop on Active Mining Maebashi<address><addrLine>Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="32" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bidirectional inference with the easiest-first strategy for tagging sequence data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing Vancouver</title>
		<meeting>Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing Vancouver</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="467" to="474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A study of structured clinical abstracts and the semantic classification of sentences</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Y</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Coiera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Workshop on BioNLP</title>
		<imprint>
			<biblScope unit="page" from="121" to="128" />
			<date type="published" when="2007">2007. 2007</date>
			<pubPlace>Prague</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An introduction to Hidden Markov Models</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B-H</forename><surname>Juang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE ASSP Magazine</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="16" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Clinical information retrieval using document and PICO structure</title>
		<author>
			<persName><forename type="first">F</forename><surname>Boudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dawes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics Los Angeles</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="822" to="830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<ptr target="http://www.evidencemap.org/" />
		<title level="m">Global Evidence Mapping Initiative</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Automatically identifying health outcome information in medline records</title>
		<author>
			<persName><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Few</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thoma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association (JAMIA)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="52" to="60" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The measurement of observer agreement in categorical data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">MALLET: A machine learning for language toolkit</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Mccallum</surname></persName>
		</author>
		<ptr target="http://mallet.cs.umass.edu" />
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The unified medical language system. Method of Information in Medicine</title>
		<author>
			<persName><forename type="first">Dab</forename><surname>Lindberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="281" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A study on automatically extracted keywords in text categorization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hulth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Megyesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics Sydney</title>
		<meeting>21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics Sydney</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="537" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards identifying intervention arms in randomized controlled trials: Extracting coordinating constructions</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Y</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="790" to="800" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning the structure of task-driven human-human dialogs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bangalore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Fabbrizio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics Sydney</title>
		<meeting>the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics Sydney</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="201" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Tagging and linking web forum posts</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fourteenth Conference on Computational Natural Language Learning</title>
		<imprint>
			<biblScope unit="page" from="192" to="202" />
			<date type="published" when="2010">2010</date>
			<pubPlace>Uppsala</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
