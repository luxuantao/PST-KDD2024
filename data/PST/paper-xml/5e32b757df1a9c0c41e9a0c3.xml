<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Software Engineering</orgName>
								<orgName type="institution">Swinburne University of Technology</orgName>
								<address>
									<postCode>3122</postCode>
									<settlement>Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education</orgName>
								<orgName type="institution">Xidian University</orgName>
								<address>
									<postCode>710071</postCode>
									<settlement>Shaanxi</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Electronics and Information</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<addrLine>ADD:127 West Youyi Road</addrLine>
									<postCode>710072</postCode>
									<settlement>Xi&apos;an Shaanxi</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A830139DE7F483600B91AB1ED7B7D47A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Self-regulated Evolutionary Multi-task Optimization</head><p>Xiaolong Zheng, A. K. Qin, Senior Member, IEEE, Maoguo Gong, Senior Member, IEEE, Deyun Zhou Abstract-Evolutionary multi-task optimization (EMTO) is a newly emerging research area in the field of evolutionary computation. It investigates how to solve multiple optimization problems (tasks) at the same time via evolutionary algorithms (EAs) to improve on the performance of solving each task independently, assuming if some component tasks are related then the useful knowledge (e.g., promising candidate solutions) acquired during the process of solving one task may assist in (and also benefit from) solving the other tasks. In EMTO, task relatedness is typically unknown in advance and needs to be captured via EA's population. Since the population of an EA can only cover a sub-region of the solution space and keeps evolving during the search, thus captured task relatedness is local and dynamic. The multifactorial EA (MFEA) is one of the most representative EMTO techniques, inspired by the biocultural model of multifactorial inheritance, which transmits both biological and cultural traits from the parents to the offspring. MFEA has succeeded in solving various MTO problems. However, the intensity of knowledge transfer in MFEA is determined via its algorithmic configuration without considering the degree of task relatedness, which may prevent the effective sharing and utilization of the useful knowledge acquired in related tasks. To address this issue, we propose a self-regulated EMTO (SREMTO) algorithm to automatically adapt the intensity of cross-task knowledge transfer to different and varying degrees of relatedness between different tasks as the search proceeds so that the useful knowledge in common for solving related tasks can be captured, shared and utilized to a great extent. We compare SREMTO with MFEA and its variants as well as the single-task optimization counterpart of SREMTO on two MTO test suites, which demonstrates the superiority of SREMTO.</p><p>Index Terms-Multi-task Optimization, Multitasking, Evolutionary Algorithm, Knowledge Transfer</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>M ULTI-TASK optimization (MTO) [1], [2] is a newly emerging research area in optimization, studying on how to solve multiple optimization problems (tasks) simultaneously to improve on the performance of solving each task independently. It works under an assumption that there exists some useful knowledge in common for solving related tasks so that the useful knowledge acquired during the process of solving one task may assist in solving another task if they are somehow related. In real-world applications, related optimization tasks are ubiquitous. For example, vehicle routing problems often contain a large number of problem instances, where many of them are closely related to each other in terms of problem description, solution space landscape and/or optimal solutions <ref type="bibr" target="#b2">[3]</ref>. Furthermore, nowadays versatile problem solvers tend to be provisioned as various services on the cloud. Suppose optimization is offered as cloud services, such services typically need to handle multiple requests of tackling similar optimization tasks by solving some (or all) of these tasks at the same time. Therefore, MTO has a great potential of becoming the next-generation mainstream optimization paradigm.</p><p>The MTO paradigm can accommodate different optimizers, resulting in different MTO algorithms. The earliest MTO algorithm is based on Bayesian optimization <ref type="bibr" target="#b0">[1]</ref>. Since then, evolutionary MTO (EMTO) algorithms have developed into the mainstream, characterized by utilizing evolutionary algorithms (EAs) as their optimizers. EAs stand for a family of population-based metaheuristic search techniques <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b5">[6]</ref>, which evolve a population of candidate solutions by applying various algorithmic operations inspired by the nature to seek the optima. EMTO intends to fully exploit the implicit parallelism of EAs in multitasking scenarios, where knowledge is implicitly carried by promising candidate solutions generated in the course of search. EMTO is often confused with evolutionary multi-objective optimization (EMOO). In fact, an EMOO problem contains only a single task which can be solved to generate a set of Pareto optimal solutions. In contrast, an EMTO problem contains multiple tasks (either single-objective <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b6">[7]</ref> or multi-objective <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>) which can be solved to simultaneously generate the optimal solution to each of these tasks. Therefore, EMTO and EMOO are fundamentally different in terms of their goals.</p><p>Since different pairs of component tasks in MTO may often have different degrees of task relatedness, solving one component task may assist in (and also benefit from) solving each of the other component tasks to a certain extent depending on the degree of task relatedness between them. Furthermore, in EMTO, task relatedness is usually explored and captured via the evolving population and thus becomes local and dynamic. Therefore, a desirable EMTO algorithm is expected to be able to adapt the intensity of cross-task knowledge transfer to different and varying degrees of relatedness between different tasks during the search. As such, the more (less) closely two tasks get related as the search proceeds, the more (less) intensively knowledge transfer between them happens and accordingly the more (less) heavily they may help each other. However, no existing EMTO algorithms can do this.</p><p>Motivated by this fact, we devise a self-regulated knowledge transfer scheme by extending the knowledge transfer scheme used in the multifactorial EA (MFEA). MFEA <ref type="bibr" target="#b1">[2]</ref> is one of the most representative EMTO algorithms, characterized by assortative mating and selective imitation which enable crosstask knowledge transfer in a controlled manner. Furthermore, we propose a self-regulated EMTO (SREMTO) algorithm by incorporating the devised self-regulated knowledge transfer scheme into MFEA's paradigm.</p><p>The proposed SREMTO algorithm involves a new concept of the ability vector which extends the concept of the skill factor used in MFEA by reflecting an individual's capability to resolve each component task instead of merely indicating the task on which an individual performs best (as the skill factor does). Based on this concept, we propose to create one task group for each component task via sampling the population in a probabilistic way based on the ability vector such that a population member can enter multiple task groups when it performs consistently well on these tasks as reflected by its ability vector. As such, when some tasks are related, there may exist some individuals which perform well on all these tasks and thus can be selected into each of the corresponding task groups. The more closely these tasks are related, the larger the number of such individuals exists and accordingly the heavier the degree of overlap between the corresponding task groups becomes. Therefore, the degree of overlap between task groups may reflect the relatedness between their corresponding tasks. By creating tasks groups in this way, different pairs of task groups may have different degrees of overlap, depending on the degree of relatedness between the corresponding tasks. At the beginning of each generation, all task groups will be recreated based on the current population so that the degree of overlap between any two task groups may change and adapt to varying degrees of task relatedness as the population evolves.</p><p>We propose to generate the offspring within each task group, independent of the offspring generation procedure in the other task groups. The cross-task knowledge transfer is enabled implicitly via the overlapping parts (i.e., common individuals) between task groups. In this way, the intensity of knowledge transfer becomes proportional to the degree of overlap between task groups and thus to the degree of task relatedness. In contrast to MFEA's assortative mating which uses a manually specified parameter to control cross-task knowledge transfer, the proposed offspring generation procedure does not rely on manual configuration to control knowledge transfer.</p><p>In addition to the offspring generation procedure which allows knowledge transfer from the aspect of the parents, we also propose an ability vector based offspring migration scheme to allow knowledge transfer from the aspect of the offspring. Specifically, we let a generated offspring to inherit the ability vector from either of its parents (as MFEA does) and propose to evaluate the quality of the offspring on multiple selected tasks at which the inherited ability vector indicates high competence. In this way, the offspring can compete for survival with respect to multiple tasks at which its parent has demonstrated high competence, where these tasks are selected in a probabilistic way based on the offspring's ability vector. In fact, when some tasks are more closely related, there may exist more individuals in the population with their ability vectors indicating high competence at these tasks. As a result, knowledge transfer in terms of the offspring becomes more intensive with the transfer intensity proportional to the degree of task relatedness.</p><p>After the offspring are generated and evaluated in the above described way with respect to each task group, the offspring generated from all task groups will compete with the individuals in the old population to produce the new population. Specifically, for each task, some individuals with the total number equal to the corresponding task group size are selected from the pool composed of both the offspring and the individuals in the old population via elitism-remained stochastic universal selection <ref type="bibr" target="#b9">[10]</ref> based on the factorial costs of all pool members on this task. The selected individuals for all tasks constitute the new population. After a new population is produced, the ability vector of each population member will be updated. The new population will then undergo the above process again for a generation to yield the next new population. The evolution process will continue generation by generation until some stopping criterion is met.</p><p>Compared to MFEA that enables knowledge transfer in a manually controlled manner via the skill factor based assortative mating and selective imitation, the proposed SREMTO can adapt the intensity of cross-task knowledge transfer to different and varying degrees of relatedness between different tasks as the search proceeds so that the useful knowledge in common for solving related tasks can be captured, shared and utilized to a great extent. In our experiments, we compare SREMTO with MFEA and its variants as well as the singletask optimization counterpart of SREMTO on two MTO test suites to demonstrate the superiority of SREMTO. We also analyze the self-regulated knowledge transfer scheme to gain an insight into its effectiveness.</p><p>The remaining paper is organized as follows. Section II describes the background of this work. The proposed SREMTO algorithm is detailed in Section III. Section IV reports and analyzes experimental results. The conclusions and future work are mentioned in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. MTO and EMTO</head><p>MTO <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref> is a newly emerging research area in the field of optimization, investigating how to effectively and efficiently solve multiple optimization problems (tasks) at the same time. In the multitasking scenario, solving one optimization problem may help solve other optimization problems because there often exists some useful knowledge in common for solving related tasks so that the useful knowledge acquired during the process of solving one task may assist in solving another task if these two tasks are somehow related. Given an MTO problem with k component tasks, without loss of generality, we assume all component tasks are single-objective, unconstrained minimization problems. The j-th task, denoted as T j , is supposed to have objective function f j : X j → , where X j denotes a D j -dimensional solution space and represents the domain of real numbers. The goal of MTO is to find the global optimum for each of the k component tasks, denoted by x o j = arg min x∈Xj f j (x), j = 1, • • • , k. Note that if certain constraints are imposed on the solution space of a specific component task, some constraint function(s) will be considered together with the objective function for that task. Furthermore, if the objective functions of the component tasks are multi-objective, MTO will solve multiple multi-objective optimization (MOO) problems.</p><p>The earliest work on MTO is based upon Bayesian optimization <ref type="bibr" target="#b0">[1]</ref> which builds (and iteratively updates) a model on some evaluated candidate solutions and uses this model to find the next most promising candidate solution to evaluate. Gupta et al. proposed an MFEA algorithm <ref type="bibr" target="#b1">[2]</ref> which performs multitasking via EAs by making full use of implicit parallelism featured by EAs. MFEA can be regarded as the pioneer work on EMTO which stands for the family of MTO techniques that utilize EAs as their optimizers. It will be detailed in the next section. Since the invention of MFEA, much research effort has been devoted into studying on EMTO techniques. For example, in terms of algorithmic improvements, Bali et al. <ref type="bibr" target="#b10">[11]</ref> proposed an enhanced MFEA with domain adaptation, named as LDA-MFEA, which derives linear transformations between the solution spaces of component tasks to pursuit high ordinal correlation between tasks in terms of the quality of population members and leverages these linear transformations to improve the quality of the generated offspring. Wen et al. <ref type="bibr" target="#b11">[12]</ref> proposed an MFEA with resource allocation, named as MFEARR, which can suppress ineffective cross-task knowledge transfer by using a newly designed survival rate of divergents (defined as the offspring generated by two parents with different skill factors) to reset parameter rmp in MFEA. Tang et al. <ref type="bibr" target="#b12">[13]</ref> proposed a group-based MFEA which groups the tasks of similar types and selectively transfers genetic information only within the groups. In addition to the works on algorithmic improvements, research effort has also been devoted into MTO frameworks. For example, Liaw et al. <ref type="bibr" target="#b13">[14]</ref> proposed an EMTO framework to achieve efficient multitasking through the adaptive control of knowledge transfer and selection of candidate solutions for evaluation from the offspring generated from all component tasks. Li et al. <ref type="bibr" target="#b14">[15]</ref> proposed a multi-population based EMTO framework, where each population addresses one unique optimization task and shares knowledge with the other populations via a newly designed mutation operator. Moreover, some researchers have focused on investigating the working principles of EMTO <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b17">[18]</ref>, analyzing and measuring task relatedness <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b18">[19]</ref>.</p><p>There also exist a large body of works on the applications of EMTO techniques to solve real-world problems. For example, Yuan et al. <ref type="bibr" target="#b19">[20]</ref> developed an improved MFEA algorithm to solve the MTO problem composed of the travelling salesman task, the quadratic assignment task, the linear ordering task, and the job-shop scheduling task. Zhou et al. <ref type="bibr" target="#b2">[3]</ref> proposed a permutation-based multi-task method for solving the multitasking of vehicle routing problems. Sampath et al. <ref type="bibr" target="#b20">[21]</ref> handled the multitasking of optimal power flow problems with different load demands on power systems. Sagarna et al. <ref type="bibr" target="#b21">[22]</ref> developed an EMTO approach to solve the multitasking of branch testing problems in software engineering. Bao et al. <ref type="bibr" target="#b22">[23]</ref> applied EMTO to solve cloud service composition problems.</p><p>In MTO, the degree of task relatedness has a great impact on the effectiveness of knowledge transfer. However, it is hard to measure task relatedness in a quantitative way, particularly when there exists no or little prior knowledge on the component tasks in an MTO problem to be solved, as typically faced by EMTO. One commonly used method <ref type="bibr" target="#b6">[7]</ref> to measure task relatedness for an MTO problem is to randomly sample the solution space, calculate the factorial costs and then factorial ranks of all samples with respect to each task, and compute inter-task similarity R s as Spearman's rank correlation coefficient <ref type="bibr" target="#b6">[7]</ref> for each task pair. This method typically requires a very large sample size, e.g., one million samples, to sample the solution space for the purpose of capturing the holistic profiles of all component tasks. It is worth noting that EMTO uses a population of individuals (samples) to implicitly explore and capture task relatedness which is thus local and dynamic because the evolving population will traverse the different subregions of the solution space as the search proceeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. MFEA</head><p>MFEA <ref type="bibr" target="#b1">[2]</ref> is the earliest EMTO algorithm which is inspired by the bio-cultural model of multifactorial inheritance, where the complex developmental features of the offspring will be formed via the interaction of genetic and cultural factors <ref type="bibr" target="#b23">[24]</ref>, i.e., both genetic and cultural transmissions will happen during the evolution of the creature. For example, in addition to genetic inheritance (like appearance), the habits and preferences of the parents will also influence the offspring.</p><p>MFEA creates a multitasking environment to evolve a single population of individuals for solving multiple tasks at the same time, where each task (with its own objective) contributes as a unique cultural factor to influence the evolution of the population. Different tasks may have different properties and thus may lead to the different representations of an individual. Accordingly, a unified representation is needed by which the solution spaces of all tasks can be easily encoded into the same representation for the purpose of search and decoded into their unique representations for the sake of evaluation. In MFEA, the unified representation is obtained via a random key approach <ref type="bibr" target="#b24">[25]</ref>, where each decision variable is encoded by a random key of its value between 0 and 1. For continuous optimization as focused in this work, encoding and decoding by using the random key approach are via linear mappings <ref type="bibr" target="#b1">[2]</ref>.</p><p>Given an MTO problem composed of k component tasks, MFEA employs a single population pop of n individuals, i.e., pop = {p i } n i=1 , to simultaneously search the global optimum for each of the k component tasks. To understand the key features of MFEA, we recap the following definitions in <ref type="bibr" target="#b1">[2]</ref>.</p><formula xml:id="formula_0">Definition 1. (Factorial Cost): The factorial cost Ψ j i of individual p i on task T j is defined as Ψ j i = λ•δ j i +f j i</formula><p>, where λ is the penalizing multiplier, and f j i and δ j i denote the objective function value and the total amount of constraint violations, respectively, of p i on task T j . Definition 2. (Factorial Rank): The factorial rank r j i of individual p i on task T j is the index of p i in the list of population members that have been sorted in ascending order with respect of their factorial costs. When multiple individuals have the same factorial costs, random tie-breaking is applied to resolve the parity. MFEA employes the skill factors of population members to implicitly partition the population into k non-overlapping task groups with each group focusing on a specific task denoted by the same skill factor associated with all its members. Based on that, it realizes knowledge transfer via two algorithmic modules, i.e., assortative mating and selective imitation <ref type="bibr" target="#b1">[2]</ref>, which operate in concert to allow knowledge transfer across different task groups. Specifically, assortative mating allows two individuals with different skill factors (and thus belonging to different task groups) to mate (via a crossover operation) under a certain probability which is controlled by an algorithmic parameter rmp, yielding two offspring. Each generated offspring then imitates either of the two parents by inheriting the skill factor of that parent and undergoing evaluation merely on the task corresponding to the inherited skill factor, which is what selective imitation does. Next, each offspring competes with the existing members of the task group denoted by its inherited skill factor to pursue entering that task group. By leveraging these two algorithmic modules, MFEA enables cross-task knowledge transfer in a controlled way from the aspects of both the parents and the offspring. The details of MFEA can be referred to <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. THE PROPOSED METHOD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Motivations</head><p>In MTO, different pairs of component tasks may have different degrees of task relatedness. Accordingly, one component task may assist in (and also benefit from) each of the other component tasks to a certain extent depending on the degree of task relatedness between them. Furthermore, in EMTO, task relatedness is usually explored and captured via the evolving population and thus becomes local and dynamic. Therefore, a desirable EMTO algorithm should be able to adapt the intensity of cross-task knowledge transfer to different and varying degrees of relatedness between different tasks during the search. As such, the more (less) closely two tasks get related as the search proceeds, the more (less) intensively knowledge transfer between them happens and accordingly the more (less) heavily they may help each other. To the best of our knowledge, no existing EMTO algorithms can do this. Although MFEA's knowledge transfer scheme has demonstrated effectiveness in a variety of applications, it has some inherent drawbacks. Firstly, the definition of the skill factor restricts the contribution of each population member to population evolution only via the task group denoted by its skill factor. Thus, even if a population member performs well on multiple tasks, which typically occurs when some tasks are closely related, it is not allowed to generate offspring as a parent for all these tasks and also the offspring generated from it is not allowed to compete for survival with respect to all these tasks. As a result, provided some tasks are closely related, the expected high intensity of knowledge transfer between them will be undesirably suppressed. Secondly, the crosstask knowledge transfer enabled via the crossover operation is controlled by a manually-specified parameter which is fixed throughout the search process. As a result, the intensity of knowledge transfer remains same for all task pairs and also does not change with varying degrees of task relatedness as the search proceeds. Thirdly, random selection of two population members for reproduction in associative mating will lead to the low probability of intra-task crossover when the task number is large, which may degrade search power with respect to a specific task. Furthermore, it does not take into account the quality of the two selected population members for inter-task crossover. Consequently, it may happen that one individual that performs well on task A but badly on task B and another individual that performs well on task B but badly on task A are selected for undergoing inter-task crossover. Since these two individuals may seldom contain the useful knowledge which can benefit solving each other's tasks, it is highly likely that the generated offspring is less competent to solve either of the two tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Self-regulated Knowledge Transfer Scheme</head><p>To address the above-discussed issues, we extend MFEA's knowledge transfer scheme from the following aspects:</p><p>1) We introduce the concept of the ability vector which extends the concept of the skill factor by reflecting an individual's capability to resolve each component task instead of merely indicating the best-performing task. 2) We propose to create a task group for each component task by sampling the population in a probabilistic way based on the ability vectors of population members so that a population member is able to enter multiple task groups when it performs well on these tasks as reflected by its ability vector. As such, when some tasks are related, there may exist some individuals which perform commonly well on these tasks and thus can be selected into the task groups of all these tasks. The more closely these tasks are related, the larger the number of such individuals exists and thus the heavier the degree of overlap between these task groups becomes. Therefore, the degree of overlap between task groups may reflect the relatedness between the corresponding tasks. By creating task groups in this way, different pairs of task groups may have different degrees of overlap, depending on the degree of task relatedness between the involved tasks.</p><p>3) We propose to generate offspring within each of the above created task groups, independent of the offspring generation process in the other task groups. The crosstask knowledge transfer is enabled implicitly via the overlapping parts (i.e., common individuals) between task groups. In this way, the intensity of knowledge transfer becomes proportional to the degree of overlap between task groups and thus to the degree of task relatedness. In contrast to MFEA's assortative mating, this offspring generation means does not rely on manual settings to control cross-task knowledge transfer while allowing for better search power within a task group. 4) We employ the same scheme used in MFEA to allow the above generated offspring to inherit the ability vector from either of its two parents, and propose to evaluate the quality of the offspring on some selected tasks at which the inherited ability vector indicates high competence. In this way, the offspring can compete for survival with respect to multiple tasks on which its parent has performed well, where the corresponding tasks are selected in a probabilistic way based on its inherited ability vector. When some tasks are more closely related, there may exist more individuals in the population with their ability vectors indicating high competence at these tasks. As a result, knowledge transfer in terms of offspring migration becomes more intensive with the transfer intensity proportional to the degree of task relatedness. 5) We propose to, at each generation, produce a new population via task-group-wise selection from the combination of the generated offspring from all task groups and the old population, update the ability vectors of all members of the new population, and re-create task groups from the new population. By doing so, task groups get updated per generation, where degrees of overlap with respect to different pairs of task groups may be different and will adapt to varying degrees of task relatedness as the population evolves. The proposed knowledge transfer scheme allows for automatically adapting the intensity of cross-task knowledge transfer to different and varying degrees of relatedness between different tasks as the search proceeds so that the useful knowledge in common for solving related tasks can be captured, shared and utilized to a great extent. Therefore, we name this scheme as self-regulated knowledge transfer. The following details the definition of the ability vector as well as its usage in this work, and further explains how the ability vector based task group generation, offspring generation and offspring migration work. Definition 6. (Ability Vector): The ability vector of individual p i is denoted by υ i = {υ j i } k j=1 . The term υ j i reflects the ability of p i to handle component task T j and is defined as</p><formula xml:id="formula_1">υ j i = f m (r j i )</formula><p>where r j i is the factorial rank of p i on T j and f m is a monotonically decreasing function which maps the factorial rank from the range of <ref type="bibr">[1, rmax]</ref> to the range of [0.0, 1.0]. The term rmax represents the maximal value of the rank which typically equals to population size n.</p><p>Based on the above definition, each element in the ability vector of an individual reflects the ability of this individual to handle a unique component task. Its value can be regarded as the normalized factorial rank such that the best performer (i.e., ranking the first) takes the value of 1.0 and the worst performer (ranking the last) takes of the value of 0.0. This is achieved via a monotonically decreasing mapping function f m which can be defined in different ways. Fig. <ref type="figure" target="#fig_1">1</ref> illustrates how ability vector υ i is defined for individual p i given k component tasks. In this work, f m is defined as: . We use this definition to ensure superior individuals for each task to stand a higher chance of being selected into the corresponding task group while leaving the room for inferior individuals being selected to maintain diversity. In the ability vector based task group generation, each task group is generated by selecting its members from the population in a probabilistic manner, where the probability of selecting a certain population member into a specific task group is determined by the value of the task-specific element in the ability vector of that population member. For example, to create a task group for task T j , elitism-remained stochastic universal selection <ref type="bibr" target="#b9">[10]</ref> can be applied to select m members from population pop = {p i } n i=1 based on {υ j i } n i=1 . By doing so, different pairs of task groups may overlap to different extents with the degree of overlap (measured by the number of the common members of the two task groups) depending on the degree of task relatedness.</p><formula xml:id="formula_2">f f f f</formula><formula xml:id="formula_3">υ j i = f m (r j i ) = a 1 • r j i + b 1 , r j i ∈ [1, m]. a 2 • r j i + b 2 , r j i ∈ [m + 1, n].</formula><p>The rationale behind this is that when a population member contains useful knowledge for two tasks, indicating these two tasks are related with respect to this population member, it may perform well on both tasks, leading to the larger element values with respect to the two tasks in its ability vector, and thus is highly likely to be selected into the task groups of these two tasks. When the two tasks are more closely related, there may exist more such population members and accordingly the generated task groups for the two tasks are more heavily overlapped. By re-creating task groups based on the evolving population at each generation, varying degrees of relatedness between any two tasks can be implicitly captured via the corresponding task-specific elements in the ability vectors of population members, which are proportional to varying degrees of overlap between the two corresponding task groups.</p><p>Based on this ability vector based task group (re-)generation process, the ability vector based offspring generation and migration are performed to enable knowledge transfer from the aspects of parents and offspring, respectively, with the transfer intensity in both aspects adapting to the degree of task relatedness. Specifically, offspring generation is focused on each task group independently with knowledge transfer implicitly realized via the common members between the corresponding task group and the other task groups. This may not only adapt the transfer intensity to the degree of task groups' overlap (and thus the degree of task relatedness) as the search proceeds but also enhance the intra-task search power due to the high-quality parents contained in each task group. Offspring migration makes any generated offspring to inherit the ability vector from either of its parents, and then evaluate the quality of the offspring on some randomly selected tasks with selection probabilities determined by the element values in the inherited ability vector. Next, the offspring can compete for survival with respect to multiple tasks on which its parent has performed well to realize knowledge transfer. When some tasks are more closely related, there may exist more population members (as parents) with their ability vectors reflecting high competence at these tasks. Accordingly, knowledge transfer in terms of offspring migration gets intensified with the transfer intensity proportional to the degree of task relatedness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Self-regulated EMTO (SREMTO) Algorithm</head><p>By incorporating the above-described self-regulated knowledge transfer scheme into MFEA's paradigm, we propose a self-regulated EMTO (SREMTO) algorithm. The pseudo-code of SREMTO is described in Algorithm 1, where two modules in SREMTO regarding offspring generation and selective evaluation are described in Algorithms 2 and 3, respectively.</p><p>Given an MTO problem with k component tasks, SREMTO evolves a population of n individuals to solve it, where each population member is associated with an ability vector to reflect its capability to deal with each task which gets updated as the population evolves. At the beginning of executing SREMTO, each population member is randomly initialized within the search space, and then evaluated on all component tasks to obtain its factorial costs on them. The factorial rank of a population member on each task is then computed based on the factorial costs of all population members on the corresponding task, followed by the calculation of the ability vector as per Definition 6.</p><p>After this initialization process, the ability vector based task group generation is applied to create k task groups of size m, where m is set as n/k. Specifically, for each task T j (j = 1, • • • , k), elitism-remained stochastic universal selection <ref type="bibr" target="#b9">[10]</ref> is used to select (with replacement) m individuals from the population to form task group group j based on the values of the j-th element in the ability vectors of all population members. As such, k overlapping task groups (i.e., group j , j = 1, </p><formula xml:id="formula_4">for task j = 1 to k do 6:</formula><p>Selecting m individuals from pop to create task group group j for T j via elitism-remained stochastic universal selection based on the values of the j th element of the ability vectors of all individuals in pop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>Applying reproduction operations on group j to generate a set of m offspring along with their ability vectors, denoted by of f spring group j (see Algorithm 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8:</head><p>Evaluating each member of of f spring group j on selected tasks (see Algorithm 3). Concatenating pop and all of the generated offspring over k component tasks to form intermediate pop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>Selecting m individuals from intermediate pop with respect to each task via elitism-remained stochastic universal selection based on factorial costs to form a new population which updates pop.</p><p>12:</p><p>Updating the ability vector of each individual in pop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>13:</head><p>Updating the best solution found so far on each task, i.e., {x *</p><formula xml:id="formula_5">1 , x * 2 , • • • , x * k }. 14: end while</formula><p>After that, each task group group j (j = 1, • • • , k) undergoes some reproduction operations independently to produce a set of m offspring, where each of the generated offspring inherits the ability vector from one of its parents. The set of m generated offspring along with their abilities vectors with respect to group j (j = 1, • • • , k) is denoted by of f spring gorup j (j = 1, • • • , k). For example, in group j , two group members are first randomly selected as parents p 1 and p 2 . The selected two parents then produce two offspring c 1 and c 2 by undergoing one of the three reproduction processes, i.e., simulated binary crossover (SBX) <ref type="bibr" target="#b25">[26]</ref>, SBX followed by differential mutation (DM) <ref type="bibr" target="#b26">[27]</ref> and polynomial mutation Algorithm 2 Offspring Generation Input:</p><p>group j (T j 's task group)</p><p>The ability vector of each member of group j x * j (the best solution found so far on T j ) Output:</p><p>of f spring group j (the set of m generated offspring along with their abilities vectors with respect to group j ) 1: Randomly selecting two members from group j as two parents p 1 and p 2 . 2: if rand ≤ P α then 3:</p><p>(c 1 , c 2 ) = SBX(p 1 , p 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>if rand ≤ P β then 5:</p><formula xml:id="formula_6">c 1 = DM (c 1 , p 1 , p 2 , x * j ).</formula><p>6:</p><formula xml:id="formula_7">c 2 = DM (c 2 , p 2 , p 1 , x * j ). 7:</formula><p>end if 8: else  11: end if 12: c 1 randomly inherits the ability vector of p 1 or p 2 , and c 2 inherits the other. 13: Adding c 1 and c 2 as well as their ability vectors υ c1 and υ c2 into of f spring group j . 14: Repeat steps 1-13 until m offspring are generated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 Selective Evaluation Input:</head><p>of f spring group j (the set of m generated offspring along with their abilities vectors with respect to group j ) Output:</p><p>Ψ c = {Ψ js c } k js=1 , ∀c ∈ of f spring group j (the factorial costs of each member of of f spring group j on k component tasks) 1: Pick up any individual, say c, from of f spring group j with ability vector υ c . 2: for task j s = 1 to k do  Ψ js c = ∞.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>end if 8: end for 9: Removing c from of f spring group j . 10: Repeat steps 1-9 until of f spring group j is empty.</p><p>(PM) <ref type="bibr" target="#b25">[26]</ref>, determined by two algorithmic parameters P α and P β which control the selection probabilities of certain reproduction operations. Comparatively, the three reproduction processes have distinct search power which may greatly facilitate intra-task search when used together in a properly balanced manner, where the balance is controlled via P α and P β . Finally, each of the two offspring thus generated inherits the ability vector from either of its parents. Such an offspring generation process will be repeated until m offspring are generated. Algorithm 2 describes this procedure in detail. SBX and PM are very commonly used reproduction operations with each having a distribution index parameter. DM is an ad hoc operation defined as DM (y 1 , y 2 , y 3 , y 4 ) = y 1 + F × (y 4 -y 1 + y 2 -y 3 ) according to <ref type="bibr" target="#b26">[27]</ref>, where parameter F is set as a uniform random number in the range of [0, 1]. In this work, y 1 , y 2 , y 3 and y 4 are set to c 1 , p 1 , p 2 and x * j , respectively, when DM is applied to c 1 , and to c 2 , p 2 , p 1 and x * j , respectively, when DM is applied to c 2 . Here, x * j denotes the best solution found so far for T j . The m offspring thus generated will then undergo a selective evaluation process as detailed in Algorithm 3. For each offspring, a set of tasks is first selected in a probabilistic way with task selection probabilities determined by the element values of this offspring's ability vector. The task corresponding to the task group where this offspring is generated is added into this set if not selected. Then, this offspring is evaluated on these selected tasks to obtain its factorial costs on them. The factorial costs of this offspring on the unselected tasks will be set to infinity as MFEA does.</p><p>After each task group undergoes the procedure as described in the previous paragraph, the offspring generated from all task groups will compete with the individuals in the old population to yield the new population. Specifically, an intermediate population intermediate pop is first created which consists of old population members and the offspring generated from all k tasks. Then, m individuals are selected with respect to each task from intermediate pop via elitism-remained stochastic universal selection <ref type="bibr" target="#b9">[10]</ref> based on the factorial costs of all members of intermediate pop on the corresponding task. These selected individuals constitutes the new population which updates the old one.</p><p>After the new population is generated, the ability vector of each population member is updated as per Definition 6 based on the factorial ranking results. Then, this new population will undergo the above process again for a generation to yield the next new population. The evolution process will continue generation by generation until some stopping criterion is met. This work use the maximum number of function evaluations (maxFEs) as the stopping criterion, where an evaluation on any component task is counted as one evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>We comprehensively evaluate the performance of the proposed SREMTO algorithm in comparison of the original MFEA <ref type="bibr" target="#b1">[2]</ref> and its two recent variants (i.e., LDA-MFEA <ref type="bibr" target="#b10">[11]</ref> and MFEARR <ref type="bibr" target="#b11">[12]</ref>) as well as the single-task optimization counterpart of SREMTO on two MTO test suits, and make an in-depth analysis of the self-regulated knowledge transfer scheme in SREMTO to demonstrate:</p><p>-SREMTO can significantly outperform MFEA and its variants; -SREMTO can greatly benefit from the MTO paradigm to improve the overall performance of solving multiple (component) tasks; -The self-regulated knowledge transfer scheme can make the intensity of knowledge transfer in SREMTO to well adapt to the variation of task relatedness.</p><p>The following details test problems, the experimental setup, and experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Test Problems</head><p>We use two suites of test problems in our experiments. Test suite 1 contains 15 MTO problems with each problem composed of two distinct single-objective optimization tasks which have the same problem dimensionality (10D or 30D) as well as their own global optima and search ranges. For a majority of these MTO problems, their two component tasks have the same global optimum in the origin. As to the rest, their two component tasks have different global optima separated to different extents. For the sake of the performance analysis relevant to task relatedness, inter-task similarity R s (which reflects the degree of pair-wise task relatedness) is calculated in the same way as did in <ref type="bibr" target="#b6">[7]</ref>, and reported for 10D and 30D problems, respectively. R s has a range between -1 and 1, where its magnitude measures the degree of relatedness with the values of 0 and 1 denoting the lowest and highest relatedness, respectively, and its positive and negative signs represent positive and negative relatedness, respectively.</p><p>Test suite 2 contains 9 MTO problems used in the CEC 2017 Evolutionary Multi-Task Optimization Competition <ref type="bibr" target="#b6">[7]</ref>. Each problem consists of two distinct single-objective optimization tasks which have their own problem dimensionality (mostly same expect one problem), global optima, and search ranges. These 9 MTO problems belong to 9 problem categories with different degrees of overlap between their component tasks' global optima and different degrees of inter-task similarity between their component tasks.</p><p>Comparatively, test suite 1 contains MTO problems with controlled complexity in terms of problem dimensionality, the overlap between component tasks' global optima, and inter-task similarity. It suits the comprehensive evaluation and analysis of the proposed SREMTO algorithm. Test suite 2 is composed of MTO problems with relatively higher complexity. It has been used as a state-of-the-art benchmarking testbed and is more suitable for comparing SREMTO with existing algorithms. A detailed description of the above two test suites and the component tasks in the MTO problems contained in these test suits is given in the online supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Setup</head><p>We will conduct three sets of experiments to (1) evaluate the performance of SREMTO in comparison to the original MFEA on test suite 1 for both 10D and 30D cases, (2) compare the performance of SREMTO with the original MFEA and its two recent variants as well as the single-task optimization counterpart of SREMTO on test suite 2, and (3) analyze the effectiveness of the self-regulated knowledge transfer scheme in SREMTO using test suite 1.</p><p>The two MFEA variants used in comparison are LDA-MFEA <ref type="bibr" target="#b10">[11]</ref> and MFEARR <ref type="bibr" target="#b11">[12]</ref>. LDA-MFEA derives linear transformations between the solution spaces of component tasks to pursuit high ordinal correlation between tasks in terms of the quality of population members and leverages these linear transformations to improve the quality of the generated offspring. It employs polynomial mutation in MFEA and applies Lamarckian learning via the BFGS quasi-Newton method <ref type="bibr" target="#b27">[28]</ref> to improve any generated offspring with respect to the task denoted by its inherited skill factor. MFEARR utilises the survival rate of divergents defined as the offspring generated by two parents with different skill factors to reset parameter rmp in MFEA so that ineffective cross-task knowledge transfer can be suppressed. The single-task optimization counterpart of SREMTO, named as SREMTO STO, uses the SREMTO algorithm to independently solve each component task in an MTO problem by assuming it solves an MTO problem composed of only one task. It is compared to SREMTO to verify the effectiveness of knowledge transfer.</p><p>The parameter settings of the proposed SREMTO algorithm and each of the compared algorithms are specified as follows. The population size is set to 100 for all algorithms in comparison, where SREMO STO uses the size of 50 for each of the two component tasks because it solves them independently. The crossover probability (P α ) and mutation probability (P β ) in SREMTO are set to 0.7 and 1.0, respectively. The distribution indices of SBX and PM are set to 1 and 39, respectively, for SREMTO, and to 2 and 5, respectively, for MFEA, LDA-MFEA and MFEARR. The random mating probability (rmp) used in MFEA, LDA-MFEA and MFEARR is set to 0.3. The small number needed in MFEARR is set to 0.01. The parameter settings of SREMO STO are same to those of SREMTO.</p><p>For each MTO problem, each algorithm under evaluation will be run for 20 times. The maximum number of function evaluations (maxFEs) is employed as the stopping criterion to terminate a run, which is set to 100,000 in our experiments as suggested in <ref type="bibr" target="#b6">[7]</ref>. All algorithms are implemented via MATLAB 2016a 9.0.0.341360 and executed on a Windows PC with Intel Core i7 CPU at 3.6GHz and 8GB RAM.</p><p>The mean and standard deviation of the best objective function error values (FEVs) achieved when the algorithm terminates over 20 runs are used to measure the performance of the algorithm in terms of optimization accuracy. Here, the FEV is defined as the difference between the objective function value of the found solution and that of the global optimum. The convergence curve of the best achieved FEV versus the number of executed function evaluations (#FEs) is used to measure the performance of the algorithm in terms of optimization efficiency. To make performance comparison in a statistically sound way, we employ Wilcoxon's rank sum test <ref type="bibr" target="#b28">[29]</ref> at the significant level of 0.05 to compare two algorithms, and Friedman's test <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref> at the significant level of 0.05 followed by Holm's post-hoc procedure <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref> to compare more than two algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Experimental Results</head><p>1) Comparison of the proposed SREMTO algorithm and the original MFEA on test suite 1: We evaluate and compare the performances of SREMTO and MFEA on test suite 1 in terms of both optimization accuracy and optimization efficiency. For each component task in each of the 15 test problems at specific problem dimensionality, we first calculate the mean of the best achieved FEVs over 20 runs for SREMTO and MFEA, and choose the one (between SREMTO and MFEA) that has the smaller mean value as the control method (where tie will be broken randomly). Then, we apply Wilcoxon's rank sum test at the significant level of 0.05 to determine whether another method is statistically similar to the control method. Based on such statistical comparison results, we calculate the win, tie and loss of SREMTO in comparison to MFEA over all 30 component tasks across 15 test problems at 10D and 30D, respectively. Specifically, "win" (with respect to a specific component task in a specific test problem) means that SREMTO is determined as the control method and meanwhile not statistically similar to MFEA; "tie" means SREMTO and MFEA are statistically similar to each other (no matter which one is the control method); "loss" means that MFEA is determined as the control method and meanwhile not statistically similar to SREMTO. The performance superiority of SREMTO over MFEA can be evidenced by the fact that SREMTO wins 26 out of 30 tasks, ties 3 out of 30 tasks and loses 1 out of 30 tasks at 10D, and wins 28 out of 30 tasks and loses 2 out of 30 tasks with no ties at 30D. Due to space limitation, we leave in the online supplementary material two tables (i.e., Tables <ref type="table" target="#tab_4">SIII</ref> and<ref type="table" target="#tab_2">SIV</ref>) which report the mean and standard deviation of the best achieved FEVs over 20 runs on each of the 30 component tasks across 15 test problems at 10D and 30D, respectively, and also give the details of statistical comparison results.</p><p>Among 15 test problems at 10D and 30D, there exist three problems, i.e., problem 4 at 10D (P4 10D), problem 3 at 30D (P3 D30) and problem 4 at 30D (P4 D30), where SREMTO performs worse than MFEA in one of the two component tasks (as reported in Tables <ref type="table" target="#tab_4">SIII</ref> and<ref type="table" target="#tab_2">SIV</ref>). We further look into these three problems to study the reasons. For P4 10D, its two component tasks are both difficult to solve as reported in <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>. Furthermore, they are unrelated (with intertask similarity R s = 0.0) and have their global optima far away to each other. As a result, SREMTO can hardly show its ability. For both P3 D30 and P4 D30, SREMTO solves T 2 a bit better while solving T 1 a bit worse. This can be explained by the fact that the two component tasks in both problems 3 and 4 are highly complex, little related (with R s close or equal to 0) and have their global optima far away to each other, which makes it difficult for SREMTO to demonstrate its advantages.</p><p>Fig. <ref type="figure" target="#fig_8">2</ref> shows the convergence curves of the mean of the best achieved FEVs over 20 runs versus #FEs (which increases up to maxFEs) on both component tasks in two representative test problems, i.e., problems 1 and 7 at 10D. The convergence curves for the other test problems are illustrated in Fig. <ref type="figure" target="#fig_1">S1</ref> in the online supplementary material due to space limitation. It can be observed that SREMTO has much faster convergence speed than MEFA for finding the desirable best FEV on problem 1 (and also on problems 2, 9, 12-15 as shown in Fig. <ref type="figure" target="#fig_1">S1</ref>). On problem 7 (and many other problems as shown in Fig. <ref type="figure" target="#fig_1">S1</ref>), the convergence speed of SREMTO is still gently faster than that of MEFA.</p><p>2) Comparison of the proposed SREMTO algorithm, the original MFEA and its two recent variants LDA-MFEA and   <ref type="bibr" target="#b28">[29]</ref> at the significant level of 0.05, which reveals the existence of significant difference between the compared algorithms. Then, Holm's post-hoc test <ref type="bibr" target="#b28">[29]</ref> is applied to identify the top performer(s) among the compared algorithms. To do so, we first calculate the average rank of each compared algorithm as the intermediate output of Friedman's test, which is reported as meanrank in the last row of Table <ref type="table" target="#tab_2">I</ref>. It can be observed that SREMTO has the smallest rank of 1.56 and thus is chosen as the control method. Then, we compare each of the other three algorithms to the control method as per Holm's posthoc procedure <ref type="bibr" target="#b28">[29]</ref> to test whether any of them is statistically similar to the control method. This procedure is illustrated in Table <ref type="table" target="#tab_3">II</ref>, where z is the test statistic used for calculating the p values <ref type="bibr" target="#b29">[30]</ref> of those methods compared to the control and α/(k-i) calculates the adjusted α values used in Holm's posthoc test. R i denotes the average rank of the i-th algorithm with i = 0, • • • , 3 referring to SREMTO, MFEA, LDA-MFEA and MFEARR, respectively. SE = k(k + 1)/6N <ref type="bibr" target="#b29">[30]</ref> is used in the calculation of z, where k and N denote the total number of compared algorithms and test cases which are equal to 4 and 18, respectively. It can be observed in Table <ref type="table" target="#tab_3">II</ref> that Holm's post-hoc test rejects each of the three null hypotheses assuming no significant difference between SREMTO and each of the three compared algorithms, evidenced by the p value being smaller than the adjusted α value. Hence, SREMTO performs statistically significantly better than the other three compared algorithms.</p><p>In addition to verifying the superiority of SREMTO over the existing state-of-the-arts, we also compare SREMTO with    It can be observed that localR s has a large initial value at generation 1 which is similar to the value of (global) R s for problem 1 (R s = 0.75 as reported in Table SI in the online supplementary material). As the population evolves, the value of localR s varies (first decreasing and then increasing) since the population traverses different sub-regions of the solution space which correspond to different degrees of local task relatedness. When the population gradually converges towards the common global optimum (i.e., the origin) of the two component tasks, the sub-regions, traversed by the population, correspond to higher and higher degrees of local task relatedness. Accordingly, the value of localR s goes up to one. The curve of KT I is very similar to that of localR s , meaning that when the value of localR s goes higher (or lower) the value of KT I also goes higher (or lower). This indicates that KT I can adapt to varying localR s as the population evolves. As a result, the intensity of knowledge transfer is automatically adjusted as per the degree of local task relatedness. It can be observed that at generation 1 the initial value of localR s is low due to the shifting of the two global optima (and thus the fitness landscape) which makes the sub-regions captured by the initial population to correspond to low task relatedness. As the population evolves, the value of localR s varies (first decreasing and then nearly flatting) because the population traverses different sub-regions of the solution space which correspond to different degrees of local task relatedness. As the algorithm executes, the population is gradually split into two groups with each group converging towards one component task's global optimum. As a result, the value of localR s quickly drops and remains low because the highlyranked individuals for one component task, moving towards the global optimum of this task, are deemed to rank lower on another component task compared to the individuals moving towards another component task's global optimum. Same as in the previous experiment, the curve of KT I is very similar to that of localR s , indicating that KT I can adapt to varying localR s as the population evolves.</p><p>To consolidate the above observations and findings, we further choose problems 6-9 in test suite 1 to repeat the above experiment on them, where problems 8 and 9 have the same global optimum in the origin (like problem 1), and problems 6-7 have separated global optima as reported in Table SI in the online supplementary material (like shifted problem 1). The curves regarding localR s and KT I as well as the best achieved FEV versus the number of generations are illustrated in Fig. <ref type="figure">5</ref> (for problems 8 and 9) and Fig. <ref type="figure" target="#fig_10">6</ref> (for problems 6 and 7). Figs. <ref type="figure">5</ref> and<ref type="figure" target="#fig_10">6</ref> show the similar patterns as those demonstrated in Figs. <ref type="figure" target="#fig_0">3</ref> and<ref type="figure">4</ref>, respectively.</p><p>The above experiments demonstrate that the proposed selfregulated knowledge transfer scheme in SREMTO is competent at adapting the knowledge transfer intensity to the degree of task relatedness as the population evolves, which helps to effectively co-solve the component tasks in an MTO problem.</p><p>Discussion on potential adverse transfer: MTO assumes that there exists some useful knowledge in common for solving related tasks so that the useful knowledge acquired during the process of solving one task may assist in solving another task if they are somehow related. In EMTO, useful knowledge in common indicates the individuals which can perform commonly well in all considered tasks. However, there is no guarantee that such individuals are deemed to help solving each of the considered tasks. Although in many cases they do assist in accelerating the optimization of each task, in some cases adverse transfer might happen. For example, given an MTO problem consisting of two component tasks T a and T b , if the global optimum of T a happens to be the local optimum of T b , the population could be misled by the proposed knowledge transfer scheme to converge to T b 's local optimum (i.e., T a 's global optimum). However, this misleading situation may not easily happen due to some reasons. Firstly, the two component tasks usually correspond to different convergence speeds. If T a 's task group converges to T a 's global optimum while T b 's task group still does not find any candidate solution better than T b 's local optimum that coincides with T a 's global optimum, T b 's task group will be forced to converge to this local optimum. However, if T b 's task group can find some candidate solutions better than this local optimum prior to the convergence of T a 's task group to T a 's global optimum, it can continue its search. This really depends on the convergence speeds of the two task groups. Secondly, even if T a 's task group has a much faster convergence speed than T b 's task group, the convergence of T a 's task group would be slowed down due to the existence of "unhelpful" knowledge transfer from T b . This increases the chance for T b 's task group to find some candidate solutions better than the abovediscussed local optimum before T a 's task group converges. In fact, even considering the worst case in which both task groups converge to T a 's global optimum (i.e., T b 's local optimum), we can address this issue by increasing the value of parameter T H to enhance the diversity of each task group and accordingly slow down task groups' convergence and/or adjusting the parameters in offspring generation operations to enhance exploration power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUDING REMARKS AND FUTURE WORK</head><p>We proposed a SREMTO algorithm which extends MFEA by tackling the deficiencies of its knowledge transfer scheme. SREMTO is armed with a novel self-regulated knowledge transfer scheme, where the ability vector was devised to reflect an individual's capability for resolving each component task instead of merely indicating the task on which it performs best as the skill factor used in MFEA does. Furthermore, the ability vector based task group generation, offspring generation and offspring migration were designed to allow adapting the intensity of cross-task knowledge transfer to different and varying degrees of relatedness between different tasks as the search proceeds so that the useful knowledge in common for solving related tasks can be captured, shared and utilized to a great extent. We compared SREMTO with MFEA and its variants as well as the single-task optimization counterpart of SREMTO on two MTO test suites to show the superiority of SREMTO. Moreover, we analyzed the self-regulated knowledge transfer scheme to gain an insight into its effectiveness.</p><p>In the future, we plan to investigate the performance of SREMTO on the MTO problems that contain more than two tasks. We will also study on the scalability of SREMTO when solving MTO problems with many tasks, and design the parallel implementations of SREMTO to speed up its computation. Moreover, we will investigate the performance of SREMTO in the discrete domain, where component tasks are discrete optimization problems. We also plan to apply SREMTO to real-world engineering applications to test its efficacy and make further improvements on it.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Definition 3 .</head><label>3</label><figDesc>(Scalar Fitness): The scalar fitness ϕ i of individual p i is defined by ϕ i = 1/min j∈{1,••• ,k} r j i . Definition 4. (Skill Factor): The skill factor τ i of individual p i is defined as the index of the task at which the individual demonstrates the highest competence amongst all tasks, i.e., τ i = arg min j∈{1,••• ,k} {r j i }. Definition 5. (Multifactorial Optimality): Individual p o is claimed as a multifactorial optimum if only it is the global optimum of any of the k component tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of the definition of the ability vector υ i for individual p i given k component tasks T j , j = 1, • • • , k and population size n.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>,</head><label></label><figDesc>where n denotes population size and m (set to n/k in this work with k being the number of component tasks) represents the size of each task group. As per the two-point representation of a line, parameters a 1 and b 1 are determined via points (1, 1.0) and (m, T H) which are the two end points of one line segment. Parameters a 2 and b 2 are determined via points (m, T H) and (n, 0.0) which are the two end points of another line segment. Based on this definition, the ranking indices from 1 to m and then to n will be mapped in a piece-wise linear way into [1.0, T H] and then [T H, 0.0]. The two line segments (corresponding to the two pieces of the linear mapping) have different slopes controlled via a manually-specified parameter (T H) with the value range of [0.0, 1.0]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>9 :c 1 =</head><label>91</label><figDesc>P M (p 1 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>10 : c 2 =</head><label>102</label><figDesc>P M (p 2 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>3 : 4 :</head><label>34</label><figDesc>if j s = j || rand ≤ υ js c then Calculating c's factorial cost on T js , i.e., Ψ js c , as per Definition 1.5:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. The convergence curves of the mean of the best achieved FEVs over 20 runs versus the number of executed function evaluations (#FEs) increasing up to maxFEs with respect to SREMTO and MFEA on problems 1 and 7 at 10D in test suite 1, where the curves of SREMTO on both component tasks T 1 and T 2 in problem 1 terminate before reaching maxF Es because the global optimum has been found.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 3 Fig. 3 .Fig. 4 .</head><label>334</label><figDesc>Fig. 3. (a) Average trends of localRs and KT I on problem 1; (b) Average FEV convergence curves on the two component tasks in problem 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. (a) Average trends of localRs and KT I on problem 6; (b) Average FEV convergence curves on the two component tasks in problem 6; (c) Average trends of localRs and KT I on problem 7; (d) Average FEV convergence curves on the two component tasks in problem 7.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>• • • , k) are created. Initializing population pop of size n. 2: Evaluating each individual in pop on k component tasks. 3: Computing the ability vector of each individual. 4: while (stopping criterion is not met) do</figDesc><table><row><cell>Algorithm 1 SREMTO</cell></row><row><cell>Input:</cell></row><row><cell>n (population size)</cell></row><row><cell>P α (crossover probability)</cell></row><row><cell>P β (mutation probability)</cell></row><row><cell>Distribution index of SBX</cell></row><row><cell>Distribution index of PM</cell></row><row><cell>Output:</cell></row><row><cell>{x  *  1 , x  *  2 , • • • , x  *  k } (the best solution found for each of the</cell></row><row><cell>k component tasks)</cell></row><row><cell>1: 5:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>convergence curves of the mean of the best achieved FEVs over 20 runs versus the number of executed function evaluations (#FEs) increasing up to maxFEs with respect to SREMTO and MFEA on problems 1 and 7 at 10D in test suite 1, where the curves of SREMTO on both component tasksT1 and T 2 in problem 1 terminate before reaching maxF Es because the global optimum has been found. MFEARR as well as SREMTO STO on test suite 2: To demonstrate the performance superiority of SREMTO in a solid way, we use the 9 test problems in test suite 2 to evaluate the performance of SREMTO in comparison to MFEA, LDA-MFEA and MFEARR. Table I reports the mean and standard deviation of the best achieved FEVs over 20 runs on each component task in each of the 9 test problems. To perform statistical comparison, we treat each component task in each test problem as an individual test case, leading to 18 test cases in total. The mean best FEVs over these 18 test cases, as reported in Table I, are used for comparing SREMTO, MFEA, LDA-MFEA and MFEARR via Friedman's test</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I COMPARISON</head><label>I</label><figDesc>OF SREMTO, MFEA, LDA-MFEA AND MFEARR IN TERMS OF THE MEAN AND STANDARD DEVIATION (IN BRACKETS) OF THE BEST ACHIEVED FEVS OVER 20 RUNS ON 9 MTO PROBLEMS IN TEST SUITE 2. THE meanrank IS OBTAINED VIA FRIEDMAN'S TEST.</figDesc><table><row><cell cols="2">Problem Task</cell><cell>MFEA</cell><cell>LDA-MFEA</cell><cell>MFEARR</cell><cell>SREMTO</cell></row><row><cell>1</cell><cell>T 1 T 2</cell><cell>3.614e-01 (4.652e-02) 1.957e+02 (5.081e+01)</cell><cell>4.917e-01 (5.943e-02) 2.028e+02 (3.527e+01)</cell><cell>2.367e-01 (5.171e-02) 2.135e+02 (5.265e+01)</cell><cell>6.278e-03 (7.732e-03) 2.487e+01 (2.673e+01)</cell></row><row><cell>2</cell><cell>T 1 T 2</cell><cell>4.837e+00 (7.232e-01) 2.208e+02 (5.453e+01)</cell><cell>4.349e+00 (7.369e-01) 2.239e+02 (5.343e+01)</cell><cell>4.357e+00 (8.233e-01) 2.062e+02 (5.797e+01)</cell><cell>3.387e+00 (7.028e-01) 6.556e+01 (2.710e+01)</cell></row><row><cell>3</cell><cell>T 1 T 2</cell><cell>2.015e+01 (6.682e-02) 3.879e+03 (4.919e+02)</cell><cell>2.022e+01 (3.471e+00) 5.406e+03 (1.426e+03)</cell><cell>2.020e+01 (8.156e-02) 3.805e+03 (4.868e+02)</cell><cell>2.108e+01 (2.109e-01) 6.504e+03 (9.442e+02)</cell></row><row><cell>4</cell><cell>T 1 T 2</cell><cell>5.803e+02 (1.133e+02) 8.186e+00 (1.800e+00)</cell><cell>4.828e+02 (9.032e+01) 9.732e+00 (2.319e+00)</cell><cell>5.122e+02 (8.951e+01) 4.577e+00 (9.316e-01)</cell><cell>2.813e+02 (1.097e+02) 2.598e-06 (3.593e-06)</cell></row><row><cell>5</cell><cell>T 1 T 2</cell><cell>3.510e+00 (4.909e-01) 5.973e+02 (9.822e+01)</cell><cell>3.573e+00 (4.240e-01) 5.958e+02 (2.956e+02)</cell><cell>3.321e+00 (5.605e-01) 3.732e+02 (7.989e+01)</cell><cell>2.221e+00 (6.308e-01) 1.168e+02 (4.158e+01)</cell></row><row><cell>6</cell><cell>T 1 T 2</cell><cell>1.925e+01 (3.497e+00) 1.907e+01 (4.092e+00)</cell><cell>3.987e+00 (6.526e-01) 4.160e+00 (1.020e+00)</cell><cell>1.607e+01 (7.034e+00) 1.623e+01 (7.148e+00)</cell><cell>3.541e+00 (8.552e-01) 3.318e+00 (1.060e+00)</cell></row><row><cell>7</cell><cell>T 1 T 2</cell><cell>7.737e+02 (2.518e+02) 2.634e+02 (9.070e+01)</cell><cell>1.208e+03 (5.587e+02) 2.689e+02 (5.971e+01)</cell><cell>5.935e+02 (4.308e+02) 2.513e+02 (8.544e+01)</cell><cell>1.331e+02 (4.858e+01) 7.009e+01 (2.436e+01)</cell></row><row><cell>8</cell><cell>T 1 T 2</cell><cell>4.378e-01 (6.988e-02) 2.657e+01 (2.938e+00)</cell><cell>6.379e-01 (7.404e-02) 1.855e+01 (2.883e+00)</cell><cell>3.040e-01 (6.492e-02) 2.685e+01 (3.348e+00)</cell><cell>1.063e-02 (1.187e-02) 1.990e+01 (2.155e+00)</cell></row><row><cell>9</cell><cell>T 1 T 2</cell><cell>6.200e+02 (1.709e+02) 3.612e+03 (3.683e+02)</cell><cell>5.362e+02 (9.926e+01) 4.581e+03 (9.723e+02)</cell><cell>5.493e+02 (1.182e+02) 3.749e+03 (5.203e+02)</cell><cell>2.809e+02 (5.140e+01) 5.878e+03 (9.640e+02)</cell></row><row><cell cols="2">meanrank</cell><cell>3.00</cell><cell>3.00</cell><cell>2.44</cell><cell>1.56</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II COMPARISON</head><label>II</label><figDesc>OF SREMTO, MFEA, LDA-MFEA AND MFEARR ON TEST SUIT 2 BY USING FRIEDMAN'S TEST FOLLOWED BY HOLM'S POST-HOC PROCEDURE AT THE SIGNIFICANT LEVEL OF α = 0.05. The aim is to demonstrate the effectiveness of knowledge transfer in SREMTO. The comparison results are reported in TableIIIin terms of the mean and standard deviation of the best achieved FEVs over 20 runs on all 9 test problems.For each component task in each test problem, either of SREMTO and SREMTO STO which achieves the smaller mean best FEV is indicated in bold. Meanwhile, if another has statistically similar performance, validated by Wilcoxon's rank sum test at the significant level of 0.05 applied to the two sets of results over 20 runs, it is also denoted in bold. Based on such statistical comparison results, we calculate the win, tie and loss of SREMTO in comparison to SREMTO STO over all 18 component tasks across 9 test problems, and report the result at the bottom of the TableIII. The win/tie/loss of 7/8/3 demonstrates the superiority of SREMTO and accordingly verifies the effectiveness of knowledge transfer.3) Analysis of the Self-Regulated Knowledge Transfer Scheme in SREMTO: We conduct further experiments to gain insight into the self-regulated knowledge transfer scheme</figDesc><table><row><cell>i</cell><cell>Algorithms</cell><cell>z = (R i -R 0 )/SE</cell><cell>p</cell><cell>α/(k-i)</cell></row><row><cell>1</cell><cell>MFEA</cell><cell>3.357</cell><cell>0.0008</cell><cell>0.017</cell></row><row><cell>2</cell><cell>LDA-MFEA</cell><cell>3.357</cell><cell>0.0008</cell><cell>0.025</cell></row><row><cell>3</cell><cell>MFEARR</cell><cell>2.066</cell><cell>0.0394</cell><cell>0.05</cell></row><row><cell cols="5">SREMTO STO which is the single-task optimization coun-</cell></row><row><cell cols="5">terpart of SREMTO where each task is solved independently</cell></row><row><cell cols="5">using the same evolutionary operations and their associated</cell></row><row><cell cols="3">parameters as in SREMTO.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE III COMPARISON</head><label>III</label><figDesc>OF SREMTO AND SREMTO STO IN TERMS OF THE MEAN AND STANDARD DEVIATION (IN BRACKETS) OF THE BEST ACHIEVEDFEVS OVER 20 RUNS ON 9 MTO PROBLEMS IN TEST SUITE 2. Firstly, we choose to use problem 1 at 10D in test suite 1 and apply SREMTO to solve it using the parameters settings described in Section IV-B, where the two component tasks have the same global optimum, and both can be well solved by SREMTO as reported in Table SIII in the online supplementary material. As the algorithm executes, we calculate the value of population-based local R s (denoted by localR s ), where the samples used to compute R s are the members of the population at each generation, and record R s values across all generations. Meanwhile, we compute the knowledge transfer intensity (KT I) at each generation as the percentage of the population members who simultaneously participate in the processes of solving both component tasks and record KT I values across all generations. The values of localR s and KT I with respect to each generation are averaged over 20 runs, respectively, and illustrated in</figDesc><table><row><cell cols="2">Problem Task</cell><cell>SREMTO STO</cell><cell>SREMTO</cell></row><row><cell>1</cell><cell>T 1 T 2</cell><cell>6.913e-03 (9.135e-03) 2.496e+02 (7.323e+01)</cell><cell>6.278e-03 (7.733e-03) 2.487e+01 (2.673e+01)</cell></row><row><cell>2</cell><cell>T 1 T 2</cell><cell>4.468e+00 (3.969e+00) 2.500e+02 (6.638e+01)</cell><cell>3.387e+00 (7.029e-01) 6.557e+01 (2.710e+01)</cell></row><row><cell>3</cell><cell>T 1 T 2</cell><cell>2.119e+01 (3.965e-02) 5.851e+03 (8.051e+02)</cell><cell>2.108e+01 (2.110e-01) 6.504e+03 (9.442e+02)</cell></row><row><cell>4</cell><cell>T 1 T 2</cell><cell>2.520e+02 (8.444e+01) 2.537e-09 (4.916e-09)</cell><cell>2.813e+02 (1.097e+02) 2.599e-06 (3.593e-06)</cell></row><row><cell>5</cell><cell>T 1 T 2</cell><cell>4.293e+00 (4.007e+00) 1.926e+02 (1.254e+02)</cell><cell>2.222e+00 (6.308e-01) 1.169e+02 (4.158e+01)</cell></row><row><cell>6</cell><cell>T 1 T 2</cell><cell>3.452e+00 (5.089e-01) 9.458e+00 (3.053e+00)</cell><cell>3.542e+00 (8.553e-01) 3.319e+00 (1.060e+00)</cell></row><row><cell>7</cell><cell>T 1 T 2</cell><cell>1.593e+02 (1.669e+02) 2.783e+02 (6.201e+01)</cell><cell>1.332e+02 (4.859e+01) 7.010e+01 (2.436e+01)</cell></row><row><cell>8</cell><cell>T 1 T 2</cell><cell>7.893e-03 (7.646e-03) 3.139e+01 (4.458e+00)</cell><cell>1.063e-02 (1.187e-02) 1.991e+01 (2.156e+00)</cell></row><row><cell>9</cell><cell>T 1 T 2</cell><cell>2.491e+02 (5.408e+01) 5.656e+03 (4.846e+02)</cell><cell>2.810e+02 (5.141e+01) 5.878e+03 (9.641e+02)</cell></row><row><cell cols="2">win/tie/loss</cell><cell>7 / 8 / 3</cell><cell></cell></row><row><cell cols="2">in SREMTO.</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by the National Natural Science Foundation of China (Grant no. 61772393, 61603299 and 61602385), the National key research and development program of China (Grant no. 2017YFB0802200), the Key research and development program of Shaanxi Province (Grant no. 2018ZDXM-GY-045), Australian Research Council (Grant no. DP160103595, LP180100114) and the Shenzhen Research and Development Foundation (Grant no. JCYJ20170306153943097). X. Zheng is with School of Electronics and Information, Northwestern Polytechnical University, ADD:127 West Youyi Road, Xi'an Shaanxi, 710072, China and with Research &amp; Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen, China</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Xiaolong Zheng received the B.S. degree from Xidian University, Xi'an, Shannxi, China, in 2016. He is currently pursuing his PhD degree in the School of Electronics and Information at Northwestern Polytechnical University, Xi'an, Shannxi, China. His major research interests include evolutionary computation and machine learning. His current research interests are Integrated Control Theory and Application, Information Fusion, Intelligent Information Processing, Evolutionary Optimization and so on.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multi-task bayesian optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2004" to="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multifactorial evolution: Toward evolutionary multitasking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="343" to="357" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Evolutionary multitasking in combinatorial search spaces: A case study in capacitated vehicle routing problem</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-M</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SSCI</title>
		<imprint>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Evolutionary computation: comments on the history and current state</title>
		<author>
			<persName><forename type="first">T</forename><surname>Back</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hammel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Schwefel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="17" />
			<date type="published" when="1997-04">Apr 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Performance evaluation of multiagent genetic algorithm</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="96" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Evolutionary algorithms in engineering applications</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Evolutionary multitasking for single-objective continuous optimization: Benchmark problems, performance metrics and baseline results</title>
		<author>
			<persName><forename type="first">B</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multiobjective multifactorial optimization in evolutionary multitasking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on cybernetics</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1652" to="1665" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Evolutionary multitasking for multiobjective continuous optimization: Benchmark problems, performance metrics and baseline results</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reducing bias and inefficiency in the selection algorithm</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second international conference on genetic algorithms</title>
		<meeting>the second international conference on genetic algorithms</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="14" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Linearized domain adaptation in evolutionary multitasking</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Bali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Siew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation (CEC)</title>
		<imprint>
			<biblScope unit="page" from="1295" to="1302" />
			<date type="published" when="2017-06">2017. June 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Parting ways and reallocating resources in evolutionary multitasking</title>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Ting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Computation (CEC)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="2404" to="2411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A group-based approach to improve multifactorial evolutionary algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Joy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="page" from="3870" to="3876" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Evolutionary many-tasking based on biocoenosis through symbiosis: A framework and benchmark problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Ting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="page" from="2266" to="2273" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multipopulation evolution framework for multifactorial optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference Companion</title>
		<meeting>the Genetic and Evolutionary Computation Conference Companion</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="215" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Genetic transfer or population diversification? deciphering the secret ingredients of evolutionary multitask optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<idno>abs/1607.05390</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Landscape synergy in evolutionary multitasking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Handoko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Congress on Evolutionary Computation (CEC)</title>
		<imprint>
			<date type="published" when="2016-07">July 2016</date>
			<biblScope unit="page" from="3076" to="3083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The boon of gene-culture interaction for effective evolutionary multitasking</title>
		<author>
			<persName><forename type="first">B</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Australasian Conference on Artificial Life and Computational Intelligence</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="54" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A study of similarity measure between tasks for multifactorial evolutionary algorithm</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference Companion</title>
		<meeting>the Genetic and Evolutionary Computation Conference Companion</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="229" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Evolutionary multitasking in permutation-based combinatorial optimization problems: Realization with tsp, qap, lop, and jsp</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Region 10 Conference (TENCON)</title>
		<meeting>Region 10 Conference (TENCON)</meeting>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="3157" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Evolutionary multitasking to support optimal power flow under rapid load variations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sampath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gooi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Concurrently searching branches in software tests generation through multitask evolution</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sagarna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Intelligence (SSCI)</title>
		<title level="s">IEEE Symposium Series</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">An evolutionary multitasking algorithm for cloud computing service composition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="130" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multifactorial inheritance with cultural transmission and assortative mating. II. A general model of combined polygenic and cultural inheritance</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Cloninger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Reich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Human Genetics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="176" to="198" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Genetic algorithms and random keys for sequencing and optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ORSA Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="154" to="160" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Simulated binary crossover for continuous search space</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="148" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An empirical study of multifactorial PSO and multifactorial DE</title>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Computation (CEC)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="921" to="928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Meta-lamarckian learning in memetic algorithms</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on evolutionary computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A practical tutorial on the use of nonparametric statistical tests as a methodology for comparing evolutionary and swarm intelligence algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Derrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="18" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Statistical comparisons of classifiers over multiple data sets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Demšar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine learning research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2006-01">Jan. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adaptive memetic algorithm based evolutionary multi-tasking single-objective optimization</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia-Pacific Conference on Simulated Evolution and Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="462" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Evolutionary multi-tasking singleobjective optimization based on cooperative co-evolutionary memetic algorithm</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Intelligence and Security (CIS), 2017 13th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="197" to="201" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
