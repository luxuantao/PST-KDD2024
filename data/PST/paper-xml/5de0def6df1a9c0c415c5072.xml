<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">RFAL: Adversarial Learning for RF Transmitter Identification and Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Debashri</forename><surname>Roy</surname></persName>
							<email>debashri@cs.ucf.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">University of Central Florida Orlando</orgName>
								<address>
									<postCode>32826</postCode>
									<region>FL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tathagata</forename><surname>Mukherjee</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">University of Alabama Huntsville</orgName>
								<address>
									<postCode>35899</postCode>
									<region>AL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mainak</forename><surname>Chatterjee</surname></persName>
							<email>mainak@cs.ucf.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">University of Central Florida Orlando</orgName>
								<address>
									<postCode>32826</postCode>
									<region>FL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Erik</forename><surname>Blasch</surname></persName>
							<email>erik.blasch@gmail.com</email>
							<affiliation key="aff2">
								<orgName type="department">Fellow IEEE</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eduardo</forename><surname>Pasiliao</surname></persName>
							<email>eduardo.pasiliao@us.af.mil</email>
							<affiliation key="aff3">
								<orgName type="laboratory">Munitions Directorate Air Force Research Laboratory Eglin AFB</orgName>
								<address>
									<postCode>32542</postCode>
									<region>FL</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">RFAL: Adversarial Learning for RF Transmitter Identification and Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EF6D8059F16950318D6FE9DB5954C953</idno>
					<idno type="DOI">10.1109/TCCN.2019.2948919</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCCN.2019.2948919, IEEE Transactions on Cognitive Communications and Networking</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>RF fingerprinting</term>
					<term>GAN</term>
					<term>machine learning</term>
					<term>convolutional neural network</term>
					<term>deep neural network</term>
					<term>recurrent neural network</term>
					<term>I/Q imbalance</term>
					<term>software defined radios</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent advances in wireless technologies have led to several autonomous deployments of such networks. As nodes across distributed networks must co-exist, it is important that all transmitters and receivers are aware of their radio frequency (RF) surroundings so that they can adapt their transmission and reception parameters to best suit their needs. To this end, machine learning techniques have become popular as they can learn, analyze and predict the RF signals and associated parameters that characterize the RF environment. However, in the presence of adversaries, malicious activities such as jamming and spoofing are inevitable, making most machine learning techniques ineffective in such environments.</p><p>In this paper we propose the Radio Frequency Adversarial Learning (RFAL) framework for building a robust system to identify rogue RF transmitters by designing and implementing a generative adversarial net (GAN). We hope to exploit transmitter specific "signatures" like the the in-phase (I) and quadrature (Q) imbalance (i.e., the I/Q imbalance) present in all transmitters for this task, by learning feature representations using a deep neural network that uses the I/Q data from received signals as input. After detection and elimination of the adversarial transmitters RFAL further uses this learned feature embedding as "fingerprints" for categorizing the trusted transmitters. More specifically, we implement a generative model that learns the sample space of the I/Q values of known transmitters and uses the learned representation to generate signals that imitate the transmissions of these transmitters. We program 8 universal software radio peripheral (USRP) software defined radios (SDRs) as trusted transmitters and collect "over-the-air" raw I/Q data from them using a Realtek Software Defined Radio (RTL-SDR), in a laboratory setting. We also implement a discriminator model that discriminates between the trusted transmitters and the counterfeit ones with 99.9% accuracy and is trained in the GAN framework using data from the generator. Finally, after elimination of the adversarial transmitters, the trusted transmitters are classified using a convolutional neural network (CNN), a fully connected deep neural network (DNN) and a recurrent neural network (RNN) to demonstrate building of an end-to-end robust transmitter identification system with RFAL. Experimental results reveal that the CNN, DNN, and RNN are able to correctly distinguish between the 8 trusted transmitters with 81.6%, 94.6% and 97% accuracy respectively. We also show that better "trusted transmission" classification accuracy is achieved for all three types of neural networks when data from two different types of transmitters (different manufacturers) are used rather than when using the same type of transmitter (same manufacturer).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The advent of Internet-of-Things (IoT) <ref type="bibr" target="#b0">[1]</ref>, large scale sensor networks and the possibility of having large scale vehicular networks in the near future, have ushered in a new era of industrial scale deployment of radio frequency (RF) signal sources (aka RF transmitters). Different automatic methods for optimized communication that involve localization as well as identification and characterization of such devices, are becoming indispensable for many applications such as locating a cell phone, identifying jammers and rogue transmitters, detecting the presence or absence of a signal source, tracking objects, etc. With large scale autonomous deployments of wireless networks, identification of transmitters has become an important problem. For example, a wireless sensor network (WSN) relies on trustworthy signals; however, malicious transmitters can contaminate the signals and jeopardize the utility of the sensor network. Existence of such threats underscore the need for techniques that recognize and authenticate the identity of transmitters, irrespective of the network protocols and communication technologies being used. One of the ways that this can be done is through the exchange of keys and identity information. However, such methods are prone to malicious attacks by adversaries as well. Hence techniques for robust transmitter identification and authentication in adversarial settings is important for maintaining the integrity of large scale RF deployments. A robust alternative to using a system based on key exchanges is to use machine learning (ML) for automatic identification and characterization of communicating entities.</p><p>In recent years, there has been a proliferation of autonomous systems that use ML algorithms on large scale sensor data. These systems assume that the data and signals being used are trustworthy even though they are received from several heterogeneous sources (e.g., cameras, microphones, etc.). When using ML techniques for communication networks, malicious entities, such as rogue transmitters can alter the signal (and hence the data) by exploiting different targeted data generation techniques based on generative ML models. Such threats and their ease of implementation in communication networks necessitates the use of robust learning algorithms, that are agnostic to the network and radio parameters. In this work we demonstrate the use of generative adversarial learning for the task of robust transmitter identification.</p><p>Unlike the image or speech processing domain, where ML techniques have been widely successful, learning in the RF domain is in a nascent state. Traditional ML techniques cannot be easily extended to the RF domain because of the unpredictable and varied nature of RF signals. Furthermore, the presence of adversaries make it even more difficult to learn and characterize RF signals due to unreliability of the underlying data. For example, in order for ML techniques to be effective for the task of emitter identification, one must choose an attribute or feature that is unique to a transmitter, irrespective of the signals it transmits. A feature that is commonly used for this task is the "I/Q imbalance" that is generated by the random noise introduced into the transmitter manufacturing process due to the use of uncharacterized mixers, oscillators and unbalanced low pass filters <ref type="bibr" target="#b1">[2]</ref>. However, building robust learning systems using traditional methods that only uses the "I/Q imbalance" is hard due to the underlying characteristics of the RF channel. This when coupled with the presence of active adversaries, renders the use of traditional learning algorithms in RF channels moot.</p><p>Inspired by the possibility of using "I/Q imbalance" for the task of transmitter identification, we explore the idea of automatic feature learning using multi-layer neural networks (NNs) to learn deep feature representations that are able to implicitly exploit this imbalance for transmitter "fingerprinting". In this paper, we first demonstrate the use of generative adversarial nets (GAN) to disambiguate trusted transmitters from rogue (fake) ones. After eliminating the rogue transmitters, we use a standard NN model to identify (classify) the trusted transmitters based on their radio fingerprints. Among the various approaches that can be used to discern this feature space, deep learning (DL <ref type="bibr" target="#b2">[3]</ref>) based methods provide an efficient and automatic way of learning and characterizing the same. These methods can learn and analyze the inherent properties of large deployments and characterize the associated parameters for automatic feature learning for the purpose of classification (or regression). Deep neural networks (DNNs) have been shown to be effective for automatically learning discriminating features from the data <ref type="bibr" target="#b3">[4]</ref> and with proper choice of the NN architecture and associated parameters, arbitrarily good approximations to the decision boundaries can be computed <ref type="bibr" target="#b4">[5]</ref>. Since the task of classification is equivalent to learning the decision boundary, we use NNs as the obvious choice for a learning machine.</p><p>The main contributions of this paper are:</p><p>• We propose and implement RFAL using a GAN with two primary components: i) a generative model that uses a deep neural network (DNN) for generating fake (aka, counterfeited) signals that closely resembles the real signals, by deducing the parameter space and replicating the time-invariant features and ii) a discriminative model that also uses a neural network (DNN) to distinguish trusted transmitters from rogue ones. During the learning phase, the outcome of the decision process is fed to the generative model, allowing the adversary (generator) to update its model. The generator thus serves as a compact front-end for mimicking a transmitter (rogue transmitter in this case).</p><p>• Once RFAL detects the trusted transmitters from the rogue ones, RFAL uses standard NN models to differentiate between the different trusted transmitters. RFAL first uses a convolutional neural network (CNN) which leverages the correlation between the complex-valued I/Q data constellations. We also test RFAL using a fully connected deep neural network (DNN) that improves upon the accuracy of the CNN. Finally, a recurrent neural network (RNN) with both long short term memory (LSTM) and gated recurrent units (GRU) is used with RFAL that exploits the time series properties of the I/Q data. • Our models have been validated on a laboratory testbed consisting of several Universal Software Radio Peripheral (USRP) B210s <ref type="bibr" target="#b5">[6]</ref> transmitters and a RTL-software defined radio (RTL-SDR) receiver <ref type="bibr" target="#b6">[7]</ref>. The USRPs transmitted signals on a particular frequency which were received by the RTL-SDR. The generative and discriminative models were trained and tested on the collected dataset which has 1024 complex I/Q values per timestamp, generating 2048 features. The unique pattern of variation of the I/Q imbalances for each radio is captured by the deep feature embedding learned by multiple layers of the DNN. • We collect I/Q data from a SDR made by another manufacturer, namely ADALM-PLUTO <ref type="bibr" target="#b7">[8]</ref>. We show that the I/Q imbalance is more pronounced (and thus easier to exploit both explicitly as well as implicitly) when different types of SDRs (from different manufacturers) are used as transmitters. • We also collect three more datasets of I/Q values from 8 USRP B210s with varying signal-to-noise-ratio (SNR).</p><p>We use distance and multi-path as the defining factors for SNR variation during data-collection. • We train the proposed models and present a competitive analysis of the performance of our models against the traditional techniques and state-of-the art techniques for transmitter identification (classification). Results reveal that the proposed methods out-perform the existing ones thus establishing the superiority and usefulness of the proposed models, more so considering the fact that the proposed models do not require any pre-processing of the raw I/Q data that feeds into the NN models. • The novelty of the proposed work lies in accurately modeling and implementing the proposed generative and discriminative models on real hardware using raw I/Q data. To the best of our knowledge, this is the first paper that uses GANs to identify adversarial RF signals for fingerprinting radio transmitters.</p><p>The rest of the paper is organized as follows: Section II presents some background on I/Q imbalance and discusses some prior work that are relevant to this paper. The GAN architecture along with the generator and the discriminator models are proposed in Section III. The various NN models used are discussed in Section IV. We present the testbed setup and evaluation framework in Section V. The results are presented in Section VI and conclusions are drawn in the last section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND AND RELATED WORK</head><p>In this section, we introduce the idea of I/Q imbalance and discuss its usefulness for the task of transmitter fingerprinting. We also present the machine learning (ML) techniques that are relevant to this paper, specifically GAN and NNs. We also present existing work that uses these ML techniques for transmitter identification and classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. I/Q Imbalance</head><p>The low price of radio devices comes with a trade-off; namely the presence of "almost undetectable" hardware impairments in the radio units due to the use of inexpensive bulk produced commercial off-the-shelf (COTS) components during manufacturing. One such impairment is the imbalance between the in-phase (I) and quadrature (Q) components of the transmitted signal, commonly known as the "I/Q imbalance," that is unique to different radio hardware and are caused by imperfections in local oscillators and mixers. As a result of this, the I and Q components of the modulator are not orthogonal. When a signal is transmitted using a particular radio transmitter having an I/Q imbalance, this is imposed over the complex-valued I/Q data that is being transmitted <ref type="bibr" target="#b8">[9]</ref>, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. The presence of I/Q imbalance leads to performance degradation for higher order modulations because the symbol rotation becomes more sensitive with increasing number of constellations, towards both the I and Q components <ref type="bibr" target="#b9">[10]</ref>. The number of resources having information about the I/Q imbalance of real systems is limited. Some prior works <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b15">[16]</ref> on I/Q imbalance estimation and compensation have reported amplitude imbalance test values ranging from 0.02 to 0.82 and phase imbalance test values between 2°and 11.42° <ref type="bibr" target="#b8">[9]</ref>. These estimates can in turn be used to compensate for the imbalance. In spite of these techniques for compensation of the imbalance, the fact remains that all transceivers exhibit this unique I/Q imbalance. Furthermore, the I/Q imbalance depends on the choice of the hardware components used, and is an unwanted byproduct of the manufacturing process that is hard to imitate. Hence the I/Q imbalance can be used as a basis for feature engineering (implicit or otherwise) for transmitter identification and recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Generative Adversarial Net</head><p>The idea of a generative adversarial net (GAN) <ref type="bibr" target="#b16">[17]</ref> in machine learning is based on synergistic application of ideas from game theory and unsupervised learning. It consists of two competing systems: a generator (adversary) and a discriminator. The input from the "adversaries" is used to build robust discriminative models that can operate in the presence of real adversaries. The overall training mechanism can be conceptualized as a min-max game with two players, namely the generator and the discriminator. They help each other to improve themselves through an iterative training process. Though in theory, the generator and discriminator should play the game indefinitely, in reality, depending on the ratio of data and model density, the discriminator overpowers the generator in a finite amount of time, due to the vanishing gradient of the generator. In practice, this results in generating more accurate and robust ML models. Note that the discriminator implementation is made deeper than the generator in order to get a purposeful implementation of the GAN framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Relevant Neural Networks</head><p>Neural networks (NNs) are a biologically-inspired learning paradigm that uses supervised training for building robust learning models for a variety of tasks and have been shown to be successful across several application areas. For the task of learning from RF signal data, we consider the following three learning paradigms using NNs.</p><p>1) CNN: Convolutional neural networks (CNN) are a class of NNs where the architecture operates around the idea of learning local features from the input (like spatial correlation) through the use of specially designed structures called "filters," which can be considered as masks that are designed to elicit special responses from the input data. Fully connected networks can be augmented with convolutional layers for faster training through learning progressively finer features, that in turn help the network to learn more compact and meaningful representations. Convolutional layers are like ordinary hidden layers, but instead of being fully connected to the input (or the nodes of the previous layer), they are only connected to a subset of the input (or previous layer) nodes. CNNs have proven to be effective not only for image and video processing <ref type="bibr" target="#b17">[18]</ref>, but also in the radio frequency (RF) domain. There have been quite a few attempts at using CNN for learning different RF parameters <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>.</p><p>2) DNN: Fully connected Deep Neural Networks (DNNs) are standard NNs but with multiple hidden layers (usually more than one hidden layer). Though the idea of NN has been around for quite sometime and there have been several studies as regards to their capability for approximating unknown functions, it has been the success of deeper neural architectures, which has brought the field of neural network powered Artificial Intelligence (AI) into renewed focus.</p><p>DNNs <ref type="bibr" target="#b2">[3]</ref> (like other neural networks) compute an embedding of the raw inputs in an embedded feature space and use this representation for learning a model for tasks such as classification and regression. One of the advantages of using such architectures for building learning systems is the fact that the feature space embedding is computed automatically.</p><p>Given enough training data to the DNN, it can learn the required representations without the need of incorporating prior knowledge from experts, through the use of feature engineering.</p><p>3) RNN: Automatic transmitter identification using characteristics of the transmitted signal is akin to learning the noise of the transmitter and using it for creating a "fingerprint" that is used for disambiguation. In order to estimate the noise of a RF system, the learning algorithm needs to "listen" to the underlying signal over time and "remember" the same, for noise estimation. Previously, NNs lacked this capability when used in the context of temporal data. Another issue was the problem of vanishing gradients, when trying to use back propagation with temporal data. Both these problems were solved by the invention of Recurrent Neural Networks (RNN) <ref type="bibr" target="#b2">[3]</ref>. RNNs are used for learning and forecasting different features from time series data. Long Short Term Memory (LSTM) <ref type="bibr" target="#b20">[21]</ref> and Gated Recurrent Unit (GRU) <ref type="bibr" target="#b21">[22]</ref> are special types of RNN which are designed to learn the long term inherent dependencies of time series data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Related Works</head><p>The problem of transmitter classification has been studied in the past. Here we first discuss a few traditional learning based approaches for transmitter classification. Finally, we discuss more recent transmitter identification methods based on the idea of automatic feature detectors (like neural networks). We also discuss the advantages of using automatic feature learning techniques over the traditional ones.</p><p>1) Traditional Learning based Techniques: Traditional transmitter classification methods are based on statistical learning techniques that use expert engineered features which leverage some unique characteristics of the transmitters. In <ref type="bibr" target="#b22">[23]</ref>, the authors proposed a genetic algorithm based solution for transmitter classification based on transients. A transient signal is transmitted when a transmitter is powered up or powered down. During this short period (typically few micro seconds), capacitive loads charge or discharge. A genetic algorithm generated the "transient times" from 5 different types of transmitters, which were later classified using a NN model yielding a 85% -98% accuracy. It is to be emphasized that the experimental results were solely based on the synthetically generated transient values. Though this work used NNs for the final classification, the features (transients) were empirically determined and hence we categorize this as an example of a traditional approach. A multifractal segmentation technique was proposed in <ref type="bibr" target="#b23">[24]</ref> using the same concept of transients. The segmentation technique extracted significant features from transient signals and generated a compact multifactral model. Later a probabilistic NN classifier achieved 92.5% success rate over the extracted transient features in a simulated environment. Another transient based transmitter classification was proposed in <ref type="bibr" target="#b24">[25]</ref>. A k-nearest neighbor discriminatory classifier was used to create a classification engine which leveraged transient signals for spectral feature selection. The authors achieved a 97% accuracy at 30 dB SNR and 66% accuracy at 0 dB SNR for classification of 8 transmitters.</p><p>A different approach for transmitter fingerprinting was proposed in <ref type="bibr" target="#b25">[26]</ref>, where the authors classified FM radio transmitters based on unique stray features extracted from spurious modulation characteristics. The proposed approach was able to classify samples (20 dB SNR) from 3 FM radio stations with 62%-71% accuracy. This method does not provide a competitive accuracy and is also constrained by the need to have knowledge of modulation technique. A particle swarm optimization (PSO) technique was proposed in <ref type="bibr" target="#b26">[27]</ref>, where two radar transmitter models were classified based on the radar pulse's time-frequency representation. An acceptable classification accuracy was reported with 20 dB SNR and relatively low component tolerances. In <ref type="bibr" target="#b27">[28]</ref>, the authors proposed a location-based transmitter fingerprinting approach by extracting signal characteristics (skewness and kurtosis) from wavelet transform. This transmitter location fingerprint was performed for 4 stationary transmitters in an indoor office environment. In <ref type="bibr" target="#b28">[29]</ref>, the authors proposed a dimensionality reduction method for extracting intrinsic features from bispectrum information of transmitters. They reported 99% accuracy for transmitter identification from the bispectrum matrices. However, deployment of such techniques in real-time is challenging due to the additional overhead for generating the bispectrum before the classifier can be invoked for identification.</p><p>As seen from the above discussion, there are some advantages to using traditional fingerprinting techniques such as classifying the transmitters based on their unique identifications in that we are able to leverage the expertise of the "human-in-the-loop" using such techniques through feature engineering. However, these methods have extra overhead due to the feature extraction step and furthermore the quality of the solution is constrained by the knowledge of the expert making such techniques limited in scope. Moreover, as the features are signal and protocol dependent, any change in the nature of the transmission mandates a change in the underlying model, thus making them hard to generalize across different types of transmissions (having varying protocols, heterogeneous transmitters etc.).</p><p>2) Automatic Feature Learning based Techniques: In recent years, there has been some effort at using automatic feature learning techniques for fingerprinting RF transmitters. In <ref type="bibr" target="#b18">[19]</ref> the authors presented a radio modulation classification method using naively learned features. They have shown that blind temporal learning on densely encoded time series using CNNs is a viable approach. However, this method did not perform well in the low signal to noise ratio (SNR) regime. In <ref type="bibr" target="#b19">[20]</ref>, the authors have presented an unsupervised learning technique using convolutional autoencoders, to learn the modulation basis functions and then leverage that to recognize different digital modulation schemes. They also proposed and evaluated quantitative metrics for evaluating the quality of the encoding using domain relevant performance metrics.</p><p>In <ref type="bibr" target="#b29">[30]</ref> the authors have demonstrated the use of NN for modulation detection. Apart from the results, an interesting aspect of the work is the way I/Q values were used as input to the NN. More precisely, given N I/Q values, the authors used a vector of size 2N as an input to the NN, effectively using the I and Q components as a tuple representing a point in the complex plane. A method for modulation classification was proposed in <ref type="bibr" target="#b30">[31]</ref>, for a distributed wireless spectrum sensing network. The authors used a recurrent neural network using long short term memory (LSTM) cells yielding 90% accuracy on a synthetic dataset <ref type="bibr" target="#b31">[32]</ref>.</p><p>An in-depth study on the performance of deep learning based radio signal classification was presented in <ref type="bibr" target="#b32">[33]</ref>. The authors considered 24 modulation schemes with a rigorous baseline method that uses higher order moments and strong boosted gradient tree classification for detection. The authors also applied their method to real over-the-air data collected by Software Defined Radios (SDRs). In <ref type="bibr" target="#b33">[34]</ref> an approach based on the idea of adversarial learning was proposed for synthesizing new physical layer modulation and coding schemes. The adversarial approach is used to learn the channel response approximations in any arbitrary communication system, enabling the design of a smarter channel autoencoder. All these approaches demonstrate the efficacy of using an "end-to-end" technique based on learning deep feature representations, for different tasks in the RF domain.</p><p>There have been quite a few studies that have used CNN based models for automatic feature learning <ref type="bibr" target="#b34">[35]</ref>- <ref type="bibr" target="#b40">[41]</ref> for the task of transmitter classification (or identification). The CNN models presented in <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b39">[40]</ref> require some preprocessing on the raw signal data before it can be used as input. In <ref type="bibr" target="#b37">[38]</ref>, the authors compared several learning paradigms for the task of transmitter identification. More precisely, they looked at conventional deep neural nets, convolutional neural nets, support vector machines, and deep neural nets with multistage training. They showed that deep neural nets with multistage training worked best for the problem and achieved 100% accuracy with a novel dataset having 12 transmitters. On the other hand CNN models were proposed in <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b40">[41]</ref> for existing datasets (ACARS <ref type="bibr" target="#b41">[42]</ref>, ADS-B <ref type="bibr" target="#b42">[43]</ref>, FIT/CorteXlab <ref type="bibr" target="#b43">[44]</ref>). However, none of these models directly take the the raw signal data as input. Note that none of the methods that we have discussed till now in regards to the task of transmitter identification are resilient to the presence of active adversaries. This motivated us to propose a robust NN based model which would be resilient to the presence of active adversaries and at the same time provide an end-to-end solution to the transmitter classification problem.</p><p>3) Comparison of Traditional and Deep Learning based Methods: All the traditional techniques that have been used for RF analysis lack flexibility and robustness. These approaches require an expert's involvement for determining which features (e.g., transients, spurious modulation, etc.) to extract and how to design an algorithm tuned to that feature. Even if a feature is identified, it is not necessary that this feature will be applicable for all scenarios. For example, location based fingerprinting <ref type="bibr" target="#b27">[28]</ref> will work well for indoor environments but will fail for non-stationary transmitters. However, deep learning (DL) based methods are capable of learning the features automatically from the data and hence they do not require the feature engineering step. Furthermore it is possible to use DL techniques in conjunction with adversarial learning to build robust transmitter classification models that can function in the presence of active adversaries. In this work, we use the raw I/Q data as an input to the learning model. The model automatically discerns the features that can encode the information required to disambiguate the transmitters. Note that the features computed by the DL system can be implicitly based on the "I/Q imbalance" or some other intrinsic features of the transmitter or a combination of these.</p><p>4) I/Q Imbalance based Fingerprinting: "I/Q imbalance" based fingerprinting approaches provide more significant discriminant information than transient based or modulationmetrics based approaches <ref type="bibr" target="#b44">[45]</ref>. Though the use of RF signal data in general (and I/Q data in particular) with machine learning algorithms has been limited in the past, more recently there has been several applications (see <ref type="bibr" target="#b45">[46]</ref> and references therein).</p><p>An "I/Q imbalance" based fingerprinting approach was proposed in <ref type="bibr" target="#b44">[45]</ref>, where a subclass discriminant analysis (SDA) ML method was used to estimate the distortion parameters from the I/Q constellations as features. The proposed method was tested on transmitted signals from 7 Time-division multiple access (TDMA) satellite terminals, relayed by a transparent transponder, giving 97% accuracy over 15 dB SNR. However, this method is not guaranteed to capture the difference between transmitter's "I/Q imbalances," as it is aggregated by the imbalance of the transponder. Similarly, a classifier based on Gaussian mixture models (GMM) was proposed in <ref type="bibr" target="#b46">[47]</ref>. Though, the study showed ∼100% accuracy, the experiments were conducted on artificial data. A simulation-based transmitter authentication scheme was proposed in <ref type="bibr" target="#b47">[48]</ref> using an "I/Q imbalance" matrix and multiple collaborating receivers. After analyzing these existing DL techniques, it is evident that there is still a lack of systematic "end-to-end" approaches, that can use the raw signal data from real transmitters and exploit the I/Q imbalance for fingerprinting. It must be noted that DLbased RF methods will not only exploit the "I/Q imbalances" but also extract and use other intrinsic features related to the transmitters that may or may not be directly related to I/Q imbalance. However, the end product will conceptually be able to differentiate between transmitters having different "I/Q imbalances."</p><p>Motivated by the capacity of deep learning systems to automatically learn deep discriminative features, we focus on the problem of transmitter identification in the presence of adversaries using a generative adversarial network (GAN). The idea of training discriminative models via an adversarial process was first proposed by Goodfellow <ref type="bibr" target="#b16">[17]</ref>. Since then, GANs have been adopted for solving problems in varied fields of applications and particularly for image processing where GANs have proved to be highly efficient for several different tasks <ref type="bibr" target="#b48">[49]</ref>- <ref type="bibr" target="#b50">[51]</ref>. We take inspiration from <ref type="bibr" target="#b29">[30]</ref> for using the raw I/Q data for input to our networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. GAN FOR ROGUE TRANSMITTER DETECTION</head><p>As pointed out earlier, most of the traditional ML techniques are susceptible to malicious attacks. The susceptibility increases once the attacker knows the features used by the learning algorithm. With the knowledge of the feature space (and hence the underlying feature distribution) the attacker becomes smart enough to mislead the learning process. Thus, for the problem of transmitter identification, the target of the adversaries would be to learn the probability distribution of the training data used for model creation, given a sample of the same. With this knowledge, the adversaries can use a generative model to generate signals so as to spoof the transmission of known transmitters. A GAN <ref type="bibr" target="#b16">[17]</ref> uses a generative model which enables the realistic creation of samples from a given distribution which can then be used to train a discriminator for identifying real samples from false/counterfeited ones obtained from the generator. The GAN training makes the model resilient over the trained adversarial data and thus intuitively helps it to be prepared for the "yetto-be-seen" adversaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Proposed GAN Architecture</head><p>The proposed GAN framework, as shown in Fig. <ref type="figure" target="#fig_1">2</ref>, has two primary components: a generative model (G) that generates false data using a given data distribution and a discriminative model (D) that estimates the probability that a sample came from the training data (that is known transmitters) rather than G. The adversary generates random modulation scheme (m(t)), signal amplitude (r(t)) and phase (l(t)) and mixes additive white Gaussian noise (AWGN) (n(t)) with the false signal. The generated signal (g(t)) which is initially random in nature improves over time as the generator learns from the discriminator and improves on its ability to imitate real data. On the other hand, the discriminator (D) gets input from both the generator (G) and Trusted transmitters. This helps it to learn to differentiate between real and false inputs. The known transmitter data is collected and fed to the discriminator (D) as raw I/Q values.</p><p>Overall, our objective is to train G in such a way that will maximize the probability of D making a mistake. G tunes its hyper parameters with the feedback from D. We argue that GAN is an efficient way to generate correlated data samples and thereby approximate an accurate generative model, something the adversary aims to achieve. Once the model is trained, RFAL synthesizes signals using the generator to mimic adversarial transmitters based on the learned probability distribution on the sample space of I/Q signal data from the known transmitters. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The Generative Model</head><p>In order to build the generator, we treat the overall problem as an N -class decision problem where the input is a complex base-band time series representation of the received signal. That is, the training data consists of the in-phase and quadrature components of a radio signal obtained at discrete time intervals through analog to digital conversion with a carrier frequency to obtain a 1×N complex valued vector. Classically, this is written as:</p><formula xml:id="formula_0">s(t) = c 1 m(t) + c 2 r(t) + c 3 l(t)<label>(1)</label></formula><p>where s(t) is a continuous time series signal modulated onto a sinusoid with either varying frequency, phase, amplitude, trajectory, or some permutation of these parameters. Here, m(t), r(t), and l(t) are the time series continuous signals for modulation, amplitude, and phase respectively, selected randomly by the generator. The coefficients c 1 , c 2 , and c 3 are some path loss or constant gain terms associated with m(t), r(t), and l(t) respectively. The output g(t) is obtained as:</p><formula xml:id="formula_1">g(t) = s(t) + n(t)<label>(2)</label></formula><p>where n(t) is the AWGN. The output g(t) is then fed to a generator which is used as an unsupervised learning tool as a part of the GAN framework. The generator learns the probability distribution p g (x) over sample space (x) of the I/Q input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. The Discriminative Model</head><p>The discriminative model learns by minimizing a cost function during training. The cost function, C(G; D), depends on both the generator (G) and the discriminator (D). It is formulated as</p><formula xml:id="formula_2">C(G; D) = E p data (x) log D(x) + E pg(x) log(1 - D(x))</formula><p>, where p g (x) is the generator's distribution over x, p data (x) is the data distribution over x, D(x) is the probability that x came from p data (x) than p g (x) <ref type="bibr" target="#b16">[17]</ref>. The training is formulated as:</p><formula xml:id="formula_3">max D min G C(G; D)<label>(3)</label></formula><p>For the GAN framework, there is an unique optimal discriminator for a fixed generator, D * (x) = p data (x) p data (x) + p g (x) <ref type="bibr" target="#b16">[17]</ref>.</p><p>It is also inferred that G is optimal when p g (x) = p data (x), i.e., the generator is optimal when the discriminator cannot distinguish real samples from false ones. Similarly, the D is optimal when the discriminator can recognize each real sample from the false ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. GAN Implementation</head><p>For implementing the GAN, we use "over-the-air" signal data collected from the trusted transmitters. (The testbed setup is discussed in Section V.) The generator (G) generates counterfeit data from the same sample space to impersonate Once the initial random values are generated, they are passed through two dense layers of size 512 and 1024 respectively with tanh <ref type="bibr" target="#b17">[18]</ref> activation. Then a single dense layer of twice the sample size (2048 in our case) is invoked with the sigmoid activation function <ref type="bibr" target="#b17">[18]</ref>. G continues to learn the data distribution (p g ) and generates counterfeit samples of size 2048 within the sample space of the I/Q values.</p><p>D consists of one input layer of 2048 nodes, two hidden layers of 1024 and 512 nodes respectively, and finally a softmax output layer of 2 nodes to classify an input as either Counterfeited or Trusted. We used tanh as activation function at the hidden layers and added Dropout [52] of 0.5 in between these layers for regularization. We train both the generator and discriminator through iterative sequential learning to strengthen the generative model over time.</p><p>Once the discriminator recognizes the trusted transmitters from the counterfeit ones, we feed the trusted transmitter data into another DNN (either convolutional or fully connected (dense)) for further classification into a number of classes (as determined by the number of trusted transmitters). Next we discuss the NN architectures we use for this purpose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. PROPOSED NEURAL NETWORKS FOR TRANSMITTER CLASSIFICATION</head><p>Recent advances in NNs have made it possible to obtain robust models with low generalization errors by training "deep" neural architectures efficiently. The "depth" signifies the number of iterative operations performed on the input data using each layer's transfer function and deeper architectures allow the network to learn more robust feature representations from the input data. Though such techniques require higher computation power and involve complicated layer-by-layer back-propagation, nevertheless, most DL systems are able to efficiently learn deep feature representations from the training data using back-propagation and some variation of gradient decent, with adaptive learning rates (e.g., Adam <ref type="bibr" target="#b52">[53]</ref>) and regularization to avoid overfitting (e.g., Dropout <ref type="bibr" target="#b51">[52]</ref>). Next, we present our proposed NN models for classification of Trusted transmitters. We use a total of 8 transmitters, the details of which are given in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. CNN Model</head><p>In order to capture the correlation between I/Q values, we started by implementing a convolutional neural network (CNN). We implement the CNN with three conv2D layers with 1024, 512 and 256 filters respectively, a Flatten operation and three fully connected (FC) layers of size 512, 256 and 8 nodes <ref type="bibr" target="#b53">[54]</ref> respectively, as shown in Fig. <ref type="figure" target="#fig_4">5</ref>. We use Dropout <ref type="bibr" target="#b51">[52]</ref> of 0.25 and 0.5 after each conv2D and dense layer respectively. We also use kernel size of (2,3) and stride of (2,2) at each of the Conv2D layers. We apply a pooling layer MaxPooling2D after each conv2D layer with pool size of (2,2) and stride of (2,2). We use ReLU <ref type="bibr" target="#b54">[55]</ref> activation for all convolution and fully connected layers, other than the last, where we use softmax. Note that, the number of nodes in the last layer is changed based on the number of classes the dataset has. We use Adam <ref type="bibr" target="#b52">[53]</ref> (with learning rate of 10 -3 ) based optimization with categorical cross-entropy training.</p><p>It is to be noted that we design the CNN with only 3 convolution layers and 4 fully connected layers for faster training <ref type="bibr" target="#b55">[56]</ref>, since no significant increase in the testing accuracy was observed after increasing the number of layers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. DNN Model</head><p>Apart from the CNN discussed above, we also use a fully connected (dense) DNN for the task of trusted transmitter classification. The implementation of the DNN is similar to the discriminator model of GAN and is shown in Fig. <ref type="figure" target="#fig_5">6</ref>. The only difference is that the softmax output layer has 8 nodes to recognize the 8 transmitters (or more generally k nodes if there are k transmitters). We implement a DNN with 5-layers with 1 input layer and 4 dense layers. We use tanh <ref type="bibr" target="#b17">[18]</ref> activation function for the Dense layers in this model. We apply biases and regularization to avoid under-and over-fitting. In this case also, use Adam <ref type="bibr" target="#b52">[53]</ref> based optimization with learning rate of 10 -3 , for categorical cross-entropy training. In order to exploit the the time-series property of the collected data, we use RNNs with LSTM and Gated Recurrent Unit (GRU) cells, as both avoid the "vanishing" or the "exploding" gradient problems <ref type="bibr" target="#b56">[57]</ref>.</p><p>1) Long Short Term Memory (LSTM) Cell Model: Though LSTM cells can be modeled and designed in various ways depending on the need, we implement the cells as shown in Fig. <ref type="figure">7</ref>. In each LSTM cell, there are (i) three types of gates: input (i), forget (f ) and output (o); and (ii) a state update of internal cell memory. The most interesting part of the LSTM cell is the "forget" gate, which at time t is denoted by f t . The forget gates decide whether to keep a cell state memory (c t ) or not. The forget gates are designed as per the equation ( <ref type="formula" target="#formula_4">4</ref>) on the input value of x t at time t and output (h t-1 ) at time (t -1).</p><formula xml:id="formula_4">f t = σ(W xf x t + W hf h t-1 + b f )<label>(4)</label></formula><p>where, σ denotes the sigmoid activation function, W xf and b f represent the associated weight and bias respectively, between the input (x) and the forget gate (f ). Once f t determines which memories to forget, the input gates (i t ) decide which cell states ( c t ) to update as per equations ( <ref type="formula" target="#formula_5">5</ref>) and <ref type="bibr" target="#b5">(6)</ref>.</p><formula xml:id="formula_5">i t = σ(W xi x t + W hi h t-1 + b i )<label>(5)</label></formula><formula xml:id="formula_6">c t = tanh(W xc x t + W hc h t-1 + b ct-1 )<label>(6)</label></formula><p>In equation ( <ref type="formula">7</ref>), the old cell state (c t-1 ) is updated to the new cell state (c t ) using forget gates (f t ) and input gates (i t ):</p><formula xml:id="formula_7">c t = f t • c t-1 + i t • c t (7)</formula><p>where, • is the Hadamard product. Finally, RFAL filters the output values through output gates (o t ) based on the cell states (c t ) as per equations ( <ref type="formula" target="#formula_8">8</ref>) and <ref type="bibr" target="#b8">(9)</ref>.</p><formula xml:id="formula_8">o t = σ(W xo x t + W ho h t + b o )<label>(8)</label></formula><formula xml:id="formula_9">h t = o t • tanh(c t )<label>(9)</label></formula><p>We design and implement a RNN with LSTM, the structure of which is shown in Fig. <ref type="figure">8</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Gated Recurrent Unit (GRU) Model</head><p>The main drawback of using LSTM cells is the need for additional memory. GRUs <ref type="bibr" target="#b21">[22]</ref> have one less gate than LSTMs for the same purpose, thus having a reduced memory and CPU footprint. The GRU cells control the flow of information just like the LSTM cells, but without the need for a memory unit. It just exposes the full hidden content without any control. It has a "reset gate" (z t ), an "update gate" (r t ), and a cell state memory (c t ) as shown in Fig. <ref type="figure" target="#fig_7">9</ref>. The reset gates determine whether to combine the new input with a cell state memory (c t ) or not. The update gate decides how much of c t to retain. The equations ( <ref type="formula" target="#formula_10">10</ref>), ( <ref type="formula" target="#formula_11">11</ref>), <ref type="bibr" target="#b11">(12)</ref>, and (13) related to different gates and states of GRU are given below.</p><formula xml:id="formula_10">z t = σ(W xz x t + W hz h t-1 + b z )<label>(10)</label></formula><formula xml:id="formula_11">r t = σ(W xr x t + W hr h t-1 + b r )<label>(11)</label></formula><formula xml:id="formula_12">c t = tanh(W xc x t + W hc (r t • h t-1 ))<label>(12)</label></formula><formula xml:id="formula_13">h t = (1 -z t ) • c t + z t • h t-1<label>(13)</label></formula><p>We implemented the recurrent model with GRU cells and used the same architecture as the LSTM implementation (GRU cells instead of LSTM cells at the first two layers). The proposed GRU network needs fewer parameters than the LSTM model. In this case, we also use SGD <ref type="bibr" target="#b17">[18]</ref> based optimizer with a learning rate of 10 -3 . An quantitative comparison of the results is discussed in Section VI-F. In order to validate the proposed models, we wanted to use our own "over-the-air" RF data collected from different transmitters, instead of synthetic or publicly available data. We implemented the generator and discriminator (of the GAN) to detect an unknown (adversarial) transmitter and then used the NN models to classify the known ones, the details of which are discussed next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Signal Generation and Data Collection</head><p>In order to learn the discriminating fingerprints (features) of similar transmitters, we used 8 universal software radio peripheral (USRP) radios of the same kind, namely B210 from Ettus Research <ref type="bibr" target="#b5">[6]</ref>. The overall setup for signal generation and reception is shown in Fig. <ref type="figure" target="#fig_8">10</ref>. The B210s were programmed to transmit random data on 904 MHz using Quadrature Phase Shift Keying (QPSK) modulation. We used GNURadio <ref type="bibr" target="#b57">[58]</ref> for signal processing and data transmission. The flow graph is presented in Fig. <ref type="figure" target="#fig_0">11</ref>. The modulated signal was transmitted through the USRP sink block. For the receiver, we used a RTL-SDR <ref type="bibr" target="#b6">[7]</ref> which captured "over-the-air" raw I/Q data and wrote it onto a file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Analysis of Data Collection Environment</head><p>We set up the data collection testbed in an indoor lab environment with a direct line of sight between the transmitter and the receiver with a distance of 10 ft. Thus, the underlying channel can be modeled as a Rician fading channel. There was also multi-path effects due to the reflections from the walls. We measured the signal to noise ratio (SNR) using a RTL-SDR <ref type="bibr" target="#b6">[7]</ref> dongle and Spekrtum <ref type="bibr" target="#b58">[59]</ref> which is an open source spectrum analyzer available for both Windows and Linux. We decided to calibrate the SNR using the Spekrtum software (rather than using a spectrum analyzer) due to cost and portability issues. We found that the noise floor in the lab was between -20 dB and -30 dB. The signal strength for the 200 KHz (from 903.9 MHz to 904.1 MHz) channel was between 0 dB and 10 dB. We set the transmitter gain to 45 dB and calculated the SNR as the difference between the noise floor and the signal strength. Our calculated SNR was 5 dB -(-25 dB) = 30 dB, with a 45 dB transmitter gain. It is to be noted that the signal strengths (in dB) of noise and signal measured by the Spektrum is relative, but the difference between them is absolute.</p><p>We also collected data for different SNR values by varying the transmitter-receiver distance and hindering the line-of-sight in the laboratory. As mentioned earlier, we obtained a SNR of 30 dB by keeping the transmitter and receiver at 10 feet from each other. Similarly we collect 3 more datasets with SNR of 20 dB, 10 dB and 0 dB at 20 feet, 30 feet, and 45 feet respectively. It is to be noted that the SNR of the transmitter frequency was measured at the receiver with Spektrum. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. I/Q Datasets</head><p>We collected raw I/Q signal data with a sample size of 1024, i.e., each sample consists of 1024 I and 1024 Q values. The choice of 1024 as the sample size was sufficient to capture the unique pattern of I/Q imbalances and at the same time it was not computationally expensive. We experimented with other sample sizes as well: smaller sample size yields degraded performance whereas larger sample size does not improve the accuracy. We collected 40,000 training samples from each transmitter to avoid the data skewness problem observed in ML. The configuration parameters used are given in Table <ref type="table">I</ref>. We collected two different datasets at 30 dB SNR and three datasets with three different SNRs, as discussed below.</p><p>1) Homogeneous Dataset: For the "homogeneous" dataset, we use only one type of radio, namely, the USRP B210 from Ettus Research. We collected two sets of data: (i) using 4 USRP B210 transmitters: 6.8 GB size, 160K rows and 2048 columns and (ii) using 8 USRP B210 transmitters: 13.45 GB size, 320K rows and 2048 columns. Note that the SNR was 30 db.  2) Heterogeneous Dataset: In order to investigate the performance of the proposed classification methods, when different types of transmitters (from different manufacturers) are present, we use PLUTO SDR <ref type="bibr" target="#b7">[8]</ref> apart from the B210s when collecting the data. The GNURadio flow graph for signal generation is similar to Fig. <ref type="figure" target="#fig_0">11</ref> with a different sink block for the PLUTO SDR. Note that the SNR in this case was also 30 db. The 'heterogeneous' datasets were obtained using (i) 2 USRP transmitters: 3.31 GB size, 80K rows and 2048 columns and (ii) 1 USRP B210 and 1 PLUTO transmitter: 2.85 GB size, 80K rows and 2048 columns.</p><p>3) Varying SNR Datasets: We collected 3 more datasets with 8 USRP B210 transmitters and SNRs of 20 dB, 10 dB, and 0 dB respectively. Each dataset is of size ∼13 GB with 320K rows and 2048 columns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Correlation in Dataset</head><p>Correlation between each data sample plays a crucial role in transmitter classification. Given T training samples (for T timestamps) and a sample size of M for each time stamp, where each sample is a vector (I, Q) ∈ C representing a number in the complex plane, we create a new vector </p><formula xml:id="formula_14">X(t) = [I i , Q i ; i = 1, 2, • • • , M ] t ∈ C 2 M ; t = 1,</formula><formula xml:id="formula_15">[I 0 Q 0 I 1 Q 1 I 2 Q 2 I 3 Q 3 I 4 Q 4 • • • I 1023 Q 1023 ] t .</formula><p>We used QPSK modulation, which generates a constellation plot like Fig. <ref type="figure" target="#fig_0">1</ref>. This signifies that the correlation should be between every fourth value, i.e., between I 0 and I 4 , and Q 0 and Q 4 and so on. Hence we calculate the correlation coefficient of between I 0 I 1 I 2 I 3 , I 4 I 5 I 6 I 7 and similarly, between</p><formula xml:id="formula_16">Q 0 Q 1 Q 2 Q 3 and Q 4 Q 5 Q 6 Q 7 and</formula><p>so on. We take the average of all the correlation coefficients for each sample.</p><p>We use numpy.corrcoef for this purpose which uses Pearson product-moment correlation coefficients, denoted by r. The Pearson's method for a sample is given by: The correlations for all the 40,000 samples for each transmitter are shown in Fig. <ref type="figure" target="#fig_1">12</ref>. We observed that around 75% of the samples' correlation coefficients are between -0.1 and 0.1 and the remaining 25% are close to 0.9. However, for transmitter ID 3, all the samples' correlation coefficients are between -0.1 and 0.1. This behavior of transmitter ID 3 is an obvious example of manufacturing differences. However, this observation gives us intuition about the difficulty of CNN with 2D convolutions for the task of transmitter classification. CNNs capture the correlation (local features) in the data. However, in this case, as the nature of the correlations are the same for all but one transmitter, hence there is not enough discriminative information in the correlations to disambiguate between all the transmitters, thus leading to the conclusion that CNNs with simple two dimensional convolutions will not be effective for the classification task. This was later corroborated via our testbed implementation (Section VI). </p><formula xml:id="formula_17">r = (M -1) i=0 (I i -I)(Q i -Q) (M -1) i=1 (I i -I) 2 (M -1) i=0 (Q i -Q) 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Machine Learning Libraries Used</head><p>There are several libraries and tools that implement learning frameworks with support for immensely concurrent GPU architectures, that reduce the burden of programming the traditional GPU routines for training of larger NNs. We use Keras <ref type="bibr" target="#b53">[54]</ref> as the frontend with Tensorflow [60] as the backend. Keras is an overlay on neural network primitives with Tensorflow <ref type="bibr" target="#b59">[60]</ref> or Theano <ref type="bibr" target="#b60">[61]</ref> that provides a customizable interface for quick deployment of complex NNs. We also use Numpy, Scipy, and Matplotlib Python libraries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Performance Metric</head><p>To measure the effectiveness of any NN architecture, "classification accuracy" is used as the typical performance metric. However, "classification accuracy" as it is defined can sometimes be misleading and incomplete when the data is skewed. A confusion matrix overcomes this problem by showing how the classification model performs when it comes to erroneous detections (false alarms), and correct "counterfeit" classifications. It provides more insights on the performance by identifying not only the number of errors, but more importantly the types of errors. As a result we use confusion matrices to display and analyze the results of our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. IMPLEMENTATION RESULTS AND DISCUSSIONS</head><p>In this section, we present the results of i) adversarial transmitter detection using GAN and ii) transmitter classification using different NN architectures. We conducted the experiments on a Ryzen 8 Core system with 64 GB RAM and a GTX 1080 Ti GPU unit with 11 GB memory. For the sake of being robust and statistically significant, we present the experimental results for each model after several runs of each implementation. We focused on four main aspects:</p><p>• Implementing a GAN to distinguish adversarial transmitters from trusted ones. • Implementing a CNN with 2D convolutions to exploit the correlation in collected signal data of the trusted transmitters for trusted transmitter identification. • Implementing a DNN to classify the trusted transmitters.</p><p>• Implementing RNN with both LSTM and GRU cells to improve the accuracy of trusted transmitter classification by exploiting the temporal aspect of the signal data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. GAN Results</head><p>In order to detect the adversarial transmitters, we implemented a GAN based model as described in Section III-D. We used categorical cross-entropy training and Adam <ref type="bibr" target="#b52">[53]</ref> for gradient based optimization. We notice that the discriminator was able to detect the adversarial transmitters with 50% accuracy before the GAN based training. Once the GAN goes through several epochs (&lt; 50) of adversarial training, the optimal discriminator (D * ) is able to detect the Counterfeit transmissions with about 99.9% accuracy as shown by the receiver operating characteristic (ROC) curve and confusion matrix in Fig. <ref type="figure" target="#fig_12">13</ref>. Note that one epoch consists of a forward pass and a backward pass through the GAN over the entire dataset. It is clear from the confusion matrix that the number of false negatives and false positives are very low and well within an acceptable range <ref type="bibr" target="#b17">[18]</ref>. The testing accuracy of the GAN implementation on datasets with different SNRs is presented in Table <ref type="table">II</ref>. The "parameters" represent the total number of hyper-parameters required for the respective model. In Fig. <ref type="figure" target="#fig_13">14</ref>, we present three plots to represent how the proposed generator behaves. Note that we first show the plots using randomly selected 128 samples from both the real and generated datasets. We choose the number 128 as it is also used as the batch size for the training. In Fig. <ref type="figure" target="#fig_13">14(b)</ref>, we see that the data generated before the GAN training does not represent the distribution of the real data as shown in Fig. <ref type="figure" target="#fig_13">14(a)</ref>. It is evident that initially the I/Q values are randomly generated 0 and 1. However, once the generator is trained over multiple iterations, it starts generating more realistic data as shown in Fig. <ref type="figure" target="#fig_13">14(b</ref>) which shows that the distribution of the generated data is starting to resemble the real data shown in Fig. <ref type="figure" target="#fig_13">14(a)</ref>. Once the GAN training converges, the generator has learned the data distribution of the I/Q values from the known transmitters and hence it starts to generate counterfeit data that succinctly captures the actual distribution of the I/Q values. Thus now the generated I/Q values are distributed within the range of [-1,1] as is the case with the real data. Figure <ref type="figure" target="#fig_4">15</ref> shows the plots for the real data and the generated data after full GAN training. These images are obtained by plotting 2000 I/Q samples. Also we do not discuss the theory of why the generator is able to generate realistic data because though there is some idea in the research community as to why GANs work, it is not fully understood yet. Furthermore, since this is a more applied work we refrain from adding such theory into the paper. Rather we provide references which interested readers may consult to learn more about the GANs. Note that though this paper is not about trusted transmitter classification (but rather about using adversarial learning using GANs for identifying rogue transmitters), we decided to explore the capability of systems based on neural networks for the task of trusted transmitter classification as well. Next we present the results of this endeavor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. CNN Results</head><p>Once the rogue transmitters are detected and eliminated, our system classifies the "trusted" transmitters using a neural network. First we used a CNN built according to the implementation details provided in Section IV-A for trusted transmitter classification. We obtain 89.07% and 81.6% accuracy for 4 and 8 transmitter classifications respectively. The accuracy plots and confusion matrices for both the cases are presented in Figs. <ref type="figure" target="#fig_5">16</ref> and<ref type="figure" target="#fig_0">17</ref>. We note that both the training and validation accuracy increases with the number of epochs. However for our CNN implementation the number of false positives and false negatives are somewhat high. Intuitively, this shows that the convolutional filters that were used with the network were not able to identify and encode discriminative features for this task. Since we know that there is at least one discriminative characteristic that distinguishes between the transmitters (namely the I/Q imbalance), we conclude that the input representation that we used with the CNN did not effectively encode these characteristics and hence the system could not efficiently learn them.</p><p>In order to understand the inner workings of the CNN better, we present the feature maps obtained from the first convolution layer of the CNN, for the case of four transmitter classification, in Fig. <ref type="figure" target="#fig_0">18</ref>. It can be seen that each of these feature maps encodes a different pattern, one for each of the four different transmitters. However, we also notice that the convolutions fail to capture the highly discriminative patterns from the I/Q data. Thus for example, none of the feature maps resemble Since further tuning of the CNN parameters was unsuccessful, we decided to build a fully connect DNN to try and achieve better accuracy for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. DNN Results</head><p>To overcome the deficiencies of the CNN, we use a DNN as described in Section IV-B. The DNN yields an accuracy of 96.49% for 4 transmitters and 94.60% for 8 transmitters. The accuracy plots and confusion matrices are shown in Figs. 19 and 20 respectively. It is evident that the number of false positives and false negatives in the confusion matrices are significantly low for the DNN as compared to the CNN and thus intuitively the DNN can capture and learn better features from the I/Q samples than the CNN for the task of transmitter classification. Note that from the perspective of the features learned by the DNN, it is hard to explain the types of features that are learned by these systems. However since the task of classification boils down to learning a decision boundary and recently it has been shown that DNNs are capable of learning approximations of such boundaries efficiently <ref type="bibr" target="#b4">[5]</ref>, the possible reason for the better performance of the DNN might be tied to learning a better approximation to the underlying function representing the decision boundary for this task. For the RNN, we first implement the LSTM cells as described in Section IV-C1. We achieved 97.40% and 95.78% testing accuracy for 4 and 8 transmitters respectively. The accuracy plots and confusion matrices are given in Figs.  Finally, we implement RNN with GRU cells as described in Section IV-D. We achieved 97.85% and 97.06% testing accuracy for 4 and 8 transmitters respectively. The accuracy plots and confusion matrices are shown in Figs. <ref type="figure" target="#fig_18">23</ref> and<ref type="figure" target="#fig_19">24</ref> respectively. It must be noted that the GRU implementation achieves better accuracy than the one using LSTM cells.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Classification Comparison of CNN/DNN/RNN</head><p>Once a transmitter is found to be Trusted via the proposed GAN, we used a CNN, DNN, and RNN respectively, to uniquely identify it. We used 90%, 5%, and 5% to train, validate and test respectively. The overall accuracy of the different NNs for the task of trusted transmitter classification is shown in Table <ref type="table">III</ref>. We see that the CNN does not exhibit the best performance for transmitter classification, which intuitively is due to the lack of distinguishing spatial correlation in the data from each transmitter. In Fig. <ref type="figure" target="#fig_5">26</ref>, we show a graphical representation of the classification accuracy obtained using the different neural network architectures.</p><p>We present the observed empirical training time for each model as the last column in Table <ref type="table">III</ref>. It is evident that the training time for the CNN is almost double compared to the rest of the proposed models, as convolution operations are significantly more complex than other neural network computations. We also conducted experiments by varying the number of transmitters from 2 to 8, using the proposed DNN. In Fig. <ref type="figure" target="#fig_4">25</ref>, we show how the training and testing accuracy varies as the number of transmitters are increased. We note that the training accuracy decreases when there are more classes (more number of transmitters). However the testing accuracy of the model is stable and does not change significantly with the increase in the number of transmitters. This establishes the efficacy of these methods for the task of transmitter classification, as for  production systems one wants the test accuracy to be stable no matter the number of classes involved in the problem.</p><p>In our testbed evaluation one of the goals was to explore different types of NNs to find the architecture (and model) having the best possible accuracy within the constraints of the training time (which was not more than 30 minutes in our test-bed setup for all models). The performance of any NN architecture depends, among other things, on the values of the hyper-parameters. Furthermore, as a given hyperparameter setting may be optimal for one network but not for another, we used different hyper-parameter values to train different networks. Intuitively, this dependence on the values of the hyper-parameters is due to the fact that the underlying optimization problem and hence the solution space, is different for different types of networks. We observed that decreasing the learning rate of the CNN to 10 -4 increases the accuracy by 7-8%. However, decreasing the learning rate to less than 10 -3 for RNN and DNN does not improve the testing accuracy by a significant amount (even by 0.5%). In Table <ref type="table" target="#tab_5">IV</ref> we record the values which gave the best possible accuracy under the constraints of the training time. During each training, we set the maximum epoch to 50 with an early stopping condition, such as, if there is no improvement of validation loss for five consecutive epochs, then the training is stopped. We observed through multiple runs of training, that each of the models converged within a given range of the maximum number of epochs, as presented in Table <ref type="table" target="#tab_5">IV</ref>. It is clear from the the results presented above that the GAN based NN is effective for the task of rogue transmitter identification whereas DNN and RNN are effective for the task of trusted transmitter classification. In summary we have established the following:</p><p>1) A GAN is able to distinguish between Trusted and Counterfeited RF transmitters. 2) CNN yields 81%-86% accuracy for trusted transmitter classification proving the inefficacy of spatial correlation as a discriminative attribute for transmitter classification. 3) DNN yields 94-97% accuracy for known transmitter classification. 4) RNN yields an accuracy of 97% for known transmitter classification using GRU cells. 5) Comparing the accuracies, we can conclude that I/Q data of radio signals exhibits more temporal correlation than spatial correlation. 6) DNN or RNN can be used for transmitter fingerprinting for identifying trusted transmitters and in conjunction with GAN this can be used to create an end-to-end robust system for transmitter identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Computational Complexities</head><p>In this section we present the computational time complexity for the training phase only, as the trained model gives the output within constant time (O(1)) during the deployment phase. Understanding the time complexity of training a NN is still an evolving research area. In <ref type="bibr" target="#b61">[62]</ref>, the authors proved that a NN of depth δ can be learned in poly(s 2 δ ) time, where s is the dimension of the input, and poly(.) takes a constant time depending on the configuration of the system. However, the convolution operations of CNN add additional time complexity along with the forward and back-propagation operations. In <ref type="bibr" target="#b55">[56]</ref>, the authors mentioned that the time complexity for training all the convolutional layers is:</p><formula xml:id="formula_18">O( ζ τ =1 (η τ -1 ν 2 τ .η τ ρ 2 τ )</formula><p>, where ζ is the number of convolutional layers, τ is the index of a convolutional layer, η τ -1 is the number of input channels of the τ th layer, ν τ is the spatial size of the filters at the τ th layer, η τ is the number of filters at the τ th layer and ρ τ is the size of the output  The time complexities for each implemented NN model is presented in Table <ref type="table" target="#tab_7">V</ref>, using the aforementioned results on time complexity of neural network training. The numbers within the parenthesis in the second column represents the total number of layers for a particular model. Note that we have two different datasets of dimensions 160K and 320K and as mentioned earlier, we use 95% of data for training and validation purpose. For example, the complexity for GAN with 8 layers using 95% of 160e3 data samples for training and validation, is poly(0.95 × 160e3 2 8 ). On another note we should mention that for quick estimates of the time complexity of training neural networks, the number of hyper-parameters (as presented in Table <ref type="table">III</ref>) can also be used as a measure of the required training time. Thus, the more the number of hyperparameters, the more the training time required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Experiments with Heterogeneous Dataset</head><p>So far, we have used the proposed trusted transmitter identification models on "homogeneous" datasets in that the transmitters were implemented using the SDRs from the same manufacturer. However, in reality the trusted transmitters can be from several different manufacturers. Now we want to explore how the accuracy of the trusted transmitter identification system would change if "heterogeneous" data obtained from different types of transmitters (manufacturers) (as was discussed in Section V-C) was used. From the testing accuracy as shown in Table <ref type="table" target="#tab_7">VI</ref> we observe that all the NNs perform better when the transmitters are from different manufacturers and hence are fundamentally of different types. This confirms the intuition that radios manufactured using different processes (from different manufacturers) contain easily exploitable characteristics in their I/Q samples, that can be implicitly learned using a NN. We also observe that the CNN can exploit the spatial correlation better for the heterogeneous dataset,  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Existing Transmitter Classification Techniques Comparisons</head><p>Though RFAL demonstrates the use of adversarial learning for rogue transmitter identification, a part of our work has been devoted to the problem of "trusted transmitter classification" after elimination of the rogue transmitters. "Trusted transmitter" identification systems when augmented with adversarial learning systems, as was done in RFAL, results in robust transmitter identification systems that are immune to presence of adversarial transmissions. Though our focus was not on improving or building novel "trusted transmitter" classification systems, we have explored the use of deep learning for building the same using I/Q data from the received signal. In this section we present a comparative study of our approach to "trusted transmitter classification with I/Q data" against some existing techniques for "transmitter classification" and the results of this endeavor is shown in Tables VII for traditional approaches (low accuracy) and VIII for "state-of-theart" (high respectively. Note that here the column refers to the type of inputs used for the classification algorithms. It is to be noted that all the traditional methods use some form of extracted features (obtained through preprocessing of the data) as inputs ( [23]- <ref type="bibr" target="#b25">[26]</ref>), or work with synthetic dataset ( <ref type="bibr" target="#b30">[31]</ref>). A few existing work on modulation recognition <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b32">[33]</ref> using NN based approaches also work on synthetic datasets <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b62">[63]</ref> and hence they do not yield to a fair comparison with our "trusted transmitter classification" approach as well.</p><p>For the "state-of-the-art" approaches, we observe that the test bed experiments have used various types of SDRs for obtaining over-the-air data, or used datasets from actual infrastructure transmitters (ACARS etc.). We present comparison with: (i) <ref type="bibr" target="#b35">[36]</ref>, where same SDR (USRP B210) was used, (ii) <ref type="bibr" target="#b37">[38]</ref> and <ref type="bibr" target="#b39">[40]</ref>, where different SDRs from the same manufacturer (USRP N210, USRP X310) were used, (iii) <ref type="bibr" target="#b34">[35]</ref>, where different types of devices (Zigbee) were used, and (iv) <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b38">[39]</ref> and <ref type="bibr" target="#b40">[41]</ref> where different datasets (ACARS <ref type="bibr" target="#b41">[42]</ref>, ADS-B <ref type="bibr" target="#b42">[43]</ref>, FIT/CorteXlab <ref type="bibr" target="#b43">[44]</ref>) were used.</p><p>The RFAL "trusted transmitter identification" models outperform <ref type="bibr" target="#b34">[35]</ref> where the authors achieved 91.38% accuracy for classifying 7 Zigbee devices. The CNN proposed in <ref type="bibr" target="#b35">[36]</ref> achieved 98% accuracy for 5 USRP B210 with preprocessed data (from MATLAB Communication Systems Toolbox). Similarly, in <ref type="bibr" target="#b39">[40]</ref>   <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b38">[39]</ref> and <ref type="bibr" target="#b40">[41]</ref> achieved between 96% and 99.9% accuracy for existing datasets (ACARS <ref type="bibr" target="#b41">[42]</ref>, ADS-B <ref type="bibr" target="#b42">[43]</ref>, FIT/CorteXlab <ref type="bibr" target="#b43">[44]</ref>).</p><p>We need to point out that none of methods discussed above are robust enough to work in adversarial settings. Thus if there is an adversarial transmitter then all the aforementioned methods will fail. However RFAL, due to its adversarial training will be able to identify the adversarial transmitter and eliminate it from consideration before classifying the "trusted transmitters", thus being more resilient and robust to such interference. Even if we just compare the "trusted transmitter" classification of RFAL with the methods discussed above, our method for "trusted transmitter classification" achieves the same accuracy (of 97%) using just the raw I/Q data as input, thereby paving the way for real-time deployment of "transmitter fingerprinting" systems.</p><p>Considering the state-of-art, and to the best of our knowledge, our work is the first to:</p><p>1) propose a GAN based model to detect rogue transmitters from authentic ones; 2) demonstrate a high accuracy (97%) to classify 8 USRP B210s using an RNN model considering the temporal property of RF data; 3) present a testbed evaluation for classifying transmitters from different manufacturers; 4) provide an end-to-end solution of RF transmitter classification without any preprocessing of raw data. The raw data can be captured through any SDR and is identified by the proposed models at once; 5) propose RNN based models which needed half the training time than CNN models for the same experimental training time. Our proposed RNN model entails to be faster than all state-of-the art CNN models for the same experimental environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J. Performance Comparison for Varying SNR</head><p>In this section, we present the results of RFAL "trusted transmitter classification" for varying SNR values. We compare the accuracy for the proposed NN models having 8 USRP B210s with <ref type="bibr" target="#b29">30</ref>   <ref type="table">IX</ref>. It is seen that we achieve better accuracy with all the models for higher SNR values, which is intuitive. It is to be noted that the proposed RNN (with GRU cell) model gives more than 92% accuracy at 0 dB SNR too, whereas CNN and DNN models fail to achieve that.</p><p>It must be pointed out that the proposed NN models can be a trained using raw signal data from any type of radio transmitter. We would also like to point out that though our data was collected in a lab setting, we had no control over the RF environment: there were other transmissions, uncontrolled movement of people, and multi-path effects due to the location and layout of the lab. Moreover, the power of the transmitters was low which compounded the problem further. Thus, though we mention that the data was collected in a lab environment, in reality it was an uncontrolled RF environment reflective of our surroundings. We can safely argue that the proposed methods will perform equally well in any real world deployment of large scale radio networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSIONS</head><p>In this paper, we address the problem of building a robust and resilient model for identifying similar RF transmitters in the presence of adversaries. We argue that non-adversarial machine learning techniques would not be effective in adversarial settings and that breakthroughs in generative adversarial nets (GANs) can be instrumental in building such systems for detection of rogue transmitters and subsequent accurate identification of known ones in such settings. We propose and implement RF Adversarial Learning (RFAL) framework which includes a discriminative model for identifying rogue transmitters trained with data generated from a generative model. RFAL also contains a "trusted transmitter" identification system that for categorizing the known transmitters once the adversarial transmitters have been identified and eliminated from consideration. We collected over-the-air raw I/Q data using USRP B210s and used that to train the GAN. The discriminator was able to detect rogue transmitters with an accuracy of ∼99.9%. As for the subsequent trusted transmitter classification, we first implemented a CNN (accuracy ∼89%) for exploiting the spatial correlation between the I/Q data. Then we designed and implemented a fully connected DNN and RNNs both of which obtained an accuracy of around 97% for trusted transmitter identification. We also show how the proposed NN models for "trusted transmitter classification" (especially CNN) worked when radios from different manufacturers were used. RFAL will be able to detect any active attack that involves a secondary device to pose as an authentic emitter, such as replay attacks, but it will not be able to detect passive attackers, such as traffic sniffers. Going forward we would like to use these methods for identification of actual infrastructure transmitters (for example FM, AM or GSM) in contested real world settings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. I/Q Imbalance for QPSK: (a) Before (b) After 45°Phase Imbalance</figDesc><graphic coords="3,60.32,403.59,112.50,70.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Proposed RFAL GAN architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. A Simplified View of GAN Implementation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. GAN Implementation for Rogue Transmitter Detection</figDesc><graphic coords="7,76.63,73.19,207.70,73.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. CNN Implementation for Transmitter Classification</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. DNN Implementation for Transmitter Classification</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig. 7. LSTM Cell Architecture Used in the RNN Model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. GRU Cell Architecture Used in the RNN Model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Signal Generation and Data Collection Setup</figDesc><graphic coords="9,315.15,189.80,243.19,60.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>2, • • • , T for timestamp t, and use it as an input to the NN. As mentioned before in our case (M = 1024). Thus we represent the I and Q values of each training sample at timestamp (t) as:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>, M is the sample size, I i and Q i are the sample values indexed with i. The sample mean is Ī = 1 M (M -1) i=0 I i and similarly for the Q values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>8 Fig. 12 .</head><label>812</label><figDesc>Fig. 12. Correlation Plot for Different Transmitters in the Collected Dataset</figDesc><graphic coords="10,311.98,611.97,123.38,92.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. ROC Curve and Confusion Matrix of Counterfeit Transmitter Detection from RFAL</figDesc><graphic coords="11,311.98,296.49,113.10,84.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Output from the Proposed Generator (Plot for 128 samples)</figDesc><graphic coords="12,90.97,189.14,82.26,82.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 16 .Fig. 17 .</head><label>1617</label><figDesc>Fig. 16. Accuracy Plot for Transmitter Classification using CNN</figDesc><graphic coords="12,426.18,222.70,128.52,96.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 18 .Fig. 19 .Fig. 20 .</head><label>181920</label><figDesc>Fig. 18. Feature Maps for the First Convolution Layer of the Proposed CNN Model</figDesc><graphic coords="13,305.92,313.87,128.52,96.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>21 and 22 respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 21 .Fig. 22 .</head><label>2122</label><figDesc>Fig. 21. Convergence of Transmitter Classification using LSTM Cells</figDesc><graphic coords="13,37.14,154.81,263.79,197.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 23 .</head><label>23</label><figDesc>Fig. 23. Convergence of Transmitter Classification using GRU Cells During the training phase, the hyper-parameters get adjusted depending on the categorical cross-entropy loss. Sometimes, with such adjustments, the model tends to over-fit the training</figDesc><graphic coords="13,164.91,616.80,128.53,96.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 24 .</head><label>24</label><figDesc>Fig. 24. Confusion Matrices for Transmitter Classification using GRU Cells</figDesc><graphic coords="14,42.91,61.05,128.52,96.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 25 .Fig. 26 .</head><label>2526</label><figDesc>Fig. 25. Training and Accuracy with Increasing numbers of Transmitters</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>. We use 2 LSTM layers with 1024 and 256 units sequentially. Next we add 2 fully connected</figDesc><table><row><cell>(x t ,h t-1 )</cell><cell cols="4">LSTM Cell</cell></row><row><cell cols="2">σ tanh i t</cell><cell>σ ĉ t</cell><cell>f t</cell><cell>ct-1 c t</cell><cell>σ o t h t tanh</cell></row><row><cell>tanh</cell><cell cols="4">tanh activation</cell></row><row><cell>σ</cell><cell cols="5">sigmoid activation</cell></row><row><cell></cell><cell cols="5">sum over all elements</cell></row><row><cell></cell><cell cols="5">Hadamard product</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE IV COMPARISON</head><label>IV</label><figDesc>OF CONFIGURATION SETTINGS FOR DIFFERENT MODELS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE V TIME</head><label>V</label><figDesc>COMPLEXITIES FOR TRAINING OF THE VARIOUS IMPLEMENTATIONSfeatures of the τ th layer. In the proposed CNN model, we have 3 convolutional layers, and 4 fully connected layers and hence we add in additional time complexity for training the three convolutional layers.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>, Sankhe et al. presented a CNN classifier with 16 X310 radios with 99.5% accuracy, but that method used demodulated symbols rather than raw signal data. Youssef et al. presented a multi-stage training model to achieve 100%</figDesc><table><row><cell>Approach</cell><cell>#Trans</cell><cell>SNR (dB)</cell><cell>Acc (%)</cell><cell>Inputs</cell></row><row><cell>Genetic Algorithm [23]</cell><cell>5</cell><cell>25</cell><cell>85-98</cell><cell>Transients</cell></row><row><cell>Multifractal</cell><cell></cell><cell>Not</cell><cell></cell><cell></cell></row><row><cell>Segmentation [24]</cell><cell>8</cell><cell>mentioned</cell><cell>92.5</cell><cell>Transients</cell></row><row><cell>Orthogonal Component</cell><cell></cell><cell></cell><cell></cell><cell>Spurious</cell></row><row><cell>Reconstruction (OCR) [26]</cell><cell>3</cell><cell>20</cell><cell>62 -71</cell><cell>Modulation</cell></row><row><cell>k-NN [25]</cell><cell>8</cell><cell>30</cell><cell>97</cell><cell>Transients</cell></row><row><cell>RNN [31]</cell><cell>-</cell><cell>20</cell><cell>90</cell><cell>Synthetic Dataset [32]</cell></row><row><cell>RFAL (Ours)</cell><cell>8</cell><cell>30</cell><cell>97.04</cell><cell>Raw Signal</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>TABLE VII COMPARISON</head><label>VII</label><figDesc>OF THE RFAL IMPLEMENTATION WITH THE TRADITIONAL ONES accuracy to classify 12 USRP N210s. Multi-stage training is a complex procedure and needs a easily parallelizable training environment, whereas CNN and DNN use a firstorder update rule (stochastic gradient) and are comparatively simple procedures. For the sake of generality, we compare their proposed DNN method (which has the best accuracy compared to other implemented ML methods) in Table VIII. The CNN models presented in</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>dB SNR, with 3 other datasets collected at 10 dB, and 30 dB SNRs having the same number of transmitters (8 B210s) as shown in Table</figDesc><table><row><cell>Approach</cell><cell>#Trans</cell><cell>SNR (dB)</cell><cell cols="2">Acc (%)</cell><cell>Input</cell></row><row><cell>CNN [35]</cell><cell>7</cell><cell>30</cell><cell>91.38</cell><cell cols="2">Preprocessed data</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>from MATLAB</cell></row><row><cell>CNN [36]</cell><cell>5</cell><cell>50</cell><cell>98</cell><cell cols="2">Preprocessed data</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>from MATLAB</cell></row><row><cell>CNN [37]</cell><cell>-</cell><cell>-</cell><cell>99.67</cell><cell cols="2">ACARS data [42]</cell></row><row><cell>DNN [38]</cell><cell>12</cell><cell></cell><cell>84.4</cell><cell></cell><cell>Raw signal</cell></row><row><cell>Inception</cell><cell>-</cell><cell>-</cell><cell cols="2">98.1 &amp; 96.3</cell><cell>ACARS [42] &amp;</cell></row><row><cell>ResNet [39]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ADS-B [43]</cell></row><row><cell>CNN [40]</cell><cell>16</cell><cell>30</cell><cell>99.5</cell><cell cols="2">Demodulated symbols</cell></row><row><cell>CNN [41]</cell><cell>21</cell><cell>-</cell><cell>99.99</cell><cell cols="2">FIT/CorteXlab [44]</cell></row><row><cell>RNN (Ours)</cell><cell>8</cell><cell>30</cell><cell>97.04</cell><cell></cell><cell>Raw signal</cell></row><row><cell></cell><cell></cell><cell cols="2">TABLE VIII</cell><cell></cell></row><row><cell cols="6">COMPARISON OF THE RFAL IMPLEMENTATION WITH STATE-OF-THE-ART</cell></row><row><cell></cell><cell>SNR(dB)</cell><cell></cell><cell cols="2">Accuracy (%)</cell></row><row><cell></cell><cell></cell><cell>CNN</cell><cell>DNN</cell><cell cols="2">RNN (GRU)</cell></row><row><cell></cell><cell>0</cell><cell>51.53</cell><cell>85.12</cell><cell>92.3</cell></row><row><cell></cell><cell>10</cell><cell>78.64</cell><cell>92.24</cell><cell cols="2">95.64</cell></row><row><cell></cell><cell>20</cell><cell>81.3</cell><cell>94.60</cell><cell cols="2">97.02</cell></row><row><cell></cell><cell>30</cell><cell>81.59</cell><cell>94.60</cell><cell cols="2">97.06</cell></row><row><cell></cell><cell></cell><cell cols="2">TABLE IX</cell><cell></cell></row><row><cell cols="6">ACCURACIES FOR DIFFERENT NEURAL NETWORK MODELS WITH</cell></row><row><cell></cell><cell></cell><cell cols="2">VARYING SNRS</cell><cell></cell></row><row><cell>0 dB,</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>This work was partly supported by the Air Force Research Laboratory. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the United States Air Force.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Debashri Roy received her M.S. degree in Computer Science at University of Central Florida, where she is currently a PhD Candidate. Her research interests are radio frequency machine learning Systems (RFMLs), generative adversarial nets, real-time video transmission, vehicular networks, heterogeneous networks, modeling and simulation, dynamic spectrum access. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weber</surname></persName>
		</author>
		<title level="m">Internet of Things</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Advanced Methods for I/Q Imbalance Compensation in Communication Receivers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Valkama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Renfors</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koivunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2335" to="2344" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Why does deep and cheap learning work so well?</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tegmark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rolnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Physics</title>
		<imprint>
			<biblScope unit="volume">168</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1223" to="1247" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">USRP B210</title>
		<ptr target="https://www.ettus.com/product/details/UB210-KIT" />
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Ettus Research</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">USRP B210</title>
		<author>
			<persName><surname>Nooelec</surname></persName>
		</author>
		<ptr target="http://www.nooelec.com/store/sdr/sdr-receivers/nesdr-mini-rtl2832-r820t.html" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">ADALM-PLUTO Overview</title>
		<author>
			<persName><forename type="first">A</forename><surname>Devices</surname></persName>
		</author>
		<ptr target="https://wiki.analog.com/university/tools/pluto" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Clustering-based method for detecting and evaluating I/Q impairments in radio-frequency digital transmitters</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D L</forename><surname>Angrisani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vadursi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Instrumentation and Measurement</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2139" to="2146" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Impacts of I/Q Imbalance on QPSK-OFDM-QAM Detection</title>
		<author>
			<persName><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Consumer Electronics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="984" to="989" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Joint Calibration of Transmitter and Receiver Impairments in Direct-Conversion Radio Architecture</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sheen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="832" to="841" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Correction of I and Q Errors in a Coherent Processor</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Churchill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Ogar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Aerospace and Electronic Systems</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="131" to="137" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Block-Wise Estimation of and Compensation for I/Q Imbalance in Direct-Conversion Transmitters</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Bassam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boumaiza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Ghannouchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4970" to="4973" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On the Estimation and Compensation of IQ Impairments in Direct Conversion Transmitters</title>
		<author>
			<persName><forename type="first">S</forename><surname>Burglechner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hueber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Springer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Wireless Technology</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="69" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Blind Moment Estimation Techniques for I/Q Imbalance Compensation in Quadrature Receivers</title>
		<author>
			<persName><forename type="first">L</forename><surname>Anttila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valkama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Renfors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 17th International Symposium on Personal, Indoor and Mobile Radio Communications</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Compensation of IQ imbalance in OFDM systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tubbax</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Communications</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="3403" to="3407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generative Adversarial Nets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Machine Learning (Information Science and Statistics</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Convolutional Radio Modulation Recognition Networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>O'shea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Corgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Clancy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Engineering Applications of Neural Networks</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unsupervised Representation Learning of Structured Radio Communication Signals</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>O'shea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Corgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Clancy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First International Workshop on Sensing, Processing and Learning for Intelligent Machines</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Long Short-term Memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">17351780</biblScope>
			<date type="published" when="1997-11">November 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">¸</forename><surname>Gülc ¸ehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1412.3555</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository (CoRR)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A radio transmitter fingerprinting system ODO-1</title>
		<author>
			<persName><forename type="first">J</forename><surname>Toonstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kinsner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Canadian Conference on Electrical and Computer Engineering</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="60" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multifractal Modelling of Radio Transmitter Transients for Classification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kinsner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE WESCANEX</title>
		<imprint>
			<biblScope unit="page" from="306" to="312" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Radio Transmitter Fingerprinting: A Steady State Frequency Domain Approach</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">O</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Scanlon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Mullany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Buddhikot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Nolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Rondeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Vehicular Technology Conference</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Individual Radio Transmitter Identification based on Spurious Modulation Characteristics of Signal Envelop</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE MILCOM</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Radar Transmitter Classification using a Non-stationary Signal Classifier</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Du Plessis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Olivier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Wavelet Analysis and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="482" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A PHY-layer Authentication Approach for Transmitter Identification in Cognitive Radio Networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Communications and Mobile Computing</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="154" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Structured Sparsity Preserving Projections for Radio Transmitter Recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Mobile IT Convergence</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="68" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An Introduction to Deep Learning for the Physical Layer</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Shea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoydis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cognitive Communications and Networking</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="563" to="575" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep Learning Models for Wireless Signal Classification With Distributed Low-Cost Spectrum Sensors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rajendran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cognitive Communications and Networking</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="433" to="445" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">RFML 2016</title>
		<ptr target="https://github.com/radioML/dataset" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Over-the-Air Deep Learning Based Radio Signal Classification</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>O'shea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Clancy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="168" to="179" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Physical Layer Communications System Design Over-the-Air Using Adversarial Networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>O'shea</surname></persName>
		</author>
		<idno>abs/1803.03145</idno>
	</analytic>
	<monogr>
		<title level="m">Computing Research Repository (CoRR)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep learning for rf device fingerprinting in cognitive communication networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Merchant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Revay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stantchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nousain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="160" to="167" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep Learning Convolutional Neural Networks for Radio Identification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Riyaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sankhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chowdhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="146" to="152" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Big Data Processing Architecture for Radio Signals Empowered by Deep Learning: Concept, Experiment, Applications and Challenges</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">922</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Machine Learning Approach to RF Transmitter Identification</title>
		<author>
			<persName><forename type="first">K</forename><surname>Youssef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bouchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Haigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Silovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thapa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Valk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Radio Frequency Identification</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="197" to="205" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep learning for large-scale real-world ACARS and ADS-B radio signal classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<idno>abs/1904.09425</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository (CoRR)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">ORACLE: Optimized Radio clAssification through Convolutional neuraL nEtworks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sankhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Belgiovine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riyaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chowdhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Communications (INFOCOM)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="370" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Transmitter Classification With Supervised Deep Learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Morin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoydis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Gorce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vial</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.07923</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository (CoRR)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">air/ground character-oriented protocol, specification</title>
		<idno>ARINC618-5</idno>
		<imprint>
			<date type="published" when="2000-08">August 2000</date>
			<publisher>Aeronautical Radio, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Automatic Dependent Surveillance-Broadcast (ADS-B)</title>
		<ptr target="https://www.faa.gov/nextgen/programs/adsb/" />
		<imprint>
			<date type="published" when="2018-08">August 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">CorteXlab: An open FPGA-based facility for testing SDR cognitive radio networks in a reproducible environment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Massouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Guillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Villemaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Risset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gorce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Communications Workshops (INFOCOM WK-SHPS)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="103" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Radio Frequency Fingerprinting based on the Constellation Errors</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Asia-Pacific Conference on Communications</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="900" to="905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">RSSI-Based Supervised Learning for Uncooperative Direction-Finding</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mukherjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECML-PKDD</title>
		<meeting>ECML-PKDD</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">10 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Wireless Device Authentication through Transmitter Imperfections Measurement and Classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pospil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marsalek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pomenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Personal, Indoor and Mobile Radio Communications</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="497" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Performance Enhancement of I/Q Imbalance based Wireless Device Authentication through Collaboration of Multiple Receivers</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Behnad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Communications</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="939" to="944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Denton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1486" to="1494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<idno>abs/1703.10593</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository (CoRR)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">BEGAN:Boundary Equilibrium Generative Adversarial Networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schumm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<idno>abs/1703.10717</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository (CoRR)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno>abs/1412.6980</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository (CoRR)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Keras: The Python Deep Learning library</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Rectified Linear Units Improve Restricted Boltzmann Machines</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on International Conference on Machine Learning</title>
		<meeting>International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Convolutional Neural Networks at Constrained Time Cost</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015-06">June 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Gate-variants of Gated Recurrent Unit (GRU) neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Salemt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE 60th International Midwest Symposium on Circuits and Systems (MWSCAS)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1597" to="1600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">GNU Radio</title>
		<author>
			<persName><surname>Gnuradio</surname></persName>
		</author>
		<ptr target="https://www.gnuradio.org" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Pavel</forename><surname>Sorejs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">"</forename><surname>Spektrum</surname></persName>
		</author>
		<ptr target="https://github.com/pavels/spektrum" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRRComputing Research Repository (CoRR)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Theano: A python framework for fast computation of mathematical expressions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository (CoRR)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">On the Computational Efficiency of Training Neural Networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Livni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="855" to="863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Radio Machine Learning Dataset Generation with GNU Radio</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Shea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the GNU Radio Conference</title>
		<meeting>the GNU Radio Conference</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
