<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pairwise Preference Regression for Cold-start Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Seung-Taek</forename><surname>Park</surname></persName>
							<email>park.seungtaek@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Samsung Advanced Institute of Technology Mt</orgName>
								<address>
									<addrLine>14-1, Nongseo-dong, Giheung-gu Yongin-si</addrLine>
									<postCode>446-712</postCode>
									<settlement>Gyunggi</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Chu</surname></persName>
							<email>chuwei@yahoo-inc.com</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Yahoo! Labs</orgName>
								<orgName type="department" key="dep2">Great America Parkway</orgName>
								<address>
									<postCode>4401, 95054</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pairwise Preference Regression for Cold-start Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BF3757A9274204B21231D9EAA5834A29</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>General</term>
					<term>H.3.3 [Information Search and Retrieval]: Information filtering</term>
					<term>H.3.5 [Online Information Services]: Web-based services Algorithms, Experimentation, Measurement, Performance Recommender System, cold-start problems, user and item features, ranking, normalized Discounted Cumulative Gain</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recommender systems are widely used in online e-commerce applications to improve user engagement and then to increase revenue. A key challenge for recommender systems is providing high quality recommendation to users in "coldstart" situations. We consider three types of cold-start problems: 1) recommendation on existing items for new users; 2) recommendation on new items for existing users; 3) recommendation on new items for new users. We propose predictive feature-based regression models that leverage all available information of users and items, such as user demographic information and item content features, to tackle cold-start problems. The resulting algorithms scale efficiently as a linear function of the number of observations. We verify the usefulness of our approach in three cold-start settings on the MovieLens and EachMovie datasets, by comparing with five alternatives including random, most popular, segmented most popular, and two variations of Vibes affinity algorithm widely used at Yahoo! for recommendation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Recommender systems automate the familiar social process of friends endorsing products to others in their community. Widely deployed on the web, such systems help users explore their interests in many domains, including movies, music, books, and electronics. Recommender systems are widely applied from independent, community-driven web sites to large e-commerce powerhouses like Amazon.com. Recommender systems can improve users' experience by personalizing what they see, often leading to greater engagement and loyalty. Merchants, in turn, receive more explicit preference information that paints a clearer picture of their customers. Two different approaches are widely adopted to design recommender systems: content-based filtering and collaborative filtering.</p><p>Content-based filtering generates a profile for a user based on the content descriptions of the items previously rated by the user. The major benefit of this approach is that it can recommend users new items, which have not been rated by any users. However, content-based filtering cannot provide recommendations to new users who have no historical ratings. To provide new user recommendation, content-based filtering often asks new users to answer a questionnaire that explicitly states their preferences to generate initial profiles of new users. As a user consumes more items, her profile is updated and content features of the items that she consumed will receive more weights. One drawback of content-based filtering is that the recommended items are similar to the items previously consumed by the user. For example, if a user has watched only romance movies, then content-based filtering would recommend only romance movies. It often causes low satisfaction of recommendations due to lack of diversity for new or casual users who may reveal only small fraction of their interests. Another limitation of contentbased filtering is that its performance highly depends on the quality of feature generation and selection.</p><p>On the other hand, collaborative filtering typically associates a user with a group of like-minded users, and then recommends items enjoyed by others in the group. Collaborative filtering has a few merits over content-based filtering. First, collaborative filtering does not require any feature generation and selection method and it can be applied to any domains if user ratings (either explicit or implicit) are available. In other words, collaborative filtering is content-independent. Second, collaborative filtering can provide "serendipitous finding", whereas content-based filtering cannot. For example, even though a user has watched only romance movies, a comedy movie would be recommended to the user if most other romance movie fans also love it. Collaborative filtering captures this kind of hidden connections between items by analyzing user consumption history (or user ratings on items) over the population. Note that content-based filtering uses a profile of individual user but does not exploit profiles of other users.</p><p>Even though collaborative filtering often performs better than content-based filtering when lots of user ratings are available, it suffers from the cold-start problems where no historical ratings on items or users are available. A key challenge in recommender systems including content-based and collaborative filtering is how to provide recommendations at early stage when available data is extremely sparse. The problem is of course more severe when the system newly launches and most users and items are new. However, the problem never goes away completely, since new users and items are constantly coming in any healthy recommender system. We consider three types of cold-start setting in this paper: 1) recommending existing items for new users, 2) recommending new items for existing users, and 3) recommending new items for new users.</p><p>We realize that there are additional information on users and items often available in real-world recommender systems. We can request users' preference information by encouraging them to fill in questionnaires or simply collect user-declared demographic information (i.e. age and gender) at registration. We can also utilize item information by accessing the inventory of most on-line enterpriser. These legally accessible information is valuable for both recommending new items and serving new users. To attack the cold-start problem, we propose new hybrid approaches which exploit not only user ratings but also user and item features. We construct tensor profiles for user/item pairs from their individual features. Within the tensor regression framework, we optimize the regression coefficients by minimizing pairwise preference loss. The resulting algorithm scales efficiently as a linear function of the number of observed ratings. We evaluate our approach with two standard movie data sets: MovieLens and EachMovie. We cannot use the Netflix data since it does not provide any user information. Note that one of our goals is providing reasonable recommendation to even new users with no historical ratings but only a few demographic information.</p><p>We split user ratings into four partitions. We randomly select half of users as new users and the rest as existing users. Similarly, we randomly split items as new and existing items. Figure <ref type="figure">1</ref> illustrates data partition. Then we use partition I for training and partition II, III, and IV for test. We summarize available techniques for each partition in the following:</p><p>• Partition I (recommendation on existing items for existing users): This is the standard case for most existing collaborative filtering techniques, such as useruser, item based collaborative filtering, singular value decomposition (SVD), etc.;</p><p>• Partition II (recommendation on existing items for new users): For new users without historical ratings, "most popular" strategy that recommends the highly-rated items to new users serves as a strong baseline; recommend new items to existing users based on the users' historical ratings and features of items;</p><p>• Partition VI (recommendation on new items for new users): This is a hard case, where "random" strategy is the basic means of collecting ratings.</p><p>We evaluate performance of recommender systems based on the correctness of ranking rather than prediction accuracy, the normalized Discounted Cumulative Gain (</p><p>), widely used in information retrieval (IR), as performance metric. We compare against five recommendation approaches including Random, Most Popular (MP), Segmented Most Popular (SMP), and two variations of Vibes Affinity algorithm (Affinity) <ref type="bibr" target="#b21">[21]</ref> widely used at Yahoo!.</p><p>The paper is organized as follows: We describe our algorithm in Section 2; We review related work in Section 3; We report experimental results with comparison against five existing competitive approaches in Section 4; We conclude in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">METHODOLOGY</head><p>In this section, we propose a regression approach based on profiles (TR) for cold-start recommendation. In many real recommender systems, users sometimes declare their demographical information, such as age, gender, residence, and etc., whereas the recommender systems also maintain information of items when items are either created or acquired, which may include product name, manufacturer, genre, production year, etc. Our key idea is to build a predictive model for user/item pairs by leveraging all available information of users and items, which is particularly useful for cold-start recommendation including new user and new item recommendation. In the following, we describe our approach in three subsections. The first subsection presents profile construction, and the last two subsections cover algorithm design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Profile Construction</head><p>It is crucial to generate and maintain profiles of items of interest for effective cold-start strategies. For example, we collect item contents (i.e. genre, cast, manufacturer, production year etc.) as the initial part of the profile for movie recommendation. In addition to these static attributes, we also estimate items' popularity/quality from available historical ratings in training data, e.g. indexed by averaged scores in different user segments, where user segments could be simply defined by demographical descriptors or advanced conjoint analysis.</p><p>Generally we can construct user profiles as well by collecting legally usable user-specific features that effectively represent a user's preferences and recent interests. The user features usually consist of demographical information and historical behavior aggregated to some extent.</p><p>In this way, each item is represented by a set of features, denoted as a vector z, where z ∈ ℝ and is the number of item features. Similarly, each user is represented by a set of user features, denoted as x, where x ∈ ℝ and is the number of user features. Note that we append a constant feature to the user feature set for all users. A new user with no information is represented as [0, . . . , 0, 1] instead of a vector of zero entries.</p><p>In traditional collaborative filtering (CF), the ratings given by users on items of interest are used as user profiles to evaluate commonalities between users. In our regression approach, we separate these feedbacks from user profiles. The ratings are utilized as targets that reveal affinities between user features to item features.</p><p>We have collected three sets of data, including item features, user profiles and the ratings on items given by users. Let index the -th user as x and the -th content item as z , and denote by the interaction between the user x and the item z . We only observe interactions on a small subset of all possible user/item pairs, and denote by the index set of observations { }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Regression on Pairwise Preference</head><p>A predictive model relates a pair of vectors, x and z , to the rating on the item z given by the user x . There are various ways to construct joint feature space for user/item pairs. We focus on the representation via outer products, i.e., each pair is represented as x ⊗ z , a vector of entries { , , } where , denotes the -th feature of z and , denotes the -th feature of x .</p><p>We define a parametric indicator as a bilinear function of x and z in the following:</p><formula xml:id="formula_0">= ∑ =1 ∑ =1 , , ,<label>(1)</label></formula><p>where and are the dimensionality of user and content features respectively, , are feature indices. The weight variable is independent of user and content features and characterizes the affinity of these two factors , and , in interaction. The indicator can be equivalently rewritten as</p><formula xml:id="formula_1">= x Wz ⊤ = w ⊤ (z ⊗ x ), (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where W is a matrix containing entries { }, w denotes a column vector stacked from W, and z ⊗x denotes the outer product of x and z , a column vector of entries { , , }.</p><p>The regression coefficients can be optimized in regularization framework, i.e. arg min</p><formula xml:id="formula_3">w ∑ ∈ ( - ) 2 + ∥w∥ 2 2 (3)</formula><p>where is a tradeoff between empirical error and model complexity. Least squares loss coupled with 2-norm of w, is widely applied in practice due to computational advantages. <ref type="foot" target="#foot_0">1</ref> The optimal solution of w is unique and has a closed form of matrix manipulation, i.e.</p><formula xml:id="formula_4">w * = ( ∑ ∈ z z ⊤ ⊗ x x ⊤ + I ) -1 ( ∑ ∈ z ⊗ x ) (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>where I is an by identity matrix. By exploiting the tensor structure, the matrix preparation costs ( 2 + 2 2 ) where and are the number of items and users respectively. The matrix inverse costs ( 3 3 ), which becomes the most expensive part if &lt; and &lt; 2 . The tensor idea can be traced back to the Tucker family <ref type="bibr" target="#b33">[33]</ref> and the PARAFAC family <ref type="bibr" target="#b16">[16]</ref>. Recently exploratory data analysis with tensor product has been applied to image ensembles <ref type="bibr" target="#b34">[34]</ref>, DNA microarray data intergration <ref type="bibr" target="#b22">[22]</ref> and semi-infinite stream analysis <ref type="bibr" target="#b32">[32]</ref> etc. To our best knowledge, tensor regression hasn't been applied to cold-start recommendation yet.</p><p>In recommender systems, users may enjoy different rating criteria. Thus the ratings given by different users are not comparable due to user-specific bias. We can lessen the effect by introducing a bias term for each user in the above regression formulation, however it not only enlarges the problem size dramatically from to + where denotes the number of users and usually ≫ , but also increases uncertainty in the modelling. Another concern is that the least squares loss is favorable for RMSE metric but may result in inferior ranking performance. Pairwise loss is widely used for preference learning and ranking, e.g. RankRLS <ref type="bibr" target="#b23">[23]</ref> and RankSVM <ref type="bibr" target="#b17">[17]</ref>, for superior performance.</p><p>In this paper, we introduce a personalized pairwise loss in the regression framework. For each user x , the loss function is generalized as</p><formula xml:id="formula_6">1 ∑ ∈ ∑ ∈ (( - ) -( - )) 2<label>(5)</label></formula><p>where denotes the index set of all items the user x have rated, = | | the number of ratings given by the user x , and is defined as in eq <ref type="bibr" target="#b1">(1)</ref>. Replacing the squares loss by the personalized pairwise loss in the regularization framework, we have the following optimization problem:</p><formula xml:id="formula_7">min w ∑ ⎛ ⎝ 1 ∑ ∈ ∑ ∈ (( - ) -( - )) 2 ⎞ ⎠ + ∥w∥ 2 2 (6)</formula><p>where runs over all users. The optimal solution can be computed in a closed form as well, i.e.</p><formula xml:id="formula_8">w * = ( A + 2 I ) -1 B (7) A = ∑ ∑ ∈ z (z -z ) ⊤ ⊗ x x ⊤ (8) B = ∑ ∑ ∈ (z -z ) ⊗ x (9) z = 1 ∑ ∈ z<label>(10)</label></formula><p>The size in matrix inverse is still and the matrix preparation costs ( 2 + 2 2 ) same as that of the least squares loss.</p><p>When matrix inversion with very large becomes computationally prohibitive, we can instead apply gradient-descent techniques for a solution. The gradient can be evaluated by Aw -B. There is no matrix inversion involved in each evaluation, and the most expensive step inside is to construct the matrix A once only. Usually it would take hundreds of iterations for a gradient-descent package to get close to the minimum. Note that this is a convex optimization problem with a unique solution at the minimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RELATED WORK</head><p>Two different approaches have been widely used to build recommender systems: content-based filtering and collaborative filtering. Content-based filtering uses behavioral data about a user to recommend items similar to those consumed by the user in the past while collaborative filtering compares one user's behavior against a database of other users' behaviors in order to identify items that like-minded users are interested in. The major difference between two approaches is that content-based filtering uses a single user information while collaborative filtering uses community information.</p><p>Even though content-based filtering is efficient in filtering out unwanted information and generating recommendations for a user from massive information, it often suffers from lack of diversity on the recommendation. Contentbased filtering requires a good feature generation and selection method while collaborative filtering only requires user ratings. Content-based filtering finds few if any coincidental discoveries while collaborative filtering systems enables serendipitous discoveries by using historical user data. Hundreds of collaborative filtering algorithms have been proposed and studied, including K nearest neighbors <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b28">28]</ref>, Bayesian network methods <ref type="bibr" target="#b10">[10]</ref>, classifier methods <ref type="bibr" target="#b9">[9]</ref>, clustering methods <ref type="bibr" target="#b35">[35]</ref>, graph-based methods <ref type="bibr" target="#b4">[4]</ref>, probabilistic methods <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b26">26]</ref>, ensemble methods <ref type="bibr" target="#b13">[13]</ref>, taxonomydriven <ref type="bibr" target="#b36">[36]</ref>, and combination of KNN and SVD <ref type="bibr" target="#b8">[8]</ref>.</p><p>Although collaborative filtering provides recommendations effectively where massive user ratings are available such as in the Netflix data set, it does not perform well where user rating data is extremely sparse. Several linear factor models have been proposed to attack the data sparsity. Singular Value Decomposition (SVD), Principal Component Analysis (PCA), or Maximum Margin Matrix Factoriation (MMMF) has been used to reduce the dimensions of the user-item matrix and smoothing out noise <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b14">14]</ref>. However, those linear factor models do not solve the cold-start problems for new users or new items. Several hybrid methods, which often combine information filtering and collaborative filtering techniques, have been proposed. Fab <ref type="bibr" target="#b5">[5]</ref> is the first hybrid recommender system, which builds user profiles based on content analysis and calulates user similarities based on user profiles. Basu et al. <ref type="bibr">[7]</ref> generated three different features: collaborative features (i.e. users who like the movie X), content features, and hybrid features (i.e. users who like comedy movies). Then, an inductive learning system, Ripper, is used to learn rules and rule-based prediction was generated for the recommendation. Claypool et al. <ref type="bibr" target="#b12">[12]</ref> built an online newspaper recommender system, called Tango, that scored items based on collaborative filtering and content-based filtering separately. Then two scores are linearly combined: As users provide ratings, absolute errors of two scores are measured and weights of two algorithms are adjusted to minimize error. Good et al. <ref type="bibr" target="#b15">[15]</ref> experimented with a number of types of filterbots, including including Ripper-Bots, DGBots, Genre-Bots and MegaGenreBot. A filterbot is an automated agent that rates all or most items algorithmically. The filterbots are then treated as additional users in a collaborative filtering system. Park et al. <ref type="bibr" target="#b24">[24]</ref> improved the scalability and performance of filterbots in cold-start situations by adding a few global bots instead of numerous personal bots and applying item-based instead of user-user collaborative filtering. Melville et al. <ref type="bibr" target="#b20">[20]</ref> used content-based filtering to generate default ratings for unrated items to make a useritem matrix denser. Then traditional user-user collaborative filtering is performed using this denser matrix. Schein et al. <ref type="bibr" target="#b29">[29]</ref> extended Hofmann's aspect model to combine item contents and user ratings under a single probabilistic framework. Even though hybrid approaches potentially improve the quality of the cold-start recommendation, the main focus of many hybrid methods is improving prediction accuracy over all users by using multiple data rather than directly attacking the cold-start problem for new users and items. Note that all above approaches only lessen the cold-start problem where a target user has rated at least few ratings but do not work for new user or new item recommendation.</p><p>There are a few existing hybrid approaches which are able to make new user and new item recommendation. Pazzani <ref type="bibr" target="#b25">[25]</ref> proposed a hybrid method that recommends items based on vote of four different algorithms: user-user collaborative filtering, content-based, demographic-based, and collaboration via content. This approach can provide new user recommendation by assembling several independent models. Our approach provides a unified framework of learning user-item affinity from all heterogeneous data simultaneously. Basilico and Hofmann <ref type="bibr" target="#b6">[6]</ref> proposed an online perceptron algorithm coupled with combinations of multiple kernel functions that unify collaborative and content-based filtering. The resulting algorithm is capable of providing recommendations for new users and new items, but the performance has not been studied yet. The computational complexity in the proposed kernel machine scales as a quadratic function of the number of observations, which limits its applications to largescale data sets. Agarwal and Merugu <ref type="bibr" target="#b3">[3]</ref> proposed a statistical method to model dyadic response as a function of available predictor information and unmeasured latent factors through a predictive discrete latent factor model. Even though the proposed approach can potentially solve the coldstart problems, its main focus is improving quality of recommendation in general cases and its performance in cold-start settings is not fully studied yet. Chu and Park <ref type="bibr" target="#b11">[11]</ref> proposed a predictive bilinear regression model in "dynamic content environment", where the popularity of items changes temporally, lifetime of items is very short (i.e. few hours), and recommender systems are forced to recommend only new items. This work suggests to maintain profiles for both contents and users, where temporal characteristics of contents, e.g. popularity and freshness, are updated in real-time. In their setting, only tens of items are available at each moment and the goal is recommending the best among these active items to users. In our setting, item space is rather static but the number of items available at any moment is much larger (i.e. few thousands), and the user attributes are limited to demographic information only. Recently, Stern et al. <ref type="bibr" target="#b31">[31]</ref> proposed a probabilistic model that combines user and item meta data with users' historical ratings to predict the users' interaction on items. Agarwal and Chen <ref type="bibr" target="#b2">[2]</ref> also independently proposed a regression-based latent factor model for cold-start recommendation with the same spirit. In these models, dyadic response matrix Y is estimated by a latent factor model such as Y ≈ U V, where latent factor matrices, U and V, are estimated by regression such as U ≈ FX and V ≈ MZ. X and Z denote user attribute and item feature matrices, and F and M are weight matrices learnt by regression. These approaches have similar spirit to our model, while the key difference lies on methodology to estimate the weights. In our approach, we estimate the weight matrix W as in eq(2) by solving a convex optimization, whereas in the above works the weight matrix is approximated by a low-rank matrix decomposition, such as W ≈ F M, and latent components are then estimated by either approximate Bayesian inference or expectationmaximization techniques. We note the latent components are rotation-invariant in their own space, that means there are numerous local minima in the solution space which may make the estimation complicated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS</head><p>In this section we report experimental results on two movie recommendation data sets, MovieLens and EachMovie. We first describe existing competitive algorithms we implemented for comparison purpose. Then we describe our testing procedure and report empirical results with the MoiveLens and EachMovie data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Competitive approaches</head><p>We implemented three alternative recommendation approaches for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Most popular</head><p>Most Popular (MP) provides the same recommendation to all users based on global popularity of items. The global popularity of an item is measured as following:</p><formula xml:id="formula_9">= * + * + (<label>11</label></formula><formula xml:id="formula_10">)</formula><p>where the average rating is defined as 1 ∑ ∈ , the support = | | is the number of users who have rated the -th item, denotes the average of all ratings and denotes a shrinkage parameter which is inspired by <ref type="bibr" target="#b8">[8]</ref>. Here = 3.6 for the MovieLens data and = 4.32 for the EachMovie data, which were measured in the partition I, shown in the figure <ref type="figure">1</ref>. When = 0, is purely based on its average rating . When &gt; 0, will be close to the overall average if only few users have rated the item . We set = 2</p><p>both on MovieLens and EachMovie, which yields the best performance in validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Segmented most popular</head><p>Segmented Most Popular (SMP) divides users into several user segments based on user features (i.e. age or gender) and computes predictions of items based on their local popularity within the user segment which a target user belongs to:</p><formula xml:id="formula_11">= * + * + (<label>12</label></formula><formula xml:id="formula_12">)</formula><p>where and denote the average rating of an item within a user segment and the number of users who have rated the item within the user segment . We have tested three different segmentation methods based on gender only, age only, and the combination of age and gender (age*gender). There are two gender groups, male and female (one additional age group "unknown" for EachMovie due to missing entries), and seven age groups, i.e. under 18, 18-24, 25-34, 35-44, 45-49, 50-55, and above 56 (one additional "unknown" age group for EachMovie). The parameter was determined by validation. We found the best SMP model is with = 9 on MovieLens and = 5 for EachMovie.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Vibes Affinity</head><p>The Vibes Affinity algorithm <ref type="bibr" target="#b21">[21]</ref> is used at several Yahoo properties including Yahoo! Shopping, Yahoo! Auto and Yahoo! Real Estate. The algorithm computes item-item affinity based on conditional probability such as</p><formula xml:id="formula_13">( → ) = ( | ) =<label>(13)</label></formula><p>where and denote the number of users who consumed (e.g. clicked) an item and the number of users who consumed the item and . Then preference score of each item for a user is computed as following:</p><formula xml:id="formula_14">= ∑ ∈ ( → )<label>(14)</label></formula><p>where denotes a set of items the user has consumed. To provide cold start recommendation we slightly modified the algorithm. For the partition II (existing item recommendation for new users), we modified the equation ( <ref type="formula" target="#formula_13">13</ref>) and ( <ref type="formula" target="#formula_14">14</ref>) to measure user attribute-item affinity such as</p><formula xml:id="formula_15">( → ) = ; (15) = ∑ ∈ ( → )<label>(16)</label></formula><p>where denotes the number of users who have an attribute and have consumed an item . is a set of attributes the user has.</p><p>; denotes the number of users who like among the users who have an attribute and have consumed an item . We consider that a user like an item if she rated it higher than the average rating, shown in the Table <ref type="table" target="#tab_1">1</ref>. We call this variation of the affinity model as Affinity1 hereafter. For the partition III and IV, we measure user attribute-item feature affinity such as where denotes a set of features the item has. is a number of user-item pairs in the training data, which contain both a user attribute and an item feature .</p><formula xml:id="formula_16">( → ) = ; (17) = ∑ ∈ ∑ ∈ ( → )<label>(18)</label></formula><p>;</p><p>denotes the number of positive preference pairs (e.g. rating higher than the average rating) in . We call this variant affinity model as Affinity2 hereafter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Testing Procedure &amp; Metric</head><p>We used two movie rating data sets: MovieLens and Each-Movie. In the EachMovie data, we first removed all "sounds awful" ratings since those ratings (which have a weight less than one) were not real ratings but represented users' impressions on items. In addition to rating data, both data sets also contain some user attributes and movie information. As described in Section 2.1, we collected user and movie features for the MovieLens and EachMovie datasets respectively. The features we collected are summarized in Table <ref type="table" target="#tab_2">2</ref>. The age/gender categories are same as those defined in Segmented Most Popular, see Subsection 4.1.2. In MovieLens, there are 21 occupation categories for users and 18 genre categories for movies. The movie-released year was categorized into 13 groups, <ref type="bibr">{&gt;=2000, 1999, 1998, 1997, 1996, 1995, 1994-1990, 80</ref>'s, 70's, 60's, 50's, 40's, &lt;1940}. In EachMovie, there are two "status" categories for movies, "theater-status" and "video-status". We also grouped users into three location categories based on zip code, including "US", "international" and "unknown".</p><p>In addition to item features from data, we used fourteen filterbots <ref type="bibr" target="#b24">[24]</ref> as item features for our proposed approach. These bots rate all or most of the items algorithmically according to attributes of the items or users. For example, an actor bot would rate all items in the database according to whether a specific actor was present in the movie or not. The MPBot rates items based on their global popularity computed by the equation <ref type="bibr" target="#b11">(11)</ref>. The VTBot rates items according to their "user support" such as = log / , where is the number of users who have rated an item (or user support on the item ) and is a normalization factor that caps ratings at the maximum rating (5 for MovieLens and 6 for EachMovie). The GenreBot first calculates average ratings of each genre. Then it rates items based on the average rating of the genre which a movie belongs to. If a movie has more than one genre, GenreBot rates the item based on average of genre ratings. We also built eleven SMPBots, which rates items based on their popularity in eleven segments (three gender and eight age-group segments) computed by the equation <ref type="bibr" target="#b12">(12)</ref>.</p><p>We split user ratings into four partitions. We randomly selected half of users as new users and the rest as existing users. Similarly, we randomly split items as new and existing items. Figure <ref type="figure">1</ref> illustrates data partition. Then we used partition I for training and partition II, III, and IV for test. We generated 20 partitions with different random seeds. We used the following test procedure: for each user in the partition II, III, and IV, we clustered items based on ratings given by each user. For example, if a user rated an item and five and and three, then the user would have two item clusters; one containing and and the other containing and . We considered only the items rated by each user.</p><p>Then we randomly sampled one item for each cluster. We filtered out users who have only one item cluster. In such a way, each test user is associated with a set of sampled items with size from two to five and with different ratings. Then we measured as following:</p><formula xml:id="formula_17">= 1 | | ∑ ∈ (19) = ∑ =1 2 -1 2(1 + )<label>(20)</label></formula><p>where , , and are defined as the real rating of a user on the -th ranked item, a set of users in the test data, and the best possible for the user . We measured where = 1 and 5 and observe similar results.</p><p>One potential question might be why not to measure 1 for all items that a user has rated in the test data. The reason is that there might be lots of 5 rated items for certain users in the test data and any algorithm that places one of those 5 rated items at the first place would have the best possible performance. If the number of 5 rated items for a user is larger, then the test becomes easier since algorithms just need to place one of those many 5 rated items at the first place. To remove performance bias to heavy or generous users, we sampled one item for each rating cluster to have only one best item in the test item set. For each of 20 partition sets, we sampled 500 times for each user and average 1 over those 500 runs. Then we reported the mean 1 and the standard deviations over 10,000 runs. All fourteen filterbots were imported as item features when our approach was tested on the partition II (existing item recommendation for new users). For the partition III and IV, only GenreBot was imported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Empirical Results</head><p>We conducted experiments on three types of cold-start recommendation tasks: (1) recommendation on existing items for new users, (2) recommendation on new items for existing users, and (3) recommendation on new items for new In the first recommendation task, we compared our approach to five alternative recommendation methods: Random, Most popular, Segmented Most Popular, and two variations of the Affinity algorithm. We found that SMP and our approach perform better than others but performance differences among MP, SMP, Affinity1 and our approach are not significant. Our results show that item popularity features such as global popularity (MP) or popularity within a segment (SMP) provide much stronger signals than any other item features and it makes MP and SMP hard-to-beat baselines, which is also shown in <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b11">11]</ref>.</p><p>In the second and third tasks, since all items we can recommend are new items without any historical ratings, MP, SMP, and Affinity1 cannot work. With absent of item popularity features, we clearly see our approach significantly outperforms over random and Affinity2. We would like to note that our approach can be used to estimate initial guess of item popularity for new items in online recommender systems such as Yahoo! Front Page Today Module <ref type="bibr" target="#b1">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>In many real recommender systems, great portion of users are new users and converting new users to active users is a key of success for online enterprisers. We developed hybrid approaches which exploit not only user ratings but also features of users and items for cold-start recommendation. We constructed profiles for user/item pairs by outer product over their individual features, and built predictive models in regression framework on pairwise user preferences. The unique solution is found by solving a convex optimization problem and the resulting algorithms scale efficiently for large scale data sets. Although the available features of items and users are simple and sometimes incomplete in our experiments, our methods performed consistently and significantly better than two baseline algorithms, random and Affinity2, on new user and new item recommendation. As for future work, we would like to extensively compare with other existing variants along the direction of feature-based modeling on ranking quality in cold-start situations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Basic statistics of the MovieLens and Each-Movie data.</figDesc><table><row><cell></cell><cell cols="2">MovieLens EachMovie</cell></row><row><cell>Range of ratings</cell><cell>1∼ 5</cell><cell>1 ∼ 6</cell></row><row><cell># of users</cell><cell>6,040</cell><cell>61,131</cell></row><row><cell># of items</cell><cell>3,706</cell><cell>1,622</cell></row><row><cell># of ratings</cell><cell>1,000,209</cell><cell>2,559,107</cell></row><row><cell>Average rating</cell><cell>3.58</cell><cell>4.34</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>User attributes and movie features in MovieLens and EachMovie we used.</figDesc><table><row><cell>MovieLens EachMovie</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Test results: Average 1 and standard deviation (STD) over 10,000 runs with twenty partitions are measured. Random, Most Popular (MP), Segmented Most Popular (SMP: Age segmentation), two variations of the Affinity model (Affinity1 and Affinity2), and Tensor Pairwise Regression (Pairwise) approaches are tested on three cold-start settings. Bold-face represents the best. The first type of cold-start recommendation task is executed when new users request recommendation at any system while the second and third cold-start recommendation usually happens in News domain or newly-launched systems where a recommender is always forced to recommend new items.</figDesc><table><row><cell cols="2">Cold-start setting Algorithm</cell><cell cols="2">MovieLens</cell><cell cols="2">EachMovie</cell></row><row><cell></cell><cell></cell><cell>1</cell><cell>STD</cell><cell>1</cell><cell>STD</cell></row><row><cell></cell><cell>Random</cell><cell>0.4163</cell><cell>0.0068</cell><cell>0.4553</cell><cell>0.0055</cell></row><row><cell>Existing item</cell><cell>MP</cell><cell>0.6808</cell><cell>0.0083</cell><cell>0.6798</cell><cell>0.0166</cell></row><row><cell>recommendation</cell><cell>SMP</cell><cell>0.6803</cell><cell cols="3">0.0078 0.6868 0.0146</cell></row><row><cell>for new users</cell><cell>Affinity1</cell><cell>0.6800</cell><cell>0.0077</cell><cell>0.6698</cell><cell>0.0134</cell></row><row><cell></cell><cell>Affinity2</cell><cell>0.4548</cell><cell>0.0091</cell><cell>0.5442</cell><cell>0.0154</cell></row><row><cell></cell><cell>Pairwise</cell><cell cols="2">0.6888 0.0078</cell><cell>0.6853</cell><cell>0.0149</cell></row><row><cell>New item</cell><cell>Random</cell><cell>0.4158</cell><cell>0.0059</cell><cell>0.4539</cell><cell>0.0052</cell></row><row><cell>recommendation</cell><cell>Affinity2</cell><cell>0.4489</cell><cell>0.0094</cell><cell>0.5215</cell><cell>0.0149</cell></row><row><cell>for existing users</cell><cell>Pairwise</cell><cell cols="4">0.4972 0.0145 0.5821 0.0176</cell></row><row><cell>New item</cell><cell>Random</cell><cell>0.4154</cell><cell>0.0065</cell><cell>0.4540</cell><cell>0.0046</cell></row><row><cell>recommendation</cell><cell>Affinity2</cell><cell>0.4439</cell><cell>0.0102</cell><cell>0.5212</cell><cell>0.0145</cell></row><row><cell>for new users</cell><cell>Pairwise</cell><cell cols="4">0.4955 0.0141 0.5821 0.0172</cell></row><row><cell>users.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Other loss functions could be applied as well, e.g. the hinge loss in support vector machines, while advanced quadratic programming has to be applied.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">ACKNOWLEDGMENTS</head><p>We thank our colleagues, Deepak Agarwal, Bee-Chung Chen, Pradheep Elango, and Liang Zhang for many useful discussions. We thank MovieLens and EachMovie for publishing their valuable data.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>* This work was conducted while Seung-Taek Park was at Yahoo! Labs.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Online models for content optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Elango</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Motgi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zachariah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Regression based latent factor models</title>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">B.-C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Predictive discrete latent factor models for large scale dyadic data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Merugu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Horting hatches an egg: a new graph-theoretic approach to collaborative filtering</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM KDD</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="201" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fab: content-based, collaborative recommendation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Balabanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shoham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="66" to="72" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A joint framework for collaborative and content filtering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Basilico</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recommendation as classification: Using social and content-based information in recommendation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hirsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI/IAAI</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="714" to="720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Modeling relationships at multiple scales to improve accuracy of large recommender systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning collaborative information filters</title>
		<author>
			<persName><forename type="first">D</forename><surname>Billsus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="46" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Empirical analysis of predictive algorithms for collaborative filtering</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Breese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kadie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Personalized recommendation on dynamic contents using probabilistic bilinear models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-T</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th international conference on World wide web</title>
		<meeting>the 18th international conference on World wide web</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Combining content-based and collaborative filters in an online newspaper</title>
		<author>
			<persName><forename type="first">M</forename><surname>Claypool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gokhale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Miranda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Murnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Netes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sartin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR Workshop on Recommender Systems</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Collaborative prediction using ensembles of maximum margin matrix f actorization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Decoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Eigentaste: A constant time collaborative filtering algorithm</title>
		<author>
			<persName><forename type="first">K</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Perkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="133" to="151" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Combining collaborative filtering with personal agents for better recommendations</title>
		<author>
			<persName><forename type="first">N</forename><surname>Good</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Borchers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI/IAAI</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="439" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Parafac2: Mathematical and technical notes</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Harshman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972">1972</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="30" to="44" />
		</imprint>
	</monogr>
	<note>UCLA working papers in phonetics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Support vector learning for ordinal regression</title>
		<author>
			<persName><forename type="first">R</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Obermayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Ninth International Conference on Artificial Neural Networks</title>
		<meeting>of the Ninth International Conference on Artificial Neural Networks</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="97" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An algorithmic framework for performing collaborative filtering</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Borchers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="230" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Latent class models for collaborative filtering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="688" to="693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Content-boosted collaborative filtering</title>
		<author>
			<persName><forename type="first">P</forename><surname>Melville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mooney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nagarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Vibes: A platform-centric approach to building recommender systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Nag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Eng. Bull</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="23" to="31" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A tensor higher-order singular value decomposition for integrative analysis of dna microarray data from different studies</title>
		<author>
			<persName><forename type="first">L</forename><surname>Omberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Alter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PNAS</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">47</biblScope>
			<biblScope unit="page" from="18371" to="18376" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to rank with pairwise regularized least-squares</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pahikkala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tsivtsivadze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Airola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Boberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salakoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR 2007 Workshop on Learning to Rank for Information Retrieval</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="27" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Naíve filterbots for robust cold-start recommendations</title>
		<author>
			<persName><forename type="first">S.-T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Pennock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Madani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Good</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Decoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A framework for collaborative, content-based and demographic filtering</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="393" to="408" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Collaborative filtering by personality diagnosis: A hybrid memory-and model-based approach</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pennock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="473" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Application of dimensionality reduction in recommender systems-a case study</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM WebKDD Workshop</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Methods and metrics for cold-start recommendations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Schein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Popescul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Pennock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Social information filtering: Algorithms for automating &quot;word of mouth</title>
		<author>
			<persName><forename type="first">U</forename><surname>Shardanand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Matchbox: large scale online bayesian recommendations</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th international conference on World wide web</title>
		<meeting>the 18th international conference on World wide web</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Beyond streams and graphs: Dynamic tensor analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of The Twelfth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>of The Twelfth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Some mathematical notes on three-mode factor analysis</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="279" to="311" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Efficient rank-r approximation of tensors: A new approach to compact representation of image ensembles and recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE International Conference on Computer Vision and Pattern Recognition</title>
		<meeting>of the IEEE International Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Scalable collaborative filtering using cluster-based smoothing</title>
		<author>
			<persName><forename type="first">G</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Taxonomy-driven computation of product recommendations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
