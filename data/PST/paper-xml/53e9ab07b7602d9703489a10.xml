<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Multiple-CMP Systems Using Token Coherence</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Marty</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Sciences Department</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jesse</forename><forename type="middle">D</forename><surname>Bingham</surname></persName>
							<email>jbingham@cs.ubc.ca</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of British Columbia</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
							<email>markhill@cs.wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Sciences Department</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alan</forename><forename type="middle">J</forename><surname>Hu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of British Columbia</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Milo</forename><forename type="middle">M K</forename><surname>Martin</surname></persName>
							<email>milom@cis.upenn.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Comp. &amp; Information Science</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Sciences Department</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Multiple-CMP Systems Using Token Coherence</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5D7A56987EEBEA2D907021D438AADBAB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Improvements in semiconductor technology now enable Chip Multiprocessors</head> (CMPs)<p>. As many future computer systems will use one or more CMPs and support shared memory, such systems will have caches that must be kept coherent.</p><p>Coherence is a particular challenge for Multiple-CMP (M-CMP) systems. One approach is to use a hierarchical protocol that explicitly separates the intra-CMP coherence protocol from the inter-CMP protocol, but couples them hierarchically to maintain coherence. However, hierarchical protocols are complex, leading to subtle, difficult-to-verify race conditions. Furthermore, most previous hierarchical protocols use directories at one or both levels, incurring indirections-and thus extra latency-for sharing misses, which are common in commercial workloads.</p><p>In contrast, this paper exploits the separation of correctness substrate and performance policy in the recently-proposed token coherence protocol to develop the first M-CMP coherence protocol that is flat for correctness, but hierarchical for performance. Via model checking studies, we show that flat correctness eases verification. Via simulation with micro-benchmarks, we make new protocol variants more robust under contention. Finally, via simulation with commercial workloads on a commercial operating system, we show that new protocol variants can be 10-50% faster than a hierarchical directory protocol.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The increasing number of transistors per chip now enable Chip Multiprocessors (CMPs), which implement multiple processor cores on a chip. CMP-based designs provide high-performance, cost-effective computing for workloads with abundant thread-level parallelism, such as commercial server workloads.</p><p>Smaller-scale Single-CMP (S-CMP) systems, such as Stanford Hydra <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b14">15]</ref> and Sun MAJC <ref type="bibr" target="#b36">[37]</ref>, use a single CMP along with DRAM and support chips. Larger-scale Multiple-CMP (M-CMP) systems, such as Piranha <ref type="bibr" target="#b4">[5]</ref> and IBM Power4 <ref type="bibr" target="#b35">[36]</ref>, combine multiple CMPs to further increase performance. Because all of these systems use shared memory (to preserve operating system and application investment), a key challenge for M-CMP systems is implementing correct and highperformance cache coherence protocols. These protocols keep caches transparent to software, usually by maintaining the coherence invariant that each block may have either one writer or multiple readers. S-CMP systems are conceptually straightforward, in part because designers can leverage the large body of literature on Symmetric Multiprocessors (SMPs) <ref type="bibr" target="#b10">[11]</ref> and maintain coherence with traditional non-hierarchical snooping protocols (which rely on a logical bus) or directory protocols (which track cached copies at memory).</p><p>M-CMPs present a greater challenge, because they must maintain both intra-CMP coherence and inter-CMP coherence. Ideally, an M-CMP protocol would exploit locality by separately optimizing for the lowlatency, high-bandwidth intra-CMP communication as well as the higher-latency, lower-bandwidth inter-CMP communication. One approach uses a hierarchical protocol to separate the intra-CMP coherence protocol from the inter-CMP protocol, but couples them hierarchically to maintain the coherence invariant. This approach can apply experience with non-CMP hierarchical protocols <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b37">38]</ref> to CMPs <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b35">36]</ref>. Figure <ref type="figure" target="#fig_0">1</ref> illustrates (a) a CMP node and (b) an M-CMP with a hierarchical coherence protocol.</p><p>Hierarchical coherence presents at least two challenges. First, even non-hierarchical coherence protocols are difficult to implement correctly. Coupling two protocols into a hierarchy creates additional transient states and protocol corner cases, significantly increasing verification complexity <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6]</ref>. Races occur both among messages within each CMP (e.g., processor requests to readable/writable blocks, writebacks, invalidations, acknowledgments) and between CMPs (e.g., forwarded requests, data messages, and acknowledgments). These messages lead to many transient states in L1 caches, L2 caches, and directory controllers, particularly with opti-mizations (e.g., all MOESI states). Second, many previous hierarchical protocols-non-CMP <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b37">38]</ref> or CMP <ref type="bibr" target="#b4">[5]</ref>-use directories at one level of the hierarchy (an exception is Power4 <ref type="bibr" target="#b35">[36]</ref>). Directory protocols require indirections (and thus additional latency) on sharing misses common in many commercial workloads <ref type="bibr" target="#b3">[4]</ref>. Section 2 presents our base M-CMP system, which uses directory protocols for both intra-CMP and inter-CMP coherence.</p><p>In contrast, token coherence <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b24">25]</ref> is well suited to the present challenge, because it explicitly separates the correctness substrate from a performance policy. The correctness substrate uses token counting to guarantee that, at any time, a memory block can have a single writeable copy (with all tokens), multiple read-only copies (with one or more tokens), or is not cached (all tokens at memory). To avoid starvation, it uses persistent requests that are remembered at other nodes until the requestor garners sufficient tokens.</p><p>A token coherence performance policy, on the other hand, uses unacknowledged transient requests to seek tokens and data. It can optimize common patterns, use complex predictors, and re-issue transient requests that don't find sufficient tokens. In all cases, the correctness substrate continues to provide safety (by token counting) and avoids starvation (by eventually issuing a persistent request). The original token coherence performance policy <ref type="bibr" target="#b24">[25]</ref>, however, is not well-suited for M-CMP systems because it assumes flat glueless multiprocessors with private caches.</p><p>This paper extends token coherence to M-CMP systems by developing TokenCMP. TokenCMP provides coherence in a manner that is flat for correctness (Section 3), but direct and hierarchical for performance (Section 4). We demonstrate the following three contributions:</p><p>• Simplicity. TokenCMP can be shown correct by verifying only a flat correctness substrate. Via model checking, we show the effort required is comparable or less than verifying a flat directory protocol, which is known to be much simpler than verifying hierarchical directory protocols (Section 5).</p><p>• Robustness. Under contention, the original token coherence proposal used a persistent request mechanism that could become a performance bottleneck. We extend the original starvation avoidance mechanism with persistent read requests and a distributed activation mechanism. We use microbenchmarks to show that TokenCMP variants can handle highly-contended blocks more robustly (Section 7).</p><p>• Performance. We evaluate the performance of TokenCMP versus a hierarchical directory protocol. We simulate three commercial workloads interacting with a commercial operating system on an M-CMP system using four 4-way CMPs (Section 6). We show TokenCMP can be 9-50% faster than a hierarchical directory protocol (Section 8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Base M-CMP System &amp; DirectoryCMP</head><p>In this paper, we compare TokenCMP against a base M-CMP system that uses directory protocols, not snooping, for both inter-CMP and intra-CMP coherence (similar to Piranha <ref type="bibr" target="#b4">[5]</ref>). This approach allows both on-and off-chip interconnects to be unordered and fully-connected to reduce latency.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> shows block diagrams of a CMP node and the 4-CMP system evaluated in this study. Each CMP contains four processors, private L1 instruction and data caches, shared L2 cache banks, an on-chip interconnect, a global interconnect interface, and an interface to an off-chip memory controller, which in turn connects to DRAMs. Using a separate memory controller allows the CMP to dedicate more pins for the global interconnect and support greater memory bandwidth and capacity.</p><p>Our base system uses an MOESI-based hierarchical directory protocol called DirectoryCMP. Each L2 cache bank maintains an intra-CMP directory to track copies in L1 caches. The intra-CMP directory controller maintains coherence with messages among the onchip caches, and it interfaces with the inter-CMP directory protocol.</p><p>In the inter-CMP directory protocol, each memory controller maintains an inter-CMP directory to track which CMP nodes cache a block, but not which caches within the CMP hold the block. The inter-CMP directory maintains coherence with messages between itself and the appropriate L2 cache bank at each CMP.</p><p>The intra-and inter-CMP directories and protocols cooperate to maintain M-CMP coherence. An L1 miss sends a coherence request to the appropriate on-chip L2 bank. Depending on the intra-CMP directory state and the L2 cache state, a response is directly returned, or the request is forwarded to on-chip L1 caches or to the inter-CMP directory (located at the home memory controller for the block). As responses return through the hierarchical network, they update the appropriate cache and directory state.</p><p>In designing DirectoryCMP, we made choices that improved runtime at the expense of additional control messages. DirectoryCMP implements a migratory sharing optimization <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b33">34]</ref>, in which a cache holding a modified cache block invalidates its copy when responding with the block, thus granting the requesting processor read/write access to the block (even if the request was only for read access). This optimization substantially improves performance of many workloads with read-modify-write sharing behavior. To moderately reduce DirectoryCMP complexity and enable the use of optimizations such as migratory sharing, the protocol uses per-block busy states at both the intra-CMP and inter-CMP directories to defer requests to blocks with outstanding requests. It also uses threephase writebacks, at both levels, to defer and coordinate writebacks with other requests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Flat Correctness Substrate</head><p>Token coherence provides safety (all actions correct) and starvation avoidance (take appropriate actions) with a correctness substrate that is separate from a performance policy <ref type="bibr" target="#b24">[25]</ref>. This section describes token coherence's correctness substrate and our enhancements to the substrate for shared caches and better performance robustness under contention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Safety</head><p>Token coherence's correctness substrate directly enforces the coherence invariant-that each block can have either a single writer or multiple readers-with the simple mechanism of counting tokens. Each block always has T tokens, one of which is distinguished as the owner token. Tokens are stored at and exchanged among processor nodes and memory using 1+log 2 T]bit token counts. A processor node with all T tokens may write a block, while a node with one or more tokens may read a block. To allow all processor nodes to share a block, T should be at least as large as the number of nodes. Messages with the owner token must contain valid data, while messages with only nonowner tokens may omit data (to save bandwidth).</p><p>The original scheme implicitly assumes that once tokens are given to a node, it is straightforward to maintain coherence within the node. This assumption is reasonable for a uniprocessor node, but it is not true for M-CMPs, in which each node has multiple processors with private L1 caches and a shared L2 cache.</p><p>Fortunately, we can enforce safety in M-CMP systems simply by passing tokens among caches, rather than among nodes. Thus, each cache-L1 data, L1 instruction, and unified L2 bank-essentially acts like a "node". A processor may read (fetch) a block if it's L1 data (instruction) cache has at least one token; it may write a block if its L1 data cache has all T tokens. Caches exchange data and tokens following the original token coherence rules. A block may be simultaneously cached in at most T caches. Fortunately, doubling T (e.g., to accommodate more caches than processors) adds only 1 bit to the token count.</p><p>This flat correctness substrate provides processors within an M-CMP the same simple safety checks to enforce the coherence invariant that existed in the original token coherence protocol. All the additional complexity introduced by an M-CMP's physical hierarchy (e.g., finding a block locally within a CMP when possible) is handled by a performance policy (Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Starvation Avoidance</head><p>Because token counting guarantees safety, performance policies may use unacknowledged transient requests to aggressively seek tokens without the ordering restrictions imposed by conventional protocols. This provides the flexibility to optimize hierarchical performance, but also means that transient requests may miss in-flight tokens. To ensure this situation does not lead to starvation, the correctness substrate issues a persistent request when a processor fails to acquire sufficient tokens within a time interval. The substrate activates at most one persistent request per block. Coherence components remember all activated persistent requests and forward all tokens for the blockthose tokens currently present and received in the future-to the initiator of the request. When the initiator has sufficient tokens, it performs a memory operation (e.g., a load or store instruction) and deactivates its persistent request. In addition, the system must provide a starvation-free mechanism for activating persistent requests. For glueless multiprocessors, Martin et al. <ref type="bibr" target="#b24">[25]</ref> employ arbiters and fair queuing to select one active persistent request per memory controller.</p><p>To avoid starvation in an M-CMP system, we consider two persistent request mechanisms. One extends the arbiter-based scheme and the other uses a new distributed activation approach <ref type="bibr" target="#b22">[23]</ref>. Both also include new mechanisms, discussed below, to improve worstcase performance on contended blocks.</p><p>Arbiter-based Activation. Extending the original arbiter-based persistent request mechanism to M-CMPs is straightforward, but requires each cache, not just each node, to remember active persistent requests. Using arbiter-based persistent requests provides flat starvation avoidance in M-CMP systems. Furthermore, the tables for storing active persistent requests are small (e.g., 384 bytes for 64 six-byte entries) and directly addressed.</p><p>However simple, the arbiter-based activation mechanism lacks performance robustness. That is, when performance gets bad, persistent requests tend to make it worse because the handoff from one persistent request to the next requires an indirect deactivate/activate exchange with the arbiter, increasing both latency and bandwidth consumption. Although this has little effect for well-tuned workloads, we seek an alternative mechanism that avoids surprises with more demanding applications.</p><p>Distributed Activation. The new scheme improves worst-case performance by using a distributed arbitration mechanism to directly forward contended blocks to the processor's requesting L1 cache with the next active persistent request. Each processor initiates at most one persistent request, and each cache remembers these persistent requests in a table (each table has one entry per processor). The table activates only the highest priority persistent request of those in the table seeking the same block. Priority among persistent requests is fixed (e.g., by processor number). When a cache receives a message deactivating a persis-tent request, it clears the corresponding table entry. When a processor deactivates its own persistent request, its local table "marks" all valid entries for the same block by setting a bit in the entry. A processor is allowed to issue a persistent request only when no marked entries for the desired block are present in its local persistent request table. The marking mechanism prevents a processors from continually issuing persistent requests that starve out another processor. This approach is loosely based on FutureBus <ref type="bibr" target="#b34">[35]</ref> arbitration, which uses a fixed priority but groups processors into "waves" to prevent them from re-requesting bus access until all current wave members obtain access.</p><p>Distributed activation reduces the average persistent request latency by forwarding highly contended blocks directly between processors. For example, let processors P1, P2, and P3 seek block B with persistent requests. All three will remember each other's requests, but activate only the highest priority request, say, processor P1's. When P1 succeeds, it deactivates its request, activates P2's request, and sends block B to P2. When P2 is done, it sends block B directly to P3. In this way, the distributed scheme provides a minimum latency hand-off on highly-contended blocks (e.g., hot locks). Secondarily, locality can be enhanced by simply fixing processor priority so that least-significant bits vary for processors within a CMP and more-significant bits vary between CMPs. In particular, with this approach, highly-contended spin locks tend to dynamically perform much like complex hierarchical or reactive locks <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>Distributed activation is implemented with small tables, like the arbiter-based scheme, but with a content-addressable access. When tokens for block B arrive, the table is searched for an active persistent request for block B, and, if found, tokens are forwarded. When a new persistent request for block B arrives, the table is searched for an active persistent request to block B. The incoming request is inserted and made active (possibly forwarding tokens) depending on the priority of the requestor. Furthermore, implementation is straightforward and like a fullyassociative translation lookaside buffer, but with a multi-cycle access time being acceptable.</p><p>Persistent Read Requests. The original persistent request mechanism always collects all tokens, regardless of whether the starving processor wants to read or write a block. This approach performs poorly for certain access patterns, such as a highly-contended testand-test-and-set lock. We implement a new persistent read request that forces all caches to give up all but one token <ref type="bibr" target="#b22">[23]</ref>. As long as the total number of tokens is greater than the number of caches, this approach (1) guarantees the requester will receive at least one token and (2) avoids stealing read permission away from other caches. The correctness substrate issues persistent reads when a processor fails to make progress on a load, and issues the original persistent request for stores and atomic memory operations.</p><p>Response Delay Mechanism. Highly-contended locks can result in the coherence protocol prematurely stealing permissions from the processor executing a critical section. To improve locking performance, all protocols implement a simple, non-speculative delay mechanism that ensures that a processor holds permissions for a block long enough to perform a short critical section (inspired by Rajwar et al. <ref type="bibr" target="#b30">[31]</ref>). Adding a bounded delay does not affect starvation-avoidance guarantees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Token and Data Transfer</head><p>The correctness substrate ensures that data and tokens are transferred without loss or corruption. Like most cache coherence protocols, this guarantee requires that the interconnection network eventually delivers each message accurately. The performance policy, discussed next, invokes the correctness substrate to reliably transfer data and tokens on its behalf.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Hierarchical Performance Policy</head><p>The safety and starvation-freedom guarantees provided by the correctness substrate enable aggressive performance policies. For example, a performance policy can optimize for common cases, without concern for the races that make conventional protocol optimizations so complex.</p><p>The original TokenB performance policy targets flat modestly-sized glueless multiprocessors with lowlatency, high-bandwidth, unordered interconnects <ref type="bibr" target="#b24">[25]</ref>. TokenB broadcasts transient requests to all nodes. Nodes respond to these transient requests with one or more tokens, however, a transient request may fail to collect sufficient tokens. In such situations, a processor re-broadcasts its transient request after a timeout threshold. TokenB monitors average response times to determine this timeout threshold, and it re-broadcasts a transient request up to three times. After a fourth timeout the substrate issues a persistent request. Pseudorandom backoff avoids lock-step retries.</p><p>TokenB is not well-suited for an M-CMP system. First, the timeout threshold does not account for the difference in response latency between local and remote caches. Second, broadcasting requests requires greater cache lookup bandwidth, since all L1 and L2 caches may hold tokens. Third, requests do not exploit locality; doing so can reduce both latency and inter-CMP bandwidth by finding tokens and data within the local CMP. Finally, it may be worthwhile to filter external requests arriving at a CMP to save the intra-CMP bandwidth of forwarding the requests to all L1 caches. TokenB does not consider these optimizations because it assumed a flat system.</p><p>Table <ref type="table" target="#tab_0">1</ref> lists the TokenCMP variants evaluated in this study. TokenCMP-arb0 and TokenCMP-dst0 use no performance policy and never issue transient requests; instead, they rely on the correctness substrate to immediately issue a persistent request for all processor requests. We use these variants to stress robustness, but we do not recommend deploying them in real systems (because persistent requests are less efficient than transient requests). TokenCMP-arb0 uses the original arbiter-based persistent request activation mechanism, while TokenCMP-dst0 and all subsequent variants use the new distributed activation mechanism (described in Section 3.2).</p><p>The last four TokenCMP variants have much in common. On an L1 miss, each broadcasts a coherence request only within its CMP to the appropriate on-chip L2 cache bank and other on-chip L1 caches. The local L1 caches check their tags. On a write request, an L1 replies with data (if it holds the owner token) and all its tokens. An L1 cache responds to a local read request if it has multiple tokens. If it has all tokens and has modified the data, it optimizes for migratory sharing by transferring the data and all tokens. Otherwise it responds with data and one token. On an L2 miss, each CMP broadcasts the request to other CMPs. A CMP responds to external write requests by returning all tokens (and data if it holds the owner token). A CMP responds to external read requests only if it holds the owner token. To reduce the latency of a future intra-CMP request, read responses include C tokens (if possible), rather than the necessary 1 token, where C is the number of caches on a CMP node. A cache may also respond to a read request with all T tokens to optimize for migratory sharing.</p><p>In all cases, a cache only responds to external requests when it actually has tokens. In contrast, a traditional protocol may need to track or block pending requests, allowing it to create a queue of pending requests for a contended block.</p><p>Finally, the TokenCMP variants set their timeout threshold using responses from memory. We found that TokenB's approach of averaging in the latency of all responses led to a rapid burst of retries, because fast on-chip hits accounted for a substantial portion of the running average.</p><p>The last four TokenCMP variants differ as follows. TokenCMP-dst4 follows TokenB's approach of issuing three retries (four transient requests total) before resorting to a persistent request. In contrast, TokenCMP-dst1 uses a persistent request immediately after the initial transient request times out. This policy exploits the lower latency of the new distributed activation mechanism.</p><p>TokenCMP-dst1-pred adds a predictor to detect highly-contended blocks and immediately issue a persistent request to avoid a potential timeout. Our base predictor uses a four-way set-associative 256-entry table of 2-bit saturating counters (other configurations performed similarly). A counter is allocated and incremented when a transient request is retried. Counters are reset pseudo-randomly to allow adaptation to different phase behaviors.</p><p>Finally, TokenCMP-dst1-filt filters external transient requests to conserve intra-CMP bandwidth. Each L2 bank maintains an approximate directory of L1 sharers and forwards external transient requests to only those caches. This filtering can be approximate because the correctness substrate provides safety and prevents starvation (persistent requests are never filtered). This approach contrasts with previous coherence filters that could cause coherence violations if they filtered too many coherence requests <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b31">32]</ref>.</p><p>For our workloads and system size (16 processors in four 4-processor CMPs), however, we will see that TokenCMP-dst1-pred and TokenCMP-dst1-filt may not contribute enough to justify their implementation costs. Nevertheless, these and other ideas (e.g., multicast via destination set prediction <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>) may be more valuable in larger systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Complexity Discussion &amp; Results</head><p>Quantifying the design and verification complexity of a system is notoriously hard, because what really matters is the subjective complexity experienced by the human designers, rather than some easily measurable quantity. A clean, modular design might be larger in terms of lines of code or number of transistors, yet be far easier to understand, design, debug, and modify. We justify our claim of simplicity two ways. First, we provide concrete examples of how we subjectively found TokenCMP variants easier to design and modify. Second, we present objective results from model-checking experiments, which show that the correctness substrate shared by all TokenCMP variants has comparable model-checking complexity to a simplified, non-hierarchical version of DirectoryCMP in which all intra-CMP details are omitted.</p><p>Subjective Experience. As an example of the greater simplicity of TokenCMP, consider writebacks. Handling writebacks correctly is difficult in a flat coherence protocol and even harder in a hierarchical one. Traditional directory protocols often require twophase or three-phase writebacks of dirty blocks to handle races and complications arising from protocol optimizations. The root of the complexity in these protocols is that all requests must find the pertinent copies of the block, even when they are in transit as part of a writeback operation. In contrast, writebacks are much simpler in protocols based on token coherence. When a cache needs to write back a block (dirty or otherwise), it simply sends tokens and (in some cases) data to either the L2 or memory; no extra messages or transient states at any caches or memory are required. A request that misses any in-flight tokens may be reissued, and the substrate will eventually invoke a persistent request to ensure that all misses eventually complete. This same property allows token coherence variants to more simply handle multiple concurrent requests to the same block.</p><p>Also, in our experience, TokenCMP is easier to change and debug than DirectoryCMP. For example, we can add or remove the migratory sharing optimization by changing the number of tokens returned in response to a read request. Adding this optimization to TokenCMP required only one additional state and a few small modifications to protocol finite state machines. Moreover, these changes are clearly correct, because they do not affect the correctness substrate. In contrast, implementing the migratory sharing optimization in a flat directory protocol was somewhat complex and doing so in a hierarchical directory protocol was even more challenging.</p><p>Model Checking. In addition to our subjective experience, we performed model-checking experiments in an effort to objectively quantify the relative complexity of TokenCMP and DirectoryCMP, as well as to increase our confidence in the correctness. Model checking is a technique for verifying properties of complex systems by exhaustively exploring the state space <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b28">29]</ref>. Model checking has become almost routine for enhancing confidence (and finding bugs) in cache coherence protocols, and the literature is too vast to survey here comprehensively. We simply note a few facts. ( <ref type="formula">1</ref>) Model checking provides exhaustive analysis, completely analyzing obscure corner cases and protocol interactions. It provides a thoroughness difficult to achieve via other analysis approaches. (2) The exhaustive analysis is also the Achilles' heel of model checking. Because the state space explodes exponentially, only very small or highly simplified configurations can be model checked successfully. With reasonably detailed protocol models, tiny configurations with only a few caches and a few blocks per cache are the limit of the state-of-the-art. (3) Despite those tiny configurations, model checking often finds bugs, e.g., McMillan and Schwalbe's seminal work for the Encore Gigamax <ref type="bibr" target="#b25">[26]</ref> through Joshi et al.'s recent results on the EV6 and EV7 <ref type="bibr" target="#b16">[17]</ref> (Braun, et al. <ref type="bibr" target="#b7">[8]</ref> cites numerous other case studies.) (4) We are not aware of any published work that has reported model checking a detailed model of a hierarchical protocol as a hierarchical protocol. The model would simply be too large. Instead, previous work considered only one layer of the hierarchy at a time, manually abstracting away the other layers.</p><p>We used the TLA+ description language <ref type="bibr" target="#b17">[18]</ref> and its TLC model checking tool <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b39">40]</ref> to model and verify TokenCMP variants and a non-hierarchical simplification of DirectoryCMP that omits all intra-CMP details. We used standard techniques for simplifying the protocols to enable model checking, e.g., symmetry, down-scaling <ref type="bibr" target="#b11">[12]</ref>, data independence <ref type="bibr" target="#b38">[39]</ref>, etc. We verified three versions of the token coherence correctness substrate: (1) TokenCMP-arb, (2) TokenCMP-dst, and (3) TokenCMP-safety, a simplified TokenCMP, used only for easily verifying safety properties, that lacks any starvation-prevention mechanisms. We modeled only the correctness substrate and the interfaces used by any performance protocol. By allowing the model to nondeterministically invoke these interfaces, we verify the correct behavior of not just one performance protocol, but all possible performance protocols.</p><p>We verified that the protocols were free of deadlock and provided a serial view of memory, in which every load returns the value of the most recent store to the same location <ref type="bibr" target="#b26">[27]</ref>. We also verified that the persistent request mechanisms in TokenCMP variants ensure that the system eventually satisfies all requests, under certain fairness constraints, e.g., messages are eventually delivered, and once a persistent request is satisfied it is eventually deactivated.</p><p>We were able to verify the correctness of all versions of TokenCMP for small configurations. The model-checking complexity was similar between TokenCMP-arb and the simplified, non-hierarchical version of DirectoryCMP. TokenCMP-dst was somewhat more computationally intensive to verify; TokenCMP-safety was somewhat less intense to verify because it omits any persistent request mechanism.</p><p>Furthermore, the number of non-comment lines of TLA+ descriptions is 383 lines for TokenCMP-arb and 396 lines for TokenCMP-dst, versus 1025 for the simplified, flat DirectoryCMP. Obviously, the size of the TLA+ descriptions is only an indirect complexity metric and depends on various modeling decisions and coding style. However, we feel that this metric accurately reflects the benefit of decoupling correctness from performance in shared memory protocols: the brevity of the token coherence TLA+ description stems from the fact that only the correctness substrate need be verified. The directory protocol does not afford such a reduction because there is no clean division between correctness and performance.</p><p>The model checking results highlight that, because the correctness substrate is flat, the TokenCMP approach is as model-checkable as a typical flat directory protocol, which is important because only flat protocols (or flat protocols manually sliced from hierarchical protocols) are currently model-checkable. Furthermore, because of token coherence's separation of correctness from performance, our model checking results apply immediately to any performance policy, including hierarchical ones. In contrast, to model check DirectoryCMP either we would need to model check a full, hierarchical M-CMP configuration, which is computationally intractable, or else we would have to resort to manual reasoning to justify abstracting away the intra-CMP protocol and hope that all corner cases have been handled correctly. We conclude that TokenCMP is simpler than a hierarchical directory protocol.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Methods</head><p>This section describes the commercial workloads, target M-CMP system assumptions, and simulation methods we use for our performance evaluation.</p><p>Benchmarks. We evaluate protocols with commercial workloads from an enhanced version of the Wisconsin Commercial Workload Suite <ref type="bibr" target="#b0">[1]</ref>. As detailed in Table <ref type="table">2</ref>, we use locking and barrier micro-benchmarks, a static web serving workload (Apache), an online transaction processing workload (OLTP), and a Java middleware workload (SPECjbb). The macrobenchmarks execute on a simulated SPARC multiprocessor running Solaris 9, while the micro-benchmarks use a testing facility immune to operating system effects.</p><p>Target M-CMP System. We target an M-CMP system that uses four directly-connected CMPs, each containing four dynamically-scheduled SPARC processors (16 processors total) with a total system memory of 4GB. We focus on 16-processor systems because (1) most multiprocessor systems have a small or moderate number of processors, and (2) the commercial workloads on which we focus can less easily exploit scalable multiprocessing systems (in contrast to technical workloads). Figure <ref type="figure" target="#fig_2">1a</ref> depicts the CMP node, while Table <ref type="table" target="#tab_1">3</ref> provides additional assumptions.</p><p>Target M-CMP Coherence Protocols We evaluate several alternative M-CMP protocols:</p><p>• DirectoryCMP provides coherence hierarchically (Figure <ref type="figure" target="#fig_2">1b</ref>) with the two-level directory protocol described in Section 2. We show results for both a DRAM directory and an unrealistic zero-cycle directory (DirectoryCMP-zero).</p><p>• TokenCMP variants are introduced in Section 4 and summarized in Table <ref type="table" target="#tab_0">1</ref>.</p><p>• PerfectL2 provides an unimplementable lower bound. All L1 misses hit in an infinite L2 cache shared across all CMPs. Simulation Infrastructure. We simulate target M-CMPs with the Virtutech Simics full-system functional execution-driven simulator <ref type="bibr" target="#b21">[22]</ref> and a perfor-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2. Benchmark Descriptions</head><p>Locking Micro-benchmark. In this micro-benchmark, each processor thinks for 10 ns, acquires a random lock (different from the last lock acquired), holds the lock for 10 ns, and repeats until the total number of acquires performed by each processor reaches a pre-determined limit. Lock acquires use test-and-test-and-set <ref type="bibr" target="#b10">[11]</ref> and contention is varied by changing the number of locks.</p><p>Barrier Micro-benchmark. This micro-benchmark models processors performing local work, waiting for a sense-reversing barrier <ref type="bibr" target="#b10">[11]</ref>, and repeating 99 more times. Local work takes 3000 ns with and without optional variability. When each processor reaches the barrier, it acquires a lock and increments a count in the same cache block. If the count is not maximum, the processor releases the lock and spins on a flag in another cache block. If the count is maximum, the processor zeros the counter, reverses the sense of the flag, and releases the lock. All processors now pass the barrier and begin the next work phase.</p><p>Apache: Static Web Content Serving. Web servers such as Apache are an important enterprise server application. We use Apache 2.0.43 configured to use a hybrid multi-process multithreaded server model with 64 POSIX threads per server process. We use 800,000 requests to warm the system, 1000 requests to warm simulated hardware caches, and detailed simulations of 100 requests for our reported results.</p><p>OLTP: Online Transaction Processing. DB2 with a TPCC-like workload. The TPC-C benchmark models the database activity of a wholesale supplier. Our OLTP workload is based on the TPC-C v3.0 benchmark using IBM's DB2 v7.2 EEE database management system. We use 10,000 transactions to warm the system and database buffer pool, 500 transactions to warm simulated hardware caches, and detailed simulations of 100 transactions for our reported results.</p><p>SPECjbb: Java Server Workload. SPECjbb2000 is a serverside Java benchmark that models a 3-tier system, but its main focus is on the middleware server business logic. We use over a million transactions to warm the system, 100,000 transactions to warm simulated hardware caches, and detailed simulations of 2000 transactions for our reported results. mance simulation infrastructure used to simulate memory hierarchies and out-of-order processors <ref type="bibr" target="#b0">[1]</ref>. We pseudo-randomly perturb simulations and calculate error bars as described by Alameldeen et al. <ref type="bibr" target="#b1">[2]</ref>. Improvements in the next section are statistically significant with 95% confidence when error bars do not overlap. We extended this infrastructure to model an M-CMP's physical hierarchy and specified both Direc-toryCMP and TokenCMP variants in a table-driven language for protocol specification <ref type="bibr" target="#b32">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Robustness Results</head><p>The distributed persistent request mechanism (Section 3.2) tries to improve performance robustness. We evaluate how well it does this using the locking and barrier micro-benchmarks and performance policies that use only persistent requests. Figure <ref type="figure">2</ref> shows runtime (smaller is better), normalized to DirectoryCMP with 512 locks, for 16 processors as the number of locks varies from 2 (high contention) to 512 (low contention). The middle two lines show DirectoryCMP with a realistic directory and an unrealizable zero-cycle directory. The other two lines show TokenCMP variants that use only persistent requests. We see that the original arbiter method (TokenCMP-arb0) performs worse than DirectoryCMP, while the new distributed method (TokenCMP-dst0) performs comparably or better than the directory variants. Not shown, TokenCMP-arb0 performs even worse when highlycontended locks map to the same arbiter, while the distributed method is immune to where locks map.</p><p>Although TokenCMP-dst0 has good runtime for this micro-benchmark, its exclusive use of persistent requests is not well suited for macro-benchmarks, in part, because of the traffic of broadcasting activate and deactivate messages to all caches. Instead, our goal is to develop protocols that are both (1) robust for contended micro-benchmarks and (2) perform well for macro-benchmarks.</p><p>Figure <ref type="figure">3</ref> shows runtime results for the various TokenCMP performance policies (normalized to Direc-toryCMP with 512 locks). For low contention (e.g., 512 locks), the results show that (1) TokenCMP variants perform well and (2) TokenCMP outperforms DirectoryCMP. This result occurs because the requested lock is often in an L1 cache in another CMP, causing many directory indirections in DirectoryCMP.</p><p>As contention increases, TokenCMP variants differ. TokenCMP-dst4 is not robust, because it wastes time issuing three retries that often fail before issuing a successful persistent request. TokenCMP-dst1 does better, and comparable to directory variants, by issuing a persistent request immediately after an initial transient request fails. Finally, TokenCMP-dst1-pred does better by using persistent requests immediately in high contention and acting like TokenCMP-dst1 in low contention. Not shown, TokenCMP-dst1-filt performs identically to TokenCMP-dst1.</p><p>To further exercise robustness, we also compare protocols using the barrier micro-benchmark from Table <ref type="table">2</ref>. Results in Table <ref type="table" target="#tab_3">4</ref> show runtimes (normalized to DirectoryCMP) for the various protocols, in which the work each processor does between barriers takes either a constant 3000 ns (middle column) or has some uniform variability (right). These results (and results using other parameters not shown) corroborate locking micro-benchmark results that TokenCMP-arb0 and TokenCMP-dst4 should be avoided (results highlighted in bold).</p><p>In summary, TokenCMP-dst1, TokenCMP-dst1pred, and TokenCMP-dst1-filt all provide robust performance even under high contention.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Performance Results</head><p>This section evaluates TokenCMP performance using commercial workloads, presenting runtime and intra-CMP and inter-CMP bandwidth results.</p><p>Runtime. Figure <ref type="figure" target="#fig_3">6</ref> displays runtime results for the macro-benchmarks from Table <ref type="table">2</ref>, normalized to Direc-toryCMP. Hash marks for a perfect global L2 cache bound the possible improvement, while DirectoryCMP is shown with both a DRAM directory and an unrealistic 0-cycle directory. We find:</p><p>• The TokenCMP variants perform significantly better than DirectoryCMP. In particular, TokenCMP-dst1 is faster than DirectoryCMP (with DRAM directory) by 50% for OLTP, 29% for Apache, and 10% for SpecJBB. 1</p><p>• All TokenCMP variants perform similarly. This implies that contention is modest and changes to improve robustness did not hurt. Persistent requests occur rarely-less than 0.3% of L1 misses for all workloads and protocols.</p><p>• TokenCMP-dst1 is best. It is more robust than TokenCMP-dst4 with similar macro-benchmark performance. The cost of TokenCMP-dst1-pred's predictor and TokenCMP-dst1-filt's filter are not justified for these workloads and system sizes. Inter-CMP Bandwidth. For our parameters, inter-CMP traffic generates little queuing delay. Nevertheless, to examine possible effects for other assumptions, we plot inter-CMP traffic in Figure <ref type="figure">7a</ref> and break it down by message type. Results are in bytes and normalized to traffic of DirectoryCMP. Data messages are 72 bytes and control messages 8 bytes. Results show TokenCMP variants generate somewhat less traffic than DirectoryCMP. We initially believed this result incorrect, because TokenCMP uses broadcast between nodes. Nevertheless, further investigation supported the result by revealing that DirectoryCMP can send more control messages than TokenCMP. Consider, for example, a sequence in which a CMP obtains an exclusive copy of a block from remote memory, updates it, and writes it back to memory. With TokenCMP, a CMP sends three request messages to the other CMPs, receives a data message, and then sends a data writeback message. With DirectoryCMP, a CMP sends a request message, receives a data message, sends an unblock message (used to reduce the implementation complexity), requests a writeback, gets a writeback grant, and sends a data writeback message. A total of 168 bytes for TokenCMP and 176 bytes for Directory-CMP.</p><p>In a system with more CMPs, TokenCMP traffic results will be worse (unless multicast with destination set predictions is employed <ref type="bibr" target="#b23">[24]</ref>). Our directory protocol also expends messages to increase performance and manage complexity whereas other implementations may choose different tradeoffs. Regardless, the current TokenCMP has reasonable traffic characteristics for modest numbers of CMPs per system.</p><p>Intra-CMP Bandwidth. Intra-CMP traffic also generates little queuing delay for our assumptions. However we plot intra-CMP traffic in Figure <ref type="figure">7b</ref> and break it down by message type. To first order, all protocols use similar intra-CMP bandwidth. As expected, TokenCMP protocols expend more traffic for request messages (both internal and external) due to broadcast. Unexpectedly, DirectoryCMP uses more traffic for response data because of an artifact of the strictly hier-   data responses must be handled by the L2 cache (intra-CMP directory). For example, an L1 cache responding to a forwarded request from an external CMP, must transfer the data to the L2 cache where it may collect other invalidation acknowledgments. Only then does the L2 send the data to the requesting chip which in turn sends the data to the requesting processor. In contrast, in TokenCMP an L1 cache directly sends the forwarded request to the requesting processor, using a single data message on the on-chip interconnect.</p><p>As introduced in Section 4, TokenCMP-dst1-filt uses an approximate directory of L1 sharers to filter external transient requests. Figure <ref type="figure">7b</ref> shows that the filter reduces intra-CMP bandwidth 6-8%, but the utilization is sufficiently low that this does not affect runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusions</head><p>Few papers have considered implementing coherence in systems with multiple chip multiprocessors (M-CMPs). Those that do implement hierarchical protocols (e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b35">36]</ref>). This paper advocates using token coherence to obtain TokenCMP protocols that have flat correctness properties, but exhibit hierarchical performance characteristics. We found TokenCMP variants easier to verify than hierarchical directory protocols. We improved token coherence performance robustness under high-contention. Finally, we showed commercial workloads can run significantly faster on M-CMP systems using TokenCMP variants instead of a hierarchical directory protocol.</p><p>This appendix provides supporting data for model checking (Section 5) and macro-benchmark execution (Section 8).  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. A CMP Node with Two Alternative Multiple CMP (M-CMP) Systems. Part (a) expands a CMP node with processors, private L1 caches, shared L2 cache banks, on-chip interconnect, global interconnect interface, and interface to offchip memory controller with DRAM. Part (b) symbolizes a direct-interconnect M-CMP system with coherence maintained via an intra-CMP protocol interacting with a inter-CMP protocol. Part (c) symbolizes an M-CMP with a logically-flat coherence protocol, such as TokenCMP developed in this paper.(a) (b) (c) Intra-CMP Coherence</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Figure 2. Locking micro-benchmark results using only persistent requests</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 .</head><label>1</label><figDesc>X% faster = runtime(DirCMP)/runtime(TokenCMP) -1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Runtime of commercial workloads</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . TokenCMP Variants</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell># Transient</cell><cell>Persistent Request</cell></row><row><cell>Name</cell><cell>Performance Policy</cell><cell>Requests</cell><cell>Activation</cell></row><row><cell>TokenCMP-arb0</cell><cell>None: immediately issues persistent requests</cell><cell>0</cell><cell>Arbiter-based</cell></row><row><cell>TokenCMP-dst0</cell><cell>None: immediately issues persistent requests</cell><cell>0</cell><cell>Distributed activation</cell></row><row><cell>TokenCMP-dst4</cell><cell>Hierarchical protocol with 1 transient request &amp; up to 3 retries</cell><cell>up to 4</cell><cell>Distributed activation</cell></row><row><cell>TokenCMP-dst1</cell><cell>Hierarchical protocol with 1 transient request, but no retries.</cell><cell>1</cell><cell>Distributed activation</cell></row><row><cell cols="2">TokenCMP-dst1-pred Hierarchical protocol with predictor to choose immediate per-</cell><cell>0 or 1</cell><cell>Distributed activation</cell></row><row><cell></cell><cell>sistent request or a single transient request.</cell><cell></cell><cell></cell></row><row><cell>TokenCMP-dst1-filt</cell><cell cols="2">Like TokenCMP-dst1 with filter on incoming external requests. 1</cell><cell>Distributed activation</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 . Target System Parameters</head><label>3</label><figDesc></figDesc><table><row><cell cols="2">Each CMP</cell></row><row><cell>number of processors</cell><cell>4 per CMP</cell></row><row><cell>cache block size</cell><cell>64 Bytes</cell></row><row><cell>split L1 I &amp; D caches</cell><cell>128kBytes, 4-way, 2ns</cell></row><row><cell>interconnect topology</cell><cell>directly connected</cell></row><row><cell>interconnect link bw</cell><cell>64 GBytes/sec</cell></row><row><cell>interconnect latency</cell><cell>2ns (one-way)</cell></row><row><cell>shared unified L2 cache</cell><cell>8MByte, 4-banks, 4-way, 7ns</cell></row><row><cell>memory/dir controllers</cell><cell>6ns latency</cell></row><row><cell cols="2">Each Dynamically Scheduled Processor</cell></row><row><cell>clock frequency</cell><cell>2 Ghz</cell></row><row><cell>reorder buffer/scheduler</cell><cell>128/64 entries</cell></row><row><cell>pipeline width</cell><cell>4-wide fetch &amp; issue</cell></row><row><cell>pipeline stages</cell><cell>11</cell></row><row><cell>direct branch predictor</cell><cell>1kBytes YAGS</cell></row><row><cell>indirect branch predictor</cell><cell>64 entry (cascaded)</cell></row><row><cell>return address stack</cell><cell>64 entry</cell></row><row><cell cols="2">Per-CMP Memory</cell></row><row><cell cols="2">latency to mem controller 20ns (off-chip)</cell></row><row><cell>DRAM latency</cell><cell>80ns</cell></row><row><cell>memory bank capacity</cell><cell>1 GByte per bank</cell></row><row><cell cols="2">Between CMPs</cell></row><row><cell>number of CMPs</cell><cell>4 (16 processors total)</cell></row><row><cell>interconnect topology</cell><cell>directly connected</cell></row><row><cell>interconnect link bw</cell><cell>16 GBytes/sec</cell></row><row><cell>interconnect link latency</cell><cell>20ns (including interface,</cell></row><row><cell></cell><cell>wire, &amp; sync.)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 . Barrier Micro-benchmark Runtime (Normalized to DirectoryCMP)</head><label>4</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">Work between barriers</cell></row><row><cell></cell><cell>3000 ns</cell><cell>3000 ns +</cell></row><row><cell>Protocol</cell><cell>fixed</cell><cell>U(-1000,+1000)</cell></row><row><cell>TokenCMP-arb0</cell><cell>1.40</cell><cell>1.29</cell></row><row><cell>TokenCMP-dst0</cell><cell>0.94</cell><cell>0.91</cell></row><row><cell>DirectoryCMP</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell>DirectoryCMP-zero</cell><cell>0.95</cell><cell>0.93</cell></row><row><cell>TokenCMP-dst4</cell><cell>1.15</cell><cell>1.01</cell></row><row><cell>TokenCMP-dst1</cell><cell>0.99</cell><cell>0.95</cell></row><row><cell>TokenCMP-dst1-pred</cell><cell>0.96</cell><cell>0.93</cell></row><row><cell>TokenCMP-dst1-filt</cell><cell>0.99</cell><cell>0.95</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Results for model checking safety. Runtimes in minutes; timeout is 10,000 minutes.</figDesc><table><row><cell></cell><cell cols="3">Parameter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Protocol</cell></row><row><cell>Processors</cell><cell>Messages</cell><cell>Addresses</cell><cell>Cache Size</cell><cell>Tokens</cell><cell cols="2">TokenCMP-dst time (min.) states</cell><cell cols="2">TokenCMP-arb time (min.) states</cell><cell>TokenCMP-safety Flat DirectoryCMP time (min.) states time (min.) states</cell></row><row><cell cols="5">2 2 1 1 1 2 2 1 1 2</cell><cell>15 85</cell><cell>1,166 6,279</cell><cell>1 5</cell><cell>460 3,177</cell><cell>0 1</cell><cell>24 267</cell><cell>0</cell><cell>1012</cell></row><row><cell cols="5">2 2 2 1 1 2 2 2 1 2</cell><cell>800 timeout</cell><cell>20,348</cell><cell>38 1123</cell><cell>8,831 176,356</cell><cell>4 353</cell><cell>384 24,380</cell><cell>15</cell><cell>39,686</cell></row><row><cell cols="5">2 2 2 2 1</cell><cell>1,315</cell><cell>32,856</cell><cell>63</cell><cell>14,438</cell><cell>4</cell><cell>405</cell><cell>138</cell><cell>268,073</cell></row><row><cell cols="5">2 3 1 1 1 2 3 1 1 2</cell><cell>50 425</cell><cell>5,344 30,560</cell><cell>1 15</cell><cell>1,004 8,988</cell><cell>0 1</cell><cell>24 267</cell><cell>0</cell><cell>1,296</cell></row><row><cell cols="5">2 3 2 1 1</cell><cell>4,081</cell><cell>141,080</cell><cell>235</cell><cell>54,502</cell><cell>4</cell><cell>384</cell><cell>32</cell><cell>80,155</cell></row><row><cell cols="5">2 3 2 2 1</cell><cell>6,301</cell><cell>217,188</cell><cell>397</cell><cell>91,803</cell><cell>4</cell><cell>405</cell><cell>582 1,086,192</cell></row><row><cell cols="5">3 3 1 1 1</cell><cell>263</cell><cell>16,916</cell><cell>6</cell><cell>1,976</cell><cell>0</cell><cell>24</cell></row><row><cell cols="5">3 3 1 1 2</cell><cell>timeout</cell><cell></cell><cell>77</cell><cell>18,616</cell><cell>3</cell><cell>270</cell><cell>8</cell><cell>16,852</cell></row><row><cell cols="5">3 3 1 1 3</cell><cell>timeout</cell><cell></cell><cell>382</cell><cell>69,977</cell><cell>26</cell><cell>1,945</cell></row><row><cell cols="5">3 3 2 1 1</cell><cell>timeout</cell><cell></cell><cell>1,297</cell><cell>119,281</cell><cell>10</cell><cell>384</cell><cell>timeout</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .</head><label>6</label><figDesc>Results for model checking liveness.Runtimes in minutes; timeout is 10,000 minutes.</figDesc><table><row><cell></cell><cell cols="3">Parameter</cell><cell></cell><cell></cell><cell cols="2">Protocol</cell></row><row><cell>Processors</cell><cell>Messages</cell><cell>Addresses</cell><cell>Cache Size</cell><cell>Tokens</cell><cell cols="2">TokenCMP-dst time (min.) states</cell><cell>TokenCMP-arb time (min.) states</cell></row><row><cell cols="5">2 2 1 1 1</cell><cell>3</cell><cell>432</cell><cell>8</cell><cell>327</cell></row><row><cell cols="5">2 2 2 1 1</cell><cell>262</cell><cell>5,952</cell><cell>21</cell><cell>4,688</cell></row><row><cell cols="5">2 2 2 2 1</cell><cell>418</cell><cell>8,920</cell><cell>28</cell><cell>7,342</cell></row><row><cell cols="5">2 2 1 1 2</cell><cell>32</cell><cell>2,556</cell><cell>10</cell><cell>2,463</cell></row><row><cell cols="5">2 2 2 1 2</cell><cell>timeout</cell><cell></cell><cell>361</cell><cell>105,274</cell></row><row><cell cols="5">2 3 1 1 1</cell><cell>19</cell><cell>1,966</cell><cell>8</cell><cell>723</cell></row><row><cell cols="5">2 3 1 1 2</cell><cell>188</cell><cell>12,044</cell><cell>15</cell><cell>6,853</cell></row><row><cell cols="5">2 3 2 1 1</cell><cell>2,109</cell><cell>40,680</cell><cell>91</cell><cell>29,388</cell></row><row><cell cols="5">2 3 2 1 2</cell><cell>timeout</cell><cell></cell><cell>3,691</cell><cell>885,624</cell></row><row><cell cols="5">2 3 2 2 1</cell><cell>3,253</cell><cell>59,204</cell><cell>114</cell><cell>47,535</cell></row><row><cell cols="5">3 3 1 1 1</cell><cell>170</cell><cell>6,123</cell><cell>14</cell><cell>3,658</cell></row><row><cell cols="5">3 3 1 1 2</cell><cell>2,434</cell><cell>49,647</cell><cell>110</cell><cell>38,191</cell></row><row><cell cols="5">3 3 2 1 1</cell><cell>timeout</cell><cell></cell><cell>1,255</cell><cell>179,541</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 . Macro-Benchmarks Absolute Data All</head><label>7</label><figDesc>numbers in thousands. Instruction and miss counts are totals for 16 processors.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>L1</cell><cell>L2</cell></row><row><cell>Protocol</cell><cell>Cycles</cell><cell>Instructions</cell><cell>Misses</cell><cell>Misses</cell></row><row><cell cols="3">SpecJBB (2,000 transactions)</cell><cell></cell><cell></cell></row><row><cell>Perfect L2</cell><cell>6,017</cell><cell>106,795</cell><cell>1,130</cell><cell>0</cell></row><row><cell>DirectoryCMP</cell><cell>11,707</cell><cell>109,462</cell><cell>1,418</cell><cell>374</cell></row><row><cell>DirectoryCMP-zero</cell><cell>11,324</cell><cell>109,422</cell><cell>1,405</cell><cell>368</cell></row><row><cell>TokenCMP-dst4</cell><cell>10,676</cell><cell>108,984</cell><cell>1,379</cell><cell>418</cell></row><row><cell>TokenCMP-dst1</cell><cell>10,658</cell><cell>108,984</cell><cell>1,379</cell><cell>417</cell></row><row><cell>TokenCMP-dst1-pred</cell><cell>10,622</cell><cell>108,972</cell><cell>1,377</cell><cell>413</cell></row><row><cell>TokenCMP-dst1-filt</cell><cell>10,675</cell><cell>108,994</cell><cell>1,380</cell><cell>420</cell></row><row><cell></cell><cell cols="2">Apache (100 transactions)</cell><cell></cell><cell></cell></row><row><cell>Perfect L2</cell><cell>2,922</cell><cell>24,690</cell><cell>808</cell><cell>0</cell></row><row><cell>DirectoryCMP</cell><cell>9,083</cell><cell>30,575</cell><cell>1,180</cell><cell>363</cell></row><row><cell>DirectoryCMP-zero</cell><cell>7,928</cell><cell>27,583</cell><cell>1,048</cell><cell>352</cell></row><row><cell>TokenCMP-dst4</cell><cell>6,996</cell><cell>26,006</cell><cell>1,025</cell><cell>347</cell></row><row><cell>TokenCMP-dst1</cell><cell>7,023</cell><cell>26,212</cell><cell>1,037</cell><cell>346</cell></row><row><cell>TokenCMP-dst1-pred</cell><cell>6,977</cell><cell>25,521</cell><cell>960</cell><cell>345</cell></row><row><cell>TokenCMP-dst1-filt</cell><cell>6,911</cell><cell>25,697</cell><cell>1,012</cell><cell>341</cell></row><row><cell></cell><cell cols="2">OLTP (100 transactions)</cell><cell></cell><cell></cell></row><row><cell>Perfect L2</cell><cell>16,216</cell><cell>180,668</cell><cell>3,458</cell><cell>0</cell></row><row><cell>DirectoryCMP</cell><cell>37,769</cell><cell>274,955</cell><cell>3,750</cell><cell>1,292</cell></row><row><cell>DirectoryCMP-zero</cell><cell>30,933</cell><cell>228,801</cell><cell>3,695</cell><cell>1,243</cell></row><row><cell>TokenCMP-dst4</cell><cell>25,155</cell><cell>193,385</cell><cell>3,645</cell><cell>1,391</cell></row><row><cell>TokenCMP-dst1</cell><cell>25,038</cell><cell>198,909</cell><cell>3,642</cell><cell>1,362</cell></row><row><cell>TokenCMP-dst1-pred</cell><cell>24,492</cell><cell>192,026</cell><cell>3,633</cell><cell>1,319</cell></row><row><cell>TokenCMP-dst1-filt</cell><cell>24,479</cell><cell>192,111</cell><cell>3,567</cell><cell>1,339</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Supporting Data (not included in HPCA proceedings version)</head><label></label><figDesc></figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Virtutech AB, the Wisconsin Condor group, and the Wisconsin Computer Systems Lab for their help and support. We thank Brad Beckmann, Kevin Moore, the Wisconsin Multifacet group, and the Wisconsin Computer Architecture Affiliates for their comments on this work.</p><p>This work is supported in part by the National Science Foundation (CCR-0324878, EIA/CNS-0205286, and CCR-0105721) and donations from Intel Corporation and Sun Microsystems. Hu is supported in part by a research grant from the Natural Sciences and Engineering Research Council of Canada, and Bingham is supported by a UBC Graduate Fellowship. Hill and Wood have a significant financial interest in Sun Microsystems.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Simulating a $2M Commercial Server on a $2K PC</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Alameldeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M K</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Mauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Sorin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="50" to="57" />
			<date type="published" when="2003-02">Feb. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Variability in Architectural Simulations of Multi-threaded Workloads</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Alameldeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth IEEE Symposium on High-Performance Computer Architecture</title>
		<meeting>the Ninth IEEE Symposium on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2003-02">Feb. 2003</date>
			<biblScope unit="page" from="7" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Barroso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gharachorloo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
			<publisher>Personal Communication</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Memory System Characterization of Commercial Workloads</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Barroso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bugnion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual International Symposium on Computer Architecture</title>
		<meeting>the 25th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1998-06">June 1998</date>
			<biblScope unit="page" from="3" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Piranha: A Scalable Architecture Based on Single-Chip Multiprocessing</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Barroso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nowatzyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qadeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Verghese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual International Symposium on Computer Architecture</title>
		<meeting>the 27th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
			<biblScope unit="page" from="282" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Managing Complexity in the Piranha Server-Class Processor Design</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Barroso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ravishankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stets</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Workshop on Complexity-Effective Design held in conjunction with the 27th International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="2001-06">June 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">EXA Cache/Scalability Controllers</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Borkenhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Hoover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Valk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IBM Enterprise X-Architecture Technology: Reaching the Summit</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="37" to="50" />
		</imprint>
	</monogr>
	<note>International Business Machines</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Proving Sequential Consistency by Model Checking</title>
		<author>
			<persName><forename type="first">T</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Condon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Juse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leslie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International High-Level Design, Validation, and Test Workshop</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001-11">Nov. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Design and Synthesis of Synchronization Skeletons using Branching Time Temporal Logic</title>
		<author>
			<persName><forename type="first">E</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Emerson</surname></persName>
		</author>
		<idno>pag- es 52-71</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Logics of Programs</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Kozen</surname></persName>
		</editor>
		<meeting>the Workshop on Logics of Programs</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1981-05">May 1981</date>
			<biblScope unit="volume">131</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adaptive Cache Coherency for Detecting Migratory Shared Data</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Fowler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual International Symposium on Computer Architecture</title>
		<meeting>the 20th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1993-05">May 1993</date>
			<biblScope unit="page" from="98" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Parallel Computer Architecture: A Hardware/Software Approach</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Culler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Morgan Kaufmann Publishers, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Protocol Verification as a Hardware Design Aid</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Dill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Drexler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Design</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1992-10">Oct. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Architecture and Design of AlphaServer GS320</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Steely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Doren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the Ninth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2000-11">Nov. 2000</date>
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">WildFire: A Scalable Path for SMPs</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hagersten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth IEEE Symposium on High-Performance Computer Architecture</title>
		<meeting>the Fifth IEEE Symposium on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1999-01">Jan. 1999</date>
			<biblScope unit="page" from="172" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Stanford Hydra CMP</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hubbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Siu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="71" to="84" />
			<date type="published" when="2000-04">March-April 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Single-Chip Multiprocessor</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Nayfeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="79" to="85" />
			<date type="published" when="1997-09">Sept. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Checking Cache-Coherence Protocols with TLA+</title>
		<author>
			<persName><forename type="first">R</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lamport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tasiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tuttle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Formal Methods in System Design</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="131" />
			<date type="published" when="2003-03">March 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Lamport</surname></persName>
		</author>
		<title level="m">Specifying Systems: The TLA+ Language and Tools for Hardware and Software Engineers</title>
		<imprint>
			<publisher>Addision-Wesley</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Directory-Based Cache Coherence Protocol for the DASH Multiprocessor</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lenoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Laudon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hennessy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Annual International Symposium on Computer Architecture</title>
		<meeting>the 17th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1990-05">May 1990</date>
			<biblScope unit="page" from="148" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Reactive Synchronization Algorithms for Multiprocessors</title>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="1994-10">Oct. 1994</date>
			<biblScope unit="page" from="25" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">STiNG: A CC-NUMA Computer System for the Commercial Marketplace</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Lovett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Clapp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23th Annual International Symposium on Computer Architecture</title>
		<meeting>the 23th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1996-05">May 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Simics: A Full System Simulation Platform</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Magnusson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="50" to="58" />
			<date type="published" when="2002-02">Feb. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Token Coherence</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M K</forename><surname>Martin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Using Destination-Set Prediction to Improve the Latency/Bandwidth Tradeoff in Shared Memory Multiprocessors</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M K</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Sorin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th Annual International Symposium on Computer Architecture</title>
		<meeting>the 30th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
			<biblScope unit="page" from="206" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Token Coherence: Decoupling Performance and Correctness</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M K</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th Annual International Symposium on Computer Architecture</title>
		<meeting>the 30th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
			<biblScope unit="page" from="182" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Formal Verification of the Gigamax Cache-Consistency Protocol</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Mcmillan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schwalbe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Shared Memory Multiprocessing</title>
		<imprint>
			<publisher>Information Processing Society of Japan</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="242" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Mosberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memory Consistency Models. Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="26" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">JET-TY: Filtering Snoops for Reduced Power Consumption in SMP Servers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Memik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Choudhary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh IEEE Symposium on High-Performance Computer Architecture</title>
		<meeting>the Seventh IEEE Symposium on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2001-01">Jan. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Specification and Verification of Concurrent Systems in Cesar</title>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Queille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sifakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Symposium on Programming</title>
		<title level="s">Lecture Notes in Computer Science Number</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1981">1981</date>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page" from="337" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Efficient Synchronization for Nonuniform Communication Architectures</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Radovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hagersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SC2002</title>
		<meeting>SC2002</meeting>
		<imprint>
			<date type="published" when="2002-11">Nov. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Improving the Throughput of Synchronization by Insertion of Delays</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rajwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kägi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth IEEE Symposium on High-Performance Computer Architecture</title>
		<meeting>the Sixth IEEE Symposium on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2000-01">Jan. 2000</date>
			<biblScope unit="page" from="168" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Performance of Pruning-Cache Directories for Large-Scale Multiprocessors</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="520" to="534" />
			<date type="published" when="1993-05">May 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Specifying and Verifying a Broadcast and a Multicast Snooping Cache Coherence Protocol</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Sorin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Plakal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Condon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M K</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="556" to="578" />
			<date type="published" when="2002-06">June 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Adaptive Cache Coherence Protocol Optimized for Migratory Sharing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Stenström</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brorsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sandberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual International Symposium on Computer Architecture</title>
		<meeting>the 20th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1993-05">May 1993</date>
			<biblScope unit="page" from="109" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Improved Control Acquisition Scheme for the IEEE 896 Futurebus</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Taub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1987-06">June 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">POWER4 System Microarchitecture</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Tendler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dodson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fields</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sinharoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The MAJC Architecture: A Synthesis of Parallelism and Scalability</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tremblay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Conigliaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Tse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="12" to="25" />
			<date type="published" when="2000-12">Nov-Dec 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Profusion: A Buffered, Cache Coherent Crossbar Switch</title>
		<author>
			<persName><forename type="first">G</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vogt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Hot Interconnects Symposium</title>
		<meeting>the 5th Hot Interconnects Symposium</meeting>
		<imprint>
			<date type="published" when="1997-08">Aug. 1997</date>
			<biblScope unit="page" from="87" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Expressing Interesting Properties of Programs in Propositional Temporal Logic</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wolper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th ACM Symp. on Principles of Programming Languages</title>
		<meeting>13th ACM Symp. on Principles of Programming Languages</meeting>
		<imprint>
			<date type="published" when="1986-01">Jan. 1986</date>
			<biblScope unit="page" from="184" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Model Checking TLA+ Specifications</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Manolios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lamport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Correct Hardware Design and Verification Methods (CHARME &apos;99)</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Pierre</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Kropf</surname></persName>
		</editor>
		<meeting>Correct Hardware Design and Verification Methods (CHARME &apos;99)</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="54" to="66" />
		</imprint>
	</monogr>
	<note>number 1703 in LNCS</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
