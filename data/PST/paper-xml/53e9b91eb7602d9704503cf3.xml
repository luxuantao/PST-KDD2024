<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Haptic Turk: a Motion Platform Based on People</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lung-Pan</forename><surname>Cheng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>LÃ¼hne</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pedro</forename><surname>Lopes</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christoph</forename><surname>Sterz</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Baudisch</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Hasso Plattner Institute</orgName>
								<address>
									<settlement>Potsdam</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>Toronto</settlement>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Haptic Turk: a Motion Platform Based on People</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C5DA172570CAAD983A17B66456CB7BED</idno>
					<idno type="DOI">10.1145/2556288.2557101</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Haptics</term>
					<term>force-feedback</term>
					<term>motion platform</term>
					<term>immersion H5.2 [Information interfaces and presentation]: User Interfaces. -Graphical user interfaces</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Motion platforms are used to increase the realism of virtual interaction. Unfortunately, their size and weight is proportional to the size of what they actuate. We present haptic turk, a different approach to motion platforms that is light and mobile. The key idea is to replace motors and mechanical components with humans. All haptic turk setups consist of a player who is supported by one or more humanactuators. The player enjoys an interactive experience, such as a flight simulation. The motion in the player's experience is generated by the actuators who manually lift, tilt, and push the player's limbs or torso. To get the timing and force right, timed motion instructions in a format familiar from rhythm games are displayed on actuators' mobile devices, which they attach to the player's body. We demonstrate a range of installations based on mobile phones, projectors, and head-mounted displays. In our user study, participants rated not only the experience as player as enjoyable (6.1/7), but also the experience as an actuator (4.4/7). The approach of leveraging humans allows us to deploy our approach anytime anywhere, as we demonstrate by deploying at an art festival in the Nevada desert.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>For a long time, the key to immersion in interactive experience and games was sought in photorealistic graphics <ref type="bibr" target="#b7">[8]</ref>. More recently, game makers made games more immersive by requiring players to physically enact the game such as with Wii (http://wii.com) and Kinect <ref type="bibr" target="#b25">[26]</ref>. With graphics and user interaction now part of many games, many researchers argue that haptics and motion are the next step towards increasing immersion and realism, i.e., applying the forces triggered by the game onto the player's body during the experience. While some game events can be realistically rendered using one or more vibrotactile actuators (e.g., driving over gravel in a racing game <ref type="bibr" target="#b13">[14]</ref>), a much larger number of gaming events result in directional forces, such as centrifugal forces pulling at a steering wheel or a car bumping into the railing. Such events have been simulated using motion platforms <ref type="bibr" target="#b26">[27]</ref>. Motion platforms are able to move one or more users around and have been used to add realism to flight simulators <ref type="bibr" target="#b21">[22]</ref> and theme park rides. Unfortunately, the size and weight of motion platforms tends to be proportional to what they actuate. As a result, motion platforms not only tend to be prohibitively expensive, but also large and heavy and thus stationary, limiting their use to arcades and lab environments. In this paper, we present haptic turk, a software platform that allows experiencing motion anywhere there is people.</p><p>Its key idea is to substitute the motors and mechanical components of traditional motion platforms with humans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HAPTIC TURK</head><p>Haptic turk is a motion platform based on people. The name is inspired by the 18 th century chess automaton "The Turk" <ref type="bibr" target="#b19">[20]</ref> that was powered by a human chess master.</p><p>The specific configuration shown in Figure <ref type="figure" target="#fig_0">1</ref> involves one player located in the center. The player is enjoying an immersive experience, here a first-person simulation of flying a hang-glider, running on a hand-held device (iPad). In the shown setup, the player can steer the hang-glider by tilting the iPad.</p><p>The main difference to regular video games is that the player's experience comes with motion-this motion is administered by human-actuators who manually lift, tilt, and push the player around. Here there are four of them.</p><p>To get the timing and force right, all actuators receive timed motion instructions in a format familiar from rhythm games (see Figure <ref type="figure" target="#fig_2">3</ref> for a preview). In the set-up shown in Figure <ref type="figure" target="#fig_0">1</ref>, actuators receive these motion instructions on their mobile devices (here iPods and iPhones) that they have attached to the player's body.</p><p>During the experience, actuators execute the motion instructions displayed on their respective device by moving the part of the player's body assigned to them. At the moment shown in Figure <ref type="figure" target="#fig_0">1</ref>, for example, the two actuators left of the player lift up their side of the player, causing the player to be rotated ("rolled") towards the camera. Haptic turk generates these motion instructions so as to feed into the player's experience. As actuators perform their motion instructions, they therefore contribute to the player's experience, making it richer and more immersive.</p><p>A haptic turk experience may incentivize actuators to perform their best by measuring and scoring how well they match their motion instructions in terms of timing, position, and force-using the inertial measurement unit (IMU) in their mobile device. However, we obtain a better player experience by scoring actuators as a group, as this encourages actuators to synchronize during cooperative moves. But finally, several participants in our user study stated that they simply enjoyed supporting the player, suggesting that the act of providing an experience to the player provides all the necessary incentive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WALKTHROUGH</head><p>We now illustrate the haptic turk platform at the example of the specific configuration from Figure <ref type="figure" target="#fig_0">1</ref> (four actuators with mobile devices) and a hang glider experience we call team flight. The actual experience takes three minutes and contains 14 motion event groups (25 individual actuator movements overall). We present selected scenes that allow us to illustrate the design elements. As illustrated by Figure <ref type="figure" target="#fig_1">2</ref>, the experience starts out in calm weather and the player's hang glider is in a neutral, horizontal position. Accordingly, the actuator displays are blank. This instructs all actuators to stand upright, relaxed, shoulders dropped-a position that actuators can sustain with minimum effort. We design our experiences to bring actuators back to this position frequently to avoid fatigue. Note that the actuator displays show the timelines of all actuators so as the help actuators see "the big picture" and to synchronize their actions.</p><p>Up/down-bars: The player is approaching a big fan located on the right and the hang glider is about to get caught by the fan's draft. Haptic turk reflects this by rendering up/down motion instructions. The bars enter the actuator display from below and travel up the screen as the hang glider is approaching the fan (Figure <ref type="figure" target="#fig_2">3a</ref>). This leverages the visual language of, for example, dance dance revolution (www.konami.com/ddr). As the bars reach the actuators' bullseyes at the top of the screen, the respective actuators execute the instructions. Motion instructions take about seven seconds to reach the bullseye. This is essential as it allows actuators to get ready so as to perform their motion on time, i.e., in sync with the player's experience.  Up/down bars are haptic turk's most versatile design element and they are used to render the vast majority of motion events. As shown in Figure <ref type="figure" target="#fig_3">4</ref>, up/down bars come with values from -2 to +2, with +2 'chest level', +1 'waist level', blank 'relaxed', -1 'knee level', and -2 'foot level'. Redundant color-coding makes the display more glanceable (sun orange means up; grass green means down). The main idea behind up/down bars is that they show actuators exactly Here the player enters a tornado, which causes the player's hang glider to shoot up into the air. Haptic turk renders this by instructing all four actuators to abruptly lift the player to '+2' the chest level.</p><p>To make the player's experience even more intense, haptic turk instructs actuators to first lower the player slightly in anticipation and then to perform the vertical '+2' move. Collisions: In Figure <ref type="figure" target="#fig_6">6</ref>, the player's hang glider collides with an object, here a blimp approaching from the left. Haptic turk renders the event as a pair of "bump" instructions on the left. As the bump events reach the bullseyes, the left two actuators bump the player using their thighs. Bumpy ride: In Figure <ref type="figure" target="#fig_7">7</ref> the player enters turbulences, here created by a group of fans pointed at the player from different directions. Haptic turk responds by creating 'shake' instructions for all actuators, which each actuator executes as an unsynchronized vertical shake. Horizontal motion: In Figure <ref type="figure" target="#fig_8">8</ref>, the player is entering the field of a very powerful fan that propels the glider quickly out over the desert. Haptic turk emphasizes the onset of this movement with a horizontal move event, which actuators execute by taking a step into the specified direction. After all, the shown implementation of haptic turk is mobile, allowing actuators to walk around during the experience. The concept of haptic turk is broader than just motion. Figure <ref type="figure" target="#fig_9">9</ref> shows two effects that we have explored, i.e., water and heat. They are administered by an additional "special effects" actuator. Landing: Finally, the player has reached the destination: a temple in the middle of the desert. As the player approaches the ground, haptic turk generates landing instructions, as shown in Figure <ref type="figure" target="#fig_10">10</ref>. These were all simple scenes, taken from an experience designed to be calm and serene, as one would expect a</p><formula xml:id="formula_0">-1 -1 -1 -1 -1 -1 -1 -1 b a b a a b</formula><p>hang-glider experience to be. Figure <ref type="figure" target="#fig_11">11</ref> shows a more action packed game sequence we created-note how the actuator display now handles multiple actions at once. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GETTING THE TIMING RIGHT: PREEMPTIVE WARNING</head><p>The main technical challenge behind haptic turk is to get the timing right, i.e., to make sure that actuators provide force exactly at the moment required by the player's experience. This is a challenge because actuators' are inherently subject to human response time and thus delay. The mean response time for humans to react to a simple visual stimulus is 220ms <ref type="bibr" target="#b16">[17]</ref>, to which we add network delay and human movement. This duration is substantially longer than the 50ms humans tolerate in delayed haptic feedback <ref type="bibr" target="#b14">[15]</ref>.</p><p>For pose changes, we found this delay to not cause too much of an issue as long as we simulate a vehicle that moves smoothly. Hang gliders, for example, change their position only gradually in response to their pilots shifting their weight around. Here, haptic turk simply displays a preview of the expected goal pose as soon as the player starts to steer; this gives actuators ample time.</p><p>The true challenge comes from instantaneous events, such as the forces resulting from a user colliding with an object. Haptic turk addresses this challenge with two approaches. We use this approach for all player actions where precision matters, either because they result in a high force or because that are performed by multiple actuators in synchrony.</p><p>The ejection seat button in the racecar of our racing game, for example, uses a three-second countdown before it fires.</p><p>The countdown not only adds drama to the game, but, more importantly allows haptic turk to give actuators advance warning. This is essential, as it allows actuators to throw the player up in the air in synchrony.</p><p>Only certain game events can plausibly be fitted with a countdown. For other events, such as those resulting from physical collisions, haptic turk creates timely responses through "anticipation".</p><p>#2: Anticipate collisions. Rather than waiting for the collision to happen, haptic turk continuously checks for the possibility of an upcoming collision. Whenever, a collision is likely, haptic turk displays a possible bump event, allowing actuators to get ready. We call this haptic turk's "presponse" mechanism. Haptic turk probes the space the user is likely to reach in the next seconds using probe lines (Figure <ref type="figure" target="#fig_13">13</ref>, inspired by imaginary reality games <ref type="bibr" target="#b1">[2]</ref>). In team flight, for example, we send probe lines forward, as this is the only direction the glider can go. Each probe line is as long as the player can travel in the 7 seconds that actuator displays project into the future. At every frame, haptic turk counts how many probe lines predict a collision. If a collision seems likely (&gt;30%) haptic turk injects a motion event into the actuator displays (Figure <ref type="figure" target="#fig_14">14a</ref>). It renders the motion instruction's opacity so as to reflect the probability of the event, so 70% opacity represents a 70% probability. Haptic turk then continuously updates the actuator display. player steers into the obstacle or they may slow down if the player turns to hit the obstacle more tangentially. At the same time, the expected collision probability and thus the opacity of the motion instructions will vary. If the probability ever drops below a threshold (&lt;15%), haptic turk removes the bump instruction-a "false alarm".</p><p>To enable probe lines, all the in-game objects have their own "colliders" and corresponding motion instruction. The tornado in the hang gliding game, for example, has a cylindrical collider. Probing it triggers the -1/+2 up/down bars shown earlier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ONE PLATFORM, MANY CONFIGURATIONS</head><p>The haptic turk software is a general-purpose platform for creating motion experiences based on people. In the examples shown above, we used one particular hardware setup based on mobile devices, one for each actuator. This installation was designed with ubiquitous use in mind in that it only requires devices that users are likely to carry with themselves at all times. In the following, we show other hardware configurations we have explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Display/sensing configurations</head><p>Figure <ref type="figure" target="#fig_15">15a</ref> shows another mobile set-up. It reduces hardware requirements further by running on two iPads-one for the player and a single shared iPad for the actuators. Figure <ref type="figure" target="#fig_15">15b</ref> shows one of our walk-up installations designed for use at tradeshows, museum exhibits, and art shows. Walk-up installations do not require participants to bring anything and we designed them to minimize per-player setup time. The shown version integrates player display and actuator display and projects onto the floor. This version allows players to control the game using a simulated delta, which we implemented by attaching an iPod to a bar. We also combined our walk-up installation with a headmounted display (Oculus Rift, http://oculusvr.com) as shown in Figure <ref type="figure" target="#fig_16">16</ref>. It allows users to look around in the virtual environment. As the head mounted display is closing out reality, it delivers a higher level of immersion than any of the other installations. We deployed this version at Burning Man 2013 (see section "Deployment", Figure <ref type="figure" target="#fig_27">25</ref>). Finally, we may record haptic turk experiences and share them as "haptic turk movies". People downloading the movie may then render the experience on any installation they have access to. While this could be done by using any video format that allows for timed annotations (e.g., mpeg 7), we feel that the most effective format is to overlay the actuator instructions directly onto the video stream (as in Figure <ref type="figure" target="#fig_15">15b</ref>). This allows us to share on any medium that transports video, including web pages, file sharing services, and YouTube.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mechanical configurations</head><p>All designs shown so far use four actuators to keep the player suspended. We initially had actuators hold the player directly (Figure <ref type="figure" target="#fig_22">20</ref>), but then added the slingshots shown in Figure <ref type="figure" target="#fig_17">17</ref> to reduce actuator fatigue, increase player safety, and to soften potential proxemics issues. The shown design we made from the seat cushions of foldable chairs (Folding stool Stockholm II by Lectus), curtain bars, and linen ribbon.</p><p>Slingshots can be rolled up to carry.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Actuator interfaces</head><p>The actuator interface presented earlier in the "walkthrough" section was the result of a series of iterations. Figure <ref type="figure" target="#fig_20">19</ref> shows two earlier designs for context. Our initial "level and arrows" design (Figure <ref type="figure" target="#fig_20">19a</ref>) caused split attention, but most of all it caused ergonomic issues: Since this display style only indicated the desired player tilt, but no absolute height, actuators tended to spend most of their time in non-neutral postures, resulting in substantial fatigue.</p><p>We consequently switched to a model that instructed actuators using a notion of absolute height (Figure <ref type="figure" target="#fig_20">19b</ref>). The 2x2 layout also showed the actuator instructions of up to four actuators, allowing actuators to better synchronize. The interface, however, was limited in that it provided actuators with too little preview of upcoming events, which is a truly essential requirement for actuator displays. We addressed this by lining up the four timelines at the top of the display and unifying all instructions to fit the timeline format-which brought us to the version shown throughout this paper (Figure <ref type="figure" target="#fig_20">19c</ref>). It performed very well throughout studies and deployment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONTRIBUTION &amp; BENEFITS</head><p>The main contribution of this paper is a new mechanism for creating a motion platform-based on humans. We present user interfaces and a system of motion instructions, three display and four mechanical configurations, interactive experiences, and two approaches to address lag. The main benefit of our approach is ubiquitous availability.</p><p>(1) Instantaneous: Since the underlying units-people-are incredibly flexible, users may obtain new experiences simply by downloading them from a network "into the actuators". This means that the actuators that formed a hang glider a second ago may now serve as a car or battle robot. This way, haptic turk reduces the sharing of motion experiences to the sharing of data files. (2) Available: Haptic turk runs on equipment that is orders of magnitude cheaper and more space-efficient than the technical equipment it emulates. In particular, the mobile versions of haptic turk could potentially reach millions of users by leveraging the existing install base of mobile devices. (3) Everywhere: We have deployed haptic turk not only in the lab and the student cafeteria but also at a desert festival, i.e., a hostile environment that would make it hard to deploy an actual motion platform. A single person was able to bring the equipment on the plane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LIMITATIONS</head><p>Limitations of our approach include that it requires multiple people, is tiring, and that human actuators cannot rival a computerized motion platform in terms of responsiveness and reliability. In particular, a real time unpredictable event is difficult to handle in our current system. For example, if players controlling a racing game swerve and hit a wall, this hit is difficult to predict. This makes the event difficult to haptically render by our system, as it does not leave enough time to properly prepare actuators for their action. Haptic turk runs in to similar issues if multiple events become possible at a given moment.</p><p>In addition, there are all the risks that come with motion equipment in the first place, such as motion sickness and the risk of injury. The approach may also raise proxemics considerations, the extent of which should be expected to vary across cultures. We address some of these issues with the design of slingshots that reduce actuator fatigue, increase player safety, and soften proxemics issues, but these are certainly only a partial solution.</p><p>In exchange to the proxemics issues, haptic turk delivers not only force feedback, but also a human-to-human experience that lets people interact in a new way. While we initially expected that competing to win the rhythm game would be the main incentive for actuators, the physical activity itself and, in particular, the social nature of the setup turned out to be the main driving force that made people participate in studies and experimental deployment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK</head><p>The work presented in this paper is related to interaction concepts, such as Wizard of Oz as well as motion platforms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Wizard of Oz and Crowdsourcing</head><p>Haptic Turk shares some characteristics with Wizard of Oz systems, such as the aforementioned Turk <ref type="bibr" target="#b17">[18]</ref>. Researchers use the wizard of oz method to speed up prototyping <ref type="bibr" target="#b5">[6]</ref> and to give users new experiences <ref type="bibr" target="#b6">[7]</ref>. Haptic Turk is different from crowdsourcing, such as Amazon's Mechanical Turk (www.mturk.com/mturk), which focus on recruiting workers. However, haptic turk could use crowdsourcing platform such as TaskRabbit (www.taskrabbit.com), CommunitySourcing <ref type="bibr" target="#b12">[13]</ref> and Friendsourcing <ref type="bibr" target="#b2">[3]</ref> to help recruit actuators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Motion Platforms, Exoskeletons &amp; Mobile Haptics</head><p>A wide variety of force feedback devices have been used to enhance the realism of virtual reality interactions including virtual object manipulation and motion simulation <ref type="bibr" target="#b17">[18]</ref>.</p><p>Motion simulators simulate motion by shaking, lifting or tilting players or groups of player sitting or standing on them. They are intensively used in driving and flight simulation for both training and entertainment purposes <ref type="bibr" target="#b21">[22]</ref>.</p><p>Most of them are based on a Stewart platform <ref type="bibr" target="#b26">[27]</ref>, which has six degrees of freedom driven by six hydraulic cylinders as actuators.</p><p>HapSeat <ref type="bibr" target="#b4">[5]</ref> achieves motion simulation with lower cost and a more compact form factor by actuating the user's head and hands. The fact that users perceive motion mainly using their visual, auditory, vestibular, and kinesthetic systems <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10]</ref> allows this project to limit actuation to armand headrests.</p><p>Researchers also showed that vibrotactile feedback may generate the illusion of self-motion <ref type="bibr" target="#b24">[25]</ref>. Tactile Brush <ref type="bibr" target="#b13">[14]</ref> uses this haptic illusion and renders vibrotactile strokes on the user's back using a grid of actuators in the chair.</p><p>Exoskeletons are wearable machines not only for amplifying users' motion but also providing force feedback. There are different kinds of exoskeletons, such as <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19]</ref> that use different actuators (pneumatic, hydraulic and strings) to help users perform six or more degrees of freedom tasks either in the real or the virtual world. They can provide large forces, but are also heavy and large because of their actuators and mechanical parts. FlexTorque <ref type="bibr" target="#b28">[29]</ref> offers an exoskeleton in a portable form factor; it provides force feedback to the arm of a user playing shooting games.</p><p>Mobile Haptics Lopes et al. <ref type="bibr" target="#b20">[21]</ref> proposed a mobile force feedback device, which relies on electrical muscle stimulation to actuate the user's opposing muscles to counter the current input motion. GyroTab <ref type="bibr" target="#b0">[1]</ref> produces torque in a mobile form factor based on a gyroscopic effect. Yano et al. <ref type="bibr" target="#b29">[30]</ref> proposed a handheld haptic device that uses a laser range finder to control a linear servomotor that touches users fingertips so that users can touch the object remotely. Han et al. <ref type="bibr" target="#b8">[9]</ref> proposed a handheld haptic device that integrates a linear servomotor and a solenoid-magnet pair located under a membrane to simulate huge and subtle kinesthetic feedback when the finger touches the membrane. Another mobile haptic device is POKE <ref type="bibr" target="#b22">[23]</ref>, which uses an air pump and silicon membranes on the front side to poke the caller's face remotely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IMPLEMENTATION</head><p>We implemented the haptic turk platform and the experiences (hang glider and racing) in C# and JavaScript on the Unity3D engine (http://unity3d.com). We then deploy to notebook computers (we used Mac OSX, but can also deploy to Windows and Linux) and mobile devices (we used iOS, but can also deploy to Android). By switching to the professional version of Unity3D, we obtained the ability to deploy to the oculus rift. The actuators' mobile devices sample their accelerometers and gyros 60 times a second and assess actuators' performance by comparing these readers with the received motion instructions in terms on tilt, roll, and acceleration. Haptic turk connects devices using WiFi. Informal testing showed a mean latency of 32ms, which is faster than the earlier discussed 50ms delays that humans tolerate in a haptic response. Haptic turk achieves this with off-the-shelf components, so we found no need for more sophisticated network synchronizations methods such as Delay Measurement Time Synchronization <ref type="bibr" target="#b23">[24]</ref>.</p><p>To run an experience, one person starts the haptic turk app as "host", which makes this person the "player" for the first round (Figure <ref type="figure" target="#fig_22">20a</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LAB STUDY</head><p>To validate our approach, we conducted a user study. Our main objective was to verify that the haptic experience does indeed produce an enjoyable experience-for players and for actuators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experience</head><p>In teams of six (player, four motion actuators, one special effects actuator) participants played the team flight hang glider experience, parts of which we presented in the walkthrough section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interface</head><p>We ran the team flight experience on the walk-up virtual reality setup of haptic turk already shown in Figure <ref type="figure" target="#fig_16">16</ref>, i.e., players experienced the world through a head mounted display (an Oculus Rift). Actuators saw their instruction on the computer screen in front of the player.</p><p>To assure that all participants enjoyed the same experience, we set the hang glider experience to autopilot. This limited player's interaction abilities to looking around using the oculus rift, but assured that all participants encountered the same events. It also allowed us to always complete the experience in a fixed amount of time (3min), thereby creating a controlled experience also for the actuators. Session: Whole Body Sensing and Interaction CHI 2014, One of a CHInd, Toronto, ON, Canada</p><p>Similarly, there was no actuator/actuator team scoring, so that the only reward for actuators was the opportunity to affect the player, plus the experience itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>We brought in participants in groups of 2, 3, or 4 and filled in experimenters so as to reach the 5 people required to play (plus we provided one experimenter for the water special effects). We then played one round of the team flight experience for each participant, so that each participant had the opportunity to be player exactly once.</p><p>With each new group, we provided two minutes of training during which we explained the handling of the slingshots, the actuator display and how high to lift the player for the four types of up/down bars, which track each actuator was expected to follow, and how to wear the oculus rift.</p><p>Participants played once as a player and 1-3 times as a actuator, according to their group size. Within these constraints, player/actuator order was counterbalanced. After all participants of a group were done playing and turking, all participants filled in questionnaires about their experience. We then released the group of participants and brought in the next group. Running a group of 2-4 participants took 10 to 15 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>We recruited 14 participants (4 females) from our university. Their age ranged from 20 to 28 years (mean 23.6), BMI from 19-25 (mean 22.3). We recruited participants in groups of 2-4, i.e., participants were familiar with some of their actuators/co-actuators, but never all of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 22 summarizes our results.</head><p>As players, participants rated their experience on average as 6.1 (SD=0.7) on a 7-point Likert scale (1=unpleasant, 7=enjoyable)-so clearly as enjoyable. Overall, players preferred the large motion events. Five players stated that they liked the intense motion resulting from lifting, shaking and bumping. Another player stated that he particularly enjoyed whole-body movements, such as being lifted or being swung forward-more so than being tilted and rolled. Along the same lines, three participants stated that they did not enjoy the extensive landing period in which they were tilted down. One participant described tilting as uncomfortable.</p><p>Accordingly, when asked about the most impressive moment of their player experience, 11 participants picked the intense -1/+2 boost caused by the tornado. One player expressed that "the changes in altitude were amazing and immersive". Another player explained that he enjoyed the moment when he bumped into the blimp. Players rated that the actuators "were pushing me at the wrong/right time" as 5.4 (SD=0.8), i.e., they were satisfied with the actuators' timing.</p><p>As actuators, participants rated the experience as actuator as less enjoyable than as players, yet still on the "enjoyable" side (M=4.4, SD=1.2). Very obviously, the actuators' experience was strongly driven by their perception of players' experience. Actuators felt that their performance contributed to player's experience (M=5.4, SD=1.3) (the "contribution" bar in Figure <ref type="figure" target="#fig_24">22</ref>). Our observations match this. Five actuators said that they enjoyed seeing their players scream and giggle. One actuator said "it's fun to play this with your friends and see their reactions as they fly." And one simply stated "it's fun to watch." One participant would have enjoyed an even better view of what the player is experiencing. While we thought of the special effects role as being less exciting, one actuator said he would have also liked to take on that role. The most likely reason for the lower score on enjoyment was fatigue. Seven actuators mentioned fatigue. One actuator mentioned that fatigue kicks in after two rounds of turking. Another actuator said "The person we moved was too heavy for me and I was smaller than the other players so my arms end at a lower height." Two actuators mentioned that lifting the player to level +2 repeatedly had caused fatigue.</p><p>To learn more about proxemics, we asked participants who they would play team flight with. They indicated that they would play with friends (14/14) and family (10/14), but only 1/14 felt it was appropriate to play with the public.</p><p>Given that this study had forced participants to play with a group of mostly strangers, this suggests that subjective satisfaction may improve further if experienced in a closer circle of friends and family. One participant explicitly said that she would enjoy playing haptic turk with her kids.</p><p>The human-human nature of haptic turk polarized participants. While 7/14 participants responded that they would have preferred an experience administered by a mechanical motion platform, 5/14 stated that they preferred being actuated by humans (Figure <ref type="figure" target="#fig_25">23</ref>). This suggests that these participants found an enjoyable quality in the human element. This is interesting, especially given that the actuators were assigned to them for the purpose of the experiment and not the friends or family that participants would have liked to play with.</p><p>In summary, our simple study provides some initial validation for the haptic turk concept. Most importantly, participants very much enjoyed the player experience. The actuator experience, while still enjoyable, could be improved by longer breaks and by giving the choice of who to play with.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EXPERIMENTAL DEPLOYMENT</head><p>Encouraged by the results of the study, we decided to try an experimental deployment of haptic turk and the team flight experience at an art festival in the Nevada desert (burning man, http://burningman.com). Our goal was to learn more about the social dynamics of haptic turk-outside the lab. We again opted for the walk-up VR haptic-turk set-up previously shown in Figure <ref type="figure" target="#fig_16">16</ref>. As shown in Figure <ref type="figure" target="#fig_26">24</ref>, we adapted the set-up to the hostile desert environment by placing the projector in a box equipped with air filters, etc. The entire installation (minus the generator, which we acquired on site) was transported, set up, and run by one of the authors, emphasizing haptic turk's potential to deliver motion experiences anytime anywhere. We ran the installation only at night. While players wore the oculus rift, the projector projected a copy of the rift display with overlaid actuator display onto the desert ground, which served as actuator display (Figure <ref type="figure" target="#fig_27">25</ref>). As before, we ran the team flight experience in autopilot and without additional incentives for actuators. On three nights, we ran about 100 attendees. Player weights ranged from an estimated 100 pounds to a self-declared 200 pounds. While the venue did not afford running questionnaires, we observed attendees and videotaped four of the runs for further analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Players recruited actuators</head><p>Unlike a lab study, our set-up had to begin by attracting its own audience. Every run unfolded as follows. An attendee or a small group of 2-3 attendees would walk by and in-spect the installation. There was no particular attract mode, but the projection showed the game running. Whenever an attendee was interested in playing, they would convince their friends to turk for them. Groups, however, were small-never large enough to play. We then encouraged attendees to recruit strangers as additional actuators. This typically took them a minute or two ("can you help us play a video game?") and was simplified by the friendly atmosphere of the event. While most attendees recruited to be able to play, several attendees "gifted" the experience to a friend-oftentimes their boy/girlfriend-i.e., they recruited actuators, but then stepped back and let their friend take on the role as player while they actuated. Given the constant competition for visual attention at the festival, it was essential for us to get started as quickly as possible. To get started in about a minute, we assigned actuator positions, helped actuators into the slingshots, and taught them about how high to raise lower at the individual up/down bars. We then filled in one actuator position ourselves, which allowed us to start right away and instead coach the other actuators as the experience was unfolding. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Observations</head><p>As during the study, the large motion events were favorites for players and actuators and led to audible expressions of joy. Upon "landing", several players were visible taken by the immersion of the experience and typically required a few seconds to find their way back to reality. Among actuators, the most popular scenes were again the large motion events, but also the rocky ride sequence in generator projector in,filter,box speakers notebook computer head7mounted display which actuators had the opportunity to shake up the player a bit. One player reported motion sickness. None of the actuators mentioned fatigue this time. The reason could be that, unlike our study, most attendees actuated only once, very few of them twice. This suggests that the fatigue threshold for this particular 4-person setup is around 3-5 min for this particular young athletic audience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>We have presented haptic turk, an approach to having motion experience everywhere. With haptic turk, we tackle this challenge orders of magnitude cheaper, more space efficient, and faster-to-deploy than the technical equipment it is inspired by. By leveraging the existing install base of mobile devices, haptic turk has the potential to reach hundreds of millions of users. As a side effect, haptic turk produces an interesting new social experience.</p><p>future work, we plan on using haptic turk to apply force feedback to players' hands and to use haptic turk for virtual reality, rehabilitation, and for rapid prototyping haptic machinery. We also plan on exploring how to give actuators a more active role, e.g., by allowing them to slip into the role of game world characters and to control game events.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Haptic turk allows producing motion experiences anywhere anytime. Here, the suspended player is enjoying an immersive hang gliding game. The four actuators create just the right physical motion to fill in the player's experience.</figDesc><graphic coords="1,318.35,233.77,239.71,179.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The team flight hang glider experience has started:The actuator display is blank, actuators are relaxed.</figDesc><graphic coords="2,56.30,446.08,103.00,77.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: (a) The player is about to get caught by the draft of a fan "lift to +1" motion instructions appear, and (b) are executed as they reach the actuator's bullseyes. The shown up/down bars in the two right columns reach the bullseye exactly at the moment the player enters the draft of the fan. The up/down bars are labeled "1"; the two actuators right of the player therefore lift their side of the player to position "1", which is waist height. This causes the player to be rotated or "rolled" to the left, as the player's hang glider is pushed sideways by the fan. The two up/down bars have round heads, which demands actuators to move up abruptly, right at the moment the round head fills the round bullseye. Actuators continue to hold the player at +1 height, then return smoothly to the relaxed position, as demanded by the bars' diagonal tails.</figDesc><graphic coords="2,319.85,258.73,102.91,77.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Up/down bar representations for (a) drop, (b) face down tilt, (c) face up tilt, and (d) up-left tilt-roll.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>of a CHInd, Toronto, ON, Canada what to do, yet, with experience, allow them to see the big picture. Large movements &amp; anticipation: Figure 5 shows how haptic turk performs a large motion event.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Right before the player enters the tornado, haptic turk lets players anticipate the move by lowering the player.</figDesc><graphic coords="3,55.80,271.88,102.81,77.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: As the player collides with an object, here a blimp, actuators bump the player using their thighs</figDesc><graphic coords="3,55.80,528.10,102.91,77.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The fans cause an unsynchronized vertical shake</figDesc><graphic coords="3,319.85,63.67,102.89,77.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: This fan produces a strong wind that shoots the player off horizontally, rendered as horizontal motion Special effects:The concept of haptic turk is broader than just motion. Figure9shows two effects that we have explored, i.e., water and heat. They are administered by an additional "special effects" actuator.</figDesc><graphic coords="3,318.35,246.33,102.98,77.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: This special effects actuator (a) sprays water at the player as the player enters a waterfall and (b) uses a hair dryer to emulate a hot breeze, as the player crosses over into the desert terrain in Figure 8.</figDesc><graphic coords="3,319.85,585.75,102.87,77.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: To land the player, the front actuators whip up the player to +2, while the back two set down the player's feet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: More action-packed games, such as our car racing game contains faster sequences of motion instruction. (This experience is administered by 3 actuators, thus 3 timelines)</figDesc><graphic coords="4,56.30,113.69,102.91,77.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 :# 1 :</head><label>121</label><figDesc>Figure 12: Delaying a game event using a countdown: (a) In response to the player pressing the 'eject' button, (b) haptic turk renders up/down bar. (c) When the countdown runs down, the actuators eject the player-well prepared. #1: Countdown events. Haptic turk cannot speed actuators up, but it can slow reality down-by adding a countdown.We use this approach for all player actions where precision matters, either because they result in a high force or because that are performed by multiple actuators in synchrony.The ejection seat button in the racecar of our racing game, for example, uses a three-second countdown before it fires.</figDesc><graphic coords="4,54.30,503.33,115.61,86.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: (a) Haptic turk's debug view: the hang glider on the bottom right continuously sends out probe lines (~1000 on a MacBook Pro). Here some of them detect a blimp (shown in red). (b) As the player turns right to avoid the blimp, no more probe lines are reaching the blimp.</figDesc><graphic coords="4,318.35,305.48,114.12,57.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: (a) Haptic turk anticipates a collision with the curb and crates a bump event. (b) As the player turns, the bump event changes to reflect the new expected orientation of the bump. (c) If the car stays the course, the collision takes place. Otherwise, (d) the bump event dissolves.As the player navigates, the expected collision time tend to change. The motion instructions may thus speed up if the</figDesc><graphic coords="4,319.85,507.67,239.89,130.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 15 :</head><label>15</label><figDesc>Figure 15: (a) Haptic Turk running on two iPads (b) The walk-up installation, designed for museums etc., is designed to minimize per-user start-up time. This version integrates player and actuator display into a single projection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: This installation uses a head-mounted display for the player experience (and projection as actuator display).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: We made these custom slingshots to reduce actuator fatigues, increase player safety, and soften proxemics.</figDesc><graphic coords="5,319.85,386.63,239.45,81.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 18</head><label>18</label><figDesc>Figure18shows some of the alternative mechanical configurations we have explored. The shown designs (a, b, c) allow three experiences that require an upright player pose, such as car racing, (b, c, d) provide additional physical support to the player, thereby reducing actuator fatigue. They allow playing with fewer actuators and/or people with a wider range of physical abilities.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 18 :</head><label>18</label><figDesc>Figure 18: Haptic Turk configurations: (a) racing game based on two actuators, (b) chair and (c) swing allow for singleactuator use, and (d) in swimming pool.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 19 :</head><label>19</label><figDesc>Figure 19: Earlier versions of the actuator interface: (a) Initial version based on the metaphor of a two-dimensional level. Only for bumping events did we use the time-line metaphor. (b) This second helped us get actuators into the neutral position, thus improved actuator ergonomics. (c) The current actuator interface. The thick bullseye highlights the actuator's timeline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>(b) All other users join the session as actuators. (c) Haptic turk indicates each actuator where to stand with respect to the player. The actuators Velcro-strap their devices to the indicated part of the player's body.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 20 :</head><label>20</label><figDesc>Figure 20: Setting up a haptic turk session via WiFi: (a) player starts a session, (b) joining actuator are assigned a position on the player's body, (c) play.</figDesc><graphic coords="7,476.11,165.31,81.84,92.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 21 :</head><label>21</label><figDesc>Figure 21: One team of participants playing team flight</figDesc><graphic coords="7,319.85,572.31,115.59,115.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 22 :</head><label>22</label><figDesc>Figure 22: Players rated gameplay as 6.1, so clearly enjoyable. Also as actuators, participants enjoyed the experience. Error bars are +/-1 standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure 23 :</head><label>23</label><figDesc>Figure 23: Some participants preferred haptic turk, other would have preferred a mechanical motion platform. machine prefer human</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 24 :</head><label>24</label><figDesc>Figure 24: Our walk-up installation with head mounted display at the Burning Man art festival in the Nevada desert. A plastic box with fans protected the projector from desert dust.</figDesc><graphic coords="9,55.80,351.17,239.69,145.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Figure 25 :</head><label>25</label><figDesc>Figure 25: A player wearing the oculus rift. Our installation projected the actuator interface (overlaid onto the game world) onto the desert ground. This player weighed 200 pounds.</figDesc><graphic coords="9,319.85,329.48,239.84,112.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Figure 26 :</head><label>26</label><figDesc>Figure 26: A player entering a tornado.</figDesc><graphic coords="9,323.32,553.59,110.60,115.12" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We thank Caro Fetzer for her help modeling the team flight 3D world.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">GyroTab: a handheld device that provides reactive torque feedback</title>
		<author>
			<persName><forename type="first">A</forename><surname>Badshah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;12</title>
		<meeting>CHI &apos;12</meeting>
		<imprint>
			<biblScope unit="page" from="3153" to="3156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Imaginary Reality Gaming: Ball Games Without a Ball</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reinicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wittmers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Luehne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Knaust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Koehler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Holz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;13</title>
		<meeting>UIST &apos;13</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Personalization via Friendsourcing</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Czerwinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOCHI</title>
		<imprint>
			<biblScope unit="volume">08</biblScope>
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The Brain&apos;s Sense of Movement (Perspectives in Cognitive Neuroscience)</title>
		<author>
			<persName><forename type="first">A</forename><surname>Berthoz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Harvard University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Producing Motion Sensation with Multiple Force-feedback Devices Embedded in a Seat</title>
		<author>
			<persName><forename type="first">F</forename><surname>Danieau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fleureau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Guillotel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mollet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>LÃ©cuyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Christie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">!</forename><surname>Hapseat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VRST &apos;12</title>
		<meeting>VRST &apos;12</meeting>
		<imprint>
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Wizard of Oz Prototyping of Pen-based User Interfaces</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Saponas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shilman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Landay</surname></persName>
		</author>
		<author>
			<persName><surname>Sketchwizard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;07</title>
		<meeting>UIST &apos;07</meeting>
		<imprint>
			<biblScope unit="page" from="119" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Eliza Meets the Wizard-of-oz: Blending Machine and Human Control of Embodied Characters</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Dow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Macintyre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mateas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;10</title>
		<meeting>CHI &apos;10</meeting>
		<imprint>
			<biblScope unit="page" from="547" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Perception and cognition in immersive Virtual Reality</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gaggioli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Breining</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Emerging Communication: Studies on New Technologies and Practices in</title>
		<imprint>
			<biblScope unit="page" from="71" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Physical mobile interaction with kinesthetic feedback</title>
		<author>
			<persName><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. HAPTICS &apos;12</title>
		<meeting>HAPTICS &apos;12</meeting>
		<imprint>
			<biblScope unit="page" from="571" to="575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Simulating self motion I: cues for the perception of motion</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jenkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zikovitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Virtual Reality</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="75" to="85" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Control method of robot suit HAL working as operator&apos;s muscle using biological and dynamical information</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kawamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sankai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IROS &apos;05</title>
		<meeting>IROS &apos;05</meeting>
		<imprint>
			<biblScope unit="page" from="3063" to="3068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Crowdsourcing graphical perception: using mechanical turk to assess visualization design</title>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;10</title>
		<meeting>CHI &apos;10</meeting>
		<imprint>
			<biblScope unit="page" from="203" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CommunitySourcing: engaging local crowds to perform expert work via physical kiosks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Heimerl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gawalt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hartmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;12</title>
		<meeting>CHI &apos;12</meeting>
		<imprint>
			<biblScope unit="page" from="1539" to="1548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tactile Brush!: Drawing on Skin with a Tactile Grid Display</title>
		<author>
			<persName><forename type="first">A</forename><surname>Israr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Poupyrev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;11</title>
		<meeting>CHI &apos;11</meeting>
		<imprint>
			<date type="published" when="2019">2019-2028</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Modeling the effects of delayed haptic and visual feedback in a collaborative virtual environment</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Glencross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hubbold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOCHI</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Crowdsourcing user studies with Mechanical Turk</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kittur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;08</title>
		<meeting>CHI &apos;08</meeting>
		<imprint>
			<biblScope unit="page" from="453" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Kosinski</surname></persName>
		</author>
		<ptr target="http://biae.clemson.edu/bpc/bp/lab/110/reaction.htm" />
		<title level="m">A literature review on reaction time</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Recent Developments and Applications of Haptic Devices</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Laycock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Day</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="117" to="132" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Design of a force reflecting master arm and master hand using pneumatic actuators</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICRA &apos;98</title>
		<meeting>ICRA &apos;98</meeting>
		<imprint>
			<biblScope unit="page" from="2574" to="2579" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The Turk, Chess Automation</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Levitt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>McFarland &amp; Company, Incorporated Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Muscle-Propelled Force Feedback: Bringing Force Feedback to Mobile Devices</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;13</title>
		<meeting>CHI &apos;13</meeting>
		<imprint>
			<biblScope unit="page" from="2577" to="2580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<ptr target="http://www.nasa.gov/centers/ames/research/technology-onepagers/vms.html." />
		<title level="m">NASA Vertical Motion Simulator</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The roles of touch during phone conversations: long-distance couples&apos; use of POKE in their homes</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Beak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nam</forename></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;13</title>
		<meeting>CHI &apos;13</meeting>
		<imprint>
			<biblScope unit="page" from="1679" to="1688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Delay Measurement Time Synchronization for Wireless Sensor Networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ping</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Berkeley, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Towards Lean and Elegant Self-Motion Simulation in Virtual Reality</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Riecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulte-Pelkum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Caniard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Bulthoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE VR &apos;05</title>
		<meeting>IEEE VR &apos;05</meeting>
		<imprint>
			<biblScope unit="page" from="131" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Real-time human pose recognition in parts from a single depth image</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Finocchio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kipman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR &apos;11</title>
		<meeting>CVPR &apos;11</meeting>
		<imprint>
			<biblScope unit="page" from="1297" to="1304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Platform with Six Degrees of Freedom</title>
		<author>
			<persName><forename type="first">D</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Institution of Mechanical Engineers</title>
		<imprint>
			<biblScope unit="volume">180</biblScope>
			<biblScope unit="page" from="371" to="386" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Telban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cardullo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Telban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Cardullo</surname></persName>
		</author>
		<title level="m">Motion Cueing Algorithm Development: Initial Investigation and Redesign of the Algorithms</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">ExoInterfaces: novel exosceleton haptic interfaces for virtual reality, augmented sport and rehabilitation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tsetserukou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tachi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AH &apos;10</title>
		<meeting>AH &apos;10</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Haptic Interface for Perceiving Remote Object Using a Laser Range Finder</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Miyamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iwata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WHC &apos;09</title>
		<meeting>WHC &apos;09</meeting>
		<imprint>
			<biblScope unit="page" from="196" to="201" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
