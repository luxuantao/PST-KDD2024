<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Cross-Device Interaction Style for Mobiles and Surfaces</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dominik</forename><surname>Schmidt</surname></persName>
							<email>schmidtd@comp.lancs.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Communications</orgName>
								<orgName type="institution">Lancaster University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Julian</forename><surname>Seifert</surname></persName>
							<email>julian.seifert@uni-due.de</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">paluno</orgName>
								<orgName type="institution" key="instit2">University of Duisburg</orgName>
								<address>
									<settlement>Essen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Enrico</forename><surname>Rukzio</surname></persName>
							<email>enrico.rukzio@uni-due.de</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Communications</orgName>
								<orgName type="institution">Lancaster University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">paluno</orgName>
								<orgName type="institution" key="instit2">University of Duisburg</orgName>
								<address>
									<settlement>Essen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hans</forename><surname>Gellersen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Communications</orgName>
								<orgName type="institution">Lancaster University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Cross-Device Interaction Style for Mobiles and Surfaces</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2C240B6EFA886AAD7A1CB14365BA50D1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Interactive tabletops</term>
					<term>surface computing</term>
					<term>mobile phones</term>
					<term>personal devices</term>
					<term>interaction techniques H.5.2 Information Interfaces and Presentation: User Interfaces: Input devices and strategies</term>
					<term>Interaction Styles</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Natural forms of interaction have evolved for personal devices that we carry with us (mobiles) as well as for shared interactive displays around us (surfaces) but interaction across the two remains cumbersome in practice. We propose a novel crossdevice interaction style for mobiles and surfaces that uses the mobile for tangible input on the surface in a stylus-like fashion. Building on the direct manipulation that we can perform on either device, it facilitates fluid and seamless interaction spanning across device boundaries. We provide a characterization of the combined interaction style in terms of input, output, and contextual attributes, and demonstrate its versatility by implementation of a range of novel interaction techniques for mobile devices on interactive surfaces.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Mobiles and surfaces and their associated forms of interaction become ever more powerful and pervasive in our lives, but in their separate ways. By mobiles we mean small devices of a personal nature that we have with us for interaction; devices that are highly personalized, that store private data, and that are a proxy of ourselves in the digital world. By surfaces we mean larger displays that we walk up to for interaction, that let us interact with content at larger scale, that are more public and that afford sharing. In terms of interaction, rich and distinctive direct manipulation styles have evolved with either class: mobiles incorporate multimodal interfaces and can sense in 3D how they are being manipulated, and surfaces support multi-user and multi-touch interaction. However, in spite of the advances on either platform, it remains cumbersome in practice to interact across mobiles and surfaces.</p><p>Figure <ref type="figure">1</ref>. A natural style for cross-device interaction with mobiles and surfaces. The mobile is used like a stylus for direct selection on the surface. For example, users can pick up content from the surface by touching it with their phone.</p><p>There are compelling reasons for combined use of mobiles and surfaces, and for seamless interaction across the two. Mobiles are great for carrying data and media while surfaces offer better scale for interaction with content. Mobiles provide user control over personal data while surfaces make it easy to share. Surfaces can be used by multiple users in the same way while mobiles can be used in highly personalized ways.</p><p>These are not new insights. Ever since the advent of mobiles, researchers have investigated topics such as coupling with surfaces for larger display <ref type="bibr" target="#b29">[30]</ref>, sharing of personal data on surfaces for collaboration <ref type="bibr" target="#b10">[11]</ref>, direct manipulation techniques for data transfer <ref type="bibr" target="#b28">[29]</ref>, remote interaction with larger surfaces <ref type="bibr" target="#b21">[22]</ref>, and private input, output and authentication around public devices <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b5">6]</ref>. For any of these concerns, numerous techniques have been demonstrated. Data transfer, for instance, has been shown in terms of hyperdragging in augmented environments <ref type="bibr" target="#b28">[29]</ref>, "squirting" onto target devices in wireless networks <ref type="bibr" target="#b17">[18]</ref>, touching of target areas using NFC <ref type="bibr" target="#b13">[14]</ref>, tangible placement of mobiles on horizontal surfaces <ref type="bibr" target="#b36">[37]</ref>, as well as other ways. However, no single interaction style has emerged that would underpin mobile-surface-interaction more generically.</p><p>In this work we investigate a novel cross-device interaction style that we envision to be a generic platform for synergistic interaction with mobiles and surfaces across a variety of tasks and applications (Figure <ref type="figure">1</ref>). The essence of this style is that the mobile device is used for selection of targets on a surface by direct touch, creating touch events that are associated with a position on the surface and the identity of the mobile. We build on the recently introduced PhoneTouch technique which demonstrated that this style can be implemented on multi-touch surfaces concurrently with finger touch sensing, by combining touch sensing embedded in the mobile with touch detection on the surface <ref type="bibr" target="#b31">[32]</ref>.</p><p>We investigate our vision of a generic interaction style for mobiles and surfaces in three steps. Our first step is to characterize DIS 2012 • In the Wild June 11-15, 2012 • Newcastle, UK the interactions that are enabled by fusing mobile and surface. We identify the fundamental input, output, and contextual attributes that define the building blocks for mobile-surface interaction techniques. The second step is to demonstrate our vision by implementation of a range of interactions. We do this in the concrete setting of smartphone use on an interactive tabletop, building on top of the PhoneTouch method for sensing mobile touch events. For the purposes of our main argument, we show that our interaction style is generic and capable of underpinning a versatile range of interaction goals. At the same time we show that the way in which we facilitate integration of mobiles is effective in addressing practical challenges in surface interaction, by introducing novel techniques for data transfer, personalization, user interface composition, authentication, localized and private feedback, and input expressiveness. Our third step is to illustrate our interaction style in a number of applications we have built, to demonstrate the flow and fluidity of interaction across mobile and surface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK</head><p>How mobile devices and larger display surfaces can be used in complementary ways has been explored widely, in early visions <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b28">29]</ref>, work on combining PDAs with single display groupware <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b21">22]</ref> and recent interest in the use of phones with interactive surfaces <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b31">32]</ref>. Work has frequently been driven by specific application agendas, such as working across personal and shared contexts <ref type="bibr" target="#b10">[11]</ref>, whereas our concern is to generally support symbiotic use of small personal devices and large displays <ref type="bibr" target="#b25">[26]</ref>.</p><p>Many of the techniques that have been developed are for interaction at a distance and do not involve direct contact between mobile and surface. This includes indirect manipulation techniques, such as data synchronization through a standard user interface <ref type="bibr" target="#b10">[11]</ref>, remote cursor control by stylus input on a handheld <ref type="bibr" target="#b21">[22]</ref>, and mouse-like cursor control by relative motion of a mobile phone <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b2">3]</ref>. Other techniques permit direct manipulation at a distance by pointing of a mobile with respect to the surface. This was first demonstrated with a PDA-mounted laser for direct pointing at a remote display, coupled with fine-grained interactions that then take place on the handheld screen, using a linked representation <ref type="bibr" target="#b22">[23]</ref>. Recent work has leveraged built-in cameras, including Point &amp; Shoot using camera-phones as view finders for remote selection on large displays <ref type="bibr" target="#b2">[3]</ref>, and related work by Pears et al. adding direct interaction on the phone's touch screen <ref type="bibr" target="#b24">[25]</ref>, and Touch projector with and additionally enables multi-touch interactions <ref type="bibr" target="#b3">[4]</ref>.</p><p>A range of recent works have contributed techniques that are based on contact between mobiles and surfaces, enabling initial device association in a physically grounded manner <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b31">32]</ref>. Many of these techniques have been developed specifically for horizontal surfaces (tabletops), and involve placement of the mobile on the surface for the entire duration of the interaction <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b14">15]</ref>). In the case of BlueTable the placement is used to initiate data transfer from mobile phones: as soon as a phone is placed on a surface, it transfers content (photos) for exploration onto the surface <ref type="bibr" target="#b36">[37]</ref>. Microsoft Surface Mobile Connect is a related commercial system to share photos and other media <ref type="bibr" target="#b18">[19]</ref>. In other work, mobiles are used more dynamically on the surface. Amnesia's Razorfish Connect [1],</p><p>for instance, allows users to freely move iPhones or iPads on a multi-touch tabletop as magic lenses or focus plus context screens <ref type="bibr" target="#b23">[24]</ref>.</p><p>The interaction style we propose builds on PhoneTouch, a 'lighter' touch technique for mobiles on surfaces, where the mobile is not placed on the surface but used like a stylus <ref type="bibr" target="#b31">[32]</ref>.</p><p>While adopting stylus-like interaction, PhoneTouch is fundamentally different from pen-based techniques (such as Pickand-Drop <ref type="bibr" target="#b26">[27]</ref>) as the primary concern is to leverage the mobile for symbiotic use with the surface. In related work, mobile phones were used for touch interaction with NFC-tagged displays, however with a coarser-grained touch resolution due to the tag size (4x4cm) <ref type="bibr" target="#b13">[14]</ref>. Other work has employed similar touch techniques but not focused on interaction <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INPUT &amp; OUTPUT SPACE</head><p>We first consider the input and output attributes that characterize the proposed mobile-surface interaction style. The sequence in which we present the attributes does not imply any dependence. Each attribute stands by itself, and attributes can be combined in a variety of ways, as we will illustrate in subsequent sections (see Table <ref type="table">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source, Type Input Attribute</head><p>Mobile, fixed value</p><formula xml:id="formula_0">ID 3 ID 1 ID 2</formula><p>Identifier The mobile's identifier allows different mobiles to be distinguished. Therefore, each mobile touch can be associated to a corresponding mobile that is its source. Note that the identifier is fixed for a particular device.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Surface, 2D position</head><p>Location The touch location is detected at the same granularity and within the same input space as finger touches. Note that finger and mobile touches are distinguished.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mobile, 3D rotation</head><p>Orientation The mobile's orientation determines the device part that is in contact with the surface (e.g., allowing different functions to be bound to each corner of the mobile). In addition, orientation can provide a stream of continuous input through rotation of the mobile around its axis while it touches the surface.</p><p>Table <ref type="table">1</ref>. Basic input attributes associated with the touch of a mobile device on a surface.</p><p>The user action at the heart of the proposed interaction style is a touch performed with a mobile on a surface. Table <ref type="table">1</ref> describes the basic input attributes associated with this action: the identity of the mobile device, the location of the touch point on the surface, and the relative orientation of the mobile device during the touch. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mobile</head><p>Selection Users may explicitly select options to parameterize a touch. For example, they might first choose a command (e.g., "delete") from a UI shown on the mobile, and then touch targets on the surface to apply it. Likewise, they could specify photos to transfer from mobile to surface. Input on the mobile during a touch could also trigger events to realize additional input states, similar to mouse clicks <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Surface</head><p>Multi-touch On the surface, a natural relationship between the touch with a mobile and finger touches from the user's other hand is established based on proximity. This can be used for bimanual interactions. In particular, finger touches close to a mobile device touch point can be associated to the mobile and by extension to its user.   The output space for our interaction style is made up of the surface area under the touch, and output on the mobile. In contrast to feedback on the surface, output produced on the mobile can provide localized or private feedback. Visual, haptic, or audio responses may be given in the context of a touch by using output components commonly available on mobile devices, such as displays, vibrators, or speakers (Figure <ref type="figure" target="#fig_1">2</ref>). For example, audio feedback can be localized using the mobile's speaker, or private using a connected headset. Vibration can be used for unobtrusive feedback or alerts, and visual feedback on the phone mobile might be to provide tooltips or personalized information related to a touch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CROSS-DEVICE INTERACTION TECHNIQUES</head><p>For demonstration of our vision of mobile-surface interaction we have developed a demonstration system for smartphone interaction on an interactive surface. The implementation is based on Windows Phone OS 7 (WP7) on the phone side and .NET / Windows Presentation Framework (WPF) for the surface, and we have used HTC Mozart smartphones and custom-built multi-touch surfaces for development of the interaction techniques that we introduce in this section, as well as for applications that we describe further below. The interactions we demonstrate are not dependent on this particular configuration, and we have for instance also used iPhones for demonstration of some of the cross-device techniques.</p><p>To detect and identify phone-touches, we use the synchronous PhoneTouch timing approach introduced by Schmidt et al. <ref type="bibr" target="#b31">[32]</ref>.</p><p>Both surface and phones sense touch events independently.</p><p>The surface uses a camera, and phones their internal microphone. All detected events are time stamped and communicated over a wireless link. Valid phone-touches are identified based on event correlation in time. Although collisions are unavoidable, Schmidt et al. showed that this approach is suitable for collocated collaboration in small groups.</p><p>Our development of cross-device interaction techniques was framed by six issues in the use multi-touch surfaces that we identified as challenges that can be addressed in novel ways by symbiotic use of phone and surface:</p><p>• Data Transfer. Phones store personal information that are a rich data source for surface applications, and surfaces are natural for viewing of personal media <ref type="bibr" target="#b36">[37]</ref>. Data transfer between phones and surface allows users to bring personal data to a larger display and facilitates sharing amongst users. • Personalization. As their user's proxy, phones can be used for personalization in shared interfaces to enable novel interactions that are otherwise not possible <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b33">34]</ref>. • User Interface Composition. Command menus and tool palettes present challenges with respect to orientation, reachability, and clutter <ref type="bibr" target="#b34">[35]</ref> which can addressed by moving such interface elements from the surface to a mobile. • Authentication. The inherently private process of authentication is a design challenge in shared interfaces <ref type="bibr" target="#b16">[17]</ref> that can be addressed by integrating personal devices. • Localized &amp; Private Feedback Individual feedback can be beneficial in collaboration around shared surfaces <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b12">13]</ref>, for which phones can provide suitable channels. • Input Expressiveness. Interactive surfaces enable natural input on a two-dimensional plane, but additional degrees of freedom can benefit certain tasks <ref type="bibr" target="#b1">[2]</ref>.</p><p>Table <ref type="table">3</ref> provides an overview of the ten techniques we have conceived, to address the above issues. For each technique it is shown how it leverages attributes of the input &amp; output space for mobile-surface interaction. All techniques exploit mobile device identity and touch point location as core feature, as well as selected other attributes. All techniques have been fully implemented with the exception of numbers 10 and 12, which represent more speculative ideas that we chose to only develop conceptually at this stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Transfer</head><p>Data transfer across devices is naturally desirable around shared surfaces, for users to be able to bring personal data into a shared context and to collect data for personal use. We contribute two techniques to support this in a fast and fluid manner: PhonePick&amp;Drop for transfer from phone to surface and vice versa and PhoneCopy&amp;Paste for temporary transfer onto the phone as personal clipboard. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! ! 2</head><p>PhoneCopy&amp;Paste employs phones as personal clipboards for surface applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! !</head><note type="other">Personalization 3</note><p>PhoneFill makes existing personal information from phones available on the surface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! ! 4</head><p>PhoneLenses provide flexible ad hoc personalization of any surface content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! !</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User Interface Composition 5</head><p>PhonePalettes move tool palettes and menus from surface to phone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! ! 6</head><p>PhoneFac ¸ades afford fluid interface customization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! !</head><p>Authentication</p><formula xml:id="formula_1">7</formula><p>PhoneKey enables fine-grained ad hoc authentication on the surface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! ! 8</head><p>PhonePass allows users entering passwords unobserved on their phone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! !</head><p>Localized &amp; Private Feedback</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9</head><p>PhoneSpeaker provides localized or private audio feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! !</head><p>10 PhoneZone † opens continuous private spaces spanning surface and phone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! ! ! !</head><p>Input Expressiveness 11 PhoneHandle allows for direct manipulation of scalar controls.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! !</head><p>12 PhoneGestures † enables motion-based gestural input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! !</head><p>Table <ref type="table">3</ref>. Interaction techniques, the issue that they address, and input or output attributes that they use.</p><p>Local output indicates that audio, haptic, visual, or any combination of these three is conceptually required. † PhoneZone and PhoneGestures have been developed conceptually; all other techniques have been fully implemented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">PhonePick&amp;Drop</head><p>This technique is for intuitive transfer of data objects from phone to surface and vice versa. To transfer objects from phone to surface (drop), the user makes a selection in private on the phone (Figure <ref type="figure" target="#fig_27">3(a)</ref>) and then touches the surface with the phone to initiate transfer and display at the selected location on the surface (Figure <ref type="figure" target="#fig_3">3(b)</ref>). To transfer objects from the surface to the phone (pick), the user directly selects objects on the surface by phone-touch to initiate their transfer (Figure <ref type="figure" target="#fig_3">3(c)</ref>). The technique inherits the simplicity of Rekimoto's Pick-and-Drop <ref type="bibr" target="#b26">[27]</ref> but is adapted for fast and intuitive data transfer between phone and surface. Users can in one step choose and transfer items to pick, and likewise select a target location and initiate a drop in one go.</p><p>PhonePick&amp;Drop is based on a blackboard metaphor for sharing. This affords users to asynchronously interchange information from their phones via the surface, and to inspect items on the surface before picking them up onto their personal devices. In this respect, the technique is related to other work on data transfer by placement of phones on a shared surface [1, <ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b36">37]</ref>. In contrast to those works, our technique provides fine-grained control over which items to reveal: users select data items in private on the phone before dropping them onto the shared display. We believe this is important, as phones are very private devices that users would not typically share. For example, while it is common that users show content on their phones to others, they typically do so without giving their phone out of their hands. 2 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PhoneCopy&amp;Paste</head><p>This technique extends surface interaction with phones as personal clipboard. It is based on the same user actions as above for selection of objects and target locations on the surface, however with a copy-and-paste semantic. Phone-Pick&amp;Drop was motivated for sharing of phone content, while PhoneCopy&amp;Paste is designed for manipulation of surface content, with phones serving as transient storage only. The enables multiple users to each have their individual clipboards, addressing the problem of correctly associating copy-andpaste actions in multi-user environments, and also affords visualization and efficient access to a history of copied items without consuming surface space.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Personalization</head><p>Personalized interactions can be beneficial to multi-user applications <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b33">34]</ref> but only few interactive surfaces support user identification directly (e.g., <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b32">33]</ref>). Integration with phones offers an alternative by taking a proxy-based approach.</p><p>Since each phone-touch is associated with a phone identifier, its user can be inferred. Phones also hold personal data of potential use for personalization of surface applications (e.g., user preferences). We introduce two techniques, PhoneFill and PhoneLenses, that leverage this potential. 3 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PhoneFill</head><p>Users commonly store a variety of personal collections on their phone, such as contacts, music playlists, and browser bookmarks. This information can also benefit surface applications. For example, browsing the web on the surface, users may want to access a site they have previously bookmarked on their personal device, but manual transfer of the URL to the surface browser is tedious. To address this, we have designed the PhoneFill technique, enabling users to make existing personal information instantly available on the surface. This is illustrated in Figure <ref type="figure" target="#fig_5">4</ref>: the surface object touched with the phone determines the context for PhoneFill. Based on this context, the phone identifies and provides relevant information to the surface application. In the shown example, the user phone-touches the browser's bookmark control (Figure <ref type="figure" target="#fig_5">4</ref>(a)). This triggers the phone to automatically retrieve and send its bookmark collection to the surface, where it becomes instantly available. Users can then choose from their personal bookmarks directly on the surface (Figure <ref type="figure" target="#fig_5">4</ref>(b)), even in collaborative scenarios where browser interaction may be shared between multiple users. In the same way, a phone can provide contact details to send email from a surface application, or automatically fill-in payment forms.  PhoneFill makes existing personal information from the phone available to surface applications. 4 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PhoneLenses</head><p>A phone-touch can act as a proxy for user identity, but is limited to a single point of contact. To extend user identification to multi-touch, we have integrated PhoneTouch with IdLenses, a concept for interaction through personalized lenses on a shared surface <ref type="bibr" target="#b33">[34]</ref>. A user can open a PhoneLens by performing a phone-touch anywhere within an enabled surface application. The lens then defines an area in which any finger touch input is associated with the phone's user. The lens moves along with the phone and disappears once the phone is lifted off the surface. The concept allows for any form of personalization of the surface content under the lens. Figure <ref type="figure" target="#fig_7">5</ref> shows an example from one of the applications we have built. A user explores  the map of a museum with a personal lens through which content is adapted to their language, based on user preferences automatically provided by the user's phone. In this way, a user can view content adapted to their needs, without disrupting other users viewing other parts of the shared display. Users can also provide input through the lens, for example marking a museum room on the shared map as a personal favorite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User Interface Composition</head><p>Placement of command menus and toolbars can be problematic on shared surfaces, as it can be difficult to make them easily accessible for different users in terms of physical reach and orientation <ref type="bibr" target="#b34">[35]</ref>. We propose two techniques that address this issue with user interface composition across surface and phones. PhonePalettes are for off-loading of tool palettes to the phone, and PhoneFac ¸ades support ad hoc customization of the interface. 5 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PhonePalettes</head><p>The principal idea is to move tool palettes from the surface onto the phone to be close to hand on whichever part of a larger surface the user is working. This is related to the concept of detached user interfaces, in which tools were moved off the main display and onto a handheld device, in analogy to a painter whose focus lies on the canvas while keeping tools handy on a palette <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b11">12]</ref>. However, PhonePalettes are different as the phone itself is used to select the target of a command on the surface. For demonstration of the technique, we have implemented a simplified graphics editor. In the example shown in Figure <ref type="figure" target="#fig_9">6</ref>, the user selects the "Circle" command on the phone (Figure <ref type="figure" target="#fig_27">6(a)</ref>) and then touches the surface to apply the command at the selected location (Figure <ref type="figure" target="#fig_9">6(b)</ref>). The same command can be applied repeatedly on the surface. The commands can also be parametrized through the phone's interface, for example to choose from different colors (Figure <ref type="figure" target="#fig_9">6(c)</ref>). It is possible to preselect multiple compatible commands to be executed simultaneously with the next phone-touch (e.g., fill and stroke color can be applied together). Frequently applied tool settings can also be stored on the phone as personal preferences.</p><p>Input sequences that require prior selection of a mode (e.g., selecting "bold" before text entry) are common in graphical user interfaces, but problematic on interactive surfaces that lack the ability to distinguish touches of different users <ref type="bibr" target="#b30">[31]</ref>. A related problem is visual feedback that indicates the selected mode <ref type="bibr" target="#b8">[9]</ref>. PhonePalettes solve this issue as commands are selected on the user's personal device, enabling multiple users  to work on a shared interface, each within their own mode. It is also possible to keep an audit trail based on the phone-touch identifier, and to provide per-user undo operations. 6 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PhoneFac ¸ades</head><p>Many tasks involve only a small set of an application's command set. The idea of PhoneFac ¸ades, inspired by User Interface Fac ¸ades <ref type="bibr" target="#b35">[36]</ref>, is to enable users to pick commands from the surface in order to assemble a customized interface on the phone. In the example shown in Figure <ref type="figure" target="#fig_11">7</ref>, the user picks the application's "Square" command by selecting it with a phone-touch (Figure <ref type="figure" target="#fig_27">7(a)</ref>). As a result, a representation of the command is automatically added to the phone (Figure <ref type="figure" target="#fig_11">7(b)</ref>). The command is now ready to be used as described above for PhonePalettes. As this shows, PhoneFac ¸ades involve only minimal overhead for interface customization. Users can pick up and arrange commands on their phone in an ad hoc fashion, to match their workflow. Multiple users can each assemble individually customized interfaces to use in a shared surface application.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Authentication</head><p>Authentication is an inherently private process that presents a distinct design challenge on shared surfaces. System-wide authentication is typically not appropriate due to the multi-user context, but interaction-based authentication can be desirable, for example if users have different roles with varying levels of authority. We contribute two new techniques for authentication, PhoneKey for locking and unlocking of restricted content, and PhonePass for remote and unobserved password entry. 7 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PhoneKey</head><p>PhoneKey is a technique for token-based authentication.</p><p>Metaphorically, the phone serves as a key to control access to items on the shared surface, for example interactive applications or restricted content. To demonstrate the PhoneKey technique, we implemented multiple personal workspaces on a shared surface. A user can lock their workspace to protect enclosed data by touching the lock button (Figure <ref type="figure" target="#fig_13">8</ref>(a)).</p><p>To regain access, the user unlocks the workspace with a phone-touch on the lock button (Figure <ref type="figure" target="#fig_13">8</ref>  PhoneKey facilitates lightweight and fine-grained access control. Any surface element that is accessible by finger touch is also accessible by phone-touch, and so can be protected using PhoneKey. The technique is generic and not bound to any particular underlying authentication mechanism. A unique device ID may be sufficient for some applications, but depending on required security, PhoneKey could also be combined with cryptographic key exchange between phone and surface.  Many existing applications, for example many web-based services, require users to enter a password to log in. This is problematic on shared services due to potential shouldersurfing attacks <ref type="bibr" target="#b16">[17]</ref>. PhonePass addresses this problem by enabling users to enter passwords via their phone. The user initiates this interaction by touching the password field with their phone (Figure <ref type="figure" target="#fig_15">9</ref>(a)). A corresponding control appears on the phone where the password can be entered unobserved (Figure <ref type="figure" target="#fig_18">9(b)</ref>). The only feedback on the surface is given in form of disguised characters, shown as asterisks. The phone could also store a collection of passwords in an internal vault. A phonetouch on a password field would then automatically retrieve and fill-in the matching password, similar to a PhoneFill interaction. In contrast to other proposed surface authentication approaches <ref type="bibr" target="#b16">[17]</ref>, PhonePass integrates readily with existing applications. Closely related is PocketPIN <ref type="bibr" target="#b5">[6]</ref>, but PhonePass affords a simpler method of associating phone and password field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Localized &amp; Private Feedback</head><p>Output on large displays and shared surfaces is public by default. However it has been argued that private feedback can be beneficial (e.g., individual audio channels have led to a more equitable task participation <ref type="bibr" target="#b20">[21]</ref>). We contribute two new feedback techniques: PhoneSpeaker provides a personal audio channel, and PhoneZone an output zone that is shielded from the view of other users.   This technique implements audio feedback for phone-touch events. Localized feedback is given through the phone's internal speaker, and private feedback when headphones are connected. For example, localized feedback of affirmative or negative sound has been shown to raise user awareness of input errors <ref type="bibr" target="#b12">[13]</ref>. Private audio feedback can be useful to access audio content on surfaces while avoiding interference among multiple users. In an example application that we have implemented, multiple users can browse a music collection on a shared surface and preview tracks individually by touching them with their phones (Figure <ref type="figure" target="#fig_17">10</ref>). 10 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PhoneZone</head><p>The idea of PhoneZone, developed as concept but not fully implemented, is to provide the user with a visual output area that is shielded from other users. As shown in Figure <ref type="figure" target="#fig_17">10(b)</ref>, the concept is for users to place their phone sideways on the surface in order to open a private space that combines display space on the phone with display space on the surface, "in the shadow of the phone". Like the horizontal hand gesture proposed by Wu et. al <ref type="bibr" target="#b37">[38]</ref>, the phone shields parts of the surface, thereby blocking it from other users' view. The combined display space of a PhoneZone could also be exploited for direct manipulations, such as sliding content off the phone down onto the surface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input Expressiveness</head><p>Input on interactive surfaces is inherently two-dimensional. We contribute two new techniques that exploit the phone as a device that we use for planar interaction on the surface but that offers additional degrees of freedom (in similar ways as the Rockin' Mouse <ref type="bibr" target="#b1">[2]</ref>). PhoneHandle uses device motion to manipulate scalar controls, and PhoneGestures enables discrete gestures performed with the phone. 11 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PhoneHandle</head><p>The idea of this technique is to manipulate scalar controls that are selected by a phone-touch on the surface. As the phone is held like a stylus with a contact point on the surface, it can be manipulated naturally in terms of varying pitch (forwardbackward tilt), yaw (left-right tilt), or roll (rotation around the z-axis). The range of device motions is constrained by the way a phone is held, and limitations of arm and wrist movement, but this can be accommodated in the design of the control. Figure <ref type="figure" target="#fig_27">11(a)</ref> shows an example of a slider control that we have implemented as PhoneHandle. The slider on the surface is selected by a phone-touch, and the user manipulates its value by tilting the phone forward and backward, using a rate control mapping. A second example, in Figure <ref type="figure" target="#fig_21">11</ref>   12 PhoneGestures</p><p>PhoneGestures are based on the same device motions used in PhoneHandle, but afford discrete gestures instead of direct motion-to-control mapping. We have not included PhoneGestures in our current implementation, but conceptually we foresee two types of gestures. The first type are counter-intuitive movements of a phone in extension of a phone-touch, as a safety catch to avoid accidental activation of critical functions. For example, in order to delete items on the surface permanently, a user could be required to not only select the delete button but to also perform a rotation of the phone while the button is selected. The interaction metaphor here is that of a launch key. Such a gesture can be designed to be unlikely to be performed accidentally but to be easily integrated into the touch interaction flow.</p><p>The second type of gesture we propose are metaphorical. For example, a phone-touch could be combined with screwdriver motion, for fastening or unfastening of an object on the surface. It could also be combined with a pumping motion, to lift or lower an object selected on the surface. This allows for additional forms of expression that may build on metaphors that are intuitive in particular application contexts, or that provide for playful interaction in games and entertainment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPLICATIONS</head><p>We have implemented a number of applications to further illustrate mobile-surface interaction. The applications make use of a variety of the interaction techniques and demonstrate them in realistic flows of interaction. They also highlight the fluidity of the interaction style in terms of seamlessly moving between interactions on the phone and on the surface.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Collage Designer</head><p>This is an application for multiple users to bring their photos to the surface, and to creatively arrange them into a combined collage, making use PhonePalettes in addition to the techniques demonstrated in the word game. Users can freely move, rotate, and scale photos with multi-touch, and they can use editing tools, for instance to choose from different picture frames, to add captions, or to delete photos. Editing options were integrated in two ways, on PhonePalettes as shown in Figure <ref type="figure" target="#fig_24">13</ref>, and alternatively via context menus on the surface. This provides users with choices in their workflow.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Music Store</head><p>The music store application allows users to browse through different albums using common multi-touch interaction on a shared surface (Figure <ref type="figure" target="#fig_26">14</ref>(a)). To preview a song we apply PhoneSpeaker, providing individual audio over headphones. In doing so, multiple users can listen to songs without disturbing each other. Users can directly buy songs by touching them with their phone, thus using the phone not only to transfer the music to, but also for authenticating the purchase (Figure <ref type="figure" target="#fig_26">14(b)</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Calendar</head><p>Personal calendars are a standard application on mobile phones. However, scheduling or sharing events amongst multiple co-located users is not readily supported, as each user has access to their own calendar only. We address this with a calendar sharing application that we built on our platform. The application lets users drop their personal calendar onto a surface by tapping the surface while the application is open on the phone (Figure <ref type="figure" target="#fig_28">15(a)</ref>). The calendar becomes shared in a privacy-sensitive way, initially only showing the blocked times but without event details. This allows users to jointly look for free slots. The owner of the calendar can also selectively unlock individual entries in the calendar using PhoneKey. This makes the event detail visible, and allows other users to copy the event to their own calendars, using PhonePick&amp;Drop (Figure <ref type="figure" target="#fig_28">15(b)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Exposure to Users</head><p>We recruited six graduate students (2 female, 4 male; aged 23 to 29) for trial sessions to expose the techniques we developed to use by others but ourselves. Five of them were smartphone users (4 iPhone, 1 Nexus One), one owned a Nokia phone without touch screen. The participants individually tried the ten techniques we had fully implemented, and were paired up for multi-user trial of the word game and the collage designer. Each trial session lasted about 30 minutes. We observed the participants' behavior and comments, and conducted informal post-study interviews about their opinions and suggestions.</p><p>Participants found the style of interaction natural. One participant suggested that users might be concerned about using expensive phones for input by impact on a surface, but none of the participants showed any hesitation in applying the phonetouch techniques. Of all techniques, PhonePass and PhoneFill appealed most to the participants as they address problems that users found familiar and important, beyond the setting of interactive tabletops that was used in the trial session.</p><p>In the multi-user part of the trial, users engaged quickly with the word game as its board game variant is well-known. Without having been prompted to do so, they intuitively used the phone as private screen, and naturally moved back and forth between interaction on the phone and on the surface. The collage designer presented a more artificial task but it prompted participants to comment on the distinct ease by which photos stored on the phone can be shared for joint viewing on a larger screen, a process that is clearly perceived as cumbersome with state of the art camera phones and digital cameras. The PhonePalette technique was learned without difficulties, but some participants had reservations about its value as the same options were accessible also via the surface. Yet several participants perceived PhonePalettes as a shortcut and possible solution to orientation problems of menus on tabletops.</p><p>Participant also made suggestions for improvement. In particular, they proposed to clearly indicate which surface functions can be accessed via phone versus finger touches. Further, several participants suggested that the phone could be used "like a finger for the other hand", indicating that the phone was seen as unobtrusive tool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION</head><p>The introduced interaction style is suitable for any settings in which users interact directly with touch-sensitive surfaces. Most of the shown examples were based around a tabletop, but the interaction style and introduced techniques can be equally applied on vertical surfaces. Some of the techniques could also be considered for interaction with other devices than interactive displays. For example, a user could drop a photo onto a printer, by phone-touching the printer's UI.</p><p>The concept is generic and versatile as demonstrated by the diversity of techniques and applications we have described above. As a direct manipulation style, the concept is well suited for interactions that take place in the context of specific elements or objects on an interactive surface, where finegrained selection is key. It lends itself to applications that involve a combination of interaction on mobiles and interaction on surfaces, where people need to easily switch between the devices. Touch input with a mobile as opposed to pen or finger is useful when additional features of the mobile are exploited; this may simply be the identifier, but can also be stored data or user-selected options in the mobile UI.</p><p>The interactions are consistently based on direct manipulation (on the phone, on the surface, and of the phone on the surface)</p><p>to promote a natural interface. However, users might find it less natural to use a mobile as a stylus, and they might be concerned about causing damage to either their mobile or the surface, as both represent expensive devices. In our user trial sessions this did not appear to be an issue, however participants were provided with devices and might have been concerned if they had been asked to use their own. The concern can be addressed with inexpensive bumpers or covers that are already widely used.</p><p>The implementation of our concept is based on a distributed sensing approach. Previous work has shown that the temporal correlation of impact sensing in the phone and touch recognition on the surface leads to robust detection <ref type="bibr" target="#b31">[32]</ref>. Device association with a touch can only be confused if it occurs in the same recognition frame (approx. 25ms). Depending on application, simultaneous touch might be ruled out (e.g., word game) or is not critical. In other cases it might be appropriate to integrate a recovery mechanism, such as undo, or to consider a different sensing approach that does not depend on temporal correlation only. For instance, both mobile and surface could measure impact and correlate impact patterns to discriminate simultaneous touch.</p><p>The interaction style is new but it does not require new or specialized hardware. On the mobile side, we used unmodified off-the-shelf components only in our implementation. On the surface side, we used a standard setup for vision-based multi-touch that did not require any hardware modification for our purposes. We would expect that detection of mobile device touch can also be integrated with alternative surface technologies, in inexpensive ways.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>The vision underlying this work was to support natural interaction across personal mobile devices, and larger interactive surfaces. Our contribution is an interaction style that fuses direct manipulation interactions of three kinds: interactions we perform on mobiles, multi-touch interactions on surfaces, and stylus-like use of mobiles on a surface. We have shown that this interaction style readily gives rise to a versatile range of interaction techniques and application concepts. Up to this point, we have covered a breadth of interaction techniques, rather than providing in-depth analysis. We believe, however, that additional work into this direction is clearly beneficial. Promising directions for future work also include using multiple surfaces at a time, integrating interactions into further application domains, and long-term deployments of our techniques in a real-world setting, to gain a deeper understanding of their use.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( a )</head><label>a</label><figDesc>Audio feedback can be localized or private (i.e., via headsets) (b) Haptic feedback may indicate slider ticks, for example. (c) Visual feedback is given without occupying surface space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Output on the phone provides localized or private feedback using multiple modalities.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( a )</head><label>a</label><figDesc>The user selects items to drop. (b) Dropping selected items by touch. (c) Picking up items by touch. (d) Transferred items on the phone.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. PhonePick&amp;Drop allows users to transfer data between phone and surface in both directions.</figDesc><graphic coords="4,321.53,583.10,117.97,88.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>( a )</head><label>a</label><figDesc>Touching a web browser. . . (b) . . . to transfer personal bookmarks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4.PhoneFill makes existing personal information from the phone available to surface applications.</figDesc><graphic coords="5,54.35,442.34,117.97,88.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>( a )</head><label>a</label><figDesc>Any finger touch through a lens is associated to the phone's user.(b) The surface area under a lens is personalized (e.g., translated).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. PhoneLenses can be invoked anywhere on the surface and move along with the phone.</figDesc><graphic coords="5,321.53,67.52,117.97,88.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>( a )</head><label>a</label><figDesc>Selecting tools and commands. . . (b) . . . which are applied by touch.(c) PhonePalettes also support parameterized commands.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. PhonePalettes move tool palettes and menus from surface to phone.</figDesc><graphic coords="6,53.81,176.06,243.19,91.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>( a )</head><label>a</label><figDesc>Picking up surface commands. (b) Customized command set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. PhoneFac ¸ades lets users assemble a set of commands picked from the surface.</figDesc><graphic coords="6,54.35,534.32,117.97,88.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>(b)). Authentication takes place implicitly, with the phone serving as the access token. Finger touches and other phones cannot unlock the workspace, but could for instance trigger display of an alert message.(a) Locking a workspace.(b) Access with an authorized phone.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. PhoneKey enables token-based authentication and finegrained access control.</figDesc><graphic coords="6,321.53,289.82,117.97,88.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>( a )</head><label>a</label><figDesc>The user touches a password field on the surface to select it. . . . (b) . . . and enters the password unobserved via the phone.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. PhonePass enables users to enter passwords unobserved on their phone. 8 PhonePass</figDesc><graphic coords="6,321.53,522.38,117.97,88.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>(a) Using PhoneSpeaker for private audio feedback. (b) PhoneZone creates a private space across phone and surface.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. Localized and private feedback.</figDesc><graphic coords="7,54.35,326.00,117.97,88.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>9</head><label>9</label><figDesc>PhoneSpeaker</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>(b)  shows rotation of a phone to control a knob displayed on the surface.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>( a )</head><label>a</label><figDesc>Slider control by tilting. (b) Knob control by rotation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. PhoneHandle allows users to directly manipulate scalar controls through device motion.</figDesc><graphic coords="7,321.53,366.74,117.97,88.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>(a) Users arrange words in private on their phone to then. . . (b) . . . drop them onto the shared word game board.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. Word game illustrates seamless integration of private and shared interactions.</figDesc><graphic coords="8,54.35,208.46,117.97,88.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 13 .</head><label>13</label><figDesc>Figure 13. The collage designer implements PhonePalettes, letting users apply various settings, such as changing a photo's frame.</figDesc><graphic coords="8,53.81,513.14,243.19,91.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>( a )</head><label>a</label><figDesc>Browsing music using multi-touch. (b) Using the phone to purchase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 14 .</head><label>14</label><figDesc>Figure 14. Music store lets users browse music manually and integrates a phone for transactions.</figDesc><graphic coords="8,321.53,121.46,117.91,66.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>( a )</head><label>a</label><figDesc>Dropping a calendar for sharing. (b) Unlocking event detail.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Figure 15 .</head><label>15</label><figDesc>Figure 15. Calendar lets users share their personal calendars with finegrained privacy control.</figDesc><graphic coords="8,321.53,346.16,117.91,66.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>captures additional input</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>DIS 2012 • In the Wild June 11-15, 2012 • Newcastle, UK</head><label></label><figDesc></figDesc><table><row><cell>Source</cell><cell>Input Attribute</cell></row><row><cell>Mobile</cell><cell>Data Context Mobiles (e.g., phones)</cell></row><row><cell></cell><cell>hold a great amount of personal infor-</cell></row><row><cell></cell><cell>mation which can provide useful data in</cell></row><row><cell></cell><cell>the context of a touch action. For ex-</cell></row><row><cell></cell><cell>ample, touching the recipient field in an</cell></row><row><cell></cell><cell>email application on the surface could</cell></row><row><cell></cell><cell>automatically fill in a selection of known</cell></row><row><cell></cell><cell>contacts, using the address book on the</cell></row><row><cell></cell><cell>mobile as source.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Additional input attributes, which attach contextual information to a touch event.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>June 11-15, 2012 • Newcastle, UK</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>Parts of this work were conducted within the Emmy Noether research group Mobile Interaction with Pervasive User Interfaces funded by the German Research Foundation (DFG). We would further like to thank Sascha Geeren for implementation support and fruitful discussions, Paul Holleis for valuable feedback, and all our study participants.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>Dis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012-06-11">2012. June 11-15, 2012</date>
			<pubPlace>Newcastle, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Rockin&apos;Mouse: Integral 3D manipulation on a plane</title>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Baudel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kurtenbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fitzmaurice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sweep and Point &amp; Shoot: Phonecam-based interactions for large public displays</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ballagas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rohs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Borchers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI Ext. Abstracts</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1200" to="1203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Touch projector: Mobile interaction through video</title>
		<author>
			<persName><forename type="first">S</forename><surname>Boring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gustafson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2287" to="2296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A three-state model of graphical input</title>
		<author>
			<persName><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERACT</title>
		<meeting>INTERACT</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="449" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A privacy-respectful input method for public terminals</title>
		<author>
			<persName><forename type="first">A</forename><surname>De Luca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Frauendienst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NordiCHI</title>
		<meeting>NordiCHI</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="455" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">DiamondTouch: A multi-user touch technology</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Leigh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
		<meeting>UIST</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="219" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Supporting casual interactions between board games on public tabletop displays and mobile devices</title>
		<author>
			<persName><forename type="first">F</forename><surname>Echtler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nestler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dippon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Klinker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pers. and Ubiq. Comp</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="609" to="617" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Modal spaces: spatial multiplexing to mediate direct-touch input on large displays</title>
		<author>
			<persName><forename type="first">K</forename><surname>Everitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ryall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forlines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI Ext. Abstracts</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1359" to="1362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Situated information spaces and spatially aware palmtop computers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Fitzmaurice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. ACM</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="39" to="49" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">PDAs and shared public displays: Making personal information public, and public information personal</title>
		<author>
			<persName><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Laberge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pers. and Ubiq. Comp</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="54" to="64" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Attach me, detach me, assemble me like you work</title>
		<author>
			<persName><forename type="first">D</forename><surname>Grolaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderdonckt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Van Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERACT</title>
		<meeting>INTERACT</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="198" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploring non-speech auditory feedback at an interactive multi-user tabletop</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forlines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ryall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GI</title>
		<meeting>GI</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="41" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Touch &amp; Interact: Touch-based interaction of mobile phones with displays</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rukzio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MobileHCI</title>
		<meeting>MobileHCI</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="245" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">FlashLight: Optical communication between mobile phones and interactive tabletops</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hesselmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Henze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ITS</title>
		<meeting>ITS</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="135" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distinguishing multiple smart-phone interactions on a multi-touch wall display using tilt correlation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hutama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chi-Wing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Goh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-touch authentication on tabletops</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dunphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Briggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nicholson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nicholson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Olivier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1093" to="1102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">People, places, things: Web presence for the real world</title>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mob. Netw. Appl</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="365" to="376" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Surface Mobile Connect</title>
		<ptr target="http://technet.microsoft.com/en-us/library/ee692087.aspx" />
		<imprint>
			<date type="published" when="2012-03-24">24 March 2012</date>
			<publisher>Microsoft</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">C-Blink: A hue-difference-based light signal marker for large screen interaction via any mobile terminal</title>
		<author>
			<persName><forename type="first">K</forename><surname>Miyaoku</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Higashino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tonomura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
		<meeting>UIST</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="147" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Individual audio channels with single display groupware: effects on communication and task strategy</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CSCW</title>
		<meeting>CSCW</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="242" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Using handhelds and PCs together</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. ACM</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="34" to="41" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Interacting at a distance: Measuring the performance of laser pointers and other devices</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bhatnagar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Spatially aware handhelds for high-precision tangible interaction with large displays</title>
		<author>
			<persName><forename type="first">A</forename><surname>Olwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. TEI</title>
		<meeting>TEI</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="181" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Smart phone interactions with registered displays</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pears</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Oliver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Perv. Comp</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="14" to="21" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fostering a symbiotic handheld environment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Raghunath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Narayanaswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pinhanez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comp</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="56" to="65" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Pick-and-Drop: A direct manipulation technique for multiple computer environments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rekimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
		<meeting>UIST</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="31" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A multiple device approach for supporting whiteboard-based interactions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rekimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="344" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Augmented surfaces: A spatially continuous work space for hybrid computing environments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rekimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saitoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="378" to="385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dual device user interface design: Pdas and interactive television</title>
		<author>
			<persName><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wharton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ashworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Franzke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">iDwidgets: parameterizing widgets by user identity</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ryall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Esenther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Everitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forlines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shipman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vernier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERACT</title>
		<meeting>INTERACT</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1124" to="1128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">PhoneTouch: A technique for direct phone interaction on surfaces</title>
		<author>
			<persName><forename type="first">D</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chehimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rukzio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gellersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
		<meeting>UIST</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="13" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">HandsDown: Hand-contour-based user identification for interactive surfaces</title>
		<author>
			<persName><forename type="first">D</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gellersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NordiCHI</title>
		<meeting>NordiCHI</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="432" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">IdLenses: Dynamic personal areas on shared surfaces</title>
		<author>
			<persName><forename type="first">D</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gellersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ITS</title>
		<meeting>ITS</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="131" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Informing the design of direct-touch tabletops</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ryall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forlines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Esenther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vernier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Everitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wigdor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comp. Graph. and App</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="36" to="46" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">User interface fac ¸ades: Towards fully adaptable user interfaces</title>
		<author>
			<persName><forename type="first">W</forename><surname>Stuerzlinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Chapuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Roussel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
		<meeting>UIST</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="309" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">BlueTable: Connecting wireless mobile devices on interactive surfaces using vision-based handshaking</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sarin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GI</title>
		<meeting>GI</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="119" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Multi-finger and whole hand gestural interaction techniques for multi-user tabletop displays</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
		<meeting>UIST<address><addrLine>Newcastle, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003. 2012. June 11-15. 2012</date>
			<biblScope unit="page" from="193" to="202" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
