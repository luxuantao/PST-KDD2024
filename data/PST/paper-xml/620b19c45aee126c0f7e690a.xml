<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graph-GAN: A spatial-temporal neural network for short-term passenger flow prediction in urban rail transit systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hua</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Rail Traffic Control and Safety</orgName>
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<postCode>100044</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jinlei</forename><surname>Zhang</surname></persName>
							<email>zhangjinlei@bjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Rail Traffic Control and Safety</orgName>
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<postCode>100044</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lixing</forename><surname>Yang</surname></persName>
							<email>lxyang@bjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Rail Traffic Control and Safety</orgName>
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<postCode>100044</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianguo</forename><surname>Qi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Rail Traffic Control and Safety</orgName>
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<postCode>100044</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ziyou</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Rail Traffic Control and Safety</orgName>
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<postCode>100044</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Graph-GAN: A spatial-temporal neural network for short-term passenger flow prediction in urban rail transit systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deep learning</term>
					<term>short-term passenger flow prediction</term>
					<term>GCN</term>
					<term>GAN</term>
					<term>urban rail transit</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Short-term passenger flow prediction plays an important role in better managing the urban rail transit (URT) systems. Emerging deep learning models provide good insights to improve short-term prediction accuracy. However, a large number of existing prediction models combine diverse neural network layers to improve accuracy, making their model structures extremely complex and difficult to be applied to the real world. Therefore, it is necessary to trade off between the model complexity and prediction performance from the perspective of real-world applications. To this end, we propose a deep learningbased Graph-GAN model with a simple structure and high prediction accuracy to predict short-term passenger flows of the URT network. The Graph-GAN consists of two major parts: (1) a simplified and static version of the graph convolution network (GCN) used to extract network topological information;</p><p>(2) a generative adversarial network (GAN) used to predict passenger flows, with generators and discriminators in GAN just composed of simple fully connected neural networks. The Graph-GAN is tested on two large-scale real-world datasets from Beijing Subway. A comparison of the prediction performance of Graph-GAN with those of several state-of-the-art models illustrates its superiority and robustness. This study can provide critical experience in conducting short-term passenger flow predictions, especially from the perspective of real-world applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Nowadays, with the rapid development of urban rail transit (URT), the passenger flow volume is becoming increasingly large, thus causing heavy congestions in URT systems.</p><p>One of the means to alleviate traffic congestions is to accurately predict the short-term flow volume <ref type="bibr">(Liu et al., 2019;</ref><ref type="bibr" target="#b10">Li et al., 2021)</ref> and then conduct corresponding management measures. Therefore, short-term passenger flow prediction is of great significance to better manage the URT systems. For passengers, accurately predicting the inflow and outflow of each station in URT can effectively help them plan travel routes, thus saving travel time and cost <ref type="bibr" target="#b0">(Cheng et al., 2021;</ref><ref type="bibr" target="#b25">Noursalehi et al., 2021)</ref>. For operators, the congested stations can be detected leveraging the prediction results. Therefore, if some stations are critically congested, the corresponding passenger control measures can be implemented there to avoid congestions. Some accidents caused by excessive passenger flows can thus be avoided, which is of great significance for ensuring people's safety. Moreover, the timetable can be timely optimized so as to transport more passengers during peak hours according to predictions results, which can also alleviate congestions. For advertisers, they can post more advertisements to promote their products in some stations with extremely large predicted flow volumes. In summary, it is in urgent need to solve the problem of short-term passenger flow prediction for a better operation of URT systems.</p><p>As a hot and very important research topic, short-term passenger flow prediction has experienced a long history. The most conventional models are statistical-based prediction models, such as autoregressive model (AR), moving average model (MA), autoregressive integrated moving average (ARIMA) <ref type="bibr" target="#b49">(Zhang et al., 2014;</ref><ref type="bibr" target="#b4">Guo et al., 2014)</ref>, etc. However, the prediction accuracy is to be improved and they cannot generally meet the real-time requirements. Due to the excellent ability to capture complex spatiotemporal correlations, many machine learning and deep learning-based prediction models have been applied to the URT systems recently. For the machine learning-based models, such as support vector machine <ref type="bibr" target="#b30">(Su and Yu, 2007)</ref>, and random forest <ref type="bibr">(Liu et al., 2019)</ref>, etc, a major limitation of this kind of prediction method is that they are generally applied to a single station rather than the entire URT network. Another limitation is that they cannot effectively capture the complex nonlinear spatiotemporal dependence between stations. The deep learning-based models <ref type="bibr" target="#b6">(Ke et al., 2017;</ref><ref type="bibr" target="#b21">Ma et al., 2015)</ref>, have been proved to be superior to conventional methods in capturing complex correlations from large amounts of data, which significantly improve the prediction accuracy on a network-wide level. However, on the one hand, some deep learning algorithms only consider the temporal correlation of passenger flow and ignore the topological structure between subway stations. On the other hand, recent prediction models are becoming more and more complex, only considering the improvement of model accuracy while ignoring the complexity of the model, which is impractical from the perspective of real-world applications.</p><p>To address these limitations, in this paper, we propose a spatiotemporal network based on the graph conventional network (GCN) and generative adversarial network (GAN) (called Graph-GAN) for short-term passenger flow prediction in URT systems. The GCN has been extensively applied in many fields, including network analysis, recommendation system, traffic prediction, computer vision, etc. In this study, we propose a simplified and static GCN to incorporate the topological information between stations into prediction models, thus helping extract spatial features of URT networks. The GAN is a powerful generative framework with an adversarial process and has been widely utilized in various domains including image generation, video prediction, and text classification.</p><p>In this study, the GAN composed of fully connected neural networks is used to generate prediction results with higher accuracy. In the adversarial process, we train the generator to generate the passenger flow for the next time slice based on historical data. The discriminator is to discriminate the passenger flow generated by the generator from the real records. Therefore, the proposed Graph-GAN aims to extract the internal topological relationship between subway stations through GCN, and then generate more accurate passenger flow prediction results through GAN with adversarial training. We summarize our main contributions as follows:</p><p>1. A simplified and static GCN rather than the initial GCN is proposed to incorporate the topological information between stations into the prediction model. When predicting the passenger flow on a network level, the internal correlations among subway stations are thus considered.</p><p>2. The GAN is applied to train a linear model with higher prediction accuracy. The generator and discriminator in the GAN are composed of a simple fully connected neural network. With the historical passenger flow series and the adjacency matrix as inputs, the generator is applied to generate the passenger flow for the next time slice. The discriminator is used to discriminate the passenger flow generated by the generator from the real records.</p><p>3. We proposed an extremely simple model framework to solve an extremely complex problem, showing that it is not the more complex the better for the deep learning-based prediction models, it is the more appropriate the better. To the best of our knowledge, this is the first time that the GAN is applied to the URT system.</p><p>4. The proposed Graph-GAN is tested on two real-world datasets. Results show its superiority in the prediction accuracy, the model robustness, and the number of model parameters compared with the several existing prediction methods.</p><p>The remainder of this article is organized as follows: Section 2 reviews related works.</p><p>In section 3, we give a formal definition of the problem and show the framework of our solution. Section 4 introduces the methodology. Evaluations are given in Section 5. Finally, we conclude this article in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Literature review</head><p>In this section, conventional traffic flow prediction models, traffic predictions with GCN, and the GAN are reviewed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Traffic flow prediction</head><p>As an important topic of spatiotemporal data mining, traffic flow prediction <ref type="bibr" target="#b29">(Shu et al., 2021;</ref><ref type="bibr">Ma et al., 2021;</ref><ref type="bibr">Zhang et al., 2020;</ref><ref type="bibr" target="#b37">Wu, 2021)</ref> has been extensively studied in recent years.</p><p>Conventional traffic prediction models are statistic-based, such as autoregressive model (AR), moving average model (MA), differential integrated autoregressive moving average model (ARIMA), linear regression <ref type="bibr" target="#b31">(Sun et al., 2014)</ref>. <ref type="bibr" target="#b36">Williams et al. (1998)</ref> proposed a seasonal ARIMA to conduct traffic flow prediction problems for urban freeways. Williams <ref type="bibr">(2001)</ref> applied the ARIMA model to short-term predictions for motorways. <ref type="bibr" target="#b40">Yan (2010)</ref> extended the ARIMA model with spatial dimension and further applied it for trajectory predictions. However, the statistic-based passenger flow prediction models cannot effectively capture the complex nonlinear relationship in the time series, thus exhibiting limited performance and adaptability.</p><p>With the development of machine learning, machine learning-based models, such as backpropagation neural networks <ref type="bibr" target="#b32">(Wang and Liu, 2008)</ref>, random forest learning <ref type="bibr" target="#b41">(Zarei et al., 2013)</ref>, support vector regression model <ref type="bibr" target="#b30">(Su and Yu, 2007)</ref>, are applied to traffic flow predictions. For example, <ref type="bibr" target="#b47">Zhang et al. (2011)</ref> proposed a hybrid model combining the SARIMA and SVM to address the periodicity, nonlinearity, uncertainty, and complexity of short-term traffic predictions. <ref type="bibr" target="#b13">Lippi et al. (2013)</ref> built two support vector regression models to specifically predict seasonal traffic flows. <ref type="bibr" target="#b34">Wang et al. (2018)</ref> proposed a support vector machine partial online model to capture the weekly periodicity and nonlinearity characteristics of short-term ridership. However, most of these models only consider the temporal correlation and ignore the topological information. Therefore, the prediction accuracy still remains to be improved. Moreover, these models are generally applied to a single station rather than a whole URT network.</p><p>Recently, many deep learning models, such as vallina RNN, LSTM, and CNN, have been applied to short-term traffic predictions because of their strong learning ability in capturing spatiotemporal information. For example, Nejadettehad et al.  <ref type="formula">2021</ref>) applied an improved GRU to predict traffic flows. <ref type="bibr">Ma et al. (2021)</ref> proposed an improved LSTM to implement short-term traffic flow prediction. These models generally show favorable prediction performance and can be applied to network-level predictions. However, the topological information of the network cannot be fully captured during the modeling process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">GCN</head><p>Since CNN cannot be applied to the non-Euclidean data, the GCN is proposed to extract the topological information in graphs. Recently, GCN has been widely utilized in various fields due to its powerful ability to extract spatial information, such as natural language processing <ref type="bibr" target="#b22">(Marcheggiani and Titov, 2017</ref>), text classification <ref type="bibr" target="#b7">(Kipf and Welling, 2016)</ref>, computer vision <ref type="bibr" target="#b2">(Garcia and Bruna, 2017)</ref>, traffic flow prediction <ref type="bibr" target="#b9">(Lei et al., 2019;</ref><ref type="bibr" target="#b10">Li et al., 2021;</ref><ref type="bibr" target="#b50">Zhu et al., 2022;</ref><ref type="bibr">Zhang et al., 2021;</ref><ref type="bibr" target="#b26">Peng et al., 2021;</ref><ref type="bibr">M. et al., 2021)</ref>. <ref type="bibr" target="#b22">Marcheggiani and Titov (2017)</ref> proposed a new version of GCN to model syntactic dependency graphs. Kipf and Welling (2016) explored semi-supervised node-level classification with GCN. <ref type="bibr" target="#b2">Garcia and Bruna (2017)</ref> defined a GCN architecture to study the problem of few-shot learning on a partially observed graphical model. The results showed the ability of graph-based models to operate well on "relational" tasks. Because the GCN can capture the structural information, it is also applied to the traffic network to capture the topological relationships between the nodes or links. <ref type="bibr" target="#b9">Lei et al. (2019)</ref> introduced a novel GCN-GAN model to tackle the link prediction task on weighted dynamic networks. <ref type="bibr" target="#b50">Zhu et al. (2022)</ref> proposed a new multi-graph convolutional network to explore the heterogeneous correlations among sensors, so as to improve the traffic prediction accuracy. <ref type="bibr">Zhang et al. (2021)</ref> proposed a graph-based temporal attention framework GTA, which considers both spatial and temporal correlations, to predict traffic flows using data collected from multiple sensors. <ref type="bibr" target="#b26">Peng et al. (2021)</ref> proposed a long-term traffic flow prediction method based on dynamic graphs. <ref type="bibr" target="#b17">Lv et al. (2021)</ref> propose T-MGCN (Temporal Multi-Graph Convolutional Network), a deep learning framework for traffic flow predictions. In summary, the GCN has been proved to be effective enough in traffic prediction tasks. Therefore, we propose a variant of GCN to capture the spatial correlations of URT networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">GAN</head><p>GAN is a powerful neural network based on the adversarial process, which shows strong learning ability in text classification <ref type="bibr" target="#b23">(Miyato et al., 2016)</ref>, semantic segmentation <ref type="bibr" target="#b16">(Luc et al., 2016)</ref>, image super-resolution <ref type="bibr" target="#b8">(Ledig et al., 2016</ref><ref type="bibr">), etc. Miyato et al. (2016)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem definition</head><p>In this section, the definition of traffic networks and feature matrix is defined, and a normal problem definition is introduced.</p><p>The purpose of this study is to use historical AFC data to predict the passenger flow volume of URT systems in the next time interval. The data extracted from the AFC data can be integrated at different time intervals (e.g. 15 minutes, 30 minutes). The time interval used in this study is 15 minutes. Definition 1 (traffic networks): First, we define the subway networks as a graph 𝐺 = (𝑉, 𝐸, 𝐴) , where 𝑉 = (𝑉 1, 𝑉 2, ⋯ , 𝑉 𝑛 ) is a set of subway stations, 𝑛 is the total number of subway stations. 𝐸 is a set of edges between subway stations. 𝐴 ∈ ℝ 𝑛×𝑛 is the adjacent matrix, which is used to describe the corresponding topological structure of URT systems.</p><p>If there is a link between two stations, the corresponding element in the adjacent matrix is 1; otherwise, it is 0.</p><p>Definition 2 (feature matrix): We treat the passenger flow volume as the attribute feature of the subway station in URT systems, expressed as 𝑥 𝑖,𝑡 𝑘 ∈ 𝑅 𝑛 * 𝑚 * 𝑘 , which denote the 𝑘 𝑡ℎ feature of the subway station 𝑖 at the time interval 𝑡 In 𝑥 𝑖,𝑡 𝑘 ∈ 𝑅 𝑛 * 𝑚 * 𝑘 , the 𝑛 is the station number, the 𝑚 is the number of time steps, and the 𝑘 is the number of characteristic matrices. In this study, each subway station has two characteristic matrices: inflow and outflow. Therefore, 𝑘 = 2.𝑋 𝑡 = (𝑥 1,𝑡 𝑘 , 𝑥 2,𝑡 𝑘 , ⋯ , 𝑥 𝑛,𝑡 𝑘 ) 𝑇 denotes the values of all the features of all subway stations at the time</p><formula xml:id="formula_0">𝑡. 𝑋 = (𝑋 1 , 𝑋 2 , ⋯ , 𝑋 𝑇 ) = ( 𝑥 1,1 𝑘 𝑥 1,2 𝑘 𝑥 2,1 𝑘 𝑥 2,2 𝑘 ⋯ 𝑥 1,𝑇 𝑘 ⋯ 𝑥 2,𝑇 𝑘 ⋮ ⋮ 𝑥 𝑛,1 𝑘 𝑥 𝑛,2 𝑘 ⋱ ⋮ ⋯ 𝑥 𝑛,𝑇 𝑘 )</formula><p>denotes the values of all the features of all subway stations over 𝑇 time slices. In addition, we set 𝑌 𝑡+1 ∈ 𝑅 𝑛 * 1 * 𝑘 to represent the traffic flow of all subway stations at a time 𝑡 + 1 in the future.</p><p>Problem: Given 𝑋, we use the passenger flow volumes of all subway stations over past 𝑚 time slices to predict the future traffic flow</p><formula xml:id="formula_1">𝑌 𝑡+1 = (𝑌 1,𝑡+1 𝑘 , 𝑌 2,𝑡+1 𝑘 , ⋯ , 𝑌 𝑛,𝑡+1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>𝑘</head><p>) of all subway stations on the whole traffic network. Therefore, the problem can be defined as Eq.</p><p>(1).</p><formula xml:id="formula_2">𝑌 𝑡+1 = 𝑓 (𝑋 𝑡 )<label>(1)</label></formula><p>where 𝑓 indicates the model to be learned during the training process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head><p>In this section, we describe the proposed adversarial learning framework in detail. We first introduce the framework of Graph-GAN. Then, one of its components, namely the GCN, is introduced. Finally, the other components, namely the GAN, are presented. In the GAN, the generator and discriminator comprising linear models are described. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Graph-GAN framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">GCN</head><p>In this section, we apply the GCN model to capture the topological dependence between stations in the URT network. Some conventional traffic prediction models often regard traffic networks as grid matrices, which ignore the influence of network topology on prediction accuracy. The GCN model shows a strong ability to extract spatiotemporal characteristics and network topology information <ref type="bibr" target="#b7">(Kipf and Welling, 2016)</ref>. From spectral convolution filter to Chebyshev polynomial filter, and then to first-order approximation filter, the performance of GCN has been significantly improved <ref type="bibr">(Zhang et al., 2021)</ref>. Thus, we apply the GCN model to obtain the internal topological relations between subway stations. Figure <ref type="figure">2</ref> shows the general structure of the GCN model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input layer Output layer Hidden layer</head><p>Figure <ref type="figure">2</ref> The internal structure of the GCN model Assume that there are N nodes with M-dimensional features in a static graph. The topological structure and node features can be respectively represented by an adjacency matrix A and a feature matrix Z. The typical GCN model proposed by <ref type="bibr" target="#b7">Kipf and Welling (2016)</ref> takes the feature matrix Z as the input and conducts the graph convolution operation with localized first-order approximation on it. The GCN functions without biases can be defined as follows:</p><formula xml:id="formula_3">𝑋 = 𝐺𝐶𝑁(𝑍, 𝐴) = 𝑓(𝐷 ̂−1 2 𝐴 ̂𝐷 ̂−1 2 𝑍𝑊)<label>(2)</label></formula><p>where 𝐴 ̂= 𝐴 + 𝐼 𝑁 , 𝐴 is the adjacency matrix, 𝐼 𝑁 is an N-dimensional identity matrix, 𝐷 ̂ is the diagonal node-degree matrix of 𝐴 ̂, 𝑊 is the weight matrix, 𝑍 is the feature matrix, 𝑓(•) is the activation function, X is the final output.</p><p>However, existing studies have confirmed that the performance of the GCN model will become worse with the increase of the number of stacked GCN layers <ref type="bibr" target="#b38">(Wu et al., 2020;</ref><ref type="bibr" target="#b11">Li et al., 2019)</ref>. More stacked GCN layers will not only lead to higher complexity in the process of backpropagation but also lead to problems such as gradient disappearance, thus reducing the performance of deep GCN. In addition, a serious "over-smoothing" problem, which means that several features of a vertex converge to the same value as the number of layers increases, is also a common problem in deep GCN <ref type="bibr" target="#b12">(Li et al., 2018)</ref>. In view of this, this paper extends the general GCN to a simplified and static GCN to reduce the deficiencies of the GCN model <ref type="bibr" target="#b46">(Zhang et al., 2019)</ref> as shown in Eq. ( <ref type="formula" target="#formula_4">3</ref>). It is noted that Eq.</p><p>(3) can be computed in advance. Therefore, there is no additional parameter to be learned during the training process.</p><formula xml:id="formula_4">𝐼𝑛 ′ = 𝐷 ̂−1 2 𝐴 ̂𝐷 ̂−1 2 𝐼𝑛<label>(3)</label></formula><p>where 𝐷 ̂−1 2 𝐴 ̂𝐷 ̂−1 2 is symmetric normalized Laplacian, 𝐼𝑛 ∈ 𝑅 𝑛 * 𝑚 * 𝑘 is the model input, where 𝑛 is the number of subway stations, 𝑚 is the number of historical time steps used by each station, and the 𝑘 is the number of characteristic matrices. The transformed 𝐼𝑛 ′ and 𝐼𝑛 have the same dimension, but the 𝐼𝑛 ′ contains richer network topology information and is subsequently used as the inputs of GAN.</p><p>Since the inflow and outflow are affected by the passenger flow of corresponding neighboring periods, daily periods, and weekly periods, we thus utilize the passenger flows under three patterns in this study: the real-time pattern, the daily pattern, and the weekly pattern. Suppose the time interval is 𝑡𝑖, the time step is 𝑡𝑠, the current time is time slice 𝑡, and the passenger flow of the next period 𝑡 + 1 is to be predicted. Details about the three patterns are as follows:</p><p>(1) The real-time pattern: 𝑋 𝑟𝑒𝑎𝑙 = (𝑋 𝑡−𝑡𝑠+1 , 𝑋 𝑡−𝑡𝑠+2 , ⋯ , 𝑋 𝑡 ) , a segment of historical time series adjacent to the predicting period. The passenger flow in adjacent periods will affect the increase or decrease of passenger flow in the next period. For example, under emergent events, the number of passengers entering or leaving the subway station will change correspondingly.</p><p>(2) The daily pattern:</p><formula xml:id="formula_5">𝑋 𝑑𝑎𝑦 = (𝑋 𝑡− 1440 𝑡𝑖 −𝑡𝑠+1 , 𝑋 𝑡− 1440 𝑡𝑖 −𝑡𝑠+2 , ⋯ , 𝑋 𝑡− 1440 𝑡𝑖</formula><p>), a segment of historical time series for the same time of the day before the predicting period. In the Xday, the current time is t, and the same time the previous day is 𝑡 − 60 𝑡𝑖 * 24, that is, 𝑡 − 1140 𝑡𝑖 . Due to the morning peak and evening peak, the passenger flow will present a certain trend every day. Therefore, it is necessary to predict current passenger flows according to the previous day.</p><p>(3) The weekly pattern: Therefore, it can be used to generate the final prediction results. The objective function is as shown in Eq. ( <ref type="formula">4</ref>) <ref type="bibr" target="#b3">(Goodfellow et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>𝑚𝑖𝑛 𝐺 𝑚𝑎𝑥ℒ(𝐺, 𝐷) 𝐷 = 𝔼 𝒳~𝑃 𝑑𝑎𝑡𝑎 (𝒳) [𝑙𝑜𝑔𝐷(𝒳)] + 𝔼 𝒵~𝑃 𝒵 (𝒵) [log (1 − 𝐷(𝐺(𝒵)))] (4)</head><p>where 𝒳 is the real data, 𝑃 𝑑𝑎𝑡𝑎 (𝒳) is the real data distribution 𝐷(𝒳) is the probability that 𝒳 comes from the data distribution, 𝒵 is the random noise, 𝑃 𝒵 (𝒵) is the prior distribution on input noise 𝒵, 𝐺(𝒵) is a generator that generates "fake" data from 𝒵, and 𝐷(𝐺(𝒵)) represents the probability that the generated "fake" sample comes from the data distribution. The goal of the objective function is to maximize the probability of assigning the correct label to both real and fake samples from G.</p><p>In our work, we aim to use historical inflow and outflow𝑋 = (𝑋 1 , 𝑋 2 , ⋯ , 𝑋 𝑇 ) to predict the future passenger flow 𝑌 𝑡+1 . We utilize a fully connected neural network as the generator G to generate prediction results and a fully connected neural network as the discriminator which tries to distinguish which one is real and which one is generated by the generator G.</p><p>First, the process of generating samples through the generator is introduced. We design the generator G via a fully connected neural network with two hidden layers and one output layer. The inflow (𝑋 1 𝑐𝑎𝑡 , 𝑋 2 𝑐𝑎𝑡 , ⋯ , 𝑋 𝑇 𝑐𝑎𝑡 ) output by the GCN model is used as the input of the generator. Then, we get the output 𝑋 1 ′ , 𝑋 2 ′ , ⋯ , 𝑋 𝑇 ′ ) generated by the generator.</p><p>Given the real and generated inflow data (𝑋, 𝑋 ′ ), the discriminator D distinguishes which one is real and which one is generated. We also implement the discriminator D via a fully connected neural network with two hidden layers and one output layer. In the training process, the discriminator D alternatively takes the generated 𝑋 ′ and the real inflow 𝑋 as the input. Then the error of discriminator D will be backpropagated to the generator G to minimize the errors between the generated data and the real data.</p><p>In this study, we apply the Wasserstein GAN (WGAN) rather than the initial GAN.</p><p>The main difference between WGAN and the initial GAN is that the WGAN introduces Wasserstein distance instead of JS divergence and KL divergence as optimization objectives. Because of the more smoothing characteristics of Wasserstein distance compared with KL divergence and JS divergence, the WGAN fundamentally solves the problem of gradient disappearance of the original GAN, which ensures the following two advantages: First, it is much easier to train the WGAN because the training process is more stable and less sensitive to the model architecture and hyperparameters, and there is no need to carefully balance the training of the generator and the discriminator. For example, only training a simple fully connected network can achieve higher performance. Secondly, the problem of collapse mode is solved, and the diversity of generated samples is ensured.</p><p>For example, the WGAN can generate more diverse samples so that the training of generator G can be accelerated. The objective function of WGAN is as shown in Eq. ( <ref type="formula" target="#formula_6">5</ref>) <ref type="bibr" target="#b33">(Wang et al., 2020)</ref>.</p><formula xml:id="formula_6">𝑚𝑖𝑛 𝜃 𝑚𝑎𝑥ℒ(𝐺, 𝐷) 𝜔 𝔼 𝒳~𝑃 𝑑𝑎𝑡𝑎 (𝒳) [𝑓 𝜔 (𝒳)] + 𝔼 𝒵~𝑃 𝒵 (𝒵) [log (1 − 𝑓 𝜔 (𝑔 𝜃 (𝒵)] (<label>5</label></formula><formula xml:id="formula_7">)</formula><p>where 𝜔 is the critic parameters, 𝜃 is the generator's parameters, and 𝑓 𝜔 (𝒳) is a parameterized family of functions {𝑓 𝜔 } 𝜔∈𝒲 that are all K-Lipschitz for K.</p><p>According to our experiences, we summarize the training skills of WGAN for the first time, which is much more important to practitioners, to give some hints for future studies as follows:</p><p>(1) During WGAN training, the sigmoid activation function layer was removed from the last layer of discriminator D.</p><p>(2) The loss function of the generator and discriminator is calculated without taking a log operation.</p><p>(3) After each update of the discriminator's parameters, truncate their absolute value to no more than a fixed constant c. (4) When choosing an optimizer, do not use momentum-based optimizer algorithms, such as the Adam with momentum. The optimizer of RMSProp and SGD are recommended. During the alternative training of the discriminator and generator, the discriminator is suggested to be trained several more times than the generator in each epoch. So that an equilibrium state between the discriminator and generator can be reached much more easily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>In this section, we test the proposed model with two real-world datasets and compare it with some baseline models. The experimental results are analyzed from multiple perspectives.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Model configurations and evaluation metrics</head><p>Hyperparameters: The same parameters of GAN are applied for both of the two datasets The optimizer is RMSprop with a learning rate of 0.00005. All models are implemented with PyTorch on a desktop computer with Intel® Core™ i9-10900X CPU, 32 GB memory, and an NVIDIA GeForce RTX3080 GPU.</p><p>Preprocessing: Before training, we use the Min-Max normalization method to scale the inflow data into the range [0, 1]. In the evaluation process, we re-scale the prediction back to the original scale, which is used to compare with the real data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics:</head><p>We use Root Mean Squared Error(RMSE), Mean Average Error(MAE), and Weighted Mean Absolute Percentage Error(WMAPE) as the evaluation metrics as shown in Eq. ( <ref type="formula" target="#formula_8">6</ref>) to (8):</p><formula xml:id="formula_8">𝑀𝐴𝐸 = 1 𝑁 ∑ |(𝑦 𝑖 − 𝑦 ̂𝑖)| 𝑁 𝑖=1<label>(6)</label></formula><formula xml:id="formula_9">𝑅𝑀𝑆𝐸 = √ 1 𝑁 ∑ (𝑦 𝑖 − 𝑦 ̂𝑖) 2 𝑁 𝑖=1<label>(7)</label></formula><formula xml:id="formula_10">𝑊𝑀𝐴𝑃𝐸 = ∑ { 𝑦 𝑖 ∑ 𝑦 𝑖 𝑁 𝑗=1 | 𝑦 𝑖 −𝑦 ̂𝑖 𝑦 𝑖 |} 𝑁 𝑖=1<label>(8)</label></formula><p>where 𝑁 is the number of samples, 𝑦 𝑖 i s the actual value, 𝑦 ̂𝑖 is the predicted value,</p><formula xml:id="formula_11">∑ 𝑦 𝑗 𝑁 𝑗=1</formula><p>is the sum of the actual values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Baselines</head><p>To illustrate the superiority of our model, we compare it with eight baseline models as follows:</p><p>Autoregressive Integrated Moving Average (ARIMA): We apply the same ARIMA model to the passenger flows from all URT stations. The three parameters in the model, namely the lag order, the degree of difference, and the order of the moving average, are set as 9, 1, 0, respectively after fine-tuning.</p><p>Long Short Term Memory Neural Network (LSTM): Specifically, we apply two LSTM layers and three fully connected layers <ref type="bibr" target="#b21">(Ma et al., 2015)</ref>. The optimizer is Adam with a learning rate of 0.001. The batch size is 32. The inputs are inflow series in the last 10 time steps. The outputs are the inflow series in the next time step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Convolutional Neural Network (CNN):</head><p>We apply two CNN layers and three fully connected layers <ref type="bibr" target="#b20">(Ma et al., 2017)</ref>. The kernel size is 3*3. The optimizer is Adam with a learning rate of 0.001. The batch size is 32. The inputs and outputs are the same as that of the LSTM model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ST-ResNet:</head><p>It was proposed by <ref type="bibr" target="#b45">Zhang et al. (2017)</ref>. Here, we only adopt three branches of this model and do not use the weather data. The other parameters are similar to <ref type="bibr" target="#b45">Zhang et al. (2017)</ref>.</p><p>ConvLSTM: ConvLSTM was proposed by <ref type="bibr" target="#b28">Shi et al. (2015)</ref> and achieves great success in 2015. We apply two ConvLSTM layers and three fully connected layers. Other parameters are the same with the CNN model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ResLSTM:</head><p>A deep-learning architecture comprises GCN, ResNet, and attention LSTM <ref type="bibr" target="#b46">(Zhang et al., 2019)</ref>. The parameters are the same as <ref type="bibr" target="#b46">Zhang et al. (2019)</ref>.</p><p>GAN: Generative adversarial networks were proposed by Ian <ref type="bibr" target="#b3">Goodfellow et al. (2014)</ref>.</p><p>Except for the GCN module, the parameters of GAN are the same as that of the Graph-GAN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conv-GCN:</head><p>A deep-learning architecture combining graph convolutional network (GCN) and 3D convolutional neural network 3D CNN <ref type="bibr">(Zhang et al., 2020)</ref>. The parameters are similar to <ref type="bibr">Zhang et al. (2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Experiment results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Network-wide prediction performance</head><p>Table <ref type="table" target="#tab_2">2</ref> and Figure <ref type="figure" target="#fig_7">5</ref> show the performance of Graph-GAN in comparison to other baselines methods for both MetroBJ2016 and MetroBJ2018 datasets. As is shown in Table <ref type="table" target="#tab_2">2</ref>, deep learning models considerably outperform mathematical statistics-based models. In both MetroBJ2016 and MetroBJ2018 datasets, ARIMA is the model with the worst performance, with RMSE of 81.4562 and 69.4250, and MSE of 42.8006 and 33.9540 for the two datasets, respectively. This is because ARIMA cannot capture the comprehensive nonlinear characteristics of passenger flow.</p><p>We further compare our model with the well-known deep learning methods, such as LSTM and CNN. Among deep learning models, LSTM may not model spatial correlations while CNN may not capture temporal dynamics. Thus, these two models perform worse than the graph-GAN model which can consider both spatial and temporal information.</p><p>ST-Resnet, Conv-GCN, and Conv-LSTM are several prevailing approaches for passenger flow prediction considering both the spatial correlations and temporal dynamics. All of these approaches achieve accuracy improvements over the LSTM and CNN. However, these models are relatively complex in terms of structure. Therefore, we propose a simpler model to achieve a better prediction performance.</p><p>As we have already discussed, GAN has shown its potential and has been widely used in many applications. With the adversarial training process, the generator model can significantly improve its ability to get more accurate prediction results. Therefore, we train the generator and discriminator with stacking layers of two fully connected neural networks in an adversarial way, thus achieving better prediction results using simple neural networks. Results show that basic GAN performs better than LSTM and CNN, however, cannot adequately capture spatial and temporal information because the topological information is not fully utilized.</p><p>We then propose the graph-GAN model combining the GCN with GAN to better capture spatial and temporal relationships in high dimensional data.   In summary, the Graph-GAN model can achieve favorable prediction results not only for the whole URT network but also for each station. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.3">Prediction performance in different time intervals</head><p>In order to evaluate the prediction performance in different time intervals, we calculate the average prediction accuracy at each time interval from 5:00 to 23:00 for both MetroBJ2016 and MetroBJ2018. The performance comparison between the proposed model and baseline models at different time intervals is shown in Figure <ref type="figure">7</ref>. Several findings are listed as follows.</p><p>First, the relationship between the prediction performance in different time intervals and the overall prediction performance is discussed. It can be seen from Figure <ref type="figure" target="#fig_7">5</ref>  Finally, the prediction performance of each model on different datasets is discussed.</p><p>It can be seen from Figure <ref type="figure">7</ref> that there exhibit similar patterns both for MetroBJ2016 and MetroBJ2018, proving the generalization ability of each model.</p><p>In summary, the proposed model can achieve favorable prediction results no matter on the whole day but also at different time intervals, showing significant robustness. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.4">Comparison of model parameters</head><p>We compare the trainable model parameters of the proposed model with the baseline models that can capture the spatiotemporal correlations on the MetroBJ2016 and MetroBJ2018, as shown in Table <ref type="table" target="#tab_4">3</ref>. It can be seen that there are the fewest model parameters for the Graph-GAN we proposed. The number of parameters of the Graph-GAN is the same as the GAN. However, the accuracy has been improved, which also proves the effectiveness of the GCN module. Comparison of model parameters proves that we do not intend to increase the model prediction accuracy at the expense of increasing model complexity, and fully consider the trade-off between the model complexity and model performance from the application purpose. We just apply simple fully connected neural networks, together with a more advanced model training method, namely the GAN, while achieving the best prediction accuracy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and future work</head><p>In this study, we propose a deep learning architecture called Graph-GAN incorporating GCN and GAN for a more accurate short-term passenger flow prediction in URT systems.</p><p>The component of the generator and discriminator of the GAN is just simple fully connected neural networks. To the best of our knowledge, this is the first time that the GAN is applied to the URT system. The main conclusions are summarized as follows. 0 5 : 0 0 0 6 : 3 0 0 8 : 0 0 0 9 : 3 0 1 1 : 0 0 1 2 : 3 0 1 4 : 0 0 1 5 : 3 0 1 7 : 0 0 1 8 : 3 0 2 0 : 0 0 2 1 : 3 0 2 3 : 0 0 convolutional networks with synthetic data for traffic volume forecasting", Expert Systems with Applications, Vol. 187, pp. 115992.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(2020) applied three kinds of recurrent neural networks including vallina RNN, GRU, and LSTM to predict short-term traffic flows. Sameen and Pradhan (2017) utilized RNN to predict traffic accidents. Ma et al. (2015) utilized LSTM for traffic speed prediction. Jin et al. (2018) proposed a deep-learning-based framework named STRCNs to predict both inflow and outflow in urban areas. They combined the CNN and LSTM network to capture spatiotemporal dependencies simultaneously. Duan et al. (2019) proposed an origindestination flow prediction model based on convolutional LSTM. Shu et al. (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>extended the adversarial training process to the text classification. Luc et al (2016) proposed an adversarial training approach to train semantic segmentation models to detect and correct differences between ground truth segmentation maps and the ones produced by the segmentation net. Ledig et al. (2016) presented SRGAN, a GAN model for image superresolution to improve the resolution of images. In order to solve various traffic problems, various kinds of improved GAN have been proposed. Zhang (2019) proposes deep learning-based trip information maximizing generative adversarial network (T-InfoGAN) for travel time distribution prediction. Wang et al. (2020) proposed a sequence-to-sequence (Seq2Seq) generative adversarial nets model (SeqST-GAN) to perform multi-step spatiotemporal crowd predictions. Xu et al. (2020) proposed a novel deep learningframework GE-GAN using topological information from adjacent links to estimate road traffic states. However, to the best of our knowledge, no studies are applying GAN to predict the passenger flow of the URT network to date.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 Figure 1</head><label>11</label><figDesc>Figure1shows the framework of Graph-GAN. As is shown, the Graph-GAN contains two parts: the GCN model and the GAN model. Moreover, GAN contains the generator G and the discriminator D. In this framework, the historical passenger flow data is first aggregated into three patterns: the real-time pattern, the daily pattern, and the weekly pattern. and the GCN model is applied to capture the temporal and spatial correlation of passenger flows in each pattern. Then the outputs of the three patterns are merged and used as inputs to the generator in GAN. For the generator G, we propose a linear model to generate the future traffic flow 𝑋 𝑔𝑒𝑛𝑒𝑟𝑎𝑡𝑜𝑟 of all subway stations on the whole URT network, using the merged data 𝑋 𝐺𝐶𝑁 as inputs. For the discriminator D, its inputs are the historical passenger flow data 𝑋 𝑟𝑒𝑎𝑙 and the generated data 𝑋 𝐺𝑒𝑛𝑒𝑟𝑎𝑡𝑜𝑟 . The discriminator D tries to distinguish which one is real and which one is generated by G. G and D are trained iteratively, and the generated data is so similar to the real data that D cannot distinguish them. After the training, the generator can be used as the prediction model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3</head><label>3</label><figDesc>Figure 3 The framework of generative adversarial network GAN is a generative model with an adversarial process and has been widely used in various fields, such as image generation, video prediction, and text classification. As shown in Figure 3, GAN consists of two components: a generative model (Generator, G) and a discriminant model (Discriminator, D). The G captures the potential distribution of real data, and generates new data from the potential distribution; the D is a two-category classifier that discriminates whether the input is real data or generated data. The optimization process is similar to the minimax game process. The G and D are trained iteratively. Through the backpropagation algorithm, the final goal can achieve the Nash equilibrium, that is, the generator completely obtains the distribution of real data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>There are a total of 17 lines and 276 stations in operation in March 2016. The second dataset is MetroBJ2018, which is collected from October 8, 2018, to November 11, 2018. There are a total of 22 lines and 308 stations in operation in 2018. The time series of inflows under 15-minute time granularity is extracted from about 130 million pieces of AFC data in 25 working days for 5 consecutive weeks. To extract the inflow and outflow volumes, the entering and exiting times are transformed into minutes, from 0 to 1080, which represents 05:00 to 23:00. The dimension of the passenger flow series from MetroBJ2016 is 276*1800 and the dimension of that from MetroBJ2018 is 308*1800. Moreover, we give a unique station number for all subway stations. In this study, due to the limited amount of data and the consideration of the three patterns of real-time pattern, daily pattern, and weekly pattern in the prediction model, the data from the first four weeks are used to train and validate the proposed model, and the rest data are used to test the model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>as follows: Generator G and discriminator D are fully connected networks with two hidden layers and one output layer. The unit numbers of the hidden layer in generator G and discriminator D are[1024, 512]  and[512, 256], respectively. The activation functions for hidden layers of generator G and discriminator D are the ReLU function and LeakyReLU function, respectively. Since we use WGAN for training, the activation function for the output layer of the generator is the Tanh function. And there is no activation function in the discriminator's output layer. We select 80% of all data as the training data and validation data, and the remaining 20% is chosen as the testing data. The batch size is 32.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4</head><label>4</label><figDesc>Figure 4 Comparison of performances for different models5.4.2 Prediction performance of individual stationsWe select three stations with different passenger flow characteristics to show the prediction performance of the Graph-GAN. The first station is the Huilongguan station, a large community with millions of people living nearby. The second station is the Dongzhimen station, which is a typical traffic hub where three subway lines interchange there. The last one is Beijing South Railway station, which is a subway station close to a large railway station. The prediction results of the three subway stations are shown in Figure6. Some critical points can be drawn as follows.The prediction result of the Huilongguan station is shown in Figure6(a). It can be seen from the figure that the predicted value is always consistent with the actual value, no matter in the peak period or off-peak period, which indicates that the Graph-GAN model has strong robustness. Moreover, because Huilongguan Subway station is located near large residential areas, passengers commute extremely regularly on weekdays, and there exist strong morning and evening peak characteristics, which helps to improve the prediction performance. The prediction result of the Dongzhimen station is shown in Figure 6 (b). It can be seen that the passenger flow of Dongzhimen Subway station presents obvious evening peak characteristics. The prediction performance is favorable no matter during the peak or off-peak periods, indicating that the model can be applied to transfer stations. The prediction result of the Beijing South Railway station is shown in Figure 6 (c). It can be seen that the passenger flow of Beijing South Railway station fluctuates significantly without obvious morning and evening peaks. In this case, the proposed model can still capture the variation of passenger flow well, indicating that the model performs well under different conditions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5</head><label>5</label><figDesc>Figure 5 Comparison of actual and predicted values of the three selected stations in MetroBJ2016 and MetroBJ2018: (a) Huilongguan station; (b) Dongzhimen station; (c) Beijingnan station</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(the overall prediction result of each model) and Figure7(the prediction result of each model intervals) that the performance of different models at different time intervals shows the same pattern as the overall performance. For example, the ARIMA performs the worst during both peak periods and off-peak periods. Moreover, the prediction error of the ARIMA presents the largest fluctuations, which indicates that the statistics-based model is not suitable for large-scale data prediction. The Graph-GAN generally performs better than baseline models during both peak periods and off-peak periods. These results show the stability of the Graph-GAN model.Then, we analyze the prediction performance of the same model in different time intervals. Taking the Graph-GAN model as an example, the performance of the Graph-GAN during the off-peak periods is better than that during the peak periods. The performance of other models at different time intervals is similar to that of the Graph-GAN, which indicates that the model's prediction performance declines when the URT passenger flow fluctuates sharply. However, compared with other baseline models, the fluctuation of the prediction error of the Graph-GAN model during peak periods is the most slight.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6</head><label>6</label><figDesc>Figure 6 Comparison of the model performance in different time intervals in MetroBJ2016 and MetroBJ2018</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Two datasets from Beijing Subway are used in the experiments, as shown in Table1. The first dataset is MetroBJ2016, which is collected fromFebruary 29, 2016, to April 3, 2016.    </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">Data description</cell></row><row><cell>Description</cell><cell>The first AFC data</cell><cell>The second AFC data</cell></row><row><cell>Date</cell><cell>February 29, 2016, to April 3, 2016</cell><cell>October 8, 2018, to November 11, 2018</cell></row><row><cell>Time in a day</cell><cell>05:00 to 23:00</cell><cell>05:00 to 23:00</cell></row><row><cell>Line number</cell><cell>17</cell><cell>22</cell></row><row><cell>Station number</cell><cell>276</cell><cell>308</cell></row><row><cell>Time interval</cell><cell>15</cell><cell>15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>shows that</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="4">Comparison of performances of different models</cell></row><row><cell>models</cell><cell>RMSE</cell><cell cols="2">MetroBJ2016 MAE WMAPE</cell><cell>RMSE</cell><cell>MetroBJ2018 MAE WMAPE</cell></row><row><cell>ARIMA</cell><cell cols="2">81.4562 42.8006</cell><cell>16.159%</cell><cell cols="2">69.4250 33.9540 17.431%</cell></row><row><cell>LSTM</cell><cell cols="2">41.5995 23.8519</cell><cell>8.991%</cell><cell cols="2">35.9800 17.9691</cell><cell>9.203%</cell></row><row><cell>CNN</cell><cell cols="2">39.6387 23.2622</cell><cell>8.765%</cell><cell cols="2">34.5978 17.9192</cell><cell>9.193%</cell></row><row><cell>ST-Resnet</cell><cell cols="2">38.8923 22.4507</cell><cell>8.468%</cell><cell cols="2">35.1211 17.8985</cell><cell>9.162%</cell></row><row><cell cols="3">Conv-LSTM 36.0977 20.9608</cell><cell>7.910%</cell><cell cols="2">34.7646 17.2812</cell><cell>8.863%</cell></row><row><cell>Conv-GCN</cell><cell cols="2">35.2723 20.7382</cell><cell>7.747%</cell><cell cols="2">34.1104 17.0581</cell><cell>8.652%</cell></row><row><cell>GAN</cell><cell cols="2">35.8525 20.8074</cell><cell>7.857%</cell><cell cols="2">33.7604 17.1859</cell><cell>8.816%</cell></row><row><cell cols="3">Graph-GAN 34.6653 20.3786</cell><cell>7.693%</cell><cell cols="2">32.9536 16.6860</cell><cell>8.549%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>Number of Trainable Parameters models</figDesc><table><row><cell></cell><cell cols="2">Number of Trainable Parameters</cell></row><row><cell></cell><cell>MetroBJ2016</cell><cell>MetroBJ2018</cell></row><row><cell>ST-Resnet</cell><cell>23.28M</cell><cell>25.92M</cell></row><row><cell>Conv-GCN</cell><cell>18.28M</cell><cell>22.77M</cell></row><row><cell>Conv-LSTM</cell><cell>26.11M</cell><cell>29.07M</cell></row><row><cell>GAN</cell><cell>9.15M</cell><cell>10.15M</cell></row><row><cell>Graph-GAN</cell><cell>9.15M</cell><cell>10.15M</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We wish to thank the anonymous reviewers for the valuable comments, suggestions, and discussions. This work was supported by the Fundamental Research Funds for the Central Universities (No. 2021RC270) and the National Natural Science Foundation of China (Nos. 71621001, 71825004).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1. The comparison of the prediction performance between the Graph-GAN and GAN proves that the simplified and static GCN is effective in capturing topological information of the URT networks.</p><p>2. The Graph-GAN only composed of simple fully connected neural networks achieves the best prediction performance, showing that it is not the more complex the better for the deep learning-based prediction models, it is the more appropriate the better.</p><p>3. The results tested on two real-world datasets indicate that the Graph-GAN achieves the best prediction performance and robustness with the fewest model parameters, showing significant potential to be applied in the real world from the application perspective.</p><p>However, there are several limitations to our study. For example, we did not consider weekend passenger flows because of substantial fluctuations and fewer regularities.</p><p>Moreover, multi-source data, such as weather conditions, road congestion, and accidents, could also be explored in the future. Besides, it would be interesting to further study whether the proposed model can be applied to other spatial-temporal data mining tasks, such as trajectory prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflicts of Interest</head><p>The authors declare no conflict of interest.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Incorporating travel behavior regularity into passenger flow forecasting</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Trépanier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page">103200</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Prediction of cityscale dynamic taxi origin-destination flows using a hybrid deep neural network combined with travel time</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="127816" to="127832" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Few-shot learning with graph neural networks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04043</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adaptive Kalman filter approach for stochastic short-term traffic flow rate prediction and uncertainty quantification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="50" to="64" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Spatio-temporal recurrent convolutional networks for citywide short-term crowd flows prediction</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Compute and Data Analysis</title>
				<meeting>the 2nd International Conference on Compute and Data Analysis</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="28" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Short-term forecasting of passenger demand under on-demand ride services: A spatio-temporal deep learning approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="591" to="608" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Photo-realistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Huszar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4681" to="4690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">GCN-GAN: A non-linear temporal link prediction model for weighted dynamic networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM 2019 -IEEE Conference on Computer Communications</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="388" to="369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multistep traffic forecasting by dynamic graph convolution: Interpretations of real-time spatial correlations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Knoop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Van Lint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page">103185</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deepgcns: Can gcns go as deep as cnns?</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
				<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="9267" to="9276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deeper insights into graph convolutional networks for semisupervised learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI conference on artificial intelligence</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Short-term traffic flow forecasting: an experimental comparison of time-series analysis and supervised learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lippi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="871" to="882" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">DeepPF: A deep learning based architecture for metro passenger flow prediction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="18" to="34" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A tailored machine learning approach for urban transport network flow estimation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="130" to="150" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Semantic segmentation using adversarial networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Luc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.08408</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Temporal multi-graph convolutional network for traffic flow prediction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3337" to="3348" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Short-term traffic flow prediction for urban road sections based on time series analysis and LSTM_BILSTM Method</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Early access</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Input data selection for daily traffic flow forecasting through contextual mining and intra-day pattern recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">B</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="page">114902</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning traffic as images: a deep convolutional neural network for large-scale transportation network speed prediction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">818</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Long short-term memory neural network for traffic speed prediction using remote microwave sensor data</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="187" to="197" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Encoding sentences with graph convolutional networks for semantic role labeling</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.04826</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Adversarial training methods for semisupervised text classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07725</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Short-term demand forecasting for online car-hailing services using recurrent neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nejadettehad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mahini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bahrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Predictive decision support platform and its application in crowding prediction and passenger information generation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Noursalehi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Koutsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page">103139</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dynamic graph convolutional network for long-term traffic flow prediction with reinforcement learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">578</biblScope>
			<biblScope unit="page" from="401" to="416" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Severity prediction of traffic accidents with recurrent neural networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Sameen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pradhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences-Basel</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">476</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Convolutional LSTM network: A machine learning approach for precipitation nowcasting</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Woo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="802" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A short-term traffic flow prediction model based on an improved gate recurrent unit neural network</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Early access</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Hybrid GA based online support vector machine model for short-term traffic flow forecasting</title>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Advanced Parallel Processing Technologies</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="743" to="752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Passenger flow prediction of subway transfer stations based on nonparametric regression model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Discrete Dynamics in Nature and Society</title>
		<imprint>
			<biblScope unit="volume">2014</biblScope>
			<biblScope unit="page">397154</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Network traffic prediction based on improved BP wavelet neural network</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 4th International Conference on Wireless Communications, Networking and Mobile Computing</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">SeqST-GAN: Seq2Seq generative adversarial nets for multi-step urban crowd flow prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Spatial Algorithms and Systems</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>TSAS)</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Forecasting of short-term metro ridership with support vector machine online model</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Advanced Transportation</title>
		<imprint>
			<biblScope unit="volume">2018</biblScope>
			<biblScope unit="page">3189238</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multivariate vehicular traffic flow prediction: Evaluation of ARIMAX modeling</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Record</title>
		<imprint>
			<biblScope unit="volume">1776</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="194" to="200" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Urban freeway traffic flow prediction: Application of seasonal autoregressive integrated moving average and exponential smoothing models</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Durvasula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Record</title>
		<imprint>
			<biblScope unit="volume">1644</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="132" to="141" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Spatiotemporal dynamic forecasting and analysis of regional traffic flow in urban road networks using deep learning convolutional neural network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Early access</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">GE-GAN: A novel deep learning framework for traffic state estimation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page">102635</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Traj-ARIMA: A spatial-time series model for network-constrained trajectory</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">X</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Workshop on Computational Transportation Science</title>
				<meeting>the Third International Workshop on Computational Transportation Science</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="11" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Road traffic prediction using context-aware random forest based on volatility nature of traffic flows</title>
		<author>
			<persName><forename type="first">N</forename><surname>Zarei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ghayour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hashemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Intelligent Information and Database Systems</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Short-term origin-destination demand prediction in urban rail transit systems: A channel-wise attentive split-convolutional neural network method</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page">102928</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Multi-graph convolutional network for short-term passenger flow forecasting in urban rail transit</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Intelligent Transport Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1210" to="1217" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep-learning architecture for short-term passenger flow forecasting in urban rail transit</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ieee Transactions On Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="7004" to="7014" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep spatio-temporal residual networks for citywide crowd flows prediction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-first AAAI conference on artificial intelligence</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A novel generative adversarial network for estimation of trip travel time distribution with trajectory data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="223" to="244" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Seasonal autoregressive integrated moving average and support vector machine models prediction of short-term traffic flow on freeways</title>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Record</title>
		<imprint>
			<biblScope unit="issue">2215</biblScope>
			<biblScope unit="page" from="85" to="92" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A graph-based temporal attention framework for multi-sensor traffic flow forecasting</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Early access</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A hybrid short-term traffic flow forecasting method based on spectral analysis and statistical volatility model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Haghani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="65" to="78" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">K</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Spatiotemporal multi-graph</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
