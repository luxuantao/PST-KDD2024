<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Debiased Contrastive Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-07-05">5 Jul 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ching-Yao</forename><surname>Chuang</surname></persName>
							<email>cychuang@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CSAIL</orgName>
								<orgName type="institution" key="instit2">Massachusetts Institute of Technology</orgName>
								<address>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joshua</forename><surname>Robinson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CSAIL</orgName>
								<orgName type="institution" key="instit2">Massachusetts Institute of Technology</orgName>
								<address>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lin</forename><surname>Yen-Chen</surname></persName>
							<email>yenchenl@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CSAIL</orgName>
								<orgName type="institution" key="instit2">Massachusetts Institute of Technology</orgName>
								<address>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
							<email>torralba@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CSAIL</orgName>
								<orgName type="institution" key="instit2">Massachusetts Institute of Technology</orgName>
								<address>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CSAIL</orgName>
								<orgName type="institution" key="instit2">Massachusetts Institute of Technology</orgName>
								<address>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Debiased Contrastive Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-07-05">5 Jul 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2007.00224v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A prominent technique for self-supervised representation learning has been to contrast semantically similar and dissimilar pairs of samples. Without access to labels, dissimilar (negative) points are typically taken to be randomly sampled datapoints, implicitly accepting that these points may, in reality, actually have the same label. Perhaps unsurprisingly, we observe that sampling negative examples from truly different labels improves performance, in a synthetic setting where labels are available. Motivated by this observation, we develop a debiased contrastive objective that corrects for the sampling of same-label datapoints, even without knowledge of the true labels. Empirically, the proposed objective consistently outperforms the state-of-the-art for representation learning in vision, language, and reinforcement learning benchmarks. Theoretically, we establish generalization bounds for the downstream classification task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Learning good representations without supervision has been a long-standing goal of machine learning. One such approach is self-supervised learning, where auxiliary learning objectives leverage labels that can be observed without a human labeler. For instance, in computer vision, representations can be learned from colorization <ref type="bibr" target="#b37">[38]</ref>, predicting transformations <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26]</ref>, or generative modeling <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b19">20]</ref>. Remarkable success has also been achieved in the language domain <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>Recently, self-supervised representation learning algorithms that use a contrastive loss have outperformed even supervised learning <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b23">24]</ref>. The key idea of contrastive learning is to contrast semantically similar (positive) and dissimilar (negative) pairs of data points, encouraging the representations f of similar pairs (x, x + ) to be close, and those of dissimilar pairs (x, x − ) to be more orthogonal:</p><formula xml:id="formula_0">E x,x + ,{x − i } N i=1   − log e f (x) T f (x + ) e f (x) T f (x + ) + ∑ N i=1 e f (x) T f (x − i )   .<label>(1)</label></formula><p>In practice, the expectation is replaced by the empirical estimate. For each training data point x, it is common to use one positive example, e.g., derived from perturbations, and N negative examples x − i . Since true labels or true semantic similarity are typically not available, negative counterparts x − i are commonly drawn uniformly from the training data. But, this means it is possible that x − is actually similar to x, as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>. This phenomenon, which we refer to as sampling bias, can empirically lead to significant performance drop. Figure <ref type="figure" target="#fig_1">2</ref> compares the accuracy for learning with this bias, and for drawing x − i from data with truly different labels than x; we refer to this method as unbiased (further details in Section 5.1).</p><p>However, the ideal unbiased objective is unachievable in practice since it requires knowing the labels, i.e. learning is supervised. This dilemma poses the question whether it is possible to reduce the gap between the ideal objective and standard contrastive learning, without supervision. In this work, we false negative sample  demonstrate that this is indeed possible, while still assuming only access to unlabeled training data and positive examples. In particular, we develop a correction for the sampling bias that yields a new, modified loss which we call the debiased contrastive loss. The key idea underlying our approach is to indirectly approximate the distribution of negative examples. The new objective is easily compatible with any algorithm that optimizes the standard contrastive loss. Empirically, our approach improves over the state of the art in vision, language and reinforcement learning benchmarks.</p><p>Our theoretical analysis relates the debiased contrastive loss to supervised learning: optimizing the debiased contrastive loss corresponds to minimizing an upper bound on a supervised loss. This leads to a generalization bound for the supervised task, when training with the debiased contrastive loss. In short, this work makes the following contributions:</p><p>• We develop a new, debiased contrastive objective that corrects for the sampling bias of negative examples, while only assuming access to positive examples and the unlabeled data;</p><p>• We evaluate our approach via experiments in vision, language, and reinforcement learning;</p><p>• We provide a theoretical analysis of the debiased contrastive representation with generalization guarantees for a resulting classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Contrastive Representation Learning. The contrastive loss has recently become a prominent technique in unsupervised representation learning, achieving state-of-the-art results. The main difference between approaches to contrastive learning lies in their strategy of obtaining positive pairs. Examples in computer vision include random cropping and flipping <ref type="bibr" target="#b26">[27]</ref>, or different views of the same scene <ref type="bibr" target="#b32">[33]</ref>. Chen et al. <ref type="bibr" target="#b1">[2]</ref> extensively study verious data augmentation methods. For language, Logeswaran and Lee <ref type="bibr" target="#b23">[24]</ref> treat the context sentences as positive samples to efficiently learn sentence representations. Srinivas et al. <ref type="bibr" target="#b30">[31]</ref> improve the sample efficiency of reinforcement learning with representations learned via the contrastive loss. Computational efficiency has been improved by maintaining a dictionary of negative examples <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16]</ref>. Concurrently, Wang and Isola <ref type="bibr" target="#b34">[35]</ref> analyze the asymptotic contrastive loss and propose new metrics to measure the representation quality. All of these works sample negative examples from p(x). Arora et al. <ref type="bibr" target="#b0">[1]</ref> theoretically analyze the effect of contrastive representation learning on a downstream, "average" classification task and provide a generalization bound for the standard objective. They too point out the sampling bias as a problem, but do not propose models to address it.</p><p>Positive-unlabeled Learning. Since we approximate the contrastive loss with only unlabeed data from p(x) and positive examples, our work is also related to Positive-Unlabeled (PU) learning, i.e., learning from only positive (P) and unlabeled (U) data. Common applications of PU learning are retrieval or outlier detection <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref>. Our approach is related to unbiased PU learning, where the unlabeled data is used as negative examples, but down-weighted appropriately <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b21">22]</ref>. While these works focus on zero-one losses, we here address the contrastive loss, where existing PU estimators are not directly applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Setup and Sampling Bias in Contrastive Learning</head><p>Contrastive learning assumes access to semantically similar pairs of data points (x, x + ), where x is drawn from a data distribution p(x) over X . The goal is to learn an embedding f : X → R d that maps an observation x to a point on a hypersphere with radius 1/t, where t is the temperature scaling hyperparameter. Without loss of generality, we set t = 1 for all theoretical results.</p><p>Similar to <ref type="bibr" target="#b0">[1]</ref>, we assume an underlying set of discrete latent classes C that represent semantic content, i.e., similar pairs (x, x + ) have the same latent class. Denoting the distribution over classes by ρ(c), we obtain the joint distribution p x,c (x, c) = p(x|c)ρ(c). Let h : X → C be the function assigning the latent class labels. Then p +</p><p>x (x ) = p(x |h(x ) = h(x)) is the probability of observing x as a positive example for x and p − x (x ) = p(x |h(x ) = h(x)) the probability of a negative example. We assume that the class probabilities ρ(c) = τ + are uniform, and let τ − = 1 − τ + be the probability of observing any different class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sampling Bias</head><p>Intuitively the contrastive loss will provide most informative representations for downstream classification tasks if the positive and negative pairs correspond to the desired latent classes. Hence, the ideal loss to optimize would be</p><formula xml:id="formula_1">L N Unbiased ( f ) = E x∼p,x + ∼p + x x − i ∼p − x   − log e f (x) T f (x + ) e f (x) T f (x + ) + Q N ∑ N i=1 e f (x) T f (x − i )   ,<label>(2)</label></formula><p>which we will refer to as the unbiased loss. Here, we introduce a weighting parameter Q for the analysis. When the number N of negative examples is finite, we set Q = N, in agreement with the standard contrastive loss. However, p −</p><formula xml:id="formula_2">x (x − i ) = p(x − i |h(x − i ) = h(x)</formula><p>) is not accessible in practice. The standard approach is thus to sample negative examples x − i from the (unlabeled) p(x) instead. We refer to the resulting loss as the biased loss L N Biased . When drawn from p(x) the sample x − i will come from the same class as x with probability τ + .</p><p>Lemma 1 shows that in the limit, the standard loss L N Biased upper bounds the ideal, unbiased loss. Lemma 1. For any embedding f and finite N, we have</p><formula xml:id="formula_3">L N Biased ( f ) ≥ L N Unbiased ( f ) + 0 ∧ E x∼p   log E x + ∼p + x exp f (x) f (x + ) E x − ∼p − x exp f (x) f (x − )   − e 3/2 π 2N . (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>where a ∧ b denotes the minimum of two real numbers a and b.</p><p>Recent works often use large N, e.g., N = 65536 in <ref type="bibr" target="#b15">[16]</ref>, making the last term negligible. While, in general, minimizing an upper bound on a target objective is a reasonable idea, two issues arise here: (1) the smaller the unbiased loss, the larger is the second term, widening the gap; and (2) the empirical results in Figure <ref type="figure" target="#fig_1">2</ref> and Section 5 show that minimizing the upper bound L N Biased and minimizing the ideal loss L N Unbiased can result in very different learned representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Debiased Contrastive Loss</head><p>Next, we derive a loss that is closer to the ideal L N Unbiased , while only having access to positive samples and samples from p. Figure <ref type="figure" target="#fig_1">2</ref> shows that the resulting embeddings are closer to those learned with L N Unbiased . We begin by decomposing the data distribution as</p><formula xml:id="formula_5">p(x ) = τ + p + x (x ) + τ − p − x (x ).</formula><p>An immediate approach would be to replace p − x in L N Unbiased with p − x (x ) = (p(x ) − τ + p + x (x ))/τ − and then use the empirical counterparts for p and p +</p><p>x . The resulting objective can be estimated with samples from only p and p +</p><p>x , but is computationally expensive for large N:</p><formula xml:id="formula_6">1 (τ − ) N N ∑ k=0 N k (−τ + ) k E x∼p,x + ∼p + x {x − i } k i=1 ∼p + x {x − i } N i=k+1 ∼p   − log e f (x) T f (x + ) e f (x) T f (x + ) + ∑ N i=1 e f (x) T f (x − i )   ,<label>(4)</label></formula><p>where</p><formula xml:id="formula_7">{x − i } j i=k = ∅ if k &gt; j.</formula><p>It also demands at least N positive samples. To obtain a more practical form, we consider the asymptotic form as the number N of negative examples goes to infinity. Lemma 2. For fixed Q and N → ∞, it holds that</p><formula xml:id="formula_8">E x∼p,x + ∼p + x {x − i } N i=1 ∼p − x N   − log e f (x) T f (x + ) e f (x) T f (x + ) + Q N ∑ N i=1 e f (x) T f (x − i )  <label>(5)</label></formula><formula xml:id="formula_9">−→ E x∼p x + ∼p + x   − log e f (x) T f (x + ) e f (x) T f (x + ) + Q τ − (E x − ∼p [e f (x) T f (x − ) ] − τ + E v∼p + x [e f (x) T f (v) ])   . (<label>6</label></formula><formula xml:id="formula_10">)</formula><p>The limiting objective <ref type="bibr" target="#b5">(6)</ref>, which we denote by L Q Debiased , still samples examples x − from p, but corrects for that with additional positive samples v. This essentially reweights positive and negative terms in the denominator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The empirical estimate of L Q</head><p>Debiased is much easier to compute than the straightforward objective (5). With N samples {u i } N i=1 from p and M samples {v i } M i=1 from p + x , we estimate the expectation of the secong term in the denominator as</p><formula xml:id="formula_11">g(x, {u i } N i=1 , {v i } M i=1 ) = max 1 τ − 1 N N ∑ i=1 e f (x) T f (u i ) − τ + 1 M M ∑ i=1 e f (x) T f (v i ) , e −1/t . (<label>7</label></formula><formula xml:id="formula_12">)</formula><p>We constrain the estimator g to be greater than its theoretical minimum e</p><formula xml:id="formula_13">−1/t ≤ E x − ∼p − x e f (x) T f (x − i )</formula><p>to prevent calculating the logarithm of a negative number. The resulting population loss with fixed N and M per data point is</p><formula xml:id="formula_14">L N,M Debiased ( f ) = E x∼p;x + ∼p + x {u i } N i=1 ∼p N {v i } N i=1 ∼p + x M − log e f (x) T f (x + ) e f (x) T f (x + ) + Ng(x, {u i } N i=1 , {v i } M i=1 )<label>(8)</label></formula><p>where, for simplicity, we set Q to the finite N. The class prior τ + can be estimated from data <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18]</ref> or treated as a hyperparameter. Theorem 3 bounds the error due to finite N and M as decreasing with rate O(N −1/2 + M −1/2 ).</p><p>Theorem 3. For any embedding f and finite N and M, we have</p><formula xml:id="formula_15">L N Debiased ( f ) − L N,M Debiased ( f ) ≤ e 3/2 τ − π 2N + e 3/2 τ + τ − π 2M .<label>(9)</label></formula><p>Empirically, the experiments in Section 5 also show that larger N and M consistently lead to better performance. In the implementations, we use a full empirical estimate for L N,M Debiased that averages the loss over T points x, for finite N, M.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section we evaluate our new objective L N Debiased empirically, and compare it to the standard loss L N Biased and the ideal loss L N Unbiased . In summary, we observe the following: (1) the new loss outperforms state of the art contrastive learning on vision, language and reinforcement learning benchmarks; (2) the learned embeddings are closer to those of the ideal, unbiased objective; (3) both larger N and large M improve the performance; even one more positive example than the standard M = 1 can help noticeably. Detailed experimental settings can be found in the appendix B. The code is available at https://github.com/chingyaoc/DCL. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">CIFAR10 and STL10</head><p>First, for CIFAR10 <ref type="bibr" target="#b22">[23]</ref> and STL10 <ref type="bibr" target="#b5">[6]</ref>, we implement SimCLR <ref type="bibr" target="#b1">[2]</ref> with ResNet-50 <ref type="bibr" target="#b14">[15]</ref> as the encoder architecture and use the Adam optimizer <ref type="bibr" target="#b18">[19]</ref> with learning rate 0.001 and weight decay 1e − 6. Following <ref type="bibr" target="#b1">[2]</ref>, we set the temperature t = 0.5 and the dimension of the latent vector to 128. All the models are trained for 400 epochs and evaluated by training a linear classifier after fixing the learned embedding.</p><p>To understand the effect of the sampling bias, we additionally consider an estimate of the ideal L N Unbiased , which is a supervised version of the standard loss, where negative examples x − i are drawn from the true p −</p><p>x , i.e., using known classes. Since STL10 is not fully labeled, we only use the unbiased objective on CIFAR10.</p><p>Debiased Objective with M = 1. For a fair comparison, i.e., no possible advantage from additional samples, we first examine our debiased objective with positive sample size M = 1 by setting v 1 = x + . Then, our approach uses exactly the same data batch as the biased baseline. The debiased objective can be implemented by a slight modification of code as Figure <ref type="figure" target="#fig_2">3</ref> shows. The results with different τ + are shown in Figure <ref type="figure" target="#fig_4">4(a,b</ref>). Increasing τ + in Objective <ref type="bibr" target="#b6">(7)</ref> leads to more correction, and gradually improves the performance in both benchmarks for different N. Remarkably, with only a slight modification to the loss, we improve the accuracy of SimCLR on STL10 by 4.26%. The performance of the debiased objective also improves by increasing the negative sample size N.  Debiased Objective with M ≥ 1. By Theorem 3, a larger M leads to a better estimate of the loss. To probe its effect, we sample M positive samples for each x (e.g., M times data augmentation) while fixing N = 510 and τ + = 0.1. The results for M = 1, 2, 4, 8 are shown in Figure <ref type="figure" target="#fig_4">4</ref>(c), and indicate that the performance of the debiased objective can indeed be further improved by increasing the number of positive samples. Surprisingly, with only one additional positive sample, the top-1 accuracy on STL10 can be significantly improved.</p><p>Figure <ref type="figure" target="#fig_5">5</ref> shows t-SNE visualizations of the representations learned by the biased and debiased objectives (N = 510) on CIFAR10. The debiased contrastive loss leads to better class separation than the contrastive loss, and the result is closer to that of the ideal, unbiased loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR10</head><p>Debiased M=8 Debiased M=1 Biased Unbiased The debiased objective (τ + = 0.1) leads to better data clustering than the (standard) biased loss; its effect is closer to the supervised unbiased objective. Following <ref type="bibr" target="#b32">[33]</ref>, we test our approach on ImageNet-100, a randomly chosen subset of 100 classes of Imagenet. Compared to CIFAR10, ImageNet-100 has more classes and hence smaller class probabilities τ + . We use contrastive multiview coding (CMC) <ref type="bibr" target="#b32">[33]</ref> as our contrastive learning baseline, and M = 1 for a fair comparison. The results in Table <ref type="table" target="#tab_0">1</ref> show that, although τ + is small, our debiased objective still improves over the biased baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">ImageNet-100</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Sentence Embeddings</head><p>Next, we test the debiased objective for learning sentence embeddings. We use the BookCorpus dataset <ref type="bibr" target="#b20">[21]</ref> and examine six classification tasks: movie review sentiment (MR) <ref type="bibr" target="#b28">[29]</ref>, product reviews (CR) <ref type="bibr" target="#b16">[17]</ref>, subjectivity classification (SUBJ) <ref type="bibr" target="#b27">[28]</ref>, opinion polarity (MPQA) <ref type="bibr" target="#b35">[36]</ref>, question type classification (TREC) <ref type="bibr" target="#b33">[34]</ref>, and paraphrase identification (MSRP) <ref type="bibr" target="#b7">[8]</ref>. Our experimental settings follow those for quick-thought (QT) vectors in <ref type="bibr" target="#b23">[24]</ref>.</p><p>In contrast to vision tasks, positive pairs here are chosen as neighboring sentences, which can form a different positive distribution than data augmentation. The minibatch of QT is constructed with a contiguous set of sentences, hence we can use the preceding and succeeding sentences as positive samples (M = 2). We retrain each model 3 times and show the mean in Table <ref type="table" target="#tab_2">2</ref>. The debiased objective improves over the baseline in 4 out of 6 downstream tasks, verifying that our objective also works for a different modality.</p><p>Objective  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Reinforcement Learning</head><p>Lastly, we consider reinforcement learning. We follow the experimental settings of Contrastive unsupervised representations for reinforcement learning (CURL) <ref type="bibr" target="#b30">[31]</ref> to perform image-based policy control on top of the learned contrastive representations. Similar to vision tasks, the positive pairs are two different augmentations of the same image. We again set M = 1 for a fair comparison. Methods are tested at 100k environment steps on the DeepMind control suite <ref type="bibr" target="#b31">[32]</ref>, which consists of several continuous control tasks. We retrain each model 3 times and show the mean and standard deviation in Table <ref type="table">3</ref>. Our method consistently outperforms the state-of-the-art baseline (CURL) in different control tasks, indicating that correcting the sampling bias also improves the performance and data efficiency of reinforcement learning. In several tasks, the debiased approach also has smaller variance. With more positive examples (M = 2), we obtain further improvements. </p><formula xml:id="formula_16">310±33 850±20 918±96 266±41 623±120 928±47 Debiased Objective with M = 1 Debiased (τ + = 0.01) 324±34 843±30 927±99 310±12 626±82 937±9 Debiased (τ + = 0.05) 308±57 866±7 916±114 284±20 613±22 945±13 Debiased (τ + = 0.1) 364±36 860±4 868±177 302±29 594±33 951±11 Debiased Objective with M = 2 Debiased (τ + = 0.01) 330±10 858±10 754±179 286±20 746±93 949±5 Debiased (τ + = 0.1) 381±24 864±6 904±117 303±5 671±75 957±5</formula><p>Table <ref type="table">3</ref>: Scores achieved by biased and debiased objectives. Our debiased objective outperforms the biased baseline (CURL) in all the environments, and often has smaller variance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Discussion</head><p>Class Distribution: Our theoretical results assume that the class distribution ρ is close to uniform. In reality, this is often not the case, e.g., in our experiments, CIFAR10 and Imagenet-100 are the only two datasets with perfectly balanced class distributions. Nevertheless, our debiased objective still consistently improves over the baselines even when the classes are not well balanced, indicating that the objective is robust to violations of the class balance assumption.</p><p>Positive Distribution: To remain unsupervised, our method and other contrastive losses only sample from the data distribution and a "surrogate" positive distribution, mimicked by data augmentations or context sentences. It is an interesting avenue of future work to adopt our debiased objective to a semi-supervised learning setting <ref type="bibr" target="#b36">[37]</ref> where true positive samples are accessible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Theoretical Analysis: Generalization Implications for Classification Tasks</head><p>Next, we relate the debiased contrastive objective to a supervised loss, and show how our contrastive learning approach leads to a generalization bound for a downstream supervised learning task. Our supervised task is a classification task T with K classes {c 1 , . . . , c K } ⊆ C. After contrastive representation learning, we fix the representations f (x) and then train a linear classifier q(x) = W f (x) on task T with the standard multiclass softmax cross entropy loss L Softmax (T , q). Hence, we define the supervised loss for the representation f as</p><formula xml:id="formula_17">L Sup (T , f ) = inf W∈R K×d L Softmax (T , W f ).<label>(10)</label></formula><p>In line with the approach of <ref type="bibr" target="#b0">[1]</ref> we analyze the supervised loss of a mean classifier <ref type="bibr" target="#b29">[30]</ref>, where for each class c, the rows of W are set to the mean of representations</p><formula xml:id="formula_18">µ c = E x∼p(•|c) [ f (x)</formula><p>]. We will use L µ Sup (T , f ) as shorthand for its loss. Note that L µ Sup (T , f ) is always an upper bound on L Sup (T , f ). To allow for uncertainty about the task T , we will bound the average supervised loss for a uniform distribution D over K-way classification tasks with classes in C.</p><formula xml:id="formula_19">L Sup ( f ) = E T ∼D L Sup (T , f ).<label>(11)</label></formula><p>We begin by showing that the asymptotic unbiased contrastive loss is an upper bound on the supervised loss of the mean classifier. Lemma 4. For any embedding f , whenever N ≥ K − 1 we have</p><formula xml:id="formula_20">L Sup ( f ) ≤ L µ Sup ( f ) ≤ L N Debiased ( f ).</formula><p>Lemma 4 uses the asymptotic version of the debiased loss. Together with Theorem 3 and a concentration of measure result, it leads to a generalization bound for debiased contrastive learning, as we show next. Generalization Bound. In practice, we use an empirical estimate L N,M Debiased , i.e., an average over T data points x, with M positive and N negative samples for each x. Our algorithm learns an empirical risk minimizer f ∈ arg min f ∈F L N,M Debiased ( f ) from a function class F . The generalization depends on the empirical Rademacher complexity R S (F ) of F with respect to our data sample S = {x j , x + j , {u i,j</p><formula xml:id="formula_21">} N i=1 , {v i,j } M i=1 } T j=1 . Let f |S = ( f k (x j ), f k (x + j ), { f k (u i,j )} N i=1 , { f k (v i,j )} M i=1 ) j∈[T],k∈[d] ∈ R (N+M+2</formula><p>)dT be the restriction of f onto S, using [T] = {1, . . . , T}. Then R S (F ) is defined as</p><formula xml:id="formula_22">R S (F ) := E σ sup f ∈F σ, f |S<label>(12)</label></formula><p>where σ ∼ {±1} (N+M+1)dT are Rademacher random variables. Combining Theorem 3 and Lemma 4 with a concentration of measure argument yields the final generalization bound for debiased contrastive learning.</p><p>Theorem 5. With probability at least 1 − δ, for all f ∈ F and N ≥ K − 1,</p><formula xml:id="formula_23">L Sup ( f ) ≤ L N,M Debiased ( f ) + O    1 τ − 1 N + τ + τ − 1 M + λR S (F ) T + B log 1 δ T    (<label>13</label></formula><formula xml:id="formula_24">)</formula><p>where λ = 1</p><formula xml:id="formula_25">(τ − ) 2 ( M N + 1) + (τ + ) 2 ( N M + 1) and B = log N 1 τ − + τ + .</formula><p>The bound states that if the function class F is sufficiently rich to contain some embedding for which L N,M Debiased is small, then the representation encoder f , learned from a large enough dataset, will perform well on the downstream classification task. The bound also highlights the role of the positive and unlabeled sample sizes M and N in the objective function, in line with the observation that a larger number of negative/positive examples in the objective leads to better results <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">16]</ref>. The last two terms in the bound grow slowly with N, but the effect of this on the generalization error is small if the dataset size T is much larger than N and M, as is commonly the case. The dependence on on N and T in Theorem 5 is roughly equivalent to the result in <ref type="bibr" target="#b0">[1]</ref>, but the two bounds are not directly comparable since the proof strategies differ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this work, we propose debiased contrastive learning, a new unsupervised contrastive representation learning framework that corrects for the bias introduced by the common practice of sampling negative (dissimilar) examples for a point from the overall data distribution. Our debiased objective consistently improves the state-of-the-art baselines in various benchmarks in vision, language and reinforcement learning. The proposed framework is accompanied by generalization guarantees for the downstream classification task. Interesting directions of future work include (1) trying the debiased objective in semi-supervised learning or few shot learning, and (2) studying the effect of how positive (similar) examples are drawn, e.g., analyzing different data augmentation techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Proofs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Proof of Lemma 1</head><p>Lemma 1. For any embedding f and finite N, we have</p><formula xml:id="formula_26">L N Biased ( f ) ≥ L N Unbiased ( f ) + 0 ∧ E x∼p   log E x + ∼p + x exp f (x) f (x + ) E x − ∼p − x exp f (x) f (x − )   − e 3/2 π 2N . (<label>14</label></formula><formula xml:id="formula_27">)</formula><p>where a ∧ b denotes the minimum of two real numbers a and b.</p><p>Proof. We use the notation h(x, x) = exp f (x) f ( x) for the critic. We will borrow Theorem 3 to prove this lemma. Setting τ + = 0, Theorem 3 states that</p><formula xml:id="formula_28">E x∼p x + ∼p + x − log h(x, x + ) h(x, x + ) + NE x − ∼p h(x, x − i )<label>(15)</label></formula><formula xml:id="formula_29">− E x∼p x + ∼p + x {x − i } N i=1 ∼p N − log h(x, x + ) h(x, x + ) + ∑ N i=1 h(x, x − i ) ≤ e 3/2 π 2N . (<label>16</label></formula><formula xml:id="formula_30">)</formula><p>Equipped with this inequality, the biased objective can be decomposed into the sum of the debiased objective and a second term as follows,</p><formula xml:id="formula_31">L N Biased ( f ) = E x∼p x + ∼p + x {x − i } N i=1 ∼p N − log h(x, x + ) h(x, x + ) + ∑ N i=1 h(x, x − i ) ≥ E x∼p x + ∼p + x − log h(x, x + ) h(x, x + ) + NE x − ∼p x h(x, x − ) − e 3/2 π 2N = E x∼p x + ∼p + x − log h(x, x + ) h(x, x + ) + NE x − ∼p − x h(x, x − ) + E x∼p x + ∼p + x log h(x, x + ) + NE x − ∼p x h(x, x − ) h(x, x + ) + NE x − ∼p − x h(x, x − ) − e 3/2 π 2N = L N Debiased ( f ) + E x∼p x + ∼p + x log h(x, x + ) + NE x − ∼p x h(x, x − ) h(x, x + ) + NE x − ∼p − x h(x, x − ) − e 3/2 π 2N = L N Debiased ( f ) + E x∼p x + ∼p + x log h(x, x + ) + τ − NE x − ∼p − x h(x, x − ) + τ + NE x − ∼p + x h(x, x − ) h(x, x + ) + τ − NE x − ∼p − x h(x, x − ) + τ + NE x − ∼p − x h(x, x − ) − e 3/2 π 2N . If E x − ∼p + x h(x, x − ) ≥ E x − ∼p − x h(x, x − ) then this expression can be lower bounded by L N Debiased ( f ) + log 1 = L N Debiased ( f ). Else, if E x − ∼p + x h(x, x − ) ≤ E x − ∼p − x h(x,</formula><p>x − ) then using the elementary fact that a+c b+c ≥ a b for a ≤ b and a, b, c ≥ 0, the expression can be lower bounded by,</p><formula xml:id="formula_32">L N Debiased ( f ) + E x∼p log E x − ∼p + x h(x, x − ) E x − ∼p − x h(x, x − ) − e 3/2 π 2N</formula><p>Bringing these two possibilities together we conclude that</p><formula xml:id="formula_33">L N Biased ( f ) ≥ L N Debiased ( f ) ∧ L N Debiased ( f ) + E x∼p log E x + ∼p + x h(x, x + ) E x − ∼p − x h(x, x − ) − e 3/2 π 2N</formula><p>where we replaced the dummy variable x − in the numerator by x + .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Proof of Lemma 2</head><p>Lemma 2. For fixed Q and N → ∞, it holds that</p><formula xml:id="formula_34">E x∼p,x + ∼p + x {x − i } N i=1 ∼p − x N   − log e f (x) T f (x + ) e f (x) T f (x + ) + Q N ∑ N i=1 e f (x) T f (x − i )   (17) −→ E x∼p x + ∼p + x   − log e f (x) T f (x + ) e f (x) T f (x + ) + Q τ − (E x − ∼p [e f (x) T f (x − ) ] − τ + E v∼p + x [e f (x) T f (v) ])   . (<label>18</label></formula><formula xml:id="formula_35">)</formula><p>Proof. Since the contrastive loss is bounded for finite Q, applying Dominated Convergence Theorem completes the proof.</p><p>lim</p><formula xml:id="formula_36">N→∞ E   − log e f (x) T f (x + ) e f (x) T f (x + ) + Q N ∑ N i=1 e f (x) T f (x − i )   =E   lim N→∞ − log e f (x) T f (x + ) e f (x) T f (x + ) + Q N ∑ N i=1 e f (x) T f (x − i )   (Dominated Convergence Theorem) =E   − log e f (x) T f (x + ) e f (x) T f (x + ) + QE x − ∼p − x e f (x) T f (x − )   .</formula><p>Since p − x (x ) = (p(x ) − τ + p + x (x ))/τ − and by the linearity of the expectation, we have</p><formula xml:id="formula_37">E x − ∼p − x e f (x) T f (x − ) = τ − (E x − ∼p [e f (x) T f (x − ) ] − τ + E x − ∼p + x [e f (x) T f (x − ) ]</formula><p>), which completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Proof of Theorem 3</head><p>In order to prove Theorem 3 we first seek a bound on the tail probability that the difference of the integrands of the asymptotic and non-asymptotic objective functions. That is we wish to bound the probability that the following quantity is greater than ε,</p><formula xml:id="formula_38">∆ = − log h(x, x + ) h(x, x + ) + Qg(x, {u i } N i=1 , {v i } M i=1 ) + log h(x, x + ) h(x, x + ) + QE x − ∼p − x h(x, x − ) .</formula><p>where we again write h(x, x) = exp f (x) f ( x) for the critic. Note that implicitly ∆ depends on x, x + and the collections {u i } N i=1 and {v i } M i=1 . Theorem A.2. Let x and x + in X be fixed. Further, let {u i } N i=1 and {v i } M i=1 be collections of i.i.d. random variables sampled from p and p +</p><p>x respectively. Then for all ε &gt; 0,</p><formula xml:id="formula_39">P(∆ ≥ ε) ≤ 2 exp − Nε 2 (τ − ) 2 2e 3 + 2 exp − Mε 2 (τ − /τ + ) 2 2e 3 .</formula><p>We delay the proof until after we prove Theorem 3; which we are ready to prove with this fact in hand.</p><p>Theorem 3. For any embedding f and finite N and M, we have</p><formula xml:id="formula_40">L N Debiased ( f ) − L N,M Debiased ( f ) ≤ e 3/2 τ − π 2N + e 3/2 τ + τ − π 2M .<label>(19)</label></formula><p>Proof. By Jensen's inequality we may push the absolute value inside the expectation to see that</p><formula xml:id="formula_41">| L N Unbiased ( f ) − L N,M Debiased ( f )| ≤ E∆.</formula><p>All that remains is to exploit the exponential tail bound of Theorem A.2.</p><p>To do this we write the expectation of ∆ for fixed x, x + as the integral of its tail probability,</p><formula xml:id="formula_42">E ∆ = E x,x + E[∆|x, x + ] = E x,x + ∞ 0 P(∆ ≥ ε|x, x + )dε ≤ ∞ 0 2 exp − Nε 2 (τ − ) 2 2e 3 dε + ∞ 0 2 exp − Mε 2 (τ − /τ + ) 2 2e 3 dε.</formula><p>The outer expectation disappears since the tail probably bound of Theorem A.2 holds uniformly for all fixed x, x + . Both integrals can be computed analytically using the classical identity</p><formula xml:id="formula_43">∞ 0 e −cz 2 dz = 1 2 π c .</formula><p>Applying the identity to each integral we finally obtain the claimed bound,</p><formula xml:id="formula_44">2e 3 π (τ − ) 2 N + 2e 3 π (τ − /τ + ) 2 M = e 3/2 τ − 2π N + e 3/2 τ + τ − 2π M .</formula><p>We still owe the reader a proof of Theorem A.2, which we give now.</p><p>Proof of Theorem A.2. We first decompose the probability as follows,</p><formula xml:id="formula_45">P − log h(x, x + ) h(x, x + ) + Qg(x, {u i } N i=1 , {v i } M i=1 ) + log h(x, x + ) h(x, x + ) + QE x − ∼p − x h(x, x − ) ≥ ε = P log h(x, x + ) + Qg(x, {u i } N i=1 , {v i } M i=1 ) − log h(x, x + ) + QE x − ∼p − x h(x, x − ) ≥ ε = P log h(x, x + ) + Qg(x, {u i } N i=1 , {v i } M i=1 ) − log h(x, x + ) + QE x − ∼p − x h(x, x − ) ≥ ε + P − log h(x, x + ) + Qg(x, {u i } N i=1 , {v i } M i=1 ) + log h(x, x + ) + QE x − ∼p − x h(x, x − ) ≥ ε</formula><p>where the final equality holds simply because |X| ≥ ε if and only if X ≥ ε or −X ≥ ε. Consider the first term; it can be bounded as follows,</p><formula xml:id="formula_46">P log h(x, x + ) + Qg(x, {u i } N i=1 , {v i } M i=1 ) − log h(x, x + ) + QE x − ∼p − x h(x, x − ) ≥ ε P log h(x, x + ) + Qg(x, {u i } N i=1 , {v i } M i=1 ) h(x, x + ) + QE x − ∼p − x h(x, x − ) ≥ ε ≤ P Qg(x, {u i } N i=1 , {v i } M i=1 ) − QE x − ∼p − x h(x, x − ) h(x, x + ) + QE x − ∼p − x h(x, x − ) ≥ ε = P g(x, {u i } N i=1 , {v i } M i=1 ) − E x − ∼p − x h(x, x − ) ≥ ε 1 Q h(x, x + ) + E x − ∼p − x h(x, x − ) ≤ P g(x, {u i } N i=1 , {v i } M i=1 ) − E x − ∼p − x h(x, x − ) ≥ εe −1 . (<label>20</label></formula><formula xml:id="formula_47">)</formula><p>The first inequality follows by applying the fact that log x ≤ x − 1 for x &gt; 0. The second inequality holds since 1</p><formula xml:id="formula_48">Q h(x, x + ) + E x − ∼p − x h(x, x − ) ≥ 1/e.</formula><p>Next we move on to bounding the second term, which proceeds similarly, using the same two bounds.</p><formula xml:id="formula_49">P − log h(x, x + ) + Qg(x, {u i } N i=1 , {v i } M i=1 ) + log h(x, x + ) + QE x − ∼p − x h(x, x − ) ≥ ε = P log h(x, x + ) + QE x − ∼p − x h(x, x − ) h(x, x + ) + Qg(x, {u i } N i=1 , {v i } M i=1 ) ≥ ε ≤ P QE x − ∼p − x h(x, x − ) − Qg(x, {u i } N i=1 , {v i } M i=1 ) h(x, x + ) + Qg(x, {u i } N i=1 , {v i } M i=1 ) ≥ ε = P E x − ∼p − x h(x, x − ) − g(x, {u i } N i=1 , {v i } M i=1 ) ≥ ε 1 Q h(x, x + ) + g(x, {u i } N i=1 , {v i } M i=1 ) ≤ P E x − ∼p − x h(x, x − ) − g(x, {u i } N i=1 , {v i } M i=1 ) ≥ εe −1 .<label>(21)</label></formula><p>Combining equation <ref type="bibr" target="#b19">(20)</ref> and equation ( <ref type="formula" target="#formula_49">21</ref>), we have</p><formula xml:id="formula_50">P(∆ ≥ ε) ≤ P g(x, {u i } N i=1 , {v i } M i=1 ) − E x − ∼p − x h(x, x − ) ≥ εe −1 .</formula><p>It therefore suffices to bound the right hand tail probability. We are bounding the tail of a difference of the form</p><formula xml:id="formula_51">| max(a, b) − c| where c ≥ b. Notice that | max(a, b) − c| ≤ |a − c|. If a &gt; b then this relation is obvious, while if a ≤ b we have | max(a, b) − c| = |b − c| = c − b ≤ c − a ≤ |a − c|.</formula><p>Using this elementary observation we can decompose the random variable whose tail we wish to control as follows,</p><formula xml:id="formula_52">g(x, {u i } N i=1 , {v i } M i=1 ) − E x − ∼p − x h(x, x − ) ≤ 1 τ − 1 N N ∑ i=1 Ex∼ph(x, u i ) − E x − ∼p x∼p h(x, x − ) + τ + τ − 1 M M ∑ i=1 Ex∼ph(x, v i ) − E x − ∼p + x x∼p h(x, x − )</formula><p>Using this observation we find that</p><formula xml:id="formula_53">P g(x, {u i } N i=1 , {v i } M i=1 ) − E x − ∼p − x h(x, x − ) ≥ εe −1 ≤ P 1 τ − 1 N N ∑ i=1 e f (x) T f (u i ) − τ + 1 M M ∑ i=1 e f (x) T f (v i ) − E x − ∼p − x h(x, x − ) ≥ εe −1 ≤ I(ε) + II(ε).</formula><p>where</p><formula xml:id="formula_54">I(ε) = P   1 τ − 1 N N ∑ i=1 h(x, u i ) − E x − ∼p h(x, x − ) ≥ εe −1 2   II(ε) = P   τ + τ − 1 M M ∑ i=1 h(x, v i ) − E x − ∼p + x h(x, x − ) ≥ εe −1 2   .</formula><p>Hoeffding's inequality states that if X, X 1 , . . . , X N are i.i.d random variables bounded in the range [a, b] then,</p><formula xml:id="formula_55">P   1 n N ∑ i=1 X i − EX ≥ ε   ≤ 2 exp − 2Nε 2 b − a</formula><p>In our particular case e −1 ≤ h(x, x) ≤ e, yielding the following bound on the tails of both terms, 3  and II(ε) ≤ 2 exp − Mε 2 (τ − /τ + ) 2 2e 3 .</p><formula xml:id="formula_56">I(ε) ≤ 2 exp − Nε 2 (τ − ) 2 2e</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Proof of Lemma 4</head><p>Lemma 4. For any embedding f , whenever N ≥ K − 1 we have</p><formula xml:id="formula_57">L Sup ( f ) ≤ L µ Sup ( f ) ≤ L N Debiased ( f ).</formula><p>Proof. We first show that N = K − 1 is the smallest loss:</p><formula xml:id="formula_58">L N Unbiased ( f ) = E x∼p x + ∼p + x   − log e f (x) T f (x + ) e f (x) T f (x + ) + NE x − ∼p − x e f (x) T f (x − )   ≥ E x∼p x + ∼p + x   − log e f (x) T f (x + ) e f (x) T f (x + ) + (K − 1)E x − ∼p − x e f (x) T f (x − )   = L K−1 Unbiased ( f )</formula><p>To show that L K−1 Unbiased ( f ) is an upper bound on the supervised loss L sup ( f ), we additionally introduce a task specific class distribution ρ T which is a uniform distribution over the classes in task T .</p><formula xml:id="formula_59">L K−1 Unbiased ( f ) = E x∼p x + ∼p + x   − log e f (x) T f (x + ) e f (x) T f (x + ) + (K − 1)E x − ∼p − x e f (x) T f (x − )   = E T ∼D E c∼ρ T ;x∼p(•|c) x + ∼p(•|c)   − log e f (x) T f (x + ) e f (x) T f (x + ) + (K − 1)E T ∼D E ρ T (c − ∼|c − =h(x)) E x − ∼p(•|c − ) e f (x) T f (x − )   ≥ E T ∼D E c∼ρ T ;x∼p(•|c)     − log e f (x) T E x + ∼p(•|c) f (x + ) e f (x) T E x + ∼p + x,T f (x + ) + (K − 1)E T ∼D E ρ T (c − |c − =h(x)) E x − ∼p(•|c − ) e f (x) T f (x − )     ≥ E T ∼D E c∼ρ T ;x∼p(•|c)   − log e f (x) T E x + ∼p(•|c) f (x + ) e f (x) T E x + ∼p(•|c) f (x + ) + (K − 1)E ρ T (c − |c − =h(x)) E x − ∼p(•|c − ) e f (x) T f (x − )   = E T ∼D E c∼ρ T ;x∼p(•|c)   − log e f (x) T E x + ∼p(•|c) f (x + ) e f (x) T E x + ∼p(•|c) f (x + ) + (K − 1)E ρ T (c − |c − =h(x)) E x − ∼p(•|c − ) e f (x) T f (x − )   ≥ E T ∼D E c∼ρ T ;x∼p(•|c)   − log e f (x) T E x + ∼p(•|c) f (x + ) e f (x) T E x + ∼p(•|c) f (x + ) + (K − 1)E ρ T (c − |c − =h(x)) e f (x) T E x − ∼p(•|c − ) f (x − )   = E T ∼D E c∼ρ T ;x∼p(•|c) − log exp( f (x) T µ c ) exp( f (x) T µ c ) + ∑ c − ∈T ,c − =c exp( f (x) T µ c − ) = E T ∼D L µ Sup (T , f ) = Lµ Sup ( f )</formula><p>where three inequalities follows from Jensen's inequality. The first and third inequality shift the expectations E x + ∼p +</p><p>x,T and E x − ∼p(•|c − ) , respectively, via the convexity of the functions and the second move the expectation E T ∼D out via the concavity. Note that LSup ( f ) ≤ Lµ Sup ( f ) holds trivially.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Proof of Theorem 5</head><p>We wish to derive a data dependent bound on the downstream supervised generalization error of the debiased contrastive objective. Recalling that a sample (x,</p><formula xml:id="formula_60">x + , {u i } N i=1 , {v i } M i=1 ) yields loss − log    e f (x) f (x + ) e f (x) f (x + ) + Ng(x, {u i } N i=1 , {v i } M i=1 )    = log 1 + N g(x, {u i } N i=1 , {v i } M i=1 ) e f (x) f (x + ) which is equal to f (x) f (u i ) − f (x + ) N i=1 , f (x) f (v i ) − f (x + ) M i=1</formula><p>where we define,</p><formula xml:id="formula_61">({a i } N i=1 , {b i } M i=1 ) = log    1 + N max 1 τ − 1 N N ∑ i=1 a i − τ + 1 M M ∑ i=1 b i , e −1    .</formula><p>In order to derive our bound we will exploit a concentration of measure result due to <ref type="bibr" target="#b0">[1]</ref>. They consider an objective of the form</p><formula xml:id="formula_62">L un ( f ) = E ({ f (x) f (x i ) − f (x + ) } k i=1 )</formula><p>where (x, x + , x − 1 , . . . , x − k ) are sampled from any fixed distribution on X k+2 (they were particularly focused on the case where x − i ∼ p, but the proof holds for arbitrary distributions). Let F be a class of representation functions X → R d such that f (•) ≤ R for R &gt; 0. The corresponding empirical risk minimizer is,</p><formula xml:id="formula_63">f ∈ arg min f ∈F 1 T T ∑ j=1 { f (x j ) f (x ji ) − f (x + ) } k i=1 over a training set S = {(x j , x + j , x − j1 , . . . , x − jk )} T j=1 of i.i.d. samples.</formula><p>The following result bounds the loss of the empirical risk minimizer.</p><p>Lemma A.3. [1] Let : R k → R be η-Lipschitz and bounded by B. Then with probability at least 1 − δ over the training set S = {(x j , x + j , x − j1 , . . . ,</p><formula xml:id="formula_64">x − jk )} T j=1 , for all f ∈ F L un ( f ) ≤ L un ( f ) + O    ηR √ kR S (F ) T + B log 1 δ T   <label>(22)</label></formula><p>where</p><formula xml:id="formula_65">R S (F ) = E σ∼{±1} (k+2)dT   sup f ∈F σ, f |S   ,<label>(23)</label></formula><formula xml:id="formula_66">and f |S = f t (x j ), f t (x + j ), f t (x − j1 ), . . . , , f t (x − jk ) j∈[T] t∈[d]</formula><p>.</p><p>In our context we have k = N + M and R = e. So, it remains to obtain constants η and B such that </p><formula xml:id="formula_67">({a i } N i=1 , {b i } M i=1 ) is η-Lipschitz,</formula><formula xml:id="formula_68">= e • 1 (τ − ) 2 N + (τ + ) 2 M , B = O log N 1 τ − + τ + .</formula><p>Proof. First it is easily observed that is upper bounded by plugging in a i = e and b i = e −1 , yielding a bound of,</p><formula xml:id="formula_69">log 1 + N max 1 τ − e − τ + e −1 , e −1 = O log N 1 τ − + τ + .</formula><p>To bound the Lipschitz constant we view as a composition</p><formula xml:id="formula_70">({a i } N i=1 , {b i } M i=1 ) = φ g ({a i } N i=1 , {b i } M i=1</formula><p>where 1 ,</p><p>1 Note the definition of g is slightly modified in this context.</p><formula xml:id="formula_71">φ(z) = log 1 + N max(z, e −1 ) g({a i } N i=1 , {b i } M i=1 ) = 1 τ − 1 N N ∑ i=1 a i − τ + 1 M M ∑ i=1 b i .</formula><p>If z &lt; e −1 then ∂ z φ(z) = 0, while if z ≥ e −1 then ∂ z φ(z) = N 1+Nz ≤ N 1+Ne −1 ≤ e. We therefore conclude that φ is e-Lipschitz. Meanwhile, ∂ a i g = 1 τ − N and ∂ b i g = τ + M . The Lipschitz constant of g is bounded by the Forbenius norm of the Jacobian of g, which equals,</p><formula xml:id="formula_72">N ∑ i=1 1 (τ − N) 2 + M ∑ j=1 (τ + ) 2 M 2 = 1 (τ − ) 2 N + (τ + ) 2 M .</formula><p>We are ready to prove theorem 5.</p><p>Theorem 5. With probability at least 1 − δ, for all f ∈ F and N ≥ K − 1,</p><formula xml:id="formula_73">L Sup ( f ) ≤ L µ Sup ( f ) ≤ L N,M Debiased ( f ) + O    1 τ − 1 N + τ + τ − 1 M + λR S (F ) T + B log 1 δ T   <label>(24)</label></formula><p>where λ = e f (x) T f (x + ) + ∑ N i=1 e f (x) T f (x − i )</p><p>.</p><p>We plug in the decomposition as follows:</p><formula xml:id="formula_74">E x∼p,x + ∼p + x {x − i } N i=1 ∼p − x [ (x, x + , {x − i } N i=1 , f )] = p(x)p + x (x + ) N ∏ i=1 p − x (x − i ) (x, x + , {x − i } N i=1 , f )dxdx + N ∏ i=1 dx − i = p(x)p + x (x + ) N ∏ i=1 p(x − i ) − τ + p + x (x − i ) τ − (x, x + , {x − i } N i=1 , f )dxdx + N ∏ i=1 dx − i = 1 (τ − ) N p(x)p + x (x + ) N ∏ i=1 p(x − i ) − τ + p + x (x − i ) (x, x + , {x − i } N i=1 , f )dxdx + N ∏ i=1 dx − i</formula><p>By the Binomial Theorem the product can be separated into N + 1 groups corresponding to how many x − i are sampled from p.</p><p>(1)</p><formula xml:id="formula_75">N ∏ i=1 p(x − i ) (2) N 1 (−τ + )p + x (x − 1 ) N ∏ i=2 p(x − i ) (3) N 2 2 ∏ j=1 (−τ + )p + x (x − j ) N ∏ i=3 p(x − i ) • • • (k + 1) N k k ∏ j=1 (−τ + )p + x (x − j ) N ∏ i=k+1 p(x − i ) • • • (N + 1) N ∏ i=1 (−τ + )p + x (x − i )</formula><p>In particular, the objective becomes</p><formula xml:id="formula_76">1 (τ − ) N N ∑ k=0 N k (−τ + ) k E x∼p,x + ∼p + x {x − i } k i=1 ∼p + x {x − i } N i=k+1 ∼p   − log e f (x) T f (x + ) e f (x) T f (x + ) + ∑ N i=1 e f (x) T f (x − i )   .</formula><p>where {x − i } j i=k = ∅ if k &gt; j. Note that this is exactly Inclusion-exclusion principle. The numerical value of this objective is extremely small when N is large. We tried various approaches to optimize this objective, e.g., hyperparameter tuning and pretraining, but none of them worked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Experiment Details</head><p>Cifar10 and STL10 We adopt PyTorch to implement SimCLR <ref type="bibr" target="#b1">[2]</ref> with Resnet-50 <ref type="bibr" target="#b14">[15]</ref> as the encoder architecture and use the Adam optimizer <ref type="bibr" target="#b18">[19]</ref> with learning rate 0.001 and weight decay 1e − 6. We set the temperature t as 0.5 and the dimension of the latent vector as 128. All the models are trained for 400 epochs. The PyTorch code for data augmentation is shown in Figure <ref type="figure">6</ref>. Note that a minibatch of N examples will result in 2N data points after augmentation. SimCLR treat the other 2(N − 1) augmented examples as negative samples.</p><p>The models are evaluated by training a linear classifier with cross entropy loss after fixing the learned embedding. We again use the Adam optimizer with learning rate 0.001 and weight decay 1e − 6.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: "Sampling bias": The common practice of drawing negative examples x − i from the data distribution p(x) may result in x − i that are actually similar to x.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Sampling bias leads to performance drop: Results on CIFAR-10 for drawing x − i from p(x) (biased) and from data with different labels, i.e., truly semantically different data (unbiased).</figDesc><graphic url="image-11.png" coords="2,328.03,66.24,180.01,135.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Pseudocode for debiased objective with M = 1. The implementation only requires a small modification of the code.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Negative Sample Size (N) Negative Sample Size (N) Top-1 Accuracy Positive Sample Size (M) (a) CIFAR10 (M=1) (b) STL10 (M=1) (c) Effect of Positive Samples</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Classification accuracy on CIFAR10 and STL10. (a,b) Biased and Debiased (M = 1) SimCLR with different negative sample size N where N = 2(BatchSize − 1). (c) Increasing the positive sample size M improves the performance of debiased SimCLR.</figDesc><graphic url="image-13.png" coords="6,231.81,67.00,171.29,128.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: t-SNE visualization of learned representations on CIFAR10. Classes are indicated by colors.The debiased objective (τ + = 0.1) leads to better data clustering than the (standard) biased loss; its effect is closer to the supervised unbiased objective.</figDesc><graphic url="image-19.png" coords="6,400.75,405.85,132.92,132.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>1 τ − 2 1 τA. 6</head><label>1216</label><figDesc>( M N + 1) + τ + 2 ( N M + 1) and B = log N 1 τ − + τ + .Proof. By Lemma 4 and Theorem 3 we haveL sup ( f ) ≤ L N Unbiased ( f ) ≤ L N,MDebiased ( .3 and Lemma A.<ref type="bibr" target="#b3">4</ref>, with probability at least 1 − δ, for all f ∈ F we haveL N,M Debiased ( f ) ≤ L N,M Debiased ( f ) + O − 2 ( M N + 1) + τ + 2 ( N M + 1) and B = log N 1 τ − + τ + Derivation of Equation (4) Let (x, x + , {x − i } N i=1 , f ) = − log e f (x) T f (x + )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>ImageNet</figDesc><table><row><cell>Objective</cell><cell cols="2">Top-1 Top-5</cell></row><row><cell>Biased (CMC)</cell><cell cols="2">73.58 92.06</cell></row><row><cell cols="3">Debiased (τ + = 0.005) 73.86 91.86</cell></row><row><cell>Debiased (τ + = 0.01)</cell><cell>74.6</cell><cell>92.08</cell></row></table><note>-100 Top-1 and Top-5 classification results.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Classification</figDesc><table /><note>accuracy on downstream tasks. We compare sentence representations on six classification tasks. 10-fold cross validation is used in testing the performance for binary classification tasks (MR, CR, SUBJ, MPQA)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>and bounded by B. Note that since we consider normalized embeddings f , we have f (•) ≤ 1 and therefore only need to consider the domain where e −1 ≤ a i , b i ≤ e. Suppose that e −1 ≤ a i , b i ≤ e. The function ({a i } N i=1 , {b i } M i=1 ) is η-Lipschitz, and bounded by B for</figDesc><table><row><cell>Lemma A.4. η</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements This work was supported by MIT-IBM Watson AI Lab. JR acknowledges support as a graduate research assistant from the NSF TRIPODS+X grant (number: 1839258). We thank Wei Fang, Tongzhou Wang, Wei-Chiu Ma, and Behrooz Tahmasebi for helpful discussions and suggestions.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Imagenet-100</head><p>We adopt the official code 2 of contrastive multiview coding (CMC) <ref type="bibr" target="#b32">[33]</ref>. To implement the debiased objective, we only modify the "NCE/NCECriterion.py" file and left the rest of the code unchanged. The temperature of CMC is set to 0.07, which often makes the estimator</p><p>less than e −1/t . To retain the learning signal, when the estimator is less than e −1/t , we will optimize the biased loss instead. This improves the convergence and stability of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence Embedding</head><p>We adopt the official code 3 of quick-thought (QT) vectors <ref type="bibr" target="#b23">[24]</ref>. To implement the debiased objective, we only modify the "src/s2v-model.py" file and left the rest of the code unchanged. Since the official BookCorpus <ref type="bibr" target="#b20">[21]</ref> dataset is missing, we use the unofficial version 4 for the experiments. The feature vector of QT is not normalized, therefore, we simply constrain the estimator described in equation ( <ref type="formula">7</ref>) to be greater than zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reinforcement Learning</head><p>We adopt the official code 5 of Contrastive unsupervised representations for reinforcement learning (CURL) <ref type="bibr" target="#b30">[31]</ref>. To implement the debiased objective, we only modify the "curl-sac.py" file and left the rest of the code unchanged. We again constrain the estimator described in equation <ref type="bibr" target="#b6">(7)</ref> to be greater than zero since the feature vector of CURL is not normalized.</p><p>2 https://github.com/HobbitLong/CMC/ 3 https://github.com/lajanugen/S2V 4 https://github.com/soskek/bookcorpus 5 https://github.com/MishaLaskin/curl</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A theoretical analysis of contrastive unsupervised representation learning</title>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrishikesh</forename><surname>Khandeparkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orestis</forename><surname>Plevrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikunj</forename><surname>Saunshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Infogan: Interpretable representation learning by information maximizing generative adversarial nets</title>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rein</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2172" to="2180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04297</idno>
		<title level="m">Improved baselines with momentum contrastive learning</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Class-prior estimation for learning from positive and unlabeled data</title>
		<author>
			<persName><forename type="first">Marthinus</forename><surname>Christoffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="221" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth international conference on artificial intelligence and statistics</title>
				<meeting>the fourteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources</title>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on Computational Linguistics</title>
				<meeting>the 20th international conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">350</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Discriminative unsupervised feature learning with convolutional neural networks</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jost</forename><surname>Tobias Springenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="766" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Convex formulation for learning from positive and unlabeled data</title>
		<author>
			<persName><forename type="first">Marthinus</forename><surname>Du Plessis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1386" to="1394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Analysis of learning from positive and unlabeled data</title>
		<author>
			<persName><forename type="first">Du</forename><surname>Marthinus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Plessis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masashi</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="703" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning classifiers from only positive and unlabeled data</title>
		<author>
			<persName><forename type="first">Charles</forename><surname>Elkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Noto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="213" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Estimating the class prior and posterior from noisy positives and unlabeled data</title>
		<author>
			<persName><forename type="first">Shantanu</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Predrag</forename><surname>Radivojac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2693" to="2701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Russ R Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Positive-unlabeled learning with non-negative risk estimator</title>
		<author>
			<persName><forename type="first">Ryuichi</forename><surname>Kiryo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Marthinus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masashi</forename><surname>Du Plessis</surname></persName>
		</author>
		<author>
			<persName><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1675" to="1685" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An efficient framework for learning sentence representations</title>
		<author>
			<persName><forename type="first">Lajanugen</forename><surname>Logeswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Representation learning with contrastive predictive coding</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd annual meeting on</title>
				<meeting>the 42nd annual meeting on</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">271</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd annual meeting on association for computational linguistics</title>
				<meeting>the 43rd annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4077" to="4087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Laskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.04136</idno>
		<title level="m">Curl: Contrastive unsupervised representations for reinforcement learning</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Tassa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yotam</forename><surname>Doron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alistair</forename><surname>Muldal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>De Las</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><surname>Budden</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.00690</idno>
		<title level="m">Abbas Abdolmaleki, Josh Merel, Andrew Lefrancq, et al. Deepmind control suite</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05849</idno>
		<title level="m">Contrastive multiview coding</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Understanding contrastive representation learning through alignment and uniformity on the hypersphere</title>
		<author>
			<persName><forename type="first">Tongzhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.10242</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Annotating expressions of opinions and emotions in language. Language resources and evaluation</title>
		<author>
			<persName><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="165" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">S4l: Self-supervised semi-supervised learning</title>
		<author>
			<persName><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
				<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1476" to="1485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Colorful image colorization</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="649" to="666" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
