<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Power of Deep Learning for Channel Estimation and Signal Detection in OFDM Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hao</forename><surname>Ye</surname></persName>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Geoffrey</forename><forename type="middle">Ye</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Fred</forename><surname>Juang</surname></persName>
						</author>
						<title level="a" type="main">Power of Deep Learning for Channel Estimation and Signal Detection in OFDM Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/LWC.2017.2757490</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article presents our initial results in deep learning for channel estimation and signal detection in orthogonal frequency-division multiplexing (OFDM) systems. In this article, we exploit deep learning to handle wireless OFDM channels in an end-to-end manner. Different from existing OFDM receivers that first estimate channel state information (CSI) explicitly and then detect/recover the transmitted symbols using the estimated CSI, the proposed deep learning based approach estimates CSI implicitly and recovers the transmitted symbols directly. To address channel distortion, a deep learning model is first trained offline using the data generated from simulation based on channel statistics and then used for recovering the online transmitted data directly. From our simulation results, the deep learning based approach can address channel distortion and detect the transmitted symbols with performance comparable to the minimum meansquare error (MMSE) estimator. Furthermore, the deep learning based approach is more robust than conventional methods when fewer training pilots are used, the cyclic prefix (CP) is omitted, and nonlinear clipping noise exists. In summary, deep learning is a promising tool for channel estimation and signal detection in wireless communications with complicated channel distortion and interference.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Orthogonal frequency-division multiplexing (OFDM) is a popular modulation scheme that has been widely adopted in wireless broadband systems to combat frequency-selective fading in wireless channels. Channel state information (CSI) is vital to coherent detection and decoding in OFDM systems. Usually, the CSI can be estimated by means of pilots prior to the detection of the transmitted data. With the estimated CSI, transmitted symbols can be recovered at the receiver.</p><p>Historically, channel estimation in OFDM systems has been thoroughly studied. The traditional estimation methods, i.e., least squares (LS) and minimum mean-square error (MMSE), have been utilized and optimized in various conditions <ref type="bibr" target="#b1">[2]</ref>. The method of LS estimation requires no prior channel statistics, but its performance may be inadequate. The MMSE estimation in general leads to much better detection performance by utilizing the second order statistics of channels.</p><p>In this article, we introduce a deep learning approach to channel estimation and symbol detection in an OFDM system. Deep learning and artificial neural networks (ANNs) have numerous applications. In particular, it has been successfully applied in localization based on CSI <ref type="bibr" target="#b2">[3]</ref>, channel equalization <ref type="bibr" target="#b4">[5]</ref>, and channel decoding <ref type="bibr" target="#b3">[4]</ref> in communication systems. With</p><p>The authors are with the Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, 30332 USA (e-mail: yehao@gatech.edu; liye@ece.gatech.edu; juang@ece.gatech.edu).</p><p>the improving computational resources on devices and the availability of data in large quantity, we expect deep learning to find more applications in communication systems.</p><p>ANNs have been demonstrated for channel equalization with online training, which is to adjust the parameters according to the online pilot data. However, such methods can not be applied directly since, with deep neural networks (DNNs), the number of parameters increased a lot, which requires a large number of training data together with the burden of a long training period. To address the issue, we train a DNN model that predicts the transmitted data in diverse channel conditions. Then the model is used in online deployment to recover the transmitted data.</p><p>This article presents our initial results in deep learning for channel estimation and symbol detection in an end-to-end manner. It demonstrates that DNNs have the ability to learn and analyze the characteristics of wireless channels that may suffer from nonlinear distortion and interference in addition to frequency selectivity. To the best of our knowledge, this is the first attempt to use learning methods to deal with wireless channels without online training. The simulation results show that deep learning models achieve performance comparable to traditional methods if there are enough pilots in OFDM systems, and it can work better with limited pilots, CP removal, and nonlinear noise. Our initial research results indicate that deep learning can be potentially applied in many directions in signal processing and communications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DEEP LEARNING BASED ESTIMATION AND DETECTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Deep Learning Methods</head><p>Deep learning has been successfully applied in a wide range of areas with significant performance improvement, including computer vision <ref type="bibr" target="#b5">[6]</ref>, natural language processing <ref type="bibr" target="#b6">[7]</ref>, speech recognition <ref type="bibr" target="#b7">[8]</ref>, and so on. A comprehensive introduction to deep learning and machine learning can be found in <ref type="bibr" target="#b0">[1]</ref>.</p><p>The structure of a DNN model is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Generally speaking, DNNs are deeper versions of ANNs by increasing the number of hidden layers in order to improve the ability in representation or recognition. Each layer of the network consists of multiple neurons, each of which has an output that is a nonlinear function of a weighted sum of neurons of its preceding layer, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. The nonlinear function may be the Sigmoid function, or the Relu function, defined as f S (a) = 1 1+e -a , and f R (a) = max(0, a), respectively. Hence, the output of the network z is a cascade of nonlinear transformation of input data I, mathematically expressed as</p><formula xml:id="formula_0">z = f (I, ?) = f (L-1) (f (L-2) (? ? ?f (1) (I))),<label>(1)</label></formula><p>where L stands for the number of layers and ? denotes the weights of the neural network. The parameters of the model are the weights for the neurons, which need to be optimized before the online deployment. The optimal weights are usually learned on a training set, with known desired outputs. The architecture of the OFDM system with deep learning based channel estimation and signal detection is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>. The baseband OFDM system is the same as the conventional ones. On the transmitter side, the transmitted symbols inserted with pilots are first converted to a paralleled data stream, then the inverse discrete Fourier transform (IDFT) is used to convert the signal from the frequency domain to the time domain. After that, a cyclic prefix (CP) is inserted to mitigate the inter-symbol interference (ISI). The length of the CP should be no shorter than the maximum delay spread of the channel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. System Architecture</head><p>We consider a sample-spaced multi-path channel described by complex random variables {h(n)} N -1 n=0 . The received signal can be expressed as</p><formula xml:id="formula_1">y(n) = x(n) ? h(n) + w(n),<label>(2)</label></formula><p>where ? denotes the circular convolution while x(n) and w(n) represent the transmitted signal and the additive white Gaussian noise (AWGN), respectively. After removing the CP and performing DFT, the received frequency domain signal is</p><formula xml:id="formula_2">Y (k) = X(k)H(k) + W (k),<label>(3)</label></formula><p>where Y (k), X(k), H(k), and W (k) are the DFT of y(n), x(n), h(n) and w(n), respectively. We assume that the pilot symbols are in the first OFDM block while the following OFDM blocks consist of the transmitted data. Together they form a frame. The channel can be treated as constant spanning over the pilot block and the data blocks, but change from one frame to another. The DNN model takes as input the received data consisting of one pilot block and one data block in our initial study, and recovers the transmitted data in an end-to-end manner.</p><p>As shown in Fig. <ref type="figure" target="#fig_1">2</ref>, to obtain an effective DNN model for joint channel estimation and symbol detection, two stages are included. In the offline training stage, the model is trained with the received OFDM samples that are generated with various information sequences and under diverse channel conditions with certain statistical properties, such as typical urban or hilly terrain delay profile. In the online deployment stage, the DNN model generates the output that recovers the transmitted data without explicitly estimating the wireless channel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Model Training</head><p>The models are trained by viewing OFDM modulation and the wireless channels as black boxes. Historically, researchers have developed many channel models that well describe the real channels in terms of channel statistics. With these channel models, the training data can be obtained by simulation. In each simulation, a random data sequence is first generated as the transmitted symbols and the corresponding OFDM frame is formed with a sequence of pilot symbols and the pilot symbols need to be fixed during the training and deployment stages. The current random channel is simulated based on the channel models. The received OFDM signal is obtained based on the OFDM frames undergoing the current channel distortion, including the channel noise. The received signal and the original transmitted data are collected as the training data. The input of deep learning model is the received data of the pilot block and one data block. The model is trained to minimize the difference between the output of the neural network and the transmitted data. The difference can be portrayed in several ways.</p><p>In our experiment settings, we choose the L 2 loss,</p><formula xml:id="formula_3">L 2 = 1 N k ( X(k) -X(k)) 2 ,<label>(4)</label></formula><p>where X(k) is the prediction and X(k) is the supervision message, which is the transmitted symbols in this situation.</p><p>The DNN model we use consists of five layers, three of which are hidden layers. The numbers of neurons in each layers are 256, 500, 250, 120, 16, respectively. The input number corresponds to the number of real parts and imaginary parts of 2 OFDM blocks that contain the pilots and transmitted </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SIMULATION RESULTS</head><p>We have conducted several experiments to demonstrate the performance of the deep learning methods for joint channel estimation and symbol detection in OFDM wireless communication systems. A DNN model is trained based on simulation data, and is compared with the traditional methods in term of bit-error rates (BERs) under different signal-to-noise ratios (SNRs). In the following experiments, the deep learning based approach is proved to be more robust than LS and MMSE under scenarios where fewer training pilots are used, the CP is omitted, or there is nonlinear clipping noise. In our experiments, an OFDM system with 64 sub-carriers and the CP of length 16 is considered. The wireless channel follows the wireless world initiative for new radio model (WINNER II) <ref type="bibr" target="#b8">[9]</ref>, where the carrier frequency is 2.6 GHz, the number of paths is 24, and typical urban channels with maximum delay 16 sampling period are used. QPSK is used as the modulation method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Impact of Pilot Numbers</head><p>The proposed method is first compared with the LS and MMSE methods for channel estimation and detection, when 64 pilots are used for channel estimation in each frame. From Fig. <ref type="figure" target="#fig_2">3</ref>, the LS method has the worst performance since no prior statistics of the channel has been utilized in the detection. On the contrary, the MMSE method has the best performance because the second-order statistics of the channels are assumed to be known and used for symbol detection. The deep learning based approach has much better performance than the LS method and is comparable to the MMSE method.</p><p>Since the channel model has a maximum delay of 16 sampling period, it can be estimated with much fewer pilots, leading to better spectrum utilization. When only 8 pilots are used, the first OFDM block consists of 8 pilots and transmitted data. The input and output of DNN remain unchanged. From Fig. <ref type="figure" target="#fig_2">3</ref>, when only 8 pilots are used, the BER curves of the LS and MMSE methods saturate when SNR is above 10 dB while the deep learning based method still has the ability to reduce its BER with increasing SNR, which demonstrates that the DNN is robust to the number of pilots used for channel estimation. The reason for the superior performance of the DNN is that the characteristics of the wireless channels can be learned based on the training data generated from the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Impact of CP</head><p>As indicated before, the CP is necessary to convert the linear convolution of the physical channel into circular convolution and mitigate ISI. But it costs time and energy for transmission. In this experiment, we investigate the performance with CP removal.</p><p>Fig. <ref type="figure" target="#fig_3">4</ref> illustrates the BER curves for an OFDM system without CP. From the figure, neither MMSE nor LS can effectively estimate channel. The accuracy tends to be saturated when SNR is over 15 dB. However, the deep learning method still works well. This result shows again that the characteristics of the wireless channel have been revealed and can be learned in the training stage by the DNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Impact of Clipping and Filtering Distortion</head><p>As indicated in <ref type="bibr" target="#b9">[10]</ref>, a notable drawback of OFDM is the high peak-to-average power ratio (PAPR). To reduce PAPR, the clipping and filtering approach serves as a simple and effective approach <ref type="bibr" target="#b9">[10]</ref>. However, after clipping, nonlinear noise is introduced that degrade the estimation and detection performance. The clipped signal becomes</p><formula xml:id="formula_4">x(n) = x(n), if |x(n)| ? A, Ae j?(n) , otherwise, (<label>5</label></formula><formula xml:id="formula_5">)</formula><p>where A is the threshold and ?(n) is the phase of x(n). Fig. <ref type="figure" target="#fig_4">5</ref> depicts the detection performance of the MMSE method and deep learning method when the OFDM system is contaminated with clipping noise. From the figure, when clipping ratio (CR = A/?, where ? is the root mean square of signal) is 1, the deep learning method is better than the MMSE  method when SNR is over 15 dB, proving that deep learning method is more robust to the nonlinear clipping noise.</p><p>Fig. <ref type="figure" target="#fig_5">6</ref> compares DNN with the MMSE method when all above adversities are combined together, i.e., only 8 pilots are used, the CP is omitted, and there is clipping noise. From the figure, DNN is much better than the MMSE method but has a gap with detection performance under ideal circumstance, as we have seen before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Robustness Analysis</head><p>In the simulation above, the channels in the online deployment stage are generated with the same statistics that are used in the offline training stage. However, in real-world applications, mismatches may occur between the two stages. Therefore, it is essential for the trained models to be relatively robust to these mismatches. In this simulation, the impact of variation in statistics of channel models used during training and deployment stages is analyzed. Fig. <ref type="figure" target="#fig_6">7</ref> shows the BER curves when the maximum delay and the number of paths in the test stage vary from the parameters used in the training stage described in the beginning of this section. From the figure, variations on statistics of channel models do not have significant damage on the performance of symbol detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSIONS</head><p>In this article, we have demonstrated our initial efforts to employ DNNs for channel estimation and symbol detection in an OFDM system. The model is trained offline based on the simulated data that view OFDM and the wireless channels as black boxes. The simulation results show that the deep learning method has advantages when wireless channels are complicated by serious distortion and interference, which proves that DNNs have the ability to remember and analyze the complicated characteristics of the wireless channels. For realworld applications, it is important for the DNN model to have a good generalization ability so that it can still work effectively when the conditions of online deployment do not exactly agree with the channel models used in the training stage. An initial experiment has been conducted in this article to illustrate the generalization ability of DNN model with respect to some parameters of the channel model. More rigorous analysis and more comprehensive experiments are left for the future work. In addition, for practical use, samples generated from the real wireless channels could be collected to retrain or fine-tune the model for better performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An example of deep learning models.</figDesc><graphic url="image-1.png" coords="2,61.56,53.49,225.90,163.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. System model.</figDesc><graphic url="image-2.png" coords="2,61.56,399.50,225.90,131.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. BER curves of deep learning based approach and traditional methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. BER curves without CP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. BER curves with clipping noise</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. BER curves when combining all adversities.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. BER curves with mismatches between training and deployment stages.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning in neural networks: An overview</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="85" to="117" />
			<date type="published" when="2015-01">Jan. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robust channel estimation for OFDM systems with rapid dispersive fading channels</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Cimini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Sollenberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="902" to="915" />
			<date type="published" when="1998-07">Jul. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">CSI-based fingerprinting for indoor localization: A deep learning approach</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pandey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Veh. Technol</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="763" to="776" />
			<date type="published" when="2017-01">2017. Jan. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning to decode linear codes using deep learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nachmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Beery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burshtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">54&apos;th Annual Allerton Conf. On Commun., Control and Computing</title>
		<meeting><address><addrLine>Mouticello, IL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-09">Sept. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adaptive equalization of finite nonlinear channels using multilayer perceptrons</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Grant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="107" to="119" />
			<date type="published" when="1990-06">Jun. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Learning phrase representations using RNN encoderdecoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1406.1078" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recurrent deep neural networks for robust speech recognition</title>
		<author>
			<persName><forename type="first">C</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H F</forename><surname>Juang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2014-05">May 2014</date>
			<biblScope unit="page" from="5532" to="5536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">IST-4-027756 WINNER II D1.1.2 v.1.1: WINNER II Channel Models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kyosti</surname></persName>
		</author>
		<ptr target="http://www.ist-winner.org" />
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Effects of clipping and filtering on the performance of OFDM</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Cimini</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comm. Lett</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="131" to="133" />
			<date type="published" when="1998-05">May 1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
