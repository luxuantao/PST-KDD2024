<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Marcus</forename><surname>Hutter</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Universal Induction &amp; Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Universal Induction &amp; Intelligence</orgName>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Machine learning is concerned with developing algorithms that learn from experience, build models of the environment from the acquired knowledge, and use these models for prediction. Machine learning is usually taught as a bunch of methods that can solve a bunch of problems (see my Introduction to SML last week). The following tutorial takes a step back and asks about the foundations of machine learning, in particular the (philosophical) problem of inductive inference, (Bayesian) statistics, and artificial intelligence. The tutorial concentrates on principled, unified, and exact methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table of Contents</head><p>The common principle to their solution is Occam's simplicity principle.</p><p>Based on Occam's and Epicurus' principle, Bayesian probability theory, and Turing's universal machine, Solomonoff developed a formal theory of induction. I describe the sequential/online setup considered in this tutorial and place it into the wider machine learning context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Marcus Hutter</head><p>-7 -Universal Induction &amp; Intelligence</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Philosophical Problems</head><p>• Does inductive inference work? Why? How?</p><p>• How to choose the model class?</p><p>• How to choose the prior?</p><p>• How to make optimal decisions in unknown environments?</p><p>• What is intelligence?</p><note type="other">Marcus Hutter -8 -Universal Induction &amp; Intelligence</note><p>On the Foundations of Machine Learning</p><p>• Example: Algorithm/complexity theory: The goal is to find fast algorithms solving problems and to show lower bounds on their computation time. Everything is rigorously defined: algorithm, Turing machine, problem classes, computation time, ...</p><p>• Most disciplines start with an informal way of attacking a subject. With time they get more and more formalized often to a point where they are completely rigorous. Examples: set theory, logical reasoning, proof theory, probability theory, infinitesimal calculus, energy, temperature, quantum field theory, ...</p><p>• Machine learning: Tries to build and understand systems that learn from past data, make good prediction, are able to generalize, act intelligently, ... Many terms are only vaguely defined or there are many alternate definitions. What is the probability p(1|1 d ) that the sun will rise tomorrow? (d = past # days sun rose, 1 =sun rises. 0 = sun will not rise)</p><p>• p is undefined, because there has never been an experiment that tested the existence of the sun tomorrow (ref. class problem).</p><p>• The p = 1, because the sun rose in all past experiments.</p><p>• p = 1 − , where is the proportion of stars that explode per day.</p><p>• p = d+1 d+2 , which is Laplace rule derived from Bayes rule. • Derive p from the type, age, size and temperature of the sun, even though we never observed another star with those exact properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion:</head><p>We predict that the sun will rise tomorrow with high probability independent of the justification. Example 2: Digits of a Computable Number</p><p>• Extend 14159265358979323846264338327950288419716939937?</p><p>• Looks random?!</p><p>• Frequency estimate: n = length of sequence. k i = number of occured i =⇒ Probability of next digit being i is i n . Asymptotically i n → 1 10 (seems to be) true. • But we have the strong feeling that (i.e. with high probability) the next digit will be 5 because the previous digits were the expansion of π.</p><p>• Conclusion: We prefer answer 5, since we see more structure in the sequence than just random digits.</p><p>-12 -Universal Induction &amp; Intelligence</p><p>Occam's Razor to the Rescue</p><p>• Is there a unique principle which allows us to formally arrive at a prediction which -coincides (always?) with our intuitive guess -or-even better, -which is (in some sense) most likely the best or correct answer?</p><p>• Yes! Occam's razor: Use the simplest explanation consistent with past data (and use it for prediction).</p><p>• Works! For examples presented and for many more.</p><p>• Actually Occam's razor can serve as a foundation of machine learning in general, and is even a fundamental principle (or maybe even the mere definition) of science.</p><p>• Problem: Not a formal/mathematical objective principle.</p><p>What is simple for one may be complicated for another.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Marcus Hutter</head><p>-13 -Universal Induction &amp; Intelligence</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Grue Emerald Paradox</head><p>Hypothesis 1: All emeralds are green.</p><p>Hypothesis 2: All emeralds found till y2010 are green, thereafter all emeralds are blue.</p><p>• Which hypothesis is more plausible? H1! Justification?</p><p>• Occam's razor: take simplest hypothesis consistent with data.</p><p>is the most important principle in machine learning and science. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem Setup</head><p>• Induction problems can be phrased as sequence prediction tasks.</p><p>• Classification is a special case of sequence prediction.</p><p>(With some tricks the other direction is also true)</p><p>• This tutorial focusses on maximizing profit (minimizing loss). We're not (primarily) interested in finding a (true/predictive/causal) model.</p><p>• Separating noise from data is not necessary in this setting! Bayesian Sequence Prediction: Abstract</p><p>The aim of probability theory is to describe uncertainty. There are various sources and interpretations of uncertainty. I compare the frequency, objective, and subjective probabilities, and show that they all respect the same rules, and derive Bayes' and Laplace's famous and fundamental rules. Then I concentrate on general sequence prediction tasks. I define the Bayes mixture distribution and show that the posterior converges rapidly to the true posterior by exploiting some bounds on the relative entropy. Finally I show that the mixture predictor is also optimal in a decision-theoretic sense w.r.t. any bounded loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Uncertainty and Probability</head><p>The aim of probability theory is to describe uncertainty.</p><p>Sources/interpretations for uncertainty:</p><p>• Frequentist: probabilities are relative frequencies. (e.g. the relative frequency of tossing head.)</p><p>• Objectivist: probabilities are real aspects of the world. (e.g. the probability that some atom decays in the next hour)</p><p>• Subjectivist: probabilities describe an agent's degree of belief. (e.g. it is (im)plausible that extraterrestrians exist)</p><note type="other">Marcus Hutter -21 -Universal Induction &amp; Intelligence</note><p>Frequency Interpretation: Counting</p><p>• The frequentist interprets probabilities as relative frequencies.</p><p>• If in a sequence of n independent identically distributed (i.i.d.) experiments (trials) an event occurs k(n) times, the relative frequency of the event is k(n)/n.</p><p>• The limit lim n→∞ k(n)/n is defined as the probability of the event.</p><p>• For instance, the probability of the event head in a sequence of repeatedly tossing a fair coin is 1 2 . • The frequentist position is the easiest to grasp, but it has several shortcomings:</p><p>• Problems: definition circular, limited to i.i.d, reference class problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Marcus Hutter -22 -Universal Induction &amp; Intelligence</head><p>Objective Interpretation: Uncertain Events</p><p>• For the objectivist probabilities are real aspects of the world.</p><p>• The outcome of an observation or an experiment is not deterministic, but involves physical random processes.</p><p>• The set Ω of all possible outcomes is called the sample space.</p><p>• It is said that an event E ⊂ Ω occurred if the outcome is in E.</p><p>• In the case of i.i.d. experiments the probabilities p assigned to events E should be interpretable as limiting frequencies, but the application is not limited to this case.</p><p>• (Some) probability axioms:</p><formula xml:id="formula_0">p(Ω) = 1 and p({}) = 0 and 0 ≤ p(E) ≤ 1. p(A ∪ B) = p(A) + p(B) − p(A ∩ B). p(B|A) = p(A∩B) p(A)</formula><p>is the probability of B given event A occurred.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Marcus Hutter -23 -Universal Induction &amp; Intelligence</head><p>Subjective Interpretation: Degrees of Belief</p><p>• The subjectivist uses probabilities to characterize an agent's degree of belief in something, rather than to characterize physical random processes.</p><p>• This is the most relevant interpretation of probabilities in AI.</p><p>• We define the plausibility of an event as the degree of belief in the event, or the subjective probability of the event.</p><p>• </p><formula xml:id="formula_1">ω ∈ Ω = {0, 1} ∞ Basic event: Γ x = {ω : ω 1 = x 1 , ..., ω n = x n } = set of all sequences starting with x.</formula><p>Data likelihood:</p><formula xml:id="formula_2">p θ (x) := p(Γ x |H θ ) = θ n 1 (1 − θ) n 0 .</formula><p>Bayes (1763): Uniform prior plausibility: p(θ)</p><formula xml:id="formula_3">:= p(H θ ) = 1 ( R 1 0 p(θ) dθ = 1 instead P i∈I p(H i ) = 1) Evidence: p(x) = 1 0 p θ (x)p(θ) dθ = 1 0 θ n 1 (1 − θ) n 0 dθ = n 1 !n 0 ! (n 0 +n 1 +1)!</formula><note type="other">Marcus Hutter -26 -Universal Induction &amp; Intelligence</note><p>Example: Bayes' and Laplace's Rule</p><p>Bayes: Posterior plausibility of θ after seeing x is:</p><formula xml:id="formula_4">p(θ|x) = p(x|θ)p(θ) p(x) = (n+1)! n 1 !n 0 ! θ n 1 (1−θ) n 0 .</formula><p>Laplace: What is the probability of seeing 1 after having observed x?</p><formula xml:id="formula_5">p(x n+1 = 1|x 1 ...x n ) = p(x1) p(x) = n 1 +1 n + 2</formula><p>Laplace believed that the sun had risen for 5000 years = 1'826'213 days, so he concluded that the probability of doomsday tomorrow is • Symmetry argument: It doesn't matter whether you switch, the expected gain is the same.</p><p>• Refutation: With probability p = 1/2, the other envelope contains twice/half the amount, i.e. if you switch your expected gain increases by a factor 1.25=(1/2)*2+(1/2)*(1/2).</p><p>• Present a Bayesian solution.</p><note type="other">Marcus Hutter -28 -Universal Induction &amp; Intelligence</note><p>The Bayes-Mixture Distribution ξ</p><p>• Assumption: The true (objective) environment µ is unknown.</p><p>• Bayesian approach: Replace true probability distribution µ by a Bayes-mixture ξ.</p><p>• Assumption: We know that the true environment µ is contained in some known countable (in)finite set M of environments.</p><p>• The Bayes-mixture ξ is defined as</p><formula xml:id="formula_6">ξ(x 1:m ) := ν∈M w ν ν(x 1:m ) with ν∈M w ν = 1, w ν &gt; 0 ∀ν</formula><p>• The weights w ν may be interpreted as the prior degree of belief that the true environment is ν, or k ν = ln w −1 ν as a complexity penalty (prefix code length) of environment ν.</p><p>• Then ξ(x 1:m ) could be interpreted as the prior subjective belief probability in observing x 1:m .</p><note type="other">Marcus Hutter -29 -Universal Induction &amp; Intelligence</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Convergence and Decisions</head><p>Goal: Given seq.</p><formula xml:id="formula_7">x 1:t−1 ≡ x &lt;t ≡ x 1 x 2 ...x t−1 , predict continuation x t . Expectation w.r.t. µ: E[f (ω 1:n )] := x∈X n µ(x)f (x) KL-divergence: D n (µ||ξ) := E[ln µ(ω 1:n ) ξ(ω 1:n ) ] ≤ ln w −1 µ ∀n Hellinger distance: h t (ω &lt;t ) := a∈X ( ξ(a|ω &lt;t ) − µ(a|ω &lt;t )) 2</formula><p>Rapid convergence:</p><formula xml:id="formula_8">∞ t=1 E[h t (ω &lt;t )] ≤ D ∞ ≤ ln w −1 µ &lt; ∞ implies ξ(x t |ω &lt;t ) → µ(x t |ω &lt;t ), i.e.</formula><p>ξ is a good substitute for unknown µ.</p><p>Bayesian decisions: Bayes-optimal predictor Λ ξ suffers instantaneous loss l Λ ξ t ∈ [0, 1] at t only slightly larger than the µ-optimal predictor Λ µ :</p><formula xml:id="formula_9">∞ t=1 E[( l Λ ξ t − l Λ µ t ) 2 ] ≤ ∞ t=1 2E[h t ] &lt; ∞ implies rapid l Λ ξ t → l Λ µ t .</formula><p>Pareto-optimality of Λ ξ : Every predictor with loss smaller than Λ ξ in some environment µ ∈ M must be worse in another environment.</p><note type="other">Marcus Hutter -30 -Universal Induction &amp; Intelligence Generalization: Continuous Classes M</note><p>In statistical parameter estimation one often has a continuous hypothesis class (e.g. a Bernoulli(θ) process with unknown θ ∈ [0, 1]).</p><formula xml:id="formula_10">M := {ν θ : θ ∈ IR d }, ξ(x) := I R d dθ w(θ) ν θ (x), I R d dθ w(θ) = 1</formula><p>Under weak regularity conditions [CB90,H'03]:</p><formula xml:id="formula_11">Theorem: D n (µ||ξ) ≤ ln w(µ) −1 + d 2 ln n 2π + O(1)</formula><p>where O(1) depends on the local curvature (parametric complexity) of ln ν θ , and is independent n for many reasonable classes, including all stationary (k th -order) finite-state Markov processes (k = 0 is i.i.d.). Bayesian Sequence Prediction: Summary</p><formula xml:id="formula_12">D n ∝ log(n) = o(n) still</formula><p>• The aim of probability theory is to describe uncertainty.</p><p>• Various sources and interpretations of uncertainty: frequency, objective, and subjective probabilities.</p><p>• They all respect the same rules.</p><p>• General sequence prediction: Use known (subj.) Bayes mixture ξ = ν∈M w ν ν in place of unknown (obj.) true distribution µ.</p><p>• Bound on the relative entropy between ξ and µ.</p><p>⇒ posterior of ξ converges rapidly to the true posterior µ.</p><p>• ξ is also optimal in a decision-theoretic sense w.r.t. any bounded loss function.</p><p>• No structural assumptions on M and ν ∈ M. The Universal Prior</p><p>• Quantify the complexity of an environment ν or hypothesis H ν by its Kolmogorov complexity K(ν).</p><p>• Universal prior:</p><formula xml:id="formula_13">w ν = w U ν := 2 −K(ν)</formula><p>is a decreasing function in the model's complexity, and sums to (less than) one.</p><formula xml:id="formula_14">⇒ D n ≤ K(µ) ln 2, i.e. the number of ε-deviations of ξ from µ or l Λ ξ</formula><p>from l Λ µ is proportional to the complexity of the environment.</p><p>• No other semi-computable prior leads to better prediction (bounds).</p><p>• For continuous M, we can assign a (proper) universal prior (not density) w U θ = 2 −K(θ) &gt; 0 for computable θ, and 0 for uncomp. θ. • This effectively reduces M to a discrete class {ν θ ∈ M : w U θ &gt; 0} which is typically dense in M.</p><p>• This prior has many advantages over the classical prior (densities). Universal Choice of Class M</p><p>• The larger M the less restrictive is the assumption µ ∈ M.</p><p>• The class M U of all (semi)computable (semi)measures, although only countable, is pretty large, since it includes all valid physics theories. Further,</p><formula xml:id="formula_15">ξ U is semi-computable [ZL70].</formula><p>• Solomonoff's universal prior M (x) := probability that the output of a universal TM U with random input starts with x.</p><p>• Formally: M (x) := p : U (p)=x * 2 − (p) where the sum is over all (minimal) programs p for which U outputs a string starting with x.</p><p>• M may be regarded as a 2 − (p) -weighted mixture over all deterministic environments ν p . (ν p (x) = 1 if U (p) = x * and 0 else)</p><p>• M (x) coincides with ξ U (x) within an irrelevant multiplicative constant. </p><formula xml:id="formula_16">E[h n ] × &lt; 1 n ln w(µ) −1 and E[h n ] × &lt; 1 n ln w −1 µ = 1 n K(µ) ln 2.</formula><p>• Bounds for computable environments: Rapidly M (x t |x &lt;t ) → 1 on every computable sequence x 1:∞ (whichsoever, e.g. 1 ∞ or the digits of π or e), i.e. M quickly recognizes the structure of the sequence. • Weak instantaneous bounds: valid for all n and x 1:n and xn = x n : </p><formula xml:id="formula_17">2 −K(n) × &lt; M (x n |x &lt;n ) × &lt; 2 2K(x 1:n * )−K(n) • Magic instance numbers: e.g. M (0|1 n ) × = 2 −K(n) → 0,</formula><formula xml:id="formula_18">+ = 0)</formula><p>2) A processed x is similar to x (K(f (x)|x)</p><formula xml:id="formula_19">+ = 0 if K(f ) = O(1)</formula><p>). e.g. doubling, reverting, inverting, encrypting, partially deleting x.</p><p>3) A random string is with high probability not similar to any other string (K(random|y) =length(random)).</p><p>The problem with K(x|y) as similarity=distance measure is that it is neither symmetric nor normalized nor computable.</p><note type="other">Marcus Hutter -48 -Universal Induction &amp; Intelligence</note><p>The Universal Similarity Metric</p><p>• Symmetrization and normalization leads to a/the universal metric d:</p><formula xml:id="formula_20">0 ≤ d(x, y) := max{K(x|y), K(y|x)} max{K(x), K(y)} ≤ 1</formula><p>• Every effective similarity between x and y is detected by d</p><formula xml:id="formula_21">• Use K(x|y) ≈ K(xy)−K(y) (coding T) and K(x) ≡ K U (x) ≈ K T (x)</formula><p>=⇒ computable approximation: Normalized compression distance:</p><formula xml:id="formula_22">d(x, y) ≈ K T (xy) − min{K T (x), K T (y)} max{K T (x), K T (y)} 1</formula><p>• For T choose Lempel-Ziv or gzip or bzip(2) (de)compressor in the applications below.</p><p>• Theory: Lempel-Ziv compresses asymptotically better than any probabilistic finite state automaton predictor/compressor.</p><p>Genomics &amp; Phylogeny: SARS Virus and Others </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Perfect classification!</head><p>The Agent Model </p><formula xml:id="formula_23">r 1 | o 1 r 2 | o 2 r 3 | o 3 r 4 | o 4 r 5 | o 5 r 6 | o 6 ...<label>y</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimal Policy and Value</head><p>The σ-optimal policy p σ := arg max p V p σ maximizes V p σ ≤ V * σ := V p σ σ . Explicit expressions for the action y k in cycle k of the σ-optimal policy p σ and their value V * σ are V * σ (yx 1:k y k+1 )</p><formula xml:id="formula_24">y k = arg max</formula><formula xml:id="formula_25">• • • • • • • • • • • • • • • • • • • • • • • • Marcus Hutter -69 - Universal Induction &amp; Intelligence</formula><p>Known environment µ</p><p>• Assumption: µ is the true environment in which the agent operates</p><p>• Then, policy p µ is optimal in the sense that no other policy for an agent leads to higher µ AI -expected reward.</p><p>• Special choices of µ: deterministic or adversarial environments, Markov decision processes (mdps), adversarial environments.</p><p>• There is no principle problem in computing the optimal action y k as long as µ AI is known and computable and X , Y and m are finite.</p><p>• Things drastically change if µ AI is unknown ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Questions of Interest</head><p>• It is natural to follow the policy p ξ which maximizes V p ξ . • If µ is the true environment the expected reward when following policy p ξ will be V p ξ µ .</p><p>• The optimal (but infeasible) policy p µ yields reward V p µ µ ≡ V * µ .</p><p>• Are there policies with uniformly larger value than V p ξ µ ?</p><p>• How close is V p ξ µ to V * µ ? • What is the most general class M and weights w ν .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>•</head><label></label><figDesc>On the Foundations of Machine Learning • Example 1: Probability of Sunrise Tomorrow • Example 2: Digits of a Computable Number • Example 3: Number Sequences • Occam's Razor to the Rescue • Grue Emerald and Confirmation Paradoxes • What this Tutorial is (Not) About • Sequential/Online Prediction -Setup considering the philosophical problems concerning machine learning in general and induction in particular. I illustrate the problems and their intuitive solution on various (classical) induction examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>•</head><label></label><figDesc>I offer you two closed envelopes, one of them contains twice the amount of money than the other. You are allowed to pick one and open it. Now you have two options. Keep the money or decide for the other envelope (which could double or half your gain).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>File Types Classification of files based on markedly different file types using bzip2 • Four mitochondrial gene sequences • Four excerpts from the novel "The Zeppelin's Passenger" • Four MIDI files without further processing • Two Linux x86 ELF executables (the cp and rm commands) • Two compiled Java class files No features of any specific domain of application are used!</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>y k x k max y k+1 x k+1 .</head><label>k+1</label><figDesc>.. max y m x m (r k + ... +r m )•σ(x k:m |y 1:m x &lt;k ), max y m x m (r 1 + ... +r m )•σ(x 1:m |y 1:m ). Keyword: Expectimax tree/algorithm. &lt;k y k ) action y k with max value. &lt;k y k ) = X x k [r k + V * σ (yx 1:k )]σ(x k |yx &lt;k y k )σ expected reward r k and observation o k .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-12.png" coords="80,593.72,166.56,199.73,299.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Let D be some possible data (i.e. D is event with p(D) &gt; 0) and {H i } i∈I be a countable complete class of mutually exclusive hypotheses (i.e. H i are events with H i ∩ H j = {} ∀i = j and i∈I H i = Ω).Finite sequence: x = x 1 x 2 ...x n with n 1 ones and n 0 zeros.</figDesc><table><row><cell>Marcus Hutter Marcus Hutter</cell><cell>-24 --25 -</cell><cell>Universal Induction &amp; Intelligence Universal Induction &amp; Intelligence</cell></row><row><cell cols="3">Bayes' Famous Rule Example: Bayes' and Laplace's Rule</cell></row><row><cell cols="3">Assume data is generated by a biased coin with head probability θ, i.e.</cell></row><row><cell cols="2">H θ :=Bernoulli(θ) with θ ∈ Θ := [0, 1].</cell><cell></cell></row></table><note>It is natural to assume that plausibilities/beliefs Bel(•|•) can be repr. by real numbers, that the rules qualitatively correspond to common sense, and that the rules are mathematically consistent. ⇒ • Cox's theorem: Bel(•|A) is isomorphic to a probability function p(•|•) that satisfies the axioms of (objective) probabilities. • Conclusion: Beliefs follow the same rules as probabilities Given: p(H i ) = a priori plausibility of hypotheses H i (subj. prob.) Given: p(D|H i ) = likelihood of data D under hypothesis H i (obj. prob.) Goal: p(H i |D) = a posteriori plausibility of hypothesis H i (subj. prob.) Solution: p(H i |D) = p(D|H i )p(H i ) i∈I p(D|H i )p(H i ) Proof: From the definition of conditional probability and i∈I p(H i |...) = 1 ⇒ i∈I p(D|H i )p(H i ) = i∈I p(H i |D)p(D) = p(D) Sample infinite sequence:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>implies excellent prediction and decision for most n.</figDesc><table><row><cell>Marcus Hutter</cell><cell>-31 -</cell><cell>Universal Induction &amp; Intelligence</cell></row><row><cell></cell><cell></cell><cell>[RH'07]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Solomonoff completed the Bayesian framework by providing a rigorous, unique, formal, and universal choice for the model class and the prior. I will discuss in breadth how and in which sense universal (non-i.i.d.) sequence prediction solves various (philosophical) problems of traditional Bayesian sequence prediction. I show that Solomonoff's model possesses many desirable properties: Fast convergence, and in contrast to most classical continuous prior densities has no zero p(oste)rior problem, i.e. can confirm universal hypotheses, is reparametrization and regrouping invariant, and avoids the old-evidence and updating problem. It even performs well (actually better) in non-computable environments. Universal Induction &amp; IntelligenceSchematic Graph of Kolmogorov ComplexityAlthough K(x) is incomputable, we can draw a schematic graph</figDesc><table><row><cell>Marcus Hutter Marcus Hutter Marcus Hutter</cell><cell>-32 --33 --40 -</cell><cell>Universal Induction &amp; Intelligence Universal Induction &amp; Intelligence Universal Induction &amp; Intelligence</cell></row><row><cell cols="3">Universal Inductive Inferences: Abstract</cell></row><row><cell cols="3">Universal Inductive Inferences: Contents</cell></row><row><cell cols="3">• Foundations of Universal Induction</cell></row><row><cell cols="3">• Bayesian Sequence Prediction and Confirmation</cell></row><row><cell cols="2">• Fast Convergence</cell><cell></cell></row><row><cell cols="3">• How to Choose the Prior -Universal</cell></row><row><cell cols="2">• Kolmogorov Complexity</cell><cell></cell></row><row><cell cols="3">• How to Choose the Model Class -Universal</cell></row><row><cell cols="3">• Universal is Better than Continuous Class</cell></row><row><cell cols="3">• Summary / Outlook / Literature</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>−K(θ) always exists and is invariant w.r.t. all computable reparametrizations f . (Jeffrey prior only w.r.t. bijections, and does not always exist) • The Problem of Old Evidence: No risk of biasing the prior towards past data, since w U θ is fixed and independent of M. • The Problem of New Theories: Updating of M is not necessary, since M U includes already all. • M predicts better than all other mixture predictors based on any (continuous or discrete) model class and prior, even in non-computable environments. µ) ln 2, where h t (ω &lt;t ) := a∈X ( ξ(a|ω &lt;t ) − µ(a|ω &lt;t )) 2 . • Instantaneous i.i.d. bounds: For i.i.d. M with continuous, discrete, and universal prior, respectively:</figDesc><table><row><cell>Marcus Hutter Universal is better than Continuous Class&amp;Prior -42 -Universal Induction &amp; Intelligence • Problem of zero prior / confirmation of universal hypotheses: P[All ravens black|n black ravens] ≡ 0 in Bayes-Laplace model f ast −→ 1 for universal prior w U θ • Reparametrization and regrouping invariance: w U -43 -Universal Induction &amp; Intelligence Convergence and Loss Bounds θ = 2 Marcus Hutter • Total (loss) bounds: ∞ n=1 E[h n ]</cell></row></table><note>× &lt; K(</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>but spikes up for simple n. M is cautious at magic instance numbers n.• Future bounds / errors to come: If our past observations ω 1:n contain a lot of information about µ, we make few errors in future: Universal Induction &amp; Intelligence</figDesc><table><row><cell>Conditional Kolmogorov Complexity</cell></row><row><cell>Question: When is object=string x similar to object=string y?</cell></row><row><cell>Universal solution: x similar y ⇔ x can be easily (re)constructed from y</cell></row><row><cell>⇔ Kolmogorov complexity K(x|y) := min{ (p) : U (p, y) = x} is small</cell></row><row><cell>Examples:</cell></row><row><cell>1) x is very similar to itself (K(x|x)</cell></row></table><note>∞ t=n+1 E[h t |ω 1:n ] + &lt; [K(µ|ω 1:n )+K(n)] ln 2</note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Universal Induction &amp; Intelligence</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bayesian Sequence Prediction and Confirmation</head><p>• Assumption: Sequence ω ∈ X ∞ is sampled from the "true" probability measure µ, i.e. µ(x) := P[x|µ] is the µ-probability that ω starts with x ∈ X n .</p><p>• Model class: We assume that µ is unknown but known to belong to a countable class of environments=models=measures M = {ν 1 , ν 2 , ...}.</p><p>[no i.i.d./ergodic/stationary assumption]</p><p>• Hypothesis class: {H ν : ν ∈ M} forms a mutually exclusive and complete class of hypotheses.</p><p>• Prior: w ν := P[H ν ] is our prior belief in H ν is our posterior belief in ν (Bayes' rule). How to Choose the Prior?</p><p>• Subjective: quantifying personal prior belief (not further discussed)</p><p>• Objective: based on rational principles (agreed on by everyone)</p><p>• Indifference or symmetry principle: Choose w ν = 1 |M| for finite M. • Jeffreys or Bernardo's prior: Analogue for compact parametric spaces M.</p><p>• Problem: The principles typically provide good objective priors for small discrete or compact spaces, but not for "large" model classes like countably infinite, non-compact, and non-parametric M.</p><p>• Solution: Occam favors simplicity ⇒ Assign high (low) prior to simple (complex) hypotheses.</p><p>• Problem: Quantitative and universal measure of simplicity/complexity. + Simple strings like 000...0 have small K, irregular (e.g. random) strings have large K.</p><p>• The definition is nearly independent of the choice of U .</p><p>+ K satisfies most properties an information measure should satisfy.</p><p>+ K shares many properties with Shannon entropy but is superior.</p><p>− K(x) is not computable, but only semi-computable from above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fazit:</head><p>K is an excellent universal complexity measure, suitable for quantifying Occam's razor.</p><p>Universal Inductive Inference: Summary The Universal Similarity Metric: Abstract</p><p>The MDL method has been studied from very concrete and highly tuned practical applications to general theoretical assertions. Sequence prediction is just one application of MDL. The MDL idea has also been used to define the so called information distance or universal similarity metric, measuring the similarity between two individual objects. I will present some very impressive recent clustering applications based on standard Lempel-Ziv or bzip2 compression, including a completely automatic reconstruction (a) of the evolutionary tree of 24 mammals based on complete mtDNA, and (b) of the classification tree of 52 languages based on the declaration of human rights and (c) others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Based on [Cilibrasi&amp;Vitanyi'05] Universal Induction &amp; Intelligence</head><p>Tree-Based Clustering</p><p>• If many objects x 1 , ..., x n need to be compared, determine the similarity matrix</p><p>• Now cluster similar objects.</p><p>• There are various clustering techniques.</p><p>• Tree-based clustering: Create a tree connecting similar objects,</p><p>• e.g. quartet method (for clustering) Genomics &amp; Phylogeny: SARS Virus and Others</p><p>• Clustering of SARS virus in relation to potential similar virii based on complete sequenced genome(s) using bzip2:</p><p>• The relations are very similar to the definitive tree based on medical-macrobio-genomics analysis from biologists.</p><p>Language Tree (Re)construction</p><p>x n be the "The Universal Declaration of Human Rights" in various languages 1, ..., n.</p><p>• Distance matrix M ij based on gzip. Language tree constructed from M ij by the Fitch-Margoliash method [Li&amp;al'03]</p><p>• All main linguistic groups can be recognized (next slide) Preprocessing the MIDI files:</p><p>• Delete identifying information (composer, title, ...), instrument indicators, MIDI control signals, tempo variations, ...</p><p>• Keep only note-on and note-off information.</p><p>• A note, k ∈ Z Z half-tones above the average note is coded as a signed byte with value k.</p><p>• The whole piece is quantized in 0.05 second intervals.</p><p>• Tracks are sorted according to decreasing average volume, and then output in succession.</p><p>Processed files x 1 , ..., x n still sounded like the original. The Clustering Method: Summary</p><p>• based on the universal similarity metric,</p><p>• based on Kolmogorov complexity,</p><p>• approximated by bzip2,</p><p>• with the similarity matrix represented by tree,</p><p>• approximated by the quartet method</p><p>• leads to excellent classification in many domains.</p><note type="other">Marcus Hutter -62 -Universal Induction &amp; Intelligence</note><p>Universal Rational Agents: Contents Here we combine both ideas and develop an elegant parameter-free theory of an optimal reinforcement learning agent embedded in an arbitrary unknown environment that possesses essentially all aspects of rational intelligence. The theory reduces all conceptual AI problems to pure computational ones.</p><p>We give strong arguments that the resulting AIXI model is the most intelligent unbiased agent possible. Other discussed topics are relations between problem classes. Universal Induction &amp; Intelligence</p><p>Rational Agents in Deterministic Environments</p><p>-Value V pq km := r k + ... + r m , optimal policy p best := arg max p V pq 1m , Lifespan or initial horizon m. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Agents in Probabilistic Environments</head><p>Given history y 1:k x &lt;k , the probability that the environment leads to perception x k in cycle k is (by definition) σ(x k |y 1:k x &lt;k ).</p><p>Abbreviation (chain rule)</p><p>The average value of policy p with horizon m in environment σ is defined as</p><p>The goal of the agent should be to maximize the value. Universal Induction &amp; Intelligence</p><p>The Bayes-mixture distribution ξ Assumption: The true environment µ is unknown.</p><p>Bayesian approach: The true probability distribution µ AI is not learned directly, but is replaced by a Bayes-mixture ξ AI .</p><p>Assumption: We know that the true environment µ is contained in some known (finite or countable) set M of environments.</p><p>The Bayes-mixture ξ is defined as</p><p>The weights w ν may be interpreted as the prior degree of belief that the true environment is ν.</p><p>Then ξ(x 1:m |y 1:m ) could be interpreted as the prior subjective belief probability in observing x 1:m , given actions y 1:m . Universal Induction &amp; Intelligence</p><p>A universal choice of ξ and M</p><p>• We have to assume the existence of some structure on the environment to avoid the No-Free-Lunch Theorems [Wolpert 96].</p><p>• We can only unravel effective structures which are describable by (semi)computable probability distributions.</p><p>• So we may include all (semi)computable (semi)distributions in M.</p><p>• Occam's razor and Epicurus' principle of multiple explanations tell us to assign high prior belief to simple environments.</p><p>• Using Kolmogorov's universal complexity measure K(ν) for environments ν one should set w ν ∼ 2 −K(ν) , where K(ν) is the length of the shortest program on a universal TM computing ν.</p><p>• The resulting AIXI model [Hutter:00] is a unification of (Bellman's) sequential decision and Solomonoff's universal induction theory. Universal Induction &amp; Intelligence</p><p>The AIXI Model in one Line</p><p>The most intelligent unbiased learning agent</p><p>is an elegant mathematical theory of AI Claim: AIXI is the most intelligent environmental independent, i.e.</p><p>universally optimal, agent possible.</p><p>Proof: For formalizations, quantifications, and proofs, see <ref type="bibr" target="#b2">[Hut05]</ref>.</p><p>Applications: Strategic Games, Function Minimization, Supervised</p><p>Learning from Examples, Sequence Prediction, Classification.</p><p>In the following we consider generic M and w ν . Universal Induction &amp; Intelligence</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pareto-Optimality of p ξ</head><p>Policy p ξ is Pareto-optimal in the sense that there is no other policy p with V p ν ≥ V p ξ ν for all ν ∈ M and strict inequality for at least one ν.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Self-optimizing Policies</head><p>Under which circumstances does the value of the universal policy p ξ converge to optimum?</p><p>The least we must demand from M to have a chance that (1) is true is that there exists some policy p at all with this property, i.e.</p><p>Main result: (2) ⇒ (1): The necessary condition of the existence of a self-optimizing policy p is also sufficient for p ξ to be self-optimizing. Universal Induction &amp; Intelligence Environments w. (Non)Self-</p><note type="other">Optimizing Policies Marcus Hutter -76 -Universal Induction &amp; Intelligence Particularly Interesting Environments</note><p>• Sequence Prediction, e.g. weather or stock-market prediction.</p><p>Strong result:</p><p>), m =horizon. • Strategic Games: Learn to play well (minimax) strategic zero-sum games (like chess) or even exploit limited capabilities of opponent.</p><p>• Optimization: Find (approximate) minimum of function with as few function calls as possible. Difficult exploration versus exploitation problem.</p><p>• Supervised learning: Learn functions by presenting (z, f (z)) pairs and ask for function values of z by presenting (z , ?) pairs. Supervised learning is much faster than reinforcement learning.</p><p>AIξ quickly learns to predict, play games, optimize, and learn supervised.</p><note type="other">Marcus Hutter -77 -Universal Induction &amp; Intelligence</note><p>Universal Rational Agents: Summary</p><p>• Setup: Agents acting in general probabilistic environments with reinforcement feedback.</p><p>• Assumptions: Unknown true environment µ belongs to a known class of environments M.</p><p>• Results: The Bayes-optimal policy p ξ based on the Bayes-mixture ξ = ν∈M w ν ν is Pareto-optimal and self-optimizing if M admits self-optimizing policies.</p><p>• We have reduced the AI problem to pure computational questions (which are addressed in the time-bounded AIXItl).</p><p>• AIξ incorporates all aspects of intelligence (apart comp.-time).</p><p>• How to choose horizon: use future value and universal discounting.</p><p>• ToDo: prove (optimality) properties, scale down, implement. • Bayes needs prior(H i )</p><p>• Occam+Epicurus: High prior for simple models.</p><p>• Kolmogorov/Solomonoff: Quantification of simplicity/complexity  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Universal Induction &amp; Intelligence Genomics &amp; Phylogeny: Mammals Let x 1 , ..., x n be mitochondrial genome sequences of different mammals: Partial distance matrix M ij using bzip2(?) Cat Echidna Gorilla</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Clustering by compression</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cilibrasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M B</forename><surname>Vitányi</surname></persName>
		</author>
		<ptr target="http://arXiv.org/abs/cs/0312044" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Information Theory</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1523" to="1545" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Universal Artificial Intelligence: Sequential Decisions based on Algorithmic Probability</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
		<ptr target="http://www.hutter1.net/ai/uaibook.htm" />
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On universal prediction and Bayesian confirmation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/0709.1516" />
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">384</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="48" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Universal intelligence: a definition of machine intelligence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11023-007-9079-x</idno>
		<ptr target="http://dx.doi.org/10.1007/s11023-007-9079-x" />
	</analytic>
	<monogr>
		<title level="j">Minds &amp; Machines</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="391" to="444" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
