<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Empowering Language Models with Knowledge Graph Reasoning for Question Answering</title>
				<funder>
					<orgName type="full">NASA</orgName>
				</funder>
				<funder>
					<orgName type="full">Cisco</orgName>
				</funder>
				<funder>
					<orgName type="full">Amazon Fellowship and Baidu PhD Fellowship</orgName>
				</funder>
				<funder ref="#_JkaS3Pf #_A2Eg274">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder>
					<orgName type="full">CISCO</orgName>
				</funder>
				<funder>
					<orgName type="full">Okawa Foundation Grant, Amazon Research Awards</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ziniu</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yichong</forename><surname>Xu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Cognitive Services Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wenhao</forename><surname>Yu</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Notre Dame</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Cognitive Services Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ziyi</forename><surname>Yang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Cognitive Services Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Cognitive Services Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Empowering Language Models with Knowledge Graph Reasoning for Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Answering open-domain questions requires world knowledge about in-context entities. As pre-trained Language Models (LMs) lack the power to store all required knowledge, external knowledge sources, such as knowledge graphs, are often used to augment LMs. In this work, we propose knOwledge REasOning empowered Language Model (OREOLM), which consists of a novel Knowledge Interaction Layer that can be flexibly plugged into existing Transformer-based LMs to interact with a differentiable Knowledge Graph Reasoning module collaboratively. In this way, LM guides KG to walk towards the desired answer, while the retrieved knowledge improves LM. By adopting OREOLM to RoBERTa and T5, we show significant performance gain, achieving state-of-art results in the Closed-Book setting. The performance enhancement is mainly from the KG reasoning's capacity to infer missing relational facts. In addition, OREOLM provides reasoning paths as rationales to interpret the model's decision.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Open-Domain Question Answering (ODQA), one of the most knowledge-intensive NLP tasks, requires QA models to infer out-of-context knowledge to the given single question. Following the pioneering work by <ref type="bibr" target="#b5">Chen et al. (2017)</ref>, ODQA systems often assume to access an external text corpus (e.g., Wikipedia) as an external knowledge source. Due to the large scale of such textual knowledge sources (e.g., 20GB for Wikipedia), it cannot be encoded in the model parameters. Therefore, most works retrieve relevant passages as knowledge and thus named Open-Book models <ref type="bibr" target="#b31">(Roberts et al., 2020)</ref>, with an analogy of referring to textbooks during an exam. Another line of Closedbook models <ref type="bibr" target="#b31">(Roberts et al., 2020)</ref> assume knowledge could be stored implicitly in parameters of Language Models (LM, e.g. BERT <ref type="bibr">(Devlin et al.</ref>, 2019) and T5 <ref type="bibr" target="#b29">(Raffel et al., 2020)</ref>). These LMs directly generate answers without retrieving from an external corpus and thus benefit from faster inference speed and simpler training. However, current LMs still miss a large portion of factual knowledge <ref type="bibr" target="#b28">(P?rner et al., 2020;</ref><ref type="bibr">Lewis et al., 2021a)</ref>, and are not competitive with Open-Book models.</p><p>To improve the knowledge coverage of LM, one natural choice is to leverage knowledge stored in Knowledge Graph (KG, e.g. FreeBase <ref type="bibr" target="#b2">(Bollacker et al., 2008)</ref> and WikiData <ref type="bibr" target="#b32">(Vrandecic and Kr?tzsch, 2014)</ref>), which explicitly encodes world knowledge via relational triplets between entities. There are several good properties of KG: 1) a KG triplet is a more abstract and compressed representation of knowledge than text, and thus KG could be stored in memory and directly enhance LM without using an additional retrieval model; 2) the structural nature of KG could support logical reasoning <ref type="bibr">(Ren et al., 2020)</ref> and infer missing knowledge through high-order paths <ref type="bibr" target="#b21">(Lao et al., 2011;</ref><ref type="bibr" target="#b7">Das et al., 2018)</ref>. Taking the question "what cheese is used to make the desert cannoli?" as an example, even if this relational fact is missing in KG, we could still leverage high-order relationships, e.g., both Ricotta Cheese and Cannoli are specialties in Italy, to infer the answer "Ricotta Cheese."</p><p>In light of the good properties of KG, there are several efforts to build Knowledge Base Question Answering (KBQA) systems. As is illustrated in Figure <ref type="figure" target="#fig_0">1</ref>(a), most KBQA models use LM as a parser to map textual questions into a structured form (e.g., SQL query or subgraph), and then based on KG, the queries could be executed by symbolic reasoning <ref type="bibr" target="#b1">(Berant et al., 2013)</ref> or neural reasoning (e.g. Graph Neural Networks) <ref type="bibr" target="#b44">(Sun et al., 2019)</ref> to get the answer. Another recent line of research <ref type="bibr">(Verga et al., 2021;</ref><ref type="bibr">Yu et al., 2022b)</ref> tries to encode the knowledge graph as the memory into LM parameters. However, for most methods discussed above, LM is not interacting with KG to correctly understand the question, and the answer is usually restricted to a node or edge in KG.</p><p>In this paper, we propose knOwledge REasOning empowered Language Model (OREOLM), a model architecture that can be applied to Transformer-based LMs to improve Closed-Book ODQA. As is illustrated in <ref type="bibr">Figure 1(b)</ref>, the key component is the Knowledge Interaction Layers (KIL) inserted amid LM layers, which is like cream filling within two waffles, leading to our model's name OREO. KIL interacts with a KG reasoning module, in which we maintain different reasoning paths for each entity in the question. We formulate the retrieval and reasoning process as a contextualized random walk over the KG, starting from the in-context entities. Each KIL is responsible for one reasoning step. It first predicts a relation distribution for every in-context entity, and then the KG reasoning module traverses the graph following the predicted relation distribution. The reasoning result in each step is summarized as a weighted averaged embedding over the retrieved entities from the traversal.</p><p>By stacking T layers of KIL, OREOLM can retrieve entities that are T -hop away from in-context entities and help LM to answer open questions that require out-of-context knowledge or multi-hop reasoning. The whole procedure is fully differentiable, and thus OREOLM learns and infers in an end-toend manner. We further introduce how to pre-train OREOLM over unlabelled Wikipedia corpus. In addition to the salient entity span masking objective, we introduce two self-supervised objectives to guide OREOLM to learn better entity and relation representations and how to reason over them.</p><p>We test OREOLM with RoBERTa and T5 as our base LMs. By evaluating on several single-hop ODQA datasets in closed-book setting, we show that OREOLM outperforms existing baselines with fewer model parameters. Specifically, OREOLM helps more for questions with missing relations in KG, and questions that require multi-hop reasoning. We further show that OREOLM can serve as a backbone for open-book setting and achieves comparable performance compared with the stateof-the-art QA systems with dedicated design. In addition, OREOLM has better interpretability as it can generate reasoning paths for the answered question and summarize general relational rules to infer missing relations.</p><p>This key contributions are as follows:  <ref type="bibr" target="#b21">(Lao et al., 2011;</ref><ref type="bibr" target="#b34">Xiong et al., 2017;</ref><ref type="bibr" target="#b7">Das et al., 2018)</ref> have been proposed to answer the one-hop query via finding multi-hop paths.</p><p>For example, to answer the query (s, Mother, ?), a path s</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Father</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>---? j</head><p>Wife --? t could reach the target answer t. In this paper we try to integrate symbolic KG reasoning into neural LMs and help it deal with ODQA problems.</p><p>Overview of OREOLM We illustrate the overall architecture of OREOLM in Figure <ref type="figure" target="#fig_1">2</ref>. All the light blue blocks are our added components to support KG reasoning, while the dark blue Transformer layers are knowledge-injected LM. The key component of OREOLM for conducting KG reasoning is the Knowledge Interaction Layers (KIL), which are added amid LM layers to enable deeper interaction with the KG.</p><p>Given a question q = "The Bauhaus represented Germany's recovery from which event?", QA model needs to extract knowledge about all n in-context entity mentions M = {m i } n i=1 , e.g., the history of "Germany" at the time when "Bauhaus" is founded, to get the answer a = "World War I". Such open-domain Q&amp;A can be abstracted as P (a|q, M ).</p><p>Starting from each mentioned entity m i , we desire the model to learn to walk over the graph to retrieve relevant knowledge and form a T -length reasoning path for answering this question, where T is a hyper-parameter denote the longest reasoning path required to answer the questions. We define each reasoning path starting from the entity mention m i as a chain of entities (states) random variables ? i = {e t i } T t=0 , where each mentioned entity is the initial state, i.e., e 0 i = m i . The union of all paths for this question is defined as ? = {? i }, which contains the reasoning paths from each mentioned entity to answer the question. We assume (1) reasoning paths starting from different entities are generated independently; and (2) reasoning paths can be generated autoregressively.</p><p>In this way, the QA problem can be decomposed into two entangled steps: 1) KG Reasoning, which autoregressively walks through the graph to get a path ? i starting from each entity mention m i ; and 2) knowledge-injected LM, which benefits from the reasoning paths to obtain the out-context knowledge for answer prediction.</p><p>The relational path ? i in KG Reasoning requires the selection of next entity e t i at each step t. We further decompose it into two steps: 1.a) relation prediction, in which LM is involved to predict the next-hop relation based on the current state and context; and 1.b) the non-parametric state transition, which is to predict the next-hop entity based on the KG and the predicted relation. Formally: We keep track of the entity distribution at each step t via the probability vector 1 ?</p><formula xml:id="formula_0">(t) i ? R |E| , with ? (t)</formula><p>i [e] being the probability of staying at entity e, i.e., P e t i = e|q, e &lt;t i . We highlight the three procedures in red dotted box in Figure <ref type="figure" target="#fig_1">2</ref>. We take the first reasoning step starting from entity mention "Bauhaus" as an example. In the first red box within KIL, we predict which relation action should be taken for entity "Bauhaus", and send the prediction (e.g. "Founded") to KG. In the second red box, KG reweights the graph and conducts contextualized random walk to update entity distribution, where "Walter" has the highest probability. Finally, weighted by the entity distribution, an aggregated entity embedding is sent back to KIL and added into a placeholder token as the knowledge, so the later LM layer knows to focus on the retrieved "Walter". We introduce these steps in the following.</p><p>Input Initially, we first identify all N entity mentions {m i } N i=1 in the input question q as well as the corresponding KG entities 2 .. For each mention m i we add three special tokens as the interface for Knowledge Interaction Layers (KIL) to send instruction and receive knowledge: we add a [S-ENT] token before, and encode the relevant information in question q that hints next relation. We maintain a global relation key memory K rel ? R |R|?d storing each relation's d-dimentional embedding. To calculate similarity, we first get relation query</p><formula xml:id="formula_1">Q (t)</formula><p>REL[i] by projecting relation token's embedding into the same space of key memory via a projection head Q-Proj<ref type="foot" target="#foot_0">3</ref> followed by a LayerNorm (abbreviated as LN), and then calculate dot-product similarity followed by softmax:</p><formula xml:id="formula_2">Q (t) REL[i] = LN (t) Q-Proj (t) (LM (t) REL[i] ) ,<label>(1)</label></formula><formula xml:id="formula_3">? (t) i = P rel r t i |q, e &lt;t i = Softmax Q (t) REL[i] K T rel .<label>(2)</label></formula><p>Note that the relation queries</p><formula xml:id="formula_4">LM (t)</formula><p>REL[i] are different for every mention m i and reasoning step t depending on the context, and thus the the relation distributions ?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(t)</head><p>i gives contextualized predictions based on the question q. The predicted relations are sent to the knowledge graph reasoning module as instruction to conduct state transition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Contextualized KG Random Walk</head><p>Next, we introduce how we conduct state transition P walk e t i |r t i , e &lt;t i . One classic transition algorithm is random walk, which is a special case of markov chain, i.e. the transition probability only depends on previous state. Consider a state at entity s, the probability walking to target t is</p><formula xml:id="formula_5">1 deg(s) if A[s, t] = 1.</formula><p>Based on it, we define the Markov transition matrix for random walk as M rw = D -1 A A, where the degree matrix D A ? R |E|?|E| is defined as the diagonal matrix with the degrees deg(1), . . . , deg(|E|) on the diagonal. With random walk Markov matrix M rw we can transit the state distribution as: ? (t) = ? (t-1) M , The limitation of random walk is that the transition strategy is not dependent on the question q. We thus propose a Contextualized Random Walk (CRW).</p><p>Based on the predicted relation distribution ? </p><formula xml:id="formula_6">A (t) i = r?R w r ? ? (t) i,r ? A r ,<label>(3)</label></formula><formula xml:id="formula_7">M crw,i (t) = D -1 A (t) i A (t) i , ?i ? [1, N ]. (4)</formula><p>where w r is a learnable importance weight for relation r that helps solving downstream tasks, and t) , the state transition is defined as ?</p><formula xml:id="formula_8">? (t) i,r is the probability corresponding to relation r in ? (t) i . With the transition matrix M crw,i<label>(</label></formula><formula xml:id="formula_9">(t) i = ? (t-1) i M (t) crw,i .</formula><p>CRW allows each reasoning path ? i to have its transition matrix. However, as the total number of entity nodes |E| could be huge (e.g., 5M for Wiki-Data), we cannot afford to update the entire adjacency matrix for every in-batch mention. We thus adopt a scatter-gather pipeline to implement graph walking as shown in Algorithm 1. We first gather the entity and relation probability to each edge, and then scatter the probability to target nodes. This allows us to simultaneously conduct message passing with modified adjacency weight A t i for all entity mention m i in parallel. The complexity is # of in-batch entities times # of edges in T -hop subgraph starting from these entities, i.e., O(n?#edge), and thus this operation is not expensive. Another concern is why not using Graph Neural Networks (GNNs). We provide discussion in Sec. C in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Knowledge-Injected LM</head><p>After we get the updated entity distribution ? (t) i , we want to inject such information back to the LM without harming its overall structure. We maintain a global entity embedding value memory V ent ? R |E|?d storing entity embeddings. We only consider the entities within the sampled local subgraph in each batch. We thus get an entity index list I as the query to sparsely retrieve a set of candidate entity embeddings and then aggregate them weighted by entity distribution and embedding table. We then use a Value Projection block to map the aggregated entity embedding into the space of LM, and then directly add the transformed embedding back to the output of T-ENT.</p><formula xml:id="formula_10">V (t) i = V-Proj (t) ? (t) i ? V ent [I] ,</formula><p>(5)</p><formula xml:id="formula_11">LM (t) T-ENT[i] = LN (t) LM (t) T-ENT[i] + V (t) i .<label>(6)</label></formula><p>Then, we just take all</p><formula xml:id="formula_12">LM (t)</formula><p>T-ENT as input to next Transformer-based LM layer to learn the interaction between the retrieved knowledge with in-context words via self-attention.</p><p>By repeating the KIL for T times, the final representation LM</p><p>T is conditioned on the reasoning paths ? i = e 0:T i , which reaches entities that are Thop away from initial entity m i in the question. Finally, we can predict the answer of open questions P a|q, {e 0:T i } n i=1 by taking knowledge-injected representation LM</p><p>T for span extraction, entity prediction or direct answer generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Pre-Train OREOLM to Reason</head><p>The design of OREOLM allows end-to-end training given QA datasets. However, due to the small coverage of knowledge facts for existing QA datasets, we need to pretrain OREOLM on a large-scale corpus to get good entity embeddings.</p><p>Salient Span Masking One straightforward approach is to use Salient Span Masking (SSM) objective <ref type="bibr" target="#b15">(Guu et al., 2020)</ref> masks out entities or noun tokens requiring specific out-of-context knowledge. We mainly mask out entities for guiding OREOLM to reason. Instead of randomly masking entity mentions, we explicitly sample a set of entity IDs and mask every mentions linking to these entities. This could prevent the model copy the entity from the context to fill in the blank. We also follow <ref type="bibr" target="#b35">(Yang et al., 2019)</ref> to mask out consecutive token spans. We then calculate the cross-entropy loss on each salient span masked (SSM) token as L SSM .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Weakly Supervised Training of KIL</head><p>Ideally, OREOLM can learn all the entity knowledge and how to access the knowledge graph by solely optimizing L SSM . However, without a good initialization of entity and relation embeddings, KIL makes a random prediction, and the retrieved entities by KG reasoning are likely to be unrelated Entity Linking Loss To initialize the large entity embedding tables in V ent , we use other entities that are not masked as supervision. Similar to F?vry et al. ( <ref type="formula">2020</ref>), we force the output embedding of [S-ENT] token before the first KIL followed by a projection head E-Proj to be close to its corresponding entity embedding:</p><formula xml:id="formula_13">E S-ENT[i] = LN E-Proj(LM (1) S-ENT[i] ) , P (0) ent e|m i , q = Softmax E S-ENT[i] V ent [I] T , L ent = m i -log P (0) ent e|m i , q ? ? 0 i [I].</formula><p>Similar to Section 2.2, we only consider entities within the batch, denoted by index I. This contrastive loss guides each entity's embedding V ent [e] closer to all its previously mentioned contextualized embedding, and thus memorizes those context as a good initialization for later knowledge integration.</p><p>Weakly Supervised Relation Path Loss Entity mentions within each Wikipedia passage are naturally grounded to WikiData KG. Therefore, after we mask out several entities, we can utilize the KG to get all reasoning paths from other in-context entities to the masked entities as weakly supervised relation labels.</p><p>Formally, we define a Grounded Dependency Graph DG, which contains all reasoning paths within T -step from other in-context entities to masked entities, and then define R DG (m i , t) as the set of all relations over every edges for entity mention m i at t-th hop. Based on it, we define the weakly supervised relation label q</p><p>(t) i ? R |R| as the probabilistic vector which uniformly distributed on each relation in set. Note that we call uniformly-weighted q (t) i as weakly supervised because 1) some paths lead to multiple entities rather than only the target masked entity; 2) the correct relation is dependent on the context. Therefore, q (t) i only provides all potential candidates for reachability, and more fine-grained signals for reasoning should be learned from unsupervised L SSM . We adopt a list-wise ranking loss to guide the model to assign a higher score on these relations than others.</p><formula xml:id="formula_14">L rel = m i T t=1 -log P (t) rel r|m i , q ? q (t) i .</formula><p>Overall, L ent and L rel provide OREOLM with good initialization of the large KG memory. Afterward, via optimizing L SSM , the reasoning paths that provide informative knowledge receive a positive gradient, guiding OREOLM to reason.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>The proposed KIL layers can be pugged into most Transformer-based Language Models without hurting its original structure. In this paper, we experiment with both encoder-based LM, i.e. RoBERTabase (d = 768, l = 12), and encoder-decoder LM, i.e. T5-base (d = 768, l = 12) and T5-large (d = 1024, l = 24). For all LMs, add 1 KIL layer or 2 KIL layers to the encoder layers. The statistics of KG are shown in Table <ref type="table" target="#tab_3">1</ref>. Altogether, it takes about 0.67B parameter for KG memory, which is affordable to load as model parameter. We pretrain all LMs using the combination of L SSM , L ent and L rel for 200k steps on 8 V100 GPUs, with a batch size of 128 and default optimizer and learning rate in the original paper, taking approximately one week to finish pre-training of T5-large model, and 1-2 days for base model. Implementation details are elaborated in Appendix A. Generative QA Task Following the hyperparameters and setting in <ref type="bibr" target="#b31">(Roberts et al., 2020)</ref>, we directly fine-tune the T5-base and T5-large augmented by our OREOLM on the three single-hop ODQA datasets: Natural Question (NQ) <ref type="bibr" target="#b20">(Kwiatkowski et al., 2019)</ref>, WebQuestions (WQ) <ref type="bibr" target="#b1">(Berant et al., 2013)</ref> and TriviaQA (TQA) <ref type="bibr" target="#b17">(Joshi et al., 2017)</ref>. To test OREOLM's ability to solve complex questions, we also evaluate on two multi-hop QA datasets, i.e. Complex WQ (Talmor and <ref type="bibr">Berant, 2018)</ref> and HotpotQA <ref type="bibr" target="#b36">(Yang et al., 2018)</ref>. Detailed dataset statistics and experimental setups are in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluate for</head><p>Experimental results are shown in Table <ref type="table">7</ref>. We use Exact Match accuracy as the metric for all the datasets. On the three single-hop ODQA datasets, OREOLM with 2 KIL blocks achieves 3.3 absolute accuracy improvement to T5-base, and 3.4 improvement to T5-large. Compared with T5 model with more model parameters (e.g., T5-3B and T5-11B), our T5-large augmented by OREOLM could outperform T5-3B on NQ and WQ datasets. In addition, OREOLM could use the generated reasoning path to interpret the model's prediction. We show examples in Table <ref type="table" target="#tab_3">10</ref> in Appendix.</p><p>For the two multi-hop QA datasets, the performance improvement brought by OREOLM is more significant, i.e., 7.8 to T5-base and 8.2 to T5large. Notably, by comparing the T5-3B and T5-11B's performance on HotpotQA (we take results from <ref type="bibr" target="#b6">(Chen et al., 2022)</ref>), T5-large augmented by OREOLM achieves 1.2 higher than T5-11B. This shows that OREOLM is indeed very effective for improving Closed-Book QA performance, especially for complex questions.</p><p>Entity Prediction Task Encoder-based LM (i.e. RoBERTa) in most cases cannot be directly used for Closed-Book QA, but more serve as reader to extract answer span. However, <ref type="bibr">Verga et al. (2021)</ref> propose a special evaluation setting as Closed-Book Entity Prediction. They add a single [MASK] token after the question, and use its output embedding to classify WikiData entity ID. This restricts that answers must be entities that are covered by Wiki-Data, which they call WikiData-Answerable questions. We follow Verga et al. ( <ref type="formula">2021</ref>) to use such reduced version of WebQuestionsSP (WQ-SP) <ref type="bibr" target="#b38">(Yih et al., 2015)</ref> and TriviaQA (TQA) as evaluation dataset, and finetune the RoBERTa (base) model augmented by OREOLM to classify entity ID. We mainly compare OREOLM with EaE (F?vry et al., 2020) and FILM <ref type="bibr">(Verga et al., 2021)</ref>, which are two KG memory augmented LM. We also run experiments on KEPLER <ref type="bibr" target="#b33">(Wang et al., 2019)</ref>, a RoBERTa model pre-trained with knowledge augmented task.</p><p>Experimental results are shown in Table <ref type="table" target="#tab_5">3</ref>. Similar to the observation reported by Verga et al. (2021), adding KG memory for this entity prediction task could significantly improve over vanilla LM, as most of the factual knowledge required to predict entities are stored in KG. By comparing with FILM <ref type="bibr">(Verga et al., 2021)</ref>, which is the stateof-the-art model in this setup, OREOLM with reasoning step (T = 2) outperforms FILM by 2.9, with smaller memory consumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Analyze KG Reasoning Module</head><p>In our previous studies, we find that using a higher reasoning step, i.e. T = 2, generally performs better than T = 1. We hypothesize that the KG we use has many missing one-hop facts, and highorder reasoning helps recover them and empowers the model to answer related questions. To test whether OREOLM indeed can infer missing facts, we use EntityQuestions (EQ) (Sciavolino et al., 2021), which is a synthetic dataset by mapping each WikiData triplet to natural questions. We take RoBERTa-base model augmented by OREOLM trained on NQ as entity predictor and directly test its transfer performance on EQ dataset without further fine-tuning.</p><p>To test whether OREOLM could recover missing relation, we mask all the edges corresponding to each relation separately and make the prediction again. The average results before and after removing edges are shown on the left part of Figure <ref type="figure" target="#fig_6">4</ref>. When we remove all the edges to each relation, OREOLM with T = 1 drops significantly, while T = 2 could still have good accuracy. To understand why OREOLM (T = 2) is less influenced, in the right part of Figure <ref type="figure" target="#fig_6">4</ref>, we generate a reasoning path for each relation by averaging the predicted probability score at each reasoning step and pick the relation with the top score. For example, to predict the "Capital" of a country, the model learns to find the living place of the president, or the location of a country's central bank. Both are very reasonable guesses. Many previous works <ref type="bibr" target="#b34">(Xiong et al., 2017)</ref> could also learn such rules in an ad-hoc manner and require costly searching or reinforcement learning. In contrast, OREOLM could learn such reasoning capacity for all relations end-to-end during pre-training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Studies</head><p>We conduct several ablation studies to evaluate which model design indeed contributes to the model. As shown in the bottom blocks in Table <ref type="table" target="#tab_5">3</ref>, we first remove the KG reasoning component and provide RoBERTa base model via concatenated KB triplets and train such a model using L SSM over the same WikiDataset. Such a model's results are close to the KEPLER results but much lower than other models with explicit knowledge memory. We further investigate the role of pre-training tasks. Without pre-training, the OREOLM only performs slightly better than RoBERTa baseline, due to the cold-start problem of entity and relation embedding. We further show that removing L ent and L ent could significantly influence final performance. The current combination is the best choice to train OREOLM to reason.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evaluate for Open-Book QA</head><p>Though OREOLM is designed for Closed-Book QA, the learned model can serve as backbone for Open-Book QA. We take DPR and FiD models as baseline. For DPR retriever, we replace the question encoder to RoBERTa + OREOLM, fixing the passage embedding and only finetune on each downstream QA dataset. For FiD model, we replace the T5 + OREOLM. We also changed the retriever with our tuned DPR. Results in Table <ref type="table" target="#tab_6">4</ref> show that by augmenting both retriever and generator, OREOLM improves a strong baseline like FiD, for about 3.1% for Base and 1.8% for Large, and it outperforms the very recent KG-FiD model for 1.6% in base setting, and achieve comparative performance in a large setting. Note that though our results is still lower than some recent models (e.g., EMDR 2 ), these methods are dedicated architecture or training framework for Open-Book QA. We may integrate OREOLM with these models to further improve their performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Open-Domain Question Answering (ODQA) gives QA model a single question without any context and asks the model to infer out-of-context knowledge.</p><p>Following the pioneering work by <ref type="bibr" target="#b5">Chen et al. (2017)</ref>, most ODQA systems assume the model can access an external text corpus (e.g. Wikipedia). Due to the large scale of web corpus (20GB for Wikipedia), it could not be simply encoded in the QA model parameters, and thus most works propose a Retrieval-Reader pipeline, by firstly index the whole corpus and use a retriever model to identify which passage is relevant  <ref type="formula">2020</ref>) defines these methods as Open-book, with an analogy to referring textbooks during exam. Closed-book QA models (mostly a single LM) try to answer open questions without accessing external knowledge. This setting is much harder as it requires LM to memorize all pertinent knowledge in its parameters, and even recent LMs with much larger model parameters is still not competitive to state-of-the-art Open-book models.</p><p>Knowledge-augmented Language Models explicitly incorporate external knowledge (e.g. knowledge graph) into LM <ref type="bibr">(Yu et al., 2022d)</ref>. Overall, these approaches can be grouped into two categories: The first one is to explicitly inject knowledge representation into language model pre-training, where the representations are precomputed from external sources <ref type="bibr" target="#b44">(Zhang et al., 2019;</ref><ref type="bibr" target="#b26">Liu et al., 2021;</ref><ref type="bibr" target="#b16">Hu et al., 2021)</ref>. For example, ERNIE <ref type="bibr" target="#b44">(Zhang et al., 2019)</ref> encodes the pre-trained TransE <ref type="bibr" target="#b3">(Bordes et al., 2013)</ref> embeddings as input. The second one is to implicitly model knowledge information into language model by performing knowledge-related tasks, such as entity category prediction <ref type="bibr">(Yu et al., 2022b)</ref> and graph-text alignment <ref type="bibr" target="#b19">(Ke et al., 2021)</ref>. For example, JAKET <ref type="bibr">(Yu et al., 2022b)</ref> jointly pre-trained both the KG representation and language representation by adding entity category and relation type prediction self-supervised tasks.</p><p>There also exists several QA works using KG to help ODQA. For example, <ref type="bibr" target="#b0">Asai et al. (2020)</ref> and <ref type="bibr" target="#b27">Min et al. (2019)</ref> expand the entity graph following wikipedia hyperlinks or triplets in knowledge base. <ref type="bibr" target="#b12">Ding et al. (2019)</ref> extract entities from current context via entity-linking and turn them into a cognitive graph, and a graph neural network is applied on top of it to extract answer. <ref type="bibr" target="#b11">Dhingra et al. (2020)</ref> and Lin et al. ( <ref type="formula">2020</ref> To encode knowledge (significantly smaller than the web corpus) as memory into LM parameter, a line of works try compressed knowledge including QA pairs <ref type="bibr" target="#b6">(Chen et al., 2022;</ref><ref type="bibr">Lewis et al., 2021b;</ref><ref type="bibr">Yu et al., 2022c)</ref>, entity embedding (F?vry et al., 2020) and reasoning cases <ref type="bibr" target="#b9">(Das et al., 2021</ref><ref type="bibr" target="#b8">(Das et al., , 2022</ref>). There's also several works utilizing Knowledge Graph (KG) to augment LM. FILM <ref type="bibr">(Verga et al., 2021)</ref> turns KG triplets into memory. Given a question, LM retrieves most relevant triplet as answer. GreaseLM <ref type="bibr" target="#b43">(Zhang et al., 2022)</ref> propose to interact LM with KG via a interaction node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented OREOLM, a novel model that incorporates symbolic KG reasoning with existing LMs. We showed that OREOLM can bring significant performance gain to open-domain QA benchmarks, both for closed-book and open-book settings, as well as encoder-only and encoder-decoder models. Additionally, OREOLM produces reasoning paths that helps interpret the model prediction.</p><p>In future, we'd like to improve OREOLM by training to conduct more reasoning steps, supporting locial reasoning, and apply OREOLM to a broader range of knowledge-intensive NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Limitations</head><p>Limited Reasoning Steps In our experiments, we show that using reasoning step T = 2 has better performance to T = 1 on one-hop and multi-hop (mostly two) QA datasets. Thus, it's a natural question about whether we could extending reasoning steps more? As previous KG reasoning mostly could support very long path (with LSTM design)</p><p>Though we didn't spend much time exploring before the paper submission, we indeed try using T = 3, but currently it didn't get better results. We hypothesize the following reasons: 1) A large portion of our current model's improvement relies on the weakly supervised relation pre-training. To do it, we construct a K-hop (K=2 now) subgraph, and sample dependency graph based on it. The larger K we choose, the more noise is included into the generated relation label, in an exponential increasing speed. Thus, it's harder to get accurate reasoning path ground-truth for high-order T . Another potential reason is that within Transformer model, the representation space in lower and upper layer might be very different, say, encode more syntax and surface knowledge at lower layers, while more semantic knowledge at upper layers. Currently we adopt a MLP projection head, wishing to map integrated knowledge into the same space, but it might have many flaws and need further improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Large Entity Embedding Table requires Pre-</head><p>Training and GPU resources Our current design has a huge entity embedding table, which should be learned through additional supervision and could not directly fine-tune to downstream tasks. This is restricts our approach's usage.</p><p>Require Entity Linking Current model design requires an additional step of entity linking for incoming questions, and then add special tokens as interface. A truly end-to-end model should identify which elements to start conducting reasoning by its own without relying on external models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Only support relational path-based reasoning</head><p>Though there are lots of potential reasoning tasks, such as logical reasoning, commonsense reasoning, physical reasoning, temporal reasoning, etc. Our current model design mainly focus on path-based relational reasoning, and it should not work for other reasoning tasks at current stage.</p><p>Unreasonable Assumption of Path Independency When we derive equation 1, we have the assumption that reasoning paths starting from different entities should be independent. This is not always correct, especially for questions that require logical reasoning, say, have conjunction or disjunction operation over each entity state. And thus our current methods might not work for those complex QA with logical dependencies. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Implementation Details</head><p>Entity Linking durine pre-training We use the 2021 Jan. English dump of Wikidata and Wikipedia. For each wikipedia page, we link all entity mentions with hyperlinks to WikiData entity entry, augment all other mentions with same aliases, tokenize via each LM's tokenizer and split into chunks with maximum token length allowed.</p><p>We then construct induced k-hop subgraphs connecting entities within each chunk for quickly get grounded computational graph.</p><p>For entities, Wikipedia provides hyperlinks with ground-truth entity ID, but it doesn't cover all the entity mentions, mostly hyperlinks only appear when this entity appears for the first time. Therefore, we first collect all entities appeared in hyperlinks as well as their aliases stored in WikiData, and then search any mentions that have any of these alias and link it to the corresponding entity.</p><p>Hyperparameters In this work, we don't have too much hyperparmaters to be tuned, as most parameters as well as optimizing setting of LM is fixed. Our random walk part is non-parametric. The only tunable hyperparamter is hidden dimension size. We simply choose one setting, which is 128 for entity embedding, and 768 for relation embedding. The former is because entity is super large (over 5M), so we use a reletively smaller dimension size. Detailed statistics about wikidata memory is in Table <ref type="table" target="#tab_3">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Dataset Details</head><p>Below shows details for each dataset, and the detailed dataset split is shown in Figure <ref type="figure">5</ref> Natural Questions <ref type="bibr" target="#b20">(Kwiatkowski et al., 2019)</ref> contains questions from Google search queries, and the answers are text spans in Wikipedia. We report short answer Exact Match (EM) performance. The open version of this dataset is obtained by discarding answers with more than 5 tokens.</p><p>WebQuestions (WQ) <ref type="bibr" target="#b1">(Berant et al., 2013)</ref> contains questions from Google Suggest API, and the answers are entities in Freebase.</p><p>TriviaQA <ref type="bibr" target="#b17">(Joshi et al., 2017)</ref> contains trivia questions and answers are text spans from the Web. We report Exact Match (EM) performance. We use its unfiltered version for evaluation.</p><p>HotpotQA <ref type="bibr" target="#b36">(Yang et al., 2018</ref>) is a multi-hop QA dataset. There are two evaluation settings. In the distractor setting, 10 candidate paragraphs are provided for each question, of which there are two golden paragraphs. In the full-wiki setting, a model is required to extract paragraphs from the entire Wikipedia. We report Exact Match (EM) on fullwiki setting.</p><p>Complex WebQuestions (Talmor and <ref type="bibr">Berant, 2018)</ref> is a dataset that composite simple one-hot questions in WebQuestionsSP by extending entities or adding constraints, so that each question eequires complex reasoning to solve.</p><p>WebQuestionsSP <ref type="bibr" target="#b38">(Yih et al., 2015)</ref> is annotated dataset from WebQuestions, such taht each quetsion is answerable using Freebase via a SQL query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Discussion with Previous Works</head><p>Compare with FILM Though FILM has the advantage of end-to-end training and easily modification of knowledge memory, it simply stacks KG module on top of LM without interaction, and can only handle one-hop relational query that is answerable by KG. Our approach, OREOLM, follows the same memory idea by encoding KG into LM parameter, and we desire LM and KG reasoning module could interact and collaboratively improve each other.</p><p>Notably, OREOLM with T = 1 shares a similar design with FILM. The major differences are: 1) they store every triplet as a key-value pair, while we explicitly keep the KG adjacency matrix and conduct a random walk, which has smaller search space and is more controllable. 2) They add the memory on top of LM, and thus the knowledge could not help language understanding, and FILM could mainly help wikipedia-answerable questions. Instead, we insert the KIL layer amid LM layers to encourage interaction, and thus the model could also benefit encoder-decoder model (as shown above).</p><p>Compare with Previous Path-Based Reasoning and Retrieval Pre-Training Note that as our definition of entity state ? i and relation action ? i are both continuous probabilistic vector, the whole KG Reasoning is fully differentiable and thus could be integrated into LM seamlessly and trained end-toend. This is different from previous path traversal works such as DeepPath <ref type="bibr" target="#b34">(Xiong et al., 2017)</ref> and MINERVA <ref type="bibr" target="#b7">(Das et al., 2018)</ref>  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An Illustrative figure of OREOLM. Compared with previous KBQA systems that stack reasoner on top of LM, OREOLM enables interaction between the two.</figDesc><graphic url="image-1.png" coords="1,306.14,212.61,218.27,114.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Model architecture of OREOLM. Three key procedures are highlighted in red dotted box: 1) Relation Prediction (Sec. 2.1.1): Knowledge Interaction Layers (KIL) predicts relation action for each entity mention. 2) One-step State Transition (Sec. 2.1.2): Based on the predicted relation, KG re-weights each graph and conduct contextualized random walk to update entity distribution state. 3) Knowledge Integration (Sec. 2.2): An weighted aggregated entity embedding is added into a placeholder token as retrieved knowledge.</figDesc><graphic url="image-2.png" coords="3,65.02,70.85,453.56,225.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>OREOLM factorizes P a|q, M by incorporat-ing possible paths ? as a latent variable, yielding:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>calculate a different weighted adjacency matrix A (t) i ? R |E|?|E| by adjusting the edge weight:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 1 :</head><label>1</label><figDesc>Pytorch Pseudocode of CRW def ContextualizedRandomWalk( i_init, KG, # initial entity index and Graph w_deg, w_rel, # inv(degree) and relation weights p_ent, p_rel # entity and predicted relation dis-# tribution tensor @ t-th step. ): -&gt; FloatTensor # Get &lt;src, rel, tgt&gt; edge list of k-hop subgraph i_src, i_rel, i_tgt = k_hop_subgraph(i_init, KG) # Gather entity and relation probability to edge p_src = (p_ent * w_deg)[:, i_src] # N x n_edge p_rel = (p_rel * w_rel)[:, i_rel] # N x n_edge p_edge = l1_normalize(p_src * p_rel, dim=1) # Scatter edge probability to target node p_ent = scatter_add(src=p_edge, idx=i_tgt, dim=1) return p_ent #(t+1)-th step's entity distribution</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Pre-training sample w/ golden reasoning path. More real examples are shown inTable 8 in Appendix.</figDesc><graphic url="image-3.png" coords="6,70.86,70.85,218.28,121.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Testing the reasoning capacity of OREOLM to infer missing relations. On the left, the barplot shows the transfer performance on EQ before and after removing relation edges, OREOLM (T = 2) is less influenced. On the right shows reasoning paths (rules) automatically generated by OREOLM for each missing relation.</figDesc><graphic url="image-4.png" coords="9,70.86,71.84,462.63,59.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>) construct an entity-mention bipartite graph and then model the QA reasoning as graph traversal by filtering only the contexts that are relevant to the question. Lin et al. (2019), Feng et al. (2020) and Yasunaga et al. (2021) parse the question into a sub-graph of knowledge base, and apply graph neural networks as reasoner for extracting one of the entities as the answer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Table 10: Example of QA prediction with reasoning path on NQ (part 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>entity mention m i . KIL can be flexibly inserted into arbitrary LM intermediate layer. By default, we just insert each KIL every N Transformer-based LM layers, thus the input to the t-th KIL are contextualized embeddings of each token k as LM</head><label></label><figDesc>the relation distribution to guide walking through the graph. Denote the corresponding [REL] token as REL[i] (and similarly for other special tokens). The contextual embedding LM</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(t)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>REL[i]</cell></row><row><cell></cell><cell></cell><cell cols="3">[REL], [T-ENT] to-</cell></row><row><cell cols="5">kens after each (t) k , including added special tokens.</cell></row><row><cell cols="5">2.1 LM involved KG Reasoning We first introduce the reasoning process</cell></row><row><cell>P e t i |q, e &lt;t i</cell><cell cols="2">= r P r t i |q, e &lt;t i</cell><cell cols="2">? P e t i |r t i , e &lt;t i</cell><cell>.</cell></row><row><cell cols="3">2.1.1 Relation Prediction.</cell><cell></cell></row><row><cell cols="5">For each entity mention m i , we desire to predict which relation action should take r t i as instruction to transit state. We define the predicted relation</cell></row><row><cell cols="2">probability vector ?</cell><cell cols="2">(t) i = P rel r t i |q, e &lt;t i</cell><cell>? R |R|</cell></row><row><cell cols="5">1 Throughout the paper, all vectors are row-vectors</cell></row></table><note><p><p><p><p>2 </p>For Wikipedia pretraining, we use the ground-truth entity label as one-hot initialization for ? 0 i . For downstream tasks we use GENRE</p><ref type="bibr" target="#b4">(Cao et al., 2021)</ref> </p>to get top 5 entity links. representing</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Statistics and parameter of KG Memory.</figDesc><table><row><cell>Name</cell><cell>Number</cell><cell>dimension</cell><cell>#param (M)</cell></row><row><cell>Number of Entity Number of Relation Number of Edges</cell><cell>4,947,397 2,008 45,217,947</cell><cell>128 768 -</cell><cell>633 1.5 47</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Closed-Book QA OREOLM is designed for improving Closed-Book QA, so we first evaluate it in this setting. Closed-Book Generative QA performance of Encoder-Decoder LM on Single-and Multi-hop Dataset.</figDesc><table><row><cell>Models</cell><cell>#param</cell><cell cols="4">NQ WQ TQA ComplexWQ HotpotQA</cell></row><row><cell>T5 (Base) + OREOLM (T =1) + OREOLM (T =2)</cell><cell cols="2">0.22B 0.23B + 0.68B 28.3 30.6 25.9 27.9 0.24B + 0.68B 28.9 31.2</cell><cell>29.1 32.4 33.7</cell><cell>11.6 20.8 23.7</cell><cell>22.8 24.1 26.3</cell></row><row><cell>T5 (Large) + OREOLM (T =1) + OREOLM (T =2)</cell><cell cols="2">0.74B 0.75B + 0.68B 30.6 32.8 28.5 30.6 0.76B + 0.68B 31.0 34.3</cell><cell>35.9 39.1 40.0</cell><cell>16.7 24.5 27.1</cell><cell>25.3 28.2 31.4</cell></row><row><cell>T5-3B (Roberts et al., 2020) T5-11B (Roberts et al., 2020)</cell><cell>3B 11B</cell><cell>30.4 33.6 32.6 37.2</cell><cell>43.4 50.1</cell><cell>--</cell><cell>27.8 30.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Closed-Book Entity Prediction performance of Encoder LM on WikiData-Answerable Dataset.</figDesc><table><row><cell>Models</cell><cell>#param (B)</cell><cell>WQ-SP</cell><cell>TQA</cell></row><row><cell>EaE (F?vry et al., 2020) FILM (Verga et al., 2021) KEPLER (Wang et al., 2019)</cell><cell>0.11 + 0.26 0.11 + 0.72 0.12</cell><cell>62.4 78.1 48.3</cell><cell>24.4 37.3 24.1</cell></row><row><cell>RoBERTa (Base) + OREOLM (T =1) + OREOLM (T =2)</cell><cell>0.12 0.12 + 0.68 0.13 + 0.68</cell><cell>43.5 80.1 80.9</cell><cell>21.3 39.7 40.3</cell></row><row><cell cols="2">Ablation Studies</cell><cell></cell><cell></cell></row><row><cell>RoBERTa + Concat KB + L SSM</cell><cell>0.12</cell><cell>47.1</cell><cell>22.6</cell></row><row><cell>+ OREOLM (T =2) w/o PT w. L SSM w. L SSM + Lent</cell><cell>0.13 + 0.68 0.13 + 0.68 0.13 + 0.68</cell><cell>46.9 51.9 68.4</cell><cell>22.7 26.8 35.7</cell></row><row><cell>Models</cell><cell>#param (B)</cell><cell>NQ</cell><cell>TQA</cell></row><row><cell>Graph-Retriever (Min et al., 2019) REALM (Guu et al., 2020)</cell><cell>0.11 0.33 + 16</cell><cell>34.7 40.4</cell><cell>55.8 -</cell></row><row><cell>DPR (Karpukhin et al., 2020) + BERT + OREOLM (DPR, T =2)</cell><cell>0.56 + 16 0.57 + 17</cell><cell>41.5 43.7</cell><cell>56.8 58.5</cell></row><row><cell>FiD (Base) = DPR + T5 (Base) + OREOLM (T5, T =2) + OREOLM (DPR &amp; T5, T =2)</cell><cell>0.44 + 16 0.45 + 17 0.46 + 17</cell><cell>48.2 49.3 51.1</cell><cell>65.0 67.1 68.4</cell></row><row><cell>FiD (Large) = DPR + T5 (Large) + OREOLM (T5, T =2) + OREOLM (DPR &amp; T5, T =2)</cell><cell>0.99 + 16 0.99 + 17 1.00 + 17</cell><cell>51.4 52.4 53.2</cell><cell>67.6 68.9 69.5</cell></row><row><cell>KG-FiD (Base) (Yu et al., 2022a) KG-FiD (Large) (Yu et al., 2022a) EMDR 2 (Sachan et al., 2021b)</cell><cell>0.44 + 16 0.99 + 16 0.44 + 16</cell><cell>49.6 53.2 52.5</cell><cell>66.7 69.8 71.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Open-Book QA Evaluation.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 11 :</head><label>11</label><figDesc>Example of QA prediction with reasoning path on NQ (part 2).</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>We denote a non-linear MLP projection as X-Proj(h) =W X 2 ?(W X 1 h+b1)+b2, where X have different instantiations.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement We sincerely thank anonymous reviewers for their constructive comments to improve this paper. The project was partially supported in part by <rs type="funder">CISCO</rs>, <rs type="funder">NSF</rs> <rs type="grantNumber">III-1705169</rs>, <rs type="funder">NSF</rs> <rs type="grantNumber">1937599</rs>, <rs type="funder">NASA</rs>, <rs type="funder">Okawa Foundation Grant, Amazon Research Awards</rs>, <rs type="funder">Cisco</rs> research grant, and Picsart gift. Ziniu is supported by the <rs type="funder">Amazon Fellowship and Baidu PhD Fellowship</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_JkaS3Pf">
					<idno type="grant-number">III-1705169</idno>
				</org>
				<org type="funding" xml:id="_A2Eg274">
					<idno type="grant-number">1937599</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>and action as discrete and could only be trained via reinforcement learning rewards. The reasoner training is also different from passage retrieval pretraining <ref type="bibr" target="#b15">(Guu et al., 2020;</ref><ref type="bibr">Sachan et al., 2021a)</ref>, as the passage are naturally consisted of discrete tokens, and thus the reader is still required to reencode the question with each passage, and different objectives are required to train retriever and reader separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion of Graph Walking-based Reasoning vs Graph Neural Networks Recently, Graph</head><p>Neural Networks (GNNs) have shown superior performance for structured representation learning. There's also a lot of works trying to use GNNs for Question Answering <ref type="bibr" target="#b37">(Yasunaga et al., 2021;</ref><ref type="bibr" target="#b43">Zhang et al., 2022)</ref>. The one that has very similar motivation with us is GreaseLM. Therefore, a natural question is, whether could we use GNN instead of the non-parametric random walk module, for ODQA?</p><p>To answer this question, let's consider a simplest setup of GNN. We could identify initial entities, connected them via a k-hop subgraph, and encode graph with text <ref type="bibr" target="#b43">(Zhang et al., 2022)</ref> or independently <ref type="bibr">(Yu et al., 2022b)</ref>. When we want to retrieve knowledge from graph to LM, normally we just take the contextualized node embedding as input for knowledge fusion.</p><p>In this setup, say the answer is K-hop away from an initial entity, the ground-truth reasoning path is e 0 , r 1 , e 1 , r 2 , ..., e k-1 , r k , e k = a. Using our method, we first predict r1, transit to e 1 , and step by step conduct reasoning via walking. However, if we use GNN's final embedding, it requires to pass information from neighbor to itself. Therefore, suppose we have a K-layer GNN, the first step should be identify r k , and pass information from answer e k = a to e k-1 . This is conter-intuitive as we normally cannot assume to know the answer, nor knowling the last step to reach the answer. In situations where all candidate answer is given, like CommonSenseQA, where GreaseLM mainly works on, this problem is less harmful as it's guaranteed to contain the answer in a restricted small graph. However, in open-domain setup, we need to try best to narrow down the search space by following the forward reasoning instead of the backward manner. Therefore, in this work we adopt walking-based reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Illustration of Pre-Trained Data and Reasoning Paths</head><p>The pre-training samples and reasoning paths (generated by T5-large on NQ dataset) is shown from Table <ref type="table">8</ref>      </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to retrieve reasoning paths over wikipedia graph for question answering</title>
		<author>
			<persName><forename type="first">Akari</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations, ICLR 2020</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26">2020. April 26-30, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Grand Hyatt Seattle, Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2013-10">2013. 2013. 18-21 October 2013</date>
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName><forename type="first">Kurt</forename><forename type="middle">D</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="DOI">10.1145/1376616.1376746</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the ACM SIGMOD International Conference on Management of Data<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008-06-10">2008. 2008. June 10-12, 2008</date>
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Garc?a-Dur?n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held</title>
		<meeting><address><addrLine>Lake Tahoe, Nevada, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-12-05">2013. December 5-8, 2013</date>
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Autoregressive entity retrieval</title>
		<author>
			<persName><forename type="first">Nicola</forename><surname>De Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
		<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<publisher>OpenReview</publisher>
			<date type="published" when="2021-05-03">2021. May 3-7, 2021</date>
		</imprint>
	</monogr>
	<note>net</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reading wikipedia to answer opendomain questions</title>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1171</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-07-30">2017. July 30 -August 4</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Augmenting pre-trained language models with qa-memory for open-domain question answering</title>
		<author>
			<persName><forename type="first">Wenhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pat</forename><surname>Verga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Michiel De Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2204.04581</idno>
		<idno>CoRR, abs/2204.04581</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning</title>
		<author>
			<persName><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shehzaad</forename><surname>Dhuliawala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishan</forename><surname>Durugkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshay</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<title level="s">Conference Track Proceedings. OpenReview.net</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30">2018. 2018. April 30 -May 3, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Knowledge base question answering by case-based reasoning over subgraphs</title>
		<author>
			<persName><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ameya</forename><surname>Godbole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankita</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elliot</forename><surname>Tower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<idno>CoRR, abs/2202.10610</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Lazaros Polymenakos, and Andrew McCallum. 2021. Casebased reasoning for natural language queries over knowledge bases</title>
		<author>
			<persName><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dung</forename><surname>Thai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ameya</forename><surname>Godbole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Yoon Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizhen</forename><surname>Tan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.755</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-11-11">7-11 November, 2021</date>
			<biblScope unit="page" from="9594" to="9611" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06-02">2019. June 2-7, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Differentiable reasoning over a virtual knowledge base</title>
		<author>
			<persName><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vidhisha</forename><surname>Balachandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations, ICLR 2020</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26">2020. April 26-30, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cognitive graph for multi-hop reading comprehension at scale</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qibin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1259</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2019-07-28">2019. July 28-August 2, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2694" to="2703" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Scalable multihop relational reasoning for knowledge-aware question answering</title>
		<author>
			<persName><forename type="first">Yanlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyue</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11-16">2020. 2020. November 16-20, 2020</date>
			<biblScope unit="page" from="1295" to="1309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Entities as experts: Sparse memory access with entity supervision</title>
		<author>
			<persName><surname>Thibault F?vry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baldini</forename><surname>Livio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><surname>Kwiatkowski</surname></persName>
		</author>
		<idno>CoRR, abs/2004.07202</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">REALM: retrievalaugmented language model pre-training</title>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zora</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<idno>abs/2002.08909</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Relation-guided pre-training for open-domain question answering</title>
		<author>
			<persName><forename type="first">Ziniu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-emnlp.292</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana</title>
		<meeting><address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">2021. 16-20 November, 2021</date>
			<biblScope unit="page" from="3431" to="3448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1147</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-07-30">2017. 2017. July 30 -August 4</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno>CoRR, abs/2004.04906</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Jointgt: Graph-text joint representation learning for text generation from knowledge graphs</title>
		<author>
			<persName><forename type="first">Pei</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haozhe</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Ran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.223</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08-01">2021. August 1-6, 2021</date>
			<biblScope unit="page" from="2526" to="2538" />
		</imprint>
	</monogr>
	<note>ACL/IJCNLP 2021 of Findings of ACL</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Natural questions: a benchmark for question answering research</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><forename type="middle">P</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="452" to="466" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Random walk inference and learning in A large scale knowledge base</title>
		<author>
			<persName><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, UK</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2011-07-31">2011. 2011, 27-31 July 2011</date>
			<biblScope unit="page" from="529" to="539" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">2021a. Question and answer test-train overlap in open-domain question answering datasets</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pontus</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">April 19 -23, 2021</date>
			<biblScope unit="page" from="1000" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Aleksandra Piktus, Pontus Stenetorp, and Sebastian Riedel. 2021b. PAQ: 65 million probably-asked questions and what you can do with them</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linqing</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pasquale</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heinrich</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName><surname>K?ttler</surname></persName>
		</author>
		<idno>CoRR, abs/2102.07033</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Kagnet: Knowledge-aware graph networks for commonsense reasoning</title>
		<author>
			<persName><forename type="first">Xinyue</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Ren</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1282</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11-03">2019. November 3-7, 2019</date>
			<biblScope unit="page" from="2829" to="2839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Differentiable open-ended commonsense reasoning</title>
		<author>
			<persName><forename type="first">Haitian</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhuwan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manzil</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><surname>Cohen</surname></persName>
		</author>
		<idno>CoRR, abs/2010.14439</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">KG-BART: knowledge graph-augmented BART for generative commonsense reasoning</title>
		<author>
			<persName><forename type="first">Ye</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021-02-02">2021. February 2-9, 2021</date>
			<biblScope unit="page" from="6418" to="6425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Knowledge guided text retrieval and reading for open domain question answering</title>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno>CoRR, abs/1911.03868</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">E-BERT: efficient-yet-effective entity embeddings for BERT</title>
		<author>
			<persName><forename type="first">Nina</forename><surname>P?rner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulli</forename><surname>Waltinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Sch?tze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.71</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event</title>
		<imprint>
			<date type="published" when="2020-11">2020. 16-20 November 2020</date>
			<biblScope unit="page" from="803" to="818" />
		</imprint>
	</monogr>
	<note>EMNLP 2020 of Findings of ACL. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">67</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Query2box: Reasoning over knowledge graphs in vector space using box embeddings</title>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hongyu Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th International Conference on Learning Representations, ICLR 2020</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26">2020. April 26-30, 2020</date>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">How much knowledge can you pack into the parameters of a language model?</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.437</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="5418" to="5426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Wikidata: a free collaborative knowledgebase</title>
		<author>
			<persName><forename type="first">Denny</forename><surname>Vrandecic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Kr?tzsch</surname></persName>
		</author>
		<idno type="DOI">10.1145/2629489</idno>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">KEPLER: A unified model for knowledge embedding and pre-trained language representation</title>
		<author>
			<persName><forename type="first">Xiaozhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaocheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<idno>CoRR, abs/1911.06136</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deeppath: A reinforcement learning method for knowledge graph reasoning</title>
		<author>
			<persName><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thien</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/d17-1060</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-09-09">2017. 2017. September 9-11, 2017</date>
			<biblScope unit="page" from="564" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-08">2019. 2019. 2019. December 8-14, 2019</date>
			<biblScope unit="page" from="5754" to="5764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Hotpotqa: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d18-1259</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-10-31">2018. October 31 -November 4, 2018</date>
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">QA-GNN: reasoning with language models and knowledge graphs for question answering</title>
		<author>
			<persName><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.45</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-06-06">2021. June 6-11, 2021</date>
			<biblScope unit="page" from="535" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Semantic parsing via staged query graph generation: Question answering with knowledge base</title>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/p15-1128</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015-07-26">2015. 2015. July 26-31, 2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1321" to="1331" />
		</imprint>
	</monogr>
	<note>The Association for Computer Linguistics</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">2022a. Kg-fid: Infusing knowledge graph in fusion-in-decoder for opendomain question answering</title>
		<author>
			<persName><forename type="first">Donghan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">May 22-27, 2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4961" to="4974" />
		</imprint>
	</monogr>
	<note>ACL 2022</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">JAKET: joint pre-training of knowledge graph and language understanding</title>
		<author>
			<persName><forename type="first">Donghan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Conference on Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">AAAI</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">2022c. Generate rather than retrieve: Large language models are strong context generators</title>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Iter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumya</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2209.10063</idno>
		<idno>CoRR, abs/2209.10063</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">A survey of knowledge-enhanced text generation</title>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaitang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>ACM Computing Survey</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Greaselm: Graph reasoning enhanced language models for question answering</title>
		<author>
			<persName><forename type="first">Xikun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<idno>CoRR, abs/2201.08860</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">ERNIE: enhanced language representation with informative entities</title>
		<author>
			<persName><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1139</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07-28">2019. July 28-August 2, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1441" to="1451" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
