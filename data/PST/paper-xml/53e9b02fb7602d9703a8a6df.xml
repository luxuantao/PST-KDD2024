<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Concurrency Control Performance Modeling: Alternatives and Implications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Agrawal</forename><surname>Rakesh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bell</forename><surname>At&amp;t</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Laboratories</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Miron</forename><surname>Carey</surname></persName>
						</author>
						<author>
							<persName><surname>Livny</surname></persName>
						</author>
						<author>
							<persName><roleName>AT&amp;T</roleName><forename type="first">R</forename><surname>Agrawal</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bell</forename><surname>Laboratories</surname></persName>
						</author>
						<author>
							<persName><roleName>NJ</roleName><forename type="first">Murray</forename><surname>Hill</surname></persName>
						</author>
						<author>
							<persName><forename type="first">;</forename><forename type="middle">M J</forename><surname>Carey</surname></persName>
						</author>
						<author>
							<persName><forename type="first">M</forename><surname>Livny</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Computer Sciences Department</orgName>
								<orgName type="institution">University of Wisconsin</orgName>
								<address>
									<postCode>53706</postCode>
									<settlement>Madison</settlement>
									<region>WI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Concurrency Control Performance Modeling: Alternatives and Implications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E2DAF0C43EAC02BCAA71947B8F630C99</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.2.4 [Database Management]: Systems-transaction processing; D.4.8 [Operating Systems]: Performance-simulation</term>
					<term>modeling and prediction Algorithms</term>
					<term>Performance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A number of recent studies have examined the performance of concurrency control algorithms for database management systems. The results reported to date, rather than being definitive, have tended to be contradictory.</p><p>In this paper, rather than presenting "yet another algorithm performance study," we critically investigate the assumptions made in the models used in past studies and their implications. We employ a fairly complete model of a database environment for studying the relative performance of three different approaches to the concurrency control problem under a variety of modeling assumptions. The three approaches studied represent different extremes in how transaction conflicts are dealt with, and the assumptions addressed pertain to the nature of the database system's resources, how transaction restarts are modeled, and the amount of information available to the concurrency control algorithm about transactions' reference strings. We show that differences in the underlying assumptions explain the seemingly contradictory performance results. We also address the question of how realistic the various assumptions are for actual database systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Research in the area of concurrency control for database systems has led to the development of many concurrency control algorithms. Most of these algorithms are based on one of three basic mechanisms: locking <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b45">44,</ref><ref type="bibr" target="#b49">48]</ref>, timestamps <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b53">52]</ref>, and optimistic concurrency control (also called commit-time validation or certification) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr">271</ref>. Bernstein and Goodman <ref type="bibr">[9,</ref> 101 survey many of the algorithms that have been developed and describe how new algorithms may be created by combining the three basic mechanisms.</p><p>Given the ever-growing number of available concurrency control algorithms, considerable research has recently been devoted to evaluating the performance of concurrency control algorithms. The behavior of locking has been investigated using both simulation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b39">[39]</ref><ref type="bibr" target="#b40">[40]</ref><ref type="bibr" target="#b41">[41]</ref><ref type="bibr">471</ref> and analytical models <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b51">50,</ref><ref type="bibr" target="#b52">51,</ref><ref type="bibr" target="#b54">53]</ref>. A qualitative study that discussed performance issues for a number of distributed locking and timestamp algorithms was presented in <ref type="bibr" target="#b6">[7]</ref>, and an empirical comparison of several concurrency control schemes was given in <ref type="bibr" target="#b33">[34]</ref>. Recently, the performance of different concurrency control mechanisms has been compared in a number of studies. The performance of locking was compared with the performance of basic timestamp ordering in <ref type="bibr" target="#b20">[21]</ref> and with basic and multiversion timestamp ordering in <ref type="bibr" target="#b29">[30]</ref>. The performance of several alternatives for handling deadlock in locking algorithms was studied in <ref type="bibr" target="#b5">[6]</ref>. Results of experiments comparing locking to the optimistic method appeared in [42 and 431, and the performance of several variants of locking, basic timestamp ordering, and the optimistic method was compared in [12 and 151. Finally, the performance of several integrated concurrency control and recovery algorithms was evaluated in [l and <ref type="bibr">21.</ref> These performance studies are informative, but the results that have emerged, instead of being definitive, have been very contradictory. For example, studies by Carey and Stonebraker <ref type="bibr" target="#b14">[15]</ref> and Agrawal and Dewitt <ref type="bibr" target="#b1">[2]</ref> suggest that an algorithm that uses blocking instead of restarts is preferable from a performance viewpoint, but studies by Tay [50, 511 and Balter et al, <ref type="bibr" target="#b5">[6]</ref> suggest that restarts lead to better performance than blocking. Optimistic methods outperformed locking in <ref type="bibr" target="#b19">[20]</ref>, whereas the opposite results were reported in [2 and 151. In this paper, rather than presenting "yet another algorithm performance study," we examine the reasons for these apparent contradictions, addressing the models used in past studies and their implications.</p><p>The research that led to the development of the many currently available concurrency control algorithms was guided by the notion of serializability as the correctness criteria for general-purpose concurrency control algorithms <ref type="bibr">[ 11, 19, 331.</ref> Transactions are typically viewed as sequences of read and write requests, and the interleaved sequence of read and write requests for a concurrent execution of transactions is called the execution log. Proving algorithm correctness then amounts to proving that any log that can be generated using a particular concurrency control algorithm is equivalent to some serial log (i.e., one in which all requests from each individual transaction are adjacent in the log). Algorithm correctness work has therefore been guided by the existence of this widely accepted standard approach based on logs and serializability. Algorithm performance work has not been so fortunate-no analogous standard performance model has been available to guide the work in this area. As we will see shortly, the result is that nearly every study has been based on its own unique set of assumptions regarding database system resources, transaction behavior, and other such issues.</p><p>In this paper, we begin by establishing a performance evaluation framework based on a fairly complete model of a database management system. Our model captures the main elements of a database environment, including both users (i.e., terminals, the source of transactions) and physical resources for storing and processing the data (i.e., disks and CPUs), in addition to the characteristics of the workload and the database. On the basis of this framework, we then show that differences in assumptions explain the apparently contradictory performance results from previous studies. We examine the effects of alternative assumptions, and we briefly address the question of which alternatives seem most reasonable for use in studying the performance of database management systems.</p><p>In particular, we critically examine the common assumption of infinite resources. A number of studies (e.g., <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b51">50,</ref><ref type="bibr">511)</ref> compare concurrency control algorithms under the assumption that transactions progress at a rate independent of the number of active transactions. In other words, they proceed in parallel rather than in an interleaved manner. This is only really possible in a system with enough resources so that transactions neuer have to wait before receiving CPU or I/O service-hence our choice of the phrase "infinite resources." We will investigate this assumption by performing studies with truly infinite resources, with multiple CPU-I/O devices, and with transactions that think while holding locks. The infinite resource case represents an "ideal" system, the multiple CPU-I/O device case models a class of multiprocessor database machines, and having transactions think while executing models an interactive workload.</p><p>In addition to these resource-related assumptions, we examine two modeling assumptions related to transaction behavior that have varied from study to study. In each case, we investigate how alternative assumptions affect the performance results. One of the additional assumptions that we address is the fake restart assumption, in which it is assumed that a restarted transaction is replaced by a new, independent transaction, rather than running the same transaction over again. This assumption is nearly always used in analytical models in order to make the modeling of restarts tractable. Another assumption that we examine has to do with write-lock acquisition. A number of studies that distinguish between read and write locks assume that read locks are set on read-only items and that write locks are set on the items to be updated when they are first read. In reality, however, transactions often acquire a read lock on an item, then examine the item, and only then request that the read lock be upgraded to a write lockbecause a transaction must usually examine an item before deciding whether or not to update it [B. <ref type="bibr">Lindsay, personal communication, 19841.</ref> We examine three concurrency control algorithms in this study, two locking algorithms and an optimistic algorithm, which represent extremes as to when and how they detect and resolve conflicts. Section 2 describes our choice of concurrency control algorithms. We use a simulator based on a closed queuing model of a single-site database system for our performance studies. The structure and characteristics of our model are described in Section 3. Section 4 discusses the performance metrics and statistical methods used for the experiments, and it also discusses how a number of our parameter values were chosen. Section 5 presents the resource-related performance experiments and results. Section 6 presents the results of our examination of the other modeling assumptions l R. Agrawal et al. described above. Finally, in Section 7 we summarize the main conclusions of this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">CONCURRENCY CONTROL STRATEGIES</head><p>A transaction T is a sequence of actions {ai, u2, . . . , a,], where ci is either read or write. Given a concurrent execution of transactions, action oi of transaction Ti and action aj of Tj conflict if they access the same object and either (1) oi is read and aj is write, or (2) ai is write and aj is read or write. The various concurrency control algorithms basically differ in the time when they detect conflicts and the way that they resolve conflicts <ref type="bibr" target="#b8">[9]</ref>. For this study we have chosen to examine the following three concurrency control algorithms that represent extremes in conflict detection and resolution:</p><p>Blocking. Transactions set read locks on objects that they read, and these locks are later upgraded to write locks for objects that they also write. If a lock request is denied, the requesting transaction is blocked. A waits-for graph of transactions is maintained <ref type="bibr" target="#b22">[23]</ref>, and deadlock detection is performed each time a transaction blocks.' If a deadlock is discovered, the youngest transaction in the deadlock cycle is chosen as the victim and restarted. Dynamic two-phase locking <ref type="bibr" target="#b22">[23]</ref> is an example of this strategy.</p><p>Immediate-Resturt. As in the case of blocking, transactions read-lock the objects that they read, and they later upgrade these locks to write locks for objects that they also write. However, if a lock request is denied, the requesting transaction is aborted and restarted after a restart delay. The delay period, which should be on the order of the expected response time of a transaction, prevents the same conflict from occurring repeatedly. A concurrency control strategy similar to this one was considered in <ref type="bibr">[50 and 511.</ref> Optimistic. Transactions are allowed to execute unhindered and are validated only after they have reached their commit points. A transaction is restarted at its commit point if it finds that any object that it read has been written by another transaction that committed during its lifetime. The optimistic method proposed by Kung and Robinson <ref type="bibr" target="#b26">[27]</ref> is based on this strategy. These algorithms represent two extremes with respect to when conflicts are detected. The blocking and immediate-restart algorithms are based on dynamic locking, so conflicts are detected as they occur. The optimistic algorithm, on the other hand, does not detect conflicts until transaction-commit time. The three algorithms also represent two different extremes with respect to conflict resolution. The blocking algorithm blocks transactions to resolve conflicts, restarting them only when necessary because of a deadlock. The immediate-restart and optimistic algorithms always use restarts to resolve conflicts.</p><p>One final note in regard to the three algorithms: In the immediate-restart algorithm, a restarted transaction must be delayed for some time to allow the conflicting transaction to complete; otherwise, the same lock conflict will occur repeatedly. For the optimistic algorithm, it is unnecessary to delay the restarted whereas the throughput keeps increasing for the optimistic algorithm. These results agree with predictions in <ref type="bibr" target="#b19">[20]</ref> that were based on similar assumptions. Figure <ref type="figure" target="#fig_0">6</ref> shows the blocking and restart ratios for the three concurrency control algorithms. Note that the thrashing in blocking is due to the large increase in the number of times that a transaction is blocked, which reduces the number of transactions available to run and make forward progress, rather than to an increase in the number of restarts. This result is in agreement with the assertion in [6, 50 and 511 that under low resource contention and a high level of multiprogramming, blocking may start thrashing before restarts do. Although the restart ratio for the optimistic algorithm increases quickly with an increase in the multiprogramming level, new transactions start executing in place of the restarted ones, keeping the effective multiprogramming level high and thus entailing an increase in throughput.</p><p>Unlike the other two algorithms, the throughput of the immediate-restart algorithm reaches a plateau. This happens for the following reason: When a transaction is restarted in the immediate-restart strategy, a restart delay is invoked to allow the conflicting transaction to complete before the restarted transaction is placed back in the ready queue. As described in Section 4, the duration of the delay is adaptive, equal to the running average of the response time. Because of this adaptive delay, the immediate-restart algorithm reaches a point beyond which all of the transactions that are not active are either in a restart delay state or else in a terminal thinking state (where a terminal is pausing between the completion of one transaction and submitting a new transaction). This point is reached when the number of active transactions in the system is such that a new transaction is basically sure to conflict with an active transaction and is therefore sure to be quickly restarted and then delayed. Such delays increase the average response time for transactions, which increases their average restart delay time; this has the effect of reducing the number of transactions competing for active status and in turn reduces the probability of conflicts. In other words, the adaptive restart delay creates a negative feedback loop (in the control system sense). Once the plateau is reached, there are simply no transactions waiting in the ready queue, and increasing the multiprogramming level is a "no-op" beyond this point. (Increasing the allowed number of active transactions cannot increase the actual number if none are waiting anyway.)</p><p>Figure <ref type="figure" target="#fig_1">7</ref> shows the mean response time (solid lines) and the standard deviation of response time (dotted lines) for each of the three algorithms. The response times are basically what one would expect, given the throughput results plus the fact that we have employed a closed queuing model. This figure does illustrate one interesting phenomenon that occurred in nearly all of the experiments reported in this paper: The standard deviation of the response time is much smaller for blocking than for the immediate-restart algorithm over most of the multiprogramming levels explored, and it is also smaller than that of the optimistic algorithm for the lower multiprogramming levels (i.e., until blocking's performance begins to degrade significantly because of thrashing). The immediate-restart algorithm has a large response-time variance due to its restart delay. When a transaction has to be restarted because of a lock conflict during its execution, its response time is increased by a randomly chosen restart delay period with a mean of one entire response time, and in addition the transaction must be run all over again. Thus, a restart leads to a large response time increase for the restarted transaction. The optimistic algorithm restarts transactions at the end of their execution and requires restarted transactions to be run again from the beginning, but it does not add a restart delay to the time required to complete a transaction. The blocking algorithm restarts transactions much less often than the other algorithms for most multiprogramming levels, and it restarts them during their execution (rather than at the end) and without imposing a restart delay. Because of this, and because lock waiting times tend to be quite a bit smaller than the additional response time added by a restart, blocking has the lowest response time variance until it starts to thrash significantly. A high variance in response time is undesirable from a user's standpoint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiment 2: Resource-Limited Situation</head><p>In Experiment 2 we analyzed the impact of limited resources on the performance characteristics of the three concurrency control algorithms. A database system with one resource unit (one CPU and two disks) was assumed for this experiment. The throughput results are presented in Figure <ref type="figure" target="#fig_2">8</ref>.</p><p>Observe that for all three algorithms, the throughput curves indicate thrashing-as the multiprogramming level is increased, the throughput first increases, then reaches a peak, and then finally either decreases or remains roughly constant. In a system with limited CPU and I/O resources, the achievable throughput may be constrained by one or more of the following factors: It may be that not enough transactions are available to keep the system resources busy. Alternatively, it may be that enough transactions are available, but because of data contention, the "useful" number of transactions is less than what is required to keep the resources "usefully" busy. That is, transactions that are blocked due to lock conflicts are not useful. Similarly, the use of resources to process transactions that are later restarted is not useful. Finally, it may be that enough useful, nonconflicting transactions are available, but that the available resources are already saturated.</p><p>As the multiprogramming level was increased, the throughput first increased for all three concurrency control algorithms since there were not enough transactions to keep the resources utilized at low levels of multiprogramming. Figure <ref type="figure">9</ref> shows the total (solid lines) and useful (dotted lines) disk utilizations for this experiment. As one would expect, there is a direct correlation between the useful utilization curves of Figure <ref type="figure">9</ref> and the throughput curves of Figure <ref type="figure" target="#fig_2">8</ref>. For blocking, the throughput peaks at mpl = 25, where the disks are being 97 percent utilized, with a useful utilization of 92 percent.' Increasing the multiprogramming level further only increases data contention, and the throughput decreases as the amount of blocking and thus the number of deadlock-induced restarts increase rapidly. For the optimistic algorithm, the useful utilization of the disks peaks at mpl = 10, and the throughput decreases with an increase in the multiprogramming level because of the increase in the restart ratio. This increase in the restart ratio means that a larger fraction of the disk time is spent doing work that will be redone later. For the immediate-restart algorithm, the throughput also peaks at mpl = 10 and then decreases, remaining roughly constant beyond 50. The throughput remains constant for this algorithm for the same reason as described in the last experiment: Increasing the allowable number of transactions has no effect beyond 50, since all of the nonactive transactions are either in a restart delay state or thinking. With regard to the throughput for the three strategies, several observations are in order. First, the maximum throughput (i.e., the best global throughput) was obtained with the blocking algorithm. Second, immediate-restart performed as well as or better than the optimistic algorithm. There were more restarts with the optimistic algorithm, and each restart was more expensive; this is reflected in the relative useful disk utilizations for the two strategies. Finally, the throughput achieved with the immediate-restart strategy for mpl = 200 was somewhat better than the throughput achieved with either blocking or the optimistic algorithm at this same multiprogramming level. Figure <ref type="figure">10</ref> gives the average and the standard deviation of response time for the three algorithms in the limited resource case. The differences are even more noticeable than in the infinite resource case. Blocking has the lowest delay (fastest response time) over most of the multiprogramming levels. The immediate-restart algorithm is next, and the optimistic algorithm has the worst response time. As for the standard deviations, blocking is the best, immediaterestart is the worst, and the optimistic algorithm is in between the two. As in Experiment 1, the immediate-restart algorithm exhibits a high response time variance.</p><p>One of the points raised earlier merits further discussion. Should the performance of the immediate-restart algorithm at mpl = 200 lead us to conclude that immediate-restart is a better strategy at high levels of multiprogramming? We believe that the answer is no, for several reasons. First, the multiprogramming ACM Transactions cm Database Systems, Vol. 12, No. 4, December 1987. level is internal to the database system, controlling the number of transactions that may concurrently compete for data and resources, and has nothing to do with the number of users that the database system may support; the latter is determined by the number of terminals. Thus, one should configure the system to keep multiprogramming at a level that gives the best performance. In this experiment, the highest throughput and smallest response time were achieved using the blocking algorithm at mpl = 25. Second, the restart delay in the immediate-restart strategy is there so that the conflicting transaction can complete before the restarted transaction is placed back into the ready queue. However, an unintended side effect of this restart delay in a system with a finite population of users is that it limits the actual multiprogramming level, and hence also limits the number of conflicts and resulting restarts due to reduced data contention. Although the multiprogramming level was increased to the total number of users (200), the actual average multiprogramming level never exceeded about 60. Thus, the restart delay provides a crude mechanism for limiting the multiprogramming level when restarts become overly frequent, and adding a restart delay to the other two algorithms should improve their performance at high levels of multiprogramming as well.</p><p>To verify this latter argument, we performed another experiment in which the adaptive restart delay was used for restarted transactions in both the blocking and optimistic algorithms as well. The throughput results that we obtained are shown in Figure <ref type="figure" target="#fig_5">11</ref>. It can be seen that introducing an adaptive restart delay helped to limit the multiprogramming level for the blocking and optimistic algorithms under high conflicts, as it does for immediate-restart, reducing data contention at the upper range of multiprogramming levels. Blocking emerges as the clear winner, and the performance of the optimistic algorithm becomes comparable to the immediate-restart strategy. The one negative effect that we observed from adding this delay was an increase in the standard deviation of the response times for the blocking and optimistic algorithms. Since a restart delay only helps performance for high multiprogramming levels, it seems that a better strategy is to enforce a lower multiprogramming level limit to avoid thrashing due to high contention and to maintain a small standard deviation of response time. realistic performance model, a side effect of the delay is that it can lead the database system to become "starved" for transactions when the multiprogramming level is increased beyond a certain point. That is, increasing the multiprogramming level has no effect on system throughput beyond this point because the actual number of active transactions does not change. This form of starvation can lead an otherwise increasing throughput to reach a plateau when viewed as a function of the multiprogramming level. In order to verify that our conclusions were not distorted by the inclusion of a think time, we repeated Experiments 1 and 2 with no think time (i.e., with e&amp;-think-time = 0). The throughput results for these experiments are shown in Figures <ref type="figure" target="#fig_25">12</ref> and<ref type="figure" target="#fig_8">13</ref>, and the figures to which these results should be compared are Figures <ref type="figure">5</ref> and<ref type="figure" target="#fig_2">8</ref>. It is clear from these figures that, although the exact performance numbers are somewhat different (because it is now never the case that the system is starved for transactions while one or more terminals is in a thinking state), the relative performance of the algorithms is not significantly affected. The explanations given earlier for the observed performance trends are almost all applicable here as well. In the infinite resource case (Figure <ref type="figure" target="#fig_7">12</ref>), blocking begins thrashing beyond a certain point, and the immediate-restart algorithm reaches a plateau because of the large number of restarted transactions that are delaying (due to the restart delay) before running again. The only significant difference in the infinite resource performance trends is that the throughput of the optimistic algorithm continues to improve as the multiprogramming level is increased, instead of reaching a plateau as it did when terminals spent some time in a thinking state (and thus sometimes caused the actual number of transactions in the system to be less than that allowed by the multiprogramming level). Franaszek and Robinson predicted this <ref type="bibr" target="#b19">[20]</ref>, predicting logarithmically increasing throughput for the optimistic algorithm as the number of active transactions increases under the infinite resource assumption. Still, this result does not alter the general conclusions that were drawn from Figure <ref type="figure">5</ref> regarding the relative performance of the algorithms. In the limited resource case (Figure <ref type="figure" target="#fig_8">13</ref>), the throughput for each of the algorithms peaks when resources become saturated, decreasing beyond this point as more and more resources are wasted because of restarts, just as it did before (Figure <ref type="figure" target="#fig_2">8</ref>). Again, fewer and/or earlier restarts lead to better performance in the case of limited resources. On the basis of the lack of significant differences between the results obtained with and without the external think time, then, we can safely conclude that incorporating this delay in our model has not distorted our results. The remainder of the experiments in this paper will thus be run using a nonzero external think time (just like Experiments 1 and 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Experiment 3: Multiple Resources</head><p>In this experiment we moved the system from limited resources toward infinite resources, increasing the level of resources available to 5, 10, 25, and finally 50 resource units. This experiment was motivated by a desire to investigate performance trends as one moves from the limited resource situation of Experiment 2 toward the infinite resource situation of Experiment 1. Since the infinite resource assumption has sometimes been justified as a way of investigating what performance trends to expect in systems with many processors <ref type="bibr" target="#b19">[20]</ref>, we were interested  in determining where (i.e., at what level of resources) the behavior of the system would begin to approach that of the infinite resource case in an environment such as a multiprocessor database machine. For the cases with 5 and 10 resource units, the relative behavior of the three concurrency control strategies was fairly similar to the behavior in the case of just 1 resource unit. The throughput results for these two cases are shown in Figures <ref type="figure" target="#fig_9">14</ref> and<ref type="figure" target="#fig_12">16</ref>, respectively, and the associated disk utilization figures are given in Figures <ref type="figure" target="#fig_10">15</ref> and<ref type="figure" target="#fig_13">17</ref>. Blocking again provided the highest overall throughput. For large multiprogramming levels, however, the immediate-restart strategy provided better throughput than blocking (because of its restart delay), but not enough so as to beat the highest throughput provided by the blocking algorithm. With 5 resource units, where the maximum useful disk utilizations for blocking, immediate-restart, and the optimistic algorithm were 72, 60, and 58 percent, respectively, the results followed the same trends as those of Experiment 2. Quite similar trends were obtained with 10 resource units, where the maximum useful utilizations of the disks for blocking, immediate-restart, and optimistic were 56, 45, and 47 percent, respectively. Note that in all cases, the total disk utilizations for the restart-oriented algorithms are higher than those for the blocking algorithm because of restarts; this difference is partly due to wasted resources. By wasted resources here, we mean resources used to process objects that were later undone because of restarts-these resources are wasted in the sense that they were consumed, making them unavailable for other purposes such as background tasks.</p><p>With 25 resource units, the maximum throughput obtained with the optimistic algorithm beats the maximum throughput obtained with blocking (although not by very much). The throughput results for this case are shown in Figure <ref type="figure" target="#fig_2">18</ref>, and the utilizations are given in Figure <ref type="figure" target="#fig_14">19</ref>. The total and the useful disk utilizations for the maximum throughput point for blocking were 34 and 30 percent (respectively), whereas the corresponding numbers for the optimistic algorithm were 81 and 30 percent. Thus, the optimistic algorithm has become attractive because a large amount of otherwise unused resources are available, and thus the waste of resources due to restarts does not adversely affect performance. In other words, with useful utilizations in the 30 percent range, the system begins to behave somewhat like it has infinite resources. As the number of available resources is increased still further to 50 resource units, the results become very close indeed to those of the infinite resource case; this is illustrated by the throughput and utilizations shown in Figures <ref type="figure" target="#fig_25">20</ref> and<ref type="figure" target="#fig_25">21</ref>. Here, with maximum useful utilizations down in the range of 15 to 25 percent, the shapes and relative positions of the throughput curves are very much like those of Figure <ref type="figure">5</ref> (although the actual throughput values here are still not quite as large).</p><p>Another interesting observation from these latter results is that, with blocking, resource utilization decreases as the level of multiprogramming increases and hence throughput decreases. This is a further indication that blocking may thrash due to waiting for locks before it thrashes due to the number of restarts [6, 50, 511, as we saw in the infinite resource case. On the other hand, with the optimistic algorithm, as the multiprogramming level increases, the total utilization of resources and resource waste increases, and the throughput decreases       somewhat (except with 50 resource units). Thus, this strategy eventually thrashes because of the number of restarts (i.e., because of resources). With immediaterestart, as explained earlier, a plateau is reached for throughput and resource utilization because the actual multiprogramming level is limited by the restart delay under high data contention.</p><p>As a final illustration of how the level of available resources affects the choice of a concurrency control algorithm, we plotted in Figures 22 through 24 the percent throughput improvement of the algorithms with respect to that of the blocking algorithm as a function of the resource level. The resource level axis gives the number of resource units used, which ranges from 1 to infinity (the infinite resource case). Figure <ref type="figure" target="#fig_25">22</ref> shows that, for a multiprogramming level of 50, blocking is preferable with up to almost 25 resource units; beyond this point the optimistic algorithm is preferable. For a multiprogramming level of 100, as shown in Figure <ref type="figure" target="#fig_16">23</ref>, the crossover point comes earlier because the throughput for blocking is well below its peak at this multiprogramming level. Figure <ref type="figure" target="#fig_17">24</ref> compares the maximum attainable throughput (over all multiprogramming levels) for each algorithm as a function of the resource level, in which case locking again wins out to nearly 25 resource units. (Recall that useful utilizations were down in the mid-20 percent range by the time this resource level, with 25 CPUs and 50 disks, was reached in our experiments.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Experiment 4: Interactive Workloads</head><p>In our last resource-related experiment, we modeled interactive transactions that perform a number of reads, think for some period of time, and then perform their  writes. This model of interactive transactions was motivated by a large body of form-screen applications where data is put up on the screen, the user may change some of the fields after staring at the screen awhile, and then the user types "enter," causing the updates to be performed. The intent of this experiment was to find out whether large intratransaction (internal) think times would be another way to cause a system with limited resources to behave like it has infinite resources. Since Experiment 3 showed that low utilizations can lead to behavior similar to the infinite resource case, we suspected that we might indeed see such behavior here. The interactive workload experiment was performed for internal think times of 1, 5, and 10 seconds. At the same time, the external think times were increased to 3,11, and 21 seconds, respectively, in order to maintain roughly the same ratio of idle terminals (those in an external thinking state) to active transactions. We have assumed a limited resource environment with 1 resource unit for the system in this experiment. Figure pairs <ref type="bibr" target="#b24">(25,</ref><ref type="bibr" target="#b25">26)</ref>, <ref type="bibr" target="#b26">(27,</ref><ref type="bibr" target="#b27">28)</ref>, and <ref type="bibr" target="#b28">(29,</ref><ref type="bibr" target="#b29">30)</ref> show the throughput and disk utilizations obtained for the 1, 5, and 10 second intratransaction think time experiments, respectively. On the average, a transaction requires 150 milliseconds of CPU time and 350 milliseconds of disk time, so an internal think time of 5 seconds or more is an order of magnitude larger than the time spent consuming CPU or I/O resources. Even with many transactions in the system, resource contention is significantly reduced because of such think times, and the result is that the CPU and I/O resources behave more or less like infinite resources. Consequently, for large think times, the optimistic algorithm performs better than the blocking strategy (see Figures <ref type="figure" target="#fig_25">27</ref> and<ref type="figure" target="#fig_21">29</ref>). For an internal think time of 10 seconds, the useful utilization of resources is much higher with the optimistic algorithm than the blocking strategy, and its highest throughput value is also considerably higher than that of blocking. For a 5-second internal think time, the throughput and the useful utilization with the optimistic algorithm are again better than those for blocking. For a l-second internal think time, however, blocking performs better (see Figure <ref type="figure" target="#fig_25">25</ref>). In this last case, in which the internal think time for transactions is closer to their processing time requirements, the resource utilizations are such that resources wasted because of restarts make the optimistic algorithm the loser.</p><p>The highest throughput obtained with the optimistic algorithm was consistently better than that for immediate-restart, although for higher levels of multiprogramming the throughput obtained with immediate-restart was better than the throughput obtained with the optimistic algorithm due to the mpl-limiting effect of immediate-restart's restart delay. As noted before, this high multiprogramming level difference could be reversed by adding a restart delay to the optimistic algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Resource-Related Conclusions</head><p>Reflecting on the results of the experiments reported in this section, several conclusions are clear. First, a blocking algorithm like dynamic two-phase locking is a better choice than a restart-oriented concurrency control algorithm like the immediate-restart or optimistic algorithms for systems with medium to high l FL Agrawal et al.     levels of resource utilization.</p><p>On the other hand, if utilizations are sufficiently low, a restart-oriented algorithm becomes a better choice. Such low resource utilizations arose in our experiments with large numbers of resource units and in our interactive workload experiments with large intratransaction think times. The optimistic algorithm provided the best performance in these cases. Second, the past performance studies discussed in Section 1 were not really contradictory after all: they simply obtained different results because of very different resource modeling assumptions. We obtained results similar to each of the various studies [l, 2, 6, 12, 15, 20, 50, 511 by varying the level of resources that we employed in our database model. Clearly, then, a physically justifiable resource model is a critical component for a reasonable concurrency control performance model. Third, our results indicate that it is important to control the multiprogramming level in a database system for concurrency control reasons. We observed thrashing behavior for locking in the infinite resource case, as did [6, 20, 50, and 511, but in addition we observed that a significant thrashing effect occurs for both locking and optimistic concurrency control under higher levels of resource contention.</p><p>(A similar thrashing effect would also have occurred for the immediate-restart algorithm under higher resource contention levels were it not for the mpl-limiting effects of its adaptive restart delay.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">TRANSACTION BEHAVIOR ASSUMPTIONS</head><p>This section describes experiments that were performed to investigate the performance implications of two modeling assumptions related to transaction behavior. In particular, we examined the impact of alternative assumptions about how restarts are modeled (real versus fake restarts) and how write locks are acquired (with or without upgrades from read locks). Based on the results of the previous section, we performed these experiments under just two resource settings: infinite resources and one resource unit. These two settings are sufficient to demonstrate the important effects of the alternative assumptions, since the results under other settings can be predicted from these two. Except where explicitly noted, the simulation parameters used in this section are the same as those given in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experiment 6: Modeling Restarts</head><p>In this experiment we investigated the impact of transaction-restart modeling on performance. Up to this point, restarts have been modeled by "reincarnating" transactions with their previous read and write sets and then placing them at the end of the ready queue, as described in Section 3. An alternative assumption that has been used for modeling convenience in a number of studies is the fak restart assumption, in which a restarted transaction is assumed to be replaced by a new transaction that is independent of the restarted one. In order to model this assumption, we had the simulator reinitialize the read and write sets for restarted transactions in this experiment. The throughput results for the infinite resource case are shown in Figure <ref type="figure" target="#fig_23">31</ref>, and Figure <ref type="figure" target="#fig_24">32</ref> shows the associated conflict ratios. Solid lines show the new results obtained using the fake restart assumption, and the dotted lines show the results obtained previously under the real restart model. For the conflict ratio curves, hollow points show restart ratios and  solid points show blocking ratios. Figures <ref type="figure" target="#fig_6">33</ref> and<ref type="figure" target="#fig_28">34</ref> show the throughput and conflict ratio results for the limited resource (1 resource unit) case.</p><p>In comparing the fake and real restart results for the infinite resource case in Figure <ref type="figure" target="#fig_23">31</ref>, several things are clear. The fake restart assumption produces significantly higher throughputs for the immediate-restart and optimistic algorithms. The throughput results for blocking are also higher than under the real restart assumption, but the difference is quite a bit smaller in the case of the blocking algorithm. The restart-oriented algorithms are more sensitive to the fake-restart assumption because they restart transactions much more often. Figure <ref type="figure" target="#fig_24">32</ref> shows how the conflict ratios changed in this experiment, helping to account for the throughput results in more detail. The restart ratios are lower for each of the algorithms under the fake-restart assumption, as is the blocking algorithm's blocking ratio. For each algorithm, if three or more transactions wish to concurrently update an item, repeated conflicts can occur. For blocking, the three transactions will all block and then deadlock when upgrading read locks to write locks, causing two to be restarted, and these two will again block and possibly deadlock. For optimistic, one of the three will commit, which causes the other two to detect readset/writeset intersections and restart, after which one of the remaining two transactions will again restart when the other one commits. A similar problem will occur for immediate-restart, as the three transactions will collide when upgrading their read locks to write locks-only the last of the three will be able to proceed, with the other two being restarted. Fake restarts eliminate this problem, since a restarted transaction comes back as an entirely new transaction. Note that the immediate-restart algorithm has the smallest reduction in its restart ratio. This is because it has a restart delay that helps to alleviate such problems even with real restarts.</p><p>Figure <ref type="figure" target="#fig_6">33</ref> shows that, for the limited resource case, the fake-restart assumption again leads to higher throughput predictions for all three concurrency control algorithms. This is due to the reduced restart ratios for all three algorithms (see Figure <ref type="figure" target="#fig_28">34</ref>). Fewer restarts lead to better throughput with limited resources, as more resources are available for doing useful (as opposed to wasted) work. For the two restart-oriented algorithms, the difference between fake and real restart performance is fairly constant over most of the range of multiprogramming levels. For blocking, however, fake restarts lead to only a slight increase in throughput at the lower multiprogramming levels. This is expected since its restart ratio is small in this region. As higher multiprogramming levels cause the restart ratio to increase, the difference between fake and real restart performance becomes large. Thus, the results produced under the fake-restart assumption in the limited resource case are biased in favor of the restart-oriented algorithms for low multiprogramming levels. At higher multiprogramming levels, all of the algorithms benefit almost equally from the fake restart assumption (with a slight bias in favor of blocking at the highest multiprogramming level). In this experiment we investigated the impact of write-lock acquisition modeling on performance. Up to now we have assumed that write locks are obtained by upgrading read locks to write locks, as is the case in many real database systems.   In this section we make an alternative assumption, the no lock upgrades assumption, in which a write lock is obtained instead of a read lock on each item that is to eventually be updated the first time the item is read. Figures <ref type="figure" target="#fig_29">35</ref> and<ref type="figure" target="#fig_6">36</ref> show the throughputs and conflict ratios obtained under this new assumption for the infinite resource case, and Figures <ref type="figure" target="#fig_6">37</ref> and<ref type="figure" target="#fig_6">38</ref> show the results for the limited resource case. The line and point-style conventions are the same as those in the previous experiment. Since the optimistic algorithm is (obviously) unaffected by the lock upgrade model, results are only given for the blocking and immediaterestart algorithms.</p><p>The results obtained in this experiment are quite easily explained. The upgrade assumption has little effect at the lowest multiprogramming levels, as conflicts are rare there anyway. At higher multiprogramming levels, however, the upgrade assumption does make a difference. The reasons can be understood by considering what happens when two transactions attempt to read and then write the same data item. We consider the blocking algorithm first. With lock upgrades, each transaction will first set a read lock on the item. Later, when one of the transactions is ready to write the item, it will block when it attempts to upgrade its read lock to a write lock; the other transaction will block as well when it requests its lock upgrade. This causes a deadlock, and the younger of the two transactions will be restarted. Without lock upgrades, the first transaction to lock the item will do so using a write lock, and then the other transaction will simply block without causing a deadlock when it makes its lock request. As indicated in Figures <ref type="figure" target="#fig_6">36</ref> and<ref type="figure" target="#fig_6">38</ref>, this leads to lower blocking and restart ratios for the blocking algorithm under the no-lock upgrades assumption. For the immediate-restart algorithm, no restart will be eliminated in such a case, since one of the two conflicting transactions must be still restarted. The restart will occur much sooner under the no-lock upgrades assumption, however.</p><p>For the infinite resource case (Figures <ref type="figure" target="#fig_29">35</ref> and<ref type="figure" target="#fig_6">36</ref>), the throughput predictions are significantly lower for blocking under the no-lock upgrades assumption. This is because write locks are obtained earlier and held significantly longer under this assumption, which leads to longer blocking times and therefore to lower throughput. The elimination of deadlock-induced restarts as described above does not help in this case, since wasted resources are not really an issue with infinite resources. For the immediate-restart algorithm, the no-lock upgrades assumption leads to only a slight throughput increase-although restarts occur earlier, as described above, again this makes little difference with infinite resources.</p><p>For the limited resource case (Figures <ref type="figure" target="#fig_6">37</ref> and<ref type="figure" target="#fig_6">38</ref>), the throughput predictions for both algorithms are significantly higher under the no-lock upgrades assumption. This is easily explained as well. For blocking, eliminating lock upgrades eliminates upgrade-induced deadlocks, which leads to fewer transactions being restarted. For the immediate-restart algorithm, although no restarts are eliminated, they do occur much sooner in the lives of the restarted transactions under the no-lock upgrades assumption. The resource waste avoided by having fewer restarts with the blocking algorithm or by restarting transactions earlier with the immediate-restart algorithm leads to considerable performance increases for both algorithms when resources are limited.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Transaction Behavior Conclusions</head><p>Reviewing the results of Experiments 6 and 7, several conclusions can be drawn. First, it is clear from Experiment 6 that the fake-restart assumption does have a significant effect on predicted throughput, particularly for high multiprogramming levels (i.e., when conflicts are frequent). In the infinite resource case, the fake-restart assumption raises the throughput of the restart-oriented algorithms more than it does for blocking, so fake restarts bias the results against blocking somewhat in this case. In the limited resource case, the results produced under the fake-restart assumption are biased in favor of the restart-oriented algorithms at low multiprogramming levels, and all algorithms benefit about equally from the assumption at higher levels of multiprogramming.</p><p>In both cases, however, the relative performance results are not all that different with and without fake restarts, at least in the sense that assuming fake restarts does not change which algorithm performs the best of the three. Second, it is clear from Experiment 7 that the no-lock upgrades assumption biases the results in favor of the immediaterestart algorithm, particularly in the infinite resource case. That is, the performance of blocking is significantly underestimated using this assumption in the case of infinite resources, and the throughput of the immediate-restart algorithm benefits slightly more from this assumption than blocking does in the limited resource case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS AND IMPLICATIONS</head><p>In this paper, we argued that a physically justifiable database system model is a requirement for concurrency control performance studies. We described what we feel are the key components of a reasonable model, including a model of the database system and its resources, a model of the user population, and a model of transaction behavior. We then presented our simulation model, which includes all of these components, and we used it to study alternative assumptions about database system resources and transaction behavior.</p><p>One specific conclusion of this study is that a concurrency control algorithm that tends to conserve physical resources by blocking transactions that might otherwise have to be restarted is a better choice than a restart-oriented algorithm in an environment where physical resources are limited. Dynamic two-phase locking was found to outperform the immediate-restart and optimistic algorithms for medium to high levels of resource utilization. However, if resource utilizations are low enough so that a large amount of wasted resources can be tolerated, and in addition there are a large number of transactions available to execute, then a restart-oriented algorithm that allows a higher degree of concurrent execution is a better choice. We found the optimistic algorithm to perform the best of the three algorithms tested under these conditions. Low resource utilizations such as these could arise in a database machine with a large number of CPUs and disks and with a number of users similar to those of today's medium to large timesharing systems. They could also arise in primarily interactive applications in which large think times are common and in which the number of users is such that the utilization of the system is low as a result. It is an open question whether or not such low utilizations will ever actually occur in real systems (i.e., whether or not such operating regions are sufficiently cost-effective). If not, blocking algorithms will remain the preferred method for database concurrency control.</p><p>A more general result of this study is that we have reconfirmed results from a number of other studies, including studies reported in [l, 2, 6, 12, 15, 20, 50, and 511. We have shown that seemingly contradictory performance results, some of which favored blocking algorithms and others of which favored restarts, are not contradictory at all. The studies are all correct within the limits of their assumptions, particularly their assumptions about system resources. Thus, although it is possible to study the effects of data contention and resource contention separately in some models <ref type="bibr" target="#b51">[50,</ref><ref type="bibr" target="#b52">51]</ref>, and although such a separation may be useful in iterative approximation methods for solving concurrency control performance models [M. Vernon, personal communication, 19851, it is clear that one cannot select a concurrency control algorithm for a real system on the basis of such a separation-the proper algorithm choice is strongly resource dependent. A reasonable model of database system resources is a crucial ingredient for studies in which algorithm selection is the goal.</p><p>Another interesting result of this study is that the level of multiprogramming in database systems should be carefully controlled. We refer here to the multiprogramming level internal to the database system, which controls the number of transactions that may concurrently compete for data, CPU, and I/O services (as opposed to the number of users that may be attached to the system). As in the case of paging operating systems, if the multiprogramming level is increased beyond a certain level, the blocking and optimistic concurrency control strategies start thrashing. We have confirmed the results of <ref type="bibr">[6, 20, 50, and 511</ref> for locking in the low resource contention case, but more important we have also seen that the effect can be significant for both locking and optimistic concurrency control under higher levels of resource contention. We found that when we delayed restarted transactions by an amount equal to the running average response time, it had the beneficial side effect of limiting the actual multiprogramming level, and the degradation in throughput was arrested (albeit a little bit late). Since the use of a restart delay to limit the multiprogramming level is at best a crude strategy, an adaptive algorithm that dynamically adjusts the multiprogramming level in order to maximize system throughput needs to be designed. Some performance indicators that might be used in the design of such an algorithm are useful resource utilization or running averages of throughput, response time, or conflict ratios. The design of such an adaptive load control algorithm is an open problem.</p><p>In addition to our conclusions about the impact of resources in determining concurrency control algorithm performance, we also investigated the effects of two transaction behavior modeling assumptions. With respect to fake versus real restarts, we found that concurrency control algorithms differ somewhat in their sensitivity to this modeling assumption; the results with fake restarts tended to be somewhat biased in favor of the restart-oriented algorithms. However, the overall conclusions about which algorithm performed the best relative to the other algorithms were not altered significantly by this assumption. With respect to the issue of how write-lock acquisition is modeled, we found relative algorithm performance to be more sensitive to this assumption than to the fake-restarts</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Conflict ratios (m resources).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Response time (00 resources).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FtFig. 8 .</head><label>8</label><figDesc>Fig. 8. Throughput (1 resource unit).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 9 .FLFig. 10 .</head><label>910</label><figDesc>Fig. 9. Disk utilization (1 resource unit).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Throughput (adaptive restart delays).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>5. 3 A</head><label>3</label><figDesc>Brief AsideBefore discussing the remainder of the experiments, a brief aside is in order. Our concurrency control performance model includes a time delay, ext-think-time, between the completion of one transaction and the initiation of the next transaction from a terminal. Although we feel that such a time delay is necessary in a l R. Agrawal et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>ConcurrencyFig. 12 .</head><label>12</label><figDesc>Fig. 12. Throughput (m resources, no external think time).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Throughput (1 resource unit, no external think time).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>ACMFig. 14 .</head><label>14</label><figDesc>Fig. 14. Throughput (5 resource units).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Disk utilization (5 resource units).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Throughput (10 resource units).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Disk utilization (10 resource units). ACM Transactions on Database Systems. Vol. 12, No. 4, December 1987.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 19 .</head><label>19</label><figDesc>Fig. 18. Throughput (25 resource units).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 21 .Fig. 22 .</head><label>2122</label><figDesc>Fig. 20. Throughput (50 resource units).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 23 .</head><label>23</label><figDesc>Fig. 23. Improvement over blocking (MPL = 100).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 24 .</head><label>24</label><figDesc>Fig. 24. Improvement over blocking (maximum).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 26 .</head><label>26</label><figDesc>Fig. 25. Throughput (1 second thinking).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 27 .</head><label>27</label><figDesc>Fig. 27. Throughput (5 seconds thinking).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 28 .</head><label>28</label><figDesc>Fig. 28. Disk utilization (5 seconds thinking).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig. 29 .</head><label>29</label><figDesc>Fig. 29. Throughput (10 seconds thinking).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig. 30 .</head><label>30</label><figDesc>Fig. 30. Disk utilization (10 seconds thinking).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Fig. 31 .</head><label>31</label><figDesc>Fig. 31. Throughput (fake restarts, m resources).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Fig. 32 .</head><label>32</label><figDesc>Fig. 32. Conflict ratios (fake restarts, m resources).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>6. 2</head><label>2</label><figDesc>Experiment 7: Write-Lock Acquisition</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head></head><label></label><figDesc>Fig. 33.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head></head><label></label><figDesc>Fig. 33.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Fig. 34 .</head><label>34</label><figDesc>Fig. 34. Conflict ratios (fake restarts, 1 resource unit).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>Fig. 35 .</head><label>35</label><figDesc>Fig. 35. Throughput (no lock upgrades, m resources).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Fig. 36 .Fig. 37 .Fig. 38 .</head><label>363738</label><figDesc>Fig. 36. Conflict ratios (no lock upgrades, m resources). ACM Transactions on Database Systems, Vol. 12, No. 4, December 1987.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>ACM Transactionson Database Systems, Vol. 12, No. 4, December 1987.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>ACM Transactions on Database Systems, Vol. 12, No. 4, December 1987.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>' Blocking's performance results would change very little if periodic deadlock detection were assumed instead<ref type="bibr" target="#b3">[4]</ref>.ACM Transactions on Database Systems, Vol. 12, No. 4, December 1987.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>ACM Transactions on Database Systems, Vol. 12, No. 4, December 198'7.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>'The actual throughput peak may of course be somewhere to the left or right of 25, in the 10-50 range, but that cannot be determined from our data. ACM Transactions on Database Systems, Vol. 12, No. 4, December 1987.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors wish to acknowledge the anonymous referees for their many insightful comments. We also wish to acknowledge helpful discussions that one or more of us have had with Mary Vernon, Nat Goodman, and (especially) Y. C. Tay. Comments from Rudd Canaday on an earlier version of this paper helped us to improve the presentation. The NSF-sponsored Crystal multicomputer project at the University of Wisconsin provided the many VAX 111750 CPU-hours that were required for this study.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Models for Studying Concurrency Control Performance: Alternatives and Implications, " in Proceedings of the International Conference on Management of Data (Austin, TX., May 28-30, 1985). M. J. Carey and M. Livny were partially supported by the Wisconsin Alumni Research Foundation under National Science Foundation grant DCR-8402818 and an IBM Faculty Development Award.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>assumption. The performance of the blocking algorithm was particularly sensitive to the no-lock upgrades assumption in the infinite resource case, with its throughput being underestimated by as much as a factor of two at the higher multiprogramming levels.</p><p>In closing, we wish to leave the reader with the following thoughts about computer system resources and the future, due to Bill Wulf:</p><p>Although the hardware costs will continue to fall dramatically and machine speeds will increase equally dramatically, we must assume that our aspirations will rise even more. Because of this, we are not about to face either a cycle or memory surplus. For the nearterm future, the dominant effect will not be machine cost or speed alone, but rather a continuing attempt to increase the return from a finite resource-that is, a particular computer at our disposal. <ref type="bibr">[54, p. 411</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Concurrency control and recovery in multiprocessor database machines: Design and performance evaluation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<pubPlace>Madison, Wise</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Sciences Department, University of Wisconsin-Madison</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Integrated concurrency control and recovery mechanisms: Design and performance evaluation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dewitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="529" to="564" />
			<date type="published" when="1985-12">Dec. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deadlock detection is cheap</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dewitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM-SZGMOD Record</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<date type="published" when="1983-01">Jan. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The performance of alternative strategies for dealing with deadlocks in database management systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mcvoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Softw. Eng</title>
		<imprint/>
	</monogr>
	<note>To be published</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Correctness of concurrency control and implications in distributed databases</title>
		<author>
			<persName><forename type="first">D</forename><surname>Badal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the COMPSAC &apos;79 Conference</title>
		<meeting>the COMPSAC &apos;79 Conference<address><addrLine>Chicago, Nov; New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1979">1979. 1979</date>
			<biblScope unit="page" from="588" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Why control of the concurrency level in distributed systems is more fundamental than deadlock management</title>
		<author>
			<persName><forename type="first">R</forename><surname>Balter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Berard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Decitre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st ACM SZGACT SZGOPS Symposium on Principles of Distributed Computing</title>
		<meeting>the 1st ACM SZGACT SZGOPS Symposium on Principles of Distributed Computing<address><addrLine>Ottawa, Ontario; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1982">Aug. 18-20,1982. 1982</date>
			<biblScope unit="page" from="183" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Fundamental algorithms for concurrency control in distributed database systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<pubPlace>Cambridge, Mass</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Corporation of America</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Timestamp-based algorithms for concurrency control in distributed database systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Very Large Data Bases</title>
		<meeting>the 6th International Conference on Very Large Data Bases</meeting>
		<imprint>
			<publisher>Montreal</publisher>
			<date type="published" when="1980-10">Oct. 1980</date>
			<biblScope unit="page" from="285" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Concurrency control in distributed database systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Suru</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="185" to="222" />
			<date type="published" when="1981-06">June 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A sophisticate&apos;s introduction to distributed database concurrency control</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Very Large Data Bases</title>
		<meeting>the 8th International Conference on Very Large Data Bases<address><addrLine>Mexico City, Sept</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1982">1982</date>
			<biblScope unit="page" from="62" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Formal aspects in serializability of database concurrency control</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shipman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Softw. Eng. SE</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1979-05">May 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Modeling and evaluation of database concurrency control algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Carey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983-09">Sept. 1983</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science Division (EECS ; U niversity of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An abstract model of database concurrency control algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Carey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SZGMOD International Conference on Manugement of Data</title>
		<meeting>the ACM SZGMOD International Conference on Manugement of Data<address><addrLine>San Jose, Calif; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1983">May 23-26, 1983. 1983</date>
			<biblScope unit="page" from="97" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The performance of multiversion concurrency control algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Muhanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="338" to="378" />
			<date type="published" when="1986-11">Nov. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The performance of concurrency control algorithms for database management systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Very Large Data Eases</title>
		<meeting>the 10th International Conference on Very Large Data Eases<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1984-08">Aug. 1984</date>
			<biblScope unit="page" from="107" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">The concurrency control problem for database systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Casanova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<pubPlace>Cambridge, Mass</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, Harvard University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the use of optimistic methods for concurrency control in distributed databases</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ceri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Owicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Berkeley Workshop on Distributed Data Management and Computer Networks</title>
		<meeting>the 6th Berkeley Workshop on Distributed Data Management and Computer Networks<address><addrLine>Berkeley, Calif; New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1982-02">Feb. 1982. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A database cache for high performance and fast restart in database systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Elhard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="503" to="525" />
			<date type="published" when="1984-12">Dec. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The notions of consistency and predicate locks in a database system</title>
		<author>
			<persName><forename type="first">K</forename><surname>Eswaren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lorie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Traiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="624" to="633" />
			<date type="published" when="1976-11">Nov. 1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Limitations of concurrency in transaction processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Franaszek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="1985-03">Mar. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Concurrency control performance issues</title>
		<author>
			<persName><forename type="first">B</forename><surname>Galler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982-09">Sept. 1982</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, University of Toronto, Ontario</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A simple analytic model for performance of exclusive locking in database systems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Suri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd ACM SZGACT-SZGMOD Symposium on Principles of Database Systems</title>
		<meeting>the 2nd ACM SZGACT-SZGMOD Symposium on Principles of Database Systems<address><addrLine>Atlanta, Ga; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1983">Mar. 21-23,1983. 1983</date>
			<biblScope unit="page" from="203" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Notes on database operating systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Operating Systems: An Advanced Course</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Bayer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Graham</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Seegmuller</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A straw man analysis of the probability of waiting and deadlock in a database system</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Homan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Korth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Obermarck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RJ</title>
		<imprint>
			<biblScope unit="volume">3066</biblScope>
			<date type="published" when="1981-02">Feb. 1981</date>
			<pubPlace>San Jose, Calif</pubPlace>
		</imprint>
		<respStmt>
			<orgName>IBM San Jose Research Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evaluating multiple server DBMS in general purpose operating system environments</title>
		<author>
			<persName><forename type="first">T</forename><surname>Haerder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Peinl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Very Large Data Bases</title>
		<meeting>the 10th International Conference on Very Large Data Bases<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1984-08">Aug. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Queuing network models for concurrent transaction processing in a database system</title>
		<author>
			<persName><forename type="first">K</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SZGMOD International Conference on Management of Data</title>
		<meeting>the ACM SZGMOD International Conference on Management of Data<address><addrLine>Boston; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1979-06-01">May 30-June 1,1979. 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On optimistic methods for concurrency control</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="226" />
			<date type="published" when="1981-06">June 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Distributed database control and allocation: Semi-annual report</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nolte</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982-01">Jan. 1982</date>
			<pubPlace>Cambridge, Mass</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Corporation of America</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Performance of two phase locking</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nolte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Berkeley Workshop on Distributed Data Management and Computer Networks</title>
		<meeting>the 6th Berkeley Workshop on Distributed Data Management and Computer Networks<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1982-02">Berkeley, Feb. 1982. 1982</date>
			<biblScope unit="page" from="131" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Basic timestamp, multiple version timestamp, and two-phase locking</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nolte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Znternational Conference on Very Large Data Bases</title>
		<meeting>the 9th Znternational Conference on Very Large Data Bases<address><addrLine>Florence</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1983-10">Oct. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Notes on distributed databases</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><surname>Et Al</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RJ</title>
		<imprint>
			<biblScope unit="volume">2571</biblScope>
			<date type="published" when="1979">1979</date>
			<pubPlace>San Jose, Calif</pubPlace>
		</imprint>
		<respStmt>
			<orgName>IBM San Jose Research Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Locking and deadlock detection in distributed databases</title>
		<author>
			<persName><forename type="first">D</forename><surname>Menasce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Muntz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Berkeley Workshop on Distributed Data Management and Computer Networks</title>
		<meeting>the 3rd Berkeley Workshop on Distributed Data Management and Computer Networks<address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1978-08">Aug. 1978. 1978</date>
			<biblScope unit="page" from="215" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The serializability of concurrent database updates</title>
		<author>
			<persName><forename type="first">C</forename><surname>Papadimitriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="631" to="653" />
			<date type="published" when="1979-10">Oct. 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Empirical comparison of database concurrency control schemes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Peinl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Reuter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Znternutionul Conference on Very Large Data Bases</title>
		<meeting>the 9th Znternutionul Conference on Very Large Data Bases</meeting>
		<imprint>
			<date type="published" when="1983-10">Florence, Oct. 1983</date>
			<biblScope unit="page" from="97" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName><surname>Ft</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Analysis of locking policies in database management systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Potier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Leblanc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="584" to="593" />
			<date type="published" when="1980-10">Oct. 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Naming and synchronization in a decentralized computer system</title>
		<author>
			<persName><forename type="first">D</forename><surname>Reed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978">1978</date>
			<pubPlace>Cambridge, Mass</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">An analytic model of transaction interference in database systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Reuter</surname></persName>
		</author>
		<idno>IB 68/83</idno>
		<imprint>
			<date type="published" when="1983">1983</date>
			<pubPlace>West Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Kaiserslautern</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Performance analysis of recovery techniques</title>
		<author>
			<persName><forename type="first">A</forename><surname>Reuter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="526" to="559" />
			<date type="published" when="1984-12">Dec. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">The effects of concurrency control on database management system performance</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ries</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<pubPlace>Berkeley, Calif</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Electrical Engineering and Computer Science, University of California at Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Effects of locking granularity on database management system performance</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="233" to="246" />
			<date type="published" when="1977-09">Sept. 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Locking granularity revisited</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="1979-06">June 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Design of concurrency controls for transaction processing systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Robinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<pubPlace>Pittsburgh, Pa</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, Carnegie-Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Experiments with transaction processing on a multi-microprocessor</title>
		<author>
			<persName><forename type="first">J</forename><surname>Robinson</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Ibm</forename><surname>Rc9725</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><surname>Watson Research</surname></persName>
		</author>
		<author>
			<persName><surname>Center</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982-12">Dec. 1982</date>
			<pubPlace>Yorktown Heights, N.Y.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">II. System level concurrency control for distributed database systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rosenkrantz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stearns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="178" to="198" />
			<date type="published" when="1978-06">June 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The commercial INGRES epilogue</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The ZNGRES Papers: Anatomy of a Relational Database System</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</editor>
		<meeting><address><addrLine>Reading, Mass</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Statistical analysis of simulation output data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sargent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Annual Symposium on the Simulation of Computer Systems</title>
		<meeting>the 4th Annual Symposium on the Simulation of Computer Systems</meeting>
		<imprint>
			<date type="published" when="1976-08">Aug. 1976</date>
			<biblScope unit="page" from="39" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Performance prototyping of data management applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Spitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM &apos;76 Annual Conference</title>
		<meeting>the ACM &apos;76 Annual Conference<address><addrLine>Houston, TX.; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1976">Oct. 20-22, 1976. 1976</date>
			<biblScope unit="page" from="287" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Concurrency control and consistency of multiple copies of data in distributed INGRES</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Softcu. Eng</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1979-05">May 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The Design of POSTGRES</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SZGMOD International Conference on Management of Data</title>
		<meeting>the ACM SZGMOD International Conference on Management of Data<address><addrLine>Washington, D.C.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">May 28-30,1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">A mean value performance model for locking in databases</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984-02">Feb. 1984</date>
			<pubPlace>Cambridge, Mass</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, Harvard University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Locking performance in centralized databases</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Suri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="415" to="462" />
			<date type="published" when="1985-12">Dec. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A majority consensus approach to concurrency control for multiple copy databases</title>
		<author>
			<persName><forename type="first">R</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="180" to="209" />
			<date type="published" when="1979-06">June 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A decomposition solution to the queuing network model of the centralized DBMS with static locking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Thomasian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ryu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM-SZGMETRZCS Conference on Measurement and Modeling of Computer Systems</title>
		<meeting>the ACM-SZGMETRZCS Conference on Measurement and Modeling of Computer Systems<address><addrLine>Minneapolis, Minn; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1983">Aug. 29-31,1983. 1983</date>
			<biblScope unit="page" from="82" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Compilers and computer architecture</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wulf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<date type="published" when="1981-07">July 1981. 1985. 1986. 1987</date>
		</imprint>
	</monogr>
	<note>Received August. revised August. accepted May</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
