<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards scalable and data efficient learning of Markov boundaries</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2006-08-11">11 August 2006</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jose</forename><forename type="middle">M</forename><surname>Pen ˜a</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">IFM</orgName>
								<orgName type="institution">Linko ¨ping University</orgName>
								<address>
									<postCode>SE-58183</postCode>
									<settlement>Linko ¨ping</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roland</forename><surname>Nilsson</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">IFM</orgName>
								<orgName type="institution">Linko ¨ping University</orgName>
								<address>
									<postCode>SE-58183</postCode>
									<settlement>Linko ¨ping</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Johan</forename><surname>Bjo ¨rkegren</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">IFM</orgName>
								<orgName type="institution">Linko ¨ping University</orgName>
								<address>
									<postCode>SE-58183</postCode>
									<settlement>Linko ¨ping</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">CGB</orgName>
								<address>
									<addrLine>Karolinska Institutet</addrLine>
									<postCode>SE-17177</postCode>
									<settlement>Stockholm</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jesper</forename><surname>Tegne ´r</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">IFM</orgName>
								<orgName type="institution">Linko ¨ping University</orgName>
								<address>
									<postCode>SE-58183</postCode>
									<settlement>Linko ¨ping</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">CGB</orgName>
								<address>
									<addrLine>Karolinska Institutet</addrLine>
									<postCode>SE-17177</postCode>
									<settlement>Stockholm</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Towards scalable and data efficient learning of Markov boundaries</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2006-08-11">11 August 2006</date>
						</imprint>
					</monogr>
					<idno type="MD5">255AEEDFB1BC2A9D5372905E2F8655A7</idno>
					<idno type="DOI">10.1016/j.ijar.2006.06.008</idno>
					<note type="submission">Received 30 December 2005; received in revised form 28 June 2006; accepted 30 June 2006</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bayesian networks</term>
					<term>Feature subset selection</term>
					<term>Classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose algorithms for learning Markov boundaries from data without having to learn a Bayesian network first. We study their correctness, scalability and data efficiency. The last two properties are important because we aim to apply the algorithms to identify the minimal set of features that is needed for probabilistic classification in databases with thousands of features but few instances, e.g. gene expression databases. We evaluate the algorithms on synthetic and real databases, including one with 139,351 features.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Probabilistic classification is the process of mapping an assignment of values to some random variables F, the features, into a probability distribution for a distinguished random variable C, the class. Feature subset selection (FSS) aims to identify the minimal subset of F that is needed for probabilistic classification. Solving the FSS problem is important for two main reasons. First, it provides insight into the domain at hand and, 0888-613X/$ -see front matter Ó 2006 Elsevier Inc. All rights reserved. doi:10.1016/j.ijar.2006.06.008 second, it reduces the search space if the probabilistic classifier is to be learnt from data.</p><p>In this paper, we are interested in solving the FSS problem as follows. Since a Markov boundary (MB) of C is defined as any minimal subset of F that renders the rest of F independent of C, then a MB of C is a solution to the FSS problem. If the probability distribution of {F, C} can be faithfully represented by a Bayesian network (BN) for {F, C}, then the MB of C is unique and can easily be obtained because it consists of the union of the parents and children of C and the parents of the children of C <ref type="bibr" target="#b11">[12]</ref>. In this paper, we are interested in solving the FSS problem for databases with thousands of features but few instances. Such databases are common in domains like bioinformatics and medicine, e.g. gene expression databases <ref type="bibr" target="#b15">[16]</ref>. Unfortunately, having to learn a BN for {F, C} in order to learn a MB of C can be painfully time consuming for such high-dimensional databases <ref type="bibr" target="#b21">[22]</ref>. This is particularly true for those algorithms for learning BNs from data that are (asymptotically) correct under the faithfulness assumption <ref type="bibr" target="#b21">[22]</ref>, which are the ones we are interested in. Fortunately, there exists an algorithm for learning a MB of C from data that scales to high-dimensional databases and that is correct under the faithfulness assumption, the incremental association Markov boundary algorithm (IAMB) <ref type="bibr" target="#b18">[19]</ref>. IAMB is scalable because it does not learn a BN for {F, C}. However, IAMB is data inefficient because it may require an unnecessarily large amount of learning data to identify a MB of C. This raises the first question addressed in this paper: Can we develop an algorithm for learning MBs from data that is scalable, data efficient, and correct under the faithfulness assumption ? The answer is yes. In Section 4, we present such an algorithm, the parents and children based Markov boundary algorithm (PCMB). This leads us to the second question addressed in this paper: Can we relax the faithfulness assumption and develop an algorithm that is correct, scalable and data efficient ? We prove that IAMB is still correct under the composition property assumption, which is weaker than the faithfulness assumption. The proof also applies to a stochastic variant of IAMB that we propose in order to overcome the data inefficiency of IAMB. We call it KIAMB. This algorithm has the following additional advantage over IAMB. If C has several MBs (something impossible under the faithfulness assumption but possible under the composition property assumption), then KIAMB does not only return a MB of C but any MB of C with non-zero probability. Therefore, KIAMB can discover different MBs of C when run repeatedly while IAMB cannot because it is deterministic. We report experiments showing that PCMB outperforms IAMB and that KIAMB outperforms both IAMB and PCMB considerably often. To show that these algorithms are scalable, part of the experiments are run on the Thrombin database which contains 139,351 features <ref type="bibr" target="#b1">[2]</ref>. Before going into the details of our contribution, we review some key concepts in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head><p>The following definitions can be found in most books on Bayesian networks, e.g. <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref>. Let U denote a set of discrete random variables. A Bayesian network (BN) for U is a pair (G, h), where G is an acyclic directed graph (DAG) whose nodes correspond to the random variables in U, and h are parameters specifying a probability distribution for each node X given its parents in G, p(XjPa(X)). A BN (G, h) represents a probability distribution for U, p(U), through the factorization pðUÞ ¼ Q X 2U pðX jPaðX ÞÞ. In addition to Pa(X), two other abbreviations that we use are PC(X) for the parents and children of X in G, and ND(X) for the non-descendants of X in G. Hereinafter, all the probability distributions and DAGs are defined over U, unless otherwise stated. We call the members of U interchangeably random variables and nodes.</p><p>Let X YjZ denote that X is independent of Y given Z in a probability distribution p. Any probability distribution p that can be represented by a BN with DAG G satisfies certain independencies between the random variables in U that can be read from G via the d-separation criterion, i.e. if d-sep(X,YjZ) then X YjZ with X, Y and Z three mutually disjoint subsets of U. The statement d-sep(X,YjZ) is true when for every undirected path in G between a node in X and a node in Y there exists a node Z in the path such that either (i) Z does not have two parents in the path and Z 2 Z, or (ii) Z has two parents in the path and neither Z nor any of its descendants in G is in Z. A probability distribution p is said to be faithful to a DAG G when X YjZ iff d-sep(X,YjZ). Let p denote a probability distribution and X 2 U, any Y (Un{X}) such that X (UnYn{X})jY is called a Markov blanket of X. Any minimal Markov blanket of X is called a Markov boundary (MB) of X, i.e. no proper subset of a MB of X is a Markov blanket of X. The following three theorems are proven in <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b11">12]</ref>, respectively. Theorem 1. Let X, Y, Z and W denote four mutually disjoint subsets of U. Any probability distribution p satisfies the following four properties:</p><formula xml:id="formula_0">Symmetry X YjZ ) Y XjZ, decomposition X (Y [ W)jZ ) X YjZ, weak union X (Y [ W)j Z ) X Yj(Z [ W), and contraction X Yj(Z [ W) ^X WjZ ) X (Y [ W)jZ.</formula><p>If p is strictly positive, then p satisfies the previous four properties plus the intersection property X</p><formula xml:id="formula_1">Yj(Z [ W) ^X Wj (Z [ Y) ) X (Y [ W)jZ.</formula><p>If p is faithful to a DAG G, then p satisfies the previous five properties plus the composition property X YjZ ^X WjZ ) X (Y [ W)jZ and the local Markov property X (ND(X)nPa(X))jPa(X) for each X 2 U.</p><p>Theorem 2. If a probability distribution p is faithful to a DAG G, then (i) for each pair of nodes X and Y in G, X and Y are adjacent in G iff X YjZ for all Z such that X, Y 6 2 Z, and (ii) for each triplet of nodes X, Y and Z in G such that X and Y are adjacent to Z but X and Y are non-adjacent, X ! Z Y is a subgraph of G iff X YjZ for all Z such that X, Y 6 2 Z and Z 2 Z. Theorem 3. If a probability distribution p satisfies the intersection property, then each X 2 U has a unique MB, MB(X). If p is faithful to a DAG G, then MB(X) is the union of PC(X) and the parents of the children of X in G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Previous work on scalable learning of MBs</head><p>In this section, we review three algorithms for learning MBs from data, namely the incremental association Markov boundary algorithm (IAMB) <ref type="bibr" target="#b18">[19]</ref>, the max-min Markov boundary algorithm (MMMB) <ref type="bibr" target="#b19">[20]</ref>, and HITON-MB <ref type="bibr" target="#b0">[1]</ref>. To our knowledge, these algorithms and some minor variants of them are the only algorithms for learning MBs from data that have experimentally been shown to scale to databases with thousands of features. However, we show that IAMB is data inefficient and that MMMB and HITON-MB do not guarantee the correct output under the faithfulness assumption. In the algorithms, X YjZ (X YjZ) denotes (in)dependence with respect to a learning database D, and dep(X, YjZ) is a measure of the strength of the dependence with respect to D. In particular, the algorithms run a v 2 independence test with the G 2 statistic in order to decide on X YjZ or X YjZ <ref type="bibr" target="#b16">[17]</ref>, and they use the negative p-value of the test as dep(X, YjZ). The three algorithms are based on the assumption that D is faithful to a DAG G, i.e. D is a sample from a probability distribution p faithful to G, and thus each node has a unique MB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">IAMB</head><p>Table <ref type="table" target="#tab_0">1</ref> outlines IAMB. The algorithm receives the target node T as input and returns MB(T) in MB as output. The algorithm works in two steps. First, the nodes in MB(T) are added to MB (lines 2-6). Since this step is based on the heuristic at line 3, some nodes not in MB(T) may be added to MB as well. These nodes are removed from MB in the second step (lines 7-9). Tsamardinos et al. prove in <ref type="bibr" target="#b18">[19]</ref> that IAMB is correct under the faithfulness assumption.</p><p>Theorem 4. Under the assumptions that the independence tests are correct and that the learning database D is an independent and identically distributed sample from a probability distribution p faithful to a DAG G, IAMB(T) returns MB(T).</p><p>The assumption that the independence tests are correct means that they decide (in)dependence iff the (in)dependence holds in p. We elaborate further on this assumption in Section 6. In order to maximize accuracy in practice, IAMB performs a test if it is reliable and skips it otherwise. Following the approach in <ref type="bibr" target="#b16">[17]</ref>, IAMB considers a test to be reliable when the number of instances in D is at least five times the number of degrees of freedom in the test. This means that the number of instances required by IAMB to identify MB(T) is at least exponential in the size of MB(T), because the number of degrees of freedom in a test is exponential in the size of the conditioning set and the test to add to MB the last node in MB(T) will be conditioned on at least the rest of the nodes in MB(T). However, depending on the topology of G, it can be the case that MB(T) can be identified by conditioning on sets much smaller than those used by IAMB, The second step can be run after each node addition at line 5, and/or the second step can be replaced by the PC algorithm <ref type="bibr" target="#b16">[17]</ref>. Finally, as Tsamardinos et al. note in <ref type="bibr" target="#b18">[19]</ref>, IAMB is similar to the grow-shrink algorithm (GS) <ref type="bibr" target="#b9">[10]</ref>. The only difference is that GS uses a simpler heuristic at line 3: Y = arg max X2(UnMBn{T}) dep(T, X j;). GS is correct under the assumptions in Theorem 4, but it is data inefficient for the same reason as IAMB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">MMMB</head><p>MMMB aims to reduce the data requirements of IAMB while still being scalable and correct under the faithfulness assumption. MMMB takes a divide-and-conquer approach that breaks the problem of identifying MB(T) into two subproblems: First, identifying PC(T) and, second, identifying the rest of the parents of the children of T in G. MMMB uses the max-min parents and children algorithm (MMPC) to solve the   <ref type="table" target="#tab_1">2</ref> outlines MMPC. The algorithm receives the target node T as input and returns PC(T) in PC as output. MMPC is similar to IAMB, with the exception that MMPC considers any subset of the output as the conditioning set for the tests that it performs and IAMB only considers the output. Tsamardinos et al. prove in <ref type="bibr" target="#b19">[20]</ref> that, under the assumptions in Theorem 4, the output of MMPC is PC(T). However, this is not always true. The flaw in the proof is the assumption that if X 6 2 PC(T), then T XjZ for some Z PC(T) and, thus, any node not in PC(T) that enters PC at line 7 is removed from it at line 11. This is not always true for the descendants of T. This is illustrated by running MMPC(T) with D faithful to the DAG (a) in Table <ref type="table" target="#tab_1">2</ref>  <ref type="bibr" target="#b19">[20]</ref> that, under the assumptions in Theorem 4, the output of MMMB is MB(T). However, this is not always true even if MMPC were correct under the faithfulness assumption. The flaw in the proof is the observation that motivates the second step of MMMB, which is not true. This is illustrated by running MMMB(T) with D faithful to the DAG (b) in Table <ref type="table" target="#tab_1">2</ref>. Let us assume that MMPC is correct under the faithfulness assumption. Then, MB = PC = {Q, S} and CanMB = {P, Q, R, S} at line 4. P enters MB at line 8 if Z = {Q} at line 5, because P 2 CanMBnPC, S 2 PC, T PjQ and T Pj{Q, S}. Consequently, the output of MMMB can include P which is not in MB(T) and, thus, MMMB does not guarantee the correct output under the faithfulness assumption even if MMPC were correct under this assumption.</p><p>In practice, MMMB performs a test if it is reliable and skips it otherwise. MMMB follows the same criterion as IAMB to decide whether a test is reliable or not. MMMB is data efficient because the number of instances required to identify MB(T) does not depend on the size of MB(T) but on the topology of G.</p><p>In <ref type="bibr" target="#b21">[22]</ref>, Tsamardinos et al. identify the flaw in MMPC and propose a corrected MMPC (CMMPC). The output of MMPC must be further processed in order to obtain PC(T), because it may contain some descendants of T in G other than its children. Fortunately, these nodes can be easily identified: If X is in the output of MMPC(T), then X is a descendant of T in G other than one of its children iff T is not in the output of MMPC(X). CMMPC, which is outlined in Table <ref type="table">3</ref>, implements this observation. The algorithm receives the target node T as input and returns PC(T) in PC as output. As shown above, however, correcting MMPC does not make MMMB correct. Independently of Tsamardinos et al., we identify and fix the flaws in both MMPC and MMMB in <ref type="bibr" target="#b12">[13]</ref>. We discuss our work in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">HITON-MB</head><p>Like MMMB, HITON-MB aims to reduce the data requirements of IAMB while still being scalable and correct under the faithfulness assumption. Like MMMB, HITON-MB identifies MB(T) by first identifying PC(T) and, then, identifying the rest of the parents of the children of T in G. HITON-MB uses HITON-PC to solve the first subproblem. Table <ref type="table" target="#tab_3">4</ref> outlines HITON-PC. The algorithm receives the target node T as input and returns PC(T) in PC as output. HITON-PC is similar to MMPC, with the exception that the former interleaves the addition of the nodes in PC(T) to PC (lines 4-5) and the removal from PC of the nodes that are not in PC(T) but that have been added to PC by the heuristic at line 4 (lines 7-9). Note also that this heuristic is simpler than the one used by MMPC, because the conditioning set is always the empty set. Aliferis et al. prove in <ref type="bibr" target="#b0">[1]</ref> that, under the assumptions in Theorem 4, the output of HITON-PC is PC(T). However, this is not </p><formula xml:id="formula_2">(T) 1 PC = ; 2 for each X 2 MMPC(T) do 3 i fT 2 MMPC(X) then 4 PC = PC [ {X} 5 return PC</formula><p>always true. The flaw in the proof is the same as that in the proof of correctness of MMPC. Running HITON-PC(T) with D faithful to the DAG (a) in Table <ref type="table" target="#tab_1">2</ref> can produce the same incorrect result as MMPC(T). Obviously, the flaw in HITON-PC can be fixed in the exactly the same way as the flaw in MMPC was fixed above.</p><p>Table <ref type="table" target="#tab_3">4</ref> outlines HITON-MB. The algorithm receives the target node T as input and returns MB(T) in MB as output. HITON-MB is similar to MMMB. The algorithm works in two steps. First, PC and MB are initialized with PC(T) and (PC(T) [ X2PC(T) PC(X))n{T}, respectively, by calling HITON-PC (lines 1-2). Second, the nodes in MB that are neither in PC(T) nor have a common child with T in G are removed from MB (lines 3-6). This step is based on the following observation. If X 2 MB and Y 2 PC, then X must be removed from MB iff T XjZ for some Z such that T, X 6 2 Z. Aliferis et al. prove in <ref type="bibr" target="#b0">[1]</ref> that, under the assumptions in Theorem 4, the output of HITON-MB is MB(T). However, this is not always true even if HITON-PC were correct under the faithfulness assumption. The flaw in the proof is the observation that motivates the second step of HITON-MB, which is not true. This is illustrated by running HITON-MB(T) with D faithful to the DAG (b) in Table <ref type="table" target="#tab_1">2</ref>. Let us assume that HITON-PC is correct under the faithfulness assumption. Then, PC = {Q, S} and MB = {P, Q, R, S} at line 3. P and R are removed from MB at line 6 because Q 2 PC and T PjQ and T RjQ. Then, MB = {Q, S} at line 7. Consequently, the output of HITON-MB does not include R which is in MB(T) and, thus, HITON-MB does not guarantee the correct output under the faithfulness assumption even if HITON-PC were correct under this assumption.</p><p>In practice, HITON-MB performs a test if it is reliable and skips it otherwise. HITON-MB follows the same criterion as IAMB and MMMB to decide whether a test is reliable or not. HITON-MB is data efficient because the number of instances required to identify MB(T) does not depend on the size of MB(T) but on the topology of G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Improving data efficiency</head><p>This section addresses the same question that motivated MMMB and HITON-MB: Can we develop an algorithm for learning MBs from data that is scalable, data efficient, and correct under the faithfulness assumption? The answer is yes. We call this new algorithm the parents and children based Markov boundary algorithm (PCMB) and prove that, unlike MMMB and HITON-MB, it is correct under the faithfulness assumption. Like IAMB, MMMB and HITON-MB, PCMB is based on the assumption that the learning database D is faithful to a DAG G and, thus, each node has a unique MB.</p><p>PCMB takes a divide-and-conquer approach that breaks the problem of identifying MB(T) into two subproblems: First, identifying PC(T) and, second, identifying the rest of the parents of the children of T in G. PCMB uses the functions GetPCD and GetPC to solve the first subproblem. X YjZ, X YjZ and dep(X, YjZ) are the same as in Section 3. Table <ref type="table" target="#tab_5">5</ref> outlines GetPCD. The algorithm receives the target node T as input and returns a superset of PC(T) in PCD as output. The algorithm tries to minimize the number of nodes not in PC(T) that are returned in PCD. The algorithm repeats three steps until PCD does not change. First, some nodes not in PC(T) are removed from CanPCD, which contains the candidates to enter PCD (lines 4-8). This step is based on the observation that X 2 PC(T) iff T Xj Z for all Z such that T, X 6 2 Z. Second, the candidate most likely to be in PC(T) is added to PCD and removed from CanPCD (lines 9-11). Since this step is based on the heuristic at line 9, some nodes not in PC(T) may be added to PCD as well. Some of these nodes are removed from PCD in the third step (lines <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref>). This step is based on the same observation as the first step.</p><p>Theorem 5. Under the assumptions that the independence tests are correct and that the learning database D is an independent and identically distributed sample from a probability distribution p faithful to a DAG G, GetPCD(T) returns a superset of PC(T) that does not include any node in ND(T)nPa(T).</p><p>Proof. First, we prove that the nodes in PC(T) are included in the output PCD. If X 2 PC(T), then T XjZ for all Z such that T, X 6 2 Z owing to Theorem 2. Consequently, X enters PCD at line 10 and does not leave it thereafter.</p><p>Second, we prove that the nodes in ND(T)nPa(T) are not included in the output PCD. It suffices to study the last time that lines 12-16 are executed. At line 12, Pa(T) PCD owing to the paragraph above. Therefore, if PCD still contains some X 2 ND(T)nPa(T), then T XjZ for some Z PCDn{X} owing to the local Markov property. Consequently, X is removed from PCD at line 16. h</p><p>The output of GetPCD must be further processed in order to obtain PC(T), because it may contain some descendants of T in G other than its children. These nodes can be easily identified: If X is in the output of GetPCD(T), then X is a descendant of T in G other than one of its children iff T is not in the output of GetPCD(X). GetPC, which is outlined in Table <ref type="table" target="#tab_5">5</ref>, implements this observation. The algorithm receives the target node T as input and returns PC(T) in PC as output. We prove that GetPC is correct under the faithfulness assumption. return MB Theorem 6. Under the assumptions that the independence tests are correct and that the learning database D is an independent and identically distributed sample from a probability distribution p faithful to a DAG G, GetPC(T) returns PC(T).</p><p>Proof. First, we prove that the nodes in PC(T) are included in the output PC. If X 2 PC(T), then T 2 PC(X). Therefore, X and T satisfy the conditions at lines 2 and 3, respectively, owing to Theorem 5. Consequently, X enters PC at line 4. Second, we prove that the nodes not in PC(T) are not included in the output PC. Let X 6 2 PC(T). If X does not satisfy the condition at line 2, then X does not enter PC at line 4. On the other hand, if X satisfies the condition at line 2, then X must be a descendant of T in G other than one of its children and, thus, T does not satisfy the condition at line 3 owing to Theorem 5. Consequently, X does not enter PC at line 4. h Finally, Table <ref type="table" target="#tab_5">5</ref> outlines PCMB. The algorithm receives the target node T as input and returns MB(T) in MB as output. The algorithm works in two steps. First, MB is initialized with PC(T) by calling GetPC (line 2). Second, the parents of the children of T in G that are not yet in MB are added to it (lines 3-8). This step is based on the following observation. The parents of the children of T in G that are missing from MB at line 3 are those that are non-adjacent to T in G. Therefore, if Y 2 PC(T), X 2 PC(Y) and X 6 2 PC(T), then X and T are non-adjacent parents of Y in G iff T XjZ [ {Y} for any Z such that T XjZ and T, X 6 2 Z. Note that Z can be efficiently obtained at line 6: GetPCD must have found such a Z and could have cached it for later retrieval. We prove that PCMB is correct under the faithfulness assumption.</p><p>Theorem 7. Under the assumptions that the independence tests are correct and that the learning database D is an independent and identically distributed sample from a probability distribution p faithful to a DAG G, PCMB(T) returns MB(T).</p><p>Proof. First, we prove that the nodes in MB(T) are included in the output MB. Let X 2 MB(T). Then, either X 2 PC(T) or X 6 2 PC(T) but X and T have a common child Y in G owing to Theorem 3. If X 2 PC(T), then X enters MB at line 2 owing to Theorem 6. On the other hand, if X 6 2 PC(T) but X and T have a common child Y in G, then X satisfies the conditions at lines 3-5 owing to Theorem 6 and the condition at line 7 owing to Theorem 2. Consequently, X enters MB at line 8.</p><p>Second, we prove that the nodes not in MB(T) are not included in the output MB. Let X 6 2 MB(T). X does not enter MB at line 2 owing to Theorem 6. If X does not satisfy the conditions at lines 3-5, then X does not enter MB at line 8. On the other hand, if X satisfies the conditions at lines 3-5, then it must be due to either T ! Y ! X or T Y X or T Y ! X. Therefore, X does not satisfy the condition at line 7 owing to the faithfulness assumption. Consequently, X does not enter MB at line 8. h</p><p>In practice, PCMB performs a test if it is reliable and skips it otherwise. PCMB follows the same criterion as IAMB, MMMB and HITON-MB to decide whether a test is reliable or not. PCMB is data efficient because the number of instances required to identify MB(T) does not depend on the size of MB(T) but on the topology of G. For instance, if G is a tree, then PCMB does not need to perform any test that is conditioned on more than one node in order to identify MB(T), no matter how large MB(T) is. PCMB scales to databases with thousands of features because it does not require learning a complete BN. The experiments in the following section confirm it. Like IAMB, MMMB and HITON-MB, if the assumptions in Theorem 7 do not hold, then PCMB may not return a MB of T but an approximation. We discuss this issue further in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental evaluation</head><p>In this section, we compare the performance of IAMB and PCMB through experiments on synthetic and real databases. We do not consider GS because IAMB outperforms it <ref type="bibr" target="#b18">[19]</ref>. We do not consider MMMB and HITON-MB because we are not interested in any algorithm that does not guarantee the correct output under the faithfulness assumption. In order to ensure that IAMB converges to a local optimum, our implementation of it interleaves the first and second steps until convergence, i.e. if some node removal occurs at line 9, then IAMB jumps to line 2 after the second step is completed. This does not invalidate Theorem 4. Our implementation of IAMB and PCMB breaks ties at random. Both IAMB and PCMB are written in C++ and all the experiments below are run on a Pentium 2.4 GHz, 512 MB RAM and Windows 2000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Synthetic data</head><p>The experiments in this section focus on the accuracy and data efficiency of the algorithms, whereas the next section addresses their scalability. For this purpose, we consider databases sampled from two known BNs, the Alarm BN <ref type="bibr" target="#b6">[7]</ref> and the Pigs BN <ref type="bibr" target="#b7">[8]</ref>. These BNs have 37 and 441 nodes, respectively, and the largest MB consists of eight and 68 nodes, respectively. We run IAMB and PCMB with each node in each BN as the target random variable T and, then, report the average precision and recall over all the nodes for each BN. Precision is the number of true positives in the output divided by the number of nodes in the output. Recall is the number of true positives in the output divided by the number of true positives in the BN. We also combine precision and recall as ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ð1 À precisionÞ 2 þ ð1 À recallÞ 2 q to measure the Euclidean distance from perfect precision and recall. Finally, we also report the running time in seconds. The significance level for the independence tests is 0.01.</p><p>Table <ref type="table" target="#tab_6">6</ref> summarizes the results of the experiments for different sample sizes. Each entry in the table shows average and standard deviation values over 10 databases (the same 10 databases for IAMB and PCMB). For the Alarm databases, both algorithms achieve similar recall but PCMB scores higher precision and, thus, shorter distance than IAMB. Therefore, PCMB usually returns fewer false positives than IAMB. The explanation is that PCMB performs more tests than IAMB and this makes it harder for false positives to enter the output. Compare, for instance, the heuristic at line 3 in IAMB with the heuristic at line 9 in GetPCD and the double check at lines 2-3 in GetPC. For the Pigs databases where larger MBs exist, PCMB outperforms IAMB in terms of precision, recall and distance. For instance, PCMB correctly identifies the MB of the node 435 of the Pigs BN, which consists of 68 nodes, with 500 instances while IAMB performs poorly for this node and sample size (precision = 1.00 ± 0.00, recall = 0.04 ± 0.00 and distance = 0.96 ± 0.00). The explanation is that, unlike IAMB, PCMB does not need to condition on the whole MB to identify it. Consequently, we can conclude that PCMB is more accurate than IAMB because it is more data efficient. It is worth mentioning that we expect the two variants of IAMB mentioned in Section 3.1 to perform better than IAMB, as they carry out more tests, but worse than PCMB, as they still have to condition on the whole MB to identify it, e.g. they require a number of instances at least exponential in 68 for perfect precision and recall for the node 435 of the Pigs BN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">Real data</head><p>The experiments in this section compare the ability of IAMB and PCMB to solve a realworld FSS problem involving thousands of features. Specifically, we consider the Thrombin database which was provided by DuPont Pharmaceuticals for KDD Cup 2001 and it is exemplary of the real-world drug design environment <ref type="bibr" target="#b1">[2]</ref>. The database contains 2543 instances characterized by 139,351 binary features. Each instance represents a drug compound tested for its ability to bind to a target site on thrombin, a key receptor in blood clotting. The features describe the three-dimensional properties of the compounds. Each compound is labelled with one out of two classes, either it binds to the target site or not. The task of KDD Cup 2001 was to learn a classifier from 1909 given compounds (learning data) in order to predict binding affinity and, thus, the potential of a compound as anti-clotting agent. There were 114 classifiers submitted to KDD Cup 2001, whose accuracy was evaluated by the organizers of the competition on the remaining 634 compounds (testing data). The accuracy of a classifier was computed as the average of the accuracy on true binding compounds and the accuracy on true non-binding compounds. Besides the huge number of features, the Thrombin database is challenging for two other reasons. First, the learning data are extremely imbalanced: Only 42 out of the 1909 compounds bind. Second, the testing data are not sampled from the same probability distribution as the learning data, because the compounds in the testing data were synthesized based on the assay results recorded in the learning data. Scoring higher than 60% accuracy is impressive <ref type="bibr" target="#b1">[2]</ref>.</p><p>To solve the FSS problem for the Thrombin database, we run IAMB and PCMB with the class random variable as the target random variable T. Unlike in the previous section, we cannot now assess the performance of IAMB and PCMB by comparing their outputs with MB(T) because this is unknown. Instead, we assess the performance of IAMB (PCMB) as the accuracy on the testing data of a naive Bayesian classifier (NB) trained on the learning data corresponding to only the features selected by IAMB (PCMB): The higher the accuracy the better the features selected and, thus, the better the algorithm used to select them. In order to train the NBs, we use the MLC++ software with the default parameters, except for the Laplace correction that is switched on <ref type="bibr" target="#b8">[9]</ref>. We also report the number of features selected and the running time in seconds. As in the section above, the significance level for the independence tests in PCMB is 0.01. For IAMB, however, better results are obtained when the significance level for the independence tests is 0.0001. This significance level seems to avoid better than 0.01 the spurious dependencies that may exist in the learning data due to the large number of features. In the case of PCMB, it seems that the criterion for a node to enter the output, which is considerably more stringent than that in IAMB, suffices to avoid the spurious dependencies.</p><p>Table <ref type="table" target="#tab_7">7</ref> summarizes the results of the experiments. The table shows average and standard deviation values over 114 runs for IAMB and PCMB because ties, which are broken at random, are common due to the high dimensionality of the learning data. Clearly, PCMB returns smaller and more accurate MBs than IAMB. Specifically, PCMB scores higher than 60% accuracy in all the runs, which is impressive according to <ref type="bibr" target="#b1">[2]</ref>. For instance, the MB to which PCMB converges most often (39 out of the 114 runs) scores 63% accuracy and contains only three features <ref type="bibr">(12,810, 79,651 and 91,839)</ref>. Regarding running time, PCMB is slower than IAMB because, as we have discussed in the previous section, it performs more tests. All in all, our results illustrate that both algorithms are scalable. We note that no existing algorithm for learning BNs from data can handle such a high-dimensional database as the Thrombin database. Hence, the importance of developing algorithms for learning MBs from data that, like IAMB and PCMB, avoid learning a complete BN as an intermediate step.</p><p>Table <ref type="table" target="#tab_7">7</ref> compiles some other results that we now describe further. We do not report the baseline accuracy of a NB with no FSS because our computer cannot run the MLC++ software with all the 139,351 features. This illustrates the importance of FSS. In <ref type="bibr" target="#b22">[23]</ref>, 50% accuracy is reported for a support vector machine with no FSS. The winner of KDD Cup 2001 was a tree augmented naive Bayesian classifier with four features scoring 68% accuracy. A NB with these four features scores 67% accuracy. In <ref type="bibr" target="#b22">[23]</ref>, a classifier that takes into account that the learning data are imbalanced reaches 77% accuracy with six features, and another classifier that takes into account the distribution of the unlabelled testing data achieves 83% accuracy with 15 features. Since the features used by these two classifiers are not reported in <ref type="bibr" target="#b22">[23]</ref>, we cannot calculate the accuracy of a NB with only those features.</p><p>In any case, the 67% accuracy of the NB with only the features in the winner of KDD Cup 2001 suffices to conclude that IAMB and PCMB return suboptimal solutions to the FSS problem for the Thrombin database. The causes of this suboptimal behavior lie, on one hand, in the data inefficiency of IAMB and, on the other hand, in the divide-and-conquer approach that PCMB takes, that is justified if the faithfulness assumption holds but that may hurt performance otherwise (see more evidence on Section 5.1). We believe that in order to improve the performance of IAMB and PCMB we have to relax the faithfulness assumption that underlies PCMB and avoid the data inefficiency of IAMB. We address this question in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Relaxing the faithfulness assumption</head><p>This section studies the following question: Can we relax the faithfulness assumption and develop an algorithm for learning MBs from data that is correct, scalable and data efficient ? We prove that IAMB is still correct under the composition property assumption, which is weaker than the faithfulness assumption (Theorem 1). We propose a stochastic variant of IAMB that can overcome the data inefficiency of IAMB while being scalable and correct under the composition property assumption. We show with experiments on the Thrombin database that this new algorithm can outperform IAMB and PCMB considerably often. Theorem 8. Under the assumptions that the independence tests are correct and that the learning database D is an independent and identically distributed sample from a probability distribution p satisfying the composition property, IAMB(T) returns a MB of T.</p><p>Proof. First, we prove that MB is a Markov blanket of T when the loop in lines 2-6 is left. Let us suppose that this is not the case, i.e. T (UnMBn{T})jMB when the loop in lines 2-6 is left. Then, there exists X 2 (UnMB n{T}) such that T XjMB due to the composition property assumption. This contradicts the assumption that the loop in lines 2-6 is left due to the assumption that the independence tests are correct.</p><p>Second, we prove that MB remains a Markov blanket of T after each node removal in line 9. It suffices to note that the independence tests are assumed to be correct and that T (UnMB n{T})jMB and T Xj(MBn{X}) yield T (Un(MBn{X})n{T})j(MBn{X}) due to the contraction property.</p><p>Third, we prove that MB is a minimal Markov blanket of T in line 10. Let us suppose that this is not the case, i.e. there exists M &amp; MB in line 10 such that M is a Markov blanket of T. Let X 2 (MBnM) and Y (U nMn{T}n{X}). Then, T (UnMn{T})jM and, thus, T (Y [ {X})jM due to the decomposition property and, thus, T Xj(M [ Y) due to the weak union property. This contradicts the assumption that M &amp; MB, because any X 2 (MBnM) would have been removed from MB in line 9 due to the assumption that the independence tests are correct. h</p><p>The following result, which we borrow from <ref type="bibr" target="#b2">[3]</ref>, illustrates that the composition property assumption is much weaker than the faithfulness assumption. If a probability distribution p(U, H, S) is faithful to a DAG G over {U, H, S}, then pðUÞ ¼ P h pðU; H ¼ h; S ¼ sÞ satisfies the composition property, though it may not be faithful to any DAG. In other words, G can include some hidden nodes H and some selection bias S = s. Moreover, this result holds not only for DAGs and the d-separation criterion but for any graph and any criterion that is based on vertex separation.</p><p>As mentioned before, false positives may enter MB at line 5 in IAMB because the heuristic at line 3 is greedy. An example, inspired by <ref type="bibr" target="#b20">[21]</ref>, follows. An integer between 0 and 3 is sent from a transmitter station T to a receiver station R through two intermediary stations I 1 and I 2 . T does not send the integer to I 1 but only wether it is in {0, 1} or in {2, 3}. Likewise, T only communicates to I 2 whether the integer is in {0, 2} or in {1, 3}. Fig. <ref type="figure" target="#fig_1">1</ref> depicts a BN for this example, where g 2 (0, 1/2) represents the noise in the transmission. Since p(T, I 1 , I 2 , R) satisfies the faithfulness assumption, {I 1 , I 2 } is the unique MB of T. If g is positive but small enough, then R has more information about the integer transmitted by T than I 1 or I 2 alone. Thus, owing to the greediness of the heuristic at line 3, we expect IAMB(T) to first add R, then add I 1 and I 2 in any order, and finally remove R. This sequence of node additions and removals is less data efficient and more prone to errors than directly adding I 1 and I 2 in any order, because the former sequence requires three independence tests to decide dependence while the latter requires only two. Therefore, the sequence that IAMB tries may not be the most data efficient and safe sequence available. This leads us to propose a stochastic variant of IAMB, called KIAMB, that can try different sequences when run repeatedly. Hopefully, some of these sequences are more data efficient and less prone to errors than the one used by IAMB, e.g. if they add fewer false positives. Table <ref type="table">8</ref> outlines KIAMB. KIAMB differs from IAMB in that it allows the user to specify the trade-off between greediness and randomness in the search through an input parameter K 2 [0, 1]. IAMB corresponds to KIAMB with K = 1. Therefore, while IAMB greedily adds to MB the most dependant node in CanMB which contains the candidates to enter MB, KIAMB adds to MB the most dependant node in CanMB2 which is a random subset of CanMB with size max(1,b(jCanMBj AE K)c) where jCanMBj is the size of CanMB (lines 7-9). The proof of Theorem 8 is also valid for the following theorem. Theorem 9. Under the assumptions that the independence tests are correct and that the learning database D is an independent and identically distributed sample from a probability distribution p satisfying the composition property, KIAMB(T, K) returns a MB of T for any value of K.</p><p>We note that Theorems 8 and 9 say ''a MB of T'' and not ''the MB of T'' because, unlike the faithfulness assumption, the composition property assumption does not imply that T has an unique MB. A necessary condition for the existence of more than one MB of T is that p does not satisfy the intersection property (Theorem 3), which implies that p cannot be strictly positive (Theorem 1). A simple example of a probability distribution p that satisfies the composition property and has several MBs of T involves two other random variables X and Y such that T = X = Y: Both {X} and {Y} are MBs of T. A more elaborated example is the integer transmission scenario introduced above with p(T) uniform and g = 0: Both {I 1 , I 2 } and {R} are MBs of T. 1 The following theorem extends Theorem 9 with the guarantee that KIAMB with K = 0 can discover any MB of T. 1 To show that this modification of the integer transmission example satisfies the composition property, we reformulate it as follows. Let B 1 and B 2 be the first and second bits, respectively, of the binary code corresponding to the integer sent by T. Then, T = R = {B 1 ,B 2 }, I 1 = {B 1 }, I 2 = {B 2 }, and X YjZ iff (XnZ) \ Y = ;. C o n s e q u e n t l y , X Y jZ ^X</p><formula xml:id="formula_3">W jZ ) ( X nZ ) \ Y = ; ^( X nZ ) \ W = ; ) ( X nZ ) \ ( Y [ W ) = ; ) X (Y [ W)jZ.</formula><p>Theorem 10. Under the assumptions that the independence tests are correct and that the learning database D is an independent and identically distributed sample from a probability distribution p satisfying the composition property, KIAMB(T, 0) returns a MB of T. The MB of T returned is any MB of T with non-zero probability.</p><p>Proof. MB is a MB of T in line 14 due to Theorem 9. Let us assume that T has several MBs. We now prove that MB is any MB of T in line 14 with non-zero probability. Let M (U n{T}) be any MB of T. First, we prove that if MB &amp; M before the node addition in line 9, then MB M with non-zero probability after the node addition. Let us assume that MB &amp; M before the node addition in line 9. Then, T (UnMBn{T})jMB and T (UnMn{T})jM. These two statements together yield T (MnMB)jMB due to the contraction property and, thus, there exists X 2 (MnMB) such that T XjMB due to the composition property assumption. Therefore, X is added to MB in line 9 with non-zero probability due to K = 0 and the assumption that the independence tests are correct.</p><p>Second, we prove that MB = M in line 14 with non-zero probability. The paragraph above guarantees that MB = M with non-zero probability when the loop in lines 2-10 is left, and the assumption that the independence tests are correct guarantees that none of the nodes in MB is removed from it in line 13. h</p><p>The theorem above does not hold for IAMB, e.g. IAMB always returns {R} in the integer transmission example with p(T) uniform and g = 0 because the heuristic at line 3 is greedy. However, in some cases IAMB can return any MB of T by just breaking ties at random, e.g. in the T = X = Y example. The theorem above guarantees that KIAMB with K = 0 discovers all the MBs of T if run repeatedly enough times. However, since T can have many MBs, it may be more realistic to say that running KIAMB repeatedly with K 5 1 has the potential to discover, if not all, at least several MBs of T. This ability to generate alternative hypothesis is important in domains such as bioinformatics and medicine <ref type="bibr" target="#b15">[16]</ref>. For instance, if the nodes in a MB of T represent genetic markers for a disease T, then the more MBs of T are identified the more biological insight into the disease T is gained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental evaluation</head><p>In the previous section, we have argued that KIAMB can outperform IAMB because it can follow a sequence of node additions and removals that is more data efficient and, thus, less prone to errors. In this section, we confirm it by adding to the 114 runs of IAMB in Section 4.1.2 the results of 114 runs of KIAMB with K = 0.8. Preliminary experiments indicated that K 2 [0.7, 0.9] performs best. We run each algorithm 114 times to guarantee that our results are comparable with those of KDD Cup 2001, which had 114 participants. Our implementation of KIAMB reuses most of the code of IAMB in Section 4.1.2, including the interleaving of the first and second steps until convergence. This does not invalidate any of the theorems in the previous section. The rest of the experimental setting is the same as in Section 4. The histograms in Fig. <ref type="figure" target="#fig_2">2</ref> also warn that KIAMB can perform worse than IAMB. To be exact, 17 of the 114 runs of KIAMB corresponding to 16 different MBs score lower than 53% accuracy, which is the lowest accuracy obtained by IAMB. We note that 79 of the 114 participants in KDD Cup 2001 scored lower than 53% accuracy. Therefore, KIAMB should be seen as a tool to generate alternative MBs, each of which should be validated before being accepted. The validation may resort to expert knowledge of the domain at hand. Or, as we have done in this paper, it may use some testing data. Obviously, having to hold some data out of the learning process for testing purposes is a drawback when the data available are scarce. However, we prefer it to running IAMB on all the data available which, as our experiments show, may produce a rather inaccurate MB. It is necessary warning that selecting the most accurate MB on some testing data out of the MBs obtained by running KIAMB repeatedly on some learning data may result in an overfitted MB if the number of repeated runs is too large <ref type="bibr" target="#b10">[11]</ref>. We do not think this is an issue in our experiments because 114 is not such a large number of runs. In any case, the risk of overfitting in our experiments should be comparable to that in KDD Cup 2001, because we run KIAMB as many times as there were participants in KDD Cup 2001. Moreover, we do not simply compare the best MB obtained via KIAMB with the winner of KDD Cup 2001 but we compare the whole distributions of results, which makes our conclusions more robust against overfitting.</p><p>The histograms in Fig. <ref type="figure" target="#fig_2">2</ref> show that KIAMB can also outperform PCMB considerably often. As a matter of fact, 16 of the 114 runs of KIAMB corresponding to 14 different  The reason why KPCMB may not return a MB of T lies in the divide-and-conquer approach that it takes, that is justified if the faithfulness assumption holds but that may hurt performance otherwise. In other words, the solutions to the subproblems that KPCMB obtains with the help of GetPCD and GetPC may not combine into a solution to the original problem of learning a MB of T. This illustrates the importance of developing algorithms for learning MBs from data that, like KIAMB, avoid the faithfulness assumption while being data efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>In this paper, we have reported the results of our research on learning MBs from data. We have presented algorithms for such a task, studied the conditions under which they are correct, scalable and data efficient, and evaluated them on synthetic and real databases. Specifically, we have introduced PCMB, an algorithm that is scalable, data efficient, and correct under the faithfulness assumption. Then, we have proven that IAMB is correct under the composition property assumption. Finally, we have introduced KIAMB, an algorithm that aims to overcome the data inefficiency of IAMB while being scalable and correct under the composition property assumption. The experimental results have shown that PCMB outperforms IAMB, and that KIAMB can outperform IAMB and PCMB considerably often. The experimental results have also confirmed that these algorithms can scale to high-dimensional domains. The reason is that they do not require learning a BN first, which can be painfully time consuming in high-dimensional domains <ref type="bibr" target="#b21">[22]</ref>. This is particularly true for those algorithms for learning BNs from data that are (asymptotically) correct under the faithfulness or composition property assumption <ref type="bibr" target="#b21">[22]</ref>, which are the ones we are interested in.</p><p>It is worth mentioning that the proofs of correctness of the algorithms in this paper assume that the independence tests are correct. If the tests are simply consistent, then the proofs of correctness become proofs of consistency, because the algorithms perform a finite number of tests. Kernel-based independence tests that are consistent for any probability distribution exist <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. The probability of error for these tests decays exponentially to zero when the sample size goes to infinity.</p><p>It is also worth mentioning that, throughout this paper, we have assumed that all the random variables are discrete. However, the results in this paper remain valid when all the random variables except the target node are continuous. Furthermore, they also remain valid when all the random variables (including the target node) are continuous. It suffices to replace the v 2 independence test by an appropriate independence test, e.g. Student's t-test or Fisher's z test. The case where all the random variables (including the target node) are continuous is particularly interesting if the learning database is assumed to be a sample from a Gaussian probability distribution, because any Gaussian probability distribution satisfies the composition property, no matter whether it is faithful to some DAG or not <ref type="bibr" target="#b17">[18]</ref>. Therefore, IAMB and KIAMB are correct if the learning database is assumed to be a sample from a Gaussian probability distribution. Such an assumption is common in many domains, e.g. when learning genetic regulatory networks from gene expression databases <ref type="bibr" target="#b14">[15]</ref>.</p><p>We are currently working on a scalable divide-and-conquer algorithm similar to PCMB that is data efficient as well as correct under the composition property assumption. At the same time, we are applying the results in this paper to solve the FSS problem for gene expression databases with thousands of features but hundreds of instances at most. Since the existing algorithms for learning BNs from data can be painfully time consuming for such high-dimensional database <ref type="bibr" target="#b21">[22]</ref>, it is very important to develop algorithms for learning MBs from data that, like those in this paper, avoid learning a complete BN as an intermediate step. An alternative approach is to reduce the search space so as to reduce the computational cost of the existing algorithms for learning BNs from data. For instance, <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b21">22]</ref> propose restricting the search for the parents of each node to a small set of candidate parents that are selected in advance. According to the experiments in the latter paper, the algorithm proposed in that paper performs better. However, both algorithms lack a proof of (asymptotic) correctness under the faithfulness assumption. Moreover, it seems unnecessarily time consuming to learn a complete BN to solve the FSS problem, because we are only interested in a very specific part of it, namely MB(T). Based on this idea and the results in this paper, we have recently presented in <ref type="bibr" target="#b13">[14]</ref> an algorithm that learns a BN for the nodes in the neighborhood of a given node. This algorithm allows us to cope with high-dimensional data by learning a local BN around a node of interest rather than a complete BN model of the data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. BN for the integer transmission example (g 2 (0, 1/2)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Histograms of the accuracy of the runs of KIAMB (accuracy in the horizontal axis and number of runs in the vertical axis).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Histograms of the accuracy of the runs of KPCMB (accuracy in the horizontal axis and number of runs in the vertical axis).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>.g. if G is a tree (see Sections 3.2 and 4). Therefore, IAMB is data inefficient because its data requirements can be unnecessarily high. Tsamardinos et al. are aware of this drawback and describe in<ref type="bibr" target="#b18">[19]</ref> some variants of IAMB that alleviate it, though they do not solve it, while still being scalable and correct under the assumptions in Theorem 4:</figDesc><table><row><cell>IAMB</cell><cell></cell><cell></cell></row><row><cell></cell><cell>IAMB(T)</cell><cell></cell></row><row><cell></cell><cell cols="2">/ * add true positives to MB * /</cell></row><row><cell cols="2">1 MB = ;</cell><cell></cell></row><row><cell>2</cell><cell>repeat</cell><cell></cell></row><row><cell>3</cell><cell cols="2">Y = arg: max X2(UnMBn{T}) dep(T, XjMB)</cell></row><row><cell>4</cell><cell cols="2">i fT YjMB then</cell></row><row><cell>5</cell><cell cols="2">MB = MB [ {Y}</cell></row><row><cell>6</cell><cell cols="2">until MB does not change</cell></row><row><cell></cell><cell cols="2">/ * remove false positives from MB * /</cell></row><row><cell>7</cell><cell cols="2">for each X 2 MB do</cell></row><row><cell>8</cell><cell>i fT</cell><cell>Xj(MBn{X}) then</cell></row><row><cell>9</cell><cell cols="2">MB = MBn{X}</cell></row><row><cell>10</cell><cell cols="2">return MB</cell></row></table><note><p>e</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="3">MMPC and MMMB</cell></row><row><cell></cell><cell cols="2">MMPC(T)</cell><cell>(a)</cell></row><row><cell></cell><cell cols="3">/ * add true positives to PC * /</cell></row><row><cell cols="2">1 PC = ;</cell><cell></cell></row><row><cell cols="2">2 repeat</cell><cell></cell></row><row><cell>3</cell><cell cols="3">for each X 2 (UnPCn{T}) do</cell></row><row><cell>4</cell><cell cols="3">Sep[X] = arg: min ZPC dep(T, XjZ)</cell></row><row><cell>5</cell><cell cols="3">Y = arg: max X2(UnPCn{T}) dep(T, XjSep[X])</cell></row><row><cell>6</cell><cell cols="2">i fT YjSep[Y] then</cell></row><row><cell>7</cell><cell cols="2">PC = PC [ {Y}</cell></row><row><cell cols="3">8 until PC does not change</cell></row><row><cell></cell><cell cols="3">/ * remove false positives from PC * /</cell></row><row><cell cols="3">9 for each X 2 PC do</cell></row><row><cell>10</cell><cell>if T</cell><cell cols="2">XjZ for some Z PCn{X} then</cell></row><row><cell>11</cell><cell cols="2">PC = PCn{X}</cell></row><row><cell cols="3">12 return PC</cell></row><row><cell></cell><cell cols="2">MMMB(T)</cell></row><row><cell></cell><cell cols="3">/ * add true positives to MB * /</cell></row><row><cell cols="3">1 PC = MMPC(T)</cell></row><row><cell cols="3">2 MB = PC</cell></row><row><cell cols="4">3 CanMB = (PC [ X2PC MMPC(X))n{T}</cell></row><row><cell></cell><cell cols="3">/ * add more true positives to MB * /</cell></row><row><cell cols="4">4 for each X 2 CanMBnPC do</cell></row><row><cell>5</cell><cell cols="2">find any Z such that T</cell><cell>XjZ and T, X 6 2 Z</cell></row><row><cell>6</cell><cell cols="2">for each Y 2 PC do</cell></row><row><cell>7</cell><cell cols="2">i fT XjZ [ {Y} then</cell></row><row><cell>8</cell><cell cols="2">MB = MB [ {X}</cell></row><row><cell cols="3">9 return MB</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>. Neither P nor R enters PC at line 7 because T Pj; and T Rj;. Q enters PC because T QjZ for all Z such that T,Q 6 2 Z. S enters PC because T Sj; and T SjQ. Then, PC = {Q, S} at line 9. Neither Q nor S leaves PC at line 11. Consequently, the output of MMPC includes S which is not in PC(T) and, thus, MMPC does not guarantee the correct output under the faithfulness assumption.Table2 outlinesMMMB. The algorithm receives the target node T as input and returns MB(T) in MB as output. The algorithm works in two steps. First, PC and MB are initialized with PC(T) and CanMB with (PC(T) [ X2PC(T) PC(X))n{T} by calling MMPC (lines 1-3). CanMB contains the candidates to enter MB. Second, the parents of the children of T in G that are not yet in MB are added to it (lines 4-8). This step is based on the following observation. The parents of the children of T in G that are missing from MB at line 4 are those that are non-adjacent to T in G. These parents are in CanMBnPC. Therefore, if X 2 CanMBnPC and Y 2 PC, then X and T are non-adjacent parents of Y in G iff T XjZ [ {Y} for any Z such that T XjZ and T, X 6 2 Z. Tsamardinos et al. prove in</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell cols="3">HITON-PC and HITON-MB</cell></row><row><cell cols="2">HITON-PC(T)</cell><cell></cell></row><row><cell>1</cell><cell>PC = ;</cell><cell></cell></row><row><cell>2</cell><cell cols="2">CanPC = Un{T}</cell></row><row><cell>3</cell><cell>repeat</cell><cell></cell></row><row><cell></cell><cell cols="2">/ * add the best candidate to PC * /</cell></row><row><cell>4</cell><cell cols="2">Y = arg: max X2CanPC dep(T, Xj;)</cell></row><row><cell>5</cell><cell cols="2">PC = PC [ {Y}</cell></row><row><cell>6</cell><cell cols="2">CanPC = CanPCn{Y}</cell></row><row><cell></cell><cell cols="2">/ * remove false positives from PC * /</cell></row><row><cell>7</cell><cell cols="2">for each X 2 PC do</cell></row><row><cell>8</cell><cell>i fT</cell><cell>XjZ for some Z PCn{X} then</cell></row><row><cell>9</cell><cell cols="2">PC = PCn{X}</cell></row><row><cell>10</cell><cell cols="2">until CanPC is empty</cell></row><row><cell>11</cell><cell>return PC</cell><cell></cell></row><row><cell cols="3">HITON-MB(T)</cell></row><row><cell></cell><cell cols="2">/ * add true positives to MB * /</cell></row><row><cell>1</cell><cell cols="2">PC = HITON-PC(T)</cell></row><row><cell>2</cell><cell cols="2">MB = (PC [</cell></row></table><note><p>X2PC HITON À PC(X))n{T} / * remove false positives from MB * / 3 for each X 2 MB do 4 for each Y 2 PC do 5 i fT XjZ for some Z {Y} [ (Un{T, X, Y}) then 6 MB = MBn{X} 7 return MB</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 CMMPC CMMPC</head><label>3CMMPC</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell cols="3">GetPCD, GetPC and PCMB</cell><cell></cell><cell></cell></row><row><cell></cell><cell>GetPCD(T)</cell><cell></cell><cell></cell><cell>GetPC(T)</cell></row><row><cell>1</cell><cell>PCD = ;</cell><cell></cell><cell cols="2">1 PC = ;</cell></row><row><cell>2</cell><cell cols="2">CanPCD = Un{T}</cell><cell cols="3">2 for each X 2 GetPCD(T) do</cell></row><row><cell>3</cell><cell>repeat</cell><cell></cell><cell>3</cell><cell cols="2">i fT 2 GetPCD(X) then</cell></row><row><cell></cell><cell cols="2">/ * remove false positives from CanPCD * /</cell><cell>4</cell><cell cols="2">PC = PC [ {X}</cell></row><row><cell>4</cell><cell cols="2">for each X 2 CanPCD do</cell><cell cols="2">5 return PC</cell></row><row><cell>5</cell><cell cols="2">Sep[X] = arg:min ZPCD dep(T, XjZ)</cell><cell></cell><cell></cell></row><row><cell>6</cell><cell cols="2">for each X 2 CanPCD do</cell><cell></cell><cell>PCMB(T)</cell></row><row><cell>7</cell><cell>i fT</cell><cell>XjSep[X] then</cell><cell></cell><cell cols="2">/ * add true positives to MB * /</cell></row><row><cell>8</cell><cell cols="2">CanPCD = CanPCDn{X}</cell><cell>1</cell><cell>PC = GetPC(T)</cell></row><row><cell></cell><cell cols="2">/ * add the best candidate to PCD * /</cell><cell>2</cell><cell>MB = PC</cell></row><row><cell>9</cell><cell cols="2">Y = arg: max X2CanPCD dep(T, XjSep[X])</cell><cell></cell><cell cols="2">/ * add more true positives to MB * /</cell></row><row><cell>10</cell><cell cols="2">PCD = PCD [ {Y}</cell><cell>3</cell><cell cols="2">for each Y 2 PC do</cell></row><row><cell>11</cell><cell cols="2">CanPCD = CanPCDn{Y}</cell><cell>4</cell><cell cols="2">for each X 2 GetPC(Y) do</cell></row><row><cell></cell><cell cols="2">/ * remove false positives from PCD * /</cell><cell>5</cell><cell>i fX 6 2 PC then</cell></row><row><cell>12</cell><cell cols="2">for each X 2 PCD do</cell><cell>6</cell><cell>find Z st T</cell><cell>XjZ and T, X 6 2 Z</cell></row><row><cell>13</cell><cell cols="2">Sep[X] = arg: min ZPCDn{X} dep(T, XjZ)</cell><cell>7</cell><cell cols="2">i fT XjZ [ {Y} then</cell></row><row><cell>14</cell><cell cols="2">for each X 2 PCD do</cell><cell>8</cell><cell cols="2">MB = MB [ {X}</cell></row><row><cell>15</cell><cell>if T</cell><cell>XjSep[X] then</cell><cell>9</cell><cell></cell></row><row><cell>16</cell><cell cols="2">PCD = PCDn{X}</cell><cell></cell><cell></cell></row><row><cell cols="3">17 until PCD does not change</cell><cell></cell><cell></cell></row><row><cell cols="3">18 return PCD</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6</head><label>6</label><figDesc>Results of the experiments with the Alarm and Pigs databases</figDesc><table><row><cell>Database</cell><cell>Instances</cell><cell>Algorithm</cell><cell>Precision</cell><cell>Recall</cell><cell>Distance</cell><cell>Time</cell></row><row><cell>Alarm</cell><cell>100</cell><cell>IAMB</cell><cell>0.85 ± 0.06</cell><cell>0.46 ± 0.03</cell><cell>0.54 ± 0.06</cell><cell>0 ± 0</cell></row><row><cell>Alarm</cell><cell>100</cell><cell>PCMB</cell><cell>0.79 ± 0.04</cell><cell>0.49 ± 0.05</cell><cell>0.51 ± 0.04</cell><cell>0 ± 0</cell></row><row><cell>Alarm</cell><cell>200</cell><cell>IAMB</cell><cell>0.87 ± 0.04</cell><cell>0.60 ± 0.03</cell><cell>0.42 ± 0.04</cell><cell>0 ± 0</cell></row><row><cell>Alarm</cell><cell>200</cell><cell>PCMB</cell><cell>0.95 ± 0.03</cell><cell>0.56 ± 0.05</cell><cell>0.38 ± 0.06</cell><cell>0 ± 0</cell></row><row><cell>Alarm</cell><cell>500</cell><cell>IAMB</cell><cell>0.91 ± 0.03</cell><cell>0.72 ± 0.04</cell><cell>0.30 ± 0.04</cell><cell>0 ± 0</cell></row><row><cell>Alarm</cell><cell>500</cell><cell>PCMB</cell><cell>0.94 ± 0.01</cell><cell>0.72 ± 0.04</cell><cell>0.26 ± 0.03</cell><cell>0 ± 0</cell></row><row><cell>Alarm</cell><cell>1000</cell><cell>IAMB</cell><cell>0.93 ± 0.03</cell><cell>0.80 ± 0.01</cell><cell>0.22 ± 0.02</cell><cell>0 ± 0</cell></row><row><cell>Alarm</cell><cell>1000</cell><cell>PCMB</cell><cell>0.99 ± 0.01</cell><cell>0.79 ± 0.01</cell><cell>0.18 ± 0.02</cell><cell>0 ± 0</cell></row><row><cell>Alarm</cell><cell>2000</cell><cell>IAMB</cell><cell>0.92 ± 0.04</cell><cell>0.83 ± 0.01</cell><cell>0.22 ± 0.04</cell><cell>0 ± 0</cell></row><row><cell>Alarm</cell><cell>2000</cell><cell>PCMB</cell><cell>1.00 ± 0.00</cell><cell>0.83 ± 0.02</cell><cell>0.14 ± 0.01</cell><cell>0 ± 0</cell></row><row><cell>Alarm</cell><cell>5000</cell><cell>IAMB</cell><cell>0.92 ± 0.02</cell><cell>0.86 ± 0.01</cell><cell>0.18 ± 0.02</cell><cell>0 ± 0</cell></row><row><cell>Alarm</cell><cell>5000</cell><cell>PCMB</cell><cell>1.00 ± 0.00</cell><cell>0.86 ± 0.02</cell><cell>0.11 ± 0.02</cell><cell>1 ± 0</cell></row><row><cell>Alarm</cell><cell>10,000</cell><cell>IAMB</cell><cell>0.92 ± 0.04</cell><cell>0.90 ± 0.01</cell><cell>0.14 ± 0.03</cell><cell>0 ± 0</cell></row><row><cell>Alarm</cell><cell>10,000</cell><cell>PCMB</cell><cell>1.00 ± 0.00</cell><cell>0.90 ± 0.02</cell><cell>0.08 ± 0.02</cell><cell>2 ± 0</cell></row><row><cell>Alarm</cell><cell>20,000</cell><cell>IAMB</cell><cell>0.94 ± 0.00</cell><cell>0.92 ± 0.00</cell><cell>0.10 ± 0.00</cell><cell>1 ± 0</cell></row><row><cell>Alarm</cell><cell>20,000</cell><cell>PCMB</cell><cell>1.00 ± 0.00</cell><cell>0.92 ± 0.00</cell><cell>0.05 ± 0.00</cell><cell>4 ± 0</cell></row><row><cell>Pigs</cell><cell>100</cell><cell>IAMB</cell><cell>0.82 ± 0.01</cell><cell>0.59 ± 0.01</cell><cell>0.48 ± 0.02</cell><cell>0 ± 0</cell></row><row><cell>Pigs</cell><cell>100</cell><cell>PCMB</cell><cell>0.83 ± 0.01</cell><cell>0.82 ± 0.02</cell><cell>0.29 ± 0.02</cell><cell>0 ± 0</cell></row><row><cell>Pigs</cell><cell>200</cell><cell>IAMB</cell><cell>0.80 ± 0.00</cell><cell>0.82 ± 0.00</cell><cell>0.37 ± 0.00</cell><cell>0 ± 0</cell></row><row><cell>Pigs</cell><cell>200</cell><cell>PCMB</cell><cell>0.97 ± 0.01</cell><cell>0.96 ± 0.01</cell><cell>0.07 ± 0.01</cell><cell>1 ± 0</cell></row><row><cell>Pigs</cell><cell>500</cell><cell>IAMB</cell><cell>0.82 ± 0.00</cell><cell>0.84 ± 0.00</cell><cell>0.34 ± 0.00</cell><cell>0 ± 0</cell></row><row><cell>Pigs</cell><cell>500</cell><cell>PCMB</cell><cell>0.98 ± 0.00</cell><cell>1.00 ± 0.00</cell><cell>0.02 ± 0.00</cell><cell>1 ± 0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7</head><label>7</label><figDesc>Results of the experiments with the Thrombin database</figDesc><table><row><cell>Algorithm</cell><cell>Features</cell><cell>Accuracy</cell><cell>Time</cell></row><row><cell>IAMB</cell><cell>6 ± 0</cell><cell>54 ± 0</cell><cell>2426 ± 72</cell></row><row><cell>PCMB</cell><cell>3 ± 1</cell><cell>63 ± 0</cell><cell>7302 ± 1012</cell></row><row><cell>No FSS</cell><cell>139,351</cell><cell>50</cell><cell>Not available</cell></row><row><cell>Winner of KDD Cup 2001</cell><cell>4</cell><cell>68</cell><cell>Not available</cell></row><row><cell>NB with the features in the winner of KDD Cup 2001</cell><cell>4</cell><cell>67</cell><cell>Not available</cell></row><row><cell>Taking into account the imbalance of the learning data</cell><cell>6</cell><cell>77</cell><cell>Not available</cell></row><row><cell>Taking into account the distribution of the testing data</cell><cell>15</cell><cell>83</cell><cell>Not available</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>1.2. The 114 runs of IAMB return 39 different MBs, all of them containing six features: 62 runs corresponding to 19 different MBs score 53% accuracy, and 52 runs corresponding to 20 different MBs score 54% accuracy. The 114 runs of KIAMB return 85 different MBs, containing from four to seven features. The left histogram in Fig. 2 summarizes the accuracy of the 114 runs of KIAMB, whereas the right histogram in the figure summarizes the accuracy of the 85 different MBs found in these runs. It is clear from the histograms that KIAMB is able to identify many MBs that outperform those found by IAMB. To be exact, 49 of the 114 runs of KIAMB corresponding to 38 different MBs score higher than 54% accuracy, which is the highest accuracy obtained by IAMB. Only 28 of the 114 participants in KDD Cup 2001 scored higher than 54% accuracy. Furthermore, 12 of the 114 runs of KIAMB corresponding to 10 different MBs score 69% accuracy, whereas the winner of KDD Cup 2001 scored 68% accuracy. Our 10 MBs scoring 69% accuracy contain six features. These are 3392, 63,916, 79,651, 135,817, 138,924 and, then, one of the following ones: 46,937, 48,386, 49,864, 51,230, 55,132, 63,853, 63,856, 73,697, 103,235 or 108,355. Regarding running time, IAMB takes 2426 ± 72 s per run and KIAMB 2408 ± 442. Therefore, our results confirm that KIAMB is scalable and that it can outperform IAMB considerably often.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>MBs score higher than 63% accuracy, which is the accuracy obtained by all the 114 runs of PCMB in Section 4.1.2. Only five of the 114 participants in KDD Cup 2001 scored higher than 63% accuracy. Finally, we report 114 runs of a stochastic version of PCMB, called KPCMB, in which the greedy heuristic at line 9 in GetPCD is modified to trade-off greediness and randomness through an input parameter K 2 [0, 1] in exactly the same way as IAMB was modified to develop KIAMB. We use K = 0.8 in the experiments. The left histogram in Fig.3summarizes the accuracy of the 114 runs of KPCMB, whereas the right histogram in the figure summarizes the accuracy of the 69 different MBs found in these runs. Surprisingly, none of the runs of KPCMB scores higher than the 63% accuracy of PCMB but 53 runs corresponding to 38 different MBs score lower than that. The reason of such poor performance lies in that KPCMB does not always return a MB of T, because there may exist some nodes not in the output of KPCMB that are dependent of T given the output. For instance, the worst run of KPCMB scores 26% accuracy and returns the features 3392, 79,651 and 135,817, but T 46,937j{3392, 79,651, 135,817}. However, neither these four features are a MB of T because T 63,916j{3392, 46,937, 79,651, 135,817}. Neither these five features are a MB of T because T 138,924 j{3392, 46,937, 63,916, 79,651, 135,817}. Now, these six features are a MB of T. Actually, they are one of the 10 MBs scoring 69% accuracy that are found by KIAMB.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>J.M. Pen ˜a et al. / Internat. J. Approx. Reason. 45 (2007) 211-232</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>J.M. Pen ˜a et al. / Internat. J. Approx. Reason. 45 (2007) 211-232</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the editors and anonymous referees for their comments. This work is funded by the Swedish Research Council (VR-621-2005-4202), the Swedish Foundation for Strategic Research, and Linko ¨ping University.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A novel Markov blanket algorithm for optimal variable selection</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Aliferis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tsamardinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Statnikov</surname></persName>
		</author>
		<author>
			<persName><surname>Hiton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 American Medical Informatics Association Annual Symposium</title>
		<meeting>the 2003 American Medical Informatics Association Annual Symposium</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="21" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hatzis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Krogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Morishita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sese</surname></persName>
		</author>
		<author>
			<persName><surname>Cup</surname></persName>
		</author>
		<ptr target="&lt;http://www.cs.wisc.edu/~dpage/kdd-cup" />
	</analytic>
	<monogr>
		<title level="j">Report. ACM SIGKDD Explorations</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2001">2001. 2002. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Finding optimal Bayesian networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Eighteenth Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="94" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pee ´r, Learning Bayesian network structure from massive datasets: the &apos;&apos;Sparse Candidate&apos;&apos; algorithm</title>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Nachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Fifteenth Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="206" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Scho ¨lkopf, Kernel methods for measuring independence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="2075" to="2129" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Kernel constrained covariance for dependence measurement</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Belitski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Augath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Murayama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pauls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Scho ¨lkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Logothetis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Workshop on Artificial Intelligence and Statistics</title>
		<meeting>the Tenth International Workshop on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Computer-based probabilistic-network construction</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Herskovits</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Blocking Gibbs sampling for inference in large and complex Bayesian networks with applications in genetics</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Jensen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>Aalborg University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Data mining using MLC++: a machine learning library in C++</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kohavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sommerfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dougherty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tools with Artificial Intelligence</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="234" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Bayesian network induction via local neighborhoods</title>
		<author>
			<persName><forename type="first">D</forename><surname>Margaritis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Neural Information Processing Systems</title>
		<meeting>Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="505" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Preventing &apos;&apos;Overfitting&apos;&apos; of cross-validation data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Conference on Machine Learning</title>
		<meeting>the Fourteenth International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="245" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<title level="m">Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</title>
		<imprint>
			<publisher>Morgan Kaufman</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Tegne ´r, Scalable, efficient and correct learning of Markov boundaries under the faithfulness assumption</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Pen ˜a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bjo ¨rkegren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth European Conference on Symbolic and Quantitative Approaches to Reasoning under Uncertainty</title>
		<title level="s">Lecture Notes in Artificial Intelligence</title>
		<meeting>the Eighth European Conference on Symbolic and Quantitative Approaches to Reasoning under Uncertainty</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3571</biblScope>
			<biblScope unit="page" from="136" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tegne ´r, Growing Bayesian network models of gene networks from seed genes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Pen ˜a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bjo ¨rkegren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="224" to="229" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An empirical Bayes approach to inferring large-scale gene association networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Scha ¨fer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Strimmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="754" to="764" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Statistical challenges in functional genomics (with discussion)</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sebastiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gussoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Kohane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ramoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="33" to="60" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<title level="m">Causation, Prediction, and Search</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Probabilistic Conditional Independence Structures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Studeny</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Algorithms for large scale Markov blanket discovery</title>
		<author>
			<persName><forename type="first">I</forename><surname>Tsamardinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Aliferis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Statnikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth International Florida Artificial Intelligence Research Society Conference</title>
		<meeting>the Sixteenth International Florida Artificial Intelligence Research Society Conference</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="376" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Time and sample efficient discovery of Markov blankets and direct causal relations</title>
		<author>
			<persName><forename type="first">I</forename><surname>Tsamardinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Aliferis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Statnikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="673" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Time and sample efficient discovery of Markov blankets and direct causal relations</title>
		<author>
			<persName><forename type="first">I</forename><surname>Tsamardinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Aliferis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Statnikov</surname></persName>
		</author>
		<idno>DSL TR-03-04</idno>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Vanderbilt University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The max-min hill-climbing Bayesian network structure learning algorithm</title>
		<author>
			<persName><forename type="first">I</forename><surname>Tsamardinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Aliferis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Scho ¨lkopf, Feature selection and transduction for prediction of molecular bioactivity for drug design</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pe ´rez-Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elisseeff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="764" to="771" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
