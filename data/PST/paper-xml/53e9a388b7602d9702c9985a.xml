<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Register Allocation for Software Pipelined Loops</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Rau</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Hewlett Packard Laboratories</orgName>
								<address>
									<addrLine>1501 Page Mill Road</addrLine>
									<postCode>94303</postCode>
									<settlement>Palo Alto</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">M</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Hewlett Packard Laboratories</orgName>
								<address>
									<addrLine>1501 Page Mill Road</addrLine>
									<postCode>94303</postCode>
									<settlement>Palo Alto</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>M. S. Schlansker</roleName><forename type="first">P</forename><forename type="middle">P</forename><surname>Tirumalai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Hewlett Packard Laboratories</orgName>
								<address>
									<addrLine>1501 Page Mill Road</addrLine>
									<postCode>94303</postCode>
									<settlement>Palo Alto</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Register Allocation for Software Pipelined Loops</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CEECB6C6E1854B60A639CAE6322D1986</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>register allocation</term>
					<term>modulo scheduling</term>
					<term>software pipelining</term>
					<term>instruction scheduling</term>
					<term>code generation</term>
					<term>instruction-level parallelism</term>
					<term>multiple operation issue</term>
					<term>VLIW processors</term>
					<term>Very Long Instruction Word processors</term>
					<term>superscalar processors</term>
					<term>pipelining</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Software pipelining is an important instruction scheduling technique for efficiently overlapping successive iterations of looPs and executing them in parallel. This parser studies the task of register allocation for-software pipeji;ed loops, both with and without hardware features that are specifically aimed at supporting software pipelines. Register allocation for software pipelines presents certain novel problems leading to unconventional solutions, especially in the presence of hardware support. 'II-&amp; paper formulates these novel problems and presents a number of alternative solution strategies. These alternatives are comprehensively tested against over one thousand loops to determine the best register allocation strategy, both with and without the hardware support for software pipelining.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>algorithms in which the loop is continuously unrolled and scheduled until a situation is reached which allows the schedule to wrap back on itself without draining the pipelines <ref type="bibr">[13]</ref>.</p><p>Although, to the best of our knowledge, there are no published measurementson this issue, it is our belief that the second class of software pipelining algorithms can cause unacceptably large code size, Consequently, our interest is in modulo scheduling. In general, this is an NP-complete problem and subsequent work has focused on various heuristic strategies for performing modulo scheduling <ref type="bibr">([9, 11, 12</ref>, 10] and the as yet unpublished heuristics in the Cydra 5 compiler <ref type="bibr">[6]</ref>). Modulo scheduling of loops with early exits is described by Tirumalai, et al. <ref type="bibr" target="#b1">[19]</ref>. Modulo scheduling is applicable to RISC, CISC, superscalar, superpipelined, and VLIW processors, and is useful whenever a processor implementation has parallelism either by having pipelined operations or by allowing multiple operations to be issued per cycle.</p><p>This paper describes methods for register allocation of modulo scheduled loops that were developed at Cydrome over the period 1984-1988, but which have not as yet been published. These techniques are applicable to VLIW processors such as the Cydra 5 <ref type="bibr" target="#b0">[18]</ref>. The processor model supports the initiation of multiple operations in a single cycle where each operation may have latency greater than one cycle. The use of hardware features, that specifically support the efficient execution of modulo scheduled loops, is assumed. These features include rotating register files (register files supporting compilermanaged hardware renaming, which were termed the MultiConncct in the Cydra 5), predicated execution, and the Iteration Control Register (ICR -a boolean register file that holds predicates) <ref type="bibr">[6,</ref><ref type="bibr" target="#b0">18]</ref>, This paper also considers register allocation of modulo scheduled loops on processors having no special support for modulo scheduling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our discussion</head><p>is limited to register allocation following modulo scheduling.</p><p>Register allocation prior to modulo scheduling places unacceptable constraints on the schedule and, therefore, results in poor performance. Concurrent scheduling and register allocation is preferable, but achieving this, in the context of modulo scheduling, is not understood. This paper does not attempt to describe a complete schedulingallocation strategy. For instance, little will be said on the important issue of what to do if the number of registers required by the register allocation exceeds the number available. Instead, the focus is on studying the relative performance of various allocation algorithms with respect to the number of registers that they end up using and their computational complexity.</p><p>In the rest of this section, we provide a brief overview of certain terms associated with modulo scheduling, descriptions of predicated execution and rotating register files, and of modulo scheduled code structure in the presence of this hardware support. We also examine the nature of the lifetimes that the register allocator must deal with for modulo scheduled loops. Section 2 discusses the various register allocation strategies and code schemas that can bc employed, anti the interdependencies between them. In the context of these alternatives, the register allocation problem is formulated in Section 3 and the candidate register allocation algorithms are laid out in Section 4. Section 5 describes the experiments performed and examines the data gathered from those experiments, finally, Section 6 states our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">A quick overview of modulo scheduling</head><p>A rotating register file is addressed by adding the register specifier in the instruction to tie contents of the Iteration Control Pointer (ICP) modulo the number of registers in the rotating register file. A special loop control operation, brtop, decrements the ICP amongst other actions. As a result of the brtop operation, a register that was previously specified as ri is specified as ri+l, and a different register now corresponds to the specifier ri. Lifetimes of a value generated by an operation in one iteration co-exist with the corresponding values generated in previous and subsequent iterations. Newly generated values are written to successive locations in the rotating register file and do not overwrite previously generated values even though exactly the same code is being executed repeatedly. This also introduces the need for the compiler to perform value tracking; the same value, each time it is used, may have to be referred to by a different register specifier depending on the number of brtop operations that lie between that use and the definition <ref type="bibr">[6]</ref>.</p><p>The Iteration Control Register file, ICR, is a rotating register file that stores boolean values called predicates. Predicated execution allows an operation to be conditionally executed based on the value of the predicate associated with it. For example, the operation a = Op(b,C) if pi executes if the predicate pi is one, and k nullified if pi k zero. The primary motivation for predicated execution k to achieve effective modulo scheduling of loops containing conditional branches <ref type="bibr">[6,</ref><ref type="bibr" target="#b0">18]</ref>. If-conversion</p><p>[1] may use predicates to eliminate all branches from the loop body. The resulting branch-free loop body can now be modulo scheduled. In the absence of predicated execution, other techniques must be used which require either multiple versions of code corresponding to the various combinations of branch conditions [7, 13] or restrictions on the extent of overlap between successive iterations <ref type="bibr">[11]</ref>. A secondary benefit of predicated execution, the one relevant to this study, is in controlling the filling and draining of the software pipeline in a highly compact form of modulo scheduled code known as kernel-only code.</p><p>The number of cycles between the initiation of successive iterations in a modulo schedule is termed the initiation interval (II). The schedule for an iteration can be divided into stages consisting of H cycles each. The number of stages in one iteration is termed the stage count (SC). If the schedule length is SL cycles, the number of stages is given by Figure <ref type="figure">1</ref> shows the record of execution of five iterations of the modtdo scheduled loop with a stage count of 4. The execution of the loop can be divided into three phases: ramp up, steady state, and ramp down. In Figure <ref type="figure">1</ref>, the first 3*II cycles, when not all stages of the software pipeline execute, constitute the ramp up phase. The steady state portion begins when the fourth and last stage of the first iteration coincides with the first stage of the fourth iteration. During the steady state phase, one iteration completes for every one that starts, The steady state phase ends when the first stage of the last iteration has completed at time 5*11. Thereafter, in the ramp down phase, one iteration completes every II cycles until the execution of the loop completes at time 8*11.</p><p>In generating code for a modulo schedule, one can take advantage of the fact that exactly the same pattern of operations is executed in each stage of the steady state portion of the modulo schedule's execution. This behavior is achieved by looping on a piece of code corresponding to one stage of the steady state portion of the record of execution. This code is termed the kernel. The record of execution leading up to the steady state is implemented with a piece of code called the prologue. The epilogue, implements the record of execution following the steady state.</p><p>In Figure <ref type="figure">1</ref>, the number of stages in the prologue and the epilogue are each equal to SC-1. In general, depending on whether or not hardware support is provided, the register allocation strategy employed and the nature of the loop, the number of stages in the prologue and epilogue can be more or less than SC-1, For DO-loops, with hardware support in the form of the rotating register file and predicated execution, it is not necessary to have explicit code for the prologue and the epilogue. Instead a single copy of the kernel is sufficient to execute the entire modulo scheduled loop. This is called kernel-on ly (KO) code. Consider the KO code depicted in Figure <ref type="figure">2a</ref>. All the operations from the same stage of the same iteration are logically grouped by attaching them to the same predicate. The KO code is repeatedly executed every II cycles. The predicates take on values as shown in Figure <ref type="figure">2b</ref>. Operations in a stage Si are executed when the corresponding predicate Pi is one. Five iterations each consisting of four stages are swept out diagonally in Figure <ref type="figure">2b</ref>. P. is the predicate pointed to by the ICP. This predicate is set to 1 by the brtop operation during the ramp up and steady state phases, and is set to O during the ramp down phase. Because brtop decrements the ICP, a different physical register P. is written into every II cycles. A detailed description of the operation of kernel-only code is provided in <ref type="bibr">[6,</ref><ref type="bibr">17]</ref>.</p><formula xml:id="formula_0">b 1 1 so ier2 probgue C&amp; S1 so ia 3 S2 .$1 se itr4 S3 S2 S1 km.] so ia5 W&amp; S3 S2 S1 so q 33 S2 S1 S3 S2 epiogue code S3 o n 2*U 3*U 4*I1 Wtt 6,1[ 7*U Figure 1. Software pipelined loop execution</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L.3 Lifetimes of values within loops</head><p>Each value produced in the loop has one producer and one or more consumers. The lifetime of a value starts when the producer is issued and ends when all of the consumers have finished. This definition of lifetime is required if the VLIW code is to be interruptible and re-startable with a hardware model in which operations, that have been issued, always go to completion before the interrupt is handled. Otherwise, the lifetime could start when the producer finishes and end when the last consumer begins.</p><p>Lifetimes correspond either to loop-invariant variables or to loop-variant variables. Loop-invariants are repeatedly used but never modified during loop execution. Loop-invariants, which are referenced in the loop, are assumed to have already been allocated in the (non-rotating) GPR file using conventional register allocation techniques. This is not the topic of this paper, A new value is generated in each iteration for a loop-variant and, consequently, there is a different lifetime corresponding to each iteration. Loop-variants can be further categorized based on whether or not the value defined in one iteration is used in a subsequent one, and on whether or not a value defined in one of the last few iterations is used after the loop, That a loopvariant is used by a subsequent iteration is equivalent to saying that each iteration uses a value defined by a previous iteration. In the case of the first few iterations, these previous iterations do not exist, and the expected vahres must be generated before the loop is entered and, therefore, are live-in to the loop. Likewise, if a vahre that is defined in one of the last few iterations is used after the loop, it will be live-out from the loop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Kernel Only Code</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P3 P2</head><p>PI Po o 0 0</p><formula xml:id="formula_1">1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 0 Predicae Wuea as controlledbybrtop so S1 so S2 S1 so 4 S3 S3 S1 so S3 S2 S1 so S3 S2 S1 S3 S2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3</head><p>Stages as enabkd by @kates (b)</p><p>Figure <ref type="figure">2</ref>. Kernel-only code  Recurrences always result in live-in loop-variants, and it is common for the last definition of a loop-variant to be live-out. Furthermore, compiler optimizations that eliminate loads snd/or stores can also result in live-in end live-out values. When a load from (store to) a particular memory location in one iteration is followed by a load from that same memory location in a subsequent iteration, the latter load is redunden~the value may be used directly from the register to (from) which it was loaded (stored). The first few iterations require that the appropriate registers be pre-loaded with the proper live-in values prior to loop en~y. Likewise, when multiple stores from separate iterations can be proven to access the same memory location, all the stores, except for the lest one, are redundant and can be eliminated. This assumes that that last store actually occurs. In the case of the last few iterations, the supposedly redundant store, that was supposed to be covered by a store in a subsequent iteration, is, in fact, not redundant since the iteration containing the covering store is not executed. The last value that should have been stored must be stored after exiting the loop and, so, must be live-out.</p><p>Such load-store optimization, of scalar as well as subscripted references, were performed by the Cydra 5 compiler [6, 14] and have also been studied by Callahan, et al. [3].</p><p>In the loop example in Figure <ref type="figure" target="#fig_1">3</ref>, load/store optimization has been done with respect to s (vr35). In the absence of this optimization, each loop iteration would have contained a load and a store ofs. The optimizer recognizes that only the load in the first iteration and the store in the last iteration are required, and that intermediate values can be held in registers. The initial load is moved out of the loop and is executed prior to loop entry establishing the value of s (vr35) for the first iteration. The initial value is, therefore, live-in to the loop. Subsequent iterations use the values generated one iteration earlier (vr35[l]).</p><p>Correspondingly, the store in the last iteration is moved out of the loop and is executed after loop exit. The value of s calculated in the last iteration is required by this store and, therefore, must be live-out.</p><p>After optimization and scheduling, the set of lifetimes corresponding to a single loop-variant is presented to the register allocator as a 4-tuple. Each 4-tuple is of the form (start, end, omega, alpha). The parameters start and end specify, respectively, the issue time of the producer of a v ahse and the latest completion time amongst all the operations that consume that value. Both start and end are expressed relative to the initiation time of the iteration containing the producer. Omega is one less than the highest numbered iteration that uses the value detlned by the fkst iteration, i.e., it is the number of iterations spanned by that value. It is also the number of live-in values for the loop-variant.</p><p>Alpha specifies the number (counting back) of iterations from the end of the loop in which the earliest live-out value was defined. It is also the number of live-out values for the loop variant. For instance, if alpha = 1, the only live-out value was defined in the last iteration; if alpha = 2, the values of the loop variant defined in the last two iterations are both live-out. Even if we want only the vahre from the second last iteration (and not that from the last iteration), we define alpha to be 2. The example in Figure <ref type="figure" target="#fig_1">3</ref> has five loop-variants which are shown in Figure <ref type="figure" target="#fig_3">4</ref>, The first and the fifth have an omega = 1 indicating that there is one live-in v ahte for each. The live-in value for loop-variant 1 is the initial value of s, and that for loop-variant 5 is the initial address of a(i), i.e., the address of a(1). These two values must be pre-loaded into the appropriate registers prior to loop entry. Loop-variant 1 also has an alpha = 1 indicating that the value computed in the last iteration is live-out . This is the final value of s which must be stored after loop exit.   in the next iteration is generated into physicaf register ri-l due to the decrementing of the ICP (even though the register specifier used is the same). If ri is O, ri-t will be the highest numbered register. As iterations are initiated every If cycles, the start times of these two lifetimes are II cycles apart. This gives rise to the wand portion (the dlagonaf band) of the set of lifetimes for a loop-variant as each iteration yields a lifetime which is lower by one register and to the right by II cycles from the lifetime in the previous iteration. The lifetime generated by the first iteration is shown in boldface. Live-in values, which are pre-loaded prior to loop entry, must remain in the registers until their lifetimes end. This adds a leading blade to the wand of recurring values which extends, on the left, all the way through cycle O. For example, the leading blade for loop-variant 1 occupies register 18 from cycle O to cycle 14. Note that the blade lifetime need not always be longer than tAe wand lifetime. For instance, the leadlng blade for loop-variant 5, which occupies register 13, is shorter than the lifetime for the first iteration, which is in register 12. This is because for this loop-variant start is less than II. As discussed, the lifetimes of live-out values, which are used after loop exit, must be extended until the loop completes. This adds a trailing blade to the wand of recurring values. For example, the trailing blade for loop-variant 1 occupies register 11 from cycles 85 through 89. The thicknesses of the leading and trailing blades depend on the values of omega and alpha, respectively. For example, if loop-variant 1 had omega = 2, the leading blade would include register 19 from cycles O through 12 as indicated by the asterisks in Figure <ref type="figure" target="#fig_4">5</ref>.</p><p>When the possibility for confusion is present, we shall refer to a single lifetime (single live range) as a scalar lifetime and to the set of lifetimes corresponding to a loop-vtwiant, across the entire execution of the loop, as a vector lifetime, The register allocation problem involves packing these vector lifetimes (wands with or without leading or trailing blades) as tightly as possible in the space-time plane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Code Generation Strategies</head><p>For our purposes here, three activities are involved in generating code for modulo scheduled loops: modulo scheduling, register allocation and determining the correct code schema to use. Register allocation is the topic of this paper. However, the manner in which this is done depends both on the presence or absence of rotating register files as well as the code schema used. Any code schema can be assembled from the following components [17], for each of which the corresponding notation is also listed:</p><p>. prologue code (P), .</p><p>kernel code (K), .</p><p>unrolled kernel code (Kn), .</p><p>epilogue code (E), q multiple-epilogue code (En), q a sequential, preconditioning loop (S). For instance, a specific code schema consisting of a prologue, an unrolled kernel, and multiple epilogues would be denoted by (PKnEn) whereas one with a preconditioning loop, a prologue, unrolled kernel, and epilogue would be denoted by (S PKnE). In the special case when the code schema consists of only the kernel or unrolled kernel code, we add the suffix O (KO, K"O). We have two schemes for handling the overlapping lifetimes for a loop-variant that are encountered in modulo scheduled code:</p><p>. static renaming via modulo variable expansion, (MVE), and q dynamic remapping via the use of rotating register files (DR), Lastly, we shall consider two styles of register allocation: q blades allocation, (BA), and .</p><p>wands-only allocation (WO).  All of these are elaborated upon below. The code schema, the renaming scheme end the style of register allocation cannot be selected independently. For instance, wands-only allocation precludes kernel-only code and vice versa, whereas blades allocation is compatible with both the kernel-on]y schema as well as the PKE schema. Modulo variable expansion always requires kernel unrolling. Furthermore, the choice of code schema is influenced and limited by the nature of the loop (DO-loop or WHILE-loop) and whether predicated execution or rotating register files or both are present <ref type="bibr">[17]</ref>. With hardware support in the form of rotating register files and predicated execution, it is not necessary to have explicit code for the prologue and the epilogue. Instead a single copy of the kernel is sufficient to execute the entire modulo scheduled loop. This is called kernel-only (KO) code (Figure <ref type="figure">2</ref>). Since the ramp up, steady state and ramp down phases of the loop execution are all effected with the same code, the kernel code, the register allocator for the kernel must take into account all the scalar lifetimes corresponding to a loop-variant, over the complete execution of the loop, l,e., the vector lifetimes, including the blades. It does so by spacing the vector lifetimes adequately far apart in the register file to ensure that no part of one vector lifelime overlaps arty part of artother (Figure <ref type="figure" target="#fig_4">5</ref>). We shall refer to this style of register allocation as blades allocation (BA). KO code is attractive in that it is very compact, but there is the possibility that the requisite BA style of allocation requires more registers due to the constraints imposed by the leading and trailing blades. Since, in general, each vector lifetime has a different shape to its blade, it might be expected that the quality of the packing of the vector lifetimes in the space-time plane will be relatively poor.</p><formula xml:id="formula_2">0000000000111111llll2222222222333333333344444444445555555555666666666677777777778888888888 01234567890123456789012345678901234567890123456789012345678901234567890123456789Ol23456789 I -----------------------------------------------------.------------------------------------</formula><formula xml:id="formula_3">I ---------------------------------------------- ----------------------- --------------------- 00000000001111111lll2222222222333333333344444444445555555555666666666677777777778888888888 01234567890123456789012345678901234567890123456789012345678901234567890123456789Ol23456789 time ---&gt;</formula><p>A second code generation strategy avoids this problem by peeling off an appropriate number of iterations of the kernel at the beginning and end of the loop to form a prologue and epilogue, respectively. The prologue is designed to be long enough that all the non-wand portions of the leading blades are in the prologue, and the epilogue is made long enough that all the non-wand portions of trailing blades are in the epilogue. The amount of prologtre peeling to ensure this is ~ps='n+'fw+ 1} over all loop-variants with omega &gt; 0. Similarly, the amount of epilogu: peeling ?eeded .to ensure that trailing blades need not be considered during register allocation is over all loop-variants with alpha &gt; 0. (Since the leng[h of Lhe prologues and epilogues are determined solely by the live-in and live-out values, and not by the requirement of achieving a steady-state schedule, this may not correspond to the SC-1 stages shown in Figure <ref type="figure">1</ref>). The corresponding style of register allocation is termed the wands-only (WO) style since blades can be ignored during register allocation for the kernel, The register allocator need only ensure that the wands do not overlap. Register allocation for the prologue and epilogue is done separately, honoring the constraints imposed by the allocation for the kernel. By construction, the prologue and epilogue are long enough to ensure that any conflict with a blade can only occur in the prologue or epilogue where the lifetimes can be re-allocated independently of the way in which the lifetimes for the same loop-variant were allocated in the kernel. However, now that the register assignments in the prologue and epilogue are different, multiple epilogues are needed to handle loop exits from the prologue. One epilogue can no longer serve in all cases since the register assignments are different. Note, also, that the amount of prologue and epilogue peeling given above is sufficient but not necessary to ensure that a register allocator which disregards leading and trailing blades will produce a correct allocation; an inspection of the register assignments after register allocation may reveal that less unpeeling is adequate based on the specific way in which the vector lifetimes have been packed. In this study, however, we treat the above formulae as if they are both necessary and sufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Code generation without hardware support</head><p>When no hardware support is available, modulo scheduling can be accomplished by modtrlo variable expansion (MVE), i.e., unrolling the kernel and renaming the multiple copies that now exist of each virtual register definition <ref type="bibr">[11]</ref>. The unrolling and renaming is required to prevent successive lifetimes, corresponding to the same loop-variant, from overwriting one another in the same register. Register allocation consists of packing the scalar lifetimes together compactly --a more traditional register allocation task, except that we would expect to see a much larger fraction of lifetimes live across the backedge than we would with a sequential loop. The minimum degree of unroll, K .~l~. is determined by the longest lifetime among the Ioop-varmnts. Because iterations are initiated every H cycles, Kmti can be calculated as:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>([ 1)</head><p>Kmin = MAX 'endil~tati) .</p><p>i By unrolling the kernel more than Kmin times, there is the possibility that fewer registers might be required in the modulo scheduled code, but at the cost of increasing the generated code size and the compile time of the allocation process. With MVE code, prologue and epilogue peeling of SC-1 stages are required to ramp up and ramp down the software pipeline. In addition to this requirement, live-in and live-out values also impose prologue and epilogue peeling constraints as explained for the WO strategy above. For the MVE renaming scheme, the number of stages of prologue and epilogue are given by PS = max{SC-1, LPS], and ES = max {SC-1, LES ], respectively.</p><p>As a result the blades may be ignored while performing register allocation for the kernel. We shall refer to this rezister allocation strategy as the MVE strategy. are required in addition to the prologue, epilogue and unrolled kernel. The software pipelined code can execute only certain integer numbers of iterations. Assume that PS stages are peeled away from the beginning of the loop, ES stages are peeled away from the end of the loop, the kernel is unrolled K times, and the schedule for an iteration has SC stages (Figure <ref type="figure">6</ref>). The code, as described above, can only execute PS+ES-SC+l +i*K iterations for i &gt; 1 if the only way of exiting the loop is at the end of the last stage of the unrolled kernel.</p><p>One code generation schema adds a sequential, non-modulo scheduled version of the loop known as the preconditioning code. The preconditioning code ensures that the pipelined part is entered with an appropriate trip count so that the loop will need to exit only after the last stage of the unrolled kernel. The loop counter, LC, is initialized with this trip count prior to entering the modulo scheduled loop and must be decremented by K each time through the unrolled kernel (every K*II cycles). The iteration of the kernel terminates when LC is O. Preconditioning does not work for WHILE-loops and loops with early exits where the trip count is not known prior to beginning the execution of the loop. Also, it decreases the performance of DO-loops because of the need to process residual iterations serially. This effect is particularly noticeable with short trip counts. Preconditioning can be avoided by placing a branch, which decrements and tests LC, in each stage of the prologue and kernel. The loop is, therefore, exited after the correct number of iterations. However, each of these exit points now requires distinct epilogue code to complete the iterations in progress at the time of exiting the software pipeline. This will result in some amount of increase in code size and code generation complexity. At the same time, it yields the highest performance code with the MVE strategy. In this paper, we shall study the code size of both code schemas for the MVE strategy.</p><p>A more detailed discussion of code schema for modulo scheduled loops is provided in <ref type="bibr">[17]</ref>. For the sake of brevity, we have limited our discussion to only a quarter of all the possibilities.</p><p>It should be noted that WHILE-loops can be handled in a very similar manner as long as certain additional details are addressed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Formulation of the register allocation problem</head><p>Informally, the register allocation task for modulo scheduled loops with hardware support consists of packing together the space-time shapes, that correspond to the vector lifetimes, so as to take up a minimum number of registers. An allocation is legal if, out of all the scalar lifetimes that make up all of the vector lifetimes, no two scalar lifetimes that over] ap in time are allocated to the same register. This bin packing trikes place on the surface of a cylinder with time corresponding to the axis and the registers corresponding to the circumference. So, tbe task is to pack the vector lifetimes together so thal they fit on the surface of a cylinder having the smallest possible circumference. In describing the allocation algorithms, wc shall need to refer to the linear ordering of registers, and it is important to bear in mind that if, for instance, we have 64 registers, it is equally correct to refer to the register below O as either -1 or as 63.</p><p>When discussing a vector lifetime, we shall use the lifetime produced by the first iteration of the loop as the point of reference. Thus, a vector lifetime has been allocated to physical register 7 if the defining operation in the first iteration writes its result to physical register 7. Iterations 2, 3, etc., would write their results to physical registers 6, 5. and so on. Note that, in this discussion, when we refer to registers, we refer to the the absolute addresses of registers which are different for each iteration. However, assuming the presence of the kind of register renaming that is provided by the rotating register file, the register svecifier in the instruction would be invariant. Also, ~e start ~nd finish times of a vector lifetime refer to those of the scalar lifetime corresponding to the first iteration.</p><p>As another point of terminology, when we say that one vector lifetime is allocated "above" another one, we mean that the wand of the first lifetime lies above (and to the right) of the wand for the second lifetime in the space-time diagram (see Figure <ref type="figure" target="#fig_4">5</ref>). Note that this does not mean that the first lifetime is allocated to a higher location than is the second. If the start time for the frst lifetime is sufficiently later than the start time for the second, then it can be allocated to a lower location even though it is "above" the second lifetime in the space-time diagram. For scalar lifetimes, "above" and "higher location" are synonymous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The register allocation constraint</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Allocation constraints</head><p>for modulo scheduled loops can be abstracted in order to simplify the formulation of the problem and the implementation of the allocation algorithms. Given four parameters for each vector lifetime (start, end, omega, alpha), we construct the matrix, DIST, which has one row and one column for each vector lifetime. Each off-diagonal element specifies the minimum distance (in registers) allowable between a pair of lifetimes when they are allocated in the rotating register file. In Figure <ref type="figure" target="#fig_7">7</ref>, vector lifetimes A and B for a schedule with II = 3 are shown in a space-time diagram. (Two possible allocations for B are shown in Figure <ref type="figure" target="#fig_7">7</ref>, labelled B( and B".) A loop Wilh five iterations is shown. Lifetime A has: (start = 8, end = 13, omega = 1, alpha = 1). Lifetime B has: (start = O, end = 3, omega= O, alpha= O). The shapes of the lifetimes A and B are compl ctel y specified by these four parameters. Whereas lifetime R is a wand, i.e., a simple diagonal shape, lifetime A is not, and must carry a value live-in and live-out due to the value of the parameters: omega = 1 and alpha = 1. Assume that lifetime A has been allocated to some register in the rotating register file. Lifetime B can be allocated adjacent to A either "below" A (B() or "above" A (B" ) in Figure <ref type="figure" target="#fig_7">7</ref>. When lifetime Et[ is moved as high as is possible without interfering with the scalar lifetime that constitutes the leading blade of A, it ends up being allocated to the same register as A. (Recall that a vector lifetime is said to be allocated to the register to which the scalar lifetime corresponding to the first iteration is allocated). Therefore, DISTIB,A] has the value O. Similarly, when lifetime B" is moved to the lowest position possible, it ends up being allocated 5 registers higher than A. Therefore, DISTIA,B] has the value 5. All off-diagonal elements of the DIST matrix are defined likewise. In this example, the distance bctwemr A and B( was limited by the interference between the leading blade of A and the wand of B(, and the distance between A and B" was Iimitcd by the interference between the wand of A and the wand of BU , In general, there are three different possible interferences, any one of which can limit the minimum distance between two blades:</p><p>1. the interference between the two wands, 2.</p><p>the interference between the leading blade of the upper vector lifetime and either the leading blade or the wand of the lower lifetime and,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>the interference between the trailing blade of the lower lifetime and either the wand or the trailing blade of the upper lifetime.</p><p>with vector or scalar lifetimes and depending on the register allocation algorithm being used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">A lower bound on the number of registers</head><p>A tight lower bound on the number of registers needed for a modulo scheduled loop is useful in assessing the success of the register allocation.</p><p>A simple, yet surprisingly tight, lower bound is obtained by calculating the total number of scalar lifetimes that are live during each cycle and taking the maximum of these totals. Clearly, at least this many registers are needed under all circumstances.</p><p>This maximum is commtted Accordingly, for vector lifetimes, DISTIA,B] is computed using over the entire length of the (possibly unrolled) kernel' after the following formulae:</p><p>scheduling. In view of the repetitive pattern of lifetimes in an unrolled kernel. the number of scalar lifetimes that are</p><formula xml:id="formula_4">dl = d2 = 1 end(A)-strrrt(B ) II 1 { dl, if omega(B ) = O max(dt, omega(A)), otherwise d3 = [ d2, if alpha(A) = O max(d2, alpha(A)), otherwise</formula><p>For WO, DISTIA,B] = dl. For BA, DISTIA,B] = d3.</p><p>The DIST matrix for scalar lifetimes. with the MVE stratezv. is The register allocation problem is to pack the lifetimes, whether vector or scalar, on the surface of a cylinder with the minimum circumference while honoring the minimum distance requirements, as specified by the DIST matrix, between every pair of lifetimes. The appropriate definition of the DIST matrix is used depending on whether the register allocator is working simultaneously "live need only be computed for any II consecutive cycles of the kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Register Allocation Algorithms</head><p>The nature of the overall register allocation process is described in Figure <ref type="figure" target="#fig_9">8</ref>. The set of lifetimes to be allocated are presented to the register allocator in some arbitrary order by the compiler. Onc can choose either to retain that order or to put it into a better order which improves the quality of the allocation achieved by a one-pass allocation algorithm. The choice of ordering heuristic is controlled by the variable Ordering Algorithm. Zero, one or multiple heuristics may be selected simultaneously.</p><p>The allocation process consists of repeatedly selecting an as yet unallocated lifetime, in the order imposed by the ordering heuristics, and allocating it. The choice of register location into which this lifetime is allocated is determined by the allocation algorithm. The variable that controls this is AllocationAlgorithm.</p><p>In this study, we only consider one-pass register allocation algorithms, i.e., algorithms in which each lifetime is allocated exactly once with no backtracking or iteration.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Register allocation algorithms</head><p>The best fit algorithm (Figure <ref type="figure">9</ref>) is an attempt to come up with the best allocation possible without an exhaustive search, backtracking or iteration, i.e., once a lifetime is allocated to a particular register, it stays allocated to that same register. As with all the allocation algorithms considered here, the lifetimes are allocated one by one in the order prescribed by the conjunction of the selected sorting heuristics (see below). Initially, allocation is performed on an infinite plane (unbounded registers). With best fit, every location is examined starting with the highest, permissible location that is "below" all the previously allocated lifetimes up through the 10west, permissible location that is "above" all of the previously allocated lifetimes. It is possible to allocate the current lifetime in between a pair of previously allocated lifetimes. For each candidate location to which it is possible to allocate the lifetime, the minimum number of registers needed to permit this allocation is computed. This is done by wrapping the infinite plane into a cylinder of minimum circumference, i.e., minimum number of registers, while respecting the minimum distance requirements between every pair of lifetimes. The location thst is finally selected is the one that minimizes the number of registers needed. Ties are broken using an additional heuristic, FOM. Each time a lifetime is allocated, some number of locations are made unavailable to the as yet unallocated lifetimes because of conflicts with the lifetime just allocated.</p><p>Figure <ref type="figure">12</ref>. The adjacency ordering algorithm However, in general, some subset of these were already unavailable due to the previously allocated lifetimes, The figure-of-merit, FOM, is inversely proportional to the number of additional locations that are made unavailable if SelectedLT is allocated to TrialLocation.</p><p>The first fit algoridun (Figure <ref type="figure">10</ref>) proceeds in a similar fashion except that it always begins its search at location O and terminates as soon as a location is found to which the lifetime can be allocated.</p><p>The end fit algorithm (Figure <ref type="figure">11</ref>) is intended to be used primarily with the adjacency ordering heuristic (see below), with each lifetime being allocated, "above" the last lifetime allocated, to the lowest possible location. Consequently, the search for a location starts with the lowest location such that the current lifetime is both above the previously allocated lifetime and does not cause a conflict with it. This location is specified by the DIST matrix. The search ends at the fust legal location that is encountered, i.e., one which has no conflict with any of the previously allocated lifetimes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Lifetime ordering heuristics</head><p>Three ordering heuristics are considered here: start-time ordering, adjacency ordering and conflict ordering. Start-time ordering is motivated primarily by the scalar lifetime case. For a single, non-loop basic block, every lifetime consists of a single in terv al. In this case, it can be shown that allocating seal ar lifetimes in increasing order of start time, to the lowest available register, yields an optimal allocation. (A sketch of the proof of this theorem is provided in <ref type="bibr">[16]</ref>.) This procedure is not necessarily optimal for a loop, especially a modulo scheduled one, in which lifetimes extend across the back-edge of the loop yielding discontinuous lifetimes, i.e., live at the beginning and end of the loop body but not in between. It can, however, be shown that an upper bound on the number of registers needed is L+M, where L and M are the maximum and minimum number of lifetimes, respectively, that are live simultaneously <ref type="bibr">[8]</ref>. In any event, ordering by start time was viewed as a potcntiall y successful heuristic to use even in thk situation and, in fac~was used as the secondary ordering heuristic for vector lifetime allocation in the Cydra 5 compiler.</p><p>The primary ordering heuristic in the Cydra 5 compiler was what we shall term adjacency ordering, This greedy heuristic was used in conjunction with the end fit allocation algorihn. At each step, that lifetime is selected which minimizes the horizontal distance, in the space-time diagram (Figure <ref type="figure" target="#fig_4">5</ref>), between the lifetime that was allocated last and the one just selected. Bearing in mind that the horizontal dimension is time, we see that this heuristic attempts to minimize the amount of time that any given register is idle. The adjacency ordering algorithm (Figure <ref type="figure">12</ref>) is quite straightforward for vector lifetimes. Lifetime 1 is selected first. Thereafter, the lifetime, B, that is seIected at each step is the one for which</p><formula xml:id="formula_5">(start[B] -end[A]) + DISTIA,B]*II</formula><p>is minimum, where A is the lifetime that was previously selected. Note that (start[B] -end[A]) is the horizontal distance in the space-time diagram if A and B were allocated to the same register. DISTIA,B]*II is the additional gap given that B must be allocated to a register that is at least DISTIA,B] higher than the one to which A has been allocated. This heuristic is quite similar to the one used with the Traveling Salesman Problem and, in fact, in the WO case, register allocation can be formulated as a Traveling Salesman Problem.</p><p>For scalar lifetimes, too, an attempt is made to minimize the time that a register is idle. In fact, the adjacency ordering algorithm essentially performs a quick-and-dirty allocation. AL any point in time, CurrentSet is the set of lifetimes that are tentatively allocated to the same register--the same row in the space-timediagram. This heuristic keeps appending lifetimes to the right-hand side of the row, always selecting at each step the lifetime that minimizes the gap between the end of the previous lifetime and the selected lifetime. When it is impossible to add an additional lifetime without conflicting with one of the lifetimes in that row (taking into account the wrap-around of the lifetime at K*II), a new row is started. In the context of the taxonomy that we have defined, the Cydra 5 compiler generates kernel-only code and performs blades allocation using the end fit allocation algorithm along with adjacency (primary) and start-time (secondary ) ordering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Computational Complexity</head><p>The worst-case computational complexity for register allocation depends upon the specific combination of ordering heuristics and allocation algorithm that is employed. From an inspection of the algorithms (Figures <ref type="figure" target="#fig_9">8</ref><ref type="figure">9</ref><ref type="figure">10</ref><ref type="figure">11</ref><ref type="figure">12</ref><ref type="figure" target="#fig_1">13</ref>) one can see that the worst-case complexity of the three ordering heuristics and the three register allocation algorithms is:</p><formula xml:id="formula_6">start time O(n2) conflict O(n2) adjacency O(n2) best fit max(O(n2), 0(n2r)) first fit max(O(n2), O(nr)) end flt max(0(n2), O(n))</formula><p>where n is the number of lifetimes (either scalar or vector) to be allocated and r is the number of registers required to do so. (Note that for the MVE strategy, the number of lifclimcs will be Kmin times greater than for the other strategies.) Empirically, we found that r was a linear function of n (approximately 0.61* n+14.5) over the range of values of n for which there was statistical significance, So, effectively, best fit, first tit and end fit are 0(n3), 0(n2) and 0(n2), respectively. Since the ordering heuristics are 0(n2), it is the selected allocation algorithm that dominates the complexity of the register allocation phase. Note that in the conflict ordering algorithm, updating RemainingTotalConflictfi] for all j that are still in NotSetAside is an O(n) operation.</p><p>When multiple ordering heuristics are used together, the lowest priority ordering is performed first, and the highest priority one last. It is necessary, therefore, that each sorting algorid~rn have the property that it maintains the relative ordering of all lifetimes that are equal under the sorting criterion that is currently being applied. Consequently, a simplistic sort of 0(n2) complexity was used for start-time ordering instead of using heapsort which is O(n log n). The complexity expressions for the allocation algorithms contain two terms, the greater one of which determines the complexity. The 0 (n2) term is caused by having to update the disallowed locations for each as yet unallocated lifetime each time a lifetime is allocated (Figure <ref type="figure" target="#fig_9">8</ref>). The updating process is O(n) in complexity, and it is invoked n times. The other term is dependent on the allocation algorithm selected. In understanding these, one should note that each of the procedures in Figures 9-11 are invoked O(n) times and that the loops in Figures 9 and 10 are executed O(r) times on each invocation. Lastly, the function FOM that is called from within the loop in the best fit algorithm is itself O(n) in complexity.</p><p>The worst-case complexity is generally quite pessimistic compared to what is actually experienced because in many cases, the iterations of the loops are guarded by IF-statements that are often not executed. So, we also have measured the empirical computational complexity for each combination. This is presented in Section 5. Counters were placed at the entry point as well as in every innermost loop of every relevant procedure. These counters count the total number of times that that point in the program is visited. In the spirit of worst-case complexity analysis, we used the largest of the counts as the indicator of empirical computational complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head><p>Measurements were taken to examine the effectiveness of the allocation algorithms described in the previous section. To this end, over one thousand FORTRAN DO-loops from the SPEC! <ref type="bibr" target="#b2">[20]</ref> and PERFECT Club [2] benchmark suites were modulo scheduled on a hypothetical machine similar to the Cydra 5 <ref type="bibr" target="#b0">[18]</ref>. Only measurements on DO-loops were performed, even though all the register allocation algorithms discussed are fully applicable to WHILE-loops and loops with early exits. This is due to the limitation of the Cydra 5 compiler which was used to generate the input to the register allocator and which is unable to recognize loops which are not DO-loops. Also, only those DO-loops with no conditional branching were selected so as to permit a meaningful comparison between MVE (which assumes no predicated execution) and the other two allocation strategies. Apart from the relative code sizes for the three allocation strategies, we do not expect any of the conclusions regarding the relative merits of the various allocation algorithms and ordering heuristics to be different across the broader set of loops. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I</head><p>The relevant details of this hypothetical machine are shown in Table <ref type="table" target="#tab_0">3</ref>. The machine model permits the issue of up to seven operations pcr cycle. All the functional unit pipelines read their inputs and write their results to a common rotating register file. The 13 cycle load latency reflects an access that bypasses the first-level cache. (Our experience has been that locality of reference is often missing within imermost loops. Until compiler algorithms are devised which reliably ascertain whether or not a sequence of references in a loop has locality, it is preferably to have the deterministic albeit longer latency that comes from consistently bypassing the first-level cache.) The Cydra 5 compiler was used to generate a modulo schedule for each loop and then output a set of lifetime descriptions for all the loop-variants. The lifetime descriptions were used as input to a program that applied all combinations of ordering heuristics and allocation algorithms to each input set in turn. The register allocation program outputs various data for each input data set and for each combination of algorithms and heuristics. The data include the number of registers needed by the loop-variants, a lower bound on the number required, the code size, and the empirical computational complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The characteristics</head><p>of the loops that were analyzed in our experiment are shown in Figure <ref type="figure" target="#fig_10">14</ref>. Each graph is a cumulative distribution. From Figure <ref type="figure" target="#fig_10">14</ref> it can be seen that most loops in our sample set had fewer than 80 loop-v ari ants, although there were a few that had more than 200. In contrast, most loops had fewer than 10 loop-invariants with a few having more than 30. Every loop had at least one live-in variable, most having ICSS than 15, and a few having over 30. Live-out variables were less frequent; not shown in Figure <ref type="figure" target="#fig_10">14</ref> is that 807. had no live-out variables and, of the remaining, about half had one live-oul and the rest had two live-outs. The graph for the initiation interval indicates that most loops had an II less than 40 cycles. Nearly 60% of the loops had an II less than 8 cycles. Schedule lengths we generally less than 90 cycles, but a few loops had schedules several hundred cycles long. The number of slagcs in the software pipeline was 10 or less 90% of the time.</p><p>Tables 4-6 contains data on the various heuristics and strategies. All combinations were studied. For each combination .</p><p>Table <ref type="table" target="#tab_6">4</ref> shows the optimality, i.e., the average of the difference between the achieved number of registers and the lower bound, .</p><p>Table <ref type="table">5</ref> shows the average measured empirical computational complexity relative to the lowest average empirical computational complexity across all combinations (that for WO with end fit), and .</p><p>Table <ref type="table" target="#tab_7">6</ref> shows the average code size in operations. For MVE, two code sizes are shown: with multiple epilogues and with preconditioning.</p><p>(In the context of VLIW machmes, a distinction needs to be made between an operation and an instruction. An instruction consists of multiple operations, whereas an opcratirm is a unit of computation equivalent to a RISC instruction. The code size is proportional to the number of operations for both VLIW and RISC processors.) Difference between achieved and lower bounf For the MVE strategy, fewest excess registers were used on the average by best fit allocation, using conflict ordering in conjunction with one or both of start-time and adjacency ordering. If first fit allocation were to be employed instead of best fit, but using the same ordering heuristics, marginally poorer allocation is obtained (&lt; 5% worse) but with almost a halving of the empirical computational complexity. The WO strategy achieves near-optimal results when it uses adjacency and start-time heuristics (with or without the use of the conflict heuristic) and regardless of which allocation algorithm is used. For the BA strategy, best results were obtained wilh besl fit allocation using adjacency, start-time and conflict ordering. This only had slightly higher empirical computational complexity (by lYo) than f~st fit or end fit.</p><p>Figure <ref type="figure" target="#fig_11">15a</ref> shows the cumulative distribution of the difference between the actual number of registers used and the lower bound, i.e., the extent of the deviation from the lower bound. It should be noted that the deviation from optimality may be less since even the optimal allocation may require more registers than the lower bound. A separate plot is shown for each of the nine combinations of allocation strategy and allocation algorithm. In each case, the results corresponding to the best combination of ordering heuristics were selected. The three plots for WO are indistinguishable.</p><p>Over 90% of the loops yield optimal allocation, and almost all of the rest require only one register over the lower bound. BA with best fit is almost as good, 80'%0of the loops are optimal, another 15% require an additional register, and very few need more than two registers over the lower bound. First fit and end fit for BA are very similar to each other, and significantly different from best fit. Especially interesting is the "plateau" between 1 and 10 registers; over 80% of the loops need at most one additional register, and almost 1090 require 11 additional registers, with the rest of the loops requiring some intermediate number of registers.</p><p>This suggests an interesting, hybrid allocation algorithm in which one first attempts first fit allocation and then, if too many additional registers end up being required, performs best fit allocation. For MVE, best fit and first fit are almost indistinguishable.</p><p>L$O'%0 of the loops are optimal, and rarely are more than 6 additional registers required. End fit for MVE is significantly worse.</p><p>h the average, all three strategies, when they employ the best combination of allocation algorithm and ordering heuristics, are able to achieve extremely good register allocation; On the average, WO is near-optimal, BA requires 0.24 reg istcrs more than the lower bound, and MVE requires 1.3 registers over the lower bound. The differences lie in their empirical complexity and the resulting code size. If preconditioned code is used with MVE, the factor drops to 7.8 (but at the cost of reduced performance, especially for small trip counts). It must be noted, however, that these results correspond only to the modulo scheduled innermost loops. The relative code size and compilation time increases for the complete program would be less depending on what fraction of the code consists of innermost loops. Furthermore, the increase in the static code size is relatively unimportan~what matters is the effect of code size on instruction cache performance. The extent to which this is a problem requires further study.</p><p>For each combination of allocation strategy and allocation algorithm, Table <ref type="table" target="#tab_8">7</ref> lists the set of preferred ordering heuristics. The combination of ordering heuristics selected is the one that yields the best register allocation, on the average. When different combinations of heuristics yield results that are very close in terms of optimality, the least expensive combination, computationally, is selected as the preferred one. In comparing the best fit and first fit algorithms for MVE, one sees that the two are very close in terms of optimality (a difference of 0.06 registers on the average) but that first fit has about half the empirical complexity of best fit. Consequently, in Table <ref type="table" target="#tab_8">7</ref>, first fit is underlined to indicate that it is preferred over best fit. With WO, all three allocation algorithms are equally optimal. So, we prefer end fit since it is the least expensive. With BA, best fit is significantly better than the other two for verv little added complexity.</p><p>Accordingly, best fit is the pr~ferred allocation algorithm for BA. Comparing the WO and BA strategies (Tables <ref type="table" target="#tab_6">4</ref><ref type="table">5</ref><ref type="table" target="#tab_7">6</ref>), it cart be seen that the number of registers used and the measured computational complexity are not very different, but the average code size for strategy WO is 2.3 times larger. If one is concerned about instruction cache performance, it may be preferable to use BA register allocation, and generate KO code. This also allows one to avoid the complexities involved with WO in generating the correct code schema for PKEn code <ref type="bibr">[17]</ref>. The performance degradation of BA relative to WO is limited to the lost opportunity in percolating outer loop computation into the prologue and epilogue. (In both cases, it is assumed that hardware support is available in the form of the rotating register file and predicated execution.) With the MVE strategy, degrees of unroll greater than G,. were attempted. Larger degrees of unroll resulted in higher empirical computational complexity and code size, and provided little to no reduction in the number of registers used. For over 80~0 of the loops, unrolling by more than Kmin saved at most one register. Very few cases were found where the savings were more than three registers.</p><p>Furthermore, the number of registers needed does not decrease monotonically as the degree of unroll is increased.</p><p>Additional unrolling beyond Kmin is not worthwhile.</p><p>Figure <ref type="figure" target="#fig_11">15b-d</ref> show the cumulative distributions for the number of registers used, the code size and the empirical computational complexity for the preferred allocation algorithm and orderin J heuristics for each strategy. For the machine model used, 980 of the loops required less than 64 registers for loop-variants, and less than 12 registers for loop-invariants.</p><p>The difference between the strategies is hardly noticeable in Figure <ref type="figure" target="#fig_11">15b</ref>, but the MVE strategy performs slightly worse than the other two. Figure <ref type="figure" target="#fig_11">15c</ref> and Figure <ref type="figure" target="#fig_11">15d</ref> show the cumulative distributions of the code size and empirical computational complexity, respectively. The relative ordering of MVE, WO and BA is the same for the variance and maximum of the code size distribution as it is for the mean: MVE is larger than WO which is larger than BA. The same is true for the empirical computational complexity; the mean, variance and maximum for MVE are all greater than the corresponding values for BA which, in turn, are marginally greater than those for WO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>When hardware support is present, in the form of predicated execution and the rotating register file, the kernel-only, b] ades allocation strategy is to be preferred over the wands-only strategy requiring prologue-kernel-epilogue code. It results in about 55q0 less code size, and with insignificant increases in the average number of registers used or in the empirical computational complexity. The best combination of heuristics to use with best fit allocation is adjacency and start-time ordering heuristics.</p><p>The absence of hardware support for modulo scheduling necessitates prologue and epilogue code, kernel unrolling, modulo variable expansion, and either a sequential preconditioning loop or multiple epilogues. Our experimental data indicate that first fit allocation with conflict ordering is the best choice. Unrolling the kernel more than the minimum number of times necess sry does not significantly reduce the number of registers required; instead it increases both the empirical computational complexity and the average code size. Our recommendation would be to employ the minimum degree of unroll.</p><p>The measurements of computational complexity and average code size lend some weight to arguments in favor of hardware support for modulo scheduling, in the form of the rotating register file and predicated execution. Without it, the increased empirical computational complexity (by a factor of 3 to 6) results in longer compile times. The increased average code size (by a factor of 7 to 14) can have a negative effect on the instruction hit rate in cache and, hence, on performance. The sequential execution of the residual iterations in preconditioned code can further degrade performance for realistic trip counts.</p><p>In this paper, we have studied the optimality of various allocation algorithms and heuristics, This serves as a useful guide in selecting the best algorithm for each situation with an objective to minimizing the number of registers needed. A different objective, and one that is equally important, is the issue of how one performs register allocation so as to make do with the number of registers that are available. The best algorithm from the first viewpoint is best from the second viewpoint, too. However, once modulo scheduling has been performed, if the register allocator fails to find a solution requiring no more registers than are available, some additional action must be taken. The options include one of the following actions:</p><p>. increasing the 11, q introducing spill code, or q splitting the loop into smaller loops followed by another modulo scheduling and register allocation pass. The issues and the difficulties in so doing are elaborated upon in <ref type="bibr">[16]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>pipelining Software pipelining [5] is a loop scheduling technique which yields highly optimized loop schedules. Algorithms for achieving software pipelining fall into two broad classes: modulo scheduling as formulated by Rau and Glaeser " [15] and, .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Mor.lulo scheduled loop example</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>--vr33 (addr of a(i))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Loop-variant lifetimes for the program in Figure 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5</head><label>5</label><figDesc>Figure 5 shows a space-time diagram generated by the register allocator for the 35 iterations of the example in Figure 3. The horizontal axis represents time in clock cycles advancing from the far left (cycle O) to the far right (cycle 89). The vertical axis denotes physical register space. The number of rows in the chart indicatesthe number of registers used in the achieved allocation. Once a value is generated into a physical register ri, it occupies that register until the lifetime ends. The same loopvariant produced in the next iteration is generated into physicaf register ri-l due to the decrementing of the ICP (even</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Space-time register allocation chart</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>(</head><label></label><figDesc>*1OOP precondition code*/ #bile ((N&lt;(PS+K+ES-SC+l)) or ((N-PS-ES+SC-1) mod K # O)) N = N-1 sequential loop body (stages A,B,C,D) ?nd while /*MVE software pipeline code*/ lC = N-1 if lC 2 0 then do WE modulo scheduled code and do MVE sot</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Distance matrix calculation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>much simpler. If two scalar lifetimes X and Y are hve simultaneously, then DISTIX,Y] = DISTIY,X] = 1. Otherwise, DISTIX,Y] = DISTIY,X] = O.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Overview of the register allocation algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 14 .</head><label>14</label><figDesc>Figure 14. Cumulative distribution functions for key statistics of the input loops</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 15 .</head><label>15</label><figDesc>Figure 15. Cumulative distribution functions for (a) the degree of optimality (b) the number of registers used (c) the code size for tie loop (d) the empirical computational complexity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>. The schedule has an</cell></row><row><cell>initiation interval, II, of 2 cycles. The issue time for each</cell></row><row><cell>operation is indicated in the left hand column. A single</cell></row><row><cell>iteration completes in 21 cycles. In the loop shown in Figure 3,</cell></row><row><cell>virtual register vr32, which is used in the address add</cell></row><row><cell>(operation 0P5), is a loop-invariant. It is allocated to the GPR</cell></row><row><cell>file end has the value 4 written into it prior to entering the</cell></row><row><cell>loop. The lifetime corresponding to a loop-invariant such as vr32 extenda through all iterations of the loop. Virtual register</cell></row><row><cell>vr37 is a loop-variant. It represents a new value of a(i)</cell></row><row><cell>computed in each iteration of the loop. This value is produced</cell></row><row><cell>by operation 0P3 and has only one consumer, operation 0P4,</cell></row><row><cell>which belongs to the same iteration. Virtual register vr35 is also</cell></row><row><cell>a loop-variant. It is produced by operation OP1 and represents</cell></row><row><cell>a new vahte ofs computed in each iteration. This value has two</cell></row><row><cell>consumers, operations 0P2 and OP1. Operation 0P2 uses the vahte produced in the same iteration whereas operation OP1</cell></row><row><cell>uses the value produced one iteration earlier, indicated by the</cell></row><row><cell>"[l]" after the vr35 operand. For loop variants like vr35 and vr37, there is a different lifetime corresponding to each</cell></row><row><cell>iteration.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Selected combinations of code schema / renaming scheme / register allocation style.</figDesc><table><row><cell></cell><cell></cell><cell>.</cell><cell>PKEn/DR/WO, and</cell></row><row><cell></cell><cell></cell><cell>.</cell><cell>PKnEn/MVE/WO or SPKnE/MVE/WO.</cell></row><row><cell></cell><cell></cell><cell cols="2">When there is no risk of confusion, we shall abbreviate and refer</cell></row><row><cell></cell><cell></cell><cell cols="2">to the first two strategies</cell><cell>as the BA and WO strategies,</cell></row><row><cell></cell><cell></cell><cell cols="2">respectively,</cell><cell>and to both variations</cell><cell>of the third one,</cell></row><row><cell></cell><cell></cell><cell cols="2">collectively, tts the MVE strategy,</cell></row><row><cell></cell><cell></cell><cell cols="2">2.1 Code generation with hardware support</cell></row><row><cell>HardwareFeatures</cell><cell>I Registerallocationstratep,yForDO-loops</cell><cell></cell></row><row><cell>None</cell><cell>I PKnEn / MVE / WO</cell><cell>I</cell></row><row><cell></cell><cell>SPKnEI MVE+WO</cell><cell></cell></row><row><cell>Predicated executinn</cell><cell>PKEnI DR I WO</cell><cell></cell></row><row><cell>and rotating register fdes</cell><cell>PKEIDRIBA</cell><cell></cell></row><row><cell></cell><cell>KO/DR/BA</cell><cell></cell></row><row><cell cols="3">A register allocation strategy is a specific combinationof the</cell></row><row><cell cols="3">register allocation style, renaming scheme and code schema. In</cell></row></table><note><p><p><p>thh paper, we shall only discuss in detail DO-loops with either no hardware support or with both predicated execution and rotating register files. Table</p>1</p>lists the legal register allocation strategies under these circumstances. We shall examine three of these irt detail: q KO/DR/BA,</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .</head><label>2</label><figDesc>Prioritization of ordering heuristics when used in conjunction with one another. The order in which the heuristics are listed is primary heuristic firs~then secondary heuristic etc.</figDesc><table><row><cell>Allocation</cell><cell>Allocation</cell><cell>Priorily of Ordering</cell></row><row><cell>Strategy</cell><cell>Algorithm</cell><cell>IIusrisIics</cell></row><row><cell>MvE</cell><cell>Best F1t</cell><cell>contlict, start</cell></row><row><cell></cell><cell>FirstFb</cell><cell>start, adjacency</cell></row><row><cell></cell><cell></cell><cell>conflict, adjacency</cell></row><row><cell></cell><cell></cell><cell>conflict, start, adjacency</cell></row><row><cell></cell><cell>End Fh</cell><cell>conftict, start</cell></row><row><cell></cell><cell></cell><cell>adjacency, start</cell></row><row><cell></cell><cell></cell><cell>adjacency, cottftict</cell></row><row><cell></cell><cell></cell><cell>adjacency, start, contlict</cell></row><row><cell>Wo</cell><cell>BestFb</cell><cell>start, conftict</cell></row><row><cell>BA</cell><cell>First Fb</cell><cell>adjacency, stat-t</cell></row><row><cell></cell><cell>End Fit</cell><cell>adjacency,conflict</cell></row><row><cell></cell><cell></cell><cell>adjacency, sum, conflict</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>Relevant details of the machine model used by the compiler for this study.</figDesc><table><row><cell cols="3">I l&gt;ipcline I Number I I Memory pm I 2 I Load</cell><cell>Operations</cell><cell>I Latency 1131</cell></row><row><cell></cell><cell></cell><cell>Store</cell><cell></cell><cell>1</cell></row><row><cell>Address ALU</cell><cell>2</cell><cell cols="2">Address add/subrract</cell><cell>1</cell></row><row><cell>Adder</cell><cell>1</cell><cell cols="3">Floating point add / subtract</cell><cell>1</cell></row><row><cell>I</cell><cell></cell><cell cols="2">I Integer add/subtract</cell><cell>I</cell><cell>1</cell></row><row><cell>Multiplier</cell><cell>1</cell><cell cols="2">Floating point multiply</cell><cell>2</cell></row><row><cell>I</cell><cell></cell><cell cols="2">I Integer multiply</cell><cell>I</cell><cell>2</cell></row><row><cell>Instruction</cell><cell>1</cell><cell cols="2">Branch</cell><cell>2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 .</head><label>4</label><figDesc>Comparison of the optimality of strategies and heuristics</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">MVE Strategy</cell><cell></cell><cell></cell><cell cols="2">WOStratcQv</cell><cell>II</cell><cell>BA Stratew</cell></row><row><cell></cell><cell></cell><cell></cell><cell>as is</cell><cell>Strtt</cell><cell>Conf</cell><cell>st/cnf</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>best</cell><cell></cell><cell>as is</cell><cell>3.21</cell><cell>1.71</cell><cell>1.32</cell><cell>1.30</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>fit</cell><cell></cell><cell>adj</cell><cell>2.40</cell><cell>1.75</cell><cell>1.30</cell><cell>1.30</cell><cell>--</cell><cell></cell><cell></cell><cell></cell></row><row><cell>t-iit</cell><cell></cell><cell>as is</cell><cell>3.36</cell><cell>1.77</cell><cell>1 36</cell><cell>1.36</cell><cell>2.46</cell><cell></cell><cell></cell><cell></cell></row><row><cell>fit</cell><cell></cell><cell>adj</cell><cell>2.5S</cell><cell>1.82</cell><cell>1.36</cell><cell>1,36</cell><cell>0,18</cell><cell></cell><cell></cell><cell></cell></row><row><cell>end</cell><cell></cell><cell>as is</cell><cell>16.42</cell><cell>35.79</cell><cell>27.75</cell><cell>28.80</cell><cell>5,65</cell><cell></cell><cell></cell><cell></cell></row><row><cell>fit</cell><cell></cell><cell>adj</cell><cell>= 3.30</cell><cell>2.51</cell><cell>3.00</cell><cell>237</cell><cell>018</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="10">Table 5. Comparison of the empirical computational complexity of strategies and heuristics</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">MVE Strategy</cell><cell></cell><cell></cell><cell cols="2">WO Strategy</cell><cell></cell><cell>BA Strategy</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>as is</cell><cell>Strtt</cell><cell>conf</cell><cell>stlcnf</cell><cell>as is</cell><cell>Strrt</cell><cell>conf</cell><cell>stlcnf</cell></row><row><cell>best</cell><cell></cell><cell>as is</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.21</cell><cell>1.14</cell><cell>1,10</cell><cell>1.12</cell><cell>1.24</cell><cell>1.18</cell><cell>1,13</cell><cell>1.17</cell></row><row><cell>fit</cell><cell></cell><cell>adj</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.01</cell><cell>1.01</cell><cell>1,01</cell><cell>1.01</cell><cell>1.05</cell><cell>1.04</cell><cell>1.04</cell><cell>1.04</cell></row><row><cell>fiit</cell><cell></cell><cell>as is</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.00</cell><cell>1.00</cell><cell>1,00</cell><cell>1.00</cell><cell>1.03</cell><cell>1.03</cell><cell>1.03</cell></row><row><cell>fit</cell><cell></cell><cell>adj</cell><cell>m</cell><cell></cell><cell></cell><cell></cell><cell>1.00</cell><cell>1.00</cell><cell>1,00</cell><cell>1.00</cell><cell>1.03</cell><cell>1,03</cell><cell>1.03</cell></row><row><cell>end</cell><cell></cell><cell>as is</cell><cell>3.58</cell><cell></cell><cell></cell><cell></cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.03</cell><cell>1.03</cell><cell>1.03</cell><cell>1.03</cell></row><row><cell>fit</cell><cell></cell><cell>adj</cell><cell>3.58</cell><cell></cell><cell></cell><cell></cell><cell>1.00</cell><cell>1.00</cell><cell>1 00</cell><cell>I.oo</cell><cell>1.03</cell><cell>1.03</cell><cell>1.03</cell><cell>1.03</cell></row><row><cell cols="2">'0 1007</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>f</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell cols="2">60--</cell><cell cols="3">E -best &amp; first fit</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0 0</cell><cell>40-</cell><cell></cell><cell></cell><cell></cell><cell cols="3">BA -first&amp; end tit</cell><cell></cell><cell></cell><cell></cell></row><row><cell>P</cell><cell>20</cell><cell></cell><cell>1</cell><cell>I</cell><cell>t</cell><cell>1</cell><cell>[</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">o</cell><cell>4</cell><cell>8</cell><cell>12</cell><cell>16</cell><cell>20</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 .</head><label>6</label><figDesc>Comparison of the code size of strategies</figDesc><table><row><cell></cell><cell>Code size</cell></row><row><cell>MVE -multiple epitogues</cell><cell>25S.51</cell></row><row><cell>MVE -preconditioning</cell><cell>14243</cell></row><row><cell></cell><cell>42.30</cell></row><row><cell></cell><cell>18.21</cell></row><row><cell cols="2">If we limit our discussion to only the best combinations for</cell></row><row><cell cols="2">each strategy, WO has the lowest empirical complexity, B A is</cell></row><row><cell cols="2">about d~o worse, and MVE is worse by a factor of 6.6. This factor</cell></row><row><cell cols="2">drops to 3.6 if first fiL instead of best fit, is used for MVE. With</cell></row><row><cell cols="2">respect to code size, BA is clearly the best. WO and MVE require</cell></row><row><cell cols="2">code that is 2.3 and 14.2 times larger, respectively.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 .</head><label>7</label><figDesc>The preferred allocation alg allocation strategy and the preferred for each allocation algorithm.</figDesc><table><row><cell></cell><cell></cell><cell>)rithm for each</cell></row><row><cell></cell><cell></cell><cell>ordering heuristics</cell></row><row><cell>Allocation Slrategy</cell><cell>Allocation</cell><cell>PreferredOrdering</cell></row><row><cell></cell><cell>Algorithm</cell><cell>Heuristics</cell></row><row><cell></cell><cell>@referred)</cell><cell></cell></row><row><cell>MVE</cell><cell>Best Fit</cell><cell>contlkt</cell></row><row><cell></cell><cell>Eir&amp;Eit</cell><cell>conftkt</cell></row><row><cell></cell><cell>End Fit</cell><cell>adjacency, stsrt, ccmtlct</cell></row><row><cell>Wo</cell><cell>Best Fh</cell><cell>adjacency, start</cell></row><row><cell></cell><cell>Fmt Fh</cell><cell>adjacency, start</cell></row><row><cell></cell><cell>m</cell><cell>adjacency, start</cell></row><row><cell>BA</cell><cell>Ik&amp;LEit</cell><cell>adjacency, stafi</cell></row><row><cell></cell><cell>First Fn</cell><cell>adjacency, conflict</cell></row><row><cell></cell><cell>End Fit</cell><cell>adjacency, conflict</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The end fit allocation algorithm and the adjacency ordering heuristic, described in this paper, were conceived of by Ross Towle who, along with Warren Ristow and Jim Dehnert, implemented register allocation for vector lifetimes in the Cydra 5 compiler.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conflict ordering is motivated by a register allocation slrategy which is to vector lifetimes what graph coloring [4] is to sealar lifetimes. This strategy reduces to the graph coloring approach in the case of scalar lifetimes. The basic idea is to establish, for each lifetime, a reasonably tight upper bound on the number of registers to which this lifetime cannot be allocated due to interference with the rest of the lifetimes, across all possible allocations for the rest of the lifetimes. This upper bound is referred to as the total conflict for that lifetime. The total conflict plus one is guaranteed to be an adequate number of registers to ensure the allocatability of that lifetime. The lifetime with the smallest total conflict is set aside and the total conflict is re-computed ignoring all lifetimes that have been set aside. This process is repeated until all lifetimes have been set aside. The Ii fetimcs are ordered in the reverse order in which they were set aside. The conflict ordering algorithm is shown in Figure <ref type="figure">13</ref>. The total conflict is computed using the CONFLICT matrix. For vector lifetimes, CONFLICT[i,j] = DIST[i,j] + DIST~,i] -1 for all i%j.</p><p>For scalar lifetimes,</p><p>for all i#j.</p><p>The total remaining conflict for lifetime i at any point in time is the sum of all CONFLICT[i,j] such that i#j and j has not yet been set aside,</p><p>Each ordering heuristic takes the incoming list of lifetimes and reorders them in accordance with the heuristic. Multiple heuristics may be employed in conduction with one another. When this is done, it is necessary to decide which heuristic is the primary one, which one is secondary (i.e., is used to break ties when the primary one cannot discriminate between two lifetimes), and so on. When two heuristics are used together, there are two possible prioritizations and, when all three are used together, there are six possible prioritizations. The success of the register allocator is sensitive to the specific prioritization selected. For each combination of allocation strategy and allocation algorithm, all possible prioritizations were ev ahrated using the input data set described in Section 5. The best prioritization in each case is listed in Table <ref type="table">2</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Cydra 5 departmental supercomputcr: design philosophies, decisions and trade-offs</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Rau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Compu</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1989-01">January, 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pamdlelization of loops with exits on pipelined architectures</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tirttmalai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Schlansker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Supercomputing &apos;90</title>
		<meeting>the Supercomputing &apos;90</meeting>
		<imprint>
			<date type="published" when="1990-11">November, 1990</date>
			<biblScope unit="page" from="200" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Uniejewski</surname></persName>
		</author>
		<title level="m">SPEC Benchmark Suite: Designed for</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Today&apos;s Advanced Systems</title>
	</analytic>
	<monogr>
		<title level="j">SPEC Newsletter</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
