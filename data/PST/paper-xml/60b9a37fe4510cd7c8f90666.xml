<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Privileged Graph Distillation for Cold Start Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-05-31">31 May 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shuai</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Key Laboratory of Knowledge Engineering with Big Data</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Key Laboratory of Knowledge Engineering with Big Data</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
							<email>zhang1028kun@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Key Laboratory of Knowledge Engineering with Big Data</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Key Laboratory of Knowledge Engineering with Big Data</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Le</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Key Laboratory of Knowledge Engineering with Big Data</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute of Artificial Intelligence</orgName>
								<orgName type="institution">Hefei Comprehensive National Science Center</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Key Laboratory of Knowledge Engineering with Big Data</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute of Artificial Intelligence</orgName>
								<orgName type="institution">Hefei Comprehensive National Science Center</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haiping</forename><surname>Ma</surname></persName>
							<email>hpma@ahu.edu.cn</email>
							<affiliation key="aff3">
								<orgName type="institution">Anhui University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Anhui University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Richang</forename><surname>Hong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Key Laboratory of Knowledge Engineering with Big Data</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Key Laboratory of Knowledge Engineering with Big Data</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Key Laboratory of Knowledge Engineering with Big Data</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute of Artificial Intelligence</orgName>
								<orgName type="institution">Hefei Comprehensive National Science Center</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Key Laboratory of Knowledge Engineering with Big Data</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute of Artificial Intelligence</orgName>
								<orgName type="institution">Hefei Comprehensive National Science Center</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Privileged Graph Distillation for Cold Start Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-05-31">31 May 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3404835.3462929</idno>
					<idno type="arXiv">arXiv:2105.14975v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cold start recommendation</term>
					<term>knowledge distillation</term>
					<term>graph convolutional networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The cold start problem in recommender systems is a long-standing challenge, which requires recommending to new users (items) based on attributes without any historical interaction records. In these recommendation systems, warm users (items) have privileged collaborative signals of interaction records compared to cold start users (items), and these Collaborative Filtering (CF) signals are shown to have competing performance for recommendation. Many researchers proposed to learn the correlation between collaborative signal embedding space and the attribute embedding space to improve the cold start recommendation, in which user and item categorical attributes are available in many online platforms. However, the cold start recommendation is still limited by two embedding spaces modeling and simple assumptions of space transformation. As user-item interaction behaviors and user (item) attributes naturally form a heterogeneous graph structure, in this paper, we propose a privileged graph distillation model (PGD). The teacher model is composed of a heterogeneous graph structure for warm users and items with privileged CF links. The student model is composed of an entity-attribute graph without CF links. Specifically, the teacher model can learn better embeddings of each entity by injecting complex higher-order relationships from the constructed heterogeneous graph. The student model can learn the distilled output with privileged CF embeddings from the teacher embeddings. Our proposed model is generally applicable to different cold start scenarios with new user, new item, or new user-new item. Finally, extensive experimental results on the real-world datasets clearly show the effectiveness of our proposed model on different types of cold start problems, with average 6.6%, 5.6%, and 17.1% improvement over state-of-the-art baselines on three datasets, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Collaborative Filtering (CF) is widely applied to various scenarios of recommender systems, which provides personalized item recommendation based on past user behaviors, such as purchasing a product <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b24">25]</ref>. Recently, graph based recommendations have shown huge success for solving data sparsity problem <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34]</ref>. Since the user-item interactions naturally form a graph, graph based recommendations obtain better user and item representations by aggregating higher-order neighbor information in a data sparsity setting. However, the cold start problem is still a challenge in CF based recommendation. Since new users or items have no historical interaction records, a conventional way to solve the cold start problem is to introduce additional data such as reviews, social networks, attributes, etc. Among them, user and item attributes are easily acquired in most online platforms (e.g., Facebook, Amazon) and described specific features. In this paper, we focus on attribute information in the cold start setting.</p><p>For most attribute enhanced recommendation methods, we summarize them into three categories according to the difference of input data: CF-based, content-based, and hybrid methods. Given the history interaction data and attributes, some researchers leverage collaborative information of the existing entities and the attribute similarity for new user (item) recommendations <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b42">43]</ref>. However, they do not model attribute information to feature space. Deep neural networks have achieved better performance in feature engineering modeling. Content-based methods make full use of auxiliary information of users and items to enhance the modeling of preference embedding <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30]</ref>. For example, DeepMusic <ref type="bibr" target="#b27">[28]</ref> and CDL <ref type="bibr" target="#b29">[30]</ref> were proposed to incorporate content data into deep neural networks and learned a general transformation function for content representations. A simple assumption is that the attribute information can be mapped into the embedding space by a general transformation function, which ignores collaborative signals for new users or items side. In order to overcome this shortcoming and further improve the model performance based on the content information, hybrid methods are proposed. Hybrid models fuse the CF and content embedding, and model the relations between CF and content space <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b43">44]</ref>. For example, DropoutNet <ref type="bibr" target="#b28">[29]</ref> was proposed to make full use of content and pretrained CF embedding for recommendation. However, most of these methods still have some weaknesses in dealing with those new users (items), that have no interactions with existing items (users).</p><p>Graph based recommendations are limited by user-item links. To obtain unseen node embedding in a graph, inductive representation learning combines node features and graph structures for node embedding <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37]</ref>. For example, PinSage is a content-based Graph Convolutional Networks (GCN) model for recommending items, which gathers both graph structure and node features for embedding learning <ref type="bibr" target="#b36">[37]</ref>. They still have weaknesses in tackling new user (item) problem mentioned above. In other words, how to make recommendations for new users (items), who have no links during test, is still challenging. Since user-item links are available during train while not available during test, interaction data is capable of providing privileged information. This problem can also be treated as how to leverage attribute information to distill privileged information for better recommendations of new users (items).</p><p>To this end, in this paper, we take advantages of graph learning and knowledge distillation in privileged information modeling and propose a novel privileged graph distillation model (PGD) for the cold start problem, which new users (items) have no link during test. Specifically, we introduce attributes of users (items) as nodes into a user-item graph and construct a heterogeneous graph, so that attribute representations can capture higher order information during embedding propagation. Since privileged information is only available offline and effective for prediction, we employ knowledge distillation method to tackle the cold start problem. More specifically, the teacher model can access all the information and make full use of attributes for privileged information learning and user preference modeling. The student model is constructed on an entity-attribute graph without CF links, which can obtain privileged information based on attributes under the guidance of the teacher model. Then, the student model can fuse CF signals of user or item embedding for final recommendations. Thus, PGD can not only make full use of attribute information for a better recommendation, but also alleviate the cold start problem when recommending for new users or items. Finally, we detail the cold start problem in recommendation into three sub-tasks and evaluate the model performance with three datasets. Extensively experimental results demonstrate the superiority of our proposed PGD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Cold Start Recommendation</head><p>CF-based algorithms personally recommend products by collecting explicit rating records and implicit feedback, which are widely applied in various recommendation systems <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b24">25]</ref>. These methods leverage matrix factorization to obtain low-dimensional representations of users and items. For example, Salakhutdinov et al. <ref type="bibr" target="#b22">[23]</ref> proposed Bayesian Personalized Ranking (BPR), which learned user and item latent vectors based on implicit feedback. Moreover, with the development of GCN, plenty of GCN-based CF methods are proposed to learn better collaborative filtering and alleviate the data sparsity problem <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b33">34]</ref>. For example, Chen et al. <ref type="bibr" target="#b4">[5]</ref> designed LR-GCCF model to simplify the embedding propagation process with linear graph convolutions, which achieved excellent performance. However, most CF-based methods require links between users and items, which limit their applications. In order to solve the cold start problem, CF-based methods leverage social data and basic matrix factorization to capture the new users' preferences conventionally <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b42">43]</ref>. Social data based methods first keep the pretrained CF representations on implicit feedback data, and then generate the new user's embedding with the connection between new users and old users <ref type="bibr" target="#b25">[26]</ref>. Despite the achievements they have made, most of these models still have some drawbacks. These methods cannot be widely used in the case of both new users and new items, and underestimate the potential of users' and items' attribute information .</p><p>In order to remedy the shortcomings of CF-based methods, researchers proposed to utilize additional content information and designed content-based methods. Content-based methods take the profile as input and train a general transform function for content information, in which new user or item representation can be generated. These methods usually learn a mapping function to transform the content representation into collaborative space <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30]</ref>, and leverage deep cross-network structure to capture higher-order relationships between features <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b31">32]</ref>. For example, xDeepFM was proposed to model cross interactions at the vector-wise level explicitly <ref type="bibr" target="#b15">[16]</ref>. In order to solve the cold start problem in graph based recommendations, PinSage was proposed to leverage both attributes as well as the user-item graph structure to generate better embeddings <ref type="bibr" target="#b36">[37]</ref>. However, most of these methods do not consider the complicated connection between CF embedding space and content space for each user (item), in which new user (item) representations cannot reflect the association with CF information.</p><p>To make full use of both CF-based methods and content-based methods, hybrid models are proposed to make better recommendations <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b43">44]</ref>. Most of these methods learn CF embedding and transformation functions to minimize prediction errors. A typical example is Heater <ref type="bibr" target="#b43">[44]</ref>, which dropped CF signals randomly to imitate new users or items situations. In particular, the CF representation is pretrained as a constraint for content embedding learning. The final prediction is conducted with a random choice of CF representation or content representation. Since the construction of user-item bipartite graph relies on interaction records, the learning of new user (item) representation is still a problem in graph based recommendations. Thus, inductive learning methods of graph are proposed to tackle unseen nodes' representation problem <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40]</ref>. Among these methods, TransGRec was proposed to feed the item's CF information and content information into the node initialization layer of the graph <ref type="bibr" target="#b34">[35]</ref>. Especially, Trans-GRec was designed to learn graph's structure information with the transfer network which is used to solve new user (item) problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Knowledge Distillation and Applications in Recommendations</head><p>Knowledge distillation is first proposed to address the lack of data and devices with limited resources. It aims to learn a better student model from a large teacher model and abandon the teacher model at the testing stage. In recent years, the knowledge distillation is presented in three ways: logits output <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b41">42]</ref>, intermediate layers <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b37">38]</ref>, and relation-based distillation <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>. Most of methods assume that the teacher model and the student model input the same regular data in the distillation process, which means the available information at test is the same as at train. In the real world, some information is helpful for prediction tasks but not always available, which called privileged information (e.g., medical reports in pathology analysis). Therefore, privileged distillation is proposed to tackle the lack of data problem in testing online, in which privileged information is only fed into the teacher model. Lopez et al. <ref type="bibr" target="#b17">[18]</ref> proposed an approach that guided the student model with fewer data and distilled the teacher model's privileged information. Since knowledge distillation is capable to solve the data missing and time-consuming problems, it attracts attention in recommendation areas. There are some works that get light models with better performance by model distillation <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b40">41]</ref>, which solve the problem of limited equipment resources and reduce the running time. For example, Zhang et al. <ref type="bibr" target="#b40">[41]</ref> constructed an embedding based model to distill user's meta-path structure and improve accuracy and interpretability. Meanwhile, to solve the problem that privileged information is unavailable in online recommendations, researchers proposed to introduce privileged distillation into recommendations <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b35">36]</ref>. Selective Distillation Network <ref type="bibr" target="#b5">[6]</ref> was proposed to use a review process framework as the teacher model, so that the student model can distill effective review information. Xu et al. <ref type="bibr" target="#b35">[36]</ref> proposed Privileged Features Distillation (PFD) to distill privileged features and in click-through rate and achieved better performance in click-through rate and conversion rate. However, most methods haven't addressed the new user or item problem.</p><p>In this paper, we treat interaction data as privileged information and design student network to imitate the situation of new users or items. Our goal is to improve model performance on cold start problems by distilling teacher's graph structure information and privileged information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEM DEFINITION</head><p>In a collaborative filtering based recommendation system, there are two sets of entities: a userset 𝑈 ( |𝑈 | = 𝑀), and an itemset 𝑉 ( |𝑉 | = 𝑁 ). Since implicit feedback is available in most scenarios, we use a rating matrix R ∈ R 𝑀×𝑁 to denote the interaction information, with 𝑟 𝑖 𝑗 = 1 indicates observed interaction between user 𝑖 and item 𝑗, otherwise it equals to 0. Traditionally, the user-item interaction behavior could be naturally formulated as a user-item bipartite graph: G 𝑅 =&lt; 𝑈 ∪ 𝑉 , A 𝑅 &gt;, where the graph adjacent matrix is constructed from the interaction matrix R:</p><formula xml:id="formula_0">A 𝑅 = 0 𝑀×𝑀 R R 𝑇 0 𝑁 ×𝑁 .<label>(1)</label></formula><p>Most of the attributes are sparse and categorical, and we generally convert continuous attributes to discrete distributions. Meanwhile, the entity attribute matrix X ∈ R (𝑀+𝑁 ) ×𝐷 is usually treated as the supplement information for user-item bipartite graph, where 𝐷 is the dimension of user and item attributes. Besides, we employ x 𝑖 ∈ R 𝐷 and x 𝑀+𝑗 ∈ R 𝐷 to denote the 𝑖 𝑡ℎ user one-hot attribute and the 𝑗 𝑡ℎ item one-hot attribute (0 ≤ 𝑖 &lt; 𝑀 , 0 ≤ 𝑗 &lt; 𝑁 ). For</p><p>x 𝑖 , the attribute's indices are between 0 and (𝐷 𝑢 − 1). For x 𝑗 , the attribute's indices are between 𝐷 𝑢 and (𝐷 − 1), where 𝐷 𝑢 is the dimension of user attributes.</p><p>The goal of graph based recommendations is to measure the user preference and predict the preference score matrix R ∈ R 𝑀×𝑁 . In order to evaluate the model performance, we also split the recommendation task into three sub-tasks to analyze the real-world scenarios in a detailed way.</p><p>Task 1: When a new user with attributes appears, we recommend existing (old) products to new users; Task 2: When a new product with attributes appears, we have to recommend new products to existing (old) users; Task 3: When new users and new products appear at the same time, we have to recommend new products to new users.</p><p>To this end, we propose a novel privileged graph distillation model (PGD) to tackle the above challenges. Next, we will introduce the technical details of PGD. Before introducing the technical details, we first introduce the necessary notations for the sake of convenience. We use U ∈ R 𝑀×𝑑 and V ∈ R 𝑁 ×𝑑 to denote the free embedding matrix of user and item respectively, where 𝑀 and 𝑁 represent the number of users and items. 𝑑 is the dimension of free embedding. Moreover, we leverage Y ∈ R 𝐷×𝑑 to represent the user attribute and item attribute node embedding matrix. Besides, we employ y 𝑘 and y 𝑙 to denote the 𝑘 𝑡ℎ user attribute and the 𝑙 𝑡ℎ item attribute (0 ≤ 𝑘 &lt; 𝐷 𝑢 , 𝐷 𝑢 ≤ 𝑙 &lt; 𝐷). Next, we will introduce the technical details of our proposed PGD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE PROPOSED MODEL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Teacher Model</head><p>As mentioned before, we intend to leverage attribute information to build connections for new users and new items. To this end, we construct a novel graph with the attributes as the nodes, and design a novel GCN, which we name as Teacher model, to generate comprehensive user and item embeddings, as well as predict the ratings of users to items. The teacher model's structure could be formulated as a user-item-attributes graph: G =&lt; 𝑈 ∪ 𝑉 ∪ X, A &gt;, where the graph matrix is constructed from the rating adjacent matrix A 𝑅 and attribute matrix X:</p><formula xml:id="formula_1">A = A 𝑅 X X 𝑇 0 𝐷×𝐷 ,<label>(2)</label></formula><p>Next, we first introduce the graph construction and model initialization. Then, we give a detailed description of the embedding propagation and model prediction.</p><p>Model Initialization Layer. In this layer, we leverage the free embedding matrix U ∈ R 𝑀×𝑑 and V ∈ R 𝑁 ×𝑑 to denote users and items. The attribute embeddings of users and items are represented with Y. They are treated as input and initialized with Gaussian  Distribution, then updated during the propagation of GCN. We have to note that the free embedding matrix U, V will be shared with Student model, which will be introduced in the following parts. Embedding Propagation Layer. In this part, we employ GCN to propagate users' (items', user attributes', item attributes') embeddings to capture higher-order information and obtain the proximity between four different type nodes for better node representation. Specifically, let u 𝑡 𝑖 and v 𝑡 𝑗 denote user 𝑖's embedding and item 𝑗's embedding at 𝑡 𝑡ℎ layer. And, y 𝑡 𝑘 denotes the attribute embedding for user, y 𝑡 𝑙 denotes the attribute embedding for item. We leverage the output of Initial Embedding Layer as the initial input of this layer, which means u 0 𝑖 = u 𝑖 , v 0 𝑗 = v 𝑗 , y 0 𝑘 = y 𝑘 , y 0 𝑙 = y 𝑙 . In order to extract the node embedding at (𝑡 + 1) 𝑡ℎ with the consideration of its neighbors' embeddings and its own free embedding at the 𝑡 𝑡ℎ layer, we utilize the graph propagation and pooling operation to update the embedding of each node. Taking user 𝑖 as an example, we leverage 𝐴 𝑖 = { 𝑗 |𝑟 𝑖 𝑗 = 1} ∪ {𝑘 |𝑥 𝑖𝑘 = 1} to denote the item set that he has clicked and his corresponding attribute set. The updating process can be formulated as follows:</p><formula xml:id="formula_2">u 𝑡 +1 𝑖 = (u 𝑡 𝑖 + ∑︁ 𝑗 ∈𝐴 𝑖 v 𝑡 𝑗 |𝐴 𝑖 | + ∑︁ 𝑘 ∈𝐴 𝑖 y 𝑡 𝑘 |𝐴 𝑖 | ).<label>(3)</label></formula><p>By employing this layer, PGD not only utilizes item neighbor information to describe the user's implicit preference, but also makes full use of attributes for the user's explicit feature. Similarly, PGD is capable of updating the item embedding based on users who have clicked it and the corresponding item attributes. Therefore, we leverage 𝐴 𝑀+𝑗 = {𝑖 |𝑟 𝑖 𝑗 = 1} ∪ {𝑙 |𝑥 ( 𝑗+𝑀)𝑙 = 1} to denote the user set who has clicked the item 𝑗 and the corresponding attribute set of item 𝑗. Then, the updating operation for item 𝑗 in the (𝑡 + 1) 𝑡ℎ layer can be described as follows:</p><formula xml:id="formula_3">v 𝑡 +1 𝑗 = (v 𝑡 𝑗 + ∑︁ 𝑖 ∈𝐴 𝑀+𝑗 u 𝑡 𝑖 |𝐴 𝑀+𝑗 | + ∑︁ 𝑙 ∈𝐴 𝑀+𝑗 y 𝑡 𝑙 |𝐴 𝑀+𝑗 | ).<label>(4)</label></formula><p>Besides, we add attribute nodes in GCN to enhance user preference modeling. Thus, user attribute embedding can be updated based on all users who have the same attributes. Meanwhile, the item attribute embedding can be updated in a similar way. The updating process at the (𝑡 + 1) 𝑡ℎ layer can be formulated as follows:</p><formula xml:id="formula_4">y 𝑡 +1 𝑘 = y 𝑡 𝑘 + ∑︁ 𝑖 ∈𝐴 𝑘+𝑀+𝑁 u 𝑡 𝑖 |𝐴 𝑘+𝑀+𝑁 | , 0 ≤ 𝑘 &lt; 𝐷 𝑢 , y 𝑡 +1 𝑙 = y 𝑡 𝑙 + ∑︁ 𝑗 ∈𝐴 𝑙 +𝑀+𝑁 v 𝑡 𝑗 |𝐴 𝑙+𝑀+𝑁 | , 𝐷 𝑢 ≤ 𝑙 &lt; 𝐷,<label>(5)</label></formula><p>where 𝐴 𝑘+𝑀+𝑁 = {𝑖 |𝑥 𝑖𝑘 = 1} ∈ X denotes the user set who has the attribute 𝑦 𝑘 . 𝐴 𝑙+𝑀+𝑁 = { 𝑗 |𝑥 ( 𝑗+𝑀)𝑙 = 1} ∈ X denotes the item set that has the attribute 𝑦 𝑙 . In order to illustrate the embedding propagation process more clearly, we formulate the fusion embedding in the matrix norm. Let matrix U 𝑡 , V 𝑡 , Y 𝑡 denote the embedding matrices of users ,items and attributes after 𝑡 𝑡ℎ propagation, then the updated embedding matrices after (𝑡 + 1) 𝑡ℎ propagation as:</p><formula xml:id="formula_5">      U 𝑡 +1 V 𝑡 +1 Y 𝑡 +1       = (       U 𝑡 V 𝑡 Y 𝑡       + D −1 A ×       U 𝑡 V 𝑡 Y 𝑡       ),<label>(6)</label></formula><p>where D is the degree matrix of A, which could efficiently propagate neighbors' embeddings and update fusion matrices. Model Prediction Layer. In this layer, we treat the output of Embedding Propagation Layer as the final user embedding û𝑖 and item embedding v𝑗 . In this layer, we treat the output of Embedding Propagation Layer as the final user embedding and item embeddings (i.e., u 𝐿 𝑖 , v 𝐿 𝑗 ), where 𝐿 is the number of GCN layers in Teacher model. Then, we predict user i's rating to item j by calculating the dot product of their embeddings, which can be formulated as follows:</p><formula xml:id="formula_6">r𝑖 𝑗 = û𝑖 ( v𝑗 ) 𝑇 = u 𝐿 𝑖 (v 𝐿 𝑗 ) 𝑇 . (<label>7</label></formula><formula xml:id="formula_7">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Student Model</head><p>As mentioned before, we introduce attribute information of users and items to alleviate the cold start problem in GCN based recommendation. However, attribute information still has some weaknesses in analyzing the collaborative filtering information of users, which is very important for user preference modeling. The former focuses on the new user problem and takes user attributes and items as input. The latter focuses on the new item problem and takes item attributes and users as input. The framework is illustrated in Figure <ref type="figure" target="#fig_1">2</ref>. Since these two sub-models perform in a similar way, we take the User Student model as an example to introduce the technical details for the sake of simplicity in the following parts. Graph Construction. Since the direct connections between new users and items are unavailable in the student model, we first need to construct the graph between new users and items based on the attribute information. As illustrated in Figure <ref type="figure" target="#fig_1">2</ref>, if user 𝑖 has clicked the item 𝑗, we could obtain the direct link between user 𝑖 and item 𝑗 in the teacher graph. However, this direct link is unavailable in the student graph. To this end, we employ indirect links between user attributes and items to replace the direct link between user and items. Specifically, if user 𝑖 have clicked item 𝑗, which will not be provided to the student model, we link the attributes of user 𝑖 to item 𝑗 to construct the user-attribute-item graph for User Student model. Moreover, if multiple users with attribute 𝑘 have clicked item 𝑗, we will assign a higher weight to the indirect link between attribute 𝑘 and item 𝑗.</p><p>We employ S 𝑢 ∈ R 𝑁 ×𝐷𝑢 to denote item-user attribute matrix and S 𝑣 ∈ R 𝑀×𝐷𝑣 denote user-item attribute matrix, where S 𝑢 and S 𝑣 is constructed from the user-item graph adjacent matrix A 𝑅 and entity attribute matrix X:</p><formula xml:id="formula_8">A 𝑅 X = 0 𝑀×𝐷𝑢 RX 𝑉 R 𝑇 X 𝑈 0 𝑁 ×𝐷𝑣 = 0 𝑀×𝐷𝑢 S 𝑣 S 𝑢 0 𝑁 ×𝐷𝑣 . (<label>8</label></formula><formula xml:id="formula_9">)</formula><p>where X 𝑈 represents the user attribute part of X and X 𝑉 represents the item attribute part of X. Since S 𝑢 is a two-order link matrix, in which 𝑠 𝑗𝑘 ≥ 1 indicates the count that item 𝑗 has indirect links with user attribute 𝑘. 𝑠 𝑗𝑘 = 0 denotes there is no indirect link between item 𝑗 and user attribute 𝑘. The user student model's graph structure could be formulated as a item-user attribute graph: G 𝑆 𝑢 =&lt; 𝑉 ∪ X 𝑈 , A 𝑆 𝑢 &gt;, where the graph adjacent matrix is constructed from the item-user attribute matrix A 𝑆𝑢 :</p><formula xml:id="formula_10">A 𝑆𝑢 = 0 𝑁 ×𝑁 S 𝑢 S 𝑇 𝑢 0 𝐷𝑢 ×𝐷𝑢 .<label>(9)</label></formula><p>Since this student graph G 𝑆 𝑢 is constructed based on secondorder connections, it will be a little denser than traditional user-item graph. After graph construction, we employ the item embedding from the teacher model as the initial embedding of the item in the student model. For the user attribute embedding e 𝑘 ∈ R 𝑑 , since user attributes only have indirect connection with items, we do not employ the user attribute embedding from teacher model and initialize it with Gaussian Distribution on the other hand.</p><p>Embedding Propagation Layer. Since there only exist indirect links between items and user attributes, we leverage the item free embedding to update the attribute embedding e 𝑘 . Taking the update in the (𝑡 +1) 𝑡ℎ layer as an example, we aggregate the item neighbors of user attribute 𝑘 to update its embedding. Let 𝐴 𝑆 𝑢 𝑘+𝑁 = { 𝑗 |𝑠 𝑗𝑘 ≥ 1} denotes the item set that has indirect connection with user attribute 𝑘, the (𝑡 + 1) 𝑡ℎ updating operation can be formulated as follows:</p><formula xml:id="formula_11">e 𝑡 +1 𝑘 = (e 𝑡 𝑘 + ∑︁ 𝑗 ∈𝐴 𝑆𝑢 𝑘+𝑁 v 𝑡 𝑗 |𝐴 𝑆 𝑢 𝑘+𝑁 | ).<label>(10)</label></formula><p>Meanwhile, item embedding can be updated with the corresponding user attribute neighbors in a similar way. Let 𝐴 𝑆 𝑢 𝑗 = {𝑘 |𝑠 𝑗𝑘 &gt;= 1} denotes the user attribute set that has indirect connections with item 𝑗. The (𝑡 + 1) 𝑡ℎ updating operation can be described as follows:</p><formula xml:id="formula_12">v 𝑡 +1 𝑗 = (v 𝑡 𝑗 + ∑︁ 𝑗 ∈𝐴 𝑆𝑢 𝑗 e 𝑡 𝑘 |𝐴 𝑆 𝑢 𝑗 | ).<label>(11)</label></formula><p>Similar to the teacher model, let matrix E 𝑡 , V 𝑡 denote the embedding matrices of user attribute in the user student model and items after 𝑡 𝑡ℎ propagation, then the updated embedding matrices after (𝑡 + 1) 𝑡ℎ propagation as:</p><formula xml:id="formula_13">V 𝑡 +1 E 𝑡 +1 = ( V 𝑡 E 𝑡 + D 𝑆𝑢 −1 A 𝑆𝑢 × V 𝑡 E 𝑡 ).<label>(12)</label></formula><p>Finally, we can get the user attribute embedding and the updated item free embedding. Taking new user 𝑖 and item 𝑗 as an example, the attribute set of new user 𝑖 can be represented with 𝑋 𝑢 𝑖 = {𝑘 | x𝑖𝑘 = 1}. Their embeddings can be represented as follows:</p><formula xml:id="formula_14">u 𝑈 𝑖 = ∑︁ 𝑘 ∈𝑋 𝑢 𝑖 e 𝐿 𝑆𝑢 𝑘 , v 𝑈 𝑗 = v 𝐿 𝑆𝑢 𝑗 ,<label>(13)</label></formula><p>where 𝐿 𝑆 𝑢 is the number of GCN layers in the user student model. Meanwhile, we can obtain the user embedding u 𝐼 𝑖 and item embedding v 𝐼 𝑗 in a similar way. Prediction Layer. In this layer, we intend to utilize the learned user embedding and item embedding to calculate the corresponding rating. Taking user 𝑖 and item 𝑗 as an example, the predicted rating can be calculated with the following function:</p><formula xml:id="formula_15">r𝑖 𝑗 = û𝑖 ( v𝑗 ) 𝑇 . (<label>14</label></formula><formula xml:id="formula_16">)</formula><p>If the user and item are available simultaneously, the predicted rating can be obtained with û𝑖 = u 𝐿 𝑖 , v𝑗 = v 𝐿 𝑗 , as illustrated in Eq.7. When dealing with cold start problem, we employ different components in PGD to generate different implementations of user embedding û𝑖 and item embedding v𝑗 in Eq. 14, which is in favor of tackling different situations of cold start problem in a unified way.</p><p>1) Task 1. In this task, we select the user student model. User embedding u 𝑖 can be represented with the sum of corresponding attribute embedding e 𝑘 (𝑘 ∈ 𝑋 𝑢 𝑖 ) in user student model. Item embedding can be represented with the free embedding v 𝐿 𝑗 generated in teacher model. Finally, Eq. 14 can be modified as follows:</p><formula xml:id="formula_17">r𝑖 𝑗 = û𝑖 ( v𝑗 ) 𝑇 = u 𝑈 𝑖 (v 𝐿 𝑗 ) 𝑇 = ( ∑︁ 𝑘 ∈𝑋 𝑢 𝑖 e 𝐿 𝑆𝑢 𝑘 )(v 𝐿 𝑗 ) 𝑇 .<label>(15)</label></formula><p>2) Task 2. In this task, we select the item student model. For user embedding, we select the user free embedding u 𝐿 𝑖 from Teacher model as the representation. For item representation, we make full use of its attribute embedding 𝑓 𝑙 (𝑙 ∈ 𝑋 𝑣 𝑗 ) as the needed embedding. Therefore, Eq. 14 is modified as follows:</p><formula xml:id="formula_18">r𝑖 𝑗 = û𝑖 ( v𝑗 ) 𝑇 = u 𝐿 𝑖 (v 𝐼 𝑗 ) 𝑇 = (u 𝐿 𝑖 )( ∑︁ 𝑙 ∈𝑋 𝑣 𝑗 f 𝐿 𝑆𝑣 𝑙 ) 𝑇 . (<label>16</label></formula><formula xml:id="formula_19">)</formula><p>3) Task 3. In this task, the user and item free embedding are not available at the same time. Therefore, we employ both user student model and item student model to generate the user and item embeddings with their attribute information. Specifically, we select the user embedding u 𝑈 𝑖 and item embedding v 𝐼 𝑗 , which are driven from their own attributes, and modify Eq. 14 as follows:</p><formula xml:id="formula_20">r𝑖 𝑗 = û𝑖 ( v𝑗 ) 𝑇 = u 𝑈 𝑖 (v 𝐼 𝑗 ) 𝑇 = ( ∑︁ 𝑘 ∈𝑋 𝑢 𝑖 e 𝐿 𝑆𝑢 𝑘 )( ∑︁ 𝑙 ∈𝑋 𝑣 𝑗 f 𝐿 𝑆𝑣 𝑙 ) 𝑇 . (<label>17</label></formula><formula xml:id="formula_21">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Optimization</head><p>Since PGD contains two main components, the optimization also consists of two parts: Rating Prediction Loss for Teacher Model, and Graph Distillation Loss for PGD. Rating Prediction Loss. For recommender system based on implicit feedback, BPR-based on pair-wise ranking is the most popular optimization algorithm. Thus, the objective function can be formulated as follows:</p><formula xml:id="formula_22">𝐿 𝑟 = ∑︁ 𝑢 ∈𝑈 ∑︁ (𝑖,𝑗) ∈𝐵 𝑢 −𝑙𝑛𝜎 ( r𝑢𝑖 − r𝑢 𝑗 ) + 𝛾 ||𝜃 || 2 , (<label>18</label></formula><formula xml:id="formula_23">)</formula><p>where 𝜎 (•) is a sigmoid activation function. 𝐵 𝑢 = {(𝑖, 𝑗)|𝑟 𝑢𝑖 = 1∧𝑟 𝑢 𝑗 ≠ 1} denotes the pairwise training data for user 𝑢. r𝑢𝑖 and r𝑢 𝑗 are computed by the free embedding of the teacher model.</p><p>𝜃 represents the user and item free embedding matrices. 𝛾 is a regularization parameter that restrains the user and item free latent embedding matrices. Graph Distillation Loss. Since distillation techniques are employed in PGD to help the student model to learn better user and item embeddings, as well as make accurate predictions based on the attribute information, with the guidance of teacher model. Thus, the learned user embedding u 𝐿 𝑖 (item embedding v 𝐿 𝑗 ) from teacher model and u 𝑈 𝑖 (v 𝐼 𝑗 ) from student model should be similar. This optimizing target can be formulated as follows:</p><formula xml:id="formula_24">𝐿 𝑢 = 𝑀−1 ∑︁ 𝑖=0 ||u 𝐿 𝑖 − u 𝑈 𝑖 || 2 , 𝐿 𝑣 = 𝑁 −1 ∑︁ 𝑗=0 ||v 𝐿 𝑗 − v 𝐼 𝑗 || 2 . (<label>19</label></formula><formula xml:id="formula_25">)</formula><p>Meanwhile, we intend the student model to predict user preference correctly. U and V represent the embedding matrices of users and items in the teacher model. U 𝑈 and V 𝐼 represent the embedding matrices of users and items in the student model. Thus, its prediction result should be similar to the results of the teacher model. which can be formulated as follows:</p><formula xml:id="formula_26">𝐿 𝑠 = | |UV 𝑇 − U 𝑈 (V 𝐼 ) 𝑇 | | 2 . (<label>20</label></formula><formula xml:id="formula_27">)</formula><p>The Graph Distillation Loss will be formulated as follows:</p><formula xml:id="formula_28">𝐿 𝑑 = 𝜆𝐿 𝑢 + 𝜇𝐿 𝑣 + 𝜂𝐿 𝑠 ,<label>(21)</label></formula><p>where 𝜆, 𝜇, 𝜂 are the weight of different information distillation loss. We can adjust their values to focus our proposed PGD on tackling different sub-tasks in code start problem in recommendation. After obtaining the two parts objective functions, The final optimization of our model can be formulated as follows:</p><formula xml:id="formula_29">𝐿𝑜𝑠𝑠 = 𝐿 𝑟 + 𝐿 𝑑 (22)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we conduct extensive experiments on three datasets to verify the effectiveness of our proposed PGD for cold start recommendation. We aim to answer the following questions:</p><p>• Will the attribute information and the utilization method in PGD be useful for solving the cold start problem (e.g., new users or new items) in recommendations? • Is the distillation technique helpful for student model to learn useful knowledge from teacher model for user or item embedding? • What is the influence of each component in our proposed PGD to the overall performance?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>In this paper, we select three suitable and public available datasets to evaluate all the models, i.e., Yelp, XING <ref type="bibr" target="#b0">[1]</ref>, and Amazon-Video Games <ref type="bibr" target="#b10">[11]</ref>. Table <ref type="table" target="#tab_2">1</ref> report the statistics of three datasets.</p><p>In order to evaluate the model performance on each of three sub-tasks in cold start problem, we manually set the new users or new items in the test sets <ref type="bibr" target="#b43">[44]</ref>. Specifically, we randomly select 30% users in the test set. Then, we keep the corresponding items and remove their connections to construct the new user test set for Task 1. Meanwhile, we apply the same operation to generate a new items test set for Task 2. As for Task 3, we collated interaction records belonging to both the new user and the new product as the test set. Then, we split 10% validation set from the rest old users and old items. The details are reported in Table <ref type="table" target="#tab_2">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Setup</head><p>Evaluation Metrics. Since the cold start problem still can be treated as top-K recommendation task, we select two popular ranking metrics to evaluate our model: HR@K and NDCG@K (𝐾 = {10, 20, 50}). Parameter Settings. First of all, the dimensions of collaborative filtering embedding and the attribute representation are all set as 64. The batch size is set as 2, 048. The depth 𝐿 of GCN is selected from {1, 2, 3, 4}, and we also make an experiment to verify the influence of different depths. During training, Adam is employed as the optimizer with learning rate 0.001.</p><p>Gaussian distribution with a mean of 0 and variance of 0.01 is employed to initialize the embedding matrices. At each iteration of the training process, we randomly sample one candidate negative sample to compose a triple data. In the testing phase, to avoid the unfairness caused by the randomly negative samples, we evaluted all models in the condition of all negative samples. As shown in Eq. 21, there are three hyper-parameters 𝜆, 𝜇 and 𝜂. We tune the three hyper-parameters on three different tasks respectively. The combination for Yelp is {𝜆 = 100, 𝜇 = 1, 𝜂 = 0.01}, for Amazon-Video Games is {𝜇 = 10} and for XING is {𝜆 = 1, 𝜇 = 100, 𝜂 = 0.001}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Overall Results</head><p>Tables <ref type="table" target="#tab_4">2 and 3</ref> report the overall results on three datasets. We can obtain that PGD outperforms all baselines across all the datasets with different evaluation metrics. Specifically, PGD achieves average 2.03%, 11.67%, 6.01% improvement across three sub-tasks on Yelp, average 27.83%, 7.28%, 16.06% improvement on XING, and average 5.6% improvement on Amazon-Game Videos, respectively. This phenomenon demonstrates the effectiveness of introducing attribute information into graph as node and learning attribute embedding and entity embeddings simultaneously under the graph constraint. Moreover, PGD makes full use of distillation techniques to narrow down the gap between attribute embedding and CF-based embedding and help the student model to learn entity embedding from the teacher model with the attribute information as input.</p><p>Meanwhile, PGD tries to tackle all three sub-tasks in a unified framework. To this end, we also designed a student baseline to address new item or new user problem independently. Specifically, for Task 1, we only select the user student model to learn the user attribute embedding and item CF-based embedding. For Task 2, we have similar operations. As for Task 3, we select the user attribute embedding and item attribute embedding from two student models. The corresponding results are illustrated in Tables <ref type="table" target="#tab_4">2 and  3</ref>. We can obtain that PGD still outperforms the student baselines, indicating the superiority and necessity of distilling and modeling user preference in a unified way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">The Impact of Different Propagation Layer</head><p>Depth L and Detailed Model Analysis.</p><p>As introduced in Section 4, the number of GCN layers will has a big impact on the model performance. Therefore, we conduct additional experiments to verify its impact. Corresponding results are illustrated in Tables <ref type="table" target="#tab_5">4 and 5</ref>. From the results, we can obtain that with the increasing number of GCN layers in the teacher model, the overall performance first rises and then falls. When the number of GCN layers is 2 or 3, PGD achieved the best performance. The possible reason is that with the increasing number of GCN layers, each node could aggregate more neighbors' information, which not only alleviate the data sparsity problem, but also gather more useful information for node embedding learning. On the other hand, too many GCN layers in the teacher model will cause the student hard to follow and node feature over smoothing problem. Therefore, we select 2 or 3 as the GCN layer number in teacher model according to tasks and datasets.</p><p>The above analysis shows that PGD can distill knowledge at the output layer. Intuitively, applying distillation operations to each layer seems to get better performance. We conduct experiments to compare the effects of the two distillation methods in Table <ref type="table" target="#tab_6">6</ref>. At 2 layer, multi-layer distillation has a little improved effect on task2 of the yelp dataset. However, there is no general enhancement but still competitive against baselines on the other tasks. We speculate the reason is that, there is still a gap between the intermediate layer embedding distillation and the final output embedding distillation. Our model is not a direct node-to-node distillation between teacher graph and student graph, and the final entity embedding of the student model fuses the attribute node information. Multi-layer distillation only relies on the weighted sum operation which does not capture well the positive impact of the distillation of the first layer on the final output distillation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Ablation Study</head><p>In the previous parts, we have illustrated the superiority of our proposed PGD. However, the student model tries to distill knowledge from teacher model with three constraints (i.e., user embedding constraint, item embedding constraint, and prediction constraint), which component plays a more important role in user preference Table <ref type="table">2</ref>: HR@K and NDCG@K comparisons for Yelp and Amazon-Video Games. '-' represents unavailable result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Metrics Yelp(Task1) Yelp(Task2) Yelp(Task3) Amazon-Video Games (Task2) @10 @20 @50 @10 @20 @50 @10 @20 @50 @10 @20 @50   <ref type="table">4</ref>: HR@20 and NDCG@20 results of our model with different propagation depth 𝐿 on Yelp and Amaon-Video Games (We fix the same gcn layer 𝐿 of student model and teacher model).</p><formula xml:id="formula_30">KNN</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Num. of GCN Layers</head><p>Yelp(Task1) Yelp(Task2) Yelp(Task3) Amazon Video Games HR@20 NDCG@20 HR@20 NDCG@20 HR@20 NDCG@20 HR@20 NDCG@20 XING(Task1) XING(Task2) XING(Task3) Num. of GCN Layers HR@20 NDCG@20 HR@20 NDCG@20 HR@20 NDCG@20 𝐿 = 1 0.02071 0.008274 0.004003 0.001754 0.006107 0.001962 𝐿 = 2 0.02107 0.009037 0.004216 0.001758 0.006727 0.002222 𝐿 = 3 0.02204 0.009160 0.003992 0.001752 0.006439 0.002100 𝐿 = 4 0.02176 0.008947 0.003907 0.001672 0.006359 0.002054   modeling is still unclear. To this end, we conduct an ablation study on parameters {𝜆, 𝜇, 𝜂} to verify the impact of each component with NDCG@20. When verifying the effectiveness of one constraint, we fix other two parameters and modify the corresponding weight to obtain the results. Figure <ref type="figure" target="#fig_3">3</ref> reports the corresponding results, from which we can obtain the following observations. With the increase of each component, model performance first increases and then decreases. The distillation loss constraint has a negative impact on the teacher model when the distillation loss is overweight. Moreover, when PGD achieves the best performance, 𝜆 and 𝜇 have similar values. Thus, we can conclude that the user embedding constraint and item embedding constraint have similar impacts on model performance. Furthermore, we can observe that the best value for 𝜂 is very small. Since this is a top-K recommendation task, the prediction constraint may have a big impact on the final performance.</p><p>We also observed that the boosting effect of these parameters is different for different tasks and different datasets. For instance, the metrics of task1 in Yelp improved 2.03%, but improved 11.67% of task2 in Yelp. We speculate the possible reason is that the types of user attributes are less than item attributes. Thus, user attributes cannot provide as much information as item attributes do. Therefore, the user embedding distillation may not be as good as item embedding distillation. As a result, item embedding constraint has a bigger impact on the model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we argued that attribute information is not fully explored in cold start recommendations. Thus, we proposed a novel privileged graph distillation model (PGD) to constrain the attribute embedding and CF-based embedding learning in a graph manner and leverage distillation technique to tackle the cold start recommendation. In concerned details, we first introduce attributes as nodes into user-item graph and learn attribute embedding and CFbased embedding simultaneously. Then, we employed distillation technique to guide PGD to learn the transformation between CFbased embedding and attribute embedding. Thus, the student model can learn effective user (item) embedding based on attribute information from the teacher model. Extensive experiments on three public datasets show the performance improvement of PGD over state-of-the-art baselines. In the future, we plan to explore different distillation architectures to better attribute node embedding.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>Figure 1 illustrates the overall architecture of our proposed PGD, which consists of three main components: 1) Teacher model: leveraging existing user-item interactions to learn user preference representation and item representation; 2) User Student model: focusing on new user preference modeling; 3) Item Student model: concentrating on new item modeling.Before introducing the technical details, we first introduce the necessary notations for the sake of convenience. We use U ∈ R 𝑀×𝑑 and V ∈ R 𝑁 ×𝑑 to denote the free embedding matrix of user and item respectively, where 𝑀 and 𝑁 represent the number of users and items. 𝑑 is the dimension of free embedding. Moreover, we leverage Y ∈ R 𝐷×𝑑 to represent the user attribute and item attribute node embedding matrix. Besides, we employ y 𝑘 and y 𝑙 to denote the 𝑘 𝑡ℎ user attribute and the 𝑙 𝑡ℎ item attribute (0 ≤ 𝑘 &lt; 𝐷 𝑢 , 𝐷 𝑢 ≤ 𝑙 &lt; 𝐷). Next, we will introduce the technical details of our proposed PGD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The user student framework of PGD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Varying 𝜂 Yelp (Task 3)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: NDCG@20 results of our model with different hyper-parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>The statistics of the three datasets.</figDesc><table><row><cell cols="2">Dataset</cell><cell>Yelp</cell><cell>XING</cell><cell>Amazon-Video Games</cell></row><row><cell></cell><cell>Old Users</cell><cell>29,777</cell><cell>20,640</cell><cell>29,129</cell></row><row><cell>Train</cell><cell>Old Items Ratings</cell><cell cols="2">27,737 159,857 133,139 17,793</cell><cell>22,547 172,089</cell></row><row><cell></cell><cell>Density</cell><cell cols="2">0.019% 0.036%</cell><cell>0.026%</cell></row><row><cell></cell><cell>Old Users</cell><cell>2,109</cell><cell>17,058</cell><cell>26,506</cell></row><row><cell>Val</cell><cell>Old Items</cell><cell>1,812</cell><cell>10,357</cell><cell>10,189</cell></row><row><cell></cell><cell>Ratings</cell><cell>2,109</cell><cell>20,258</cell><cell>29,870</cell></row><row><cell></cell><cell cols="2">New Users 12,749</cell><cell>7,105</cell><cell>/</cell></row><row><cell>Test new user</cell><cell>Old Items</cell><cell>17,121</cell><cell>7,665</cell><cell>/</cell></row><row><cell></cell><cell>Ratings</cell><cell>65,127</cell><cell>12,858</cell><cell>/</cell></row><row><cell></cell><cell>Old Users</cell><cell>27,067</cell><cell>11,013</cell><cell>22,027</cell></row><row><cell>Test new item</cell><cell cols="2">New Items 11,975</cell><cell>7,598</cell><cell>10,170</cell></row><row><cell></cell><cell>Ratings</cell><cell>69,524</cell><cell>33,079</cell><cell>98,044</cell></row><row><cell>Test new user and new item</cell><cell cols="2">New Users 11,662 New Items 8,734 Ratings 30,288</cell><cell>4,618 4,276 7,318</cell><cell>/ / /</cell></row><row><cell>User Attributes</cell><cell></cell><cell>80</cell><cell>108</cell><cell>/</cell></row><row><cell>Item Attributes</cell><cell></cell><cell>183</cell><cell>81</cell><cell>76</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>HR@K and NDCG@K comparisons for XING. '-' represents unavailable result. KNN cannot work for task3.</figDesc><table><row><cell>Model</cell><cell>Metrics</cell><cell>@10</cell><cell>XING(Task1) @20</cell><cell>@50</cell><cell>@10</cell><cell>XING(Task2) @20</cell><cell>@50</cell><cell>@10</cell><cell>XING(Task3) @20</cell><cell>@50</cell></row><row><cell>KNN</cell><cell>HR NDCG</cell><cell cols="6">0.002977 0.005945 0.001586 0.002436 0.003920 0.0006946 0.0009711 0.001913 0.01249 0.001345 0.002246 0.005768</cell><cell>--</cell><cell>--</cell><cell>--</cell></row><row><cell>LinMap</cell><cell>HR NDCG</cell><cell cols="4">0.007926 0.004242 0.006225 0.008781 0.001047 0.01483 0.02628 0.002039</cell><cell>0.003692 0.001559</cell><cell cols="4">0.007225 0.002492 0.0007650 0.001291 0.002255 0.001552 0.003338 0.007983</cell></row><row><cell>xDeepFM</cell><cell>HR NDCG</cell><cell cols="5">0.007733 0.004240 0.006289 0.009048 0.0009840 0.001526 0.01530 0.02752 0.001991 0.003892</cell><cell cols="4">0.007474 0.002450 0.0009600 0.001765 0.002794 0.002526 0.005242 0.009932</cell></row><row><cell>CDL</cell><cell>HR NDCG</cell><cell cols="5">0.007546 0.004250 0.006255 0.009263 0.0008030 0.001357 0.01469 0.02815 0.001521 0.003213</cell><cell>0.006708 0.002334</cell><cell>0.002992 0.001479</cell><cell cols="2">0.004580 0.007668 0.001854 0.002444</cell></row><row><cell>DropoutNet</cell><cell>HR NDCG</cell><cell cols="5">0.006997 0.003311 0.004959 0.007376 0.0007770 0.001531 0.01278 0.02345 0.001404 0.003784</cell><cell cols="4">0.007138 0.002458 0.0008680 0.001332 0.002222 0.001805 0.003901 0.007610</cell></row><row><cell>Heater</cell><cell>HR NDCG</cell><cell cols="4">0.006934 0.003354 0.005713 0.008451 0.001061 0.01524 0.02717 0.001766</cell><cell>0.003633 0.001667</cell><cell>0.007661 0.002722</cell><cell>0.002635 0.001429</cell><cell cols="2">0.004788 0.007963 0.001704 0.002415</cell></row><row><cell>PinSage</cell><cell>HR NDCG</cell><cell cols="5">0.004862 0.002680 0.004436 0.006818 0.0009460 0.001610 0.01119 0.02193 0.001646 0.003693</cell><cell cols="4">0.007953 0.002705 0.0004690 0.001046 0.001358 0.001002 0.002315 0.003741</cell></row><row><cell>PFD</cell><cell>HR NDCG</cell><cell cols="2">0.009043 0.005273 0.007073 0.01552</cell><cell>0.02855 0.01005</cell><cell>0.002331 0.001151</cell><cell>0.003877 0.001666</cell><cell>0.007373 0.002578</cell><cell>0.002833 0.001300</cell><cell cols="2">0.005251 0.008742 0.001942 0.002695</cell></row><row><cell>Student</cell><cell>HR NDCG</cell><cell cols="2">0.008985 0.004734 0.007033 0.01725</cell><cell cols="3">0.03114 0.01015 0.0009520 0.001460 0.001998 0.003734</cell><cell cols="4">0.007789 0.002506 0.0008830 0.001526 0.002144 0.001777 0.004040 0.006881</cell></row><row><cell>PGD</cell><cell cols="10">HR↑ NDCG↑ 0.006522 0.009160 0.01330 0.001322 0.001758 0.002780 0.001694 0.002222 0.002886 0.01149 0.02204 0.04060 0.002539 0.004216 0.008276 0.003999 0.006727 0.01018</cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>HR@20 and NDCG@20 results of our model with different propagation depth 𝐿 on XING (We fix the same gcn layer 𝐿 of student model and teacher model).</figDesc><table><row><cell>𝐿 = 1</cell><cell>0.03365</cell><cell>0.02294 0.04541</cell><cell>0.02239 0.02467</cell><cell>0.01142 0.02946</cell><cell>0.01125</cell></row><row><cell>𝐿 = 2</cell><cell>0.03404</cell><cell>0.02323 0.04606</cell><cell>0.02255 0.02589</cell><cell>0.01240 0.02953</cell><cell>0.01164</cell></row><row><cell>𝐿 = 3</cell><cell>0.03355</cell><cell>0.02186 0.04712</cell><cell>0.02306 0.02577</cell><cell>0.01198 0.02801</cell><cell>0.01124</cell></row><row><cell>𝐿 = 4</cell><cell>0.03225</cell><cell>0.02102 0.04693</cell><cell>0.02298 0.02533</cell><cell>0.01192 0.02707</cell><cell>0.01104</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>HR@20 and NDCG@20 results of output distillation and multi-layer distillation.</figDesc><table><row><cell></cell><cell>Metrics</cell><cell cols="2">2-Layer Output 2-Layer Multi-Layer</cell></row><row><cell>Yelp(Task1)</cell><cell>HR@20 NDCG@20</cell><cell>0.03404 0.02323</cell><cell>0.03415 0.02152</cell></row><row><cell>Yelp(Task2)</cell><cell>HR@20 NDCG@20</cell><cell>0.04606 0.02255</cell><cell>0.04627 0.02302</cell></row><row><cell>Yelp(Task3)</cell><cell>HR@20 NDCG@20</cell><cell>0.02589 0.01240</cell><cell>0.02638 0.01205</cell></row><row><cell>Amazon</cell><cell>HR@20 NDCG@20</cell><cell>0.02953 0.01164</cell><cell>0.02812 0.01113</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This work was supported in part by grants from the National Natural Science Foundation of China (Grant No. U1936219, U19A2079, 62006066, 61932009), the Young Elite Scientists Sponsorship Program by CAST and ISZS, CCF-Tencent RAGR20200121, and the Open Project Program of the National Laboratory of Pattern Recognition (NLPR).</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Privileged Graph Distillation for Cold Start Recommendation . In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '21), July 11-15, 2021, Virtual Event, Canada. ACM, New York, NY, USA, 10 pages.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Recsys challenge 2017: Offline and online evaluation</title>
		<author>
			<persName><forename type="first">Fabian</forename><surname>Abel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yashar</forename><surname>Deldjoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Elahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Kohlsdorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="372" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Graph convolutional matrix completion</title>
		<author>
			<persName><forename type="first">Rianne</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD Deep Learning Day</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hyperbolic graph convolutional neural networks</title>
		<author>
			<persName><forename type="first">Ines</forename><surname>Chami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">4869</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning student networks via feature embedding</title>
		<author>
			<persName><forename type="first">Hanting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TNNLS</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="25" to="35" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Revisiting graph based collaborative filtering: A linear residual graph convolutional network approach</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richang</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adversarial distillation for efficient recommendation with external knowledge</title>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Xu Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongteng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOIS</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Long Short-Term Session Search: Joint Personalized Reranking and Next Query Prediction</title>
		<author>
			<persName><forename type="first">Qiannan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning attribute-to-feature mappings for cold-start recommendations</title>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Drumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="176" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Eigentaste: A constant time collaborative filtering algorithm</title>
		<author>
			<persName><forename type="first">Ken</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theresa</forename><surname>Roeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Perkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="133" to="151" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">VBPR: visual bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="144" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Lightgcn: Simplifying and powering graph convolution network for recommendation</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuan</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="639" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">DE-RRD: A Knowledge Distillation Framework for Recommender System</title>
		<author>
			<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wonbin</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="605" to="614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">xdeepfm: Combining explicit and implicit feature interactions for recommender systems</title>
		<author>
			<persName><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongxia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangzhong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1754" to="1763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Knowledge distillation via instance relationship graph</title>
		<author>
			<persName><forename type="first">Yufan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajiong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunfeng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiming</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangxi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunqiang</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7096" to="7104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Unifying distillation and privileged information</title>
		<author>
			<persName><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improved knowledge distillation via teacher assistant</title>
		<author>
			<persName><forename type="first">Mehrdad</forename><surname>Seyed Iman Mirzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ang</forename><surname>Farajtabar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nir</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="5191" to="5198" />
		</imprint>
	</monogr>
	<note>Akihiro Matsukawa, and Hassan Ghasemzadeh</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Relational knowledge distillation</title>
		<author>
			<persName><forename type="first">Wonpyo</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongju</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minsu</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3967" to="3976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Correlation congruence for knowledge distillation</title>
		<author>
			<persName><forename type="first">Baoyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shunfeng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoning</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5007" to="5016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Social collaborative viewpoint regression with explainable recommendations</title>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shangsong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuaiqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="485" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><surname>S Rendle</surname></persName>
		</author>
		<author>
			<persName><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Uncertainty in Artificial Intelligence</title>
				<meeting>of Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fitnets: Hints for thin deep nets</title>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samira</forename><forename type="middle">Ebrahimi</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bayesian probabilistic matrix factorization using Markov chain Monte Carlo</title>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="880" to="887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Social collaborative filtering for cold-start recommendations</title>
		<author>
			<persName><forename type="first">Suvash</forename><surname>Sedhain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Sanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Darius</forename><surname>Braziunas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lexing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="345" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ranking distillation: Learning compact ranking models with high performance for recommender system</title>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2289" to="2298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep content-based music recommendation</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Schrauwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2643" to="2651" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dropoutnet: Addressing cold start in recommender systems</title>
		<author>
			<persName><forename type="first">Maksims</forename><surname>Volkovs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangwei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomi</forename><surname>Poutanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4957" to="4966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Collaborative deep learning for recommender systems</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1235" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Next Point-of-Interest Recommendation on Resource-Constrained Mobile Devices</title>
		<author>
			<persName><forename type="first">Qinyong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongzhi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanchang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nguyen</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viet</forename><surname>Hung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="906" to="916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep &amp; cross network for ad click predictions</title>
		<author>
			<persName><forename type="first">Ruoxi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingliang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ADKDD</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Neural graph collaborative filtering</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A neural influence diffusion model for social recommendation</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peijie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanjie</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richang</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiting</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="235" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Learning to Transfer Graph Embeddings for Inductive Graph based Recommendation</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Defu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richang</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
		<idno>SIGIR. 1211-1220</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Privileged Features Distillation at Taobao Recommendations</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junfeng</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changhua</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Ou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2590" to="2598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pong</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="974" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer</title>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Graphsaint: Graph sampling based inductive learning method</title>
		<author>
			<persName><forename type="first">Hanqing</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongkuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajitesh</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajgopal</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Prasanna</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Inductive matrix completion based on graph neural networks</title>
		<author>
			<persName><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Distilling structured knowledge into embeddings for explainable and accurate recommendation</title>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoran</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanning</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="735" to="743" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Rocket launching: A universal and efficient framework for training well-performing light net</title>
		<author>
			<persName><forename type="first">Guorui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Runpeng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijie</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqiang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="4580" to="4587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Functional matrix factorizations for cold-start recommendation</title>
		<author>
			<persName><forename type="first">Ke</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuang-Hong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="315" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Recommendation for New Users and New Items via Randomized Training and Mixture-of-Experts Transformation</title>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahin</forename><surname>Sefati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parsa</forename><surname>Saadatpanah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Caverlee</surname></persName>
		</author>
		<idno>SIGIR. 1121-1130</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
