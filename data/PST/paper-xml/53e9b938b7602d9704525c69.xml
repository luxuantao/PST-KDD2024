<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Boosting Prediction Accuracy on Imbalanced Datasets with SVM Ensembles</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
							<email>yliu@cs.yorku.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">York University</orgName>
								<address>
									<postCode>M3J 1P3</postCode>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aijun</forename><surname>An</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">York University</orgName>
								<address>
									<postCode>M3J 1P3</postCode>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiangji</forename><surname>Huang</surname></persName>
							<email>jhuang@cs.yorku.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">York University</orgName>
								<address>
									<postCode>M3J 1P3</postCode>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Boosting Prediction Accuracy on Imbalanced Datasets with SVM Ensembles</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D141DF2BC848777E760F0197A44E854A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning from imbalanced datasets is inherently difficult due to lack of information about the minority class. In this paper, we study the performance of SVMs, which have gained great success in many real applications, in the imbalanced data context. Through empirical analysis, we show that SVMs suffer from biased decision boundaries, and that their prediction performance drops dramatically when the data is highly skewed. We propose to combine an integrated sampling technique with an ensemble of SVMs to improve the prediction performance. The integrated sampling technique combines both over-sampling and undersampling techniques. Through empirical study, we show that our method outperforms individual SVMs as well as several other state-of-the-art classifiers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many real-world datasets are imbalanced, in which most of the cases belong to a larger class and far fewer cases belong to a smaller, yet usually more interesting class. Examples of applications with such datasets include searching for oil spills in radar images <ref type="bibr" target="#b0">[1]</ref>, telephone fraudulent detection <ref type="bibr" target="#b1">[2]</ref>, credit card fraudulent detection diagnosis of rare diseases, and network intrusion detection. In such applications, the cost is high when a classifier misclassifies the small (positive) class instances.</p><p>Despite the importance of handling imbalanced datasets, most current classification systems tend to optimize the overall accuracy without considering the relative distribution of each class. As a result, these systems tend to misclassify minority class examples when the data is highly skewed. Techniques have been proposed to handle the problem. Approaches for addressing the problem can be divided into two main directions: sampling approaches and algorithm-based approaches. Generally, sampling approaches include methods that over-sample the minority class to match the size of the majority class <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, and methods that under-sample the majority class to match the size of the minority class <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7]</ref>. Algorithmic-based approaches are designed to improve a classifier's performance based on their inherent characteristics.</p><p>This paper is concerned with improving the performance of the Support Vector Machines (SVMs) on imbalanced data sets. SVMs have gained success in many applications, such as text mining and hand-writing recognition. However, when the data is highly imbalanced, the decision boundary obtained from the training data is biased toward the minority class. Most approaches proposed to address this problem have been algorithm-based <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>, which attempt to adjust the decision boundary through modifying the decision function.</p><p>We take a complementary approach and study the use of sampling as well as ensemble techniques to improve SVM's performance. First, our observation indicates that using over-sampling alone as proposed in previous work (e.g. SMOTE <ref type="bibr" target="#b9">[10]</ref>) can introduce excessive noise and lead to ambiguity along decision boundaries. We propose to integrate the two types of sampling strategies by starting with over-sampling the minority class to a moderate extent, followed by under-sampling the majority class to the similar size. This is to provide the learner with more robust training data. We show by empirical results that the proposed sampling approach outperforms over-sampling alone irrespective of the parameter selection. We further consider using an ensemble of SVMs to boost the performance. A collection of SVMs are trained individually on the processed data, and the final prediction is obtained by combining the results from those individual SVMs. In this way, more robust results can be obtained by reducing the randomness induced by a single classifier, as well as by alleviating the information loss due to sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Sampling is a popular strategy to handle the class imbalance problem since it straightforwardly re-balances the data at the data processing stage, and therefore can be employed with any classification algorithm <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7]</ref>. As one of the successful oversampling methods, the SMOTE algorithm <ref type="bibr" target="#b10">[11]</ref> over-samples the minority class by generating interpolated data. It first searches for the Knearest-neighbors for each minority instance, and for each neighbor, randomly selects a point from the line connecting the neighbor and the instance itself, which will serve as a new minority instance. By adding the "new" minority instances into training data, it is expected that the over-fitting problem can be alleviated. SMOTE has been reported to achieve favorable results in many classification algorithms <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. Algorithm-based approaches include methods in which existing learning algorithms are tailored to improve the performance for imbalanced datasets. For example, some algorithms consider class distributions or use cost functions for decision tree inductions <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref>.</p><p>SVMs have established themselves as a successful approach for various machine learning tasks. The class imbalance issue has also been addressed in the literature. Through empirical study, Wu et al. <ref type="bibr" target="#b8">[9]</ref> report that when the data is highly imbalanced, the decision boundary determined by the training data is largely biased toward the minority class. As a result, the false negative rate that associates with the minority class might be high. To compensate for the skewness, they propose to enlarge the resolution around the decision boundary by revising kernel functions. Furthermore, Veropoulos et al. <ref type="bibr" target="#b7">[8]</ref> use pre-specified penalty constants on Lagrange multipliers for different classes; Akbani et al. <ref type="bibr" target="#b9">[10]</ref> combine SVMs with SMOTE over-sampling and cost sensitive learning. In contrast, Japkowicz et al. <ref type="bibr" target="#b14">[15]</ref> argue that SVMs are immune to the skewness of the data, because the classification decision boundary is determined only by a small quantity of support vectors. Consequently, the large volume of instances belonging to the majority class might be considered redundant. In this paper, we will demonstrate that the decision boundary changes as imbalance ratios vary, and discuss its implications.</p><p>Using an ensemble of classifiers to boost classification performance has also been reported to be effective in the context of imbalanced data. This strategy usually makes use of a collection of individually trained classifiers whose prediction results are integrated to make the final decision. The work in this direction includes that Chen et al. <ref type="bibr" target="#b5">[6]</ref> use random forest to unite the results of decision trees induced from bootstrapping the training data, and that Guo et al <ref type="bibr" target="#b3">[4]</ref> apply data boosting to improve the performance on hard examples that are difficult to classify. However, most current studies are confined to decision tree inductions instead of other classifiers, e.g, SVM. Moreover, decision-tree-based algorithms might be ill-suited for the class imbalance problem as they favor short trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Support Vector Machines</head><p>In this section we briefly describe the basic concepts in two-class SVM classification. Assume that there is a collection of n training instances T r = {x i , y i }, where x i ∈ R N and y i ∈ {-1, 1} for i = 1, . . . , n. Suppose that we can find some hyperplane which linearly separates the positive from negative examples in a feature space. The points x belonging to the hyperplane must satisfy w • x + b = 0, where w is normal to the hyperplane and b is the intercept. To achieve this, given a kernel function K, a linear SVM searches for Lagrange multiplier α i (i = 1, ..., n) in Lagrangian</p><formula xml:id="formula_0">L p ≡ 1 2 ||w|| 2 - n i=1 α i y i (x i • w + b) + n i=1 α i (1)</formula><p>such that the margin between two classes<ref type="foot" target="#foot_1">2</ref> ||w|| is maximized in the feature space <ref type="bibr" target="#b15">[16]</ref>. In addition, in the α i optimizing process, Karush Kuhn Tucker (KKT) conditions which require n i=1 α i y i = 0, must be satisfied. <ref type="foot" target="#foot_0">1</ref> To predict the class label for a new case x, we need to compute the sign of f</p><formula xml:id="formula_1">(x) = n i=1 y i α i K(x, x i ) + b.</formula><p>If the sign function is greater than zero, x belongs to the positive class, and the negative otherwise.</p><p>In SVMs, support vectors (SVs) are of crutial importance to the training set. They lie closest to the decision boundary; thus form the margin between two sides. If all other training data were removed, and training was repeated, the same separating hyperplane would still be constructed. Note that there is a Lagrange multiplier α i for each training instance. In this context, SVs correspond to those points for which α i &gt; 0; other training instances have α i = 0. This fact gives us the advantage of classifying by learning with only a small number of SVs, as all we need to know is the position of the decision boundary which lies right in the middle of the margin; other training points can be considered redundant. Further, it is of prime interest in the class imbalance problem because SVMs could be less affected by the negative instances that lie far away from the decision boundary even if there are many of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Effects of Class Imbalance on SVMs</head><p>We conducted a series of experiments to investigate how the decision boundaries are affected by the imbalance ratio, i.e., the ratio between the number of negative examples and positive examples. We start with classifying a balanced training dataset, and detect that the real decision boundary is close to the "ideal boundary", as it is almost of equal length to both sides. We then reform successive new datasets with different degrees of data skewness by removing instances from the positive and add instances to the negative. Figure <ref type="figure">1</ref> reflects the data distribution when imbalance ratios vary from 10:1 to 300:1, where crosses and circles represent the instances from positive and negative classes respectively. From Figure <ref type="figure">1</ref> (a), we find that if the imbalance ratio is moderate, the boundary will still be close to the "ideal boundary". This observation demonstrates SVMs could be robust and self-adjusting; and is thus able to alleviate the problem arising from moderate imbalance. Nonetheless, as the imbalance ratio becomes larger and larger, as illustrated in Figure <ref type="figure">1</ref> (b) and (c), the boundaries get evidently biased toward the minority class. As a consequence, making predictions with such a system may lead to a high false negative rate.  skewness. To cope with this problem, in this section, we study the use of sampling techniques to balance the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Undersampling</head><p>Under-sampling approaches have been reported to outperform over-sampling approaches in previous literatures. However, under-sampling throws away potentially useful information in the majority class; it thus could make the decision boundary trembling dramatically. For example, given the imbalance ratio as 100:1, in order to get a close match for the minority, it might be undesirable to throw away 99% of majority instances. Figure <ref type="figure">2</ref> illustrates such a scenario, where the majority class is undersampled to keep the same size as the minority, but a considerable amount of SVs lie far away from the ideal boundary y = 1. Accordingly, predicting with such SVMs may lead to low accuracies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Oversampling</head><p>Considering that simply replicating the minority instances tends to induce overfitting, using interpolated data is often preferred in the hope of supplying additional and meaningful information on the positive class. SMOTE is the method that has been mostly cited along this line. However, the improvement of integrating SVMs with the SMOTE algorithm can be limited due to its dependence on the proper selection of the number of nearest neighbors K as well as imbalance ratios. Basically, the value of K determines how many new data points will be added into the interpolated dataset. Figure <ref type="figure">3</ref> shows how the decision boundary will change with different K values. Figure <ref type="figure">3</ref> (a) shows the original class distribution while the imbalance ratio is 100:1. Figure <ref type="figure">3</ref> (b) demonstrates that the classification boundary is relatively smoothed when K has a small value; nonetheless, it is still biased toward the minority class. This is due to SMOTE actually providing little information of the minority; hence the oversampling in this case should be considered as a type of "phantom-transduction". When the interpolated dataset is considerably enlarged as K increases, as shown in Figure <ref type="figure">3</ref> (c), ambiguities could arise along the current boundary, because SMOTE makes the assumption that the instance between a positive class instance and its nearest neighbors is also positive. However  it may not be always true in practice. As a positive instance is very close to the boundary, its nearest neighbor is likely to be negative, and this possibility may increase as K and imbalance ratio become larger. Consequently, the new data instance, which actually belongs to the negative class, is mis-labeled as positive, and the induced decision boundary, as shown in Figure <ref type="figure">3</ref> (c), could be inversely distorted to the majority class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Combination of Two Types of Samplings</head><p>To address the problems arising from using each of the two types of sampling approaches alone, we integrate them together. Given an imbalance ratio, we first over-sample the minority instances with SMOTE to some extent, and then under-sample the majority class so that both sides have the same or similar amount of instances. To under-sample the majority class, we use the bootstrap sampling approach with all available majority instances, provided that the size of the new majority class is the same as that of the minority class after running SMOTE. The benefit of doing so is that this approach inherits the strength of both strategies, and alleviates the over-fitting and information loss problems.</p><p>In addition, to avoid taking risks of inducing ambuities along the decision boundary, we choose to filter out the "impure" data firstly before sampling. In this context, an instance is defined to be "impure", if and only if two of its three nearest neighbors provide different class labels other than that of itself. This idea is motivated by the Edited Nearest Neighbor Rule <ref type="bibr" target="#b6">[7]</ref>, which was originally used to remove unwanted instances from the majority. In our work, however, to further reduce the uncertainty from both classes, such a filtering process is taken on each side.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Ensemble of SVMs</head><p>In this section, we present a method that uses an ensemble of SVM classifiers integrated with a re-balancing technique that combines both over-sampling and under-sampling. Re-balancing is still necessary in this context since in learning from extremely imbalanced data, it is very likely that a bootstrap sample used to train an SVM in the ensemble is composed of few or even none of the minority instances. Hence, each component learner of the ensemble would suffer from severe skewness, and the improvement of using an ensemble would be confined. Our proposed method, called EnSVM, is illustrated in Figure <ref type="figure">4</ref>. As described in itive and negative class values. With this matrix, our performance measures are expressed as follows:</p><p>g-mean = √ a -× a + , where a -= T N T N+F P and a + = T P T P +F N ; -F-measure = 2×P recision×Recall P recision+Recall , where precision = T P T P +F P and recall = T P T P +F N .</p><p>G-mean is based on the recalls on both classes. The benefit of selecting this metric is that it can measure how balanced the combination scheme is. If a classifier is highly biased toward one class (such as the majority class), the gmean value is low. For example, if a + = 0 and a -= 1, which means none of the positive examples is identified, g-mean=0. In addition, F-measure combines the recall and precision on the positive class. It measures the overall performance on the minority class. Besides, we utilize the ROC analysis <ref type="bibr" target="#b16">[17]</ref> to assist the evaluation. A ROC curve demonstrates a trade off between true positive and false positive rates provided with different classification parameters. Informally, one point in ROC space is superior to another if it is closer to the northwest corner (TP is higher, but FP is lower). Thus, ROC curves allow for a visual comparison of classifiers: the larger the area below the ROC curve, the higher classification potential of the classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Benchmark Data</head><p>We use five datasets as our testbeds. Four of the datasets are from the UCI Machine Learning Repository and another dataset is a medical compound dataset (mcd) collected by National Cancer Institute (NCI) for discovering new compounds capable of inhibiting the HIV virus. The four UCI datasets are spambase, letter-recognition, pima-indians-diabetes and abalone. Each dataset in this study is randomly split into training and test subsets of the same size, where a stratified manner is employed to ensure that the training and test sets have the same imbalance ratio. Table <ref type="table" target="#tab_3">2</ref> shows the characteristics of the five datasets. The first three datasets (letter, pima, and spambase) are mildly imbalanced, while the next two (abalone and mcd) are very imbalanced. These datasets were carefully selected to (1) fulfill the requirements that they are obtained in real applications, (2) distinct from feature characteristics, and vary in size and imbalance ratio, and (3) maintain sufficient amount of instances in each individual class to keep the classification performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Experimental Results</head><p>In this section, we compare the performance of our proposed EnSVM method with those of five other methods: 1) single SVM without re-sampling the data, 2) single SVM with over-sampling using SMOTE <ref type="bibr" target="#b9">[10]</ref> (without applying cost functions), 3) random forest with balanced training data from under-sampling <ref type="bibr" target="#b5">[6]</ref>, 4) random forest with our combined sampling method, and 5) single SVM with our combined sampling method. In our experiments, for all the SVMs, we employed Gaussian RBF kernels of the form K(x i , x j ) = exp(-γ|x ix j |<ref type="foot" target="#foot_2">2</ref> ) of C-SVMs. For each method we repeated our experiments ten times, computed average g-mean values and F-measures. Results in terms of g-mean are shown in Table <ref type="table" target="#tab_4">3</ref>, where SVM denotes the single SVM method with the original training data, SMOTE represents oversampling the minority class and then training a system with single SVMs, RandForest 1 denotes undersampling the majority class and then making an ensemble with C4.5 decision trees, RandForest 2 denotes sampling data with our combined method, followed by forming an ensemble with C4.5, AvgSVM denotes the average performance of 10 single SVMs with our sampling method, and EnSVM is our ensemble method with the combined sampling method. For the first two datasets, the K values for SMOTE and EnSVM can only be set to be 1 since their imbalance ratio is 2:1. For each of other datasets, we test two K values: the smallest value, which always equals to 1, and the highest value. The latter will depend on the imbalance ratios of three datasets, which are 9, 39, and 99 respectively. From the results we can see that EnSVM achieves the best results on all the datasets except on the spam dataset for which RandForest 2 is the best. 2  Table <ref type="table" target="#tab_5">4</ref> shows the performance for each method in terms of F-measure. We find that EnSVM deserves the highest value on all five datasets. In particular, a big improvement is made on the datasets where the imbalance ratios are large. By comparing the results from the four SVM methods, we can see that (1) using SMOTE to over-sample the data is better than SVM without sampling;</p><p>(2) using our combined sampling method with single SVMs is better than using only over-sampling with SMOTE; and (3) using the ensemble method together with the combined sampling method achieve the best results. By comparing the two Random Forest methods, using the combined sampling method is better than using only the under-sampling method on most datasets. Moreover, between the Random Forest method and the ensemble of SVMs method, the latter performs better.</p><p>In addition to the imbalance ratio, the selection of K may also impact on the prediction accuracy of SMOTE and EnSVM. To make a better understanding, we present a ROC analysis result with the spambase dataset. This dataset is considered since it has a moderate imbalance ratio and instance volume. The original spambase has an imbalance ratio of 10; therefore, in this experiment, we test K from 1 to 9, and depict the ROC curves of the two approaches in Figure <ref type="figure">5</ref>. Clearly, compared to simply over-sampling the minority instances, EnSVM generates a better result. We also test how the g-mean value may change with different Ks in SMOTE and EnSVM. The abalone and mcd datasets are used in this case as they hold large imbalance ratios and allow K to vary in relatively large ranges. We set parameter K to vary from 1 to 39 for the abalone dataset and from 1 to 99 for the mcd dataset. As shown in Figures 6.3 (a) and (b), the prediction performance of EnSVM is superior to simply applying the SMOTE algorithm with respect to each K value. Moreover, we can see that the optimal K value can be difficult to determine in both SMOTE and EnSVM. For EnSVM, when K is small, we get better neighbors for the oversampling process, so the prediction performance can be dramatically improved. Further, when K is big, more noise is likely to be introduced, but a larger training data set is generated using EnSVM and less information is lost. Consequently, it becomes a trade off between inducing more noise and losing less information. Nonetheless, our method is better than SMOTE with all K values. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>This paper introduces a new approach to learning from imbalanced datasets through making an ensemble of SVM classifiers and combining both oversampling and under-sampling techniques. We first show in this study that using SVMs for class prediction can be influenced by the data imbalance, although SVMs can adjust itself well to some degree of data imbalance. To cope with the problem, re-balancing the data is a promising direction, but both undersampling and oversampling have limitations. In our approach, we integrate the two types of sampling strategies together. Over-sampling the minority class provides complementary knowledge for the training data, and under-sampling alleviates over-fitting problem. In addition, we make an ensemble of SVMs to enhance the prediction performance by casting a majority vote. Through extensive experiments with real application data, our proposed method is shown to be effective and better than several other methods with different data sampling methods or different ensemble methods. We are now working on a method for automatically determining the value of K based on the data set characteristics in order to optimize the performance of EnSVM.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. ROC curve of spambase dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Two-class confusion matrix Predicted Positive Predicted Negative Actual Positive TP(True Positive) FN(False Negative) Actual Negative FP(False Positive) TN(True Negative)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Benchmark datasets</figDesc><table><row><cell cols="4">Dataset Datapoints Attributes ImbalanceRatio</cell></row><row><cell>letter</cell><cell>20000</cell><cell>16</cell><cell>2:1</cell></row><row><cell>pima</cell><cell>768</cell><cell>9</cell><cell>2:1</cell></row><row><cell cols="2">spambase 3068</cell><cell>57</cell><cell>10:1</cell></row><row><cell cols="2">abalone 4280</cell><cell>8</cell><cell>40:1</cell></row><row><cell>mcd</cell><cell>29508</cell><cell>6</cell><cell>100:1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Performance in terms of g-mean</figDesc><table><row><cell cols="7">Dataset SVM SMOTE SMOTE RandForest 1 RandForest 2 AvgSVM EnSVM EnSVM</cell></row><row><cell></cell><cell cols="2">K=1 K=highest</cell><cell></cell><cell></cell><cell cols="2">K=1 K=highest</cell></row><row><cell>letter</cell><cell>0.9551 0.9552</cell><cell>0.9552</cell><cell>0.9121</cell><cell>0.9281</cell><cell cols="2">0.9563 0.9566 0.9566</cell></row><row><cell>pima</cell><cell>0.6119 0.7320</cell><cell>0.7320</cell><cell>0.7358</cell><cell>0.7002</cell><cell cols="2">0.7419 0.7503 0.7503</cell></row><row><cell>spam</cell><cell>0.8303 0.8364</cell><cell>0.8580</cell><cell>0.8593</cell><cell>0.9050</cell><cell>0.8592 0.8616</cell><cell>0.8988</cell></row><row><cell cols="2">abalone 0.6423 0.6280</cell><cell>0.8094</cell><cell>0.7358</cell><cell>0.7678</cell><cell>0.8041 0.8958</cell><cell>0.8311</cell></row><row><cell>mcd</cell><cell>0.4500 0.4496</cell><cell>0.5952</cell><cell>0.5896</cell><cell>0.5968</cell><cell>0.5931 0.5951</cell><cell>0.6039</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Performance in F-measure</figDesc><table><row><cell cols="7">Dataset SVM SMOTE SMOTE RandForest 1 RandForest 2 AvgSVM EnSVM</cell><cell>EnSVM</cell></row><row><cell></cell><cell cols="2">K=1 K=highest</cell><cell></cell><cell></cell><cell></cell><cell cols="2">K=1 K=highest</cell></row><row><cell>letter</cell><cell>0.9548 0.9549</cell><cell>0.9549</cell><cell>0.9111</cell><cell>0.9268</cell><cell cols="2">0.9406 0.9563</cell><cell>0.9563</cell></row><row><cell>pima</cell><cell>0.5664 0.7135</cell><cell>0.7135</cell><cell>0.7098</cell><cell>0.6165</cell><cell cols="2">0.7259 0.7357</cell><cell>0.7357</cell></row><row><cell>spam</cell><cell>0.8164 0.8238</cell><cell>0.8492</cell><cell>0.8512</cell><cell>0.8751</cell><cell>0.7498</cell><cell>0.8553</cell><cell>0.8950</cell></row><row><cell cols="2">abalone 0.5843 0.5659</cell><cell>0.7938</cell><cell>0.7938</cell><cell>0.7426</cell><cell cols="2">0.7875 0.8940</cell><cell>0.8190</cell></row><row><cell>mcd</cell><cell>0.3367 0.3364</cell><cell>0.5285</cell><cell>0.5285</cell><cell>0.5286</cell><cell>0.5274</cell><cell>0.5272</cell><cell>0.5415</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In the case of non-separable data, 1-norm soft-margin SVMs minimize the Lagrangian Lp = 1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>2 ||w|| 2 + C È i ξi -È i αi{yi(xi • w + b) -1 + ξi} -Èi µiξi, where ξi, i ∈[1, n]  are positive slack variables, C is selected by users with a larger C indicating a higher penalty to errors, and µi are Lagrange multipliers to enforce ξi being positive. Similarly, corresponding KKT conditions have to be met for the purpose of optimization.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>In Table</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p><ref type="bibr" target="#b2">3</ref>, from top to bottom, the optimal γ obtained empirically in using SVMs is 1.0 × 10 -2 , 5.0 × 10 -5 , 7.0 × 10 2 , and 10 2 respectively. In addition, C is set to be 1000 for each case.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>After that, we under-sample the majority class instances N times to generate N bootstrap samples so that each bootstrap sample has the same or similar size with the over-sampled positive instances. Then, each bootstrap sample (of the majority class) is combined with the over-sampled positive instances to form a training set to train an SVM. Therefore, N SVMs can be obtained from N different training sets. Finally, the N SVMs are combined to make a prediction on a test example by casting a majority vote from the ensemble of SVMs. In our experiments reported below, we set N to be 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Empirical Evaluation</head><p>In this section, we first introduce the evaluation measures used in our study, and then describe the datasets. After that, we report the experimental results that compare our proposed approach with other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Evaluation Measures</head><p>The evaluation measures used in our experiments are based on the Confusion Matrix. Table <ref type="table">1</ref> illustrates a confusion matrix for a two class problem with pos-</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Machine learning for the detection of oil spills in satellite radar images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kubat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Holte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Matwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="195" to="215" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adaptive fraud detection</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fawcett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Provost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="291" to="316" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Data mining for direct marketing: Problems and solutions</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">X</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<biblScope unit="page" from="73" to="79" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning from imbalanced data sets with boosting and data generation: the databoost-im approach</title>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Viktor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explorations</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="30" to="39" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Addressing the curse of imbalanced training sets: onesided selection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kubat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Matwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th International Conference on Machine Learning</title>
		<meeting>14th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="179" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Using random forest to learn imbalanced data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<idno>666</idno>
	</analytic>
	<monogr>
		<title level="j">Statistics Department</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>University of California at Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reduction techniques for instance-basedlearning algorithms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Martinez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="257" to="286" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Controlling the sensitivity of support vector machines</title>
		<author>
			<persName><forename type="first">K</forename><surname>Veropoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">99</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Aligning boundary in kernel space for learning imbalanced dataset</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICDM</title>
		<imprint>
			<biblScope unit="page" from="265" to="272" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Applying support vector machines to imbalanced datasets</title>
		<author>
			<persName><forename type="first">R</forename><surname>Akbani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Japkowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="39" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Smote: Synthetic minority over-sampling technique</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">O</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res. (JAIR)</title>
		<imprint>
			<biblScope unit="page" from="321" to="357" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Smoteboost: Improving prediction of the minority class in boosting</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lazarevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">O</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
		<editor>PKDD.</editor>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="107" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning when training data are costly: The effect of class distribution on tree induction</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Provost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res. (JAIR)</title>
		<imprint>
			<biblScope unit="page" from="315" to="354" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">C4.5, class imbalance, and cost sensitivity: Why under-sampling beats over-sampling</title>
		<author>
			<persName><forename type="first">C</forename><surname>Drummond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Holte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Learning from Imbalanced Datasets II held in conjunction with ICML&apos;2003</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The class imbalance problem: A systematic study</title>
		<author>
			<persName><forename type="first">N</forename><surname>Japkowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stephen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intell. Data Anal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="429" to="449" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A tutorial on support vector machines for pattern recognition</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="121" to="167" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Measuring the accuracy of diagnostic systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Swets</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">240</biblScope>
			<biblScope unit="page" from="1285" to="1293" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
