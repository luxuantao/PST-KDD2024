<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">THE APPROXIMABILITY OF CONSTRAINT SATISFACTION PROBLEMS *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Sanjeev</forename><surname>Khanna</surname></persName>
							<email>sanjeev@cis.upenn.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of CIS</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>PA</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Laboratory for Computer Science</orgName>
								<orgName type="institution">MIT</orgName>
								<address>
									<addrLine>545 Technology Square</addrLine>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>AND</roleName><forename type="first">David</forename><forename type="middle">P</forename><surname>Williamson</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Computer Science Division</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">IBM Almaden Research Center</orgName>
								<address>
									<addrLine>650 Harry Road</addrLine>
									<postCode>K53/B1, 95120</postCode>
									<settlement>San Jose</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><forename type="middle">J</forename><surname>Watson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">La</forename><forename type="middle">"</forename><surname>Sapienza</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">IEEE Computer Society Press</orgName>
								<address>
									<postCode>1997, 282-296</postCode>
									<settlement>Ulm, Germany</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">THE APPROXIMABILITY OF CONSTRAINT SATISFACTION PROBLEMS *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8689C03321C892BF92B91EBE860FEEA9</idno>
					<note type="submission">Received by the editors January 18, 1999; accepted for publication (in revised form) October 31, 2000; published electronically March 13, 2001.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>approximation algorithms</term>
					<term>approximation classes</term>
					<term>approximation-preserving reductions</term>
					<term>complete problems</term>
					<term>Boolean constraint satisfaction problems</term>
					<term>hardness of approximation AMS subject classifications. 68Q15</term>
					<term>68Q17</term>
					<term>68W25</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We study optimization problems that may be expressed as "Boolean constraint satisfaction problems." An instance of a Boolean constraint satisfaction problem is given by m constraints applied to n Boolean variables. Different computational problems arise from constraint satisfaction problems depending on the nature of the "underlying" constraints as well as on the goal of the optimization task. Here we consider four possible goals: Max CSP (Min CSP) is the class of problems where the goal is to find an assignment maximizing the number of satisfied constraints (minimizing the number of unsatisfied constraints). Max Ones (Min Ones) is the class of optimization problems where the goal is to find an assignment satisfying all constraints with maximum (minimum) number of variables set to 1. Each class consists of infinitely many problems and a problem within a class is specified by a finite collection of finite Boolean functions that describe the possible constraints that may be used.</p><p>Tight bounds on the approximability of every problem in Max CSP were obtained by Creignou [J. Comput. System Sci., 51 (1995), pp. 511-522]. In this work we determine tight bounds on the "approximability" (i.e., the ratio to within which each problem may be approximated in polynomial time) of every problem in Max Ones, Min CSP, and Min Ones. Combined with the result of Creignou, this completely classifies all optimization problems derived from Boolean constraint satisfaction. Our results capture a diverse collection of optimization problems such as MAX 3-SAT, Max Cut, Max Clique, Min Cut, Nearest Codeword, etc. Our results unify recent results on the (in-)approximability of these optimization problems and yield a compact presentation of most known results. Moreover, these results provide a formal basis to many statements on the behavior of natural optimization problems that have so far been observed only empirically.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1. Introduction. The approximability of an optimization problem is the best possible performance ratio that is achieved by a polynomial time approximation algorithm for the problem. The approximability is studied as a function of the input size and is always a function bounded from below by 1. Research in the 1990s has led to dramatic progress in our understanding of the approximability of many central optimization problems. The results cover a large number of optimization problems, deriving tight bounds on the approximability of some, while deriving "asymptotically" tight bounds on many more. 1  In this paper we study optimization problems derived from "Boolean constraint satisfaction problems" and present a complete classification of these problems based on their approximability. Our work is motivated by an attempt to unify this recent progress on the (in-)approximability of combinatorial optimization problems. In the case of positive results, i.e., bounding the approximability from above, a few paradigms have been used repeatedly and these serve to unify the results nicely. In contrast, there is a lack of similar unification among negative or inapproximability results. Inapproximability results are established by approximation-preserving reductions from hard problems, and such reductions tend to exploit every feature of the problem whose hardness is being shown, rather than isolating the "minimal" features that would suffice to obtain the hardness result. As a result inapproximability results are typically isolated and are not immediately suited for unification.</p><p>The need for a unified study is, however, quite essential at this stage. The progress in the understanding of optimization problems has shown large amounts of diversity in their approximability. Despite this diversity, natural optimization problems do seem to exhibit some noticeable trends in their behavior. However, in the absence of a terse description of known results, it is hard to extract the trends, let alone trying to provide them with a formal basis. Some such trends are described below:</p><p>• There exist optimization problems that are solvable exactly, that admit polynomial time approximation schemes (PTAS) (i.e., for every constant α &gt; 1, there exists a polynomial time α-approximation algorithm), that admit constant factor approximation algorithms, that admit logarithmic factor approximation algorithms, and that admit polynomial factor approximation algorithms. However, this list appears to be nearly exhaustive, raising the question, "Are there 'natural' optimization problems with intermediate approximability?" 2 • A number of minimization problems have an approximability of logarithmic factors. However, so far no natural maximization problem has been shown to have a similar approximability, raising the question, "Are there any 'natural' maximization problems which are approximable to within polylogarithmic factors, but no better?" • Papadimitriou and Yannakakis <ref type="bibr" target="#b40">[39]</ref> define a class of optimization problems called MAX SNP. This class has played a central role in many of the recent inapproximability results, and yet even now the class does not appear to be fully understood. The class contains a number of NP-hard problems, and for all such known problems it turns out to be the case that the approximability is bounded away from 1! This raises the natural question, "Are there any NP-hard problems in MAX SNP that admit polynomial time approximation schemes?" In order to study such questions, or even to place them under a formal setting, 1 We say that the approximability of an optimization is known asymptotically if we can determine a function f : Z → Z and constants c 1 , c 2 such that the approximability is between 1 + f (n) and 1 + c 1 f (n c 2 ). This choice is based on the common choice of an approximation preserving reduction. See Definition 2.7.</p><p>2 There are problems such as the minimum feedback arc set for which the best known approximation factor is O(log n log log n) <ref type="bibr" target="#b17">[16]</ref> and the asymmetric p-center problem, where the best known approximation factor is O(log * n) <ref type="bibr" target="#b39">[38]</ref>. However, no matching inapproximability results are known for such problems.</p><p>one needs to first specify the optimization problems in some uniform framework. Furthermore, one has to be careful to ensure that the task of determining whether the optimization problem studied is easy or hard (to, say, compute exactly) is decidable. Unfortunately, barriers such as Rice's theorem (which says this question may not in general be decidable) or Ladner's theorem (which says problems may not be just easy or hard <ref type="bibr" target="#b36">[35]</ref>) force us to severely restrict the class of problems which can be studied in such a manner.</p><p>Schaefer <ref type="bibr" target="#b43">[42]</ref> isolates one class of decision problems which can actually be classified completely. He obtains this classification by restricting his attention to "Boolean constraint satisfaction problems." A problem in this class is specified by a finite set F of Boolean functions on finitely many variables, referred to as the constraints. (These functions are specified by, say, a truth table.) A function f : {0, 1} k → {0, 1}, when applied to k variables x 1 , . . . , x k , represents the constraint f (x 1 , . . . , x k ) = 1. An instance of a constraint satisfaction problem specified by F consists of m "constraint applications" on n Boolean variables, where each constraint application is the application of one of the constraints from F to some ordered subset of the n variables. The language Sat(F) consists of all instances which have an assignment satisfying all m constraints. Schaefer describes six classes of function families such that if F is a subset of one of these classes, then the decision problem is in P; otherwise he shows that the decision problem is NP-hard.</p><p>Our setup. In this paper we consider four different optimization versions of Boolean constraint satisfaction problems. In each case the problem is specified by a family F and the instance by m constraints from F applied to n Boolean variables. The goals for the four versions vary as follows: In the problem Max CSP(F) the goal is to find an assignment that maximizes the number of satisfied constraints. Analogously in the problem Min CSP(F) the goal is to find an assignment that minimizes the number of unsatisfied constraints. Notice that while the problems are equivalent w.r.t. exact computation, their approximability may be (and often is) very different. In the problem Max Ones(F) (Min Ones(F)) the goal is to find an assignment satisfying all constraints while maximizing (minimizing) the number of variables set to 1. We also consider the weighted version of all the above problems. In the case of Weighted Max CSP(F) (Weighted Min CSP(F)) the instance includes a nonnegative weight for every constraint and the goal is to maximize (minimize) the sum of the weights of the satisfied (unsatisfied) constraints. In the case of Weighted Max Ones(F) (Weighted Min Ones(F)) the instance includes a nonnegative weight for every variable and the goal is to find an assignment satisfying all constraint maximizing (minimizing) the weight of the variables set to 1. The collection of problems {Max CSP(F) | F finite} yields the class Max CSP, and similarly we get the classes (Weighted) Min CSP, Max Ones, Min Ones.</p><p>Together these classes capture a host of interesting optimization problems. Max CSP is a subset of MAX SNP and forms a combinatorial core of the problems in MAX SNP. It also includes a number of well-studied MAX SNP-complete problems, including MAX 3-SAT, MAX 2-SAT, and Max Cut. Max Ones shows more varied behavior among maximization problems and includes Max Clique and a problem equivalent to Max Cut. Min CSP and Min Ones are closely related to each other capturing very similar problems. The list of problems expressible as one of these includes the s-t Min Cut problem, Vertex Cover, Hitting Set with bounded size sets, integer programs with two variables per inequality <ref type="bibr" target="#b26">[25]</ref>, Min UnCut <ref type="bibr" target="#b21">[20]</ref>, Min 2CNF Deletion <ref type="bibr" target="#b34">[33]</ref>, and Nearest Codeword <ref type="bibr" target="#b3">[2]</ref>. The ability to study all these different problems in a uniform framework and extract the features that make the problems easier/harder than the others shows the advantage of studying optimization problems under the constraint satisfaction framework.</p><p>We provide a complete characterization of the asymptotic approximability of every optimization problem in the classes mentioned above. For the class Max CSP such a classification was obtained by Creignou <ref type="bibr" target="#b12">[11]</ref>, who shows that every problem in the class is either solvable to optimality in polynomial time or has a constant approximability bounded away from 1. For the remaining classes we provide complete characterizations. The detailed statement of our results, comprising 22 cases, appear in Theorems 2.11-2.14. (This includes a technical strengthening of the results of Creignou <ref type="bibr" target="#b12">[11]</ref>.) In short the results show that every Max Ones problem either is solvable optimally in P, or has constant factor approximability or polynomial approximability, or it is hard to find feasible solutions. For the minimization problems, the results show that the approximability of every problem lies in one of at most seven levels. However, it does not pin down the approximability of every problem but rather highlights a number of open problems in the area of minimization that deserve further attention. In particular, it exposes a class of problems for which Min UnCut is complete, a class for which Min 2CNF Deletion is complete, and a class for which Nearest Codeword is complete. The approximability of these problems is not yet resolved.</p><p>Our results do indeed validate some of the observations about trends exhibited by optimization problems. We find that when restricted to constraint satisfaction problems, the following can be formally established. The approximability of optimization problems does come from a small number of levels; maximization problems do not have a log-approximable representative while minimization problems may have such representatives (e.g., Min UnCut). NP-hard Max CSP problems are also MAX SNPhard. We also find that weights do not play any significant role in the approximability of combinatorial optimization problems, a thesis in the work of Crescenzi, Silvestri, and Trevisan <ref type="bibr" target="#b16">[15]</ref>. <ref type="foot" target="#foot_0">3</ref>Finally, we conclude with some thoughts on directions for further work. We stress that while constraint satisfaction problems provide a good collection of core problems to work with, they are by no means an exhaustive or even near-exhaustive collection of optimization problems. Our framework lacks such phenomena as PTAS; it does not capture several important optimization problems such as the traveling salesman problem and numerous scheduling, sequencing, and graph partitioning problems. One possible reason for the nonexistence of PTAS is that in our problems the input instances have no restrictions in the manner in which constraints may be imposed on the input variables. Significant insight may be gleaned by restricting the problem instances. A widely prescribed condition is that the incidence graph on the variables and the constraints should form a planar graph. This restriction has been studied by <ref type="bibr">Khanna</ref> and Motwani <ref type="bibr" target="#b29">[28]</ref> and they show that it leads to PTAS for a general class of constraint satisfaction problems. Another input restriction of interest could be that variables are allowed to participate only in a bounded number of constraints. We are unaware of any work on this front. An important extension of our work would be to consider constraint families which contain constraints of unbounded arity (such as those included in the class Min F + Π 1 studied by <ref type="bibr">Kolaitis and Thakur [34]</ref>). Such an extension would allow us to capture problems such as Set Cover. Other directions include working with larger domain sizes (rather than Boolean domains for the variables) and working over spaces where the solution space is the set of all permutations of [n] rather than {0, 1} n .</p><p>Related work. The works of Schaefer <ref type="bibr" target="#b43">[42]</ref> and Creignou <ref type="bibr" target="#b12">[11]</ref> have already been mentioned above. We reproduce some of the results of Creignou in Theorem 2.11 with some technical strengthenings. This strengthening is described in section 2.5. Another point of difference with the result of Creignou is that our techniques allow us to directly work with the approximability of optimization problems, while in her case the results formally establish NP-hardness and the hardness of approximation can in turn be derived from them. A description of these techniques appear in section 2.6. Among other works focusing on classes showing dichotomy is that of Feder and Vardi <ref type="bibr" target="#b18">[17]</ref>, who consider the "largest" possible class of natural problems in NP that may exhibit a dichotomy. They motivate constraint satisfaction problems over larger domains and highlight a number of central open questions that lie on the path to the resolution of the complexity of deciding them. Creignou and Hermann <ref type="bibr" target="#b13">[12]</ref> show a dichotomy result analogous to Schaefer's for counting versions of constraint satisfaction problems. In the area of approximability, the works of Lund and Yannakakis <ref type="bibr" target="#b38">[37]</ref> and Zuckerman <ref type="bibr" target="#b46">[45]</ref> provide two instances where large classes of problems are shown to be hard to approximate simultaneously-to the best of our knowledge these are the only cases where the results provide hardness for many problems simultaneously. Finally we mention a few results that are directly related to the optimization problems considered here. Trevisan et al. <ref type="bibr" target="#b44">[43]</ref> provide an algorithm for finding optimal implementations (or "gadgets" in their terminology) reducing between Max CSP problems. Karloff and Zwick <ref type="bibr" target="#b28">[27]</ref> describe generic methods for finding "semidefinite relaxations" of Max CSP problems and use these to provide approximation algorithms for these problems. These results further highlight the appeal of the "constraint satisfaction" framework for studying optimization problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Definitions and results.</head><p>2.1. Constraints, constraint applications, and constraint families. We start by formally defining constraints and constraint satisfaction problems. Schaefer's work <ref type="bibr" target="#b43">[42]</ref> proposes the study of such problems as a generalization of 3-satisfiability (3-SAT). We will use the same example to illustrate the definitions below.</p><p>A constraint is a function</p><formula xml:id="formula_0">f : {0, 1} k → {0, 1}. A constraint f is satisfied by an input s ∈ {0, 1} k if f (s) = 1. A constraint family F is a finite collection of constraints {f 1 , . . . , f l }.</formula><p>For example, constraints of interest for 3-SAT are described by the constraint family</p><formula xml:id="formula_1">F 3SAT = {OR k,j : 1 ≤ k ≤ 3, 0 ≤ j ≤ k}, where OR k,j : {0, 1} k → {0, 1} denotes the constraint ¬x 1 • • • ¬x j x j+1 • • • x k . A constraint appli- cation, of a constraint f to n Boolean variables, is a pair f, (i 1 , . . . , i k )</formula><p>, where the indices i j ∈ [n] select k of the n Boolean variables to whom the constraint is applied. (Here and throughout the paper we use the notation [n] to denote the set {1, . . . , n}.) For example, to generate the clause (x 5 ¬x 3 x 2 ), we could use the constraint application OR 3,1 , (3, 5, 2) or OR 3,1 , (3, 2, 5) . Note that the applications allow the constraint to be applied to different ordered sets of variables but not literals. This distinction is an important one and is the reason that we need all the constraints OR 3,0 , OR 3,1 , etc. to describe 3-SAT. In a constraint application f, (i 1 , . . . , i k ) , we require that i j = i j ′ for j = j ′ , i.e., the variables are not allowed to be replicated within a constraint application. This is why we need both the functions OR 2,0 as well as OR 3,0 in 3-SAT.</p><p>Constraints and constraint families are the ingredients that specify an optimization problem. Thus it is necessary that their description be finite. (Notice that the description of F 3SAT is finite.) Constraint applications are used to specify instances of optimization problems (as well as instances of Schaefer's generalized satisfiability problems) and the fact that their description lengths grow with the instance size is crucially exploited here. (Notice that the description size of a constraint application used to describe a 3-SAT clause will be Ω(log n).) While this distinction between constraints and constraint applications is important, we will often blur this distinction in the rest of this paper. In particular we may often let the constraint application C = f, (i 1 , . . . , i k ) refer only to the constraint f . In particular, we will often use the expression "C ∈ F" when we mean "f ∈ F, where f is the first component of C." We now describe Schaefer's class of satisfiability problems and the optimization problems considered in this paper.</p><p>Definition 2.1 (Sat(F)).</p><p>Instance. A collection of m constraint applications of the form { f j , (i 1 (j), . . . , i kj (j)) } m j=1 on Boolean variables x 1 , x 2 , . . . , x n , where f j ∈ F and k j is the arity of f j .</p><p>Objective. Decide if there exists a Boolean assignment to the x i 's which satisfies all the constraints.</p><p>For example, the problem Sat(F 3SAT ) is the classical 3-SAT problem. Definition 2.2 (Max CSP(F) (Min CSP(F))).</p><p>Instance. A collection of m constraint applications of the form { f j , (i 1 (j), . . . , i kj (j)) } m j=1 on Boolean variables x 1 , x 2 , . . . , x n , where f j ∈ F and k j is the arity of f j .</p><p>Objective. Find a Boolean assignment to x i 's so as to maximize (minimize) the number of satisfied (unsatisfied) constraints.</p><p>In the weighted problem Weighted Max CSP(F) (Weighted Min CSP(F)) the input instance includes m nonnegative weights w 1 , . . . , w m , and the objective is to find an assignment which maximizes (minimizes) the sum of the weights of the satisfied (unsatisfied) constraints.</p><p>Definition 2.3 (Max Ones(F) (Min Ones(F))).</p><p>Instance. A collection of m constraint applications of the form { f j , (i 1 (j), . . . , i kj (j)) } m j=1 on Boolean variables x 1 , x 2 , . . . , x n , where f j ∈ F and k j is the arity of f j .</p><p>Objective. Find a Boolean assignment to x i 's which satisfies all the constraints and maximizes (minimizes) the total number of variables assigned true.</p><p>In the weighted problem Weighted Max Ones(F) (Weighted Min Ones(F)) the input instance includes n nonnegative weights w 1 , . . . , w n , and the objective is to find an assignment which satisfies all constraints and maximizes (minimizes) the sum of the weights of variables assigned true.</p><p>The class (Weighted) Max CSP is the set of all optimization problems (Weighted) Max CSP(F) for every constraint family F. The classes (Weighted) Max Ones, Min CSP, Min Ones are defined similarly.</p><p>The optimization problem Max 3 Sat is easily seen to be equivalent to Max CSP(F 3SAT ). This and the other problems Max Ones(F 3SAT ), Min CSP(F 3SAT ), and Min Ones(F 3SAT ) are considered in the rest of this paper. More interesting examples of Max Ones, Min CSP, and Min Ones problems are described in sec-tion 2.3. We start with some preliminaries on approximability that we need to state our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Approximability, reductions, and completeness.</head><p>A combinatorial optimization problem is defined over a set of instances (admissible input data); a finite set sol(x) of feasible solutions is associated with any instance. An objective function attributes an integer value to any solution. The goal of an optimization problem is, given an instance x, to find a solution y ∈ sol(x) of optimum value. The optimum value is the largest one for maximization problems and the smallest one for minimization problems. A combinatorial optimization problem is said to be an NP optimization (NPO) problem if instances and solutions can be recognized in polynomial time, solutions are polynomial-bounded in input size, and the objective function can be computed in polynomial time (see, e.g., <ref type="bibr" target="#b11">[10]</ref>).</p><p>Definition 2.4 (performance ratio). A solution s to an instance</p><formula xml:id="formula_2">I of an NPO problem A is r-approximate if it has a value V satisfying max V opt(I) , opt(I) V ≤ r.</formula><p>An approximation algorithm for an NPO problem A has performance ratio R(n) if, given any instance I of A with |I| = n, it outputs an R(n)-approximate solution.</p><p>We say that an NPO problem is approximable to within a factor R(n) if it has a polynomial time approximation algorithm with performance ratio R(n).</p><p>Definition 2.5 (approximation classes). An NPO problem A is in the class PO if it is solvable to optimality in polynomial time. A is in the class APX (resp., log-APX/poly-APX) if there exists a polynomial time algorithm for A whose performance ratio is bounded by a constant (resp., logarithmic/polynomial factor in the size of the input).</p><p>Completeness in approximation classes can be defined using the appropriate approximation-preserving reducibilities. In this paper, we use two notions of reducibility: A-reducibility and AP-reducibility. We discuss the difference between the two and the need for having two different notions after the definitions.</p><p>Definition 2.6 (A-reducibility <ref type="bibr" target="#b15">[14]</ref>). An NPO problem A is said to be Areducible to an NPO problem B, denoted A≤ A B, if two polynomial time computable functions F and G and a constant α exist such that (1) for any instance I of A, F (I) is an instance of B;</p><p>(2) for any instance I of A and any feasible solution S ′ for F (I), G(I, S ′ ) is a feasible solution for I; (3) for any instance I of A and any r ≥ 1, if S ′ is an r-approximate solution for F (I), then G(I, S ′ ) is an (αr)-approximate solution for I. Definition 2.7 (AP-reducibility <ref type="bibr" target="#b14">[13]</ref>). For a constant α &gt; 0 and two NPO problems A and B, we say that A is α-AP-reducible to B, denoted A≤ AP B, if two polynomial time computable functions F and G exist such that the following holds:</p><p>(1) For any instance I of A, F (I) is an instance of B.</p><p>(2) For any instance I of A, and any feasible solution S ′ for F (I), G(I, S ′ ) is a feasible solution for I. (3) For any instance I of A and any r ≥ 1, if S ′ is an r-approximate solution for F (I), then G(I, S ′ ) is an (1 + (r -1)α + o(1))-approximate solution for I, where the o()-notation is with respect to |I|. We say that A is AP-reducible to B if a constant α &gt; 0 exists such that A is α-APreducible to B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark.</head><p>(1) Notice that conditions (3) of both reductions preserve only the quality of an approximate solution in absolute terms (to within the specified limits) and not as functions of the instance size. For example, an A-reduction from Π to Π ′ which blows up instance size by quadratic factor and an O(n 1/3 ) approximation algorithm for Π ′ combine to give only an O(n 2/3 ) approximation algorithm for Π. <ref type="bibr" target="#b3">(2)</ref> The difference between the two reductions is the level of approximability that is preserved by them (conditions (3) in the definitions). A-reductions preserve constant factor approximability or higher, i.e., if Π is A-reducible to Π ′ and Π ′ is approximable to within a factor of r(n), then Π is approximable to within αr(n c ) for some constants α, c. This property suffices to preserve membership in APX (log-APX, poly-APX), i.e., if Π is in APX (log-APX, poly-APX), then Π ′ is also in APX (resp., log-APX, poly-APX). However, it does not preserve membership in PO or PTAS, as can be observed by setting r = 1. (3) AP-reductions are more sensitive than A-reductions. Thus if Π is AP-reducible to Π, then an r-approximate solution is mapped to an h(r)-approximate solution where h(r) → 1 as r → 1. Thus AP-reductions preserve membership in PTAS as well. However, they need not preserve membership in PO (due to the o(1)-term in their preservation of approximability). ( <ref type="formula">4</ref>) Condition (3) of the definition of AP-reductions is strictly stronger than the corresponding condition in the definition of A-reductions. Thus, every APreduction is also an A-reduction. Unfortunately, neither one of these reductions on their own suffice for our purposes. We need AP-reductions to show APX-hardness of problems, but we need the added flexibility of A-reductions for other hardness results. <ref type="bibr" target="#b6">(5)</ref> The original definitions of AP-reducibility and A-reducibility of <ref type="bibr" target="#b15">[14]</ref> and <ref type="bibr" target="#b14">[13]</ref> were more general. Under the original definitions, the A-reducibility does not preserve membership in log-APX, and it is not clear whether every APreduction is also an A-reduction. The restricted versions defined here are more suitable for our purposes. In particular, it is true that the Vertex Cover problem is APX-complete under our definition of AP-reducibility. Definition 2.8 (APX, log-APX, and poly-APX-completeness). An NPO problem Π is APX-hard if every APX problem is AP-reducible to Π. An NPO problem Π is log-APX-hard (poly-APX-hard) if every log-APX (poly-APX) problem is Areducible to Π. A problem Π is APX(log-APX, poly-APX)-complete if it is in APX (resp., log-APX, poly-APX) and it is APX (resp., log-APX, poly-APX)-hard.</p><p>The class APX contains the class MAX SNP as defined by Papadimitriou and Yannakakis <ref type="bibr" target="#b40">[39]</ref>. The containment is strict in a syntactic sense (e.g., MAX SNP does not contain any minimization problems); however, when one takes the closure of APX under AP-reductions, one obtains the class MAX SNP <ref type="bibr" target="#b30">[29]</ref>. The notion of reductions used here is also less stringent than the notion of reduction used in <ref type="bibr" target="#b40">[39]</ref>. Thus APX, APX-hardness, and APX-completeness are (mild) generalizations of the notions of MAX SNP, MAX SNP-hardness, and MAX SNP-completeness.</p><p>Most problems we consider are known/shown to be in PO or else are APXcomplete or poly-APX-complete. However, in some cases, we will not be able to establish the exact approximability of a given problem. However, we will nevertheless be able to compile all problems into a finite number of equivalence classes with some equivalence classes being defined as "problems equivalent to Π" for some problem Π of unknown approximability. The following definition captures this concept.</p><p>Definition 2.9 (Π-completeness). For NPO problems Π and Π ′ , Π ′ is said to be Π-complete if Π≤ A Π ′ and Π ′ ≤ A Π.</p><p>2.3. Problems captured by MAX CSP, MAX ONES, MIN CSP, and MIN ONES. We first specify our notation for commonly used functions.</p><p>• 0 and 1 are the functions which are always satisfied and never satisfied, respectively. Together these are the trivial functions. We will assume that all our function families do not have any trivial functions. • T and F are unary functions given by T (x) = x and F (x) = ¬x. • For a positive integer i and nonnegative integer j ≤ i, OR i,j is the function on i variables given by OR i,j (x 1 , . . . ,</p><formula xml:id="formula_3">x i ) = ¬x 1 • • • ¬x j x j+1 • • • x i . OR i = OR i,0 ; NAND i = OR i,i ; OR = OR 2 ; NAND = NAND 2 .</formula><p>• Similarly, AND i,j is given by AND i,j (x 1 , . . . ,</p><formula xml:id="formula_4">x i ) = ¬x 1 • • • ¬x j x j+1</formula><p>• • • x i . AND i = AND i,0 ; NOR i = AND i,i ; AND = AND 2 ; NOR = NOR 2 . • The function XOR i is given by XOR(x 1 , . . . ,</p><formula xml:id="formula_5">x i ) = x 1 ⊕ • • • ⊕ x i . XOR = XOR 2 . • The function XNOR i is given by XNOR(x 1 , . . . , x i ) = ¬(x 1 ⊕ • • • ⊕ x i ).</formula><p>XNOR = XNOR 2 . Now we enumerate some interesting maximization and minimization problems which are "captured" by (i.e., are equivalent to some problem in) Max CSP, Max Ones, Min CSP, and Min Ones. The following list is interesting for several reasons. First, it highlights the importance of these classes as ones that contain interesting optimization problems and shows the diversity of the problems captured by these classes. Furthermore, each of these problems turn out to be "complete" problems for the partitions they belong to. Some are even necessary for a full statement of our results. Finally, for several of the minimization problems listed below, their approximability is not yet fully resolved. We feel that these problems are somehow representative of the lack of our understanding of the approximability of minimization problems. We start with the maximization problems.</p><p>• For any positive integer k, Max kSat = Max CSP({OR i,j |i ∈ [k], 0 ≤ j ≤ i}). Max kSat is a well-studied problem and known to be MAX SNPcomplete <ref type="bibr" target="#b40">[39]</ref> for k ≥ 2. Every MAX SNP-complete problem is in APX (i.e., approximable to within a constant factor in polynomial time) <ref type="bibr" target="#b40">[39]</ref> (see also <ref type="bibr" target="#b7">[6,</ref><ref type="bibr" target="#b22">21,</ref><ref type="bibr" target="#b45">44]</ref>). Also for MAX SNP-complete problem there exists a constant α greater than 1 such that the problem is not α-approximable unless NP = P <ref type="bibr" target="#b4">[3,</ref><ref type="bibr" target="#b5">4,</ref><ref type="bibr" target="#b25">24]</ref> .</p><formula xml:id="formula_6">• For any positive integer k, Max EkSat = Max CSP({OR k,j |0 ≤ j ≤ k}).</formula><p>The problem Max EkSat is a variant of Max kSat restricted to have clauses of length exactly k. • Max Cut = Max CSP({XOR}). Max Cut is also MAX SNP-complete <ref type="bibr" target="#b40">[39]</ref>, and the best known approximation algorithm for this problem, due to <ref type="bibr" target="#b23">[22]</ref>, achieves a performance ratio of 1.14 ≈ 1/.878 • Max Clique = Max Ones(NAND). Max Clique is known to be approximable to within a factor of O(n/ log 2 n) in an n-vertex graph <ref type="bibr" target="#b10">[9]</ref> and is known to be hard to approximate to within a factor of Ω(n 1-ǫ ) for any ǫ &gt; 0 unless NP = RP <ref type="bibr" target="#b19">[18,</ref><ref type="bibr" target="#b24">23]</ref>. We now go on to the minimization problems.</p><p>• The well-known minimum s-t cut problem in directed graphs is equivalent to Weighted Min CSP(F) for F = {OR 2,1 , T, F }. This is shown in section 5.1.</p><p>This problem is well known to be solvable exactly in polynomial time.  <ref type="bibr" target="#b33">[32]</ref> and Garg, Vazirani, and Yannakakis <ref type="bibr" target="#b21">[20]</ref>. The problem is known to be MAX SNP-hard and hence not approximable to within some constant factor greater than 1. On the other hand, the problem is known to be approximable to within a factor of O(log n) <ref type="bibr" target="#b21">[20]</ref>. • Min 2CNF Deletion = Min CSP({OR, NAND}). This problem has been studied by Klein et al. <ref type="bibr" target="#b34">[33]</ref>. They show that the problem is MAX SNP-hard and that it is approximable to within a factor of O(log n log log n). • Nearest Codeword = Min CSP({XOR 3 , XNOR 3 }). This is a classical problem for which hardness of approximation results have been shown by Arora et al. <ref type="bibr" target="#b3">[2]</ref>. The Min Ones version of this problem is essentially identical to this problem. For both problems, the hardness result of Arora et al. <ref type="bibr" target="#b3">[2]</ref> shows that approximating this problem to within a factor of Ω(2 log 1-ǫ n ) is hard for every ǫ &gt; 0, unless NP ⊆ QP. No nontrivial approximation guarantees are known for this problem (the trivial bound being a factor of m, which is easily achieved since deciding if all equations are satisfiable amounts to solving a linear system). • Finally we also mention one more problem which is required to present our main theorem. Min Horn Deletion = Min CSP({OR 3,1 , T, F }). The currently known bounds on the approximability of this problem are similar to those of the Nearest Codeword, i.e., it is in poly-APX and hard to approximate to within a factor of 2 Ω(log 1-ǫ n) (see Lemma 7.21).</p><p>2.4. Properties of function families. We start with the six properties defined by Schaefer:</p><p>• A constraint f is 0-valid (resp., 1-valid) if f (0, . . . , 0) = 1 (resp., f (1, . . . , 1) = 1). • A constraint is weakly positive (resp., weakly negative) if it can be expressed as a CNF-formula having at most one negated variable (resp., at most one unnegated variable<ref type="foot" target="#foot_1">4</ref> ) in each clause. • A constraint is affine if it can be expressed as a conjunction of linear equalities over Z 2 . • A constraint is 2cnf if it is expressible as a 2CNF-formula. The above definitions extend to constraint families naturally. For instance, a constraint family F is 0-valid if every constraint f ∈ F is 0-valid. The above definitions are central to Schaefer's main theorem, restated below.</p><p>Theorem 2.10 (Schaefer's theorem <ref type="bibr" target="#b43">[42]</ref>). For any constraint family F, Sat(F) is in P if F is 0-valid or 1-valid or weakly positive or weakly negative or affine or 2cnf; otherwise deciding Sat(F) is NP-hard.</p><p>We use the shorthand "F is (not) decidable" to say that deciding membership in Sat(F) is solvable in P (is NP-hard). Abusing our vocabulary slightly, we say Max Ones(F) (or Min Ones(F)) is not decidable to indicate that determining if a given instance of this problem has a feasible solution is NP-hard.</p><p>We need to define some additional properties to describe the approximabilities of the optimization problems we consider:</p><formula xml:id="formula_7">• f is 2-monotone if f (x 1 , . . . , x k ) is expressible as (x i1 • • • x ip ) (¬x j1 • • • ¬x jq )</formula><p>for some p, q ≥ 0, (p, q) = (0, 0) (i.e., f is expressible as a DNF-formula with at most two terms-one containing only positive literals and the other containing only negative literals). • A constraint is width-2 affine if it is expressible as a conjunction of linear equations over Z 2 such that each equation has at most two variables. • A constraint is strongly 0-valid if it is satisfied by all assignments with at most one variable set to 1. (Note that a strongly 0-valid constraint is also 0-valid.) • A constraint f is IHS-B+ (for implicative hitting set-bounded+) if it is expressible as a CNF formula, where the clauses are of one of the following types:</p><formula xml:id="formula_8">x 1 • • • x k for some positive integer k ≤ B, or ¬x 1 x 2 , or ¬x 1 .</formula><p>IHS-B-constraints and constraint families are defined analogously (with every literal being replaced by its complement). A family is an IHS-B family if the family is an IHS-B+ family or an IHS-B-family. We use the following shorthand for the above families: (1) F 0 is the family of 0-valid constraints; (2) F 1 is the family of 1-valid constraints; (3) F S0 is the family of strongly 0-valid constraints; (4) F 2M is the family of 2-monotone constraints; (5) F IHS is the family of IHS-B constraints; (6) F 2A is the family of width-2 affine constraints; (7) F 2CNF is the family of 2CNF constraints; (8) F A is the family of affine constraints; (9) F WP is the family of weakly positive constraints; (10) F WN is the family of weakly negative constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Main results.</head><p>We now present the main results of this paper. A pictorial representation is available in Appendices B.1, B.2, B.3, and B.4. All theorems are stated assuming that F has no trivial constraints, i.e., constraints that are always satisfied or never satisfied. The first theorem is a minor strengthening of Creignou's theorem <ref type="bibr" target="#b12">[11]</ref> so as to cover problems such as Max EkSat. The remaining theorems cover Max Ones, Min CSP, and Min Ones, respectively.</p><p>Theorem 2.11 (Max CSP classification). For any constraint set F, the problem (Weighted) Max CSP(F) is always either in PO or is APX-complete. Furthermore, it is in PO if and only if F is 0-valid or 1-valid or 2-monotone.</p><p>Theorem 2.12 (Max Ones classification). For any constraint set F, the problem (Weighted) Max Ones(F) is either in PO or is APX-complete or poly-APXcomplete or decidable but not approximable to within any factor or not decidable. Furthermore,</p><p>(1) if F is 1-valid or weakly positive or affine with width-2, then (Weighted)</p><formula xml:id="formula_9">Max Ones(F) is in PO; (2) otherwise if F is affine, then (Weighted) Max Ones(F) is APX-complete;</formula><p>(3) otherwise if F is strongly 0-valid or weakly negative or 2CNF, then (Weighted)</p><p>Max Ones(F) is poly-APX-complete; (4) otherwise if F is 0-valid, then Sat(F) is in P but finding a solution of positive value is NP-hard;</p><p>(5) otherwise finding a feasible solution to (Weighted) Max Ones(F) is NPhard. Theorem 2.13 (Min CSP classification). For any constraint set F, the problem (Weighted) Min CSP(F) is in PO or is APX-complete or Min UnCut-complete or Min 2CNF Deletion-complete or Nearest Codeword-complete or Min Horn Deletion-complete or even deciding if the optimum is zero is NP-hard. Furthermore,</p><p>(</p><formula xml:id="formula_10">) if F is 0-valid or 1-valid or 2-monotone, then (Weighted) Min CSP(F) is in PO; (2) otherwise if F is IHS-B, then (Weighted) Min CSP(F) is APX-complete; (3) otherwise if F is width-2 affine, then (Weighted) Min CSP(F) is Min UnCut-complete; (4) otherwise if F is 2CNF, then (Weighted) Min CSP(F) is Min 2CNF Deletion-complete; (5) otherwise if F is affine, then (Weighted) Min CSP(F) is Nearest Codeword-complete;<label>1</label></formula><p>) otherwise if F is weakly positive or weakly negative, then (Weighted) Min CSP(F) is Min Horn Deletion-complete; (7) otherwise deciding if the optimum value of an instance of (Weighted) Min CSP(F) is zero is NP-complete. Theorem 2.14 (Min Ones classification). For any constraint set F, the problem (Weighted) Min Ones(F) is either in PO or APX-complete or Nearest Codeword-complete or Min Horn Deletion-complete or poly-APX-complete or inapproximable to within any factor or not decidable. Furthermore,</p><p>(1) if F is 0-valid or weakly negative or width-2 affine, then (Weighted</p><formula xml:id="formula_12">) Min Ones(F) is in PO; (2) otherwise, if F is 2CNF or IHS-B, then (Weighted) Min Ones(F) is APX-complete; (3) otherwise if F is affine, then Min Ones(F) is Nearest Codeword-complete; (4) otherwise if F is weakly positive, then (Weighted) Min Ones(F) is Min Horn Deletion-complete; (5) otherwise if F is 1-valid, then Min Ones(F) is poly-APX-complete and</formula><p>Weighted Min Ones(F) is decidable but hard to approximate to within any factor; (6) otherwise finding any feasible solution to (Weighted) Min Ones(F) is NPhard.</p><p>2.6. Techniques. Two simple ideas play an important role in this paper. First is the notion of an implementation which shows how to use the constraints of a family F to enforce constraints of a different family F ′ , thereby laying the groundwork of a reduction among problems. The notion of an implementation is inspired by the notion of gadgets formalized by Bellare, Goldreich, and Sudan <ref type="bibr" target="#b9">[8]</ref>, who in our language define implementations for specific pairs of function families (F, F ′ ). In this work we unify their definition, so as to make it work for arbitrary pairs of function families. This definition of implementation also finds applications in the work of Trevisan et al. <ref type="bibr" target="#b44">[43]</ref>, who, in our language, show uniform methods for searching for efficient implementations for pairs of function families (F, F ′ ).</p><p>A second simple idea we exploit here is that of working with weighted versions of optimization problems. Even though our primary concerns were only the approximability of the unweighted versions of problems, many of our results use as intermediate steps the weighted versions of these problems. The weights allow us to manipulate problems more locally. However, simple and well-known ideas eventually allow us to get rid of the weights, thereby yielding hardness of the unweighted problem as well. As a side-effect we also show that the unweighted and weighted problems are equally hard to approximate in all the relevant optimization problems. This extends to minimization problems the results of Crescenzi, Silvestri, and Trevisan <ref type="bibr" target="#b16">[15]</ref>.</p><p>The definitions of implementations and weighted problems follow in section 3. Section 4 shows some technical results showing how we exploit the fact that we have functions which don't exhibit some property. The results of this section play a crucial role in all the hardness results. This sets us up for the proofs of our main theorems. In section 5 we show the containment results and hardness results for Max CSP. Similarly sections 6, 7, and 8 deal with the classes Max Ones, Min CSP, and Min Ones, respectively.</p><p>3. Implementations. We now describe the main technique used in this paper to obtain hardness of approximation results. Suppose we want to show that for some constraint set F, the problem Max CSP(F) is APX-hard. We will start with a problem that is known to be APX-hard, such as Max Cut, which turns out to be Max CSP({XOR}). We will then wish to reduce this problem to Max CSP(F).</p><p>The main technique we use to do this is to "implement" the constraint XOR using constraints from the constraint set F. We show how to formalize this notion next and then show how this translates to approximation-preserving reductions.</p><p>Definition 3.1 (implementation). A collection of constraint applications C 1 , . . . , C m over a set of variables x = {x 1 , . . . , x p } called primary variables and y = {y 1 , . . . , y q } called auxiliary variables is an α-implementation of a constraint f (x) for a positive integer α if the following conditions are satisfied:</p><p>(1) For any assignment to x and y, at most α constraints from C 1 , . . . , C m are satisfied.</p><p>(2) For any x such that f (x) = 1, there exists y such that exactly α constraints are satisfied. (3) For any x, y such that f (x) = 0, at most (α -1) constraints are satisfied. Definition 3.2 (strict/perfect implementations). An α-implementation is a strict α-implementation if for every x such that f (x) = 0, there exists y such that exactly (α -1) constraints are satisfied. An α-implementation (not necessarily strict) is a perfect implementation if α = m.</p><p>We say that a constraint set F (strictly/perfectly) implements a constraint f if there exists a (strict/perfect) α-implementation of f using constraints of F for some α &lt; ∞. We use the notation F=⇒ α f to denote that F α-implements f , and F=⇒f to denote that F implements f . Similarly we use the notation F s/p =⇒ f to denote that F implements f strictly/perfectly. The above notation is also extended to allow the target to be a family of functions. For instance, F=⇒F ′ denotes that F implements every function in F ′ .</p><p>Remark. The definition of <ref type="bibr" target="#b9">[8]</ref> defined (nonstrict and nonperfect) implementations for specific choices of f and F. For each choice they provided a separate definition. We unify their definitions into a single one. Furthermore, as we will show later, the use of strictness and/or perfectness greatly enhance the power of implementations. These aspects are formalized for the first time here.</p><p>A constraint f 1-implements itself strictly and perfectly ({f } s/p =⇒ 1 f ). Some more examples of strict and/or perfect implementations are given below.</p><formula xml:id="formula_13">Proposition 3.3. {XOR} s/p =⇒ 2 XNOR.</formula><p>Proof. The constraints XOR(x, z Aux ) and XOR(y, z Aux ) perfectly and strictly implement the constraint XNOR(x, y).</p><formula xml:id="formula_14">Proposition 3.4. If f (x) = f 1 (x) • • • f k (x), then {f 1 , . . . , f k } p =⇒ k f . Proof. The collection {f 1 (x), . . . , f k (x)} is a perfect (but not necessarily strict) k-implementation of f (x).</formula><p>The following lemma shows that the implementations of constraints compose together if they are strict or perfect.</p><p>Lemma 3.5.</p><formula xml:id="formula_15">If F a s =⇒ F b and F b s =⇒ F c , then F a s =⇒ F c .</formula><p>An analogous result also holds for perfect implementations.</p><p>Proof. It suffices to consider the case when F c consists of a single function f . Furthermore, we observe that it suffices to prove the following simpler assertion (to prove the lemma):</p><formula xml:id="formula_16">If F s =⇒ g and F ∪ {g} s =⇒ f , then F s =⇒ f . To see that this suffices, let F b = {g 1 , . . . , g l }. Define F 0 = F a , F i = F a ∪ {g 1 , . . . , g i }. Note that by hypothesis we have F l s =⇒ f and F i s =⇒ g i+1 and F l s =⇒ f . The assertion above says that if F i+1 s =⇒ f , then F i s =⇒ f . Thus by induction F 0 s =⇒ f . We now prove the assertion: If F s =⇒ g and F ∪ {g} s =⇒ f , then F s =⇒ f . Let C 1 , .</formula><p>. . , C m1 be constraint applications from F ∪ {g} on variables x, y giving an α 1 -implementation of f (x) with x being the primary variables. Let C ′ 1 , . . . , C ′ m2 be constraint applications from F on variable set x ′ , z ′ yielding an α 2 -implementation of g(x ′ ). Furthermore, let the first β constraints of C 1 , . . . , C m1 be applications of the constraints g.</p><p>We create a collection of m 1 + β(m 2 -1) constraints from F on a set of variables x, y, z ′ 1 , . . . , z ′ β , where x and y are the original variables and z ′ 1 , . . . , z ′ β are new sets of disjoint auxiliary variables, i.e., the vectors z ′ i and z ′ j do not share any variables if i = j.</p><p>The m 1 + β(m 2 -1) constraints introduced are as follows. We include the constraint applications C β+1 , . . . , C m1 on variables x, y and for every constraint application C j , for j ∈ {1, . . . , β}, on variables v j (which is a subset of variables from x, y), we place the constraints C ′ 1,j , . . . , C ′ m2,j on variable set v j , z ′ j with z ′ j being the auxiliary variables.</p><p>We now show that this collection of constraints satisfies properties (1)-( <ref type="formula">3</ref>) from Definition 3.1 with α = α 1 + β(α 2 -1). Additionally we show that perfectness and/or strictness is preserved. We start with properties (1) and <ref type="bibr" target="#b4">(3)</ref>.</p><p>Consider any assignment to x satisfying f . Then any assignment to y satisfies at most α 1 constraints from the set C 1 , . . . , C m1 . Let γ of these be from the set C 1 , . . . , C β . Now for every j ∈ {1, . . . , β} any assignment to z ′ j satisfies at most α 2 of the constraints C ′ 1,j , . . . , C ′ m2,j . Furthermore, if the constraint C j was not satisfied by the assignment to x, y, then at most α 2 -1 constraints are satisfied. Thus the total number of constraints satisfied by any assignment is at most</p><formula xml:id="formula_17">γα 2 + (β -γ)(α 2 - 1) + (α 1 -γ) = α 1 + β(α 2 -1)</formula><p>. This yields property <ref type="bibr" target="#b2">(1)</ref>. Property (3) is achieved similarly.</p><p>We now show that if the α 1 -and α 2 -implementations are perfect we get property (2) with perfectness. In this case, for any assignment to x satisfying f , there exists an assignment to y satisfying C 1 , . . . , C m1 . Furthermore, for every j ∈ {1, . . . , β}, there exists an assignment to z ′ j satisfying all the constraints C ′ 1,j , . . . , C ′ m2,j . Thus there exists an assignment to x, y, z ′ 1 , . . . , z ′ β satisfying all m 1 + β(m 2 -1) constraints. This yields property (2) with perfectness.</p><p>Finally we consider the case when the α 1 -and α 2 -implementations are strict (but not necessarily perfect) and show that in this case the collection of constraints above also satisfies property (2) with strictness. Given an assignment to x satisfying f there exists an assignment to y satisfying α 1 constraints from C 1 , . . . , C m1 . If this assignment satisfied γ clauses from the set C 1 , . . . , C β and α 1γ constraints from the set C β+1 , . . . , C m1 , then for every j ∈ {1, . . . , β} such that the clauses C j is satisfied by this assignment to x, y, there exists an assignment to z ′ j satisfying α 2 clauses from the set C ′ 1,j , . . . , C ′ m2,j . Furthermore, for the remaining values of j ∈ {1, . . . , β} there exists an assignment to the variables z ′ j satisfying α 2 -1 of the constraints C ′ 1,j , . . . , C ′ m2,j (here we are using the strictness of the α 2 -implementations). This setting to y, z ′ 1 , . . . ,</p><formula xml:id="formula_18">z ′ β satisfies γα 2 + (β -γ)(α 2 -1) + α 1 -γ = α 1 + β(α 2 -1)</formula><p>of the m constraints. This yields property <ref type="bibr" target="#b3">(2)</ref>. A similar analysis can be used to show the strictness.</p><p>Next we show a simple monotonicity property of implementations. Lemma 3.6. For integers α, α ′ with α ≤ α ′ , if F=⇒ α f , then F=⇒ α ′ f . Furthermore, strictness and perfectness are preserved under this transformation.</p><p>Proof. Let constraint applications C 1 , . . . , C m from F on x, y form an α-implementation of f (x). Let g be any constraint from F and let k be the arity of g. Let C m+1 , . . . , C m+α ′ -α be α ′α applications of the constraint g on new variables z = {z 1 , . . . , z k }. Then the collection of constraints C 1 , . . . , C m+α ′ -α on variable set x, y, z form an α ′ -implementation of f . Furthermore, the transformation preserves strictness and perfectness.</p><p>3.1. Reduction from strict implementations. Here we show how strict implementations are useful in establishing AP-reducibility among Max CSP problems. However, first we need a simple statement about the approximability of Max CSP problems.</p><p>Proposition 3.7 (see <ref type="bibr" target="#b40">[39]</ref>). For every constraint family F there exists a constant k such that given any instance I of Weighted Max CSP(F) with constraints of total weight W , a solution satisfying constraints of weight W/k can be found in polynomial time.</p><p>Proof. The proposition follows from the proof of Theorem 1 in <ref type="bibr" target="#b40">[39]</ref> which shows the above for every MAX SNP problem. (Note, in particular, that a random assignment satisfies a constant fraction of Weighted Max CSP(F) instance, and such an assignment can be found deterministically by using the method of conditional probabilities.) Lemma 3.8.</p><formula xml:id="formula_19">If F ′ s =⇒ F, then Max CSP(F) ≤ AP Max CSP(F ′ ).</formula><p>Proof. The reduction uses Proposition 3.7 above. Let β be a constant such that given an instance I of Max CSP(F) with m constraints, an assignment satisfying m β constraints can be found in polynomial time.</p><p>Recall that we need to show polynomial time computable functions F and G such that F maps an instance I of Max CSP(F) to an instance of Max CSP(F ′ ), and G maps a solution to F (I) back to a solution of I.</p><p>Given an instance I on n variables and m constraints, the mapping F simply replaces every constraint in I (which belongs to F) with a strict α-implementation using constraints of F ′ for some constant α. (Notice that by Lemma 3.6 some such α does exist.) The mapping retains the original n variables of I as primary variables and uses m independent copies of the auxiliary variables-one independent copy for every constraint in I.</p><p>Let x, y be an r-approximate solution to the instance F (I), where x denotes the original variables of I and y denotes the auxiliary variables introduced by F . The mapping G uses two possible solutions and takes the better of the two: the first solution is x; and the second solution x ′ is the solution which satisfies at least m/β of the constraints in I. G outputs the solution which satisfies more constraints.</p><p>We now show that an r-approximate solution leads to an r ′ -approximate solution, where r ′ ≤ 1 + γ(r -1) for some constant γ. Let opt denote the value of the optimum to I. Then the optimum of F (I) is exactly opt+m(α-1). This computation uses the fact that for every satisfied constraint in the optimal assignment to I, we can satisfy α constraints of its implementation by choosing the auxiliary variables appropriately (from properties (1) and (2) of Definition 3.1); and for every unsatisfied constraint exactly α -1 constraints of its implementation can be satisfied (from property (3) and strictness of the implementation). Thus the solution x, y satisfies at least 1 r (opt + m(α -1)) constraints of F (I). Thus x satisfies at least 1 r (opt + m(α -1))m(α -1) constraints in I. (Here we use properties ( <ref type="formula" target="#formula_10">1</ref>) and (3) of Definition 3.1 to see that there must be at least 1 r (opt + m(α -1))m(α -1) constraints of I in whose implementations exactly α constraints must be satisfied.) Thus the solution output by G satisfies at least</p><formula xml:id="formula_20">max 1 r (opt + m(α -1)) -m(α -1), m β</formula><p>constraints. Using the fact that max{a, b} ≥ λa + (1λ)b for any λ ∈ [0, 1] and using λ = r r+β(α-1)(r-1) , we lower bound the above expression by</p><formula xml:id="formula_21">opt r + β(α -1)(r -1)</formula><p>.</p><p>Thus</p><formula xml:id="formula_22">r ′ ≤ opt opt/(r + β(α -1)(r -1)) = r + β(α -1)(r -1) = 1 + (β(α -1) + 1)(r -1).</formula><p>Thus we find that G maps r-approximate solutions of F (I) to (1+γ(r-1))-approximate solutions to I for γ = β(α -1) + 1 &lt; ∞ as required.</p><p>3.2. Reductions from perfect implementations. We now show how to use perfect implementations to get reductions. Specifically we obtain reductions among Weighted Max Ones, Weighted Min Ones, and Min CSP problems.</p><p>Lemma 3.9.</p><formula xml:id="formula_23">If F ′ p =⇒ F, then Weighted Max Ones(F) (Weighted Min Ones(F)) is AP-reducible to Weighted Max Ones(F ′ ) (resp., Weighted Min Ones(F ′ )).</formula><p>Proof. Again we need to show polynomial time computable functions F and G such that F maps an instance I of Weighted Max Ones(F) (Weighted Min Ones(F)) to an instance of Weighted Max Ones(F ′ ) (Weighted Min Ones(F)), and G maps a solution to F (I) back to a solution of I.</p><p>Given an instance I on n variables and m constraints, the mapping F simply replaces every constraint in I (which belongs to F) with a perfect α-implementation using constraints of F ′ for some constant α. (Notice that by Lemma 3.6 some such α does exist.) The mapping retains the original n variables of I as primary variables and uses m independent copies of the auxiliary variables-one independent copy for every constraint in I. Furthermore, F (I) retains the weight of the primary variables from I and associates a weight of zero with all the newly created auxiliary variables. Given a solution to F (I), the mapping G is simply the projection of the solution back to the primary variables. It is clear that every feasible solution to I can be extended into a feasible solution to F (I) such that opt(I) = opt(F (I)). Furthermore, the mapping G maps feasible solutions to F (I) into feasible solutions to I with the same objective. (This is where the perfectness of the implementations is being used.) Thus the optimum of F (I) equals the value of the optimum of I and given an r-approximate solution to F (I), the mapping G yields an r-approximate solution to I.</p><p>Lemma 3.10. If F ′ p =⇒ F, then Min CSP(F) ≤ A Min CSP(F ′ ). Proof. Let α be large enough so that any constraint from F has a perfect αimplementation using constraints from F ′ . Let I be an instance of Min CSP(F) and let I ′ be the instance of Min CSP(F ′ ) obtained by replacing each constraint of I with the respective α-implementation. Once again each implementation uses the original set of variables for its primary variables and uses its own independent copy of the auxiliary variables. Note that the optimum of I ′ may be as high as αo if o is the optimum of I (since the implementations are not strict). It is easy to check that any assignment for I ′ of cost V yields an assignment for I whose cost is between V /α and V . In particular, if the solution is an r-approximate solution to I ′ , then V ≥ o αr and thus it induces a solution that is at least an (αr)-approximate solution to I. (Note that if the implementations were strict, we would have obtained an AP-reduction by the above.) 3.3. Weighted vs. unweighted problems. Lemma 3.9 crucially depends on its ability to work with weighted problems to obtain reductions. The following lemma shows that in most cases showing hardness for weighted problems is sufficient. Specifically it shows that as long as a problem is weakly approximable, its weighted and unweighted versions are equivalent. The result uses a similar result from Crescenzi, Silvestri, and Trevisan <ref type="bibr" target="#b16">[15]</ref>, who prove that for a certain class of problems in poly-APX that they term "nice," weighted problems AP-reduce to problems with polynomially bounded integral weights. (We include a sketch of their proof, specialized to our case for the sake of completeness.) Using this result we scale all weights down to small integers and then simulate the small integral weights by replication of clauses and/or variables. (We note that the little-oh slackness in the definition of AP-reduction is exploited in this step.) Lemma 3.11. For every family F, if Weighted Max Ones(F) is in poly-APX, then Weighted Max Ones(F) AP-reduces to Max Ones(F). Analogous results hold for Min CSP(F), Max CSP(F), and Min Ones(F).</p><p>Proof. Fix a family F. We first reduce Weighted Max Ones(F) to Weighted Max Ones(F) restricted to instances with polynomially bounded positive integer weights, provided Weighted Max Ones(F) is in poly-APX. This step uses a scaling idea as in <ref type="bibr" target="#b16">[15,</ref><ref type="bibr">Theorem 4]</ref>. Essentially the same proof also works for the cases of Weighted Max CSP(F), Weighted Min CSP(F), or Weighted Min Ones(F). Given an instance I = (x, C, w) of Weighted Max Ones(F), we will define a new vector of weights w ′ and use this to define a new instance I ′ = (x, C, w ′ ) of Weighted Max Ones(F) with polynomially bounded weights. Let A be an p(n)approximation algorithm for Weighted Max Ones(F), and let t be the value of the solution returned by A on I. We let N = n 2 (p(n)) 2 + np(n), and let w ′′ i = wi•N t + 1, and finally let</p><formula xml:id="formula_24">w ′ i = min{w ′′ i , N • p(n) + 1}.</formula><p>It is clear that the weights w ′ i are polynomially bounded. Furthermore, note that if w ′ i &lt; w ′′ i , then no feasible solution to I (or I ′ ) can have x i set to 1, since any such solution would have value at least w i &gt; t • p(n), contradicting the assumption that A is a p(n)-approximation algorithm. Thus, in particular, we have opt(I ′ ) ≥ (N/t) • opt(I). Given an rapproximate solution s ′ to I ′ we return the better of the solutions s ′ and the solution returned A as the solution to I. It is clear that if r ≥ p(n), then the returned solution is still an r-approximate solution. Below we see that an r-approximate solution to I ′ , with r ≤ p(n), is also an (r + 1/n)-approximate solution to I of value at least</p><formula xml:id="formula_25">(t/N ) • (opt(I ′ )/r) -n) ≥ opt(I)/r -(nt/N ) ≥ opt(I)/r -(n • opt(I)/N ) ≥ opt(I) 1 r - 1 nr 2 + r = opt(I)/(r + 1/n).</formula><p>This concludes the first step of the reduction. In the next step we give an AP-reduction from the class of problems with polynomially bounded weights to the unweighted case.</p><p>We start with the case of Weighted Max CSP(F) first. Given an instance of Weighted Max CSP(F) on variables x 1 , . . . , x n , constraints C 1 , . . . , C m , and polynomially bounded integer weights w 1 , . . . , w m , we reduce it to the unweighted case by replication of constraints. Thus the reduced instance has variables x 1 , . . . , x n and constraint {{C j i } wi j=1 } m i=1 , where constraint C j i = C i . It is clear that the reduced instance is essentially the same as the instance we started with. Similarly we reduce Weighted Min CSP(F) to Min CSP(F).</p><p>Given an instance I of Weighted Max Ones(F) on variables x 1 , . . . , x n , constraints C 1 , . . . , C m , and weights w 1 , . . . , w n , we create an instance I ′ of Max Ones(F) on variables {{y j i } wi j=1 } n i=1 . For every constraint C j of I of the form f (x i1 , . . . , x i k ), and for every j ∈ {1, . . . , k} and n j ∈ {1, . . . , w ij }, we impose the constraints f (y n1 i1 , . . . , y n k i k ). We now claim that the reduced instance is essentially equivalent to the instance we started with. To see this, notice that given any feasible solution y to the instance I ′ , we may convert it to another feasible solution y ′ in which, for every i, all the variables {(y ′ ) j i |j = 1, . . . , w i } have the same assignment by setting (y ′ ) j i to 1 if any of the variables y j ′ i , j ′ = 1, . . . , w i , is set to 1. Notice that this preserves feasibility and increases only the contribution to the objective function. The assignment y ′ now induces an assignment to x with the same value of the objective function. Thus the reduced instance is essentially equivalent to the original one. This concludes the reduction from Weighted Max Ones(F) to Max Ones(F). The reduction from Weighted Min Ones(F) to Min Ones(F) is similar.</p><p>4. Characterizations: New and old. In this section we characterize some of the properties of functions that we study. Most of the properties are defined so as to describe how a function behaves if it exhibits the property. For the hardness results, however, we need to see how to exploit the fact that a function does not satisfy some given property. For this we would like to see some simple witness to the fact that the function does not have a given property. As an example consider the affineness property. If a function is affine, it is easy to see how to use this property. What will be important to us is whether there exists a simple witness to the fact that a function f is not affine. Schaefer <ref type="bibr" target="#b43">[42]</ref> provides such a characterization: If a function is not affine, then there exist assignments s 1 , s 2 , and s 3 that satisfy f such that s 1 ⊕ s 2 ⊕ s 3 does not satisfy f . This is exploited by Schaefer in his classification theorem (and by us, in our classifications). In this section, we describe other such characterizations and the implementations that are obtained from them. First we introduce some more definitions and notations that we will be used in the rest of the paper.</p><p>4.1. Definitions and notations. For s ∈ {0, 1} k , we let s ∈ {0, 1} k denote the bitwise complement of s. For a constraint f of arity k, let f -be the constraint  </p><formula xml:id="formula_26">f -(s) = f (s). For a constraint family F, let F -= {f -: f ∈ F}. For s 1 , s 2 ∈ {0, 1} k , s 1 ⊕ s 2 denotes</formula><formula xml:id="formula_27">4.1 (C-closed). A constraint f is C-closed (complementation-closed) if for every assignment s, f (s) = f (s). Definition 4.2 (existential zero/existential one). A constraint f is an existential zero constraint if f (0) = 1 and f (1) = 0. A constraint f is an existential one constraint if f (0) = 0 and f (1) = 1.</formula><p>The terminology above is motivated by the fact that an existential zero constraint application f (x 1 , . . . , x k ) forces at least one of the variables to be zero (while an all zero assignment definitely satisfies the application).</p><p>Every constraint f can be expressed as the conjunction of disjuncts. This representation of a function is referred to as the conjunctive normal form (CNF) representation of f . Alternately, a function can also be represented as a disjunction of conjuncts and this representation is called the disjunctive normal form (DNF) representation.</p><p>A partial setting to the variables of f that fixes the value of f to 1 is called a term of f . A partial setting that fixes f to 0 is called a clause of f . We refer to the terms and clauses in a functional form, i.e., we say OR 3,1 (x 1 , x 2 , x 3 ) = x 1 x 2 ¬x 3 is a clause of f (x 1 , . . . , x p ) if setting x 1 = x 2 = 0 and x 3 = 1 fixes f to being 0. Similarly we use the AND i,j to denote the terms. Notice that a DNF (CNF) representation of f can be obtained by expressing as the conjunction (disjunction) of its terms (clauses).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4.3 (minterm/maxterm).</head><p>A partial setting to a subset of the variables of f is a minterm if it is a term of f and no restriction of the setting to any strict subset of the variables fixes the value of f . Analogously a clause of f is a maxterm if it is a minimal setting to the variables of f so as to fix its value to 0.</p><p>As in the case of terms and clauses, we represent minterms and maxterms functionally, i.e., using OR i,j and AND i,j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4.4 (basis).</head><p>A constraint family F ′ is a basis for a constraint family F if any constraint of F can be expressed as a conjunction of constraints drawn from F ′ . Thus, for example, the basis for affine constraints is the set {XOR p |p ≥ 1} ∪ {XNOR p |p ≥ 1}. The basis for width-2 affine constraints is the set F = {XOR, XNOR, T, F }, and the basis for 2CNF constraints is the set</p><formula xml:id="formula_28">F = {OR 2,0 , OR 2,1 , OR 2,2 , T, F }.</formula><p>The definition of a basis is motivated by the fact that if F ′ is a basis for F, then F ′ can perfectly implement every function in F (see Proposition 3.4).</p><p>4.2. 0-validity and 1-validity. The characterization of 0-valid and 1-valid functions is obvious. We now show what can be implemented with functions that are not 0-valid and not 1-valid. Lemma 4.5. Let f be a nontrivial constraint which is C-closed and is not 0-valid (or equivalently not 1-valid). <ref type="foot" target="#foot_2">5</ref> Then {f } s/p =⇒ XOR. Proof. Let k denote the arity of f and let k 0 and k 1 , respectively, denote the maximum number of 0's and 1's in any satisfying assignment for f ; clearly k 0 = k 1 . Now let S x = {x 1 , . . . , x 3k } and S y = {y 1 , . . . , y 3k } be two disjoint sets of 3k variables each. In the first phase of the proof, we place a large number of constraints on the variables of S x and S y that ends up implementing perfectly, but not necessarily strictly, the constraints XOR(x i , y j ) for every i and j. In the second phase, we will introduce two new variables x and y and augment the constraints so as to implement the constraint XOR(x, y) perfectly and strictly.</p><p>We start by placing the constraint f on a large collection of inputs as follows: For every satisfying assignment s, we place 3k i 3k k-i constraints on the variable set S x ∪ S y such that every i-variable subset of S x appears in place of 0's in s and every (ki) variable subset of S y appears in place of 1's in the assignment s, where i denotes the number of 0's in s. Let this collection of constraints be denoted by I. We will first show that I gives a perfect (but possibly nonstrict) implementation of the constraint XOR(x i , y j ).</p><p>Clearly, any solution which assigns identical values to all variables in S x and the complementary value to all variables in S y satisfies all the constraints in I. We will show the converse, i.e., every assignment satisfying all the above constraints assigns identical values to all variables in S x and the complementary value to every variable in S y .</p><p>Fix any assignment satisfying all the constraints and let Z and O, respectively, denote the set of variables set to 0 and 1, respectively. We claim that any solution which satisfies all the constraints must satisfy either Z = S x and O = S y or Z = S y and O = S x .</p><p>Note first that at least one of the conditions |S x ∩ Z| ≥ k or |S x ∩ O| ≥ k must hold. Consider the case where |S x ∩ Z| ≥ k. In this case, we will show that S x = Z and S y = O. (A similar argument for the other case will show S x = O and S y = Z.)</p><p>• First we claim that |S y ∩ Z| &lt; k and thus |S y ∩ O| &gt; 2k. Assume for contradiction that |S y ∩ Z| ≥ k. Then there exists a constraint application in I with all its input variables coming from the sets S x ∩ Z and S y ∩ Z. By definition of Z all these variables are set to zero, and hence this constraint application is unsatisfied (by the 0-validity of f ). • Next we claim that every variable of S x is set to 0: Assume otherwise and, without loss of generality (w.l.o.g.), let x 1 be set to 1. Let s be an assignment with minimal number of 0's. Assume w.l.o.g. that s = 0 k0 1 k-k0 . W.l.o.g., let y 1 , . . . , y 2k be set to one. (We know 2k such variables exist since |S y ∩ O| &gt; 2k.) By our choice of constraint applications, f (x 1 , . . . , x k0 , y 1 , . . . , y k-k0 ) is one of the constraint applications. However, at most k 0 -1 variables of this constraint are set to 0 and thus this application cannot be satisfied. • Finally, similar to the above step, we can show that every variable in S y is set to 1. Thus we have shown that if |S x ∩ Z| ≥ k, then S x = Z and S y = O. The other case is similar, and this concludes the first phase.</p><p>We next augment the collection of constraints above as follows. Consider a least Hamming weight satisfying assignment s for f . W.l.o.g., we assume that s = 10 k-k1-1 1 k1 . We add the constraints f (x, x 1 , . . . , x k-k1-1 , y 1 , . . . , y k1 ) and f (y, x 1 , . . . , x k-k1-1 , y 1 , . . . , y k1 ). We now argue that the resulting collection of constraints yields a perfect and strict implementation of the constraint XOR(x, y).</p><p>Clearly s ′ = 0 k-k1 1 k1 is not a satisfying assignment (since it has smaller Hamming weight than s). Since f is C-closed, we have the following situation: Similarly if x = 0, then we must have O = S x , Z = S y and y = 1. Thus the given constraints do form a perfect implementation of XOR(x, y). Finally if x = y, then the setting O = S x and Z = S y satisfies all constraints except one (which is one of the last two additional constraints). Thus the implementation satisfies the strictness property as well.</p><formula xml:id="formula_29">f () s ′ 0 k-k1</formula><p>Lemma 4.6. Let f 0 , f 1 and g be nontrivial constraints, possibly identical, which are not 0-valid, not 1-valid, and not C-closed, respectively. Then {f 0 , f 1 , g}</p><formula xml:id="formula_30">s/p =⇒ {T, F }.</formula><p>Proof. We will describe only the implementation of constraint T (•); the implementation for the constraint F (•) is identical.</p><p>Assume, for simplicity, that all the three functions f 0 , f 1 , and g are of arity k. We use an implementation similar to the one used in the proof of Lemma 4.5. To implement T (x), we use a set of 6k auxiliary variables S x = {x 1 , . . . , x 3k } and S y = {y 1 , . . . , y 3k }. For each h ∈ {f 0 , f 1 , g}, for each satisfying assignment s of h, if j is the number of 0's in s we place the 3k j 3k k-j constraints h with all possible subsets of S x appearing in the indices in Z(s) and all possible subsets of S y appearing in O(s). Finally we introduce one constraint involving the primary variable x. Let s be the satisfying assignment of minimum Hamming weight which satisfies f 0 . Notice that s must include at least one 1. Assume, w.l.o.g., that s = 10 k-k1-1 1 k1 . Then we introduce the constraint application f 0 (x, x 1 , . . . , x k-k1-1 , y 1 , . . . , y k1 ).</p><p>It is clear that by setting all variables in S x to 0 and all variables in S y to 1 we get an assignment that satisfies all constraints except possibly the last constraint (which involves x). Furthermore, the last constraint is satisfied if and only if x = 1. Thus, to prove the lemma, it suffices to show that any solution which satisfies all the constraints above must set x to 1, all variables in S x to 0, and all variables in S y to 1.</p><p>Fix an assignment satisfying all the constraints. Let O be the set of variables in S x ∪ S y set to 1 and Z be the set of variables set to 0. We need to show that S x ∩ O = ∅ and we do so in stages.</p><p>• First, we consider the possibility |S x ∩ O| ≥ k. We consider two cases.</p><p>-Case. |S y ∩ Z| ≥ k. Consider a satisfying assignment s such that g(s) = 0. Such an assignment must exist since g is not C-closed. Note that the constraint applications include at least one where g is applied to variables where the positions corresponding to O(s) come from S y ∩ Z and positions corresponding to Z(s) come from S x ∩ O. However, this constraint is not satisfied by the assignment (since g(s) = 0).</p><p>-Case. |S y ∩ O| &gt; 2k. Let s 1 be a satisfying assignment for f 1 . Note that the application of the constraint f 1 with the positions corresponding to O(s) coming from S y ∩O and the positions corresponding to Z(s) coming from S x ∩ O is one of the constraints imposed above and is not satisfied (since f 1 is not 1-valid). Thus in either case, we find a constraint that is not satisfied and thus this possibility (|S x ∩ O| ≥ k) cannot occur. Thus we conclude |S x ∩ O| &lt; k.</p><p>• From the above, we have |S x ∩ Z| &gt; 2k. If |S y ∩ Z| ≥ k, then we can find an application of the constraint f 0 to the variables in the set Z that will not be satisfied. Thus we have |S y ∩ Z| &lt; k and thus |S y ∩ O| &gt; 2k. This can now be used to conclude that S y ∩ Z = φ as follows. Consider a satisfying assignment with smallest number of ones. The number of ones in such an assignment is positive since f 0 is not 0-valid. If we consider all the constraints corresponding to this assignment with inputs from S y and S x ∩ Z only, it is easy to see that there will be at least one unsatisfied constraint if S y ∩ Z = φ. Hence each variable in S y is set to 1 in this case. Finally, using the constraints on the constraint f 1 which is not 1-valid, it is easy to conclude that in fact Z = S x . Having concluded that S x = Z and S y = O, it is easy to see that the constraint f 0 (x, x 1 , . . . , x k-k1-1 , y 1 , . . . , y k1 ) is satisfied only if x = 1. Thus the set of constraints imposed above yields a strict and perfect implementation of T (•). The constraint F (•) can be implemented analogously.</p><p>For the CSP classes, it suffices to consider the case when F is neither 0-valid nor 1-valid. For the Max Ones and Min Ones classes we also need to consider the case when F fails only to have one of these two properties. Therefore keeping these classes in mind we prove the following lemma, which shows how to obtain a weak version of T and F in these cases.</p><p>Lemma 4.7. If F is not C-closed and not 1-valid, then F s/p =⇒ f for some existential zero constraint f 0 . Analogously, if F is not C-closed and not 0-valid, then F s/p =⇒ f 1 for some existential one constraint f 1 . Proof. We prove only the first part of the lemma. The second part is similar. The proof reduces to two simple subcases. Let f ∈ F be a constraint that is not 1-valid. If f is 0-valid, then we are done since f is an existential zero constraint. If f is not 0-valid, then F has a non-C-closed function, a non-0-valid function, and a non-1-valid function, and hence by Lemma 4.6, F perfectly and strictly implements F which is an existential zero function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">2-monotone functions.</head><p>Definition 4.8 (0/1-term). A set V ⊆ {1, . . . , k} is a 0-term (1-term) for a kary constraint f if every assignment s with Z(s) ⊇ V (resp., O(s) ⊇ V ) is a satisfying assignment for f .</p><p>The choice of the name reflects the fact that a 0-term is a term consisting of all negated variables (or variables set to 0) and a 1-term consists of all positive variables. Lemma 4.9. A constraint f is a 2-monotone constraint if and only if all the following conditions are satisfied:</p><p>(a) for every satisfying assignment s of f , either</p><formula xml:id="formula_31">Z(s) is a 0-term or O(s) is a 1-term; (b) if V 1 and V 2 are 1-terms for f , then V 1 ∩ V 2 is a 1-term; and (c) if V 1 and V 2 are 0-terms for f , then V 1 ∩ V 2 is also a 0-term.</formula><p>Proof. Recall that a 2-monotone constraint is one that can be expressed as a disjunction of two terms. Every satisfying assignment must satisfy one of the two terms and this gives property (a). Properties (b) and (c) are obtained from the fact that the constraint has at most one term with all positive literals and at most one term with all negated literals. Conversely, consider a constraint f which satisfies properties (a)-(c). Let s 1 , . . . , s l be the satisfying assignments of f such that Z(s i ) is a 0-term for i ∈ {1, . . . , l}. Let t 1 . . . . , t k be the satisfying assignments of f such that O(t j ) is a 1-term for j ∈ {1, . . . , k}. Then Z = ∩ i Z(s i ) is a 0-term and O = ∩ j O(t j ) is a 1-term for f , respectively (using (b) and (c)), and together they cover all satisfying assignments of f . Thus f (x) = (∧ i∈Z ¬x i ) ∨ (∧ j∈O x j ), which is 2-monotone.</p><p>We now use the characterization above to prove, in Lemma 4.11, that if a function f is not 2-monotone, then the family {f, T, F } implements the function XOR. We first prove a simple lemma which shows implementations of XOR by some specific constraint families. This will be used in Lemma 4.11.</p><p>Lemma 4.10.</p><p>(1) {AND 2,1 } s =⇒ XOR.</p><p>(2) For every p ≥ 2, we have {f p , T, F } s/p =⇒ XOR, where f p (x 1 , . . . , x p ) = OR p (x 1 , . . . , x p ) NAND p (x 1 , . . . , x p ).</p><p>(3) For every p ≥ 2, we have {NAND p , T, F } s =⇒ XOR. Proof. For part <ref type="bibr" target="#b2">(1)</ref> we observe that the constraints {AND 2,1 (x 1 , x 2 ), AND 2,1 (x 2 , x 1 )} provide a strict (but not perfect) 1-implementation of XOR(x 1 , x 2 ).</p><p>For part <ref type="bibr" target="#b3">(2)</ref> notice that the claim is trivial if p = 2, since the function f 2 = XOR. For p ≥ 3, the constraints {f p (x 1 , . . . , x p ), T (x 3 ), . . . , T (x p )} perfectly and strictly implement NAND(x 1 , x 2 ). Similarly the constraints {f p (x 1 , . . . , x p ), F (x 3 ), . . . , F (x p )} perfectly and strictly implement the constraint OR(x 1 , x 2 ). Finally the constraints OR(x 1 , x 2 ) and NAND(x 1 , x 2 ) perfectly and strictly implement the constraint XOR (x 1 , x 2 ). Part (2) follows from the fact that perfect and strict implementations compose (Lemma 3.5).</p><p>Finally for part (3), we first use the constraints {NAND p (x 1 , . . . , x p ), F (x 3 ), . . . , F (x p )} to implement, strictly and perfectly, the constraint NAND(x 1 , x 2 ). Now we may use {NAND(x 1 , x 2 ), NAND(x 1 .x 2 ), T (x 1 ), T (x 2 )} to obtain a 3-implementation of the constraint XOR(x 1 , x 2 ). (Note that in the case the implementation is not perfect.) Lemma 4.11. Let f be a constraint which is not 2-monotone. Then {f, T, F } s =⇒ XOR.</p><p>Proof. The proof is divided into three cases which depend on which of the three conditions defining 2-monotonicity is violated by f . We first state and prove the claims.</p><p>Claim 4.12. If f is a function violating property (a) of Lemma 4.9, then {f, T, F } s</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>=⇒ XOR.</head><p>Proof. There exists some assignment s satisfying f , and two assignments s 0 and s 1 such that Z(s) ⊆ Z(s 0 ) and O(s) ⊆ O(s 1 ), such that f (s 0 ) = f (s 1 ) = 0. Rephrasing slightly, we know that there exists a triple (s 0 , s, s 1 ) with the following properties:</p><formula xml:id="formula_32">f (s 0 ) = f (s 1 ) = 0; f (s) = 1; Z(s 0 )⊇Z(s)⊇Z(s 1 ). (1)</formula><p>Note that the condition Z(s 0 )⊇Z(s)⊇Z(s 1 ) implies that O(s 0 ) ⊆ O(s) ⊆ O(s 1 ). We call property (1) the "sandwich property." Of all triples satisfying the sandwich property, pick one that minimizes |Z(s 0 ) ∩ O(s 1 )|. W.l.o.g., assume that Z(s 0 ) ∩ O(s 1 ) = {1, . . . , p}, Z(s 0 ) ∩ Z(s 1 ) = {p + 1, . . . , q}, and O(s 0 ) ∩ O(s 1 ) = {q + 1, . . . , k}. (Notice that the sandwich property implies that O(s 0 ) ∩ Z(s 1 ) = ∅.) Let f 1 be the constraint given by f 1 (x 1 , . . . , x p ) = f (x 1 , . . . , x p , 0, . . . , 0, 1, . . . , 1). Notice that the constraint applications f (x 1 . . . x k ) and T (x i ) for every i ∈ O(s 0 ) ∩ O(s 1 ) and F (x i ) for every i ∈ Z(s 0 ) ∩ Z(s 1 ) implement the function f 1 . Thus it suffices to show that {f 1 , T, F } implements XOR.</p><p>Below we examine some properties of the constraint f 1 . We will use the characters t, t ′ , t i , t ′ i to denote assignments to f 1 , while we use the characters s, s ′ , s i , s ′ i to denote assignments to f . Note that</p><formula xml:id="formula_33">(1) f 1 (0) = f 1 (1) = 0.</formula><p>(2) f 1 has a satisfying assignment. Thus p (the arity of f 1 ) is at least 2.</p><p>(3) If f 1 (t 1 ) = 0 for some t = 1, then for every assignment t such that Z(t)⊇Z(t 1 ), it is the case that f 1 (t 1 ) = 0: This follows from the minimality of |Z(s 0 ) ∩ O(s 1 )| above. If not, then consider the assignments s ′ 0 = s 0 , s ′ = t0 q-p 1 k-q , and s ′ 1 = t 1 0 q-p 1 k-q . The triple (s ′ 0 , s ′ , s ′ 1 ) also satisfies the sandwich property and has a smaller value of |Z(s ′ 0 ) ∩ O(s ′ 1 )|. (4) If f 1 (t 0 ) = 0 for some t 0 = 0, then for every assignment t such that O(t)⊇O(t 0 ), it is the case that f 1 (t) = 0 (again from the minimality of |Z(s 0 ) ∩ O(s 1 )|).</p><p>These properties of f 1 now allow us to identify f 1 almost completely. We show that either (a) p = 2 and f 1 (x 1 x 2 ) is either AND 2,1 (x 1 , x 2 ) or AND 2,1 (x 2 , x 1 ), or (b) f is satisfied by every assignment other than the all zeroes assignment and the all ones assignment. In either case {f 1 , T, F } strictly implements XOR by Lemma 4.10, parts (1) and ( <ref type="formula">2</ref>). (Note that part (1) of Lemma 4.10 yields only a strict (but not perfect) implementation.) Thus proving that either (a) or (b) holds concludes the proof of the claim. Suppose (b) is not the case. Thus, f 1 is left unsatisfied by some assignment t and t = 0 and t = 1. Then we will show that the only assignment that can satisfy f 1 is t. However, this implies that t, t, 0, and 1 are the only possible assignments to f 1 , implying p must be 2, thereby yielding that (a) is true. Thus it suffices to show that if f 1 (t) = 0, and t ′ = t, then f 1 (t ′ ) = 0. Since t ′ is not the bitwise complement of t, there must exist some input variable which shares the same assignment in t and t ′ . W.l.o.g. assume this is the variable x 1 . Consider the case that this variable takes on the value 0 in the assignment t. Then we claim that the assignment f 1 (01 . . . 1) = 0. This is true since O(01 . . . 1)⊇O(t). Now notice that f (t ′ ) = 0 since Z(t ′ )⊇Z(01 . . . 1). (In the case that the first variable takes on the value 1 in the assignment t, it is symmetric.) Thus we conclude that either (a) or (b) always holds and this concludes the proof of the claim. Proof. Let V 1 and V 2 be two 1-terms such that V 1 ∩ V 2 is not a 1-term. Thus, there exists an assignment s such that (s.t.) O(s)⊇V 1 ∩ V 2 and f (s) = 0. Among all such assignments let s be the one with the maximum number of 1's. The situation no strict subset S ′ ⊂ S is a dependent set. Notice that f can be expressed as the conjunction of constraints on its minimally dependent sets. Thus if f is not of width-2, then it must have a minimally dependent set S of cardinality at least 3. Assume S = {1, . . . , p}, where p ≥ 3. Consider the function</p><formula xml:id="formula_34">f 1 (x 1 . . . x p ) = ∃x p+1 , . . . , x k s.t. f (x 1 , . . . x k ).</formula><p>f 1 is affine (by Lemma 4.17), is not satisfied by every assignment, and has at least 2 p-1 satisfying assignments. Thus f 1 has exactly 2 p-1 assignments (since the number of satisfying assignments must be a power of 2). Thus f 1 is described by exactly one linear constraint and by the minimality of S this must be the constraint XOR(x 1 . . . x p ) or the constraint XNOR(x 1 . . . x p ). 4.5. Horn Clauses, 2CNF, and IHS. Lemma 4.19. If f is a weakly positive (weakly negative/IHS-B+/IHS-B-/2CNF) constraint, then any function obtained by restricting some of the variables of f to constants and existentially quantifying over some other set of variables is also weakly positive (resp., weakly negative/IHS-B+/IHS-B-/2CNF).</p><p>Proof. It is easy to see that f remains weakly positive (weakly negative/IHS-B+/ IHS-B-/2CNF) when some variable is restricted to a constant. Hence it suffices to consider the case where some variable y is quantified existentially. (Combinations of the possibilities can then be handled by a simple induction.) Thus consider the</p><formula xml:id="formula_35">function f 1 (x 1 , . . . , x k ) def = ∃y s.t. f (x 1 , . . . , x k , y). Let f (x 1 , . . . , x k , y) =   m j=1 C j (x)     m0 j0=1 (C 0 j0 (x) y)     m1 j1=1 (C 1 j1 (x) ¬y)</formula><p>  be a CNF expression for f which shows it is weakly positive (weakly negative/IHS-B+/ IHS-B-/2CNF), where the clauses C j , C 0 j0 , and C 1 j1 involve literals on the variables x 1 , . . . , x k .</p><p>We first show a simple transformation which creates a CNF expression for f 1 . Later we show that f 1 inherits the appropriate properties of f . Define</p><formula xml:id="formula_36">m 0 × m 1 clauses C 01 j0j1 (x) def = C 0 j0 (x) C 1 j1 (x)</formula><p>. Next, we note that f 1 (x) can be expressed as follows:</p><formula xml:id="formula_37">f 1 (x) = f 1 (x, 0) f 1 (x, 1) =     j C j (x)     j0 C 0 j0 (x)         j C j (x)     j1 C 1 j1 (x)     =   j C j (x)       j0 C 0 j0 (x)     j1 C 1 j1 (x)     =   j C j (x)     j0 j1 C 01 j0j1 (x)   . (2)</formula><p>To conclude we need to verify that the right-hand side of (2) satisfies the same properties as f . Furthermore, we have only to consider clauses of the form C 01 j0j1 (x) since all other clauses are directly from the expression for f . We verify this below: Proof. We prove the lemma for the weakly positive case. The other case is similar. For the easy direction, recall that a function can be expressed as the conjunction of all its maxterms. If all maxterms are weakly positive, then this gives a weakly positive representation of f .</p><formula xml:id="formula_38">• If f is</formula><p>For the other direction, assume for contradiction that f is a weakly positive constraint that has C = ¬x 1 • • • ¬x p x p+1 • • • x q as a maxterm for some p ≥ 2. Let the arity of f be k. Consider the function</p><formula xml:id="formula_39">f 1 (x 1 x 2 ) def = ∃x q+1 , . . . , x k s.t. f (x 1 x 2 1 p-2 0 q-p x q+1 . . . x k ).</formula><p>Since C is an admissible clause in a CNF representation of f , we have that if we set x 1 , . . . , x p to 1 and setting x p+1 , . . . , x q to 0, then no assignment to x q+1 , . . . , x k satisfies f . Thus we find that f 1 (11) = 0. By the fact that the clause is a maxterm we have that both the assignments x 1 . . . x q = 01 p-1 0 q-p and x 1 . . . x q = 101 p-2 0 q-p can be extended to satisfying assignments of f . Thus we find that f 1 (10) = f 1 (01) = 1. Thus f 1 is either the function NOR or XOR. It can be easily verified that neither of these is 2-monotone. (Every basic weakly positive function on two variables is unsatisfied on at least one of the two assignments 01 or 10.) However, this is in contradiction to Lemma 4.19 that showed that every function obtained by restricting some variables of f to constants and existentially quantifying over some others should yield a weakly positive function.</p><p>Lemma 4.21. f is a 2CNF constraint if and only if all its maxterms are 2CNF. Proof. The "if" part is obvious. For the other direction we use Lemma 4.19. Assume for contradiction that f has a maxterm of the form</p><formula xml:id="formula_40">x 1 x 2 x 3 • • • x p ¬x p+1 • • • ¬x q .</formula><p>(For simplicity we assume p ≥ 3. Other cases where one or more of the variables x 1 , . . . , x 3 are negated can be handled similarly.) Consider the function</p><formula xml:id="formula_41">f 1 (x 1 x 2 x 3 ) def = ∃x q+1 , . . . , x k s.t. f (x 1 , x 2 , x 3 , 0 p-3 , 1 q-p , x q+1 , . . . , x k ).</formula><p>Then since x 1 x 2 x 3 . . . is a maxterm of f , we have that f 1 (000) = 0 and f 1 (100) = f 1 (010) = f 1 (001) = 1. We claim that f 1 cannot be a 2CNF function. If not, then to make f 1 (000) = 0, at least one of the clauses x 1 , x 2 , x 3 , x 1 x 2 , x 2 x 3 , or x 3 x 1 should be a clause of f 1 in any 2CNF representation. However, all these clauses are left unsatisfied by at least one of the assignments 100, 010, or 001. This validates our claim that f 1 is not a 2CNF constraint. However, f 1 was obtained from f by setting some variables to a constant and existentially quantifying over others, and by Lemma 4.19 f 1 must also be a 2CNF function. This yields the desired contradiction.</p><p>Lemma 4.22. An affine function f is a width-2 affine function if and only if all its minimally dependent sets are of cardinality at most 2.</p><p>Proof. We use the fact that F 2A ⊆ F 2CNF ∩F A . Suppose f ∈ F 2A has a minimally dependent set of size p ≥ 3 and, say, the set is x 1 , . . . , x p . Then by existential quantification over the variables x p+1 , . . . , x k and by setting the variables x 4 , . . . , x p to 0, we obtain the function f 1 (x 1 , x 2 , x 3 ) which is an affine function (by Lemma 4.17) with x 1 , x 2 , x 3 as a minimally dependent set. Thus this function is either XOR 3 or XNOR 3 . However, now notice that neither of these functions is a 2CNF function. However, since f is a 2CNF function Lemma 4.19 implies that f 1 must also be a 2CNF function. This yields the required contradiction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Classification of MAX CSP.</head><p>The main results of this section are in sections 5.1 and 5.2. These results were originally obtained by Creignou <ref type="bibr" target="#b12">[11]</ref>. Her focus, however, is on the the complexity of finding optimal solutions to the optimization problems. The proofs for hardness of approximation are left to the reader to verify. We give full proofs using the notions of implementations. Our proof is also stronger since it does not assume replication of variables as a basic primitive. This allows us to talk about problems such as Max EkSat. In section 5.3 we extend Schaefer's results to establish the hardness of satisfiable Max CSP problems. Similar results, again with replication of variables being allowed, were first shown by Hunt, Marathe, and Stearns <ref type="bibr" target="#b27">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Containment results for MAX CSP.</head><p>We start with the polynomial time solvable cases.</p><p>Proposition 5.1. Weighted Max CSP(F)</p><formula xml:id="formula_42">(Weighted Min CSP(F)) is in PO if F is 0-valid (1-valid).</formula><p>Proof. Set each variable to zero (resp., one); this satisfies all of the constraints.</p><p>Before proving the containment in PO of Max CSP(F) for 2-monotone function families, we show that the corresponding Weighted Min CSP(F) is in PO. The containment for Weighted Max CSP(F) will follow easily.</p><p>Lemma 5.</p><formula xml:id="formula_43">2. Weighted Min CSP(F) is in PO if F is 2-monotone.</formula><p>Proof. This problem reduces to the problem of finding s-t min-cut in directed weighted graphs. 2-monotone constraints have the following possible forms:</p><p>(a) AND p (x i1 , . . . , x ip ), (b) NOR q (x j1 , . . . , x jq ), and (c) AND p (x i1 , . . . , x ip ) NOR q (x j1 , . . . , x jq ). Construct a directed graph G with two special nodes, F and T , and a vertex v i corresponding to each variable x i in the input instance. Let ∞ denote an integer larger than the total weight of all constraints. Now we proceed as follows for each of the above classes of constraints:</p><p>• For a constraint C of weight w of the form (a), create a new node e C and add an edge from each v i l , l ∈ [p], to e C of capacity ∞ and an edge from e C to T of capacity w.</p><p>• For a constraint C of weight w of the form (b), create a new node e C and add an edge from e C to each v j l , l ∈ [q], of capacity ∞ and an edge from F to e C of capacity w. • Finally, for a constraint C of weight w of the form (c), we create two nodes e C and e C . For every l ∈ [p], we add an edge from v i l to e C of capacity ∞, and for every l ∈ [q], we add an edge from e C to v j l of capacity ∞ and finally an edge from e C to e C of capacity w. (Note in this case there are no edges connecting F or T to any of the vertices.) Notice that each vertex of type e C or e C can be associated with a term: e C with a term on positive literals and e c with a term on negated literals. We use this association to show that the value of the min F-T cut in this directed graph equals the weight of the minimum number of unsatisfied constraints in the given Weighted Min CSP(F) instance.</p><p>Given an assignment which fails to satisfy constraints of weight W , we associate a cut as follows: Vertex v i is placed on the F side of the cut if and only if it is set to 0. A vertex e C is placed on the T side if and only if the term associated with it is satisfied. A vertex e C is placed on the F side if and only if the term associated with it is satisfied. It can be verified that such an assignment has no directed edges of capacity ∞ going from the F side of the cut to the T side of the cut. Furthermore, for every constraint C of weight w, the associated edge of capacity w crosses the cut if and only if the constraint is not satisfied. Thus the capacity of this cut is exactly W and thus we find that the min F-T cut value is at most W .</p><p>In the other direction, we show that given a F-T cut in this graph of cut capacity W &lt; ∞, there exists an assignment which fails to satisfy constraints of weight at most W . Such an assignment is simply to assign x i = 0 if and only if v i is on the F side of the cut. Note that for any constraint C, the associated vertices e C and e c (whichever exist) may be placed on the T and F sides of the cut (respectively) only if the associated term is satisfied (otherwise there will be an edge of capacity ∞ crossing the cut). Thus, if a constraint C of capacity w is not satisfied by this assignment, then the edge of capacity w corresponding to C must cross the cut. Summing up we find that the assignment fails to satisfy constraints of total weight at most W .</p><p>Putting both directions together, we find that the min F-T cut in this graph has capacity exactly equal to the optimum of the Weighted Min CSP{XOR} instance, and thus the latter problem can be solved exactly in polynomial time.</p><p>For the sake of completeness we also prove the converse direction to the above lemma. We show that the s-t min-cut problem can be phrased as a Min CSP(F) problem for a 2-monotone family F.</p><p>Lemma 5.3. The s-t min-cut problem is in Weighted Min CSP({OR 2,1 , T, F }).</p><p>Proof. Given an instance G = (V, E) of the s-t min-cut problem, we construct an instance of Weighted Min CSP(F) on variables x 1 , x 2 , . . . , x n , where x i corresponds to the vertex i ∈ V -{s, t}:</p><p>• For each edge e = (s, i) with weight w e , we create the constraint F (x i ) with weight w e . • For each edge e = (i, t) with weight w e , we create the constraint T (x i ) with weight w e . • For each edge e = (i, j) with weight w e and such that i, j ∈ {s, t}, we create the constraint OR 2,1 (x j , x i ) with weight w e . Given a solution to this instance of Weighted Min CSP(F), we construct an s-t cut by placing the vertices corresponding to the false variables on the s-side of the cut and the remaining on the t-side of the cut. It is easy to verify that an edge e contributes to the cut if and only if its corresponding constraint is unsatisfied. Hence the optimal Min CSP(F) solution and the optimal s-t min-cut solution coincide.</p><p>Going back to our main objective, we obtain as a simple corollary to Lemma 5.2 the following corollary.</p><p>Corollary 5.4. For every F ⊆ F 2M , Weighted Max CSP(F)∈ PO.</p><p>Proof. The proof follows from the fact that given an instance I of Weighted Max CSP(F), the optimum solution to I viewed as an instance of Weighted Min CSP(F) is also an optimum solution to the Weighted Max CSP(F) version.</p><p>Finally we prove a simple containment result for all of Max CSP(F) which follows as an easy consequence of Proposition 3.7.</p><p>Proposition 5.5. For every F, Weighted Max CSP(F) is in APX.</p><p>Proof. The proof follows from Proposition 3.7 and the fact that the total weight of all constraints is an upper bound on the optimal solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Negative results for MAX CSP.</head><p>In this section we prove that if F ⊆ F 0 , F 1 , F 2M , then Max CSP(F) is APX-hard. We start with a simple observation which establishes Max CSP(XOR) as our starting point.</p><p>Lemma 5.6. Max CSP(XOR) is APX-hard.</p><p>Proof. We observe that Max CSP(XOR) captures the MAX CUT problem shown to be APX-hard by <ref type="bibr" target="#b40">[39,</ref><ref type="bibr" target="#b4">3]</ref>. Given a graph G = (V, E) with n vertices and m edges, create an instance I G of Max CSP({XOR}) with one variable x u for every vertex u ∈ V and with constraints XOR(x u , x v ) corresponding to every edge {u, v} ∈ E. It is easily seen there is a one-to-one correspondence between (ordered) cuts in G and the assignments to the variables of I G which maintains the values of the objective functions (i.e., the cut value and the number of satisfied constraints).</p><p>We start with the following lemma which shows how to use the functions which are not 0-valid or 1-valid.</p><p>Lemma 5.7. If F ⊆ F 0 , F 1 , then Max CSP(F ∪ {T, F }) is AP-reducible to Max CSP(F) and Min CSP(F ∪ {T, F }) is A-reducible to Min CSP(F).</p><p>Proof. Let f 0 be the function from F that is not 0-valid and let f 1 be the function that is not 1-valid. If some function g in F is not C-closed, then by Lemma 4.6 F perfectly and strictly implements T and F . Hence, by Lemmas 3.8 and 3.10, Max CSP(F ∪ {T, F }) is AP-reducible to Max CSP(F) and Min CSP(F ∪ {T, F }) is A-reducible to Min CSP(F).</p><p>Otherwise, every function of F is C-closed, and hence by Lemma 4.5, F perfectly and strictly implements the XOR function and hence, by Proposition 3.3, the XNOR function. Thus it suffices to show that Max CSP(F ∪ {T, F }) is AP-reducible to Max CSP(F ∪ {XOR, XNOR}) (and Min CSP(F ∪ {T, F }) is A-reducible to Min CSP(F ∪ {XOR, XNOR})) for C-closed families F. Here we use an idea from <ref type="bibr" target="#b9">[8]</ref> described next.</p><p>Given an instance I of Max CSP(F ∪ {T, F }) on variables x 1 , . . . , x n and constraints C 1 , . . . , C m , we define an instance I ′ of Max CSP(F ∪ {XOR, XNOR}) (Min CSP(F ∪ {XOR, XNOR})) whose variables are x 1 , . . . , x n and additionally one new auxiliary variable x F . Each constraint of the form F (x i ) (resp., T (x i )) in I is replaced by a constraint XNOR(x i , x F ) (resp., XOR(x i , x F )). All the other constraints are not changed. Thus I ′ also has m constraints. Given a solution a 1 , . . . , a n , a F for I ′ that satisfies m ′ of these constraints, notice that the assignment ¬a 1 , . . . , ¬a n , ¬a F also satisfies the same collection of constraints (since every function in F is C-closed). In Corollary 5.13. If F is not 0-valid or 1-valid or affine or bijunctive or weakly positive or weakly negative, then F p =⇒ F 3SAT . Thus we get the following theorem. Theorem 5.14. For every constraint set F, either SAT(F) is easy to decide or there exists ǫ = ǫ F &gt; 0 such that it is NP-hard to distinguish satisfiable instances of SAT(F) from instances where 1ǫ fraction of the constraints are not satisfiable.</p><p>6. Classification of MAX ONES. Again we will first prove the positive results and then show the negative results. However, before we do either, we will show a useful reduction between unweighted and weighted Max Ones(F) problems which holds for most interesting function families F.</p><p>6.1. Preliminaries. We begin with a slightly stronger notion of the definition of polynomial time solvability of Sat(F) (than that of <ref type="bibr" target="#b43">[42]</ref>). We then show that given this stronger form of polynomial time decidability the weighted and unweighted cases of Max Ones(F) are equivalent by showing that this stronger form of polynomial time decidability leads to a polynomial approximation algorithm. We conclude by showing that for the Max Ones problems, which we hope to show to be APX-complete or poly-APX-complete, the strong form of decidability does hold. Definition 6.1. We say that a constraint family F is strongly decidable if, given m constraints from F on n variables x 1 , . . . , x n and an index i ∈ {1, . . . , n}, there exists a polynomial time algorithm to find an assignment to x 1 , . . . , x n satisfying all m constraints and additionally satisfying the property x i = 1 if one such exists. Lemma 6.2. For every strongly decidable constraint family F, Weighted Max Ones(F) is in poly-APX.</p><p>Proof. Consider an instance of Weighted Max Ones(F) with variables x 1 , . . . , x n , constraint applications C 1 , . . . , C m , and weights w 1 , . . . , w n . Assume w 1 ≤ w 2 ≤ • • • ≤ w n . Let i be the largest index such that there exists a feasible solution with x i = 1. Notice that i can be determined in polynomial time due to the strong decidability of F. We also use the strong decidability to find an assignment with x i = 1. It is easily verified that this yields an n-approximate solution. (Weight of this solution is at least w i , while weight of optimal is at most</p><formula xml:id="formula_44">i j=1 w j ≤ iw i ≤ nw i .)</formula><p>Before concluding we show that most problems of interest to us will be able to use the equivalence established above between weighted and unweighted problems. Lemma 6.3.</p><formula xml:id="formula_45">If F ⊆ F ′ for any F ′ ∈ {F 1 , F S0 , F 2CNF , F A , F WP , F WN }, then F is strongly decidable. Proof. Recall that for i ∈ [k], f | ({i},1)</formula><p>is the constraint obtained from f by restricting the ith input to 1. Define F * to be the constraint set</p><formula xml:id="formula_46">F * def = F ∪ {f | i,1 |f ∈ F, i ∈ [k]}.</formula><p>First, observe that the problem of strong decidability of F reduces to the decision problem Sat(F * ). Furthermore, observe that if</p><formula xml:id="formula_47">F ⊆ F ′ for F ′ ∈ {F 1 , F 2CNF , F A , F WP , F WN }, then F * ⊆ F ′ as well. Finally, if F * ⊆ F S0 , then F * ⊆ F 0 .</formula><p>Thus in each case we end up with a problem from Sat(F) for a family F which is polynomial time decidable in Schaefer's dichotomy. Lemma 6.4.</p><formula xml:id="formula_48">If F p =⇒ f 0 for some existential zero constraint f 0 , then F p =⇒ F| 0 . Similarly, if F p =⇒ f 1 for some existential one constraint f 1 , then F p =⇒ F| 1 .</formula><p>Proof. Let f ∈ F. We show how to implement the constraint f (0, x 1 , . . . , x k-1 ). The proof can be extended to other constraints in F| 0 by induction. Let f 0 be an existential zero constraint implementable by F and let K be the arity of f 0 . Then the constraints f (y i , x 1 , . . . , x k-1 ), for i ∈ [K], along with the constraint f 0 (y 1 , . . . , y K ) perfectly implement the constraint f (0, x 1 , . . . , x k-1 ). (Observe that since at least one of the y i 's in the set y 1 , . . . , y K is zero, the constraint f (0, x 1 , . . . , x k-1 ) is being enforced. Furthermore, we can always set all of y 1 , . . . , y K to zero, ensuring that any assignment to x 1 , . . . , x k-1 satisfying f (0, x 1 , . . . , x k-1 ) does satisfy all the constraints listed above.) 6.2. Containment results. Lemma 6.5. If F is 1-valid or weakly positive or width-2 affine, then Weighted Max Ones(F) is in PO.</p><p>Proof. If F is 1-valid, then setting each variable to 1 satisfies all constraint applications with the maximum possible variable weight.</p><p>If F is weakly positive, consider the CNF formulae for the f i ∈ F such that each clause has at most one negated variable. Clearly, clauses consisting of a single literal force the assignment of these variables. Setting these variables may create new clauses of a single literal; set these variables and continue the process until all clauses have at least two literals or until a contradiction is reached. In the latter case, no feasible assignment is possible. In the former case, setting the remaining variables to 1 satisfies all constraints, and there exists no feasible assignment with a greater weight of ones.</p><p>In the case that F is affine with width-2, we reduce the problem of finding a feasible solution to that of checking whether a graph is bipartite and then use the bipartition to find the optimal solution. Notice that each constraint corresponds to a conjunction of constraints of the form X i = X j or X i = X j . Create a vertex X j for each variable X j and for each constraint X i = X j , add an edge (X i , X j ). For each constraint X i = X j , identify the vertices X i and X j and associate the sum of their weights to the identified vertex; if this creates a self-loop, then clearly no feasible assignment is possible. Check whether the graph is bipartite; if not, then there is no feasible assignment. If it is bipartite, then for each connected component of the graph choose the larger weight side of the bipartition and set the corresponding variables to 1.</p><p>Lemma 6.6. If F is affine, then Weighted Max Ones(F) is in APX. Remark. Our proof actually shows that Max Ones(F) has a 2-approximation algorithm. Combined with the fact that the AP-reduction of Lemma 3.11 does not lose much in the approximation factor we essentially get the same factor for Weighted Max Ones(F) as well.</p><p>Proof. By Lemmas 3.11, 6.2, and 6.3 it suffices to consider the unweighted case. (Lemma 6.3 shows that F is strongly decidable; Lemma 6.2 uses this to show that Weighted Max Ones(F) is in poly-APX; and Lemma 3.11 uses this to provide an AP-reduction from Weighted Max Ones(F) to Max Ones(F).)</p><p>Given an instance I of Max Ones(F), notice that finding a solution which satisfies all constraints is the problem of solving a linear system of equations over GF <ref type="bibr" target="#b3">[2]</ref>. Say the linear system is given by Ax = b, where A is an m × n matrix, and b is a m × 1 column vector, and the x is an n × 1 vector. Assume w.l.o.g. that the rows of A are independent. By simple row operations and reordering of the variables, we can set up the linear system as [I|A ′ ]x = b ′ . Thus if x ′ represents the vector x 1 , . . . , x m and x ′′ represents the vector x m+1 , . . . , x n , then the set of feasible solutions to the given linear system are given by</p><formula xml:id="formula_49">{ x ′ , x ′′ |x ′′ ∈ {0, 1} n-m , x ′ = -A ′ x ′′ + b ′ }.</formula><p>Pick a random element of this set by picking x ′′ at random and setting x ′ accordingly. Notice that for any i ∈ {m + 1, . . . , n} x i = 1 with probability (w.p.) 1  2 . Furthermore, for any i ∈ [m], x i is either forced to 0 in all feasible solutions, or x i is forced to 1 in all feasible solutions, or x i = 1 w.p. 1/2. Thus, if S ⊆ [n] is the set of variables which are ever set to 1 in a feasible solution, then the expected number of 1's in a random solution is at least |S|/2. However, S is an upper bound on opt. Thus the expected value of the solution is at least opt/2, and hence the solution obtained is a 2-approximate solution.</p><p>Proposition 6.7.</p><formula xml:id="formula_50">If F ⊆ F ′ for some F ′ ∈ {F 1 , F S0 , F 2CNF , F A , F WP , F WN }, then Weighted Max Ones(F) ∈ poly-APX.</formula><p>Proof. The proof follows immediately from Lemmas 6.2 and 6.3. Proposition 6.8 (see <ref type="bibr" target="#b43">[42]</ref>). If F ⊆ F 0 , then Sat(F) is in P.</p><p>6.3. Hardness results.</p><p>6.3.1. APX-hard case. We wish to show in this section that if F is an affine family but not width-2 affine, then Max Ones(F) is APX-hard. By Lemmas 6.2 and 3.11 it suffices to show this for Weighted Max Ones(F). The basic APX-hard problems we work with in this section are described in the following lemma. Lemma 6.9.</p><p>Weighted Max Ones(XNOR 3 ) and Weighted Max Ones ({XOR, XNOR 4 }) are APX-hard.</p><p>Proof. We reduce the Max Cut problem to the Weighted Max Ones(XNOR 3 ) problem as follows. Given a graph G = (V, E) we create a variable x v for every vertex v ∈ V and a variable y e for every edge e ∈ E. The weight w v associated with the vertex variable x v is 0. The weight w e of an edge variable y e is 1. For every edge e between u and v we create the constraint y e ⊕ x u ⊕ x v = 0. It is clear that any 0/1 assignment to the x v 's define a cut and for an edge e = {u, v}, y e is 1 if and only if u and v are on opposite sides of the cut. Thus solutions to the Weighted Max Ones problem correspond to cuts in G with the objective function being the number of edges crossing the cut. This shows the APX-hardness of Weighted Max Ones(XNOR 3 ).</p><p>The reduction for Weighted Max Ones({XOR, XNOR 4 }) is similar. Given a graph G = (V, E), we create the variables x v for every v ∈ V , y e for every e ∈ E, and one global variable z (which is supposed to be zero) and m def = |E| auxiliary variables y ′ e for every e ∈ E. For every edge e = {u, v} in G we impose the constraints y e ⊕ x u ⊕ x v ⊕ z = 0. In addition we throw in the constraints z ⊕ y ′ e = 1 for every i ∈ {1, . . . , m}. Finally we make the weight of the vertex variables and z 0, and the weight of the edge variables y e and the auxiliary variables y ′ e is made 1. The optimum to this Weighted Max Ones problem is Max Cut(G) + m. Given an rapproximate solution for the Weighted Max Ones({XOR 4 , XOR}) instance created above, we consider the two possible solutions (as usual): (1) the solution induced by the assignment with zero vertices on one side and one vertex on the other and (2) a cut with m/K edges crossing the cut (notice such a cut can be found based on Proposition 3.7). The better of these solutions has max{</p><formula xml:id="formula_51">( 1 r )(m + Max Cut(G)) - m, m K } ≥ 1 r(K(1-1/r)+1) Max Cut(G) ≥ 1 1+K(r-1)</formula><p>Max Cut(G) edges crossing the cut. Thus an r-approximate solution to Weighted Max Ones({XOR, XNOR 4 }) yields a (1+K(r-1))-approximate solution to Max Cut(G). Thus Max Cut(G) APreduces to Weighted Max Ones({XOR, XNOR 4 }), and hence the latter is APXhard.</p><p>The main complication here is that we don't immediately have a non-0-valid constraint to work with and thus we can't immediately reduce Max Ones(F ∪{T, F }) to Max Ones(F). Therefore we go after something weaker and try to show that F can perfectly implement F| 0,1 . In Phase 3 (Lemmas 6.20 and 6.21) we show that this suffices. Lemma 6.20 uses the fact that F| 0,1 is not weakly positive to implement either NAND 2 or XOR. In the former case we are done and in the latter case, Lemma 6.21 uses the fact that F| 0,1 is not affine to implement NAND.</p><p>Thus our task reduces to that of showing that F can implement F| 0,1 . Part of this is easy. In Phase 1, we show that F implements every constraint in F| 0 . This is shown via Lemma 6.16 which shows that any family which is either 0-valid or 2CNF or weakly negative but not 1-valid or affine or weakly positive must have a non-C-closed constraint. This along with the non-1-valid constraint allows it to implement every constraint in F| 0 (by Lemmas 4.7 and 6.4). The remaining task for Phase 2 is to show that F| 0 can implement F| 1 . If F also has a non-0-valid constraint, then we are done since now we can implement all of F| 0,1 (another application of Lemmas 4.7 and 6.4). Thus all lemmas in Phase 2 focus on F| 0 for 0-valid constraint families F. If F| 0 is all 0-valid, then all we can show is that F| 0 either implements NAND k for some k or OR 2,1 (Lemmas 6.17 and 6.18). The former is good, but the latter seems insufficient. In fact we are unable to implement F| 0,1 in this case. We salvage the situation by reverting back to reductions. We AP-reduce the problem Weighted Max Ones(F| 0 ∪ {OR 2,1 }) to Weighted Max Ones(F| 0,1 ) (Lemma 6. <ref type="bibr" target="#b20">19</ref>). This suffices to establish the poly-APX-hardness of Weighted Max Ones(F) since</p><formula xml:id="formula_52">Weighted Max Ones(F| 0,1 )≤ AP Weighted Max Ones(F| 0 ∪ {OR 2,1 }) ≤ AP Weighted Max Ones(F)</formula><p>and the problem Weighted Max Ones(F| 0,1 ) is poly-APX-hard. Lemma 6.15. Max Ones({NAND k }) is poly-APX-hard for every k ≥ 2.</p><p>Proof. We reduce from Max Clique, which is known to be poly-APX-hard. Given a graph G, construct a Max Ones({f }) instance consisting of a variable for every vertex in G and the constraint f is applied to every subset of k vertices in G which does not induce a clique. It may be verified that the optimum number of ones in any satisfying assignment to the instance created in this manner is max{k -1, ω(G)}, where ω(G) is the size of the largest clique in G. Given a solution to the Max Ones({f }) instance with l ≥ k ones, the set of vertices corresponding to the variables set to 1 form a clique of size l. If l &lt; k, output any singleton vertex. Thus in all cases we obtain a clique of size at least l/(k -1) vertices. Thus given an rapproximate solution to the Max Ones({NAND k }) problem, we can find a (k -1)rapproximate solution to Max Clique. Thus Max Clique is A-reducible to Max Ones({NAND k }).</p><p>Phase 1. F implements F| 0 . Lemma 6. <ref type="bibr" target="#b17">16</ref>.</p><formula xml:id="formula_53">If F ⊆ F ′ for some F ′ ∈ {F 0 , F 2CNF , F WN } but F ⊆ {F 1 , F 2A , F WP }, then there exists a constraint in F that is not C-closed constraint.</formula><p>Proof. Notice that a C-closed 0-valid constraint is also 1-valid. Thus if F is 0-valid, then the non-1-valid constraint is not C-closed.</p><p>Next we claim that a C-closed weakly positive constraint f is also weakly negative. To do so, consider the constraint f given by f (x) = f (x). Notice that for a C-closed constraint f = f . Suppose f (x) = j C j (x), where the C j 's are weakly positive clauses. Then f (x) can be described as j Cj (x) (where Cj (x) = C j (x)). However, in this representation f (and thus f ) is seen to be a weakly negative constraint, thereby verifying our claim. Thus if F is weakly negative but not weakly positive, the nonweakly positive constraint is the non-C-closed constraint.</p><p>Finally we consider the case when f is a 2CNF formula. Again define f (x) = f (x) and f ′ (x) = f (x) f (x). Notice that f ′ = f if f is C-closed. Again consider the CNF representation of f = j C j (x), where the C j (x)'s are clauses of f of length 2. Then f ′ (x) can be expressed as j (C j (x) Cj (x)). However, C j Cj are affine constraints of width-2! Thus f ′ , and hence f , is an affine width-2 constraint. Thus if F is 2CNF but not width-2 affine, the non-width-2 affine constraint is the non-C-closed constraint.</p><p>Lemma 4.7 along with Lemma 6.4 suffice to prove that F implements F| 0 . We now move on to Phase 2.</p><p>Phase 2. From F| 0 to F| 0,1 .</p><p>Recall that if F has a non-0-valid constraint, then by Lemmas 6.16, 4.7, and 6.4 it implements an existential one constraint and thus F| 0,1 . Thus all lemmas in this phase assume F is 0-valid. Lemma 6.17. If f is 0-valid and not weakly positive, then {f }| 0 either perfectly implements NAND k for some k ≥ 2 or OR 2,1 or XNOR.</p><p>Proof. Let C = ¬x 1 • • • ¬x p y 1 • • • y q be a maxterm in f with more than one negation, i.e., p ≥ 2. Since f is not weakly positive, Lemma 4.20 shows that such a maxterm exists. Substituting a 0 in place of variables y 1 , y 2 , . . . , y q and existentially quantifying over all variables not in C, we get a constraint g such that ¬x 1 ¬x 2 • • • ¬x p is a maxterm in g. Consider an unsatisfying assignment s for g with the smallest number of 1's and let k denote the number of 1's in s; we know k &gt; 0 since the original constraint is 0-valid. W.l.o.g. assume that s assigns value 1 to the variables x 1 , x 2 , . . . , x k and 0 to the remaining variables. It is easy to see that by fixing the variables x k+1 , x k+2 , . . . , x p to 0, we get a constraint g ′ = (¬x 1 ¬x 2 • • • ¬x k ). If k &gt; 1, then this perfectly implements the constraint NAND k (x 1 , . . . , x k ) and we are done.</p><p>Otherwise k = 1, i.e., there exists an unsatisfying assignment s which assigns value 1 to exactly one of the x i 's, say, x 1 . Now consider a satisfying assignment s ′ which assigns 1 to x 1 and has a minimum number of 1's among all assignments which assign 1 to x 1 . The existence of such an assignment follows from C being a maxterm in g. For instance, the assignment 1 p-1 0 is a satisfying assignment which satisfies such a property. W.l.o.g. assume that s ′ = 1 i 0 p-i . Thus the constraint g looks as follows:</p><p>x 1 x 2 x 3 ...x i x i+1 ... Existential quantification over the variables x 3 , x 4 , . . . , x i and fixing the variables x i+1 through x p to 0 yields a constraint g ′ which is either OR 2,1 (x 2 , x 1 ) or XNOR(x 1 , x 2 ). The lemma follows. Now we consider the case where we can implement the function XNOR and show that in this case we can perfectly implement either NAND or OR 2,1 . In the former case we are done, and for the latter case we show in Lemma 6.19 that Weighted Max Ones(F| 1 ) is AP-reducible to Weighted Max Ones(F ∪ {OR 2,1 }). Lemma 6.18.</p><p>If f is 0-valid but not affine, then {f }| 0 ∪ {XNOR} perfectly implements either NAND or the constraint OR 2,1 . (1) g(0, . . . , 0, x p+1 . . . , x q , 1, . . . , 1).</p><p>(2) XNOR(x, x i ) for i ∈ S 001 .</p><p>(3) XNOR(y, x i ) for i ∈ S 010 . ( <ref type="formula">4</ref>) XNOR(z, x i ) for i ∈ S 011 .</p><p>(5) XOR(z, x i ) for i ∈ S 100 . ( <ref type="formula" target="#formula_11">6</ref>) XOR(y, x i ) for i ∈ S 101 . ( <ref type="formula">7</ref>) XOR(x, x i ) for i ∈ S 110 . By existentially quantifying over the variables x p+1 , . . . , x q we perfectly implement a constraint h(x, y, z) with the following properties: h(000) = h(011) = h(101) = 1 and h(110) = 0. Furthermore, by restricting more variables in condition (1) above, we can actually implement any function in the set {h}| 0,1 . Claim 6.22 now shows that for any such function h, the set {h}| 0 perfectly implements either OR 2,1 or NAND. In the latter case, we are done. In the former case, notice that the constraints OR 2,1 (x, z) and XOR(z, y) perfectly implement the constraint NAND(x, y); so in this case too we are done (modulo Claim 6.22 </p><formula xml:id="formula_54">A = 0 =⇒ ∃ x h(x, y, z) = ¬y z, B = 0 =⇒ ∃ y h(x, y, z) = ¬x z, A = 1, B = 1 =⇒ h(x, y, 0) = ¬x ¬y.</formula><p>Thus in each case we perfectly implement either the constraint NAND or OR 2,1 . 6.3.3. Remaining cases. We now prove that if F is not strongly decidable, then deciding if there exists a nonzero solution is NP-hard. This is shown in Lemma 6.23. The last of the hardness results, claiming that finding a feasible solution is NP-hard if F is not 0-valid or 1-valid or 2cnf or weakly positive or weakly negative or linear, follows directly from Schaefer's theorem (Theorem 2.10). Lemma 6.23. If F ⊆ F ′ , for any F ′ ∈ {F S0 , F 1 , F 2CNF , F A , F WP , F WN }, then the problem of finding solutions of nonzero value to a given instance of (unweighted) Max Ones(F) is NP-hard. Proof. Assume, for simplicity, that all constraints of F have arity k. Given a constraint f : {0, 1} k → {0, 1} and an index i ∈ [k], let f↓ i be the constraint mapping {0, 1} k-1 to {0, 1} given by</p><formula xml:id="formula_55">f↓ i (x 1 , . . . , x k ) def = f (x 1 , . . . , x i-1 , 1, x i+1 , . . . , x k ) ∧ f (x 1 , . . . , x i-1 , 0, x i+1 , . . . , x k ).</formula><p>Let F ′ be the set of constraints defined as follows:</p><formula xml:id="formula_56">F ′ def = F ∪ {f↓ i | f ∈ F, i ∈ [k]}.</formula><p>We will show that deciding Sat(F ′ ) is NP-hard and that the problem of deciding Sat(F ′ ) reduces to finding nonzero solutions to Max Ones(F).</p><p>First observe that F ′ ⊆ F ′′ for any</p><formula xml:id="formula_57">F ′′ ∈ {F 0 , F 1 , F 2CNF , F A , F WP , F WN }.</formula><p>In particular it is not 0-valid, since F is not strongly 0-valid. Hence, once again applying Schaefer's result, we find that deciding Sat(F ′ ) is NP-hard.</p><p>Given an instance of Sat(F ′ ) on n variables x with m constraints C, with C 1 , . . . , C m ′ ∈ F and C m ′ +1 , . . . , C m ∈ F ′ \F, consider the instance of Max Ones(F) defined on variable set w 1 , . . . , w k+1 , y 1 , . . . , y n , z 1 , . . . , z n with the following constraints:</p><p>(1) Let f be a non-1-valid constraint in F. We introduce the constraint f (w 1 , . . . , w k ). (2) For every constraint</p><formula xml:id="formula_58">C i (v i1 , . . . , v i k ), 1 ≤ i ≤ m ′ , we introduce two constraints C i (y i1 , . . . , y i k ) and C i (z i1 , . . . , z i k ). (3) For every constraint C i (v i1 , . . . , v i k-1 ), m ′ + 1 ≤ i ≤ m, we introduce 2(n + k + 1) constraints. For simplicity of notation, let C i (v i1 , . . . , v i k-1 ) = g(1, v i1 , . . . , v i k-1 ) ∧ g(0, v i1 , . . . , v i k-1 ), where g ∈ F. The 2(n + k + 1) constraints are • g(w j , y i1 , . . . , y i k-1 ) for 1 ≤ j ≤ k + 1, • g(z j , y i1 , . . . , y i k-1 ) for 1 ≤ j ≤ n, • g(w j , z i1 , . . . , z i k-1 ) for 1 ≤ j ≤ k + 1,</formula><p>• g(y j , z i1 , . . . , z i k-1 ) for 1 ≤ j ≤ n. We now show that the instance of Max Ones(F) created above has a nonzero satisfying assignment if and only if the instance of Sat(F ′ ) has a satisfying assignment. Let s = s 1 s 2 . . . s k be a satisfying assignment for the non-1-valid constraint f chosen above. First if v 1 , . . . , v n form a satisfying assignment to the instance of Sat(F ′ ), then we claim that the assignment w j = s j for 1 ≤ j ≤ k, w k+1 = 1 and y j = z j = v j for 1 ≤ j ≤ n is a satisfying assignment to the instance of Max Ones(F) which has at least one 1 (namely, w k+1 ). Conversely, let some nonzero setting w 1 , . . . , w k+1 , y 1 , . . . , y n , z 1 , . . . , z n satisfy the instance of Max Ones(F). W.l.o.g. the instance I we create an LP constraint using the following transformation rules:</p><formula xml:id="formula_59">C j : x i1 • • • x i k for k ≤ B → z j + y i1 + • • • + y i k ≥ 1, C j : ¬x i1 x i2 → z j + (1 -y i1 ) + y i2 ≥ 1, C j : ¬x i1 → z j + (1 -y i1 ) ≥ 1.</formula><p>In addition we add the constraints 0 ≤ z j , y i ≤ 1 for every i, j. It may be verified that any integer solution to the above LP corresponds to an assignment to the Min CSP problem with the variable z j set to 1 if the constraint C j is not satisfied. Thus the objective function for the LP is to minimize j w j z j . Given any feasible solution vector y 1 , . . . , y n , z 1 , . . . , z m to the LP above, we show how to obtain a 0/1 vector y ′′ 1 , . . . , y ′′ n , z ′′ 1 , . . . , z ′′ m that is also feasible such that j w j z ′′ j ≤ (B + 1) j w j z j . First we set y ′ i = min{1, (B + 1)y i } and z ′ j = min{1, (B + 1)z j }. Observe that the vector y ′ 1 , . . . , y ′ n , z ′ 1 , . . . , z ′ m is also feasible and gives a solution of value at most (B + 1) j w j z j . We now show how to get an integral solution whose value is at most j w j z ′ j ≤ (B + 1) j w j z j . For this part we first set</p><formula xml:id="formula_60">y ′′ i = 1 if y ′ i = 1 and z ′′ j = 1 if z ′ i = 1</formula><p>. Now we remove every constraint in the LP that is made redundant. Notice in particular that every constraint of type z j + y i1 + • • • + y i k ≥ 1 is now redundant (either z ′′ j or one of the y ′′ i 's has already been set to 1, and hence the constraint will be satisfied by any assignment to the remaining variables). We now observe that, on the remaining variables, the LP constructed above reduces to the following: Minimize j w j z j Subject to y i2y i1 + z j ≥ 0, y i2 + z j ≥ 1, -y i1 + z j ≥ 0 with the y ′ i 's and z ′ j 's forming a feasible solution to the above LP. Notice further that every z j occurs in at most one constraint above. Thus the above LP represents s-t min-cut problem and therefore has an optimal integral solution. We set z ′′ j 's and y ′′ i to such an integral optimal solution. Notice that the solution thus obtained is integral and satisfies j w j z ′′ j ≤ j w j z ′ j ≤ (B + 1) j w j z j . Lemma 7.4. For any family F ⊆ F 2A , Weighted Min CSP(F) A-reduces to Min CSP(XOR).</p><p>Proof. First we will argue that the family F ′ = {XOR, T, F } perfectly implements F. By Proposition 3.4 it suffices to implement the basic width-2 affine functions, namely, the functions XOR, XNOR, T , and F . Every function except XNOR is already present in F ′ and by Proposition 3.3 XOR perfectly implements XNOR.</p><p>We conclude by observing that the family {XOR} is neither 0-valid nor 1-valid and hence, by Lemma 5.7, Weighted Min CSP(F ′ ) A-reduces to Weighted Min CSP(XOR). Finally the weights can be removed using Proposition 7. Proof. Again it suffices to consider the basic constraints of F and this is some subset of {OR 2,0 , OR 2,1 , OR 2,2 , T, F }.</p><p>The family {OR, NAND} contains the first and the third functions. Since it contains a non-0-valid function, a non-1-valid function and a non-C-closed function, it can also implement T and F (by <ref type="bibr">Lemma 4.6)</ref>. This leaves the function OR 2,1 which is implemented by the constraints NAND(x, z Aux ) and OR(y, z Aux ) (on the variables x and y). The A-reduction now follows from Lemma 3.10. Lemma 7.6. For any family F ⊆ F A , the family {XOR 3 , XNOR 3 } perfectly implements every function in F. Thus Weighted Min CSP(F) ≤ A Nearest Codeword.</p><p>Proof. It suffices to show implementation of the basic affine constraints, namely, constraints of the form XNOR p and XOR q for every p, q ≥ 1. We focus on the former type, as the implementation of the latter is analogous. First, we observe that the constraint XNOR(x 1 , x 2 ) is perfectly implemented by the constraints {XNOR 3 (x 1 , x 2 , z 1 ), XNOR 3 (x 1 , x 2 , z 2 ), XNOR 3 (x 1 , x 2 , z 3 ), XNOR 3 (z 1 , z 2 , z 3 )}. Next, the constraint F (x 1 ) can be perfectly implemented by {XNOR(x 1 , z 1 ), XNOR(x 1 , z 2 ), XNOR(x 1 , z 3 ), XNOR 3 (z 1 , z 2 , z 3 )}. Finally, the constraint XNOR p (x 1 , . . . , x p ) for any p &gt; 3 can be implemented as follows. We introduce the following set of constraints using the auxiliary variables z 1 , z 2 . . . , z p-2 and the set of constraints {XNOR 3 (x 1 , x 2 , z 1 ), XNOR 3 (z 1 , x 3 , z 2 ), XNOR 3 (z 2 , x 4 , z 3 ), . . . , XNOR 3 (z p-2 , x p-1 , x p )} Lemma 7.7. For any family F ⊆ F WP , we have {OR 3,1 , T, F } p =⇒ F and thus Weighted Min CSP(F) ≤ A Min Horn Deletion.</p><p>Proof. As usual, it suffices to perfectly implement every function in the basis <ref type="figure">y</ref>) is implemented by the constraints OR 3,1 (a, x, y) and T (a). OR 2,1 (x, y) is implemented by OR 3,1 (x, y, a) and F (a). The implementation of OR 3 (x, y, z) is OR(x, a) and OR 3,1 (a, y, z) (the constraint OR(x, a), in turn, may be implemented with the already shown method). Thus every k-ary constraint for k ≤ 3 can be perfectly implemented by the family {OR 3,1 , T, F }). For k ≥ 4, we use the textbook reduction from Sat to 3-Sat (see, e.g., <ref type="bibr">[19, p. 49]</ref>) and we observe that when applied to k-ary weakly positive constraints it yields a perfect implementation using only 3-ary weakly positive constraints.</p><formula xml:id="formula_61">{OR k | k ≥ 1} ∪ {OR k,1 | k ≥ 1}. The constraint OR(x,</formula><p>To conclude this section we describe the trivial approximation algorithms for Nearest Codeword and Min Horn Deletion. They follow easily from Proposition 7.2 and the fact that both families are decidable.   </p><formula xml:id="formula_62">7.9 (APX-hardness). If F ⊆ F ′ , for F ′ ∈ {F 0 , F 1 , F 2M }, then Min CSP(F) is APX-hard.</formula><p>Proof. The proof essentially follows from Lemma 5.8 in combination with Proposition 3.7. We show that for every F, Max CSP(F) AP-reduces to Min CSP(F). Let I be an instance of Max CSP(F) on n variables and m constraints. Let x ′ be a solution satisfying m/k constraints that can be found in polynomial time (by Proposition 3.7). Let x ′′ be an r-approximate solution to the same instance I viewed as an instance of Min CSP(F). If opt is the optimum solution to the maximization problem I, then x ′′ satisfies at least mr(mopt) = ropt -(r -1)m constraints. Thus the better of the two solutions is an r ′ -approximate solution to the instance I of Max CSP(F), where but the complementary maxterm is not weakly positive (and by Lemma 4.20 every maxterm of f must be weakly positive). However, if all of f 's maxterms are of the form T (x i ), F (x i ), or OR 2,1 (x i , x j ), then f is in IHS-B. The lemma follows from the fact that F ⊆ F IHS .</p><p>Lemma 7.18. If f is a weakly positive function not expressible as IHS-B+, then {f, T, F } p =⇒ OR 3,1 . If f is a weakly negative function not expressible as IHS-B-, then {f, T, F } p =⇒ OR 3,2 . Proof. Let f be a weakly positive function. By Lemma 4.20 all maxterms of f are weakly positive. Since f is not IHS-B+, f must have a maxterm of the form (¬x 1 x 2 • • • x p ) for some p ≥ 3. We first show that {f, F } can perfectly implement the function XNOR. To get the former, consider the function</p><formula xml:id="formula_63">f 1 (x 1 , x 2 ) def = ∃x p+1 , . . . , x k s.t. f (x 1 , x 2 , 0 p-2 , x p+1 , . . . , x k ).</formula><p>The function f 1 satisfies the properties f 1 (10) = 0, f 1 (00) = f 1 (11) = 1. Thus f 1 is either the function XNOR or OR 2,1 . Notice that the constraints f (x 1 , . . . , x k ) and F (x i ), i ∈ {3, . . . , p}, perfectly implement f 1 . Thus {f, F } perfectly implement either the function XNOR or OR 2,1 . In the former case, we have the claim and in the latter case we use the fact that the constraints OR 2,1 (x, y) and OR 2,1 (y, x) perfectly implement XNOR(x, y).</p><p>Next, we show how the family {f, T, F, XNOR} (and hence {f, T, F }) can perfectly implement OR 2,1 . To do so, we consider the function f 2 (x 1 , x 2 , x 3 ) def = ∃x p+1 , . . . , x k s.t. f (x 1 , x 2 , x 3 , 0 p-3 , x p+1 , . . . , x k ).</p><p>Again {f, F } implement f 2 perfectly. By the definition of a maxterm, we find that f 2 satisfies the following properties: f 2 (100) = 0 and f 2 (000) = f 2 (110) = f 2 (101) = 1. Figure <ref type="figure" target="#fig_8">3</ref> gives the truth table for f 2 , where the unknown values are denoted by A, B, C, and D. If C = 0, then restricting x 1 = 1 gives the constraint XOR(x 2 , x 3 ). However, notice that XOR is not a weakly positive function and by Lemma 4.19 every function obtained by setting some of the variables in a weakly positive function to constants and existentially quantifying over some other subset of variables is a weakly positive function. Thus C = 1. If D = 1, we implement the function OR 2,1 (x 1 , x 2 ) by the constraints f 2 (x 1 , x 2 , x 3 ) and F (x 3 ). Otherwise we have D = 0, and the constraints f 2 (x 1 , x 2 , x 3 ) and XNOR(x 1 , x 3 ) implement the constraint OR 2,1 (x 2 , x 1 ).</p><p>Finally we conclude by observing that the constraints f 2 (x, z 1 , z 2 ), OR 2,1 (z 1 , y) and OR 2,1 (z 2 , z), perfectly implement the constraint OR 3,1 (x, y, z).</p><p>This completes the proof for the first part. The proof if f is weakly negative is similar.</p><p>Lemma 7.19 (the Min Horn Deletion-hard case). If F ⊆ F ′ for any F ′ ∈ {F 0 , F 1 , F 2M , F IHS , F 2A , F 2CNF }, and either F ⊆ F WP or F ⊆ F WN , then Weighted Min CSP(F) is Min Horn Deletion-hard.</p><p>Proof. From Lemma 7.18 we have that either Min CSP({OR 3,1 , T, F } or Min CSP({OR 3,2 , T, F } is A-reducible to Min CSP(F). Furthermore, since F is not 0valid or 1-valid we have that Min CSP(F ∪ {T, F }) is A-reducible to Min CSP(F). The lemma follows by an application of Proposition 7.1 which shows that the problems Min CSP({OR 3,1 , T, F }) A-reduces to Min CSP({OR 3,2 , T, F }).</p><p>To show the hardness of Min Horn Deletion we define a variant of the "label cover" problem. The original definition from <ref type="bibr" target="#b3">[2]</ref> used a different objective function. Our variant is similar to the one used by Amaldi and Kann <ref type="bibr" target="#b2">[1]</ref> under the name Total Label Cover. Definition 7.20 (Total Label Cover p ).</p><p>Instance. An instance is described by sets R, Q, and A and by p functions (given by their tables) Q 1 , . . . , Q p : R → Q and a function Acc : R × (A) p → {0, 1}.</p><p>Feasible solutions. A solution is a collection of p functions A 1 , . . . , A p : Q → 2 A . The solution is feasible if for every R ∈ R, there exists a 1 ∈ A 1 (Q 1 (R)), . . . , a p ∈ A p (Q p (R)) such that Acc(R, a 1 , . . . , a p ) = 1.</p><p>Objective. The objective is to minimize p i=1 q∈Q |A i (q)|. In Appendix A, we show how results from interactive proofs imply the hardness of approximating Min Label-Cover to within a factor of 2 log 1-ǫ n . We now use this result to show that hardness of Min Horn Deletion.</p><p>Lemma 7.21. For every ǫ &gt; 0, Min Horn Deletion is NP-hard to approximate to within a factor of 2 log 1-ǫ n .</p><p>Proof. Let p be such that Min Label-Cover p is NP-hard to approximate to within a factor of 2 log 1-ǫ n . (By Lemma A.3 such a p exists.) We now reduce Min Label-Cover p to Min Horn Deletion.</p><p>Let (Q 1 , . . . , Q p , Acc) be an instance of Min Label-Cover p , where Q i : R → Q and Acc : R × (A) p → {0, 1}. For any R ∈ R, we define Acc(R) = {(a 1 , . . . , a p ) : V (R, a 1 , . . . , a p ) = 1}.</p><p>We now describe the reduction. For any R ∈ R, a 1 , . . . , a p ∈ A, we have a variable v R,a1,...,ap whose intended meaning is the value of Acc(R, a 1 , . . . , a p ). Moreover, for every i ∈ [p], Q ∈ Q, and a ∈ A i we have a variable x i,Q,a with the intended meaning being that its value is 1 if and only if a ∈ A i (Q). For any x i,Q,a we have the weightone constraint ¬x i,q,a . The following constraints (each with weight (p × |Q| × |A|)) enforce the variables to have their intended meaning. Due to their weight, it is never convenient to contradict them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∀R ∈ R :</head><p>(a1,...,ap)∈Acc(R) v R,a1,...,ap ∀R ∈ R, a 1 , . . . , a p ∈ A, i ∈ [p] : v R,a1,...,ap ⇒ x i,Qi(R),ai .</p><p>The constraints of the first kind can be perfectly implemented with OR 3 and OR 3,1 (see Lemma 7.7). It can be checked that this is an AP-reduction from Min Label-Cover p to Min Horn Deletion and thus the lemma follows. For any decidable constraint family F, Weighted Min Ones(F) AP-reduces to Weighted Min CSP(F ∪ {F }).</p><p>Proof. Let I be an instance of Weighted Min Ones(F) over variables x 1 , . . . , x n with weights w 1 , . . . , w n . Let w max be the largest weight. We construct an instance I ′ of Weighted Min CSP(F ∪ {F }) by leaving the constraints of I (each with weight nw max ) and adding a constraint F (x i ) of weight w i for any i = 1, . . . , n. Notice that whenever I is feasible, the optimum value for I equals the optimum value for I ′ . Given an r-approximate solution to x to I ′ , we check to see if I is feasible and if so find any feasible solution x ′ and output solution (from among x and x ′ ) that achieves a lower objective. It is clear that the solution is at least an r-approximate solution if I is feasible.</p><p>Reducing a Min CSP problem to a Min Ones problem is slightly less general. Proposition 8.2.</p><p>For any function f , let f ′ and f ′′ denote the functions f ′ (x, y) = OR(f (x), y) and f ′′ (x, y) = XOR(f (x), y), respectively. If constraint families F and F ′ are such that for every f ∈ F, f ′ or f ′′ is in F ′ , then Weighted Min CSP(F) AP-reduces to Weighted Min Ones(F ′ ).</p><p>Proof. Given an instance I of Weighted Min CSP(F) we create an instance I ′ of Weighted Min Ones(F ′ ) as follows: For every constraint C j we introduce an auxiliary variable y j . The variable takes the same weight as the constraint C j in I. The original variables are retained with weight zero. If the constraint C j (x) y j is a constraint of F ′ we apply that constraint; otherwise we apply the constraint C j (x) ⊕ y = 1. Given an assignment to the variables of I, notice that by setting y j = ¬C j , we get a feasible solution to I ′ with the same objective value; conversely, a feasible solution to I ′ when projected onto the variables x gives a solution with the same value to the objective function of I. This shows that the optimum value to I ′ equals that of I and that an r-approximate solution to I ′ projects to give an r-approximate solution to I.</p><p>Finally the following easy proposition is invoked at a few places. Proposition 8.3. If F=⇒f , then F -=⇒f -.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.">Containment results for MIN ONES.</head><p>Lemma 8.4 (PO containment). If F ⊆ F ′ for some F ′ ∈ {F 0 , F WN , F 2A }, then Weighted Min Ones(F) is solvable exactly in polynomial time.</p><p>Proof. The proof follows from Lemma 6.5 and from the observation that for any family F, solving Weighted Min Ones(F) to optimality reduces to solving Weighted Max Ones(F -) to optimality. Proof. For the case F ⊆ F 2CNF , a 2-approximate algorithm is given by Hochbaum et al. <ref type="bibr" target="#b26">[25]</ref>. Now consider the case F ⊆ F IHS . From Proposition 3.4 it is sufficient to consider only basic IHS-B constraints. Since IHS-B-constraints are weakly negative, we will restrict ourselves to basic IHS-B+ constraints. We use linear programming relaxations and deterministic rounding. Let k be the maximum arity of a function in F; we will give a k-approximate algorithm. Let φ = {C 1 , . . . , C m } be an instance of Weighted Min Ones(F) over variable set X = {x 1 , . . . , x n } with weights w 1 , . . . , w n . The following is an integer linear programming formulation of finding the minimum weight satisfying assignment for φ.</p><p>Ones(F). The lemma follows from the fact that XOR 3 ∈ {XOR 4 }| 0 .</p><p>Lemma 8.13. If F is affine but not width-2 affine or 0-valid, then, for every ǫ &gt; 0, Min Ones(F) is Nearest Codeword-hard and hard to approximate to within a factor of Ω(2 log ǫ n ).</p><p>Proof. The proof follows from the following sequence of reductions:</p><p>Nearest Codeword = Weighted Min CSP({XOR ≤ AP Weighted Min Ones(F) (using Lemmas 8.12 and 3.9) ≤ AP Min Ones(F) (using Lemma 8.10).</p><p>The second reduction above follows by combining Lemma 3.9 with the observation that the family {XOR 3 , XOR} perfectly implement the functions XOR 4 and XNOR 4 as shown next. The constraints XOR 3 (u, v, w) and XOR 3 (w, x, y) perfectly implement the constraint XNOR 4 (u, v, x, y); the constraints XOR 4 (u, v, w, x) and XOR(w, y) perfectly implement XOR 4 (u, v, x, y). The hardness of approximation of Nearest Codeword is given by Lemma 7.16. Lemma 8.14.</p><p>If F is weakly positive and not IHS-B (nor 0-valid), then Min Ones(F) is Min Horn Deletion-hard, and hence hard to approximate within 2 log 1-ǫ n for any ǫ &gt; 0.</p><p>Proof. The proof follows from the following sequence of reductions:</p><p>Min Horn Deletion = Weighted Min CSP({OR Proof. We reduce Vertex Cover to Min Ones(OR). Given a graph G on n vertices, we construct an instance of Min Ones(OR) on n variables x 1 , . . . , x n . For every edge between vertex i and j of G, we create a constraint OR(x i , x j ). We notice that there is a one-to-one correspondence between an assignment to the variables and vertex covers in G (with variables assigned 1 corresponding to vertices in the cover) and the minimum vertex cover minimizes the sum of the variables. The lemma follows from the fact that Vertex Cover is APX-hard <ref type="bibr" target="#b40">[39,</ref><ref type="bibr" target="#b4">3]</ref>.</p><p>Lemma 8.16 (APX-hardness). If F ⊆ F ′ for any F ′ ∈ {F 0 , F WN , F 2A }, then Min Ones(F) is APX-hard.</p><p>Proof. We mimic the proof of Lemma 6.14. We assume that F is not affine-the case where F is affine is shown to be Nearest Codeword-hard in Lemma 8. <ref type="bibr" target="#b14">13</ref>. By every i ∈ {1, . . . , p}, it is the case that |A i (q)| = 1. Thus the value of the optimum solution is at most p • |Q|. Now we claim for a given x, if the mapped instance of Total Label Cover has a solution of size Kp|Q|, then there exist provers Π 1 , . . . , Π p such that V accepts with probability at least K -1/p /(p + 1) p+1 .</p><p>To see this let Π i (q) be a random element of A i (q). If n i,q denotes the cardinality of A i (q), then the probability that V accepts the provers response is given by</p><formula xml:id="formula_64">1 |R| R∈R i 1/n i,Qi(R) .</formula><p>Define R i to be {R ∈ R|n i,Qi(R) ≥ (p + 1)K}. By Markov's inequality and the uniformity of the protocol |R i |/|R| ≤ 1/(p + 1).</p><formula xml:id="formula_65">Let R 0 = R -R 1 -R 2 -• • • -R p . Then |R 0 |/|R| ≥ 1/(p + 1).</formula><p>We go back to bounding the probability above:</p><formula xml:id="formula_66">1 |R| R∈R i 1/n i,Qi(R) ≥ 1 |R| R∈R0 i 1/n i,Qi(R) ≥ 1 |R| R∈R0 i 1/n i,Qi(R) ≥ 1 |R| R∈R0</formula><p>(1/((p + 1)K) p ) ≥ K -1/p /(p + 1) p+1 .</p><p>It follows that if K = K(n) is less than 2 log 1-ǫ n , then for sufficiently large n, K -1/p /(p + 1) p+1 is greater than 2 log 1-ǫ/2 n . Thus a K-approximation algorithm for Total Label Cover p can be used to decide L. Thus Total Label Cover p is NP-hard to approximate to within a factor of 2 log 1-ǫ n .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>the bitwise exclusive-or of the assignments s 1 and s 2 . For s ∈ {0, 1} k , Z(s) denotes the subset of indices i ∈ [k], where s is zero and O(s) denotes the subset of indices where s in one. For a constraint f of arity k, S ⊆ [k] and b ∈ {0, 1}, f | (S,b) is the constraint of arity k ′ = k -|S| defined as follows: For variables x i1 , . . . , x i k ′ , where {i 1 , . . . , i k ′ } = [k]-S, we define f | (S,b) (x i1 , . . . , x i k ′ ) = f (x 1 , . . . , x k ), where x i = b for i ∈ S. We will sometimes use the notation f | (i,b) to denote the function f | ({i},b) . For a constraint family F, the family F| 0 is the family {f | S,0 |f ∈ F, S ⊆ [arity(f )]}. The family F| 1 is defined analogously. The family F| 0,1 is the family (F| 0 )| 1 (or equivalently the family (F| 1 )| 0 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Definition</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>If x = 1 ,</head><label>1</label><figDesc>then to satisfy the first of the two constraints (in addition to all the earlier constraints) above, we must have Z = S x , O = S y and thus must have y = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Claim 4 . 13 .</head><label>413</label><figDesc>Suppose f violates property (b) of Lemma 4.9. Then {f, T, F } s/p =⇒ XOR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>SFig. 1 .</head><label>1</label><figDesc>Fig. 1. Partition of inputs to g.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>2 . 7 . 5 .</head><label>275</label><figDesc>Lemmas 7.5-7.7 show reducibility to Min 2CNF Deletion, Nearest Codeword, and Min Horn Deletion. Lemma For any family F ⊆ F 2CNF , the family {OR, NAND} p =⇒ F and hence Weighted Min CSP(F)≤ A Min 2CNF Deletion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Corollary 7.8 (to Proposition 7.2). Min Horn Deletion and Nearest Codeword are in poly-APX.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>7. 3 .</head><label>3</label><figDesc>Hardness results (reductions) for MIN CSP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Lemma</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Truth table of the constraint f 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>8 .</head><label>8</label><figDesc>MIN ONES classification. 8.1. Preliminaries: MIN ONES vs. MIN CSP. We start with the following easy relation between Min CSP and Min Ones problems. Recall that a family F is decidable if membership in Sat(F) is decidable in polynomial time. Proposition 8.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Lemma 8 . 5 .</head><label>85</label><figDesc>If F ⊆ F ′ for F ′ ∈ {F 2CNF , F IHS }, then Weighted Min Ones(F) is in APX.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>• The Hitting Set problem, restricted to instances in which all sets are of size at most B, can be captured as Min Ones(F) for F = {OR k |k ≤ B}.</figDesc><table><row><cell>Also, of interest to our paper is a slight generalization of this problem which</cell></row><row><cell>we call the implicative Hitting Set-B problem (Min IHS-B) which is Min</cell></row><row><cell>CSP({OR k : k ≤ B} ∪ {OR 2,1 , F }). The Min Ones version of this problem</cell></row><row><cell>will be of interest to us as well. The Hitting Set-B problem is well known</cell></row><row><cell>to be approximable to within a factor of B. We show that Min IHS-B is</cell></row><row><cell>approximable to within a factor of B + 1.</cell></row><row><cell>• Min UnCut = Min CSP({XOR}). This problem has been studied previ-</cell></row><row><cell>ously by Klein et al.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>weakly positive, then the clause C 0 j0 involves at most one negated variable, and the clause C 1 j1 involves no negated variable (since the clause participating in f is (C 1 j1 (x) ¬y) which has a negated y involved in it). Thus the clause defining C 01 j0j1 also has at most one negated variable. • Similarly if f is weakly negative, then the clauses C 01 j0j1 has at most one positive literal. • If f is 2CNF, then the clauses C 0 j0 and C 1 j1 are of length 1, and hence the clause C 01 j0j1 is of length at most 2. • If f is IHS-B+, then the clause C 0 j0 either has only one literal which is negated or has only positive literals. Furthermore, C 1 j1 has at most one positive literal. Thus C 01 j0j1 either has only positive literals or has at most two literals, one of which is negated. Hence C 01 j0j1 is also IHS-B+. • Similarly if f is IHS-B-, then the clause C 01 j0j1 is also IHS-B-. This concludes the proof of the lemma. Lemma 4.20. f is a weakly positive (weakly negative) constraint if and only if all its maxterms are weakly positive (weakly negative).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>). Figure 2 describes the truth table for the function h. The undetermined values of interest to us are indicated in the table by A and B. The following analysis shows that for every possible value of A and B, we can perfectly implement either NAND or OR 2,1 :</figDesc><table><row><cell>Claim 6.22. If h is ternary function such that h(000) = h(011) = h(101) = 1 and h(110) = 0, then {h}| 0 p =⇒ NAND or {h}| 0 p =⇒ OR 2,1 .</cell></row><row><cell>Proof.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>3 , XNOR 3 }) ≤ AP Weighted Min Ones({XOR 4 , XNOR 4 }) (using Proposition 8.2) ≤ AP Weighted Min Ones({XOR 3 , XOR}) (see below) ≤ AP Weighted Min Ones(XOR 3 ) (using Lemma 8.11)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>3,1 , T, F } ≤ AP Weighted Min Ones({OR 4,1 , OR 2 , OR 2,1 }) (using Proposition 8.2) ≤ AP Weighted Min Ones({OR 3,1 , T, F }) (using Lemmas 7.7 and 3.9) ≤ AP Weighted Min Ones(F ∪ {T, F }) (using Lemmas 7.18 and 3.9) ≤ AP Weighted Min Ones(F ∪ {F }) (using Lemma 4.6 to perfectly implement T ) ≤ AP Weighted Min Ones(F) (using Lemma 8.11) ≤ AP Min Ones(F) (using Lemma 8.10).The hardness of approximation follows from Lemma 7.21.Lemma 8.15. Min Ones(OR) is APX-hard.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>Our definition of an unweighted problem is more loose than that of Crescenzi, Silvestri, and Trevisan. In their definition they disallow instances with repeated constraints, while we do allow them. We believe that it may be possible to remove this discrepancy from our work by a careful analysis of all proofs. We do not carry out this exercise here.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>Such clauses are usually called Horn clauses.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>Notice that C-closedness implies that f is 0-valid if and only if it is 1-valid.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. We thank Mihir Bellare, Nadia Creignou, Oded Goldreich, and Jean-Pierre Seifert for useful discussions. We thank an anonymous referee for pointing out numerous errors in a previous version of this paper.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In other words s = 0 p 1 q+r+t 0 u+v 1 w and f (s) = 0. Furthermore, every assignment of the form 1 p+q+r * t+u+v+w satisfies f and every assignment of the form * p+q 1 r+t+u * v+w satisfies f (where the * 's above can be replaced by any of 0/1 independently). In particular this implies that p, u ≥ 1. Consider the function f 1 on p + u ≥ 2 variables obtained from f by restricting the variables in O(s) to 1 and restricting the variables in Z(s) -(V 1 ∪ V 2 ) to 0. Notice that the constraint applications f (x 1 . . . x k ), T (x i ) for i ∈ O(s) and F (x i ) for i ∈ Z(s) -(V 1 ∪ V 2 ) strictly implement f 1 . Thus it suffices to show that {f 1 , T, F } implements XOR. We do so by observing that f 1 (x 1 . . . x p+u ) is the function NAND p+u . Notice that f 1 (0) = 0. Furthermore, if f 1 (t) = 0 for any other assignment t, then it contradicts the maximality of the number of 1's in s. The claim now follows from Lemma 4.10, part <ref type="bibr" target="#b4">(3)</ref>, which shows that the family {NAND p+u , T, F } implements XOR, provided p + u ≥ 2. Proof. The proof is similar to the proof of the claim above.</p><p>The lemma now follows from the fact that any constraint f 2 that is not 2monotone must violate one of the properties (a), (b), or (c) from Lemma 4.9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Affine functions.</head><p>Lemma 4.15 (see <ref type="bibr" target="#b43">[42]</ref>). f is an affine function if and only if for every three satisfying assignments s 1 , s 2 , and s 3 to f , s 1 ⊕s 2 ⊕s 3 is also a satisfying assignment.</p><p>We first prove a simple consequence of the above which gives a slightly simpler sufficient condition for a function to be affine.</p><p>Corollary 4.16. If f is not affine, then there exist two satisfying assignments s 1 and s 2 for f such that s 1 ⊕ s 2 does not satisfy f . Proof. Assume otherwise. Then for any three satisfying assignments s 1 , s 2 , and s 3 , we have that f (s 1 ⊕ s 2 ) = 1, and hence f ((s 1 ⊕ s 2 ) ⊕ s 3 ) = 1, thus yielding that f is affine.</p><p>Lemma 4.17. If f is an affine constraint, then any function obtained by restricting some of the variables of f to constants and existentially quantifying over some other set of variables is also affine.</p><p>Proof. We use Lemma 4.15 above. Let f 1 be a function derived from f as above. Consider any three assignments s ′ 1 , s ′ 2 , and s ′ 3 which satisfy f 1 . Let s 1 , s 2 , and s 3 be the respective extensions which satisfy f . Then the assignment s 1 ⊕ s 2 ⊕ s 3 extends s ′ 1 ⊕ s ′ 2 ⊕ s ′ 3 and satisfies f . Thus s ′ 1 ⊕ s ′ 2 ⊕ s ′ 3 satisfies f 1 . Thus (using Lemma 4.15) again, we find that f 1 is affine. Proof. Let k be the arity of f . Define a dependent set of variables to be a set of variables S ⊆ {1, . . . , k} such that not every assignment to the variables in S extends to a satisfying assignment of f . A dependent set S is a minimally dependent set if one of these cases the assignment to x F is false and then we notice that a constraint of I is satisfied if and only if the corresponding constraint in I ′ is satisfied. Thus every solution to I ′ can be mapped to a solution to I with the same contribution to the objective function.</p><p>The required lemma now follows as a simple combination of Lemmas 4.9 and 5.7. Lemma 5.8.</p><p>Proof. By Lemma 4.11 F ∪ {T, F } strictly implements the XOR function. Thus Max CSP(XOR) AP-reduces to Max CSP(F ∪{T, F }) which in turn (by Lemma 5.7) AP-reduces to Max CSP(F). Thus Max CSP(F) is APX-hard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.</head><p>3. Hardness at gap location 1. Schaefer's dichotomy theorem can be extended to show that in the cases where Sat(F) is NP-hard to decide, it is actually hard to distinguish satisfiable instances from instances which are not satisfiable in a constant fraction of the constraints. This is termed hardness at gap location 1 by Petrank <ref type="bibr" target="#b41">[40]</ref>, who highlights the utility of such hardness results in other reductions. The essential observation needed is that perfect implementations preserve hardness gaps located at 1 and that Schaefer's proof is based on perfect implementations.</p><p>However, Schaefer's proof of NP-hardness in his dichotomy theorem relies on the ability to replicate variables within a constraint application. Specifically, the following lemma can be abstracted from his paper.</p><p>Lemma 5.9 (see <ref type="bibr" target="#b43">[42]</ref>). If F is not 0-valid or 1-valid or affine or bijunctive or weakly positive or weakly negative, then F ∪ {XNOR} p =⇒ F 3SAT . In this section, we show that a family F that is not decidable also perfectly implements the XNOR constraint and thus the lemma above can be strengthened. We start with the following lemma that shows how to use functions that are not weakly negative. Proof. We prove only the first part-the second part follows by symmetry. By Lemma 4.20 we find that f has a maxterm with at least two positive literals. W.l.o.g. the maxterm is of the form x 1 x 2 • • • x p ¬x p+1 • • • ¬x q with p ≥ 2. We consider the function f ′ which is f existentially quantified over all variables but x 1 , . . . , x q . Furthermore, we set x 3 , . . . , x p to 0 and x p+1 , . . . , x q to 1. Then the assignment x 1 = x 2 = 0 is a nonsatisfying assignment. The assignments x 1 = 0 = x 2 and x 1 = 0 = x 2 must be satisfying assignments by the definition of maxterm (and in particular by the minimality of the clause). The assignment x 1 = x 2 = 1 may go either way. Depending on this we get either the function XOR or OR.</p><p>Corollary 5.11. If f 2 is not weakly positive and f 3 is not weakly negative, then {f 2 , f 3 , T, F } p =⇒ XOR. Lemma 5.12. If F is not 0-valid or 1-valid or weakly positive or weakly negative, then F s/p =⇒ {XOR, XNOR}. Proof. If F is C-closed, then, by Lemma 4.5, we immediately get a strict and perfect implementation of XOR. If it is not C-closed, then, by Lemma 4.6, we get perfect and strict implementations of the constraints T and F . Applying Corollary 5.11 now, we get a perfect and strict implementation of XOR in this case also. Finally we use Proposition 3.3 to get a perfect and strict implementation of XNOR from the constraint XOR.</p><p>Combining Lemma 5.9 and the above, we get the following corollary.</p><p>Lemma 6.10. If F is affine but neither width-2 affine nor 1-valid, then</p><p>Proof. Since F is affine but not of width-2, it can perfectly (and strictly) implement the function XOR p or XNOR p for some p ≥ 3 (Lemma 4.18). Let f ∈ F be an affine constraint that is not 1-valid. We consider two possible cases depending on whether F is C-closed or not. If g ∈ F is not C-closed, then we find (by Lemma 4.7) that {f, g} (and hence F) perfectly implements some existential zero constraint. This case is covered in Claim 6.11 and we show that in this case F perfectly implements XNOR 3 . In the other case, F is C-closed, and hence (by Lemma 4.5) F perfectly implements the constraint XOR. This case is covered in Claim 6.12 and we show that in this case F perfectly implements either XNOR 3 or XNOR 4 . This concludes the proof of Lemma 6.10 (modulo Claims 6.11 and 6.12). Claim 6.11. If {f } is an existential zero constraint and h is either the constraint XOR p or XNOR p for some p ≥ 3, then {f, h} p =⇒ XNOR 3 . Proof. Since f is an existential zero constraint, the family {f, h} can perfectly implement {f, h}| 0 (using Lemma 6.4). In particular, {f, h} can implement the constraints x 1 ⊕ x 2 = b and x 1 ⊕ x 2 ⊕ x 3 = b for some b ∈ {0, 1}. Notice finally that the constraints x 1 ⊕ x 2 ⊕ y = b and y ⊕ x 3 = b form a perfect implementation of the constraint x 1 ⊕ x 2 ⊕ x 3 = 0. Thus {f, h} perfectly implements the constraint XNOR 3 . Claim 6.12.</p><p>Proof. Since XOR perfectly implements XNOR it suffices to prove this using the constraints {f, XOR, XNOR}.</p><p>W.l.o.g assume that f is the constraint XNOR, since otherwise XOR p (x 1 , . . . , x p-1 , y) and XOR(y, x p ) perfectly implement the constraint XNOR p (x 1 , . . . , x p ). Now if p is odd, then the constraints XNOR p (x 1 , . . . , x p ) and XNOR(x 4 , x 5 ), XNOR(x 6 , x 7 ), and so on up to XNOR(x p-1 , x p ) perfectly implement the constraint XNOR 3 (x 1 , x 2 , x 3 ). Now if p is even, then the constraints XNOR p (x 1 , . . . , x p ) and XNOR(x 5 , x 6 ), XNOR(x 7 , x 8 ), and so on up to XNOR(x p-1 , x p ) perfectly implement the constraint XNOR 4 (x 1 , x 2 , x 3 , x 4 ). Lemma 6.13. If F is affine but neither width-2 affine nor 1-valid, then Max Ones(F) is APX-hard.</p><p>Proof. By Lemma 6.6 we have Weighted Max Ones(F) is in APX and thus (by Lemma 3.11) it suffices to show APX-hardness of Weighted Max Ones(F). This now follows from Lemmas 3.9, 6.9, and 6.10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.3.2.</head><p>The poly-APX-hard case. This part turns out to be long and the bulk of the work will be done in Lemmas 6.16-6.21. We first describe the proof of the hardness result modulo the above lemmas. (Hopefully, the proof will also provide some motivation for the rest of the lemmas.) Lemma 6.14.</p><p>Proof. As usual, by Lemmas 6.2 and 3.11, it suffices to show hardness of the weighted version. First we show in Lemma 6.15 that Max Ones({NAND k }) is poly-APX-hard for every k ≥ 2. Thus our goal is to establish that any non-1-valid, nonaffine, and nonweakly positive constraint family can implement some NAND k constraint. We do so in three phases.</p><p>Proof. Corollary 4.16 shows that if f is not affine, then there exist two satisfying assignments s 1 and s 2 such that s 1 ⊕ s 2 is not a satisfying assignment for f . Reorder the variables such that Z(s 1 ) ∩ Z(s 2 ) = {x 1 , . . . , x p }, Z(s 1 ) ∩ O(s 2 ) = {x p+1 , . . . , x q }, O(s 1 ) ∩ Z(s 2 ) = {x q+1 , . . . , x r }, and O(s 1 ) ∩ O(s 2 ) = {x r+1 , . . . , x k }. Using the fact that f is 0-valid, we find that f looks as follows:</p><p>x 1 ...x p x p+1 ...x q x q+1 ...x r x r+1 ... Consider the following collection of constraints:</p><p>(1) f (0, . . . , 0, x p+1 , . . . , x k ).</p><p>(</p><p>. Existentially quantifying over the variables x p+1 , . . . , x k we obtain an implementation of a constraint h(x, y, z) such that h(000) = h(011) = h(101) = 1 and h(110) = 0. Furthermore, by restricting more of the variables in (1) above to 0, we get a perfect implementation of any constraint in {h}| 0 . Using Claim 6.22 again we get that {h}| 0 can implement either NAND or OR 2,1 , and thus we are done.</p><p>Finally we show how to use OR 2,1 constraints. Lemma 6.19.</p><p>Proof. We show something stronger, namely, Weighted Max Ones(F ∪ {T }) AP-reduces to Weighted Max Ones(F ∪ {OR 2,1 }). This suffices since T is an existential one constraint and thus F ∪ {T } can perfectly implement F| 1 .</p><p>Given an instance I of Weighted Max Ones(F ∪ {T }) construct an instance I ′ of Weighted Max Ones(F ∪ {OR 2,1 }) as follows. The variable set of I ′ is the same as that of I. Every constraint from F in I is also included in I ′ . The only remaining constraints are of the form T (x i ) for some variables x i . We simulate this constraint in I ′ with n -1 constraints of the form OR 2,1 (x j , x i ) (i.e., ¬x j x i ) for every j ∈ [n], j = i. Every nonzero solution to the resulting instance I ′ is also a solution to I, since the solution must have x i = 1 or else have x j = 0 for every j = i. Thus the resulting instance of Max Ones(F ∪ {OR 2,1 }) has the same objective function and the same feasible space and hence is at least as hard as the original problem.</p><p>This concludes Phase 2. Phase 3. F| 0,1 implements NAND. Lemma 6.20. If f is not weakly positive, then {f }| 0,1 perfectly implements either XOR or NAND.</p><p>Proof.</p><p>a maxterm in f with more than one negation, i.e., p ≥ 2. Substituting a 1 for variables x 3 , . . . , x p , a 0 for variables y 1 , . . . , y q , and existentially quantifying over all variables not in C, we get a constraint f ′ such that f ′ (11) = 0, f ′ (01) = f ′ (10) = 1. (These three properties follow from the definition of a maxterm.) Depending on whether f ′ (00) is 0 or 1 we get the function XOR or NAND, respectively. Lemma 6.21. If g is a nonaffine constraint, then {g, XOR}| 0,1 p =⇒ NAND. Proof. Again it suffices to consider {g, XOR, XNOR}| 0,1 . Let g be of arity k. By Lemma 4.15 we find that there must exist assignments s 1 , s 2 , and s 3 satisfying g such assume that one of the variable w 1 , . . . , w k+1 , y 1 , . . . , y n is a 1. Then we claim that the setting v j = z j , 1 ≤ j ≤ n, satisfies the instance of Sat(F ′ ). It is easy to see that the constraints</p><p>). Since at least one of the variables in the set w 1 , . . . , w k is a 0 and at least one of the variables in the set w 1 , . . . , w k+1 , y 1 , . . . , y n is 1, we know that both g(0, z i1 , . . . , z i k-1 ) and g(1, z i1 , . . . , z i k-1 ) are satisfied, and hence C i (v i1 , . . . , v i k-1 ) = 1. Thus the reduced instance of Max Ones(F) has a nonzero satisfying assignment if and only if the instance of Sat(F ′ ) is satisfiable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Classification of MIN CSP.</head><p>7.1. Preliminary results. We start with a simple equivalence between the complexity of the (Weighted) Min CSP problem for a function family and the family of functions obtained by complementing the 0's and 1's in its domain. Recall that for a function f , we defined f -to be the function f -(x) = f (1x), and for a function family F, we defined</p><p>Proposition 7.1. For every constraint family F, (Weighted) Min CSP(F) is AP-reducible to (Weighted) Min CSP(F -).</p><p>Proof. The reduction substitutes every constraint f (x) from F with the constraint f -(x) from F -. A solution for the latter problem is converted into a solution for the former one by complementing the value of each variable. The transformation preserves the cost of the solution.</p><p>Proposition 7.2. If F is decidable, then Weighted Min CSP(F) is in poly-APX and is AP-reducible to Min CSP(F).</p><p>Proof. Given an instance I of Weighted Min Ones(F) with constraints C 1 , . . . , C m sorted in order of decreasing weight w 1 ≥ • • • ≥ w m . Let j be the largest index such that the constraints C 1 , . . . , C j are simultaneously satisfiable. Notice that j is computable in polynomial time and an assignment a satisfying C 1 , . . . , C j is computable in polynomial time. Then the solution a is an m-approximate solution to I, since every solution must fail to satisfy at least one of the constraints C 1 , . . . , C j+1 and thus have an objective of at least w j+1 , while a achieves an objective of at most m i=j+1 w i ≤ mw j+1 . Thus we conclude that Weighted Min CSP(F) is in poly-APX. The second part of the proposition follows by Lemma 3.11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Containment results (algorithms) for MIN CSP.</head><p>We now show the containment results described in Theorem 2.13. Most results described here are simple containment results which follow easily from the notion of a "basis." The more interesting result here is a constant factor approximation algorithm for IHS-B which is presented in Lemma 7.3.</p><p>Recall that the classes contained in PO have already been dealt with in section 5.1. We now move on to APX-containment results. Given an instance I of Weighted Min CSP(IHS-B) on variables x 1 , . . . , x n with constraints C 1 , . . . , C m with weights w 1 , . . . , w m , we create a linear program on variables y 1 , . . . , y n (corresponding to the Boolean variables x 1 , . . . , x n ) and variables z 1 , . . . , z m (corresponding to the constraints C 1 , . . . , C m ). For every constraint C j in</p><p>Thus Max CSP(F) AP-reduces to Min CSP(F). The lemma follows from the APXhardness of Max CSP(F) (Lemma 5.8).</p><p>Lemma 7.10 (Min UnCut-hardness).</p><p>Proof. Recall that Min UnCut-hardness requires that Min CSP(XOR) be Areducible to Min CSP(F).</p><p>Let f ∈ F. Consider (all) the minimally dependent sets of f . By Lemma 4.22 all such sets are of cardinality at most 2. For a minimally dependent set {i, j} let</p><p>By Lemma 4.17 all the f i,j 's are affine and thus must be one of the functions T (x i ), F (x i ), XOR(x i , x j ), or XNOR(x i , x j ). Furthermore, f can be expressed as the conjunction of f i,j 's over all the minimally dependent sets. It follows that there exist i, j such that f i,j (x i , x j ) = XOR(x i , x j ). (Otherwise f would be a conjunction of T , F and XNOR functions, all of which are in F IHS , and thus f would also be in F IHS .) Thus we conclude that f implements XOR and by Lemma 3.10 we conclude that Min CSP(XOR) is A-reducible to Min CSP(F) as desired.</p><p>For the Min 2CNF Deletion-hardness proof, we need the following three simple lemmas.</p><p>Lemma 7.11. If f is a 2CNF function which is not width-2 affine, then f p =⇒ OR 2,l for some l ∈ {0, 1, 2}.</p><p>Proof. For i, j ∈ [k], let</p><p>Recall that if f can be expressed as the conjunction of f i.j 's over all its maxterms and by Lemma 4.21, all the maxterms of f 's have at most two literals in them. Thus f (x 1 , . . . , x k ) can be expressed as i,j∈[k] f i,j (x i , x j ). It follows that some f i,j must be one of the functions OR 2,0 , OR 2,1 , or OR 2,2 (all other functions on two variables are affine). Thus existentially quantifying over all variables other than x i and x j , f perfectly implements OR 2,l for some l ∈ {0, 1, 2}. Lemma 7.12. If f ∈ F 2CNF is not in IHS-B, then f p =⇒ XOR. Proof. Once again we use the fact that f can be expressed as i,j∈[k] f i,j (x i , x j ), where f i,j is the function obtained from f by existentially quantifying over all variables other than x i and x j . It follows that one of the f i,j 's must be NAND or XOR, since all the other functions on two variables are in IHS-B+. In the latter case we are done; otherwise we use the fact that f is not in IHS-B-to conclude that f perfectly implements OR or XOR. In the latter case again we are done; otherwise we use the fact that f perfectly implements both the functions NAND and OR, and that NAND(x, y) and OR(x, y) perfectly implement XOR(x, y) to conclude that in this case too, the function f perfectly implements XOR. Proof. The lemma follows from the fact that the function XOR essentially allows us to negate literals. For example, given the function OR 2,1 (x, y) and XOR, the applications OR 2,1 (x, z Aux ) and XOR(z Aux , y) perfectly and strictly implement the function NAND(x, y). Other implementations are obtained similarly.</p><p>Lemma 7.14 (Min 2CNF Deletion-hardness).</p><p>Proof. By Lemmas 7.11 and 7.12, F implements one of the functions OR 2,l for l ∈ {0, 1, 2} and the function XOR. By Lemma 7.13 this suffices to implement the family {NAND, OR}. Thus by Lemma 3.10 we conclude that Min CSP({OR, NAND}) Areduces to Min CSP(F).</p><p>Lemma 7.15.</p><p>Proof. By Lemma 4.18 we know that in this case F perfectly implements the constraint x 1 ⊕ • • • ⊕ x p = b for some p ≥ 3 and some b ∈ {0, 1}. Thus the family F ∪ {T, F } implements the functions</p><p>Since F is neither 0-valid nor 1-valid, we can use Lemma 5.7 to conclude that Min CSP(F) is Nearest Codeword-hard.</p><p>The next lemma describes the best known hardness of approximation for the Nearest Codeword problem. The result relies on an assumption stronger than NP = P. Lemma 7.16 (see <ref type="bibr" target="#b3">[2]</ref>). For every ǫ &gt; 0, Nearest Codeword is hard to approximate to within a factor of Ω(2 log 1-ǫ n ) unless NP has deterministic algorithms running in time n log O(1) n .</p><p>Proof. The required hardness of the Nearest Codeword problem is shown by Arora et al. <ref type="bibr" target="#b3">[2]</ref>. The Nearest Codeword problem, as defined in Arora et al., works with the following problem: Given an m × n matrix A and an m-dimensional vector b, find an n-dimensional vector x which minimizes the Hamming distance between Ax and b. Thus this problem can be expressed as a Min CSP problem with m affine constraints over n-variables. The only technical point to be noted is that these constraints have unbounded arity. In order to get rid of such long constraints, we replace a constraint of the form x 1 ⊕• • •⊕x l = 0 into l-2 constraints x 1 ⊕x 2 ⊕z 1 = 0, z 1 ⊕x 3 ⊕z 2 = 0, etc. on auxiliary variables z 1 , . . . , z l-3 . (The same implementation was used in Lemma 7.6.) This increases the number of constraints by a factor of at most n but does not change the objective function. Thus if M represents the number of constraints in the new instance of the problem, then the approximation hardness which is 2 log 1-ǫ m can be expressed as 2 1 2 log 1-ǫ M which is still growing faster than, say, 2 log 1-2ǫ M . Since the result of <ref type="bibr" target="#b3">[2]</ref> holds for every positive ǫ, we still get the desired result claimed above.</p><p>It remains to see the Min Horn Deletion-hard case. We will have to draw some nontrivial consequences from the fact that a family is not IHS-B.</p><p>Lemma 7.17. Assume F ⊆ F IHS and either F ⊆ F WP or F ⊆ F WN . Then F contains a function that is not C-closed.</p><p>Proof. Let f be a C-closed function in F WP (F WN ). We claim that all of f 's maxterms must be of the form T (x i ), F (x i ), or OR 2,1 (x i , x j ). If not, then since f is C-closed, the maxterm involving the complementary literals is also a maxterm of f ,</p><p>∀i ∈ {1, . . . , n}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(SCB)</head><p>Now consider the linear programming relaxation obtained by relaxing the y i ∈ {0, 1} constraints into 0 ≤ y i ≤ 1. We first find an optimum solution y * for the relaxation, and then we define a 0/1 solution by setting</p><p>It is easy to see that this rounding increases the cost of the solution at most k times and that the obtained solution is feasible for (SCB).</p><p>Lemma 8.6.</p><p>For any F ⊆ F A , Weighted Min Ones(F) is A-reducible to Nearest Codeword.</p><p>Proof. From Lemmas 7.6 and 3.9 we have that Weighted Min Ones(F) is A-reducible to Weighted Min Ones({XNOR 3 , XOR 3 }). From Proposition 8.1, we have that Weighted Min Ones(F) A-reduces to Weighted Min CSP({XOR 3 , XNOR 3 , F }). Notice further that the family {XNOR 3 , XOR 3 } can implement F (by Lemma 4.6). Thus we have that Weighted Min Ones(F) A-reduces to Weighted Min CSP({XOR 3 , XNOR 3 , }) = Nearest Codeword. Lemma 8.7. For any F ⊆ F WP , Weighted Min Ones(F) AP-reduces to Min Horn Deletion.</p><p>Proof. The proof follows from the following sequence of assertions: (1) {OR 3,1 , T, F } perfectly implements F (Lemma 7.7).</p><p>(2) Weighted Min Ones(F) AP-reduces to Weighted Min Ones({OR 3,1 , T, F }) (Lemma 3.9). (3) Weighted Min Ones({OR 3,1 , T, F }) AP-reduces to Weighted Min CSP ({OR 3,1 , T, F }) = Min Horn Deletion (Proposition 8.1). Proposition 8.8. If F is decidable, then Min Ones(F) is in poly-APX. Proof. The proposition follows immediately from the fact that in this case it is easy to determine if the input instance is feasible and if so, if the optimum value is zero. If so we output the 0 as the solution; otherwise we output any feasible solution. Since the objective is at least 1 and the solution has value at most n, this is an n-approximate solution.</p><p>8.3. Hardness results for MIN ONES. We start by considering the hardest problems first. The case when F is not decidable is immediate. We move to the case where F may be 1-valid but not in any other of Schaefer's easy classes.</p><p>Lemma 8.9. If F ⊆ F ′ for any F ′ ∈ {F 0 , F 2CNF , F A , F WP , F WN }, then Weighted Min Ones(F) is hard to approximate to within any factor, and Min Ones(F) is poly-APX-hard.</p><p>Proof. We first show how to handle the weighted case. The hardness for the unweighted case will follow easily. Consider a function f ∈ F which is not weakly positive. For such an f , there exists assignments a and b such that f (a) = 1 and f (b) = 0 and a is zero in every coordinate where b is zero. (Such an input pair exists for every nonmonotone function f and every monotone function is also weakly positive.) Now let f ′ be the constraint obtained from f by restricting it to inputs where b is one and setting all other inputs to zero. Then f ′ is a satisfiable function which is not 1-valid. We can now apply Schaefer's theorem <ref type="bibr" target="#b43">[42]</ref> to conclude that Sat(F ∪ {f ′ }) is hard to decide. We now reduce an instance of deciding Sat(F ∪ {f ′ }) to approximating Weighted Min CSP(F). Given an instance I of Sat(F ∪ {f ′ }) we create an instance which has some auxiliary variables W 1 , . . . , W k which are all supposed to be zero. This in enforced by giving them very large weights. We now replace every occurrence of the constraint f ′ in I by the constraint f on the corresponding variables with the W i 's in place which were set to zero in f to obtain f ′ . It is clear that if a "small" weight solution exists to the resulting Weighted Min CSP problem, then I is satisfiable; otherwise it is not. Thus we conclude it is NP-hard to approximate Weighted Min CSP to within any bounded factors.</p><p>For the unweighted case, it suffices to observe that by using polynomially bounded weights above, we get a poly-APX hardness. Furthermore, one can get rid of weights entirely by replicating variables.</p><p>We may now restrict our attention to function families F that are 2CNF or affine or weakly positive or weakly negative or 0-valid. In particular, by the containment results shown in the previous section, in all such cases the problem Weighted Min Ones(F) is in poly-APX. We now give a weight-removing lemma which allows us to focus on showing the hardness of the weighted problems.</p><p>Lemma 8.10. If F ⊆ F ′ for some F ′ ∈ {F 2CNF , F A , F WP , F WN , F 0 }, then Weighted Min Ones(F) AP-reduces to Min Ones(F).</p><p>Proof. By Lemma 3.11 it suffices to verify that Weighted Min Ones(F) is in poly-APX in all cases. If F is weakly negative or 0-valid, then this follows from Lemma 8.4. If F is 2CNF, then this follows from Lemma 8.5. If F is affine or weakly positive, then it A-reduces to Nearest Codeword or Min Horn Deletion, respectively, which are in poly-APX by Corollary 7.8.</p><p>Before dealing with the remaining cases, we prove one more lemma that is useful in dealing with Min Ones problems.</p><p>Lemma 8.11. For every constraint family F such that F ∪ {F } is decidable, Weighted Min Ones(F ∪ {F }) AP-reduces to Weighted Min Ones(F).</p><p>Proof. Given an instance I of Weighted Min Ones(F ∪ {F }) on n variables x 1 , . . . , x n with weights w 1 , . . . , w n we create an instance I ′ of Weighted Min Ones(F) on the variables x 1 , . . . , x n using all the constraints of I that are from F; and for every variable x i such that F (x i ) is a constraint of I, we increase the weight of the variable x i to nw max , where w max is the maximum of the weights w 1 , . . . , w n . As in the proof of Proposition 8.1 we observe that if I is feasible, then the optima for I and I ′ are equal and given an r-approximate solution to I ′ we can find an r-approximate solution to I. Furthermore, since F ∪{F } is decidable, we can decide whether or not I is feasible.</p><p>We now deal with the affine problems. Lemma 8.12.</p><p>If F is affine but not width-2 affine or 0-valid, then Min Ones(XOR 3 ) is AP-reducible to Weighted Min Ones(F).</p><p>Proof. Notice that since F is affine, so is F -. Furthermore, F -is neither width-2 affine nor 1-valid. Thus by Lemma 6.10 F -perfectly implements either the family {XNOR 3 } or the family {XOR, XNOR 4 }. Thus, by applying Proposition 8.3, we get that F implements either XOR 3 or the family {XOR, XNOR 4 }. In the former case, we are done (by Lemma 3.9). In the latter case, notice that the constraints XNOR 4 (x 1 , x 2 , x 3 , x 5 ) and XOR(x 4 , x 5 ) perfectly implement the constraint XOR 4 (x 1 , x 2 , x 3 , x 5 ). Thus we conclude that Weighted Min Ones(XOR 4 ) is APreducible to Weighted Min Ones(F). Finally we use Lemma 8.11 to conclude that the family Weighted Min Ones(F)({XOR}| 0 ) is AP-reducible to Weighted Min Appendix A. Hardness of TOTAL LABEL COVER. Definition A.1. L ∈ MIP c,s [p, q, a] if there exists a polynomial time bounded probabilistic oracle machine V (verifier) such that on input x ∈ {0, 1} n , the verifier picks a random string R ∈ {0, 1} r(n) and generates p queries</p><p>and sends query Q i to prover Π i and receives from prover Π i an answer A i = A i (Q i ) ∈ {0, 1} a(n) and then computes a verdict Acc(x, R, A 1 , . . . , A p ) ∈ {0, 1} with the following properties:</p><p>We say V is uniform if for every x and i, there exists d x,i s.t. for every query</p><p>We use a recent result of Raz and Safra <ref type="bibr" target="#b42">[41]</ref> (see also <ref type="bibr" target="#b6">[5]</ref> for an alternate proof) which provides a strong uniform-MIP containment result for NP.</p><p>Lemma A.2 (see <ref type="bibr" target="#b42">[41,</ref><ref type="bibr" target="#b6">5]</ref>). For every ǫ &gt; 0, there exist constants p, c 1 , c 2 , and c 3 such that</p><p>Remark.</p><p>(1) The result shown by <ref type="bibr" target="#b42">[41,</ref><ref type="bibr" target="#b6">5]</ref> actually has smaller answer sizes, but this turns out to be irrelevant to our application below; therefore we don't mention their stronger result. (2) The uniformity property is not mentioned explicitly in the above papers.</p><p>However, it can be verified from their proofs that this property does hold for the verifier constructed there. The following reduction is essentially from <ref type="bibr" target="#b37">[36,</ref><ref type="bibr" target="#b8">7,</ref><ref type="bibr" target="#b3">2]</ref>. Lemma A.3. For every ǫ &gt; 0, there exists a p = p ǫ such that Total Label Cover p is NP-hard to approximate to within a factor of 2 log 1-ǫ n .</p><p>Proof. We use Lemma A.2. Let L be an NP-complete language and for ǫ &gt; 0, let p, c 1 , c 2 , c 3 be such that L ∈ uniform-MIP 1,2 -log 1-ǫ/2 n [p, c 1 log n, c 2 log n, c 3 log n], and let V be the verifier that shows this containment. Given an instance x ∈ {0, 1} n of L, we create an instance of Total Label Cover p as follows: Set Q i (R) to be the query generated by V to prover Π i on input x and random string R. For every R, a 1 , . . . , a p Acc(R, a 1 , . . . , a p ) is 1 if V accepts the answers a 1 , . . . , a p on random string R.</p><p>Let Q = {0, 1} c2 log n denote the set of all possible queries and let R denote the space of all possible random strings (i.e., R = {0, 1} c1 log n ). If x ∈ L, it is clear that there exists a feasible solution A 1 , . . . , A p such that for every query q ∈ Q, and for F ⇓ </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>No Feasibility is NP-hard <ref type="bibr" target="#b43">[42]</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">it suffices to show that Weighted Min Ones(F) is APX-hard; and by Lemma 8.11 it suffices to show that Weighted Min Ones(F ∪ {F }) is APX-hard</title>
		<idno>Lemma 8.10</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">{F } is not 0-valid or 1-valid or C-closed, it implements every function in F ∪ {T, F } and thus every function in F| 0,1 . We now shift focus on to the family (F| 0,1 ) -. Furthermore, (F| 0,1 ) -is neither weakly positive nor affine and thus by Lemmas 6.20 and 6.21 it implements NAND. Using Proposition 8.3 we get that F 0,1 implements OR. Using Lemma 8.15 we get that Weighted Min Ones(OR) is APX-hard</title>
		<author>
			<persName><forename type="first">F</forename><surname>Since</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Thus we conclude that Weighted Min Ones(F) is APX-hard. REFERENCES</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The complexity and approximability of finding maximum feasible subsystems of linear relations</title>
		<author>
			<persName><forename type="first">E</forename><surname>Amaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoret. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="page" from="181" to="210" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The hardness of approximate optima in lattices, codes, and systems of linear equations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Babai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sweedyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. System Sci</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="317" to="331" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Proof verification and hardness of approximation problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sudan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="501" to="555" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Probabilistic checking of proofs: A new characterization of NP</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Safra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="70" to="122" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Improved low degree testing and its applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sudan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual ACM Symposium on Theory of Computing</title>
		<meeting>the 29th Annual ACM Symposium on Theory of Computing<address><addrLine>El Paso, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="485" to="495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Approximation algorithms for the maximum satisfiability problem</title>
		<author>
			<persName><forename type="first">T</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hirata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Comput. Sci.</title>
		<editor>
			<persName><forename type="first">Rolf</forename><forename type="middle">G</forename><surname>Swat '96</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Andrzej</forename><surname>Karlsson</surname></persName>
		</editor>
		<editor>
			<persName><surname>Lingas</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">1097</biblScope>
			<biblScope unit="page" from="100" to="111" />
			<date type="published" when="1996">1996</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient probabilistically checkable proofs and applications to approximation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bellare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual ACM Symposium on Theory of Computing</title>
		<meeting>the 25th Annual ACM Symposium on Theory of Computing<address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="294" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Free bits, PCPs, and nonapproximability-Towards tight results</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bellare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Goldreich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sudan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="804" to="915" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Approximating maximum independent sets by excluding subgraphs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Boppana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haldórsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BIT</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="180" to="196" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bovet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Crescenzi</surname></persName>
		</author>
		<title level="m">Introduction to the Theory of Complexity</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A dichotomy theorem for maximum generalized satisfiability problems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Creignou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. System Sci</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="511" to="522" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Complexity of generalized satisfiability counting problems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Creignou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. and Comput</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Structure in approximation classes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Crescenzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Silvestri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Trevisan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1759" to="1782" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Completeness in approximation classes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Crescenzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Panconesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. and Comput</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="241" to="262" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">To weight or not to weight: Where is the question?</title>
		<author>
			<persName><forename type="first">P</forename><surname>Crescenzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Silvestri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Trevisan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th IEEE Israel Symposium on Theory of Computing and Systems</title>
		<meeting>the 4th IEEE Israel Symposium on Theory of Computing and Systems<address><addrLine>Jerusalem</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="68" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Approximating minimum feedback sets and multicuts in directed graphs</title>
		<author>
			<persName><forename type="first">G</forename><surname>Even</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Naor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sudan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="151" to="174" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The computational structure of monotone monadic SNP and constraint satisfaction: A study through datalog and group theory</title>
		<author>
			<persName><forename type="first">T</forename><surname>Feder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Vardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="57" to="104" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Interactive proofs and the hardness of approximating cliques</title>
		<author>
			<persName><forename type="first">U</forename><surname>Feige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lovász</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Safra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="268" to="292" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Computers and Intractability: A Guide to the Theory of NP-Completeness</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Garey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>W. H. Freeman</publisher>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Approximate max-flow min-(multi)cut theorems and their applications</title>
		<author>
			<persName><forename type="first">N</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Vazirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yannakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="235" to="251" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">New 3 4 -approximation algorithms for the maximum satisfiability problem</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">X</forename><surname>Goemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Discrete Math</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="656" to="666" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Goemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1115" to="1145" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Clique is hard to approximate within n 1-ǫ</title>
		<author>
			<persName><forename type="first">J</forename><surname>Håstad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedinsg of the 37th Annual Symposium on Foundations of Computer Science</title>
		<meeting>eedinsg of the 37th Annual Symposium on Foundations of Computer Science<address><addrLine>Burlington, VT</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="627" to="636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Some optimal inapproximability results</title>
		<author>
			<persName><forename type="first">J</forename><surname>Håstad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual ACM Symposium on Theory of Computing</title>
		<meeting>the 29th Annual ACM Symposium on Theory of Computing<address><addrLine>El Paso, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Tight bounds and 2-approximation algorithms for integer programs with two variables per inequality</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Hochbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Megiddo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Naor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Programming</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="69" to="83" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Generalized CNF satisfiability problems and non-efficient approximability</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Marathe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Stearns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Annual Structure in Complexity Theory Conference</title>
		<meeting>the Ninth Annual Structure in Complexity Theory Conference<address><addrLine>Amsterdam, The Netherlands; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="356" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A 7/8-approximation algorithm for MAX 3SAT?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Karloff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Zwick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual Symposium on Foundations of Computer Science</title>
		<meeting>the 38th Annual Symposium on Foundations of Computer Science<address><addrLine>Miami Beach, FL</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="406" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Towards a syntactic characterization of PTAS</title>
		<author>
			<persName><forename type="first">S</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual ACM Symposium on the Theory of Computing</title>
		<meeting>the 28th Annual ACM Symposium on the Theory of Computing<address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="329" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On syntactic versus computational views of approximability</title>
		<author>
			<persName><forename type="first">S</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sudan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Vazirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="164" to="191" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Constraint satisfaction: The approximability of minimization problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sudan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Trevisan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Annual IEEE Conference on Computational Complexity</title>
		<meeting>the 12th Annual IEEE Conference on Computational Complexity<address><addrLine>Ulm, Germany; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="282" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A complete classification of the approximability of maximization problems derived from Boolean constraint satisfaction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sudan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual ACM Symposium on Theory of Computing</title>
		<meeting>the 29th Annual ACM Symposium on Theory of Computing<address><addrLine>El Paso, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Approximation through multicommodity flow</title>
		<author>
			<persName><forename type="first">P</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Annual Symposium on Foundations of Computer Science</title>
		<meeting>the 31st Annual Symposium on Foundations of Computer Science<address><addrLine>St. Louis, MO</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page" from="726" to="737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Approximation algorithms for Steiner and directed multicuts</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Plotkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">É</forename><surname>Tardos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Algorithms</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="241" to="269" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Approximation properties of NP minimization classes</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Kolaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Thakur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. System Sci</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="391" to="411" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">On the structure of polynomial time reducibility</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ladner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="155" to="171" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">On the hardness of approximating minimization problems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yannakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="960" to="981" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The approximation of maximum subgraph problems, in Automata, Languages and Programming, 20th International Colloquium</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yannakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Comput. Sci.</title>
		<editor>
			<persName><forename type="first">Svante</forename><surname>Carlsson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Andrzej</forename><surname>Lingas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rolf</forename><forename type="middle">G</forename><surname>Karlsson</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">700</biblScope>
			<biblScope unit="page" from="40" to="51" />
			<date type="published" when="1993">1993</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Lund, Sweden</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An O(log* n) approximation algorithm for the asymmetric p-center problem</title>
		<author>
			<persName><forename type="first">R</forename><surname>Panigrahy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Algorithms</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="259" to="268" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Optimization, approximation and complexity classes</title>
		<author>
			<persName><forename type="first">C</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yannakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. System Sci</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="425" to="440" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The hardness of approximation: Gap location</title>
		<author>
			<persName><forename type="first">E</forename><surname>Petrank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Complexity</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="133" to="157" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A sub-constant error-probability low-degree test, and a sub-constant error-probability PCP characterization of NP</title>
		<author>
			<persName><forename type="first">R</forename><surname>Raz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Safra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual ACM Symposium on Theory of Computing</title>
		<meeting>the 29th Annual ACM Symposium on Theory of Computing<address><addrLine>El Paso, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="475" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The complexity of satisfiability problems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schaefer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Annual ACM Symposium on Theory of Computing</title>
		<meeting>the 10th Annual ACM Symposium on Theory of Computing<address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1978">1978</date>
			<biblScope unit="page" from="216" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Gadgets, approximation, and linear programming</title>
		<author>
			<persName><forename type="first">L</forename><surname>Trevisan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Sorkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sudan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2074" to="2097" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">On the approximation of maximum satisfiability</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yannakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Algorithms</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="475" to="502" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">On unapproximable versions of NP-complete problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zuckerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1293" to="1304" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
