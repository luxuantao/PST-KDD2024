<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AN ALGEBRAIC MULTIGRID METHOD WITH GUARANTEED CONVERGENCE RATE *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Artem</forename><surname>Napov</surname></persName>
							<email>anapov@lbl.gov</email>
						</author>
						<author>
							<persName><forename type="first">Yvan</forename><surname>Notay</surname></persName>
							<email>ynotay@ulb.ac.be</email>
							<affiliation key="aff1">
								<orgName type="department">Service de Métrologie Nucléaire</orgName>
								<orgName type="institution">Université Libre de Bruxelles (C.P</orgName>
								<address>
									<addrLine>165/84), 50, Av. F.D. Roo-sevelt</addrLine>
									<postCode>B-1050</postCode>
									<settlement>Brussels</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<address>
									<addrLine>10</addrLine>
									<postCode>2012</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AN ALGEBRAIC MULTIGRID METHOD WITH GUARANTEED CONVERGENCE RATE *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8D6A69D2A070C5DC0BA70E9DEDCA4E1E</idno>
					<idno type="DOI">10.1137/100818509</idno>
					<note type="submission">Submitted to the journal&apos;s Methods and Algorithms for Scientific Computing section December 17, 2010; accepted for publication (in revised form) January 11, 2012; published electronically April</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T05:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>multigrid</term>
					<term>algebraic multigrid</term>
					<term>iterative methods</term>
					<term>preconditioner</term>
					<term>convergence analysis</term>
					<term>aggregation AMS subject classifications. 65F10</term>
					<term>65N12</term>
					<term>65N55</term>
					<term>65F50</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We consider the iterative solution of large sparse symmetric positive definite linear systems. We present an algebraic multigrid method which has a guaranteed convergence rate for the class of nonsingular symmetric M-matrices with nonnegative row sum. The coarsening is based on the aggregation of the unknowns. A key ingredient is an algorithm that builds the aggregates while ensuring that the corresponding two-grid convergence rate is bounded by a user-defined parameter. For a sensible choice of this parameter, it is shown that the recursive use of the two-grid procedure yields a convergence independent of the number of levels, provided that one uses a proper AMLIcycle. On the other hand, the computational cost per iteration step is of optimal order if the mean aggregate size is large enough. This cannot be guaranteed in all cases but is analytically shown to hold for the model Poisson problem. For more general problems, a wide range of experiments suggests that there are no complexity issues and further demonstrates the robustness of the method. The experiments are performed on systems obtained from low order finite difference or finite element discretizations of second order elliptic partial differential equations (PDEs). The set includes twoand three-dimensional problems, with both structured and unstructured grids, some of them with local refinement and/or reentering corner, and possible jumps or anisotropies in the PDE coefficients.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>is critical for many of today's applications in science and engineering. For systems arising from the discretization of elliptic partial differential equations (PDEs), algebraic multigrid (AMG) methods are known to be particularly suitable and robust <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b27">28]</ref>. These algorithms combine the effects of a smoother and of a coarse grid correction. The smoother is generally based on a simple iterative scheme such as the Gauss-Seidel method. The coarse grid correction consists in computing an approximate solution to the residual equation on a coarser grid which has fewer unknowns. The approach is applied recursively until the coarse system is small enough to make negligible the cost of an exact solution. Unlike geometric multigrid methods <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b26">27]</ref>, which require information from the discretization of the PDE, AMG carries over to the multilevel variant. In this paper, we exploit this feature to obtain a bound on the convergence rate that remains fixed independently of the number of levels.</p><p>The remainder of this paper is organized as follows. We first outline in section 2 our main result, namely the bound on a convergence rate that is guaranteed by our AMG method. In section 3 we recall needed two-grid analysis results from <ref type="bibr" target="#b19">[20]</ref>, particularizing them to the context of this paper. The AMLI-cycle is described in section 4. In section 5 we present our aggregation algorithm and explain why and how it allows us to guarantee the bound announced in section 2. Numerical results are reported in section 6.</p><p>Notation. For any ordered set Γ, |Γ| is its size and Γ(i) its ith element. <ref type="bibr">[1, k]</ref> = {1, 2, . . . , k} stands for the set of the first k integers. For any matrix B, N (B) is its null space. For any square matrix C, ρ(C) is its spectral radius (that is, its largest eigenvalue in modulus). For any SPD matrix D, κ(D) is its condition number (that is, the quotient of its largest and smallest eigenvalues). I stands for identity matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Outline of the main result.</head><p>Building an optimal method with the AMLIcycle is possible if there are a known upper bound κTG on the condition number of the two-grid method at every level and an integer γ (related to the degree of Chebyshev polynomials) such that (2.1)</p><formula xml:id="formula_0">√ κTG &lt; γ &lt; τ,</formula><p>where τ stands for the mean factor by which the matrix size is reduced from one level to the next. Both inequalities should be interpreted in a restrictive way: for an efficient method, √ κTG should be substantially away from γ and the latter itself substantially away from τ . The left inequality guarantees that the condition number remains bounded even for infinitely many levels, and the right one ensures an optimal computational complexity. That said, the left inequality is the most difficult to deal with because, recall, it has to be checked by an upper bound on the two-grid condition number, which has to hold at every level of the hierarchy and, further, has to be known explicitly because it enters the definition of the parameters of the AMLI-cycle. Therefore, by introducing a new approach based on the explicit control of the two-grid condition number, we facilitate the use of the AMLI-cycle, which here is, seemingly for the first time, combined with a truly AMG method.</p><p>Observe that, with γ = 4 , the conditions (2.1) fit well with the numbers κTG = 11.5 and τ = 8 cited in the introduction. This is on purpose: when assessing our aggregation algorithm below, we target parameter choices allowing a sensible application of the AMLI-cycle. Using the latter with γ = 4 and κTG = 11.5 , the induced multilevel preconditioner B satisfies (2.2) κ B -1 A ≤ 27.06, independently of the number of levels; that is, the explicit control of the two-grid condition number obtained thanks to our aggregation algorithms carries over to the multigrid scheme thanks to the use of the AMLI-cycle. On the other hand, with τ ≈ 8, the algorithmic complexity of one application of this preconditioner is only about twice that of the smoothing iterations at the fine grid level.</p><p>Regarding assumptions, the upper bound (2.2) requires only the system matrix A to be a symmetric M-matrix with nonnegative row sum. We consider that this property holds in the reminder of this paper. It is in particular satisfied with low Downloaded 11/25/14 to 18.101. <ref type="bibr">24.154</ref>. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php order finite difference or finite element discretizations of scalar second order elliptic PDEs, with, in the case of finite elements, some restriction on the elements' shape. For this class of applications, we thus obtain the same uniform bound independently of the mesh or problem size and of the structure or lack of structure of the discretization grid, regardless of whether the problem is two-dimensional (2D) or three-dimensional (3D), and independently of problem peculiarities such as jumps or anisotropy in the PDE coefficients, reentering corners, or lack of full elliptic regularity.</p><p>The bound <ref type="bibr">(2.</ref>2) provides the first complete convergence analysis of an AMG method based on plain aggregation. Moreover, it also seems to compare favorably with available theoretical analyses of other AMG schemes. Classical AMG methods along the lines of the seminal papers <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b24">25]</ref> also have a supporting theory based on the M-matrix assumption; see <ref type="bibr" target="#b25">[26]</ref> for a nice summary. However, this theory is only for the two-grid case, and it is unclear whether it can produce such uniform estimates. For instance, it should in principle apply to the method implemented in the old but classical code that was used in <ref type="bibr" target="#b21">[22]</ref> for numerical comparison and which failed to converge for some anisotropic problems, even though the matrix was an M-matrix. It is more difficult to develop a comparison with analyses of methods based on smoothed aggregation, as initiated in <ref type="bibr" target="#b27">[28]</ref> and further improved in <ref type="bibr" target="#b30">[31]</ref> and <ref type="bibr" target="#b7">[8]</ref>. Indeed just the statement of the assumptions in <ref type="bibr" target="#b7">[8]</ref> would require a significant amount of space; hence we refer the reader to the aforementioned works and just point out that these analyses are also for the multilevel case, while the resulting bound is hard to compare with (2.2) since it depends on the number of levels and involves an unknown constant C . Regarding assumptions, it is probably correct to state that the theory in <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b7">8]</ref> allows us to cover several discretizations of PDEs that do not result in an M-matrix, whereas some M-matrix cases such as finite difference discretizations are excluded. Note also that the discussion of these assumptions involves geometric considerations such as the mesh size h at the fine grid level and the diameter of the aggregates; hence it is unclear how it could apply to problems with strong local refinement.</p><p>Eventually, as already stated above, except for the model Poisson problem, the bound (2.2) should not be seen as a proof of optimality, since there remains some uncertainty on the algorithmic complexity. However, as commented in the first paragraph of section 7 in <ref type="bibr" target="#b7">[8]</ref>, the difficulty of proving that an AMG method has bounded algorithmic complexity is not peculiar to our approach and remains a challenge for truly black box methods that do not exploit any geometric information. Hence, although limited to a model problem, our complexity analysis also seems to represent some advance with respect to the state of the art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Two-grid analysis.</head><p>We first introduce some notation (related to our twogrid setting). We consider symmetric two-grid schemes, using SPD smoother M with one pre-and one post-smoothing step. We also assume that the coarse grid matrix is of Galerkin type; that is, given an n × n c prolongation matrix P , the coarse grid matrix is A c = P T A P . The corresponding iteration matrix is then</p><formula xml:id="formula_1">T = (I -M -1 A)(I -P A -1 c P T A)(I -M -1 A),</formula><p>which also implicitly defines the two-grid preconditioner B TG via the relation</p><formula xml:id="formula_2">I -B -1 TG A = T.</formula><p>Equivalently, one has</p><formula xml:id="formula_3">(3.1) B -1 TG = M -1 (2 M -A)M -1 + (I -M -1 A)P A -1 c P T (I -A M -1</formula><p>) . Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Now, with the coarsening by aggregation, the prolongation is obtained from the agglomeration of the unknowns into n c nonempty disjoint sets G k , k = 1, . . . , n c , called aggregates. To each aggregate G k is associated one unknown at the next coarse level in the hierarchy. In addition, following <ref type="bibr" target="#b19">[20]</ref>, some unknowns can also be kept outside the coarsening process, and the corresponding (possibly empty) set is noted G 0 ; that is, G 0 gathers the unknowns that are not associated with any coarse unknown. As a result, G 0 together with G k , k = 1, . . . , n c , defines a partitioning of the index set <ref type="bibr">[1, n]</ref> which uniquely determines the prolongation P : for i = 1, . . . , n and j = 1, . . . , n c ,</p><formula xml:id="formula_4">(3.2) (P ) ij = 1 if i ∈ G j , 0 otherwise.</formula><p>Hence a row of P is zero if and only if the corresponding unknown is in G 0 , whereas the other rows have exactly one nonzero entry. As made clearer below, the role of G 0 is to gather nodes that need not be represented on the coarse grid because the corresponding error components are sufficiently damped by the smoother alone. Note also that the entries in the coarse grid matrix A c = P T A P , where A = (a ij ), can be obtained from a simple summation process:</p><formula xml:id="formula_5">(3.3) (A c ) kl = i∈G k j∈G l a ij , k,l= 1, . . . , n c .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>It follows from this relation that if</head><p>A is an M-matrix with nonnegative row sum, then A c inherits these properties; see Theorem 3.6 in <ref type="bibr" target="#b16">[17]</ref> for an explicit proof. <ref type="foot" target="#foot_2">3</ref> This observation is important: it means that if a matrix A satisfies the basic assumptions of Theorem 3.2 below, then all successive coarse grid matrices will satisfy them as well; i.e., the theorem can be applied at any level in the hierarchy. Our analysis is first based on the well-known result from <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b30">31]</ref>, which, when the smoother M is SPD and such that vM v ≥ vAv for all v, states that</p><formula xml:id="formula_6">(3.4) v T Av ≤ v T B TG v ≤ μ v T Av ∀v ∈ R n with (3.5) μ = max v =0 v T M I -P (P T M P ) -1 P T M v v T Av .</formula><p>This is further combined with Theorem 3.2 in <ref type="bibr" target="#b19">[20]</ref>, which yields an upper bound on μ for prolongations P based on aggregation. For the sake of readability, we recall this latter result in the following lemma. Lemma 3.1. Let A and M be n × n SPD matrices. Let G k , k = 0, . . . , n c , be some partitioning of <ref type="bibr">[1, n]</ref> , and define P by <ref type="bibr">(3.2)</ref>. Assume that M is block diagonal with respect to the partitioning G k ; i.e., (M ) ij = 0 if i , j do not belong to the same subset G k .</p><p>Further, let A b , A r be nonnegative definite symmetric matrices such that A = A b + A r and A b is also block diagonal with respect to the partitioning G k . For k = A1085 0, . . . , n c , let A G k be the diagonal block of A b corresponding to indices in G k ; that is, with an appropriate reordering of unknowns, A b = blockdiag(A G0 , A G1 , . . . , A Gn c ). Similarly, let M G k denote the diagonal block of M corresponding to indices in G k , and, hence, M = blockdiag(M G0 , M G1 , . . . , M Gn c ). There holds</p><formula xml:id="formula_7">(3.6) max v =0 v T M I -P (P T M P ) -1 P T M v v T Av ≤ max k=0,...,nc μ (k) ,</formula><p>where</p><formula xml:id="formula_8">μ (0) = 0 if G 0 is empty, max v v T MG 0 v v T AG 0 v otherwise,</formula><p>and where, for k = 1, . . . , n c ,</p><formula xml:id="formula_9">μ (k) = ⎧ ⎨ ⎩ 0 if |G k | = 1, sup v / ∈N (AG k ) v T MG k (I-1G k (1 T G k MG k 1G k ) -1 1 T G k MG k )v v T AG k v otherwise, with 1 G k = (1, 1, . . . , 1) T being a vector of size |G k |.</formula><p>To apply this lemma, one first needs a proper splitting of the matrix into two nonnegative definite matrices. When A is an M-matrix with nonnegative row sum, this splitting is easy to obtain: regarding the off-diagonal entries, A b gathers those connecting unknowns inside every aggregate, and A r keeps the others; on the other hand, the diagonals are such that A r has zero row sum and therefore A b acquires the same (nonnegative) row sum as A . In other words, A b is obtained from A by discarding and lumping to the diagonal the entries that are in the block off-diagonal part with respect to the partitioning in aggregates. This lumping ensures that both A b and A r are weakly diagonally dominant and hence nonnegative definite.</p><p>Then, as follows from (3.5) and (3.6), the measure μ involved in (3.4) can be controlled if the parameter μ (k) associated with each aggregate is efficiently bounded. And this parameter depends only on the corresponding diagonal blocks in A b and M ; i.e., on quantities "local" to the aggregate: the "local" matrix entries and the row sum at "local" nodes. Observe that the lumping process mentioned above tends to make these diagonal blocks A G k ill-conditioned, or even singular when the row sum of A is zero at every node of the aggregate. But, for regular aggregates (k &gt; 0), it does not mean that μ (k) is unbounded since the matrix</p><formula xml:id="formula_10">M G k (I -1 G k (1 T G k M G k 1 G k ) -1 1 T G k M G k</formula><p>) is also, by construction, singular with the constant vector in its kernel. This is not true for μ (0) , because nodes in G 0 are kept outside the aggregation and are actually not represented anymore on the coarse grid. Therefore, smoothing iterations alone should be sufficient to efficiently damp the error at these nodes, which, in this analysis, is reflected by the requirement that the corresponding block A G0 be well-conditioned. In practice, as will be seen below, this requirement can be checked via a strong diagonal dominance criterion. Now, this works for smoothers that are block diagonal with respect to the partitioning in aggregates. A particular example is of course the damped Jacobi smoother. As discussed below, better results can, however, be obtained with more general smoothers. We therefore introduce the class of smoothers M = (m ij ) , with offdiagonal entries obtained from that of A = (a ij ) by keeping those inside a given Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php symmetric sparsity pattern and discarding the others:</p><formula xml:id="formula_11">(3.7) m ij = ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ a ij if i = j and (i, j) ∈ sp(M ), a ii + s =i (i,s) ∈sp(M) |a is | if i = j, 0 o t h e r w i s e ,</formula><p>where sp(M ) stands for the chosen sparsity pattern; the discarded off-diagonal entries are further added in absolute value to the diagonal. This ensures the weak diagonal dominance of M -A, which is therefore nonnegative definite as required for <ref type="bibr">(3.4)</ref>.</p><p>Note that the smoother defined by (3.7) is not necessarily block diagonal. This depends upon the chosen sparsity pattern. We can allow this because our analysis is actually slightly more general than the mere combination of (3.4) with Lemma 3.1. Indeed, as shown in the proof of Theorem 3.2 below (based on previous results in <ref type="bibr" target="#b19">[20]</ref>; see also <ref type="bibr" target="#b30">[31]</ref>), (3.4) also holds with μ defined as in <ref type="bibr">(3.5)</ref> in which the smoother M is replaced by any matrix M such that vM v ≤ vM v for all v . Then, to properly apply Lemma 3.1, only this M should be block diagonal. Given a smoother M defined by (3.7), a relevant M = (m ij ) is obtained using the same rule while restricting the sparsity pattern to the block diagonal part:</p><formula xml:id="formula_12">sp M = {(i, j) ∈ sp(M ) | i, j belong to the same aggregate}.</formula><p>Such M has the required block diagonal structure, whereas, according to the rule (3.7), the further discarded entries from the off-diagonal blocks are added in absolute value to the diagonal, ensuring that M -M is weakly diagonal dominant and hence nonnegative definite. It is worth noting that, since the bound depends upon M , it is thus not influenced by the off-diagonal block part of the sparsity pattern. This observation is taken into account below when we discuss some relevant choices for sp(M ) . Now, particularizing the analysis sketched above to smoothers defined via (3.7) yields the following theorem. Note that the matrices A G and M G in this theorem represent the diagonal blocks of A b = blockdiag(A G0 , A G1 , . . . , A Gn c ) and M = blockdiag(M G0 , M G1 , . . . , M Gn c ) .</p><p>Theorem 3.2. Let A = (a ij ) be an n × n nonsingular symmetric M-matrix with nonnegative row sum. Let G k , k = 0, . . . , n c , be a partitioning of <ref type="bibr">[1, n]</ref> , let sp(M ) be some symmetric sparsity pattern, and define P , M = (m ij ), and B TG by (3.2), (3.7), and (3.1), respectively.</p><p>For any subset G of <ref type="bibr">[1, n]</ref>, let A| G and M | G be the submatrices of A and M , respectively, corresponding to indices in G. Moreover, let Σ G , Δ G be |G|×|G| diagonal matrices with</p><formula xml:id="formula_13">(Σ G ) ii = j / ∈G |a G(i)j | and (Δ G ) ii = a G(i)G(i) + j∈G j =G(i) and (G(i),j) / ∈sp(M) |a G(i)j |,</formula><p>where</p><formula xml:id="formula_14">G(i) is the ith element in G. Set A G = A| G -Σ G and let M G be such that offdiag(M G ) = offdiag(M | G ) and diag(M G ) = Δ G + Σ G . Define, if |G| &gt; 1, (3.8) μ(G) = sup v / ∈N (AG) v T M G (I -1 G (1 T G M G 1 G ) -1 1 T G M G )v v T A G v</formula><p>, </p><formula xml:id="formula_15">where 1 G = (1, 1, . . . ,</formula><formula xml:id="formula_16">a ii ≥ κTG + 1 κTG -1 ⎛ ⎝ n j=1,j =i |a ij | ⎞ ⎠ ∀i ∈ G 0 ; and (ii) for k = 1, . . . , n c , either |G k | = 1 or (3.10) μ(G k ) ≤ κTG , then (3.11) v T Av ≤ v T B TG v ≤ κTG v T Av ∀v ∈ R n .</formula><p>Proof. We first show that (3.4) holds with</p><formula xml:id="formula_17">(3.12) μ = max v =0 v T M I -P (P T M P ) -1 P T M v v T Av for any matrix M such that vM v ≤ vM v.</formula><p>The left inequality is actually a standard result (e.g., [31, section 3.2]); we give a short proof for the sake of completeness: since A is SPD,</p><formula xml:id="formula_18">A 1/2 P A -1 c P T A 1/2 is an orthogonal projector; hence, v T P A -1 c P T v ≤ v T A -1 v for all v and, using this inequality in (3.1), one has for all v ∈ R n v T B -1 TG v ≤ v T M -1 (2 M -A)M -1 v + v T (I -M -1 A) A -1 (I -A M -1 )v = v T A -1 v.</formula><p>To prove the right inequality, we note that</p><formula xml:id="formula_19">λ min (B -1 TG A) = 1 -λ max (I -B -1 TG A) = 1 -ρ(I -B -1 TG A) ,</formula><p>where the second equality follows from the left inequality just proved. Hence we need to prove ρ(I -</p><formula xml:id="formula_20">B -1 TG A) ≤ 1 -μ -1 .</formula><p>To this end, one may apply Theorem 3.1 of <ref type="bibr" target="#b19">[20]</ref>. In this theorem, X denotes the equivalent global smoother. Hence, for B TG defined by (3.1), one has</p><formula xml:id="formula_21">X = (2 M -1 -M -1 AM -1 ) -1 . Since M -M is weakly diagonally dominant, one then has, for all v ∈ R n (using also v T M -1/2 AM -1/2 v ≤ 1 which follows from the nonnegative definiteness of M -A), v T M -1 v ≤ v T M -1 v ≤ v T (2 M -1 -M -1 AM -1 )v = v T X -1 v; that is, max v v T Xv v T M v ≤ 1.</formula><p>Then, noting that the matrix D referenced in Theorem 3.1 of <ref type="bibr" target="#b19">[20]</ref> can be freely chosen, and setting D = M = blockdiag(M G0 , M G1 , . . . , M Gn c ), the relations ( <ref type="formula">7</ref>) and ( <ref type="formula">8</ref>) in this theorem together with</p><formula xml:id="formula_22">λ max (X -1 A) ≤ λ max (M -1 A) ≤ 1 imply the required result; that is, ρ(I -B -1 TG A) ≤ 1 -μ -1</formula><p>and therefore (3.4) holds with μ as in (3.12). Clearly, the required result <ref type="bibr">(3.11)</ref> follows if μ ≤ κTG . We then consider Lemma 3.1 with the splitting A = A b + A r , A b = blockdiag(A G0 , A G1 , . . . , A Gn c ) , which in fact Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php corresponds to the construction procedure described just after the lemma. One sees that the condition (3.10) indeed entails μ ≤ κTG if, in addition, max</p><formula xml:id="formula_23">v∈R |G 0 | v T M G0 v v T A G0 v ≤ κTG . Now, v T M G0 v ≤ v T M (0) G0 v , where M (0) G0 = diag(a G0(i)G0(i) + j =G0(i) |a G0(i)j |) (one may check that M (0)</formula><p>G0 -M G0 is weakly diagonally dominant). The result then follows from max</p><formula xml:id="formula_24">v∈R |G 0 | v T M (0) G0 v v T A G0 v ≤ max i∈G0 a ii + n j=1,j =i |a ij | a ii - n j=1,j =i |a ij | ≤ κTG ,</formula><p>where the first inequality holds since</p><formula xml:id="formula_25">A G0 -diag(a G0(i)G0(i) - n j=1,j =G0(i) |a G0(i)j |)</formula><p>is nonnegative definite (it has negative off-diagonal entries and zero row sum), whereas the second inequality stems from (3.9).</p><p>We now discuss how to best select the sparsity pattern of the smoother. A first possibility consists in discarding all off-diagonal entries, yielding a diagonal smoother</p><formula xml:id="formula_26">M = diag( n j=1 |a ij |) .</formula><p>Since A is diagonally dominant, we then have m ii ≤ 2a ii , with equality when the corresponding row of A has zero sum. Hence such a smoother does not differ much from the classical damped Jacobi smother M = ω -1 Jac diag(a ii ) with damping factor ω Jac = 0.5 .</p><p>Here we advocate further choices, which yield better "quality" estimates μ(G k ) for the aggregates and therefore make the constraint (3.10) less restrictive. As noted above, the bound is not improved if more entries connecting different aggregates are added to the sparsity pattern. However, consider that, starting from a given smoother, say M (1) , one creates another smoother M (2) by including in the sparsity pattern some additional connections internal to an aggregate G k . One sees from (3.7) that the related matrices M</p><p>(1)</p><formula xml:id="formula_27">G k and M (2) G k will be such that M (1) G k -M (2)</formula><p>G k is weakly diagonally dominant and, hence, nonnegative definite. It can then be inferred from [20, Theorem 3.1] that μ(G k ) is at least as small for M (2) as it is for M (1) . That is, putting in the sparsity pattern of M more off-diagonal entries internal to the aggregates never deteriorates the quality estimates μ(G k ), and, in fact, as numerical computation reveals, most often improves them.</p><p>Moreover, optimizing the sparsity pattern by including for every aggregate all its internal connections has only a moderate impact on the computational cost as long as the aggregates are relatively small or have small bandwidth. From now on, we therefore consider that the smoother is one of the two described below; except in numerical experiments, it does not matter which one is actually used since, according to the discussion above, they lead to identical convergence estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Block diagonal smoother. (i, j) ∈ Sp(M ) if and only if i and j belong to the same aggregate</head><formula xml:id="formula_28">G k , 1 ≤ k ≤ n c .</formula><p>Band smoother. This smoother assumes that the matrix has been explicitly reordered according to the partitioning in aggregates; that is, the unknowns in the same set G k , k = 0, 1, . . . , n c , occupy successive positions in the index set. It then follows that the above block diagonal smoother has an explicit block diagonal structure, and it may be interesting to extend the sparsity pattern so that it comprises the whole band that includes all these diagonal blocks (except, possibly, the one corresponding to G 0 ); that is, (i, j) ∈ Sp(M ) if and only if |i-j| ≤ δ, where δ = max 1≤k≤nc bandwidth(A G k ). This allows us to use a fast band solver such as the one available in LAPACK <ref type="bibr" target="#b0">[1]</ref>. Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php 4. The AMLI-cycle. The AMLI-cycle implements the recursive use of a twolevel method. The exact solution of the coarse system that is needed to compute the action of a two-grid preconditioner is exchanged for the approximate solution obtained with a few steps of an iterative solution method. This iterative solution itself uses the two-grid preconditioner on that coarse level, leading to a recursive scheme. The recursion is stopped when the coarse system is sufficiently small to allow a direct solution method at negligible cost. Note that this description applies as well to the other cycles, such as the W-cycle <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b26">27]</ref>. What makes the AMLI-cycle different is the use, for the solution of each coarse system, of a semi-iterative method based on shifted Chebyshev polynomials. The number of iterations γ is also typically larger than the two iterations associated with the W-cycle.</p><p>This polynomial acceleration allows us to obtain a stabilized condition number (i.e., a condition number that is bounded independently of the number of levels) under rather weak conditions; see below. There is a price to pay, however. At each level, the parameters of the polynomial acceleration are to be defined according to explicit bounds on the eigenvalues of the matrix preconditioned by the two-grid method. Moreover, the overall efficiency of the scheme depends on the sharpness of these bounds.</p><p>The AMLI-cycle was originally developed in <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b29">30]</ref> for multilevel preconditioners based on recursive 2 × 2 block incomplete factorizations, and was further adapted to multigrid methods in <ref type="bibr" target="#b30">[31]</ref>. We do not bring additional contributions to that topic and therefore present only a short summary here, focusing on facts and practical aspects, whereas justifications are omitted and theoretical properties are stated without proof. We essentially follow the presentation in section 5.6 of <ref type="bibr" target="#b30">[31]</ref>, to which we refer the reader for more details.</p><p>First we introduce some additional notation. We assume that the multigrid preconditioner involves L levels, level 1 being the finest (on which the system (1.1) is solved) and level L being the coarsest. A , M , and P are, respectively, the matrix, the smoother, and the prolongation at level . Hence we have A 1 = A and, because we assume that the successive coarse grid matrices are of Galerkin type, A +1 = P T A P , = 1, . . . , L -1.</p><p>Regarding assumptions, the system matrix has to be SPD and the smoother such that</p><formula xml:id="formula_29">(4.1) ρ I -M -1 A &lt; 1, = 1, . . . , L -1.</formula><p>Furthermore, as stated above, one should know constants α , = 1, . . . , L -1, such that, for all v of appropriate size,</p><formula xml:id="formula_30">(4.2) v T A v ≤ v T B TG, v ≤ α v T A v,</formula><p>where B T G, is a two-grid preconditioner at level ; that is, the matrix defined in (3.1) with A = A , M = M , P = P , and A c = A +1 on the right-hand side. Now, as discussed in the preceding section, the smoothers considered in this work are SPD and such that M -A is nonnegative definite. Hence the eigenvalues of M -1 A belong to the interval (0, 1), and the condition (4.1) always holds. On the other hand, we intend to use Theorem 3.2 to guarantee (4.2) with a uniform bound κTG on α . We therefore continue the presentation, setting α = κTG for all .</p><p>In Algorithm 4.1 we make clear how the AMLI-cycle can be used in a practical implementation. As stated above, except for = L -1 , the coarse system is solved with γ iterations that use the preconditioner on the next coarse level (see step 4). Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Iterate:</p><formula xml:id="formula_31">for j = 0, . . . , γ -1 do if (j &gt; 0) w c ← A +1 v c v c ← B -1 +1 w c e c ← e c + ξ (j) v c (5) Coarse grid correction: z ← z + P e c (6) Compute residual: r ← r -A z (7) Relax with smoother M : z ← z + M -1 r</formula><p>The weights ξ (j) , j = 0, . . . , γ -1, are defined as follows. First, one sets κ L-1 = κTG and recursively computes (bottom to top)</p><formula xml:id="formula_32">κ = κTG + κTG κ +1 (1 -κ -1 +1 ) γ γ j=1 1 + κ -1 +1 γ-j 1 -κ -1 +1 j-1 2 , = L -2, . . . ,<label>1. (4.3)</label></formula><p>Then, at each level , the weights in Algorithm 4.1 are the coefficients of the polynomial (4.4)</p><formula xml:id="formula_33">p (t) = γ-1 j=0 ξ (j) t j = 1 t T γ 1+κ -1 +1 1-κ -1 +1 -T γ 1+κ -1 +1 -2t 1-κ -1 +1 1 + T γ 1+κ -1 +1 1-κ -1 +1 ,</formula><p>where T γ is the Chebyshev polynomial of degree γ, as defined by the recursion</p><formula xml:id="formula_34">(4.5) T 0 (t) = 1 , T 1 (t) = t, and, for k &gt; 1, T k (t) = 2t T k (t) -T k-1 (t) .</formula><p>Under the assumptions recalled above, it can be shown that the preconditioner at level as defined in Algorithm 4.1 satisfies</p><formula xml:id="formula_35">(4.6) v T A v ≤ v T B v ≤ κ v T A v .</formula><p>Hence, in particular, κ 1 is an upper bound on the condition number of the multigrid preconditioner used to solve the fine grid linear system. Further, the analysis of the recursion (4.3) reveals that κ ≥ κ +1 . In other words, the fine grid upper bound κ 1 increases with the depth of the recursion, that is, with the number of levels. However, κ 1 is uniformly bounded above if and only if</p><formula xml:id="formula_36">(4.7) κTG &lt; γ 2 ;</formula><p>that is, under this condition, one has</p><formula xml:id="formula_37">κ 1 ≤ κ * = lim L→∞ κ 1 &lt; ∞ . Downloaded 11/</formula><p>25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Thus, when sharp two-grid bounds are available, the AMLI-cycle allows us to automatically construct a multigrid method with level-independent convergence rate, selecting the number of iterations γ large enough to match the condition (4.7).</p><p>However, the computational cost has to be taken into account. Indeed, each application of the preconditioner B 1 at the first (finest) level involves γ -1 multiplications by the coarse grid matrix A 2 and γ applications of the preconditioner B 2 at the second level, and each of the latter involves γ -1 multiplications by the matrix A 3 and γ applications of the preconditioner B 3 at the third level, and so on. Now, to be more specific, let nnz(A ) be the number of nonzero entries in A , and, further, for = 1, . . . , L -1, let c (mv) nnz(A ) represent the cost of one matrix vector product with A , and let c (sm) nnz(A ) represent the cost of all operations in the above algorithm except step 4 (which is essentially the cost of smoothing operations at level ); moreover, let c L nnz(A L ) be the cost of the exact solution at level L. The overall cost associated with the top level preconditioner is then (4.8)</p><formula xml:id="formula_38">W 1 = c (sm) 1 nnz(A 1 ) + L-1 =2 γ -1 c (sm) + γ -1 γ c (mv) nnz(A ) + γ L-1 c L nnz(A L ).</formula><p>Now, as is made clear in section 6, the bandwidth of the smoother is bounded at every level, and, hence, so is c (sm) . On the other hand, the idea is to use enough levels to ensure that the size of A L is small enough to make c L of the same order as, say, c</p><p>. As a consequence, there exist constants c 1 , c 2 independent of problem peculiarities and such that</p><formula xml:id="formula_40">c 1 ≤ c (sm) 1 , c L , c (sm) + γ-1 γ c (mv) , = 2, . . . , L -1 ≤ c 2 .</formula><p>Therefore, setting</p><formula xml:id="formula_41">C W = L =1 γ -1 nnz(A ) nnz(A 1 ) ,</formula><p>there holds</p><formula xml:id="formula_42">c 1 nnz(A 1 ) C W ≤ W 1 ≤ c 2 nnz(A 1 ) C W .</formula><p>Hence, while γ has to be chosen sufficiently large so that (4.7) holds, it should also be sufficiently small to ensure that C W is not much larger than one. We call the latter number the weighted complexity; it can be seen as a generalization of the so-called operator complexity</p><formula xml:id="formula_43">C A = L =1 nnz(A ) nnz(A 1 )</formula><p>, which is often used to assess the coarsening of AMG methods (see, e.g., <ref type="bibr">[26, p. 487]</ref>). Whereas this operator complexity reflects well the memory requirements of the method, it is representative of its cost only if the so-called V-cycle is used. The weighted complexity is certainly more appropriate in this respect when using an AMLI-cycle. Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Now, let τ be such that, for = 2, . . . , L,</p><formula xml:id="formula_44">nnz(A ) nnz(A -1 ) &lt; 1 τ ;</formula><p>that is, let τ be a uniform bound on the coarsening factor (with respect to the number of nonzero entries). If (4.9) γ &lt; τ,</p><formula xml:id="formula_45">then C W ≤ 1 1-γ/τ</formula><p>, independently of L. Thus γ should be chosen such that both (4.7) and (4.9) hold. The first condition ensures that the number of iterations is bounded independently of L, whereas the second guarantees an optimal bound on the cost of each iteration. Obviously, these requirements are conflicting and such a γ might well not exist. In the context of this work, this can be seen as a constraint on the coarsening process: it should be designed in such a way that both (4.7) and (4.9) hold for some γ. In this respect, note also that in practice these conditions have to be interpreted in a rather restrictive sense: actually, one needs κTG γ 2 significantly below one for having the bound κ * on the multigrid condition number not much larger than κTG , and also γ τ significantly below one for having a meaningful bound on C W .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Aggregation procedure.</head><p>5.1. Preliminaries. AMG methods are often designed in such a way as to reproduce the behavior of a geometric multigrid method on some model problems. Along the same lines, and before we focus on practical details of the aggregation scheme, it is instructive to determine which kind of regular aggregation pattern would allow us to satisfy the two conflicting requirements stated in the previous section.</p><p>In this view, consider the matrix associated with a 3D Cartesian grid equipped with a seven-point symmetric stencil, as obtained from the finite difference discretization of the PDE</p><formula xml:id="formula_46">-α x ∂ 2 u ∂x 2 -α y ∂ 2 u ∂y 2 -α z ∂ 2 u ∂z 2 = f</formula><p>in the interior of any region in which the (positive) coefficients α x , α y , α z are constant. Note that for the discussion below neither the matrix scaling nor the direction of the strongest coefficient is important. Therefore, we assume α x = 1 ≥ α y , α z , without loss of generality.</p><p>The aggregation scheme considered in this work is based on a few passes of a pairwise matching algorithm, which groups unknowns into pairs. Therefore, we consider model aggregates that can be obtained with two or three passes, that is, the size 4 and size 8 aggregates depicted in Figure <ref type="figure" target="#fig_0">1</ref>, oriented in any direction. In Figure <ref type="figure">2</ref>, we represent on the left the smallest quality μ(G) from all possible such size 4 aggregates, as a function of α y and α z . We do the same on the right for size 8 aggregates. The qualities μ(G) are computed according to (3.8) with respect to the block diagonal or band smoother. We consider the aggregate of the best quality for each value of α y and α z because of our intention to design an aggregation algorithm that automatically adapts the aggregate's shape to match a given quality requirement. Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php We first discuss size 4 aggregates. The best quality μ(G) is most often between 4 and 5, but the function grows up to 7.65 in some region. It means that an aggregation procedure driven by our analysis should use a quality threshold κTG at least as large as 7.65 to guarantee that aggregates of size at least 4 can be formed for any α x , α y , α z . Now, the coarsening factor as defined in the previous section is about equal to the aggregates size. The only integer γ such that both conflicting requirements κTG ≈ 7.65 &lt; γ 2 and γ &lt; 4 hold is γ = 3. However, this would not be very cost effective. Indeed, the corresponding bound on the multigrid condition number is κ * = 31.17 , whereas, even with a coarsening factor effectively around 4, one gets a relatively high complexity C W ≈ 4 .</p><p>This leads us to consider size 8 aggregates. In this case, the best quality μ(G) is most often around 5-6, with a peak value equal to 11.46 for α x , α y ≈ 0.07. Setting κTG = 11.5 , it is possible to use γ = 4 . Then, the condition (4.7) holds and the limit value is κ * = 27.06 , yielding the upper bound (2.2) stated in section 2. On the other hand, if one effectively succeeds in forming size 8 aggregates almost everywhere, one will get C W ≈ 2 . This is a sensible target, especially if one takes into account that the smoothing procedure is cheap (and fast if properly implemented).</p><p>Before presenting the algorithm that implements this strategy, let us remark that the above discussion also implicitly includes 2D model problems. Indeed, it turns out that the best quality from all possible aggregates in a 2D grid coincides with that in a 3D grid in the limit case of one vanishing coefficient. Of course, as one can see from Figure <ref type="figure" target="#fig_0">1</ref>, restricting the discussion to this limit case would allow smaller threshold κTG and hence possibly some other choice for γ. We did not pursue this direction because we aimed at a truly algebraic procedure, which should therefore work regardless of the dimensionality of the underlying PDE. Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Automatic aggregation.</head><p>A naive approach when trying to build high quality aggregates of desired size would be to explore the matrix graph while testing all suitable aggregates. This is a costly strategy because of the often large number of possibilities and the need to compute the quality estimate for each of them. An alternative would be to guess a few potentially interesting aggregates of targeted size or larger and choose the most appropriate.</p><p>Here we follow the latter idea by considering an aggregation procedure based on a few passes of a pairwise algorithm, which attempts to group unknowns into pairs. This approach is inspired by the double pairwise aggregation algorithm in <ref type="bibr" target="#b21">[22]</ref>, which, although based on heuristic arguments, was found to be capable of building sensible aggregates in an inexpensive way. Further motivation comes from the fact that, when there are only two unknowns in G, the quality μ(G) as defined in (3.8) reduces to an easy-to-compute function involving only the off-diagonal entry connecting these two unknowns, their respective diagonal entries, and the sum of all off-diagonal elements in the corresponding rows. Therefore, precomputing the latter, it is inexpensive to find the best pair that contains a given unknown.</p><p>On the other hand, we observe that, whereas assessing μ(G) for larger |G| may become costly, it remains relatively cheap to check that μ(G) ≤ κTG for a given threshold. Indeed, this condition holds if and only if</p><formula xml:id="formula_47">κTG A G -M G I -1 G (1 T G M G 1 G ) -1 1 T G M G</formula><p>is nonnegative definite, which is true if and only if the Cholesky factorization of this matrix exists (i.e., no pivot is negative). Hence, requirement (ii) of Theorem 3.2 can be checked in only O(|G| 3 ) operations. This is taken into account in our aggregation procedure, which allows us to ensure that all aggregates satisfy the needed quality requirement, and hence that the relation (3.11) holds, while avoiding an explicit computation of μ(G) for any subset G with more than two unknowns. Now the initial pairwise aggregation as applied during the first pass is presented in Algorithm 5.1. It is largely inspired by Theorem 3.2. One first forms the set G 0 of unknowns that can be kept outside the aggregation by checking whether the condition (3.9) holds. Next one picks up one unknown at a time and searches, among its still unassigned neighbors, for the unknown yielding the pair with the best quality. Then, it is checked whether or not this quality satisfies the acceptance criterion; if not, the unknown initially picked up remains unassociated in the coarse grid. It is shown in Appendix A that the given expression for μ({i, j}) indeed matches the definition <ref type="bibr">(3.8)</ref>.</p><p>To obtain larger aggregates, we compute the auxiliary coarse grid matrix A = ( a) ij corresponding to this initial pairwise aggregation. Then, we apply essentially the same algorithm to this matrix to form pairs of pairs, or, in subsequent applications, pairs of aggregates from the previous pass.</p><p>However, some care is needed because both conditions (3.9) and (3.10) are to be checked with respect to the initial matrix. In particular, the set G 0 has to remain the one initially defined during the first pass. Furthermore, the estimate μ({i, j}) used to assess the quality of the pair {i, j} has to be adapted so as to correctly reflect the quality of the corresponding aggregate μ(G i ∪ G j ) in the original matrix. This is obtained by using the same formula as in Algorithm 5.1 but slightly changing the definition of s i . This change is needed to ensure that μ({i, j}) is a lower bound on μ(G i ∪ G j ) (see Appendix B for a proof). It means that if μ({i, j}) is above the threshold, the pair should be rejected anyway because μ(G i ∪ G j ) cannot be smaller Downloaded 11/25/14 to 18.101. <ref type="bibr" target="#b23">24</ref> Initialize:</p><formula xml:id="formula_48">G 0 = {i | a ii ≥ κTG+1 κTG-1 ( n k=1,k =i |a ik |)} (1) U ← [1, n]\G 0 n c ← 0 s i ← -j =i a ij for all i ∈ U (2)</formula><p>Iterate:</p><formula xml:id="formula_49">while U = ∅ do (2a) Select i ∈ U (2b) Find j ∈ U \{i} such that a ij = 0 and μ({i, j}) = -a ij + 1 aii+si+2aij + 1 ajj +sj +2aij -1 -a ij + 1 aii-si + 1 ajj -sj -1 is minimal (2c) n c ← n c + 1 (2d) if (μ({i, j}) ≤ κTG ) G nc = {i, j}; U ← U \{i, j} else G nc = {i}; U ← U \{i}</formula><p>than κTG . It also means that μ({i, j}) ≤ κTG can only be a preliminary acceptance criterion, which has to be supplemented by an explicit check that μ(G i ∪ G j ) ≤ κTG ; however, as indicated above, this can be done by factorizing a</p><formula xml:id="formula_50">|G i ∪ G j | × |G i ∪ G j | matrix.</formula><p>These considerations lead to Algorithm 5.2. Eventually, we make explicit in Algorithm 5.3 how these pairwise aggregation procedures are put together. An uncommon feature is that one can perform an arbitrary number of passes of pairwise aggregation without degrading the upper bound on the condition number. In practice, the process is stopped either if the specified maximal number of passes has been reached or once the coarsening factor is above a given target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Priority rules.</head><p>So far, we have not discussed how to select the unknown in U at step (2a) of the pairwise aggregation algorithms. For a given unknown i , there also may be several neighbors j for which μ({i, j}) or μ({i, j}) is minimal. If no priority rules are specified, the resulting aggregation will be sensitive to the ordering of the unknowns and/or the way in which off-diagonal entries are stored. Now, note that whereas the regularity of the aggregation is not an objective in itself, in practice it favors the coarsening speed at the subsequent coarse levels. Hence, after having tested several priority rules inspired from those in <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b21">22]</ref>, we found that the best results were obtained with a simple rule which primarily aims at producing regular aggregation patterns on regular grids. Somewhat surprisingly, good performance carries over to problems on unstructured grids: in such cases results obtained with the rule given below are at least as good as those obtained with more sophisticated choices based on the dynamic update of the unknowns' degree.</p><p>The rule is as follows for the initial pairwise aggregation of the top level (fine grid) matrix. We first compute a Cuthill-McKee (CMK) permutation <ref type="bibr" target="#b10">[11]</ref>; that is, we assign the number 1 to a node with minimal degree, and we assign the next numbers to its neighbors, ordered again by increasing degree; then, we number the Downloaded 11/25/14 to 18.101. <ref type="bibr" target="#b23">24</ref> </p><formula xml:id="formula_51">Initialize: U ← [1, n c ] n c ← 0 s i ← -k∈Gi j / ∈Gi a kj for all i ∈ U (2)</formula><p>Iterate: </p><formula xml:id="formula_52">while U = ∅ do (2a) Select i ∈ U (2b) Set T = {j | a ij = 0 and μ({i, j}) ≤ κTG }, where μ({i, j}) = -a ij + 1 aii+ si+2 aij + 1 ajj + sj +2 aij -1 -a ij + 1 aii-si + 1 ajj -sj -1 (2c) n c ← n c + 1 (2b) if (T = ∅) Select j ∈ T with minimal μ({i, j}) if (μ( G i ∪ G j ) ≤ κTG ) G nc = G i ∪ G j ; U ← U \{i, j} else T ← T \{j}; goto step (2b) else G nc = G i ; U ← U</formula><formula xml:id="formula_53">n c = n (s-1) c , G k = G (s-1) k , k = 1, . . . , n (s-1) c</formula><p>, and A = A (s-1) ; Output: n</p><formula xml:id="formula_54">(s) c , G (s) 1 , . . . , G (s) nc ; (3b) Form A (s) ← P T AP with P defined via (3.2) with respect to G (s) 1 , . . . , G (s) nc (3c) if (nnz(A (s) ) ≤ nnz(A) τ ) goto step (4) (4) n c ← n (s) c , G k ← G (s)</formula><p>k , k = 1, . . . , n c , and A c ← A (s) Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php unnumbered neighbors of the node that has just been given the number 2, still by increasing degree; we next proceed with the neighbors of node 3, and so on until all nodes are numbered. For example, when applying this procedure to a rectangular grid equipped with a five-point stencil, one obtains an ordering as illustrated in Figure <ref type="figure" target="#fig_3">3</ref>.</p><p>Note that there is still some uncertainty in this process, since there are in general several nodes with minimal degree, and hence several possible starting nodes. A given node may also have several unnumbered neighbors with same degree. However, the impact of the choices made here seems minimal. For instance, consider the example of Figure <ref type="figure" target="#fig_3">3</ref>. The only possible starting nodes are the four corner nodes. Once the algorithm has started from, say (as illustrated), the bottom left corner node, we can assign the number 2 to either its northern or eastern neighbor-the eastern one in the case of Figure <ref type="figure" target="#fig_3">3</ref>. This is, however, the last step where some freedom is left: all nodes processed subsequently have only one unnumbered neighbor, except those on the bottom line of the grid, but their neighbor which is itself on the bottom line has a smaller degree and therefore should be numbered first. Moreover, with other choices during the first two steps one would obtain orderings with identical structure, just rotated and/or mirrored. Hence, the remaining choices seem unimportant, and we do not specify how they should be made. Note that we tested the consistency of our approach by repeating the numerical experiments in the next section with randomized choices anywhere it was possible, obtaining for each problem nearly identical performances. Now, once this CMK permutation has been computed, we apply the initial pairwise aggregation algorithm, always giving priority to the node with the smallest number in this CMK permutation. This rule is used in Algorithm 5.1 both at step (2a) to select the unknown i in U and at step (2b) to discriminate between neighbors j yielding the same quality (up to rounding errors) for the pair {i, j} .</p><p>For the subsequent passes (Algorithm 5.2), and also for all passes at the coarser levels, we note that the ordering in the matrix at hand is driven by the ordering in which the pairs have been formed, which, during the first pass, is itself driven by the CMK permutation. Hence we simply give priority at any stage to the node with the smallest number in the current ordering. Proceeding recursively in this way, the initial CMK permutation induces the choices throughout all levels.</p><p>We illustrate in Figure <ref type="figure">4</ref> the performance of the resulting aggregation algorithm with three passes at each level. This configuration is obtained, e.g., by using Algorithm 5.3 with κTG = 11.5 , τ = 8, and n pass ≥ 3. The first three pictures show the aggregation pattern produced by these three successive passes at the top level, whereas the last picture (bottom right) gives at once the result of the multiple pairwise aggregation at the next level. Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Fig. <ref type="figure">4</ref>. Aggregation for the model Poisson problem on the unit square with h = 1/32 ; dark (red) boxes correspond to nodes in G 0 , whereas light gray (green) boxes correspond to aggregates. Top: after one (left) and two (right) pairwise aggregations passes applied to the level 1 matrix. Bottom: the complete result of the multiple pairwise aggregation algorithm with three passes at level 1 (left) and level 2 (right); in the right-hand picture, nodes that are not in any box are those in G 0 at the previous level and hence are not represented anymore in the coarse grid matrix. <ref type="figure">4</ref> that after two successive aggregation steps with three passes each, the coarse grid has a regular structure similar to the one on the fine grid. One may then wonder if this regularity depends on the problem size. In Figure <ref type="figure" target="#fig_5">5</ref> we display the aggregation pattern obtained for the same problem with h = 1/64. Clearly, the structure of the resulting coarse grid is similar to that for h = 1/32. This is not surprising. With our algorithm, aggregates are formed in a regular fashion starting from the corner in which the CMK ordering has been initiated. Irregularities occur only when reaching opposite boundaries. But if two grids with n (1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Model problem analysis. One sees in Figure</head><formula xml:id="formula_55">x × n (1)</formula><formula xml:id="formula_56">y and n (2) x × n (2)</formula><p>y nodes are such that |n <ref type="bibr" target="#b0">(1)</ref> xn </p><formula xml:id="formula_57">y -n (2)</formula><p>y | are multiples of 8, these irregularities will be treated in exactly the same way and hence the resulting matrices will have similar structure. Therefore, generally speaking, Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php starting from a matrix corresponding to h = 2 -k (that is, a grid with (2 k -1)×(2 k -1) nodes), one obtains a (2 k-3 -1) × 2 k-3 grid with five-point connectivity; this holds for any k ≥ 5. Note that, starting from a square grid we obtain a rectangular grid with rectangle "orientation" depending on which neighbor of the starting corner node has been numbered first when computing the CMK ordering (the discussion above assumes that the CMK permutation is as in Figure <ref type="figure" target="#fig_3">3</ref>). Now, one may wonder if these observations can be recursively applied to anticipate the result of further coarsening steps. Here, a key argument is that when discarding the (lines and columns of) nodes that are closest to boundaries (which will be assigned to G 0 in a further aggregation process), all remaining aggregates are square, regularly aligned, and have the same size. Hence (see <ref type="bibr">(3.3)</ref>), the entries in the stencil will be those of the standard five-point stencil we have started from, up to a scaling factor. Moreover, one may check that the ordering of this coarse grid matrix is a CMK ordering, similar to (and induced by) the fine grid one. Hence a recursive application of the above observations is possible, providing that they can be extended to cases where the starting grid is a (2 k -1) × 2 k grid, instead of a (2 k -1) × (2 k -1) grid as considered so far. In Figure <ref type="figure" target="#fig_6">6</ref>, we display the aggregation pattern obtained for such a 63 × 64 grid. One sees that the coarse grid (and, hence, the associated coarse grid matrix) after two steps corresponds to a 7 × 8 grid and is in fact identical to that obtained in Figure <ref type="figure" target="#fig_5">5</ref> when coarsening the matrix associated to the 63 × 63 grid. Moreover, one may check that the ordering associated to every coarse grid node is identical in both cases. We have therefore shown the essential part of the following proposition.</p><p>Proposition 5.1. Let A = A 1 be the matrix corresponding to the five-point discretization of the Poisson equation on the unit square with uniform mesh size h = 2 -k for some positive integer k. Consider successive applications of the multiple pairwise aggregation algorithm with three passes, using the priority rules described in section 5.3. If is a positive even integer such that k - 3  2 ≥ 2, then the resulting coarse grid matrix A corresponds to a five-point stencil on a rectangular grid with Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php (</p><formula xml:id="formula_58">2 k-3 2 -1) × 2 k-3</formula><p>2 nodes, and one has</p><formula xml:id="formula_59">(5.1) nnz(A ) ≤ 8 -nnz(A).</formula><p>Proof. The discussion above shows the main result, and it remains to prove (5.1). We have nnz(A 1 ) = 5(2 k -1) 2 -4(2 k -1), whereas</p><formula xml:id="formula_60">nnz(A ) = 5(2 k-3 2 -1)2 k-3 2 -2(2 k-3 2 -1) -2 • 2 k-3 2 .</formula><p>Hence, since k ≥ 3 2 + 2, by assumption</p><formula xml:id="formula_61">nnz(A 1 ) -2 3 nnz(A ) = 2 k (9 • 2 3 2 -14) + 9 -2 • 2 3 ≥ 4(9 • 2 3 -14 • 2 3 2 ) + 9 -2 • 2 3 = 34 • 2 3 -56 • 2 3 2 + 9.</formula><p>The latter (bottommost) expression is a second degree polynomial in 2 3 2 , which is indeed always positive when the argument is not less than 8, as ensured by the condition positive and even, which entails ≥ 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Illustration.</head><p>We conclude this section with an illustration of our aggregation procedure on an example with unstructured mesh. More precisely, we consider the linear finite element discretization of (5.2)</p><formula xml:id="formula_62">-∂ 2 u ∂x 2 -∂ 2 u ∂y 2 = 0 on Ω = [-1, 1] 2 \[0, 1] × [-1, 0], u = r 2 3 sin( 2θ 3 ) on ∂Ω,</formula><p>where (r, θ) is the polar coordinate representation of (x, y) . The discretization is performed on the mesh illustrated in Figure <ref type="figure">7</ref>, in which the simplex size is progressively decreased near the reentering corner, in such a way that the mesh size in its neighborhood is about 10 times smaller. Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Fig. <ref type="figure">7</ref>. L-shaped domain with unstructured mesh refined near the reentering corner (left) and zoom on the region near the corner delimited with blue (dark) contour (right).</p><p>The result of the application of Algorithm 5.3 to this problem is illustrated in Figure <ref type="figure">8</ref>. Priority rules are as indicated in subsection 5.3, and the parameters are threshold κTG = 11.5, maximal number of passes n pass = 5, and target coarsening factor τ = 8 . In practice, four passes have been necessary at level 1, three at level 2, and only two at level 3 (thanks to the large number of nodes in G 0 ). Hence the coarsening factor is in all cases above the target, but this sometimes requires more than the three passes needed in the case of a regular grid. In fact, as one can see in the figure, especially at the top level, the aggregates here are far from "geometric," and, if the mean aggregate size is above 8, the actual aggregate size ranges from 1 to 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Numerical experiments.</head><p>Our first set of test problems corresponds to finite element and finite difference discretizations on structured grids with uniform mesh size h in all directions; all problems are defined on a unit square (2D) or a unit cube (3D). We give only brief descriptions of these problems here and refer the reader to <ref type="bibr" target="#b21">[22]</ref> for further details. Our test problems include</p><p>• five-point discretization of constant coefficients problem in two dimensions with coefficients (1 , ε y ); we consider ε y = 1 (Mod2D), ε y = 10 -2 (Ani2D a ), and ε y = 10 -4 (Ani2D b ); • seven-point discretization of constant coefficients problem in three dimensions with coefficients (ε x , ε y , 1); we consider ε x , ε y = 1 (Mod3D), ε x = 0.07, ε y = 1 (Ani3D a ), ε x = 0.07, ε y = 0.25 (Ani3D b ), ε x = 0.07, ε y = 0.07 (Ani3D c ), ε x = 0.005, ε y = 1 (Ani3D d ), ε x = 0.005, ε y = 0.07 (Ani3D e ), ε x = 0.005, ε y = 0.005 (Ani3D f ); • five-and seven-point discretizations of piecewise-constant coefficient problem in two dimensions (Jump2D) and in three dimensions (Jump3D); • nine-point bilinear finite element discretization of isotropic constant coefficient problem in two dimensions (BFE). The remaining test problems consist of finite element discretizations on (mainly) unstructured grids. Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Fig. <ref type="figure">8</ref>. Aggregation for the problem (5.2) discretized on the mesh depicted in Figure <ref type="figure">7</ref>. Top: after one application of the multiple pairwise aggregation algorithm (left) and zoom near the reentering corner (right). Bottom: after two (left) and three (right) applications of the multiple pairwise aggregation algorithm.</p><p>Problem LUnfSt: Linear finite element discretization of (5.2) on a uniform mesh with right triangles. Problem LRfUst r : Linear finite element discretization of (5.2) on an unstructured mesh with simplex size progressively decreased near the reentering corner, in such a way that the mesh size in its neighborhood is about 10 r times smaller, with r going from 0 ( LRfUst 0 ) to 5 ( LRfUst 5 ); for r = 1, this is the mesh illustrated in Figure <ref type="figure">7</ref>, further uniformly refined four times (size S1) or five times (size S2).  Problem SphRf d : Same as above, but with five times smaller sphere Ω having 10 times smaller simplices near its surface.</p><formula xml:id="formula_63">Problem SphUnf d : Linear finite element discretization of ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ -∇ • d∇u = 0 on Ω = {r = (x, y, z) T | r &lt; 1}, -∇ • ∇u = 0 on Ω = [-2.5, 2.5] 3 \ Ω, u = 0 for |x| = 2.</formula><p>Every test problem may lead to systems with variable size n. For finite difference problems on structured grids we consider three system sizes:</p><p>• S1, corresponding to h -1 = 600 in two dimensions (n ≈ 0.36 10 6 ) and h -1 = 80 in three dimensions (n ≈ 0.51 10 6 ); • S2, corresponding to h -1 = 1600 in two dimensions (n ≈ 2.5 10 6 ) and h -1 = 160 in three dimensions (n ≈ 4.1 10 6 ); • S3, corresponding to h -1 = 5000 in two dimensions (n ≈ 25 10 6 ) and h -1 = 320 in three dimensions (n ≈ 33 10 6 ). Regarding finite element discretizations on unstructured grids, we use only two sizes: S1 and S2, which roughly correspond to O (10 5 ) and O(10 6 ) unknowns, respectively; see Table <ref type="table">1</ref> for more details.</p><p>Our method has been applied to all test problems in a uniform (black box) fashion. The multilevel algorithm was used as a preconditioner for the conjugate gradient method and implemented as in Algorithm 4.1, using the band smoother described in section 3. The AMLI cycle was used with γ = 4 iterations on the coarse levels and with weights ξ (j) being the coefficients of polynomials (4.4) based on the recursive estimate (4.3) with κTG = 11.5. For the coarsening, we uniformly use the same parameters as in section 5.5: threshold κTG = 11.5, maximal number of passes n pass = 5, and target coarsening factor τ = 8. It means that one may occasionally obtain a few aggregates of size much larger than the target (up to 32). We therefore slightly modified Algorithm 5.2 to avoid a harmful impact on the smoother's bandwidth; that is, we further reject at step (2b) also those pairs whose acceptance would induce a bandwidth larger than 10 for the band smoother. This turns out to have a limited impact on the coarsening (only aggregates of size larger than 10 can be rejected) while ensuring a reasonable computational cost of the smoothing iterations. We also checked that this modification has no impact on the coarsening depicted in Figure <ref type="figure">8</ref>; i.e., although there are some aggregates of size 10 to 16, none of them has a bandwidth larger than 10. The conjugate gradient method was used with the zero vector as initial approximation, and iterations were stopped when the relative residual error was below 10 -6 . Results are reported in Tables <ref type="table" target="#tab_5">2</ref> and<ref type="table" target="#tab_6">3</ref>. All timings are elapsed times when running a Fortran 90 implementation of the method on a computing node with two Intel XEON L5420 processors at 2.50 GHz and 16 Gb RAM memory.</p><p>What is perhaps the most striking from these results is the regularity of the method performance. Take, for instance, as reference the Mod2D problem for which our analysis also covers the coarsening speed, and consider the S3 size. The weighted Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php One sees that when AGMG 2.3 works well, it requires about 40% less time than the method presented here. However, like any heuristic method, AGMG 2.3 may occasionally fail; see the 2D example with strong local refinement. Then it pays off to use the method with guaranteed convergence rate (AggGar). Further, AGMGar seems to combine the advantages of both approaches. We explain this as follows. The relative slowness of AggGar (compared with AGMG 2.3) is mainly due to the constraints associated with the use of the AMLI-cycle, in particular the need to perform four inner iterations at each level. However, in practice (this cannot be proved), the K-cycle is as efficient as the AMLI-cycle in stabilizing the condition number once the two-grid scheme satisfies some minimal requirements <ref type="bibr" target="#b23">[24]</ref> and such minimal requirements are Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php met when using the new aggregation with the parameters indicated above. Hence combining the new aggregation algorithm with the K-cycle allows AGMGar to be as fast as the heuristic method AGMG 2.3, while preserving the additional robustness associated with the new aggregation algorithm.</p><p>On the other hand, the comparison with MATLAB "\" allows us to consider the performances of aggregation-based methods from a more general viewpoint. One sees that AGMG 2.3 and AGMGar are both faster on the model Poisson problem in two dimensions, for which the direct solver is practically scalable and known as "hard to beat." Further, interestingly enough, the AMG variants based on the new coarsening algorithm are apparently more robust in the presence of strong local refinement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions.</head><p>We have presented a purely algebraic (black box) multigrid method that has a guaranteed convergence rate for any symmetric M-matrix with nonnegative row sum. Like many AMG schemes, our method has some uncertainty in the coarsening factor and, hence, in the computational cost per iteration. However, we showed that a sufficiently fast coarsening is guaranteed at least for a model 2D problem, whereas numerical results indicate that satisfactory complexities are obtained in quite diverse cases without any parameter tuning.</p><p>Moreover, the results obtained with AGMGar (see Table <ref type="table">4</ref>) show that the aggregation method presented here can also be useful in a more general context. Of course, AGMGar would deserve a more detailed presentation, and these results raise several further questions, such as the applicability to non-M-matrices. However, we do not pursue this discussion here, as it would lead us outside the scope of the present paper. We only briefly mention that the aggregation algorithms of section 5 can actually be applied to SPD matrices that are not M-matrices, i.e., that have some positive off-diagonal entries. If the matrix has nonnegative row sum, the main steps of our analysis still apply, except that the matrix A r in the splitting A = A b + A r referred to in section 3 is no longer guaranteed to be nonnegative definite; hence, the approach corresponds to a sensible heuristic in applications for which this matrix, which still has zero row sum, remains close enough to nonnegative definiteness. On the other hand, it is worth noting that the approach developed here has been further extended in <ref type="bibr" target="#b22">[23]</ref> to nonsymmetric M-matrices.</p><p>Software. The results of this research have been integrated in the AGMG software <ref type="bibr" target="#b20">[21]</ref> (released under the terms of the GNU General Public License), whose version 3.1.1 is nearly identical to the code referred to above as AGMGar.</p><p>Appendix A. Here we derive an explicit expression for the quality μ(G) of an aggregate G = {i, j}. In this context,</p><formula xml:id="formula_64">A G = a ii -s i -a ij a ij a ji a jj -s j -a ji = -a ij 1 -1 -1 1 + δ 1 δ 2 ,</formula><p>where s i =k =i a ik , s j =k =j a jk , δ 1 = a iis i , and δ 2 = a jjs j . Since we consider the block-diagonal (or the band) smoother,</p><formula xml:id="formula_65">M G = a ii + s i + a ij a ij a ji a jj + s j + a ji = -a ij 1 -1 -1 1 + η 1 η 2 ,</formula><p>where η i = a ii + s i + 2a ij , η j = a jj + s j + 2a ij . Using these expressions in <ref type="bibr">(3.8)</ref>, some Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php A1107 elementary algebra leads to</p><formula xml:id="formula_66">μ(G) = -a ij + η 1 η 2 η 1 + η 2 sup v =1 v T ( 1 -1 -1 1 )v v T A G v = -a ij + η 1 η 2 η 1 + η 2 sup (v1,v2) =(1,1) (v 1 -v 2 ) 2 -a ij (v 1 -v 2 ) 2 + δ 1 v 2 1 + δ 2 v 2 2 .</formula><p>Now, if δ 1 = δ 2 = 0, we have μ(G) = 1 + 1 -aij η1η2 η1+η2 , whereas otherwise the supremum is reached in (v 1 , v 2 ) = (δ 2 , -δ 1 ), which yields</p><formula xml:id="formula_67">μ(G) = -a ij + η 1 η 2 η 1 + η 2 -a ij + δ 1 δ 2 δ 1 + δ 2 .</formula><p>Eventually, replacing η k , δ k , k = 1, 2 , by their expression yields the formula for μ({i, j}) in Algorithm 5.1, in which the denominator should be interpreted as equal to -a ij if either δ 1 = a iis i = 0 or δ 2 = a jjs j = 0 . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><formula xml:id="formula_68">μ( G i ∪ G j ) = sup v / ∈N (AG i ∪G j ) v T M Gi∪Gj (I -1 Gi∪Gj (1 T Gi∪Gj M Gi∪Gj 1 Gi∪Gj ) -1 1 T Gi∪Gj M Gi∪Gj )v v T A Gi∪Gj v ≥ sup w / ∈N ( A {i,j} )</formula><p>w T M {i,j} (I -1 {i,j} (1 T {i,j} M {i,j} 1 {i,j} ) -1 1 T {i,j} M {i,j} )w w T A {i,j} w = μ({i, j}), Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php where we have used v = P f w to obtain the inequality in the second line and where the last equality is shown in Appendix A.</p><p>We eventually prove (B.2), the proof of (B.3) following along the same lines. Regarding the first diagonal element of A {i,j} , we have, using <ref type="bibr">(3.3)</ref>  Hence, since A Gi∪Gj = A| Gi∪Gj -Σ Gi∪Gj and (P T f Σ Gi∪Gj P f ) 12 = 0, the equality (B.2) follows.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 .</head><label>1</label><figDesc>Introduction. Efficient solution of large sparse symmetric positive definite (SPD) n × n linear systems (1.1) Ax = b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 4 . 1 .</head><label>41</label><figDesc>Multigrid preconditioner at level : z ← B -1 r. (1) Relax with smoother M : z ← M -1 r (2) Compute residual: r ← r -A z (3) Restrict residual: r c ← P T r (4) Compute (approximate) solution e c to A +1 e c = r c if ( = L -1) e c = A -1 L r c else : Initialize: e c ← 0 ; w c ← r c</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 1. Model aggregate shapes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. CMK ordering for a five-point stencil on a 5 × 5 grid.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Aggregation for the model Poisson problem on the unit square with h = 1/64: result of the multiple pairwise aggregation algorithm with three passes at level 1 (left) and level 2 (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Aggregation for the model Poisson problem on the 1 × (1 + h) rectangle with h = 1/64: result of the multiple pairwise aggregation algorithm with three passes at level 1 (left) and level 2 (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>with ∇ = 1</head><label>1</label><figDesc>unstructured quasi-uniform mesh; we consider d = 10 -3 ( SphUnf -3 ), d = 1 ( SphUnf 0 ), and d = 10 3 ( SphUnf 3 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1) T is a vector of size |G|. Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</figDesc><table><row><cell>A1087</cell></row><row><cell>If for a given κTG ≥ 1, there holds</cell></row><row><cell>(i)</cell></row><row><cell>(3.9)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</figDesc><table><row><cell cols="2">Algorithm 5.1. Initial pairwise aggregation.</cell></row><row><cell>input:</cell><cell>n × n matrix A = (a ij )</cell></row><row><cell></cell><cell>threshold κTG</cell></row><row><cell>output:</cell><cell>n c and sets G 0 , . . . , G nc</cell></row><row><cell>(0)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</figDesc><table><row><cell cols="2">Algorithm 5.2. Further pairwise aggregation.</cell></row><row><cell>input:</cell><cell>n × n matrix A = (a ij )</cell></row><row><cell></cell><cell>threshold κTG</cell></row><row><cell></cell><cell>tentative n c and sets G k , k = 1, . . . , n c</cell></row><row><cell></cell><cell>corresponding n c × n c matrix A = ( a ij )</cell></row><row><cell>output:</cell><cell>n c and sets G 1 , . . . , G nc</cell></row><row><cell>(1)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>\{i} Algorithm 5.3. Multiple pairwise aggregation.</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>input:</cell><cell cols="2">n × n matrix A</cell></row><row><cell></cell><cell></cell><cell cols="2">threshold κTG</cell></row><row><cell></cell><cell></cell><cell cols="2">maximal number of passes n pass</cell></row><row><cell></cell><cell></cell><cell cols="2">target coarsening factor τ</cell></row><row><cell></cell><cell>output:</cell><cell cols="2">n c and sets G 0 , . . . , G nc</cell></row><row><cell></cell><cell></cell><cell cols="2">corresponding aggregation matrix A c</cell></row><row><cell>(1)</cell><cell>First pass:</cell><cell cols="2">Apply Initial pairwise aggregation algorithm</cell></row><row><cell></cell><cell></cell><cell cols="2">to matrix A with threshold κTG ;</cell></row><row><cell></cell><cell></cell><cell>Output: n</cell><cell>(1)</cell><cell>(1) 1 , . . . , G (1) nc ;</cell></row><row><cell>(2)</cell><cell></cell><cell cols="2">Form A (1) ← P T AP with P defined via (3.2)</cell></row><row><cell></cell><cell></cell><cell cols="2">with respect to G (1) 1 , . . . , G (1) nc</cell></row><row><cell>(3)</cell><cell>Iterate:</cell><cell cols="2">for s = 2, . . . , n pass</cell></row><row><cell cols="2">(3a) Next passes:</cell><cell cols="2">Apply Further pairwise aggregation algorithm</cell></row><row><cell></cell><cell></cell><cell cols="2">to matrix A with threshold κTG ,</cell></row></table><note><p>c , G 0 , and G</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>5, -2.5 ≤ y, z ≤ 2.5, u = 1 elsewhere on ∂Ω Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</figDesc><table><row><cell></cell><cell></cell><cell>Table 1</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Problem sizes.</cell><cell></cell><cell></cell></row><row><cell></cell><cell>S1</cell><cell></cell><cell>S2</cell><cell></cell></row><row><cell>Problem</cell><cell>n 10 6</cell><cell>nnz(A) 10 6</cell><cell>n 10 6</cell><cell>nnz(A) 10 6</cell></row><row><cell>LUnfSt</cell><cell>0.20</cell><cell>1.0</cell><cell>3.1</cell><cell>16</cell></row><row><cell>LRfUst</cell><cell cols="2">0.72 → 1.8 5.1 → 12</cell><cell>2.9 → 7.1</cell><cell>20 → 50</cell></row><row><cell>SphUnf</cell><cell>0.53</cell><cell>7.6</cell><cell>4.2</cell><cell>61</cell></row><row><cell>SphRf</cell><cell>0.15</cell><cell>2.2</cell><cell>1.2</cell><cell>18</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2</head><label>2</label><figDesc>Computational complexity, condition number, and number of iterations needed to reduce the residual norm by 10 -6 .</figDesc><table><row><cell></cell><cell></cell><cell>C W</cell><cell></cell><cell></cell><cell>κ(B -1 1 A)</cell><cell></cell><cell></cell><cell>#Iter</cell><cell></cell></row><row><cell>Problem</cell><cell>S1</cell><cell>S2</cell><cell>S3</cell><cell>S1</cell><cell>S2</cell><cell>S3</cell><cell>S1</cell><cell>S2</cell><cell>S3</cell></row><row><cell>Mod2D</cell><cell>1.9</cell><cell>2.0</cell><cell>2.0</cell><cell>7.0</cell><cell>7.4</cell><cell>7.6</cell><cell>23</cell><cell>24</cell><cell>26</cell></row><row><cell>Mod3D</cell><cell>1.8</cell><cell>1.9</cell><cell>1.9</cell><cell>6.0</cell><cell>6.1</cell><cell>6.1</cell><cell>18</cell><cell>18</cell><cell>19</cell></row><row><cell>Ani2Da</cell><cell>1.7</cell><cell>1.9</cell><cell>1.9</cell><cell>9.1</cell><cell>8.8</cell><cell>8.9</cell><cell>21</cell><cell>25</cell><cell>25</cell></row><row><cell>Ani2D b</cell><cell>1.8</cell><cell>1.8</cell><cell>1.9</cell><cell>1.3</cell><cell>2.0</cell><cell>7.5</cell><cell>7</cell><cell>11</cell><cell>16</cell></row><row><cell>Ani3Da</cell><cell>1.4</cell><cell>1.4</cell><cell>1.4</cell><cell>6.4</cell><cell>6.9</cell><cell>7.4</cell><cell>20</cell><cell>22</cell><cell>24</cell></row><row><cell>Ani3D b</cell><cell>1.5</cell><cell>1.5</cell><cell>1.5</cell><cell>7.1</cell><cell>7.6</cell><cell>8.2</cell><cell>18</cell><cell>19</cell><cell>26</cell></row><row><cell>Ani3Dc</cell><cell>1.7</cell><cell>1.7</cell><cell>1.8</cell><cell>6.0</cell><cell>6.0</cell><cell>6.4</cell><cell>19</cell><cell>20</cell><cell>21</cell></row><row><cell>Ani3D d</cell><cell>1.4</cell><cell>1.4</cell><cell cols="2">1.4 10.2</cell><cell>13.1</cell><cell>13.1</cell><cell>26</cell><cell>30</cell><cell>31</cell></row><row><cell>Ani3De</cell><cell>1.4</cell><cell>1.4</cell><cell cols="2">1.4 11.5</cell><cell>12.0</cell><cell>12.6</cell><cell>26</cell><cell>28</cell><cell>29</cell></row><row><cell>Ani3D f</cell><cell>1.6</cell><cell>1.6</cell><cell>1.9</cell><cell>1.8</cell><cell>7.2</cell><cell>8.5</cell><cell>10</cell><cell>20</cell><cell>23</cell></row><row><cell>Jump2D</cell><cell>1.5</cell><cell>1.5</cell><cell cols="2">1.6 10.4</cell><cell>11.2</cell><cell>12.2</cell><cell>27</cell><cell>29</cell><cell>32</cell></row><row><cell>Jump3D</cell><cell>1.5</cell><cell>1.5</cell><cell>1.5</cell><cell>6.5</cell><cell>7.1</cell><cell>7.5</cell><cell>22</cell><cell>24</cell><cell>25</cell></row><row><cell>BFE</cell><cell>1.6</cell><cell>1.6</cell><cell>1.6</cell><cell>5.6</cell><cell>5.9</cell><cell>6.1</cell><cell>21</cell><cell>23</cell><cell>24</cell></row><row><cell>LRfUst 0</cell><cell>1.7</cell><cell>1.7</cell><cell></cell><cell>5.3</cell><cell>6.5</cell><cell></cell><cell>7</cell><cell>9</cell><cell></cell></row><row><cell>LRfUst 1</cell><cell>1.7</cell><cell>1.7</cell><cell></cell><cell>5.0</cell><cell>5.6</cell><cell></cell><cell>6</cell><cell>7</cell><cell></cell></row><row><cell>LRfUst 2</cell><cell>1.7</cell><cell>1.7</cell><cell></cell><cell>5.0</cell><cell>6.4</cell><cell></cell><cell>6</cell><cell>8</cell><cell></cell></row><row><cell>LRfUst 3</cell><cell>1.7</cell><cell>1.7</cell><cell></cell><cell>5.0</cell><cell>6.2</cell><cell></cell><cell>6</cell><cell>8</cell><cell></cell></row><row><cell>LRfUst 4</cell><cell>1.7</cell><cell>1.7</cell><cell></cell><cell>5.0</cell><cell>6.2</cell><cell></cell><cell>6</cell><cell>8</cell><cell></cell></row><row><cell>LRfUst 5</cell><cell>1.7</cell><cell>1.6</cell><cell></cell><cell>5.1</cell><cell>5.3</cell><cell></cell><cell>6</cell><cell>6</cell><cell></cell></row><row><cell>LUnfSt</cell><cell>1.9</cell><cell>2.0</cell><cell></cell><cell>6.2</cell><cell>6.8</cell><cell></cell><cell>16</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3</head><label>3</label><figDesc>Set-up time, solution time, and total time reported here per million of unknowns (with T total = T sol + Tsetup).</figDesc><table><row><cell></cell><cell></cell><cell>Tsetup</cell><cell></cell><cell></cell><cell>T sol</cell><cell></cell><cell></cell><cell>Ttot</cell><cell></cell></row><row><cell>Problem</cell><cell>S1</cell><cell>S2</cell><cell>S3</cell><cell>S1</cell><cell>S2</cell><cell>S3</cell><cell>S1</cell><cell>S2</cell><cell></cell><cell>S3</cell></row><row><cell>Mod2D</cell><cell>1.2</cell><cell>1.1</cell><cell>1.7</cell><cell>6.4</cell><cell>7.6</cell><cell>8.7</cell><cell>7.5</cell><cell>8.8</cell><cell cols="2">10.3</cell></row><row><cell>Mod3D</cell><cell>1.6</cell><cell>2.6</cell><cell>2.9</cell><cell>5.7</cell><cell>6.5</cell><cell>7.3</cell><cell>7.3</cell><cell>9.1</cell><cell cols="2">10.1</cell></row><row><cell>Ani2Da</cell><cell>1.8</cell><cell>1.7</cell><cell>2.3</cell><cell>5.1</cell><cell>7.4</cell><cell>8.0</cell><cell>6.8</cell><cell>9.1</cell><cell cols="2">10.3</cell></row><row><cell>Ani2D b</cell><cell>1.8</cell><cell>1.7</cell><cell>2.5</cell><cell>1.8</cell><cell>3.1</cell><cell>4.9</cell><cell>3.6</cell><cell>4.9</cell><cell></cell><cell>7.4</cell></row><row><cell>Ani3Da</cell><cell>2.1</cell><cell>3.6</cell><cell>4.0</cell><cell>5.3</cell><cell>6.5</cell><cell>7.3</cell><cell>7.5</cell><cell>10.1</cell><cell cols="2">11.4</cell></row><row><cell>Ani3D b</cell><cell>2.4</cell><cell>4.0</cell><cell>4.5</cell><cell>4.8</cell><cell>5.6</cell><cell>8.3</cell><cell>7.1</cell><cell>9.6</cell><cell cols="2">12.8</cell></row><row><cell>Ani3Dc</cell><cell>2.8</cell><cell>4.7</cell><cell>5.2</cell><cell>6.2</cell><cell>7.4</cell><cell>8.1</cell><cell>9.1</cell><cell>12.1</cell><cell cols="2">13.3</cell></row><row><cell>Ani3D d</cell><cell>2.3</cell><cell>3.8</cell><cell>4.2</cell><cell>6.6</cell><cell>8.6</cell><cell>9.0</cell><cell>8.9</cell><cell>12.4</cell><cell cols="2">13.3</cell></row><row><cell>Ani3De</cell><cell>2.4</cell><cell>4.1</cell><cell>4.6</cell><cell>6.3</cell><cell>7.3</cell><cell>7.9</cell><cell>8.6</cell><cell>11.4</cell><cell cols="2">12.5</cell></row><row><cell>Ani3D f</cell><cell>2.3</cell><cell>4.2</cell><cell>4.6</cell><cell>2.9</cell><cell>6.3</cell><cell>8.2</cell><cell>5.2</cell><cell>10.5</cell><cell cols="2">12.8</cell></row><row><cell>Jump2D</cell><cell>1.6</cell><cell>1.7</cell><cell>2.2</cell><cell>8.5</cell><cell>10.4</cell><cell>11.9</cell><cell>10.1</cell><cell>12.1</cell><cell cols="2">14.1</cell></row><row><cell>Jump3D</cell><cell>2.2</cell><cell>3.1</cell><cell>3.4</cell><cell>7.2</cell><cell>8.5</cell><cell>9.3</cell><cell>9.4</cell><cell>11.6</cell><cell cols="2">12.6</cell></row><row><cell>BFE</cell><cell>1.8</cell><cell>1.7</cell><cell>2.2</cell><cell>7.7</cell><cell>9.4</cell><cell>10.3</cell><cell>9.5</cell><cell>11.1</cell><cell cols="2">12.5</cell></row><row><cell>LRfUst 0</cell><cell>2.2</cell><cell>2.2</cell><cell></cell><cell>2.9</cell><cell>3.9</cell><cell></cell><cell>5.1</cell><cell>6.0</cell><cell></cell></row><row><cell>LRfUst 1</cell><cell>2.2</cell><cell>2.2</cell><cell></cell><cell>2.5</cell><cell>3.0</cell><cell></cell><cell>4.7</cell><cell>5.2</cell><cell></cell></row><row><cell>LRfUst 2</cell><cell>2.1</cell><cell>2.1</cell><cell></cell><cell>2.5</cell><cell>3.6</cell><cell></cell><cell>4.6</cell><cell>5.6</cell><cell></cell></row><row><cell>LRfUst 3</cell><cell>2.2</cell><cell>2.1</cell><cell></cell><cell>2.6</cell><cell>3.6</cell><cell></cell><cell>4.7</cell><cell>5.7</cell><cell></cell></row><row><cell>LRfUst 4</cell><cell>2.2</cell><cell>2.1</cell><cell></cell><cell>2.5</cell><cell>3.6</cell><cell></cell><cell>4.7</cell><cell>5.8</cell><cell></cell></row><row><cell>LRfUst 5</cell><cell>2.2</cell><cell>2.1</cell><cell></cell><cell>2.5</cell><cell>2.6</cell><cell></cell><cell>4.7</cell><cell>4.7</cell><cell></cell></row><row><cell>LUnfSt</cell><cell>1.8</cell><cell>1.8</cell><cell></cell><cell>6.1</cell><cell>6.8</cell><cell></cell><cell>7.8</cell><cell>8.7</cell><cell></cell></row><row><cell>SphRf -3</cell><cell>7.5</cell><cell>7.3</cell><cell></cell><cell>8.0</cell><cell>10.0</cell><cell></cell><cell>15.5</cell><cell>17.4</cell><cell></cell></row><row><cell>SphRf 0</cell><cell>6.7</cell><cell>7.3</cell><cell></cell><cell>8.2</cell><cell>10.1</cell><cell></cell><cell>14.9</cell><cell>17.4</cell><cell></cell></row><row><cell>SphRf 3</cell><cell>6.6</cell><cell>7.2</cell><cell></cell><cell>8.1</cell><cell>10.0</cell><cell></cell><cell>14.7</cell><cell>17.3</cell><cell></cell></row><row><cell>SphUnf -3</cell><cell>6.7</cell><cell>7.4</cell><cell></cell><cell>8.6</cell><cell>10.4</cell><cell></cell><cell>15.3</cell><cell>17.9</cell><cell></cell></row><row><cell>SphUnf 0</cell><cell>6.7</cell><cell>7.4</cell><cell></cell><cell>8.7</cell><cell>10.4</cell><cell></cell><cell>15.4</cell><cell>17.8</cell><cell></cell></row><row><cell>SphUnf 3</cell><cell>6.7</cell><cell>7.4</cell><cell></cell><cell>8.8</cell><cell>10.6</cell><cell></cell><cell>15.5</cell><cell>18.0</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Table 4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="11">Total solution time for the different versions of aggregation-based AMG and the MATLAB</cell></row><row><cell cols="6">direct solver (" \"), reported per million of unknowns.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>S 1</cell><cell>S2</cell><cell>S3</cell><cell>S1</cell><cell>S2</cell><cell>S1</cell><cell>S2</cell><cell>S1</cell><cell></cell><cell>S2</cell></row><row><cell></cell><cell></cell><cell>Mod2D</cell><cell></cell><cell cols="2">LRfUst 0</cell><cell cols="2">LRfUst 2</cell><cell cols="3">LRfUst 4</cell></row><row><cell cols="2">AGMG 2.3 4.7</cell><cell>5.3</cell><cell>6.3</cell><cell>6.9</cell><cell>10.9</cell><cell>9.2</cell><cell>21.1</cell><cell cols="2">162.2</cell><cell>-</cell></row><row><cell>AggGar</cell><cell>7.5</cell><cell>8.8</cell><cell>10.3</cell><cell>5.1</cell><cell>6.0</cell><cell>4.6</cell><cell>5.6</cell><cell cols="2">4.7</cell><cell>5.8</cell></row><row><cell cols="2">AGMGar 3.4</cell><cell>3.5</cell><cell>3.9</cell><cell>3.3</cell><cell>3.0</cell><cell>3.4</cell><cell>2.8</cell><cell cols="2">2.9</cell><cell>2.9</cell></row><row><cell>MATLAB "\"</cell><cell>6.2</cell><cell>6.6</cell><cell>-</cell><cell>8.5</cell><cell>10.8</cell><cell>10.0</cell><cell>11.8</cell><cell cols="2">9.8</cell><cell>12.5</cell></row><row><cell></cell><cell></cell><cell>Mod3D</cell><cell></cell><cell cols="2">SphRf -3</cell><cell cols="2">SphRf 0</cell><cell cols="3">SphRf 3</cell></row><row><cell cols="2">AGMG 2.3 5.0</cell><cell>6.3</cell><cell>6.9</cell><cell>11.0</cell><cell>10.8</cell><cell>10.6</cell><cell>10.9</cell><cell cols="2">10.6</cell><cell>10.9</cell></row><row><cell>AggGar</cell><cell>7.3</cell><cell>9.1</cell><cell>10.1</cell><cell>15.5</cell><cell>17.4</cell><cell>14.9</cell><cell>17.4</cell><cell cols="2">14.7</cell><cell>17.3</cell></row><row><cell cols="2">AGMGar 3.5</cell><cell>4.3</cell><cell>5.0</cell><cell>8.5</cell><cell>7.4</cell><cell>7.1</cell><cell>7.5</cell><cell cols="2">8.4</cell><cell>7.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Gi∪Gj and M Gi∪Gj , where G i and G j are two disjoint sets, and where μ({i, j}) is defined as in the further pairwise aggregation algorithm, with s i = -k∈Gi l / ∈Gi a kl , s j = -k∈Gj l / ∈Gj a kl , and A = P T AP and with P satisfying (3.2) with respect to G i , G j .LetA {i,j} = a iis ia ij a ij a ji a jjs ja ji , M {i,j} = a ii + s i + a ij a ij a ji a jj + s j + a ij , Gi∪Gj = P f 1 {i,j}, the inequality (B.1) follows from</figDesc><table><row><cell>and</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>P f =</cell><cell cols="2">1 Gi</cell><cell>1 Gj</cell><cell>.</cell></row><row><cell>One has, as shown below,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(B.2)</cell><cell cols="2">A {i,j} = P f</cell><cell cols="2">T A Gi∪Gj P f ,</cell></row><row><cell>(B.3)</cell><cell cols="2">M {i,j} = P f</cell><cell cols="2">T M Gi∪Gj P f .</cell></row><row><cell>Noting that 1</cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p><p><p>B.</p>Here, we prove that</p>(B.1) μ(G i ∪ G j ) ≥ μ({i, j}) ,</p>where μ(•) is defined as in Theorem 3.2 with respect to A</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>and the definition of s i ,( A {i,j} ) 11 = a iis ia ij A| Gi∪Gj P f ) 11 -(P T f Σ Gi∪Gj P f ) 11 .Similarly, for the off-diagonal element,( A {i,j} ) 12 = a ij = k∈Gi l∈Gj a kl = (P T f A| Gi∪Gj P f ) 12 .</figDesc><table><row><cell>=</cell><cell>a kl +</cell><cell>a kl -</cell><cell>a kl</cell></row><row><cell>k∈Gi l∈Gi</cell><cell>k∈Gi l / ∈Gi</cell><cell>k∈Gi l∈Gj</cell><cell></cell></row><row><cell>=</cell><cell>a kl -</cell><cell>|a kl |</cell><cell></cell></row><row><cell>k∈Gi l∈Gi</cell><cell cols="2">k∈Gi l / ∈Gi∪Gj</cell><cell></cell></row><row><cell>= (P T f</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>This latter approach has its own convergence theory<ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b7">8]</ref>, which, however, has little in common with the one developed in this paper; see section</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>for further comments.<ref type="bibr" target="#b1">2</ref> For this type of methods, it is related to the convergence factor ρ via the relation ρ = 1 -1/κ. Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Strictly speaking, it is assumed in<ref type="bibr" target="#b16">[17]</ref> that the prolongation matrix has exactly one nonzero per row, whereas we allow some zero rows; the extension of the proof is, however, straightforward since the "exactly one nonzero" property is used only for further results related to irreducibility, which are not needed here. Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This author's research was supported by the Belgian FNRS ("Aspirant"). The work on the revised version of the manuscript was supported by Director, Office of Science, Office of Advanced Scientific Computing Research of the U.S. Department of Energy under contract DE-AC02-05CH11231. , homepages.ulb.ac.be/∼ynotay). This author's research was supported by the Belgian FNRS ("Directeur de recherches").</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>complexity is actually smaller for all other test problems, except 3D problems on an unstructured grid, for which it is at worst 50% larger. The resulting condition number is also at most twice that for Mod2D, and in fact remains in all cases smaller than half of the guaranteed bound (2.2). Along the same lines, the number of iterations ranges between half of and 25% more than that needed to solve the reference model problem.</p><p>Eventually, the total time per unknown is in all cases within a modest factor of that of the Mod2D problem-a factor which most often is related to a larger number of nonzero entries per row in the matrix. Note also that this stability in performance holds for both structured and unstructured grid problems, despite the fact that our aggregation algorithm mimics well a "geometric" aggregation algorithm in the structure case but may work quite differently in the unstructured one (compare Figures <ref type="figure">4</ref> and<ref type="figure">8</ref>).</p><p>Eventually, we compare the method presented here with different versions of aggregation-based AMG, and also, when feasible, with the sparse direct solver available in MATLAB via the "\" command. The total solution time (including setup) is reported in Table <ref type="table">4</ref> for a representative sample of our test examples. AggGar stands for the method described in the present paper, and AGMG 2.3 is the 2.3 version of the AGMG software <ref type="bibr" target="#b20">[21]</ref>, which implements the heuristic method from <ref type="bibr" target="#b21">[22]</ref>. On the other hand AGMGar uses our new aggregation algorithm but defines the other ingredients essentially as in <ref type="bibr" target="#b21">[22]</ref>; that is, the coarsening is obtained using Algorithm 5.3 with threshold κTG = 8 , maximal number of passes n pass = 2, and target coarsening factor τ = 4 , and this is combined with the Gauss-Seidel smoother and the K-cycle (i.e., the coarse system is solved at each level with two conjugate gradient iterations). Downloaded 11/25/14 to 18.101.24.154. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bischof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Blackford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dongarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Croz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Greenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hammarling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mckenney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sorensen</surname></persName>
		</author>
		<title level="m">LAPACK Users&apos; Guide</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>rd ed., SIAM</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Algebraic multilevel preconditioning methods. I</title>
		<author>
			<persName><forename type="first">O</forename><surname>Axelsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Vassilevski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Math</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="157" to="177" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Algebraic multilevel preconditioning methods, II</title>
		<author>
			<persName><forename type="first">O</forename><surname>Axelsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Vassilevski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Numer. Anal</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1569" to="1590" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Towards algebraic multigrid for elliptic problems of second order</title>
		<author>
			<persName><forename type="first">D</forename><surname>Braess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="379" to="393" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Algebraic multigrid (AMG) for sparse matrix equations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Mccormick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Ruge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sparsity and Its Applications</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Evans</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="257" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Algebraic multigrid based on element interpolation (AMGe)</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brezina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Cleary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Falgout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">E</forename><surname>Henson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Manteuffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Mccormick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Ruge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1570" to="1592" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adaptive smoothed aggregation (αSA) multigrid</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brezina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Falgout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maclachlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Manteuffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccormick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ruge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="317" to="346" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An improved convergence analysis of smoothed aggregation algebraic multigrid</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brezina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vaněk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Vassilevski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Linear Algebra Appl</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multi-level iterative technique and aggregation concept with semi-analytical preconditioning for solving boundary value problems</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">E</forename><surname>Bulgakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. Numer. Methods Engrg</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="649" to="657" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<author>
			<persName><forename type="first">T</forename><surname>Chartier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Falgout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">E</forename><surname>Henson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Manteuffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccormick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ruge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Vassilevski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spectral AMGe (ρAMGe)</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Reducing the bandwidth of sparse symmetric matrices</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cuthill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mckee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th National Conference of the Association for Computing Machinery</title>
		<meeting>the 24th National Conference of the Association for Computing Machinery<address><addrLine>NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Brandon Press</publisher>
			<date type="published" when="1969">1969</date>
			<biblScope unit="page" from="157" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Performance of parallel AMG-preconditioners in CFD-codes for weakly compressible flows</title>
		<author>
			<persName><forename type="first">M</forename><surname>Emans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parallel Comput</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="326" to="338" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On generalizing the algebraic multigrid framework</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Falgout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Vassilevski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Numer. Anal</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1669" to="1693" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Redistribution subject to SIAM license or copyright</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hackbusch</surname></persName>
		</author>
		<idno>11/25/14 to 18.101.24.154</idno>
		<ptr target="http://www.siam.org/journals/ojsa.php" />
	</analytic>
	<monogr>
		<title level="m">Multi-grid Methods and Applications</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Element-free AMGe: General algorithms for computing interpolation weights in AMG</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">E</forename><surname>Henson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Vassilevski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="629" to="650" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">AMGe based on element agglomeration</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Vassilevski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="109" to="133" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A multigrid method based on graph matching for convectiondiffusion equations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zikatanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Linear Algebra Appl</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="181" to="195" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Energy optimization of algebraic multigrid bases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mandel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brezina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vaněk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="205" to="228" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Analysis of aggregation-based multigrid</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Notay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1082" to="1103" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Algebraic analysis of aggregation-based multigrid</title>
		<author>
			<persName><forename type="first">A</forename><surname>Napov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Notay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Linear Algebra Appl</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="539" to="564" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Notay</surname></persName>
		</author>
		<ptr target="http://homepages.ulb.ac.be/∼ynotay/AGMG" />
		<title level="m">AGMG, software and documentation</title>
		<imprint>
			<date type="published" when="2011-07-25">25 July 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An aggregation-based algebraic multigrid method</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Notay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electron. Trans. Numer. Anal</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="123" to="146" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Aggregation-based Algebraic Multigrid for Convection-Diffusion Equations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Notay</surname></persName>
		</author>
		<idno>GANMN 11-01</idno>
		<ptr target="http://homepages.ulb.ac.be/∼ynotay" />
		<imprint>
			<date type="published" when="2011">2011</date>
			<pubPlace>Brussels, Belgium</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Université Libre de Bruxelles</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Recursive Krylov-based multigrid cycles</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Notay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Vassilevski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Linear Algebra Appl</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="473" to="487" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Algebraic multigrid</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Ruge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stüben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multigrid Methods, Frontiers Appl. Math</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Mccormick</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ed</forename><surname>Siam</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Philadelphia</forename></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="73" to="130" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">An introduction to algebraic multigrid</title>
		<author>
			<persName><forename type="first">K</forename><surname>Stüben</surname></persName>
		</author>
		<editor>Multigrid</editor>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Academic Press</publisher>
			<biblScope unit="page" from="413" to="532" />
			<pubPlace>San Diego, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">U</forename><surname>Trottenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Oosterlee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schüller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Multigrid</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Academic Press</publisher>
			<pubPlace>San Diego, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Convergence of algebraic multigrid based on smoothed aggregation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vaněk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brezina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mandel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Math</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="559" to="579" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Algebraic multigrid based on smoothed aggregation for second and fourth order elliptic problems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vaněk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mandel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brezina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="179" to="196" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Hybrid V-cycle algebraic multilevel preconditioners</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Vassilevski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Comp</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="489" to="512" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Multilevel Block Factorization Preconditioners</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Vassilevski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">General constrained energy minimization interpolation mappings for AMG</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Vassilevski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multiple vector preserving interpolation mappings in algebraic multigrid</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Vassilevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Zikatanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Matrix Anal. Appl</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1040" to="1055" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">AMGe-Coarsening strategies and application to the Oseen equations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wabro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2077" to="2097" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On an energy minimizing basis for algebraic multigrid methods</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zikatanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="121" to="127" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Redistribution subject to SIAM license or copyright</title>
		<idno>Downloaded 11/25/14 to 18.101.24.154</idno>
		<ptr target="http://www.siam.org/journals/ojsa.php" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
