<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PLANet: An Active Internetwork</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Michael</forename><surname>Hicks</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Moore</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">D</forename><surname>Scott</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexander</forename><surname>Carl</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">A</forename><surname>Gunter</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Scott</forename><forename type="middle">M</forename><surname>Nettles</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PLANet: An Active Internetwork</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C9C2CAC471DF8EF15FD3170A498F4EA5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present PLANet: an active network architecture and implementation. In addition to a standard suite of Internet-like services, PLANet has two key programmability features: 1. all packets contain programs 2. router functionality may be extended dynamically Packet programs are written in our special purpose programming language PLAN, the Packet Language for Active Networks, while dynamic router extensions are written in OCaml, a dialect of ML.</p><p>Currently, PLANet routers run as byte-code-interpreted Linux userspace applications, and support Ethernet and IP as link layers. PLANet achieves respectable performance on standard networking operations: on 300 MHz Pentium-II's attached to 100 Mbps Ethernet, PLANet can route 48 Mbps and switch over 5000 packets per second. We demonstrate the utility of PLANet's activeness by showing experimentally how it can nontrivially improve application and aggregate network performance in congested conditions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The applications that the Internet must support and the underlying network technologies that it uses to support them are evolving rapidly. Regrettably, the Internet itself is hard to change. Coupled with the desire of application and network programmers to customize the network to match their special needs, this evolutionary rigidity motivates research into programmable and extensible, or active, networks.</p><p>Exploring and justifying this change in network architecture requires understanding the advantages, disadvantages, and tradeoffs of the new approach. A number of questions arise. First, how does one build such a network and what programming abstractions should it provide? Secondly, will the added flexibility inherent in the network compromise its performance and safety? Finally, how can applications and service providers benefit from the network's expanded capabilities? In this paper we address these questions experimentally using a new internetwork, PLANet.</p><p>PLANet is indeed an internetwork: it implements network layer services directly on top of link layer technologieswithout relying on the existing IP <ref type="bibr" target="#b0">[1]</ref> infrastructure. PLANet is also 'purely active': all packets contain programs written in a special-purpose packet language called PLAN (Packet Language for Active Networks) <ref type="bibr" target="#b1">[2]</ref>, and nodes may be extended by dynamically loading additional code to change functionality <ref type="bibr" target="#b2">[3]</ref>. PLANet is the first such purely active internetwork.</p><p>Let us consider the two ways in which PLANet is active. Firstly, PLANet uses active packets which contain PLAN programs, as mentioned above. These programs serve a role similar to the header of a traditional packet in providing control of how packets operate inside the network. For simplicity and higher This work was supported by DARPA under Contract #N66001-96-C-852.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Routing Extension PLAN interpreter PLAN program(s)</head><p>Active Packets</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Link layer</head><p>Active Extensions Ethernet IP Fig. <ref type="figure">1</ref>. PLANet node architecture performance, a PLAN packet may choose to rely on 'passive' transport and thus need not be evaluated at every intermediate node. PLAN programs are typically small and serve as glue for router-resident service routines that provide general-purpose functionality not expressible in PLAN alone. Such service routines may provide simple information such as the address of the current host, or more substantial functionality, such as segmentation and reassembly.</p><p>Secondly, PLANet nodes may be programmed by dynamically loading active extensions written in OCaml <ref type="bibr" target="#b3">[4]</ref>, a dialect of the ML programming language. These extensions add to or enhance existing functionality, and may provide services available to PLAN programs. Active extensions are used to program essential services needed to operate the network, like address resolution, routing, DNS, etc. while PLAN programs are used as a means of 'smart' communication between nodes. This node architecture is visualized in Fig. <ref type="figure">1</ref>. First, a packet arrives through the link layer interface. If the program has reached its evaluation destination, it is passed to the PLAN interpreter to be evaluated; otherwise, it is simply routed onwards. During evaluation, PLAN programs may make service calls, including the service that sends PLAN programs to other nodes to be evaluated.</p><p>These design decisions flexibly position PLANet along two design-space axes that are important for active networking. The first axis spans possible mechanisms for activeness-from programmability at the packet level to extensibility at the node level. PLANet uses a mixture of these approaches in which packets carry programs that may refer to and invoke more general (and loadable) node-resident functionality. The second axis spans possible locations for active evaluation-from endpointsonly (like the Internet) to every-hop. Again, PLANet adopts a more flexible position that allows evaluation at some of the intermediate hops. Other active networking projects have only explored specific points on these axes (we defer a discussion of this related work until Section VI).</p><p>In measuring the performance of PLANet, we examined the costs of common, non-active network operations: we present both latency and bandwidth measurements for 'inactive' packets (whose only program is to deliver a payload) and compare the results to those of a kernel-based IP implementation. These measurements place an upper-bound on the overhead of using our active network architecture/implementation as compared to a nonactive one. We also demonstrate the possible gains from using our active network. While it is impossible to measure the benefit of an active network in a strictly quantitative manner, we are able to show that programmability can yield potential performance gains for problems which are not likely to have a single best-fit solution.</p><p>The paper is conceptually divided into three parts, each answering one of the questions posed earlier. The first part, in Sections II-III, describes the design and implementation of PLANet and the motivation behind the abstractions we provide. The second part, in Section IV, presents the basic performance of PLANet in comparison to a kernel-based IP implementation. The final part, in Section V, describes some useful applications of PLANet and presents some measurements of expected benefits. We conclude with related work in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PLAN</head><p>Much of the design of PLANet is based upon the language of its packets, the Packet Language for Active Networks, or PLAN. Here we highlight the salient features of the PLAN language, but we refer the reader to <ref type="bibr" target="#b1">[2]</ref> for more details. PLAN is a small language that has elements in common with Haskell <ref type="bibr" target="#b4">[5]</ref>, Scheme <ref type="bibr" target="#b5">[6]</ref>, and ML <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b3">[4]</ref>. It differs most importantly from these in that it includes primitives for evaluating an expression at a remote node; invoking such a primitive will result in a newly spawned packet. Another special characteristic of PLAN is a resource-limited semantics that ensures that PLAN programs always terminate and that packets and their descendents visit only a fixed number of nodes.</p><p>PLAN was designed to be flexible enough to write useful programs, but limited enough that its programs will not pose a security risk. By contrast, the service routines available to PLAN programs are general-purpose and may need to be protected by cryptography or other means. (Here our coverage of security issues is limited due to space considerations. For more details, we refer the reader to <ref type="bibr" target="#b7">[8]</ref> and <ref type="bibr" target="#b8">[9]</ref>.) Some functions we have implemented as PLAN programs include 'route scouting' which seeks out low-congestion routing paths (as described in Section V), source-directed multicast, traceroute, and network-DFS, to name a few. More details about programming with PLAN may be found in <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PLANET</head><p>PLANet is our active internetwork implementation based on the PLAN environment. Whenever possible, we have drawn from the experience of IP <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b10">[11]</ref> in making implementation decisions, so as to leverage the experience represented by that design. Practical experience with the Internet indicate that the following core elements are required of an internetwork: uniform, network-layer addressing and packet formats address resolution from link-layer to network-layer addresses routing between physical networks error reporting These elements form a core part of PLAN itself: with the exception of address resolution, each is visible as an abstraction in the language. We have also adopted from the Internet the idea that remote evaluation is best-effort; reliable delivery may be achieved with the addition of appropriate services.</p><p>Beyond these core elements, we have implemented other services that have counterparts in the Internet. These services do not require standardization and so are not part of PLAN but are part of the loadable service routines available to PLAN programs. These include a domain-name service, a fragmentation and/or segmentation service, reliable stream transport, and network management, among others. Indeed, it is the flexibility of being able to augment active nodes with such 'nonstandard' services that makes the prospect of active networks appealing. For instance, as we mentioned before, a standard routing scheme is not strictly needed since different packets may choose different schemes; we experiment with this idea in Section V. Of course, some routing functions are needed, and routing functions of interest must be widely deployed if they are to be widely useful. Our approach has been to supply a collection of basic network functions as PLAN programs or router-resident service routines; packets do not need to use the ones that we provide because new ones can be installed, but some basic ones will be available.</p><p>The following three subsections expand on our implementation of the core internetworking elements in PLANet as defined above. We begin with a discussion of our packet formats and addressing scheme, followed by our routing methodology, finishing up with a discussion on error handling and diagnostics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Packet Formats</head><p>To allow interoperation between diverse physical networks, an internetwork must define a set of standard packet formats. In PLANet all packets consist of PLAN programs, so this standardization reduces to defining a standard marshalling scheme for PLAN programs. This greatly simplifies the task of the implementor of a new network service, who only needs to be concerned with what information needs to be communicated, not with how that information is encoded.</p><p>The experience with the Internet has been that most packets only require basic transport. We expect this will be true for PLANet as well, and so we make the assumption that most PLAN packets will require routing but not evaluation. Therefore, we have placed the information necessary for routing in a standard position to improve routing efficiency. An extreme view of active networks might allow packets to have only as much formatting as required to unmarshal a program for evaluation, preventing such routing optimizations. While more flexible, we feel that the cost in performance of this approach is too high.</p><p>The PLAN packet format is illustrated in Fig. <ref type="figure">2</ref>  below. We begin by discussing PLANet addresses, followed by an explanation of the 'code' section of the packet (referred to as a chunk), and finally a summary of the remaining fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Addressing</head><p>The first two fields of the packet indicate the evaluation destination (evalDest for short), which is where the packet's program should be evaluated, and the source, which names the packet's oldest ancestor, used for error reporting.</p><p>Currently, PLANet uses 48 bit addresses, assigning one address for each network interface on a node. In our implementation we typically use the assigned IP address for the interface together with a 16 bit port number. This choice makes it easy for us to use UDP/IP as a 'link layer' to create tunnels between physically separated PLANets.</p><p>As in any internetwork, we must resolve network layer addresses into link layer ones for physical transport. PLANet adopts the same basic technique as ARP <ref type="bibr" target="#b11">[12]</ref>. The key difference is that in PLANet ARP requests and responses are not special kinds of packets, but rather PLAN programs. Most simply, we did this to maintain the invariant that all packets in PLANet contain PLAN programs. This obviates the need for specialpurpose ARP processing; it can be a service routine like any other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Programs as Data</head><p>The last three fields in the packet comprise the chunk (short for 'code hunk'), which is essentially its program: marshalled code, a function entry point, and initial arguments. The arguments are PLAN values that have standard marshalling formats; a PLAN programmer need not be concerned with representation issues. When a PLAN packet reaches its evalDest, its code is unmarshalled, and the appropriate function is located and called with the given values.</p><p>While requiring all packets in the network to be marshalled PLAN programs simplifies the question of packet formatting, there is a complication: what if the size of a marshalled chunk exceeds the path MTU? We address this within PLAN by allowing chunks to be manipulated as data. Notably, chunks may carry other chunks as data, providing an elegant encapsulation mechanism. Furthermore, with appropriate service routines, chunks can be fragmented, transported, reassembled, and then evaluated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Remaining Fields</head><p>Let us skim through the remaining packet fields; the crucial ones are more fully explained later in the paper. The third field of the packet is a resource bound rb similar to the IPv4 Time-To-Live field or the IPv6 hop count field. The session field provides an identifier for the end application on a host (similar to the protocol field in IP), while the flowId field provides an identifier for a packet flow through a router. The roles of these fields will be illustrated in the QoS routing example in Section V. In order to evaluate its chunk at evalDest the packet must potentially be routed, so the routFun field supplies the name of the routing function to do this. The handler field provides the name of a service routine on the source that will handle certain error communications the router may choose to offer. Error reporting is described in more detail in Section III-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Routing</head><p>To determine the 'next hop' of a PLAN packet, an intermediate node evaluates the packet's specified routFun, which names a service routine that is resident on the intermediate node. We chose this approach as a means to explore the space between two extremes. At one extreme, we might require that all legal evaluation destinations be located on the same network as the sender; to reach distant networks packets would evaluate on each hop towards that network to determine what the next hop should be. While this approach affords the maximum flexibility, it is also the most costly, both in terms of performance and programmer convenience. At the other extreme, we might implement a single routing protocol for all nodes in the network (or at least autonomous portions of it) and force all packets to be routed based on its determinations. This approach suffers from the same problem as the first: while 'dumb' packets are efficiently routed, packets wishing to follow non-standard routes must pay the penalty of per-hop evaluation. The per-packet rout-Fun serves as an alternative that does not favor one particular routing strategy over another but is still 'lightweight': it looks up the next hop without requiring the packet to be unmarshalled and/or evaluated. The only additional cost is the lookup of the routing function itself.</p><p>Most packets specify the defaultRoute routing function, which in PLANet is implemented with a simple distance vector routing service based closely on RIP <ref type="bibr" target="#b12">[13]</ref>. On the other hand, more savvy applications may make use of customized routing functions, as illustrated in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Diagnostics and Error Handling</head><p>Network errors typically fall into two categories, packet-level errors and network-level errors. Packet-level errors occur when a particular packet fails to properly reach its destination, perhaps because that destination is unreachable or the TTL of the packet has been exhausted. Packet-level errors are often symptomatic of network-level anomalies: a circularity in the routing table causes packets' TTL fields to expire or a failed node causes a destination to become unreachable. In a well-designed network, applications should be able to handle packet-level errors, and network administrators should be able to diagnose networklevel errors.</p><p>In the Internet, low-level diagnostics and errors are reported with ICMP <ref type="bibr" target="#b13">[14]</ref>. The fundamental difficulty is that only a fixed set of errors or diagnostics can be reported until a restandardization defines new ones. This limits the vocabulary of an application/operating system in dealing with errors or a network administrator in making use of diagnostics.</p><p>In PLANet, diagnostics such as ping or traceroute are simply PLAN programs, so new diagnostics can be crafted as needed. Typically, diagnostic programs will derive information about a node (such as reachability) or query it directly (perhaps to find the current packet queue length). If a service routine to provide some required information is not available, then active extensions can be downloaded to provide it, subject, of course, to security considerations. This provides significant new flexibility in diagnosing network problems, since diagnostics can be created on-the-fly.</p><p>The means by which packet-level errors may be handled is greatly enriched in PLAN, since the level of abstraction has been raised to the program-level as opposed to packet-level. Errors that arise during program evaluation may be handled directly by the program, while errors occurring en route may be handled at the source by the service routine named in the packet's handler field. This ability to flexibly handle and diagnose errors will become increasingly important as the Internet becomes more widespread and harder to change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Implementation Details</head><p>PLANet is implemented in OCaml v2.00 <ref type="bibr" target="#b3">[4]</ref> in user space under the Linux kernel version 2.0.30. Our implementation is in part based on the Active Loader, described in <ref type="bibr" target="#b2">[3]</ref>. The choice of implementing in user-space was largely motivated by expediency, and we have efforts ongoing to integrate PLANet into the kernel of various operating systems.</p><p>Our choice of OCaml is motivated by several concerns. OCaml is a type-safe, garbage-collected language. These features are exploited to provide for safe mobile code, an issue that will become even more important if we attempt to move PLANet into the kernel to improve performance. The implementation of OCaml also provides for machine-independent and downloadable code, which we need for dynamically loading active extensions. OCaml has been used like Java to provide for secure, web-based mobile code <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>. In addition, its source code is freely available, making it convenient for us to make the necessary modifications to provide direct access to our networking hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. PLANET PERFORMANCE</head><p>This section addresses the second question posed in the introduction: can an active network attain reasonable performance, especially for common operations? Our analysis leads us to believe that given the prototype nature of our implementation, PLANet's performance is quite respectable-within a factor of two of the optimal link bandwidth. Future work will involve attempting to reduce our overheads, but even our current numbers suggest that an active network need not be a slow one.</p><p>We begin by describing our basic experimental setup and the statistical issues of our measurements. We then present measurements of both the latencies to send PLANet packets and the bandwidth that PLANet achieves. We finish by looking at some of the aspects of the PLANet implementation that influence its performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Benchmarks and Systems Measured</head><p>For both latency and bandwidth we compared IP running over Ethernet (IP) to PLANet running over Ethernet (PLAN/Ether). In order to assess certain overheads (such as forwarding costs) we additionally measured PLANet running over IP (PLAN/IP). When referring to either or both of the two PLAN implementations, we shall simply use the term PLANet.</p><p>We made measurements of machines that were directly connected (one hop), as well as communicating through one, two, or three switching elements (two, three, or four hops). For IP, switching is performed by an in-kernel router, while PLAN/Ether and PLAN/IP are switched by our PLANet router running in user-space.</p><p>For each experiment we used four packet sizes: the minimum size feasible given any overheads (i.e. a 0 byte payload), and ones resulting in 342, 750, and 1500 byte Ethernet payloads. The 342 byte size is the smallest Ethernet payload that can support all of our experiments.</p><p>In order to determine upper bounds on the possible routing performance in user-space we wrote two bridge programs, one in C and one in OCaml. The C bridge uses the recv system call to read packets from the raw Ethernet interface. It then uses a fixed (two entry) table to find the outgoing interface and does a send out that interface. The C bridge does no copying, except that necessary for the two kernel crossings. The OCaml version of the bridge works in the same way, but has the additional overhead of interpreting OCaml bytecodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Conditions</head><p>For the experiments in this section, all the machines used were 300 MHz Pentium-II's with split first level caches for instruction and data, each of which is 16 KB, 4-way set associative, write-back, and with pseudo LRU replacement. The second level cache is a unified 512 KB and operates at 150 MHz (we were unable to find any additional details about the second level cache). These machines receive a rating of 11.7 on SPECint95 and have 256 MBs of EDO memory. The machines used as the source and destination for the experiments in Section V are the same, but only have 64 MBs of EDO memory. In all cases the machines have enough memory that they do not page fault. For Section V, we also use two 200 MHz Pentium-Pro's which have enough computing power to saturate the network when running as load generators.</p><p>All machines are equipped with enough 100 Mbps Ethernet interfaces to construct the required topologies. For the bandwidth and latency measurements presented in this section, we simply connect the machines linearly. Section V uses a more complicated topology which we will describe there.</p><p>Our latency results are based on repeated measurements of individual "pings", while our bandwidth measurements are based on measuring the transmission time for 5000 packets. In all cases we collect 21 trials and compute the mean, median, standard deviation, and quartiles. For all presented measurements, the standard deviation and is less than 5% of the mean, but we do observe somewhat skewed distributions. For this reason, as recommended by Jain <ref type="bibr" target="#b16">[17]</ref>, we report medians, since they are less sensitive to influence by skewed distributions. Quartiles are not presented on the graphs to enhance readability. All times reported are elapsed times, and are measured with a clock having a 4 s resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Latency Measurements</head><p>We measured the latency of both PLANet and IP as a function of the number of network hops and the payload size. For IP, we used the standard ICMP-based ping program (ping/IP). For PLANet, we used two PLAN versions of ping: the one presented in the earlier example which evaluates once on the destination and once back on the source (ping/noeval), and another version that evaluates on every hop, determining its route as it goes (ping/eval). With these tests we can determine the basic latencies of PLANet, compare those to IP, and evaluate the cost of packet evaluation per-hop.</p><p>Fig. <ref type="figure" target="#fig_0">3</ref> shows the switching latency for ping/noeval. The Xaxis shows the number of hops while the Y-axis shows the round-trip latency in milliseconds. Only minimum packet sizes are shown here. In addition to showing measurements for IP, PLAN/Ether, and PLAN/IP, we show IP being switched by both the C-bridge and the OCaml-bridge.</p><p>In the following discussion, we consider the overhead due to kernel crossings, look at the node switching costs, and finally consider the overhead imposed by per-hop evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Kernel crossing overheads</head><p>Comparing minimally-sized packets over one hop, IP ping has a latency of 0.16 ms, while PLAN/Ether ping has a latency of 1.6 ms. The majority of this cost comes from the PLAN evaluation on the endpoints; this is analyzed in more detail later. The next sizeable portion of this difference can be attributed to kernel crossings. IP ping only requires two system calls, both on the source: once to send the packet, and once to receive the response. PLANet ping is implemented as a host application which communicates with the PLAN interpreter via PLAN ports <ref type="foot" target="#foot_0">1</ref> . Since both the PLAN ping application and the local PLAN interpreter are in user space, two crossings are needed to hand the packet to the interpreter (one send by the application, and one recv by the interpreter) followed by a third when the interpreter puts the packet on the wire. The packet then must cross the kernel boundary twice on the destination (there and back), and finally do three more crossings to go through the source interpreter and back into the ping application. This results in a total of 8 crossings, 6 of which could be eliminated with an in-kernel implementation. Each additional hop imposes 4 more crossings (2 per switch per direction) for both the PLAN router and the bridges, while IP is switched in-kernel. We estimate the cost of these crossings later in the discussion to be about 35 s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Switching costs</head><p>We were interested in the detailed per-packet and per-byte switching overheads. To calculate these costs, we first made a linear least squares fit to each of our constant Ethernet packet size measurements using hops as the independent variable. The slope of these lines is the cost per hop (and remember each hop is traversed twice) for a given switching mechanism and size. Next, to find the fixed cost per packet and the cost per byte of each switching mechanism, we used the packet size as the independent variable and the cost per hop as the dependent variable. This gave us three different estimates of these values for the bridges (IP, PLAN/Ether, and PLAN/IP), and two estimates each for the IP (IP and PLAN/IP) and PLAN (PLAN/Ether, and PLAN/IP) routers.</p><p>Table <ref type="table">I</ref> shows the (averaged) results of our calculations, for the IP router (IP), the C bridge (C), the OCaml bridge (OCaml), and the PLAN router (PLAN). We have divided the per-hop calculations by 2, so these values are for one pass through the switch. The lack of kernel crossings for the IP router makes it unsurprising that this system has lowest per-byte costs. Since  the two bridges and the PLAN router do no copying internally, and make the same system calls, it is to be expected that all have (essentially) the same per-byte cost. The most striking differences were in the per-packet overheads. It would appear that the C bridge added about 35 s to the latency over IP-an indicator of the cost of a single crossing of the user/kernel boundary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of Hops</head><p>There is an additional 60 s penalty for going to the OCamlbridge and a further 130 s penalty (a doubling) when going through the PLANet implementation. Therefore Amdahl's law indicates that PLANet will require more optimization before moving it into the kernel will have a significant impact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Ping with intermediate evaluation</head><p>We also wanted to find out the overhead of PLAN program evaluation. Fig. <ref type="figure">4</ref> compares the latencies of ping/eval and ping/noeval. It shows only the maximum and minimum packet size measurements for PLAN/Ether.</p><p>From the figure it is obvious that evaluation in this case is expensive, with the added cost per hop for the smallest packets being almost 2.5 ms. Also note that ping/eval has additional code space overhead: 314 bytes per packet as opposed to 153 bytes for ping/noeval. For a fixed Ethernet packet size<ref type="foot" target="#foot_1">2</ref> , many of the overheads, such as kernel crossings, are the same for both approaches. However, at each hop, the evaluating version must unmarshal its code, evaluate it, and then remarshal the version to be sent on to the next hop. A more sophisticated implementa- Using the same statistical techniques as before, we found that ping/eval has a fixed cost of about 1400 s and a per-byte cost of about 0.19 s for each traversal of the router. Ping/noeval has fixed cost of 260 s and per-byte cost of 0.16 s. The difference suggests that the fixed cost of (this particular) evaluation is about 1200 s and the per-byte cost is 0.04 s (using unrounded original values). This is clear evidence that avoiding evaluation on intermediate routers can have important performance advantages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Throughput Measurements</head><p>We also measured bandwidth as a function of hops and payload size. We used UDP packets to provide transport for IP, while for PLANet we used simple PLAN programs providing UDP-like functionality; these programs only evaluate at the endpoint to deliver their data.</p><p>For our IP measurements, we use ttcp, while for PLANet we wrote our own measurement functions. One way our PLANet results differ from IP is that for PLANet we adjusted the rate of the sender until the packet loss at the receiver was consistently less than 1%. This results in lowering our peak transmission number by a few megabits per second, but we believe it better represents the load that PLANet can reasonably support. Unfortunately, ttcp did not allow us to make the same adjustment. Our reported bandwidths are in terms of useful payload received.</p><p>Fig. <ref type="figure" target="#fig_2">5</ref> shows the results for a subset of our bandwidth measurements for maximally sized packets. For UDP, we present measurements for both IP routing and switching with the OCaml bridge; the C bridge has the same performance as the IP router. For PLANet, we show both PLAN/Ether and PLAN/IP. For this experiment, we additionally considered the case in which PLANet routers are compiled to native code. This allows us further understand the additional overhead due to interpretation. Due to time constraints and implementation difficulties, we are unable provide further native code measurements or evaluation beyond what is presented in this subsection.</p><p>For one hop with 1500 byte Ethernet payloads, PLAN/Ether achieves a rate of 56.0 Mbps which is 60% of the maximum possible 93.4 Mbps bandwidth possible for the 1437 bytes of useful payload. In this case, the receiver is the bottleneck; we measured the maximum send bandwidth to be the peak bandwidth. Adding PLAN routers for two through four hops reduces our throughput to 48.3 Mbps or 52% of the peak possible bandwidth. Here, the router is the bottleneck. We did a linear regression on the bandwidths from 2 to 4 hops and found that each additional router reduces our bandwidth by 0.8 Mbps. Though we have no concrete explanation for this drop in bandwidth per-hop, we suspect it is due to compounding loss rates at each router. These loss rates are likely exacerbated by being resident in user space (since we have no direct control over kernel socket buffers), and to jitter from OCaml's thread scheduler. For PLAN/Ether with PLAN routers, for minimum sized packets, (which carry no payload and thus get no bandwidth by our previous metric), we can transmit 7200 packets per second over one hop, and 5100 packets per second over two. For maximum size packets, one hop can process 4900 packets per second, while the two hop case nets 4200 packets per second.</p><p>When compiled to native code, PLAN/Ether achieves the full link rate of 93.4 Mbps for one hop (a 66.8% improvement over bytecodes), while switching at about 59.7 Mbps (a 23.6% improvement). When the OCaml bridge is compiled to native code (not shown), it is able to switch at the link rate. These measurements further indicate that the PLANet switching path should be optimized.</p><p>UDP routing over in-kernel IP routers achieves 95.6 Mbps regardless of the number of hops. This figure is 99.9% of the 95.7 Mbps possible for the 1472 bytes of useful data in our 1500 byte Ethernet payloads, indicating that the network is the bottleneck in this case. The C bridge also achieves this maximum throughput, but the (bytecode) OCaml bridge is a bottleneck and limits performance to a little more than 80 Mbps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Performance Discussion</head><p>During the development of PLANet, we measured a number of aspects of our implementation to gain a better understanding of its performance. These measurements, and the enhancements that they motivated, resulted in increased peak bandwidth by about a factor of four. In this subsection, we present some of those measurements and the resulting improvements, as well as notes regarding future improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 Bottleneck Overheads</head><p>Typically we studied the overheads in the PLAN router, which was the main bottleneck. Based on the measured throughput, we know that for large packets the router spends about 240 s processing each packet.</p><p>One source of overhead is the need to cross the kernel boundary. The C bridge has almost no additional overhead beyond this one and can forward large packets at maximum rate. We added a delay loop to the C bridge and increased the delay until it started to act as a bottleneck. This happened when our added delay was 45 s, resulting in an overall service time of 122 s (based on observed throughput). Subtracting the added delay from the service time gives us an estimate of 77 s for the two kernel crossings; Note this is very close to the estimate of 35 s per crossing found for ping. Since the PLAN router makes exactly the same kernel calls to transport the same data (and in this test we actually bridged PLAN packets) it seems likely that this is a good estimate of the kernel crossing overhead for PLAN.</p><p>The next obvious measurement is the time the packet takes between the system calls for receiving and sending a packet. We measured this directly and found it to be in the range 135-150 s. We are studying this receive-to-send path to see how it can be optimized. While some portion of this cost is attributable to byte-code interpretation, the native code numbers in Fig. <ref type="figure" target="#fig_2">5</ref> indicate that there is still room for improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Threads, Copying, and Garbage Collection</head><p>During our efforts to improve PLANet's performance, tuning three areas had significant impact. First, we noted that calling the scheduler in OCaml's user-level threads system is expensive-as much as 100 s per scheduling event. We rewrote some of the router to avoid thread hand-offs and eliminate almost all calls to the scheduler. Secondly, we observed that our initial implementation had a number of extra copies of the packet. We eliminated these and noticed not only the decreased copying costs, but a more significant decrease in the cost of garbage collection (GC), which would occur far less frequently. Finally, this improvement in the cost of GC caused us to investigate how setting key GC parameters might influence our results. Such adjustments allowed us to eliminate almost all GC overhead. The first two improvements are ones that would probably be needed in any prototype router implementation, while tuning the collector mostly required understanding the application rather than the collector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. TWO EXPERIMENTS WITH ACTIVE INTERNETWORKING</head><p>The previous section explored performance for simple end-toend latency and bandwidth-tasks that the current Internetwork can do efficiently. However, we have not yet taken any real advantage of the fact that PLANet is an active network. This section shows how programmability can be used to create more flexible and better performing network functionality. We present one demonstration each for active extensions and active packets, both sharing the same basic scenario. The network topology is shown in Fig. <ref type="figure">6</ref>. Our protagonists are a source S and a destination D trying to maintain a certain transmission bandwidth. Using the default shortest hop-count routing, this flow F passes through routers R 1 and R 2 . However, during the transmission, a misbehaving source MS begins sending to another destination MD along path M at a much higher bandwidth. This saturates the router R 1 , degrading the throughput from S to D. We will demonstrate two techniques which S might use to recover some of the lost bandwidth: using router extensibility at the active loader level, and using programmability at the packet level. It is important to note that it is not the particular algorithms or techniques presented here that we are attempting to demonstrate; rather, it is the way in which the algorithms are deployed that is significant. It seems impossible to anticipate all future demands on networking functionality to create a single global standard-the continued evolution of the Internet attests to this fact. Instead, it seems likely that having a programmable networking infrastructure will allow a variety of approaches to solving future problems. This section serves to illustrate how the programmability features we support can be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Modification of a Queuing Strategy</head><p>Active extensions allow us to employ a strategy in which the router is enhanced dynamically to improve the performance of the network. One router alteration would be to install a fairer queue. In the default PLANet implementation, there is a single, first-come, first-served (FCFS) packet queue shared by all devices. Thus as the combined traffic generated by S and MS exceeds the switching capacity of R 1 , the switching capacity of the router will not be divided evenly between the two incoming packet flows. Rather, the generator which fills the queue more quickly will receive the majority of the bandwidth, while the more-well-behaved sender will receive proportionally less.</p><p>We constructed our demonstration as follows. S is attempting to send packets to R at a steady 15 Mbps. At some point, MS starts sending at the switching capacity, 40 Mbps<ref type="foot" target="#foot_2">3</ref> . Rather than allow S to continue at 15 Mbps and limit MS to 25 Mbps, the FCFS queuing system causes S to attain only 10 Mbps while MS achieves roughly 30 Mbps. This first two intervals of Fig. <ref type="figure">7</ref> illustrate this situation.</p><p>To more evenly share bandwidth, we dynamically alter the queuing system used by R 1 , resulting in the bandwidths de- In fact, this is exactly what S sees after the switchover (about 13 Mbps), while MS falls to about 20 Mbps. The round-robin queue is not without drawback: the maximum attainable capacity through any given interface is also limited, due to the additional overhead of servicing multiple queues, and the potentially wasted buffer space. While both S and MS operate with the round-robin queue, the total link bandwidth is reduced to 20 + 13 = 33 Mbps. In the fourth interval, when S stops sending, we see that MS increases its bandwidth to 38 Mbps, but it is not until the fifth interval, when the FCFS queue is dynamically reinstalled, that MS attains the maximum capacity of 40 Mbps.</p><p>Note that the time to actually dynamically link in the queuing code is negligible-about 30 ms in our current implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Selection of a Better Route</head><p>Let us re-examine our scenario. If we look at the topology shown in Fig. <ref type="figure">6</ref>, we see that there is an additional path G from S to D that passes through routers R 3 , R 4 , and R 5 . This path is 4 hops long and so would not be used by a simple shortesthop-count routing protocol like RIP. However, while MS is saturating R 1 , it might well be worthwhile to take a longer route to avoid congestion.</p><p>The approach we take in this demonstration is to allow the sender S to "shop around" for the route with the best available bandwidth. The bulk of the data will be carried in the same largely non-active transport packets that we used to measure bandwidth in Section IV. However, we will periodically intersperse scout packets that will explore the network searching for a better route and directing the flow of the transport packets. Each scout packet fits within a 1500 byte Ethernet frame, yet carries out some non-trivial computations. In particular, at each hop, the scout packet will send a copy of itself on each of the router's outgoing interfaces, thus fanning out over the network. Unlimited fanout is prevented by the properties of the PLAN language presented earlier in Section II; the global network resource usage is bounded by the resource bound found in the initial scout packet. All of the copies of the scout packet then take part in a distributed graph algorithm to discover the best available route. For our experiment here, we compute a rough path congestion metric based primarily on the queue length at each hop and secondarily on the total hop count.</p><p>The packets communicate with each other by leaving a small bit of state at each router which times out after half of the scouting interval. This state records the metric computed thus far, so that arriving packets which cannot better that mark can terminate their search. If a packet reaches the destination with the best metric so far, it generates a destination-unique flow ID and then steps backwards along its route. At each router on the return trip, the packet installs an entry in a flow-based routing table that maps the flow ID to the next hop. This results in routing quite similar to the VC-switching used in ATM networks <ref type="bibr" target="#b17">[18]</ref>. Finally, the packet reports the flow ID to the controlling application, which can then start sending the transport packets along the route just set up by the returning scout packet.</p><p>The results of this demonstration are shown in Fig. <ref type="figure" target="#fig_5">8</ref>. S begins transmitting to D using the default RIP routing service, simultaneously sending out the first scout packet. For the particular trial shown here, the scout packet returns in 36 ms with the same route through R 1 and R 2 . After a 5-second hysteresis to collect any other returning scout packets, the sender switches to the flow-based routing-note that the bandwidth is not noticeably interrupted. At time t = 15, we start a load generator on MS which begins sending on the link between R 1 and R 2 at 25 Mbps, and the perceived bandwidth at D drops to 12 Mbps. At time t = 30, the next scout packet goes out from S, and one of its descendants returns after 42 ms with a route through R 3 , R 4 , and R 5 which goes around the overloaded link. After the hysteresis interval (at t = 35), the sender begins using this new flow, bringing its bandwidth back up to 17 Mbps (note the small increase in perceived bandwidth at MD up to 28 Mbps).</p><p>Finally, at time t = 45, the misbehaving host stops sending, and at the next reporting interval (time t = 60), a scout packet discovers that the original route is now usable again, and the flow reverts.</p><p>This technique, which we call Flow-Based Adaptive Routing (FBAR) illustrates a key aspect of the design space of the evaluation of active packets. As we saw in Section IV, evaluation can be costly. However, the majority of packets only require "passive" transport, and this simpler service can be performed much more efficiently than evaluation. Our view is that evaluated ac- tive packets are like the spice that makes the meal taste better: too much or too little yields less appetizing fare. An overall benchmark objective for active networks would be to provide switching for most packets with performance comparable to IP routers while achieving better overall performance by selective use of evaluated packets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. RELATED WORK AND CONCLUSIONS</head><p>There are several other active networking projects under current development which are useful for contrast. The Active Network Transport System (ANTS) <ref type="bibr" target="#b18">[19]</ref> and NetScript <ref type="bibr" target="#b19">[20]</ref> rely entirely on dynamically extensible services which are invoked at every hop. The Smart Packets project <ref type="bibr" target="#b20">[21]</ref>, on the other hand, has programmable packets which evaluate only at the endpoints. Since PLANet allows programmable packets, dynamic extensions, and selective evaluation, it makes accessible a larger part of the design space than any one of these other systems by itself. The reader is referred to <ref type="bibr" target="#b21">[22]</ref> and the Active Network Program home page <ref type="bibr" target="#b22">[23]</ref> for a listing of other active network projects.</p><p>In addition, PLANet is the first purely active internetwork; there is no dependence upon the existing 'inactive' Internet for network-layer services. Other active networking projects such as ANTS and Smart Packets encapsulate their packets within TCP or UDP. Whereas such implementations are useful for simulation and application development, PLANet provides real insight into the issues that would arise in the creation of an active networking infrastructure. Some 'inactive' networking projects share implementation ideas with PLANet. The Fox project <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref> implements the TCP/IP protocol suite for Ethernet and ATM link layers using the ML programming language, in the approach of the x-kernel <ref type="bibr" target="#b25">[26]</ref>. OCaml has been used for other serious networking projects such as mobile programs for the MMM web browser <ref type="bibr" target="#b14">[15]</ref> and the Ensemble Project's <ref type="bibr" target="#b26">[27]</ref> generalization of TCP/IP to group communication. Some work has been done concerning security in Active Networks. Most notable is the SANE <ref type="bibr" target="#b7">[8]</ref> project (Secure Active Network Environment) which defines a general set of guidelines for trust relationships in an Active Network. An adaptation of this approach has been applied to PLANet <ref type="bibr" target="#b8">[9]</ref>.</p><p>PLANet is the best-performing active networking system in the literature to date. Wetherall et al. <ref type="bibr" target="#b18">[19]</ref> report a maximum packet forwarding rate for ANTS on a 167 MHz Ultrasparc over 100 Mbps Ethernet of 1680 packets per second for minimum size packets. This measurement uses a Java JIT, and represents about a 60% improvement over byte-code interpretation. For larger packets, over a slower link, Banchs et al., measure rates of 3.8 Mbps for M0 <ref type="bibr" target="#b27">[28]</ref>, and about half that rate for ANTS. Finally, Hartmann et al. <ref type="bibr" target="#b28">[29]</ref> show that by using aggressive compilation and special purpose operating systems, they can reduce the latency of ANTS by about a factor of about 3.5.</p><p>PLANet is a concrete demonstration that building highly extensible and non-trivial active networks is feasible. Performance of the prototype is good enough to believe that active networking techniques will perform acceptably. We have also demonstrated how active extensions and active packets can be used to provide interesting active services. Papers about PLAN and PLANet and our freely available code distribution may be found at http://www.cis.upenn.edu/switchware/PLAN.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Latencies for Switching Alternatives</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Fig. 4. Evaluation Overheads</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Bandwidth versus Number of Hops</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Fig. 6. Experimental Topology</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Fig. 7. Dynamic Queue Modification</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Flow-Based Adaptive Routing</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>PLAN ports are a means of communication between the local interpreter and an application, implemented by Unix domain sockets. See<ref type="bibr" target="#b1">[2]</ref> for more details.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Note the graph shows usable payload sizes; 1186 bytes for ping/eval and 1347 bytes for ping/noeval both result in the same size Ethernet frame.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>This number is lower than the</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="48" xml:id="foot_3"><p>Mbps earlier reported due to the additional overhead of using the active loader.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Internet protocol</title>
		<author>
			<persName><forename type="first">J</forename><surname>Postel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IETF RFC</title>
		<imprint>
			<biblScope unit="volume">791</biblScope>
			<date type="published" when="1981-09">September 1981</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">PLAN: A packet language for active networks</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pankaj</forename><surname>Kakkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><forename type="middle">A</forename><surname>Gunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Nettles</surname></persName>
		</author>
		<ptr target="www.cis.upenn.edu/switchware/papers/plan.ps" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third ACM SIGPLAN International Conference on Functional Programming Languages</title>
		<meeting>the Third ACM SIGPLAN International Conference on Functional Programming Languages</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="86" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Active bridging</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Scott</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marianne</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">M</forename><surname>Nettles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings, 1997 SIGCOMM Conference</title>
		<meeting>1997 SIGCOMM Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Caml home page</title>
		<ptr target="pauillac.inria.fr/caml/index-eng.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Haskell: A purely functional language</title>
		<ptr target="www.haskell.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Scheme home page</title>
		<ptr target="www-swiss.ai.mit.edu/scheme-home.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The Definition of Standard ML</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Milner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mads</forename><surname>Tofte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Harper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A secure active network environment architecture: Realization in SwitchWare</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Scott</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">A</forename><surname>Arbaugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelos</forename><forename type="middle">D</forename><surname>Kerom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network Magazine</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="37" to="45" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>Special issue on Active and Controllable Networks</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">PLAN system security</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Hicks</surname></persName>
		</author>
		<idno>MS-CIS- 98-25</idno>
		<ptr target="www.cis.upenn.edu/switchware/papers/plansecurity.ps" />
		<imprint>
			<date type="published" when="1998-04">April 1998</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer and Information Science, University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Network programming with PLAN</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pankaj</forename><surname>Kakkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><forename type="middle">A</forename><surname>Gunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Nettles</surname></persName>
		</author>
		<ptr target="www.cis.upenn.edu/switchware/papers/progplan.ps" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Workshop on Internet Programming Languages</title>
		<meeting>the IEEE Workshop on Internet Programming Languages</meeting>
		<imprint>
			<date type="published" when="1998-05">May 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Ipng, Internet Protocol Next Generation, Ipng Series</title>
		<editor>Scott O. Bradner and Allison Mankin</editor>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An Ethernet address resolution protocol</title>
		<author>
			<persName><forename type="first">C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><surname>Plummer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IETF RFC</title>
		<imprint>
			<biblScope unit="volume">826</biblScope>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Routing information protocol</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hedrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RFC</title>
		<imprint>
			<biblScope unit="volume">1058</biblScope>
			<date type="published" when="1988-06">June 1988</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Internet control message protocol</title>
		<author>
			<persName><forename type="first">J</forename><surname>Postel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IETF RFC</title>
		<imprint>
			<biblScope unit="volume">792</biblScope>
			<date type="published" when="1981-09">September 1981</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A web navigator with applets in Caml</title>
		<author>
			<persName><forename type="first">Francois</forename><surname>Louaix</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth WWW Conference</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Security properties of typed applets</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Leroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franc</forename><surname>ois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rouaix</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th symp. Principles of Programming Languages</title>
		<meeting>25th symp. Principles of Programming Languages</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="391" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The Art of Computer Systems Performance Analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Martin</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prycker</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Asynchronous Transfer Mode: Solution for Broadband ISDN</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Ellis Horwood</publisher>
			<pubPlace>West Sussex, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">ANTS: A toolkit for building and dynamically deploying network protocols</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Wetherall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">L</forename><surname>Tennenhouse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE OPENARCH</title>
		<imprint>
			<date type="published" when="1998-04">April 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Towards programmable networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yemini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Da Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IFIP/IEEE International Workshop on Distributed Systems: Operations and Management</title>
		<meeting><address><addrLine>L&apos;Aquila, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Smart packets home page</title>
		<ptr target="www.net-tech.bbn.com/smtpkts/smtpkts-index.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A survey of active network research</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">L</forename><surname>Tennenhouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">David</forename><surname>Sincoskie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Wetherall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><forename type="middle">J</forename><surname>Minden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="80" to="86" />
			<date type="published" when="1997-01">January 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Active network program home page</title>
		<ptr target="www.ito.darpa.mil/research/anets" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A structured TCP in Standard ML</title>
		<author>
			<persName><forename type="first">Edo</forename><surname>Biagioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings, 1994 SIGCOMM Conference</title>
		<meeting>1994 SIGCOMM Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Signatures for a network protocol stack: A systems application of Standard ML</title>
		<author>
			<persName><forename type="first">Edoardo</forename><surname>Biagioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">G</forename><surname>Milnes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1994 ACM Conference on Lisp and Functional Programming</title>
		<meeting>the 1994 ACM Conference on Lisp and Functional Programming</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A dynamic network architecture</title>
		<author>
			<persName><forename type="first">Sean</forename><forename type="middle">W</forename><surname>O'malley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><forename type="middle">L</forename><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1992-05">May 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Building adaptive systems using Ensemble</title>
		<author>
			<persName><forename type="first">Robbert</forename><surname>Van Renesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken</forename><surname>Birman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hayden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Vaysburd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Karr</surname></persName>
		</author>
		<idno>TR97-1638</idno>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Multicasting multimedia streams with active networks</title>
		<author>
			<persName><forename type="first">Albert</forename><surname>Banchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Effelsberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Tschudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Volker</forename><surname>Turau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>International Computer Science Institute</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. 97-050</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Joust: A platform for communication-oriented liquid software</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">H</forename><surname>Hartman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><forename type="middle">L</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Bavier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">A</forename><surname>Bigot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Bridges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brady</forename><surname>Montz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Piltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">A</forename><surname>Proebsting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Spatscheck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep., University of Arizona</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
