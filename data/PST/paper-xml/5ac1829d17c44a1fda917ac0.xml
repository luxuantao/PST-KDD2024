<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fuzzy Self-Tuning PSO: A Settings-Free Algorithm for Global Optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-09-05">September 5, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Marco</forename><forename type="middle">S</forename><surname>Nobile</surname></persName>
							<email>nobile@disco.unimib.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics, Systems and Communication</orgName>
								<orgName type="institution">University of Milano-Bicocca</orgName>
								<address>
									<settlement>Milano</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">SYSBIO.IT Centre of Systems Biology</orgName>
								<address>
									<settlement>Milano</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paolo</forename><surname>Cazzaniga</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Human and Social Sciences</orgName>
								<orgName type="institution">University of Bergamo</orgName>
								<address>
									<settlement>Bergamo</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">SYSBIO.IT Centre of Systems Biology</orgName>
								<address>
									<settlement>Milano</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniela</forename><surname>Besozzi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics, Systems and Communication</orgName>
								<orgName type="institution">University of Milano-Bicocca</orgName>
								<address>
									<settlement>Milano</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">SYSBIO.IT Centre of Systems Biology</orgName>
								<address>
									<settlement>Milano</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Riccardo</forename><surname>Colombo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics, Systems and Communication</orgName>
								<orgName type="institution">University of Milano-Bicocca</orgName>
								<address>
									<settlement>Milano</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">SYSBIO.IT Centre of Systems Biology</orgName>
								<address>
									<settlement>Milano</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Giancarlo</forename><surname>Mauri</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics, Systems and Communication</orgName>
								<orgName type="institution">University of Milano-Bicocca</orgName>
								<address>
									<settlement>Milano</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">SYSBIO.IT Centre of Systems Biology</orgName>
								<address>
									<settlement>Milano</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gabriella</forename><surname>Pasi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics, Systems and Communication</orgName>
								<orgName type="institution">University of Milano-Bicocca</orgName>
								<address>
									<settlement>Milano</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fuzzy Self-Tuning PSO: A Settings-Free Algorithm for Global Optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-09-05">September 5, 2017</date>
						</imprint>
					</monogr>
					<idno type="MD5">E7DE55B091B8F279D72B998366EEEC64</idno>
					<idno type="DOI">10.1016/j.swevo.2017.09.001</idno>
					<note type="submission">Received date: 19 October 2016 Revised date: 31 August 2017 Accepted date: 3 September 2017 Preprint submitted to Swarm and Evolutionary Computation</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Swarm and Evolutionary Computation Particle Swarm Optimization</term>
					<term>adaptive algorithms</term>
					<term>Fuzzy</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Among the existing global optimization algorithms, Particle Swarm Optimization (PSO) is one of the most effective methods for non-linear and complex high-dimensional problems. Since PSO performance strongly depends on the choice of its settings (i.e., inertia, cognitive and social factors, minimum and maximum velocity), Fuzzy Logic (FL) was previously exploited to select these values. So far, FL-based implementations of PSO aimed at the calculation of a unique settings for the whole swarm. In this work we propose a novel self-tuning algorithm-called Fuzzy Self-Tuning PSO (FST-PSO)-which exploits FL to calculate the inertia, cognitive and social factor, minimum and maximum velocity independently for each particle, thus realizing a complete settings-free version of PSO. The novelty and strength of FST-PSO lie in the fact that it does not require any expertise in PSO functioning, since the behavior of every particle is automatically and dynamically adjusted during the optimization. We compare the performance of FST-PSO with standard PSO, Proactive Particles in Swarm Optimization, Artificial Bee Colony, Covariance Matrix Adaptation Evolution Strategy, Differential Evolution and Genetic Algorithms. We empirically show that FST-PSO can basically outperform all tested algorithms with respect to the convergence speed and is competitive concerning the best solutions found, noticeably with a reduced computational effort.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Logic, settings-free optimization, self-tuning algorithms</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Particle Swarm Optimization (PSO) is a population-based global optimization meta-heuristics, inspired by the collective movement of birds flocks and fish schools <ref type="bibr" target="#b0">[1]</ref>. In PSO, a swarm of N individuals, called particles, moves inside a bounded search space and cooperates to identify the best solution for a given problem with respect to a given fitness function. Two components are considered in PSO to the aim of exploiting and controlling the cooperation within the swarm: (i ) the social attraction, which favors the collaboration among particles; (ii ) the cognitive attraction, which prompts a particle to rely on its individual experience. The former component drives the particle towards the (current) best particle in the swarm, or towards the best particle in a specified neighborhood; the latter component guides each particle towards the best position it autonomously found so far. Both components influence the velocity and the exploratory capabilities of particles within the search space. Two parameters are used to balance the influence of these attractors: the so-called social (c soc ) and cognitive (c cog ) factors. Moreover, to obtain an effective exploration of the search space, an inertia factor w is used to weigh the movement of particles, and the magnitude of their velocities is clamped to a given threshold v max . A vector v max = (v max 1 , . . . , v max M ) can also be defined when possibly different velocity values are assigned along the M dimensions of the search space.</p><p>As in the case of many other optimization algorithms, the performance of PSO strongly depends on the proper settings of the aforementioned factors (N, c soc , c cog , w, v max ). Unfortunately, an analytic determination of the best settings is generally impossible, being strongly problem-dependent: only a thorough knowledge of the shape and roughness of the fitness landscape-the hyper-surface characterizing all local and global optima-might help in properly choosing the values for PSO settings <ref type="bibr" target="#b1">[2]</ref>. In general, the identification of the best settings is complex, lengthy and time consuming, so that a big deal of research is devoted to the definition of self-tuning and adaptive versions of evolutionary and swarm intelligence algorithms, including PSO. For instance, TRIBES is a settings-free version of PSO that automatically changes at run-time the particles' behavior as well as the topology of the swarm <ref type="bibr" target="#b2">[3]</ref>. The Parameter-Less Evolutionary Search-based on Genetic Algorithmsdynamically determines the settings by exploiting some statistical properties of the population <ref type="bibr" target="#b3">[4]</ref>. The plague technique applied to Genetic Programming <ref type="bibr" target="#b4">[5]</ref> is a strategy consisting in automatically adjusting the number of individuals of the population according to the fitness variation. APSO-MAM is a PSO variant where, at each iteration, the settings of a particle are dynamically varied. Hu et al. <ref type="bibr" target="#b5">[6]</ref> shown that this method performs better than other algorithms that exploit automatic mechanisms to control parameter values; however, APSO-MAM is based on a subgradient procedure to improve the quality of the best particle that can be calculated only for differentiable functions. This procedure is suitable for benchmark functions-based on simple equations whose gradient can be analytically calculated-but hampers a full applicability of APSO-MAM in the case of real-world applications, in which the gradient of the fitness function does not have an analytic formulation.</p><p>Other approaches to dynamically select the PSO settings make use of Fuzzy Logic (FL) <ref type="bibr" target="#b6">[7]</ref>, to the aim of analyzing the contingent situation of the swarm. For instance, Shi and Eberhart <ref type="bibr" target="#b7">[8]</ref> proposed for the first time a Fuzzy Rule-Based System (FRBS) to drive the configuration of PSO settings. In general, a FRBS exploits fuzzy sets and FL to represent different forms of knowledge about the system, as well as to model the relationships existing between its variables <ref type="bibr" target="#b8">[9]</ref>. In the case of PSO considered in <ref type="bibr" target="#b7">[8]</ref>, the performance of the current best candidate solution and the current inertia weight are evaluated at each iteration, and exploited as inputs of the FRBS to calculate a new inertia weight for the whole swarm. Fuzzy Adaptive Turbulence in Particle Swarm Optimization was then introduced by Abraham and Liu <ref type="bibr" target="#b9">[10]</ref> to deal with the issue of the premature convergence of particles. This PSO version exploits FL to adaptively tune an additional PSO settings value, i.e., the minimum velocity of particles, in order to reduce the crowding of the swarm around the global best. Note that a vector v min could be defined, analogously to the case of the maximum velocity vector v max , to set different minimum velocity values along each dimension of the search space. However, Fuzzy Adaptive Turbulence in PSO considers only a common minimum velocity value for the whole swarm. A Fuzzy Particle Swarm Optimization algorithm (FPSO) was instead introduced by Tian and Li <ref type="bibr" target="#b10">[11]</ref> to adjust both the inertia weight and the learning coefficient (a parameter introduced on purpose to modulate the velocity of particles). In FPSO, the FRBS exploits two input variables: the improvement of the global best and the deviation of particles' fitness.</p><p>Castillo and Melin <ref type="bibr" target="#b11">[12]</ref> reported on works describing different evolutionary algorithms improved by means of FL, while a survey on different meth-ods used to tune PSO settings was presented by Razaee Jordehi and Jasni <ref type="bibr" target="#b12">[13]</ref>. All these papers show that FL represents an advantageous approach to develop self-tuning strategies for global optimization algorithms. Anyway, previous works in the context of PSO considered only a subset of its overall settings.</p><p>Traditional PSO versions consider w, c soc , c cog , v min and v max as global settings, i.e., the velocity and position of all particles in the swarm are updated according to the same values. On the contrary, in the algorithm we present in this work each particle has its own settings, determined by means of a FRBS; therefore, the simple reactive individuals of classic PSO become proactive optimizing agents. The FRBS calculates the individual settings of particles by computing two functions, the distance from the global best and a normalized fitness incremental factor, as it was initially proposed in Proactive Particles in Swarm Optimization (PPSO) <ref type="bibr" target="#b13">[14]</ref>. Here we introduce Fuzzy Self-Tuning Particle Swarm Optimization (FST-PSO), which guarantees user independence via a fully automatic FL-based methodology that calculates at run-time the settings of w, c soc , c cog , v min and v max , independently for each particle in the swarm. In Section 3 we extensively discuss the features of FST-PSO with respect to PPSO.</p><p>The performances of FST-PSO are compared against standard PSO <ref type="bibr" target="#b0">[1]</ref>, PPSO <ref type="bibr" target="#b13">[14]</ref> and state-of-the-art competitors like Artificial Bee Colony (ABC) <ref type="bibr" target="#b14">[15]</ref>, Covariance Matrix Adaptation Evolution Strategy (CMA-ES) <ref type="bibr" target="#b15">[16]</ref>, Differential Evolution (DE) <ref type="bibr" target="#b16">[17]</ref>, and Genetic Algorithms (GA) <ref type="bibr" target="#b17">[18]</ref>. All these algorithms are population-based optimization procedures, where the quality of the individuals is assessed by means of a proper fitness function.</p><p>According to the so-called no free lunch theorem <ref type="bibr" target="#b18">[19]</ref>, there exists no algorithm able to outperform all the other algorithms, on average, given any possible optimization problem. In this paper we empirically show that FST-PSO can basically outperform all tested competitors with respect to the convergence speed, and it is also competitive concerning the best solutions found. We also highlight that FST-PSO requires less computational effort with respect to the state-of-the-art competitors. Considering the aforementioned theorem and the results shown in this work, a remarkable advantage of FST-PSO is that it represents a completely settings-free "black-box" self-tuning algorithm, usable without any expertise in global optimization methods, and characterized by an excellent trade-off between exploratory capabilities and computational requirements.</p><p>The paper is structured as follows. In Section 2 we describe the standard PSO algorithm, while FST-PSO is presented in Section 3. We show the results of our analyses in Section 4, empirically proving the better performance of FST-PSO for a set of multi-dimensional benchmark functions. Finally, in Section 5 we discuss some future developments of our methodology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Particle Swarm Optimization</head><p>PSO is a population-based swarm intelligence meta-heuristics, especially suitable for optimization problems whose solutions can be encoded as realvalued vectors <ref type="bibr" target="#b0">[1]</ref>. In PSO, a population (called swarm) of N candidate solutions (called particles) cooperates to identify the optimal solution by moving within a bounded M -dimensional search space, where M is the length of the real-valued vectors.</p><p>Each particle i, i = 1, . . . , N, is characterized by two vectors in the search space: the position, x i ∈ R M , and the velocity, v i ∈ R M . Usually, the initial positions of particles are randomly selected with a uniform distribution over the search space, though different initialization strategies can be exploited <ref type="bibr" target="#b19">[20]</ref>. The position and the velocity of each particle are updated, at each iteration of the optimization phase, according to two attractors: the best position found so far by the particle itself (b i ∈ R M ), and the best position identified so far by the whole swarm (g ∈ R M ). These attractors are balanced by two non-negative PSO-specific settings, the so-called cognitive factor (c cog ∈ R + ) and social factor (c soc ∈ R + ).</p><p>Since a deterministic-driven movement of particles could funnel the particles into local optima, each attractor is multiplied by a vector of random numbers, sampled from the uniform distribution in [0, 1). In addition, the update of the velocity is modulated by an inertia weight, w ∈ R + , in order to avoid chaotic movements of the swarm. Formally, for each i = 1, . . . , N, the velocity of particle i at iteration t is given by:</p><formula xml:id="formula_0">v i (t) = w • v i (t -1)+ +c soc • R 1 • (x i (t -1) -g(t -1)) + (1) +c cog • R 2 • (x i (t -1) -b i (t -1)) ,</formula><p>where • denotes the component-wise multiplication operator between vectors, and R 1 and R 2 are two vectors of random numbers associated with the social and cognitive factor, respectively <ref type="bibr" target="#b20">[21]</ref>. We highlight here that, in standard PSO, the values of w, c soc , c cog are iteration-independent and are valid for all particles in the swarm. Accordingly, the position of particle i at iteration t is updated by calculating:</p><formula xml:id="formula_1">x i (t) = x i (t -1) + v i (t). (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>The quality of each particle in the swarm-i.e., of each candidate solution for the given optimization problem-is evaluated by exploiting an adequate fitness function (hereby denoted by f ). The fitness function drives the movement of all particles within the search space, since it is used to evaluate the values of the local and global attractors, b i and g, iteration by iteration. By calculating the fitness values of all particles over the set of feasible solutions, we obtain a hyper-surface called fitness landscape.</p><p>The methodology described so far might drive the particles outside the feasible space of solutions, or even towards the infinity. To avoid this drawback, in PSO the search space is bounded (according to domain knowledge), and specific boundary conditions are applied to all particles that reach the fixed limits. In what follows, we denote by b min ∈ R M and b max ∈ R M the vectors indicating the values of the minimum and maximum boundaries of the search space, respectively. If all components of these vectors have the same value-namely, all components in vector b min are equal to b min ∈ R and all components in vector b max are equal to b max ∈ R-then we simply denote by [b min , b max ] M the whole search space. We underline here that the boundaries of the search space are generally problem-dependent and cannot be determined with an automatic strategy. As boundary condition, we use the damping strategy <ref type="bibr" target="#b21">[22]</ref>: each particle that goes outside the search space in any dimension is relocated at the boundary of the solution space in that dimension; moreover, the velocity component in that dimension is changed in the opposite direction and it is multiplied by a random factor chosen with uniform distribution in [0, 1).</p><p>Another issue in PSO is that the velocity of particles might diverge during the optimization process. To avoid this problem, the velocity is usually clamped to a maximum value, v maxm ∈ R + , along each m-th dimension of the search space, with m = 1, . . . , M <ref type="bibr" target="#b20">[21]</ref>. On the contrary, in standard PSO the particles are not characterized by a minimum velocity. However, to improve the exploratory capabilities of the swarm, the velocity of each particle can also be clamped to a minimum value, v minm ∈ R + , along each dimension of the search space.</p><p>In general, the values for N, c soc , c cog , w, the vector of minimum velocity values v min and the vector of maximum velocity values v max , are set by the user. These PSO settings usually have a huge impact on the optimization performance <ref type="bibr" target="#b20">[21]</ref>, both in terms of convergence speed and quality of the best solution. To lower the possible negative effects of this choice, and provide unfamiliar PSO users with a settings-free global problem optimizer, in this work we propose a novel FL-based algorithm that automatically selects all these values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Fuzzy Self-Tuning PSO</head><p>We describe here a fully-automated version of PSO, called Fuzzy Self-Tuning Particle Swarm Optimization (FST-PSO), where the values of PSO settings are dynamically controlled by means of FL. In particular, each particle is associated with its own values for the inertia, the social and cognitive factors, the maximum and minimum velocity. This work represents an alternative approach to previous FL-controlled versions of PSO <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11]</ref>, whose aim consisted in improving the performance of this optimization algorithm by carrying out the automatic determination of its global settings.</p><p>FST-PSO is an extended and improved version of the FL-based PSO that we previously proposed, named Proactive Particles in Swarm Optimization (PPSO) <ref type="bibr" target="#b13">[14]</ref>, whereby the velocity and position of every particle were updated according to individual particle settings-inertia, social and cognitive factors, each one associated with a fuzzy variable-independently from the values of the other particles in the swarm. In FST-PSO, also the maximum and minimum velocity of each particle are individually adjusted by means of FL, thanks to six additional rules, providing users with a completely settingsfree version of PSO. To determine the swarm size, FST-PSO exploits the heuristic N = 10 + 2 √ M which sets the number of particles N according to the number of dimensions M of the search space, as suggested by Hansen et al. <ref type="bibr" target="#b22">[23]</ref> and also adopted in PPSO <ref type="bibr" target="#b13">[14]</ref>.</p><p>One of the main differences between FST-PSO and PPSO is that, in the latter, the velocity of all particles along each dimension of the search space was clamped to a common maximum value, proportional to a pre-defined value U ∈ (0, 1] (as default, U = 0.2 was used in PPSO <ref type="bibr" target="#b13">[14]</ref>). To be more precise, in PPSO <ref type="bibr" target="#b13">[14]</ref> we considered</p><formula xml:id="formula_3">v maxm = U • (b maxm -b minm ) , (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>where b minm and b maxm denote the boundaries of the m-th dimension of the search space. On the contrary, FST-PSO automatically determines this set-ting independently for each particle, by replacing U with a linguistic value of a linguistic variable. Moreover, FST-PSO introduces an additional setting L ∈ (0, 1], L &lt; U , which is used to clamp also the minimum velocity of each particle along the m-th dimension of the search space to</p><formula xml:id="formula_5">v minm = L • (b maxm -b minm ) . (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>FST-PSO automatically determines this setting independently for each particle, by replacing L with a linguistic value of a linguistic variable. So doing, FST-PSO becomes a fully automated self-tuning algorithm, where each particle computes its current velocity according to its performance during the previous iteration of the optimization. In Section 4, a comparative evaluation of FST-PSO with respect to PPSO is reported, which shows the improved performance of the new algorithm. Moreover, additional comparative evaluations with respect to state-of-the-art optimization techniques are reported.</p><p>In what follows, we denote by w i (t), c soc i (t), c cog i (t), L i (t) and U i (t) the inertia, social factor, cognitive factor, upper clamping value for maximum velocity and lower clamping value for minimum velocity of the i-th particle during iteration t, respectively. At each iteration, the current velocity of particle i is evaluated as:</p><formula xml:id="formula_7">v i (t) = w i (t -1) • v i (t -1)+ +c soc i (t -1) • R 1 • (x i (t -1) -g(t -1)) + (5) +c cog i (t -1) • R 2 • (x i (t -1) -b i (t -1)) ,</formula><p>where R 1 and R 2 are two vectors of random numbers associated with the social and cognitive factors, respectively; x i and b i are the current position and the best position found so far by particle i, respectively, and g is the global best position found so far by the swarm. We highlight that, differently from PSO, in FST-PSO the values of inertia, social and cognitive factors are iteration-dependent and they possibly assume a different value for each particle in the swarm.</p><p>To dynamically determine the values of w i (t), c soc i (t), c cog i (t), L i (t) and U i (t) in an automatic way, independently for each particle at each iteration t, we make use of a FRBS consisting of 15 fuzzy rules, reported in Table <ref type="table" target="#tab_0">1</ref>. These rules are based on two main concepts: the distance of the particle Rule definition</p><formula xml:id="formula_8">1 if (φ is Worse or δ is Same) then (Inertia is Low) 2 if (φ is Same or δ is Near ) then (Inertia is Medium) 3 if (φ is Better or δ is Far ) then (Inertia is High) 4 if (φ is Better or δ is Near ) then (Social is Low ) 5 if (φ is Same or δ is Same) then (Social is Medium) 6 if (φ is Worse or δ is Far ) then (Social is High) 7 if (δ is Far ) then (Cognitive is Low ) 8 if (φ is Worse or φ is Same or δ is Same or δ is Near ) then (Cognitive is Medium) 9 if (φ is Better ) then (Cognitive is High) 10 if (φ is Same or φ is Better or δ is Far ) then (L is Low ) 11 if (δ is Same or δ is Near ) then (L is Medium) 12 if (φ is Worse) then (L is High) 13 if (δ is Same) then (U is Low ) 14 if (φ is Same or φ is Better or δ is Near ) then (U is Medium) 15 if (φ is Worse or δ is Far ) then (U is High)</formula><p>from the global best g, and a function measuring the fitness improvement of each particle with respect to the previous iteration. The distance between two particles i and j, for some i, j = 1, . . . , N, is a function δ : R M × R M → R + , defined as:</p><formula xml:id="formula_9">δ(x i (t), x j (t)) = ||x i (t) -x j (t)|| 2 = M m=1 (x i,m (t) -x j,m (t)) 2 , (<label>6</label></formula><formula xml:id="formula_10">)</formula><p>where x i,m , x j,m denote the m-th components of the position vectors x i , x j of particles i and j, respectively. The normalized fitness incremental factor is a function φ : R M × R M → [-1, 1], which considers the positions of particle i at the current and previous iterations; it is defined as follows:</p><formula xml:id="formula_11">φ(x i (t), x i (t -1)) = δ(x i (t), x i (t -1)) δ max • (7) • min{f (x i (t)), f } -min{f (x i (t -1)), f } |f | ,</formula><p>where δ max is the length of the diagonal of the hyper-rectangle corresponding to the search space, while f represents the (estimated) worst fitness value for the optimization problem under investigation. In this work we consider minimization problems: the sign of function φ must therefore be inverted in the case of maximization problems, in order to exploit the set of fuzzy rules listed in Table <ref type="table" target="#tab_0">1</ref>.</p><p>We stress the fact that, since the fitness landscape of the optimization problem is generally unknown, an accurate estimate of the worst fitness value is, intuitively, as difficult as solving the optimization problem itself. For this reason, we consider f equal to the highest fitness value calculated during the first iteration of FST-PSO, according to the initial position of all particles. Then, during the optimization phase, we use the min functions in Equation <ref type="formula">7</ref>to clamp any fitness value worse than f . More precisely, the second factor in Equation 7 considers the possible improvement of the current fitness value of the i-th particle with respect to the previous iteration; the variation of the fitness function is then normalized in [-1, 1] by dividing by |f |. Note that a lower value of φ(x i (t), x i (t -1)) in [-1, 1] corresponds to a lower fitness value of particle i with respect to the previous iteration: this means that the particle is moving towards a new position x i that represents a better solution for the optimization problem. The first factor in Equation <ref type="formula">7</ref>, instead, is needed to weigh function φ according to the distance between the current and the previous position of the particle. This distance is normalized by dividing the distance value by δ max , so that the first factor takes values in the interval (0, 1).</p><p>We describe now the rationale behind the set of fuzzy rules listed in Table <ref type="table" target="#tab_0">1</ref>. In the antecedent of these rules, we use two linguistic variables, named Distance from g and Normalized fitness incremental factor, denoted by δ and φ, respectively. The definition of a linguistic variable for δ, expressing the distance of a particle from the global attractor g, allows to avoid the use of arbitrary thresholds (i.e., classic sets with crisp boundaries) to characterize the proximity to the global best. Similarly, the definition of a linguistic variable for φ allows to avoid arbitrary thresholds to characterize the improvement of a particle with respect to the fitness value it assumed in the previous iteration. In the consequent of rules, the output variables are called Inertia, Social, Cognitive, L and U , which correspond to the respective settings of particle i in FST-PSO. We want to stress the fact that, during each iteration of FST-PSO, all particles compute independently their own values for δ and φ, which are used to calculate the output variables according to the rules reported in Table <ref type="table" target="#tab_0">1</ref>.</p><p>The universe of discourse of the variable Distance from g consists of the numeric values of the distance between the position vector x i and the global best g, according to Equation <ref type="formula" target="#formula_9">6</ref>. Thus, the base variable of δ corresponds to the interval [0, δ max ]. The term set of this variable is composed by three linguistic values, Same, Near and Far. The membership functions of δ, shown in Figure <ref type="figure" target="#fig_0">1</ref>, depend on three parameters, δ 1 , δ 2 , δ 3 ∈ [0, δ max ], used to properly characterize the concept of fuzzy distance between the particle position and the global best. The values of δ 1 , δ 2 , δ 3 are set according to the size of the search space; following our domain expertise related to PSO, we use the following heuristic:</p><formula xml:id="formula_12">δ 1 = 0.2 • δ max , δ 2 = 0.4 • δ max , δ 3 = 0.6 • δ max .</formula><p>These are general-purpose multipliers, created to avoid any overfitting to the benchmark functions used in this study, and implementing a general and fuzzy concept of distance from the global best.</p><p>The universe of discourse of variable Normalized fitness incremental factor consists of the numerical values of function φ, according to Equation <ref type="formula">7</ref>; the base variable of φ therefore corresponds to the interval [-1, 1]. The term set of this variable is composed by three linguistic values, Better, Same and Worse. The membership functions of φ, shown in Figure <ref type="figure" target="#fig_1">2</ref>, are three simple triangular fuzzy sets, which correspond to a simplified version of the membership functions previously defined in PPSO <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b23">24]</ref>. FST-PSO relies on triangular fuzzy sets, for both δ and φ, because of their good trade-off between expressiveness, simplicity and computational efficiency <ref type="bibr" target="#b24">[25]</ref>.</p><p>The output variables (Inertia, Social, Cognitive, L, U ) can assume three different linguistic values, Low, Medium and High. Since our FRBS is based on the Sugeno inference method <ref type="bibr" target="#b25">[26]</ref>-which allows to define rules having fuzzy inputs and crisp outputs-each linguistic value of the five output variables is modeled as a fuzzy singleton, as given in Table <ref type="table" target="#tab_1">2</ref>. Formally, given a set R of R rules having the same output variable in their consequent (e.g., rules 1, 2, 3 in Table <ref type="table" target="#tab_0">1</ref> for Inertia), the Sugeno method calculates the final numerical value of this output variable as the weighted average of the output of each rule in R:</p><formula xml:id="formula_13">output = R r=1 ρ r z r R r=1 ρ r , (<label>8</label></formula><formula xml:id="formula_14">)</formula><p>where ρ r denotes the membership degree of the input variable of the r-th rule, and z r represents the output crisp value for the r-th rule, as given in Table <ref type="table" target="#tab_1">2</ref>.  </p><formula xml:id="formula_15">(δ : 0, 0, δ 1 , δ 2 ) = {1, if 0 ≤ δ &lt; δ 1 ; (δ 2 - δ)/(δ 2 -δ 1 ), if δ 1 ≤ δ &lt; δ 2 ; 0, if δ 2 ≤ δ ≤ δ max }. The membership function of Near is triangle(δ : δ 1 , δ 2 , δ 3 ) = {0, if 0 ≤ δ &lt; δ 1 ; (δ -δ 1 )/(δ 2 -δ 1 ), if δ 1 ≤ δ &lt; δ 2 ; (δ 3 - δ)/(δ 3 -δ 2 ), if δ 2 ≤ δ &lt; δ 3 ; 0, if δ 3 ≤ δ ≤ δ max }. The membership function of Far is trapezoid (δ : δ 2 , δ 3 , δ max , δ max ) = {0, if 0 ≤ δ &lt; δ 2 ; (δ -δ 2 )/(δ 3 -δ 2 ), if δ 2 ≤ δ &lt; δ 3 ; 1, if δ 3 ≤ δ ≤ δ max }.</formula><formula xml:id="formula_16">φ : -1, -1, 0) = {1, if φ = -1; -φ, if -1 &lt; φ &lt; 0; 0, if 0 ≤ φ ≤ 1}. The membership function of Unvaried is triangle(φ : -1, 0, 1) = 1 -|φ|. The membership function of Worse is trian- gle(φ : 0, 1, 1) = {0, if -1 ≤ φ &lt; 0; φ, if 0 ≤ φ &lt; 1; 1, if φ = 1}.</formula><p>Figure <ref type="figure" target="#fig_2">3</ref> shows the resulting heatmaps of the five output variables, as computed by the Sugeno method, which are described in the following sections.   <ref type="table" target="#tab_0">1</ref> and<ref type="table" target="#tab_1">2</ref>. Note that, in the plot of the output variable L (bottom left), the label "Medium" is not reported in the colorbar to avoid its overlap with the label "Low".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Inertia</head><p>The aim of the set of rules 1, 2 and 3, which adjust the value of the variable Inertia for every particle i, is to evaluate the contribution of the velocity value that particle i had in the previous iteration to update its velocity value at the current iteration. The rationale behind this is to increase the value of Inertia when the particle is improving its fitness value with respect to the previous iteration, and to lower it otherwise. This is achieved by setting a Low value of Inertia when either φ is Worse, or the distance δ from the global best is Same. A High value is instead set when the particle is following the right direction (i.e., φ is Better ), or it is far from the global best (i.e., δ is Far ). Finally, Inertia is set to a "neutral choice" (i.e., the value Medium), when no relevant changes in the fitness value occur with respect to the previous iteration (i.e., φ is Same) or the distance is Near.</p><p>The heatmap for Inertia (Figure <ref type="figure" target="#fig_2">3</ref>, top left) shows that the maximum value for this output variable is attained when δ is Far and φ is Better. The value of Inertia decreases when δ varies from Far to Same or φ varies from Better to Worse, reaching the lowest value when φ is Worse and δ is Same.</p><p>In particular, we observe that in the case of δ values between Near and Far, there is a plateau in the values of Inertia when φ is Better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Social attraction</head><p>Rules 4, 5 and 6 control the strength of the social information shared among particles. This is obtained by tuning the Social variable, which determines the attraction of particle i towards the global best position g in the swarm. If either the particle is finding better solutions for the optimization problem (i.e., φ is Better ), or it is approaching the global best (i.e., δ is Near ), then it is reasonable for it to "ignore" the information shared by the swarm. Therefore, Social is set to Low in these conditions. On the contrary, when the particle is not finding better solutions or it is not close to the global best, it should rather "follow the advice" of the other particles. Hence, we set Social to the High value. As in the case of Inertia, the FRBS assigns an intermediate value to Social if no relevant changes occur either in the fitness value or in the distance from g (i.e., φ and δ are Same).</p><p>The Social variable (Figure <ref type="figure" target="#fig_2">3</ref>, top middle) assumes its highest value when δ is Far and φ is Worse. This heatmap can be described by considering different aspects. On the one hand, when the value of φ changes from Worse to Better, the value of Social linearly decreases, independently from the value of δ. On the other hand, when the value of δ changes from Far to Same, the heatmap of Social is characterized by a dip in correspondence of the value Near of δ. The modulation of Social is mainly driven by φ, and the lowest value of this variable is reached when δ is Near and φ lies between Better and Same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Cognitive attraction</head><p>Rules 7, 8 and 9 are defined to calibrate the Cognitive variable, which weighs the attraction of particle i towards its personal best position b i . If the distance from the global best is Far, it is advisable that the particle limits the movement towards b i , therefore setting Cognitive to Low. On the contrary, if the particle is not improving its fitness value or it is not far from the global best (i.e., φ is Same or Worse and δ is Same or Near ), then an intermediate value of Cognitive can weigh the particle tendency to move in the direction of its personal best position b i . Finally, if the particle is finding better solutions for the optimization problem (i.e., φ is Better ), then the local exploration around its current position within the search space has to be encouraged by setting Cognitive to High.</p><p>The heatmap for Cognitive (Figure <ref type="figure" target="#fig_2">3</ref>, top right) shows that the highest value for this factor is obtained when φ and δ assume the values Better and Same, respectively. As δ moves from Same to Far and φ moves from Better to Worse, the value of Cognitive decreases reaching the lowest values in the opposite configuration (i.e., when δ is Far and φ is Worse). Note that both input variables have a comparable impact on the Cognitive factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Lower and upper clamping values for velocity</head><p>Differently from PPSO, in FST-PSO the maximum and minimum velocities of each particle are clamped using Equations 3 and 4, respectively, in which the typical swarm-shared fixed settings of U and L are dynamically replaced by using particle-specific and iteration-dependent values. Rules 10, 11, 12 and 13, 14, 15 control the values of the output variables L and U , respectively.</p><p>Concerning the L factor, it is advisable to have a High minimum velocity when the particle fitness φ is getting Worse. On the contrary, L is set to Low when φ is Same or Better, or when δ is Far, since in these situations the velocity of a particle could assume small values in order to perform a local exploration of the search space. Finally, when the particle position is close to the global best, the factor L is set to Medium. The heatmap of L factor is shown in Figure <ref type="figure" target="#fig_2">3</ref> (bottom left). We observe that this factor is mainly influenced by the value of φ. In particular, the highest value is reached when φ is Worse, then L decreases as φ reaches the Same value and, finally, there is a large plateau when φ is between Same and Better, irrespective of the δ value.</p><p>Regarding the U factor, the maximum velocity allowed is set to High in the case of a particle whose distance is far from the global best or when its fitness value is getting worse. On the contrary, this factor is set to Low only when the distance from the global optimum is Same. U is set to Medium when the fitness of the particle is improving or when the distance from the global best is Near. The heatmap of U factor is shown in Figure <ref type="figure" target="#fig_2">3</ref> (bottom right). In this case both φ and δ influence the value of this factor; in particular, there is a plateau characterized by medium values of U when φ is between Better and Same and δ is between Near and Far.</p><p>In general, by increasing the values of φ and δ, U increases and reaches its highest value in the case of φ equal to Worse and δ equal to Far.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>We investigated the performance of FST-PSO by testing the algorithm on 12 reference benchmark functions, listed in Table <ref type="table" target="#tab_2">3</ref>, which are all parametric in the number of dimensions M and have R M as domain of definition. The graphical representation given in Figure <ref type="figure" target="#fig_4">4</ref>, for M = 2, shows that these functions are emblematic examples of non-linear, multi-modal and rugged problems which can hardly be solved by means of classic optimization algorithms (e.g., gradient descent <ref type="bibr" target="#b26">[27]</ref>).   <ref type="table" target="#tab_2">3</ref>. </p><formula xml:id="formula_17">M M m=1 x 2 m ) - exp( 1 M M m=1 cos(2πxm)) [-30, 30] M f Ack (0) = 0 Alpine f Alp (x) = M m=1 |xm sin(xm) + .1xm| [-10, 10] M f Alp (0) = 0 Bohachevsky f Boh (x) = M -1 m=1 (x 2 m + 2x 2 m+1 -.3 cos(3πxm) - .4 cos(4πx m+1 ) + .7) [-15, 15] M f Boh (0) = 0 Griewank f Gri (x) = 1 4000 M m=1 x 2 m -M m=1 cos( xm √ m ) + 1 [-600, 600] M f Gri (0) = 0 Michalewicz f Mic (x) = -M m=1 sin(xm) sin 2k ( mx 2 m π ), with k = 10 in this work [0, π] M f Mic (0) = -1.8013 Plateau f Pla (x) = 30 + M m=1 xm [-5.12, 5.12] M f Pla (-5.12) = -6M + 30 Quintic f Qui (x) = M m=1 |x 5 m -3x 4 m + 4x 3 m + 2x 2 m -10xm -4| [-10, 10] M f Qui (-1) = 0 Rastrigin f Ras (x) = 10M + M m=1 (x 2 m -10 cos(2πxm)) [-5.12, 5.12] M f Ras (0) = 0 Rosenbrock f Ros (x) = M -1 m=1 [100(x 2 m -x m+1 ) 2 + (xm -1) 2 ] [-5, 10] M f Ros (1) = 0 Shubert f Shu (x) = M m=1 ( 5 i=1 i cos[(i + 1)xm + i]) [-10, 10] M Many global minima Vincent f Vin (x) = M m=1 sin(10 log(xm)) [0.25, 10] M f Vin (7.706281) = -M Xin-She Yang f Xin (x) = M m=1 |xm|[exp( M m=1 sin(x 2 m )] -1 [-2π, 2π] M</formula><p>f Xin (0) = 0 * Boldface numbers refer to vectors whose M components have the same value FST-PSO was compared against PSO, PPSO, ABC, CMA-ES, DE and GA, which are all population-based optimization methods where candidate solutions are encoded in a specific mode, according to each algorithm. The functioning of each algorithm, along with a brief description of the settings used for the tests, is summarized in the next section. Independently from the mathematical representation of the population individuals and the algorithm itself, in each optimization method the quality of each candidate solution is evaluated by means of the fitness function. In order to make a quantitative comparison between FST-PSO and each competitor algorithm, we exploited the Average Best Fitness (ABF), i.e., the mean of the fitness values of the best solution found at each iteration t, evaluated over a number Θ of runs. In all tests that follow, we set Θ = 30.</p><p>Formally, denoting by B θ (t) the best candidate solution found at iteration t during the θ-th run, it holds</p><formula xml:id="formula_18">ABF = 1 Θ Θ θ=1 f (B θ (t)). (<label>9</label></formula><formula xml:id="formula_19">)</formula><p>To perform a fair comparison, for each algorithm the number of iterations was fixed to t MAX = 400 and the population size N was chosen by using the same heuristic defined for FST-PSO, so that the same number of fitness evaluations was performed for all methods. We implemented FST-PSO using the Python language-exploiting the pyfuzzy package (website: http://pyfuzzy.sourceforge.net) as fuzzy engine, extended to fully support Sugeno inference-and relying on NumPy (website: http://www.numpy.org) (see <ref type="bibr" target="#b27">[28]</ref> for further information). The source code of FST-PSO can be installed as PyPI package (pip install fst-pso).</p><p>PSO, ABC, CMA-ES, DE and GA were implemented using the PyGMO Python package <ref type="bibr" target="#b28">[29]</ref>. Except for N , throughout all tests we relied on the default settings of PyGMO, in order to perform an "out-of-the-box" optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Competitor algorithms PSO and PPSO.</head><p>The basics of PSO and PPSO were introduced in Sections 2 and 3. We used the following settings for PSO:</p><p>• inertia w linearly decrementing from 0.9 to 0.4;</p><p>• cognitive factor c cog = 2.05;</p><p>• social factor c soc = 2.05.</p><p>In the case of PSO, the v maxm values were chosen using the same heuristic used for PPSO, as described in Section 3. For both PSO and PPSO, the v minm values were set equal to 0, that is, no minimum velocity was forced. Similarly to FST-PSO, damping boundary conditions were used for PSO and PPSO. <ref type="bibr" target="#b14">[15]</ref> is a swarm intelligence population-based optimization algorithm inspired by the foraging behavior of bees. In ABC, the population is composed of three different kinds of individuals: scout, employed and onlooker bees. Scout bees perform the exploration process, as they are randomly placed within the search space. Employed and onlookers carry out the exploitation process by means of a local search nearby the position identified by the scout. More precisely, scout bees randomly determine a new food source (i.e., a position in the search space) and, at this stage, they become employed. Free onlookers bees are then assigned to the position of employed food sources, proportionally to the fitness values of these positions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABC. Artificial Bee Colony</head><p>After a given number of trials (in PyGMO this number is equal to 20), if onlookers did not improve their positions they go back to the hive and become scout again, so that they can be randomly placed in a different position. <ref type="bibr" target="#b15">[16]</ref> is generally considered one of the most effective evolutionary algorithms for singleobjective real-valued optimization <ref type="bibr" target="#b29">[30]</ref>, and it is often regarded as the stateof-the-art for stochastic continuous optimizers. The basic ES algorithm exploits a mutation operator to explore the search space. In particular, the mutation creates novel individuals during each generation by perturbing the best individual, or by perturbing a novel individual created using a weighted average of the population. The perturbation is performed using multivariate normally distributed random deviates, having mean 0 and standard deviation σ (which is called the step-size). The Covariance Matrix Adaptation variant of ES is able to dynamically adapt such distribution to perform more effective mutation steps. In particular, CMA-ES relies on a M ×M symmetric positive covariance matrix, which is used to determine pairwise dependencies between parameters of the problem under investigation. In other words, CMA-ES introduces a modified mutation operator, based on an M -dimensional distribution ellipsoid whose size and rotation are updated iteration by iteration, according to the optimization performances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CMA-ES. Covariance Matrix Adaptation Evolution Strategy</head><p>CMA-ES is meant to be a settings-free algorithm, although the population size N and the initial step-size can be selected by the user. In our tests, we used PyGMO's default setting σ = 0.5. For further reference on CMA-ES parameters we refer the reader to <ref type="bibr" target="#b30">[31]</ref> and references therein. <ref type="bibr" target="#b16">[17]</ref> is a population-based algorithm where, at each generation, the individuals of the population evolve by means of two operators: mutation and crossover. In particular, three distinct candidate solutions are randomly selected and mixed using a weighted function (i.e., mutation). Then, the outcome is recombined by means of crossover with a fourth randomly chosen individual, to produce a new offspring called trial vector. This vector replaces the recombined individual in the next generation if it is characterized by an improved fitness value. The variant of DE used in the following tests makes use of random selection of mutation vectors (with self-adaptive weighing factor), one difference vector for trial vector generation, and exponential crossover with self-adaptive probability (this variant is called rand/1/exp, using the standard nomenclature <ref type="bibr" target="#b31">[32]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DE. Differential Evolution</head><p>GA. Genetic Algorithms <ref type="bibr" target="#b17">[18]</ref> are a population-based optimization strategy that mimics Darwinian processes like natural selection. In GA, a population of randomly generated individuals undergoes a selection mechanism and is modified by genetic operators (i.e., crossover and mutation). The selection strategy is used to choose the individuals according to their fitness values; these individuals will generate possibly improved offspring thanks to the application of the crossover operator. In order to better explore the search space, a random mutation is also performed on the offspring. The crossover and mutation operators are applied according to a specified probability. A relevant improvement to standard GA consists in the application of elitism, where the individual characterized by the best fitness value in the current generation is directly promoted to belong to the population at the next generation. PyGMO exploits the elitism operator, while the other individuals are selected using a roulette wheel strategy (i.e., selection probability is proportional to the fitness of the individual); the (single point) crossover operator exchanges parts of parents individuals and is applied with probability 0.95; mutation operator perturbs the individual exploiting a Gaussian distribution (with standard deviation equal to 0.1) and is applied with probability 0.02.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Optimization performance</head><p>To evaluate the optimization performance of each algorithm, in all executed tests we assumed M = 100 for every benchmark function listed in Table <ref type="table" target="#tab_2">3</ref>. In Figure <ref type="figure" target="#fig_5">5</ref> we show the comparison of the ABF of FST-PSO (black solid lines) against standard PSO (blue dashed lines), PPSO (gray dotted lines), ABC (red solid lines), CMA-ES (light blue solid lines), DE (green solid lines) and GA (orange solid lines). The standard deviation of each test is also pictured as a transparent filled area around the corresponding ABF curve, having the same color semantics. ABF and standard deviation values were measured during the Θ = 30 runs and t MAX = 400 iterations of each algorithm.  <ref type="table" target="#tab_2">3</ref>. Lines and filled areas represent the ABF and the corresponding standard deviation, measured during 30 runs and 400 iterations of each algorithm (due to the logarithmic scale on the y axis, standard deviation is not represented for the Shubert and Xin-She Yang functions for the sake of readability). These results show that FST-PSO often achieves the best performance in terms of convergence speed and is competitive concerning the best solution found.  Our results show that, in the case of Bohachevsky, Griewank, Quintic, Rastrigin, Rosenbrock and Xin-She Yang functions, FST-PSO achieves the best performances in terms of convergence speed (Figure <ref type="figure" target="#fig_5">5</ref>). To prove in a quantitative way the better performances of FST-PSO, from the point of view of the average convergence speed, we report in Table <ref type="table" target="#tab_3">4</ref> the integrals of the ABF curves, calculated using the trapezoidal rule. Bold values correspond to a lower ABF achieved throughout the optimization, highlighting the faster convergence of our algorithm. According to these numerical results, FST-PSO is characterized by a faster convergence than the competitor algorithms also in the case of Alpine and Vincent functions. Moreover, the ABF of FST-PSO found after 400 iterations is competitive: as reported in Figure As evidenced by the standard deviations plotted in Figure <ref type="figure" target="#fig_5">5</ref>, in the specific case of the Rastrigin function, CMA-ES is characterized by a peculiar behavior at the end of the optimization process. Despite an initial worse convergence speed, CMA-ES is able to collect-during some of the 30 runs of the optimization-enough statistical information for the covariance matrix adaptation, yielding better solutions than the other tested algorithms. However, FST-PSO converges more consistently to optimal solutions with a negligible variance.</p><p>It is worth noting that FST-PSO is more performant than PSO and PPSO on almost all tested benchmark functions: in particular, in the case of Quintic and Shubert functions, FST-PSO outperforms the other two algorithms by many orders of magnitude. A notable exception is instead represented by the Plateau function, whose piecewise "flat" fitness landscape (Figure <ref type="figure" target="#fig_4">4</ref>) might induce the firing of fuzzy rules that mislead particles in the early phases of the optimization.</p><p>A different scenario concerns the Michalewicz function, where GA obtains the best performances, FST-PSO achieves the same performances of ABC, while CMA-ES shows the worst performances. In the case of the Shubert function, GA and ABC achieve the best results, while FST-PSO and CMA-ES obtain performances similar to DE. These results highlight the validity of the no free lunch theorem <ref type="bibr" target="#b18">[19]</ref>, as mentioned in Section 1.</p><p>Alpine, Plateau and Vincent functions are those characterized by the most interesting results. For what concerns the optimization of the Plateau function, standard PSO and PPSO achieve the best results, while FST-PSO is characterized by a lower convergence speed and worse final solutions (only DE performances are worse than FST-PSO). In the case of Alpine function, FST-PSO has the highest convergence speed at the beginning of the optimization; however, after around 140 iterations CMA-ES overtakes FST-PSO but, by the end of the optimization, they both achieve the same ABF. Similarly, for what concerns the Vincent function, GA has the highest convergence speed at the beginning of the optimization, but after 100 iterations FST-PSO overtakes GA and finally achieves better solutions by the end of the optimization. Moreover, CMA-ES convergence speed is very slow at the beginning, but increases abruptly around iteration 100 and, by iteration 180, the ABF of this algorithm results to be the best one: CMA-ES indeed reaches the best solution by the end of the optimization process for this benchmark function.</p><p>In order to further investigate the performance of FST-PSO, we considered the 28 shifted/rotated benchmark functions proposed during the contest on real-parameters single-objective bound-constrained optimization of the 2013 IEEE Congress on Evolutionary Computation (CEC <ref type="bibr">'13)</ref>. For this batch of tests, we compared FST-PSO with standard PSO and with CMA-ES, which represents the FST-PSO's main competitor, given the previous results. For each test, we assumed M = 100 for every benchmark function.</p><p>As shown in Figure <ref type="figure" target="#fig_8">7</ref>, FST-PSO always outperforms standard PSO, except for the case of function f 8 (a rotated Ackley function). FST-PSO and CMA-ES exhibit similar performance for almost all benchmark functions, except for the case of functions f 3, f7, f9, f11, f12, f13, f19, f25 and f 27, where CMA-ES achieves, on average, better results. FST-PSO outperforms standard PSO and CMA-ES in the case of functions f 14 (a strongly multimodal, rotated, non-separable, asymmetrical Schwefel function, in which the second better local optimum is placed very far from the global optimum to mislead the optimization) and f 16 (the rotated Katsuura function: multimodal, non-separable, asymmetrical, and non-differentiable). It is worth noting that in three cases (f 15, f 22, and f 23), FST-PSO is characterized by better results throughout the whole optimization and it is outperformed by CMA-ES only in the latest stages of the execution. Stated otherwise, in such cases, FST-PSO can yield better results than CMA-ES when a limited budget of fitness evaluations or running time is allowed. This topic will be discussed in the following section. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Computational performance</head><p>Given the results presented in Section 4.2, it is interesting to assess the computational performances of the compared algorithms, especially in the case of FST-PSO and CMA-ES, which result to be the best optimization strategies for the benchmark functions tested in this work. To this aim, we executed additional tests to perform the optimization of the Plateau, Rastrigin and Vincent functions, for which FST-PSO and CMA-ES are characterized by the most divergent results: FST-PSO performs worse, better and initially better than CMA-ES on each of these benchmark functions, respectively (see Figure <ref type="figure" target="#fig_5">5</ref>). The comparison between FST-PSO and CMA-ES was carried out by measuring their computational costs while increasing the number of dimensions of the search space-namely, M = 1, 10, 20, 30, 50, 100-of these three benchmark functions.</p><p>Table <ref type="table" target="#tab_4">5</ref> reports the running time, expressed in seconds, required for the execution of 400 iterations of optimization of each fitness function using FST-PSO and CMA-ES on a workstation equipped with a Intel R Core TM i7-3770 CPU @ 3.40GHz, 16GB RAM and running Ubuntu 14.10. According to our results, even in the case of low-dimension problems FST-PSO scales better than CMA-ES, which is tied to the numerous calculations for the covariance matrix adaptation. In the case of the Rastrigin function, FST-PSO is able to give, on average, better solutions than CMA-ES with lower computational costs. For instance, when M = 100, FST-PSO is approximately 70× faster than CMA-ES. For the Plateau function, FST-PSO is strongly more efficient than CMA-ES, even for low dimension problems, being from 13× to 77× faster. The same holds for the Vincent function, where FST-PSO is around 81× faster than CMA-ES when M = 100. Therefore, despite its additional computational costs due to the multiple Sugeno inferences, FST-PSO proves to be a very efficient optimization algorithm.</p><p>The computational efficiency of FST-PSO can also be analyzed from a different perspective. Let us assume to fix a total amount of computation time T to execute an optimization task. In this situation, although CMA-ES can (in principle) converge to better fitting solutions, according to our tests it would be outperformed by FST-PSO, which is able to execute a larger number of iterations in the same amount of time. To properly discuss this topic, we optimized the Plateau, Rastrigin and Vincent functions with FST-PSO and CMA-ES, performing 30 runs of each algorithm for each value of M = 1, 10, 20, 30, 50, 100. During each test, we stopped CMA-ES as soon as FST-PSO completed 400 iterations, keeping track of the fitness value of the best individuals identified during the last iteration of each run, which were later used to asses the ABF. The results of these analyses, reported in Table <ref type="table" target="#tab_5">6</ref>, prove that the higher efficiency of FST-PSO with respect to CMA-ES allows a better convergence when the same budget of computational time is used: the ABF is consistently better (except in the case of Rastrigin with M = 10 and Vincent with M = 1), especially in the case of high values of M . zero, with mean equal to the reference value given in Table <ref type="table" target="#tab_1">2</ref> and standard deviation equal to 0.1. Each test was repeated 30 times, in order to assess the ABF. Figure <ref type="figure" target="#fig_9">8</ref> shows the effect of these perturbations on the optimization performances of FST-PSO. In general, we can observe that the values reported in Table <ref type="table" target="#tab_1">2</ref> represent the best choice for the optimal functioning of FST-PSO: the perturbations allowed to achieve only similar or worse results, with the exception of Ackley and Quintic functions in which different settings of U allowed to obtain slightly better results with respect to those obtained with the values listed in Table <ref type="table" target="#tab_1">2</ref>. If we compare these results with those obtained with the competitor algorithms (see Figure <ref type="figure" target="#fig_10">9</ref>), we can observe that the results described in Figures <ref type="figure" target="#fig_5">5</ref> and<ref type="figure" target="#fig_7">6</ref> are confirmed, since the ranking of the algorithms remains overall unchanged, thus proving the robustness of FST-PSO.</p><p>We also investigated the distribution of φ and δ values during the optimization process of FST-PSO. Figure <ref type="figure" target="#fig_11">10</ref> shows the distributions of φ and δ values calculated during the iterations of a single run of FST-PSO for the optimization of two peculiar benchmark functions: Rastrigin (top) and Michalewicz (bottom). Each point represents the value of φ (left) and δ (right) of a single particle at each iteration. The solid line shows the "trajectory" of such values for a single (randomly selected) particle. Even though both functions are multi-modal (as shown in Figure <ref type="figure" target="#fig_4">4</ref>), the Rastrigin function is characterized by a high number of evenly distributed local minima with similar value, while the Michalewicz function has exactly M ! narrow local minima with different values. This peculiar difference in the fitness landscapes impinges on the distribution of φ (Figure <ref type="figure" target="#fig_11">10</ref>, left): the particles moving in the search space of the Rastrigin function show small changes of φ, while the particles moving in the search space of the Michalewicz function are characterized by wide fluctuations of φ. This circumstance leads to the fast convergence of FST-PSO in the case of the Rastrigin function (faster than any competitor, as shown in Figure <ref type="figure" target="#fig_7">6</ref>). On the contrary, in the case of the Michalewicz function, the execution of opposite rules might misguide particles and slow down the convergence speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper we presented a novel self-tuning version of the PSO algorithm, starting from the concept of proactive particles in swarm optimization introduced by Nobile et al. <ref type="bibr" target="#b13">[14]</ref>. The algorithm introduced here, named FST- PSO, exploits a FRBS to dynamically adjust the values of inertia, cognitive factor, social factor, lower and upper clamping values for minimum and max-  imum velocity of the swarm particles. In particular, each particle adjusts its own values during each iteration, according to its performance, therefore turning a swarm of reactive particles typical of PSO into a population of proactive agents. Thanks to this approach, FST-PSO does not require any manual user-setting and can be used "out-of-the-box". This represents a fundamental feature to facilitate the adoption of swarm intelligence methods by inexpert users, and it is especially useful in real case applications when no a priori knowledge is available about the optimization problem under investigation.</p><p>The performance of FST-PSO was compared against different optimization methods-standard PSO, PPSO, ABC, CMA-ES, DE and GA-by exploiting twelve well known multi-dimensional and multi-modal benchmark functions. In particular, we investigated the optimization performance by analyzing the convergence speed and the Average Best Fitness obtained through 30 repetitions of each algorithm, showing that FST-PSO turns out to be the best approach in terms of convergence speed and it is also competitive concerning the best solutions found. The main competitor of FST-PSO is CMA-ES, which achieves better results in the case of Ackley, Alpine and Vincent functions. We also showed the competitiveness of FST-PSO with respect to CMA-ES on shifted/rotated benchmark functions using the CEC'13 suite: CMA-ES resulted more performing than FST-PSO only on 9 functions out of 28. In these tests, FST-PSO also outperformed standard PSO in all but one benchmark functions. However, considering the computational time required by the two methods, we observed that FST-PSO is up to 80 times faster than CMA-ES, making our method more suitable for the application to real-world problems characterized by a high number of dimensions. Moreover, since FST-PSO was implemented in pure Python code, there is still room for a further improvement of computational performances by re-implementing the method with more performing languages like C or C++.</p><p>As a future research direction, we plan to investigate alternative fuzzy inference methods, exploring the impact of different implication operators on the FST-PSO performance. We are also planning to investigate a differential modification of proactive particle's behavior-instead of the direct change of the functioning settings, which is commonly used in all versions of fuzzy PSO-in order to prevent any situation in which the consecutive application of contradictory rules might slow down the exploration capability of a particle. In addition, FST-PSO might be extended with rules able to assign negative values to the Social factor, to the aim of preserving the diversity of the swarm throughout the optimization process, thus avoiding the necessity of reboot strategies for particles <ref type="bibr" target="#b32">[33]</ref>. An additional interesting issue regards the execution of a global sensitivity analysis <ref type="bibr" target="#b33">[34]</ref> on the vertexes of the fuzzy sets for the two input variables considered in this work.</p><p>PSO is a very popular optimization method because, despite the lack of a proper convergence theorem, it has been successfully applied to many real-life problems (see <ref type="bibr" target="#b34">[35]</ref> and references therein), including the problem of kinetic parameters estimation (PE) of biological systems. As a matter of fact, PSO was empirically shown to be one of the most suitable algorithm for PE <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref>. In particular, Dräger et al. <ref type="bibr" target="#b36">[37]</ref> showed that PSO outperforms many of the algorithms that have also been tested in this paper, assumed that its functioning settings are properly selected. Therefore, as a future application we plan to integrate FST-PSO in the multi-swarm methodology for PE that we previously defined <ref type="bibr" target="#b37">[38]</ref>, in order to provide the community of Computational Systems Biology with a fully automatic methodology to determine the missing kinetic values of biochemical reaction networks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Membership functions of the linguistic values of the Distance from g variable. The membership function of Same is trapezoid (δ : 0, 0, δ 1 , δ 2 ) = {1, if 0 ≤ δ &lt; δ 1 ; (δ 2δ)/(δ 2 -δ 1 ), if δ 1 ≤ δ &lt; δ 2 ; 0, if δ 2 ≤ δ ≤ δ max }. The membership function of Near is triangle(δ : δ 1 , δ 2 , δ 3 ) = {0, if 0 ≤ δ &lt; δ 1 ; (δ -δ 1 )/(δ 2 -δ 1 ), if δ 1 ≤ δ &lt; δ 2 ; (δ 3δ)/(δ 3 -δ 2 ), if δ 2 ≤ δ &lt; δ 3 ; 0, if δ 3 ≤ δ ≤ δ max }. The membership function of Far is trapezoid (δ : δ 2 , δ 3 , δ max , δ max ) = {0, if 0 ≤ δ &lt; δ 2 ; (δ -δ 2 )/(δ 3 -δ 2 ), if δ 2 ≤ δ &lt; δ 3 ; 1, if δ 3 ≤ δ ≤ δ max }.</figDesc><graphic coords="13,207.99,379.57,194.31,145.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Membership function of the linguistic values of the Normalized fitness incremental factor variable. The membership function of Better is triangle(φ : -1, -1, 0) = {1, if φ = -1; -φ, if -1 &lt; φ &lt; 0; 0, if 0 ≤ φ ≤ 1}. The membership function of Unvaried is triangle(φ : -1, 0, 1) = 1 -|φ|. The membership function of Worse is triangle(φ : 0, 1, 1) = {0, if -1 ≤ φ &lt; 0; φ, if 0 ≤ φ &lt; 1; 1, if φ = 1}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The heatmaps show the mapping between the fuzzy value of the input variables δ and φ and the defuzzified value of the five output variables of particle i: Inertia (top left), Social (top middle), Cognitive (top right), L (bottom left) and U (bottom right), according to Tables1 and 2. Note that, in the plot of the output variable L (bottom left), the label "Medium" is not reported in the colorbar to avoid its overlap with the label "Low".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Plots of the benchmark functions (with M = 2) listed in Table3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Comparison of the optimization performances of FST-PSO (black solid line), PPSO (gray dotted line), PSO (blue dashed line), ABC (red solid line), CMA-ES (light blue solid line), DE (green solid line) and GA (orange solid line), over the benchmark functions listed in Table3. Lines and filled areas represent the ABF and the corresponding standard deviation, measured during 30 runs and 400 iterations of each algorithm (due to the logarithmic scale on the y axis, standard deviation is not represented for the Shubert and Xin-She Yang functions for the sake of readability). These results show that FST-PSO often achieves the best performance in terms of convergence speed and is competitive concerning the best solution found.</figDesc><graphic coords="22,112.77,122.47,380.82,475.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure6: Comparison of the ABF and the standard deviations evaluated after t MAX = 400 iterations of each optimization algorithm. FST-PSO (black triangles) ranks first in the case of Rastrigin and Xin-She Yang functions; it is close to CMA-ES in the case of Bohachevsky, Griewank, Quintic and Rosenbrock functions; it ranks second in the case of Ackley, Alpine and Vincent functions. In the case of the Plateau function, its performance is impaired because of the peculiar shape of the fitness landscape.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Comparison of the optimization performances of FST-PSO (black solid line), PSO (blue dashed line), and CMA-ES (light blue solid line) over the shifted/rotated CEC 2013 benchmark functions. These results show that FST-PSO outperforms standard PSO and it is largely competitive with CMA-ES.</figDesc><graphic coords="27,110.85,125.77,388.64,466.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Comparison of the ABF obtained from different perturbations of the crisp values used in FST-PSO. Inertia (yellow lines), Social (light green lines), Cognitive (pink lines), U (silver lines) and L (brown lines) refer to the perturbation of the corresponding values listed in Table2; "None" (black lines) refers to the results obtained with FST-PSO's default values.</figDesc><graphic coords="31,110.85,125.95,388.87,424.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Comparison of the ABF obtained from different perturbations of the crisp values used in FST-PSO against the ABF obtained from the competitor algorithms considered in this work: DE (dark green lines), GA (orange lines), CMA-ES (light blue lines) and ABC (red lines). The perturbations were applied to the Inertia (yellow lines), Social Factor (light green lines), Cognitive Factor (pink lines), U (silver lines), L (brown lines). "None" (black lines) corresponds to the default values used by FST-PSO.</figDesc><graphic coords="32,110.85,144.85,388.50,424.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Values of φ (left) and δ (right) in the swarm during the optimization of the Rastrigin (top) and Michalewicz (bottom) functions. Each point corresponds to the φ and δ values of a single particle of the swarm, the black solid line is used to highlight how the φ and δ values of a (randomly chosen) particle change during the iterations of the optimization. The plots are limited to the first 200 iterations for the sake of clarity.</figDesc><graphic coords="33,110.85,233.65,388.64,259.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Fuzzy rules used by FST-PSO</figDesc><table><row><cell>Rule no.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Output variables and their defuzzification</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Output variable</cell><cell></cell><cell>Term</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Low</cell><cell>Medium</cell><cell cols="2">High</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Inertia</cell><cell>0.3</cell><cell>0.5</cell><cell>1.0</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Social</cell><cell>1.0</cell><cell>2.0</cell><cell>3.0</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Cognitive</cell><cell>0.1</cell><cell>1.5</cell><cell>3.0</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>L</cell><cell>0.0</cell><cell>0.001</cell><cell cols="2">0.01</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>U</cell><cell>0.1</cell><cell>0.15</cell><cell>0.2</cell><cell></cell></row><row><cell></cell><cell>Far</cell><cell>Inertia</cell><cell></cell><cell>Far</cell><cell>Social</cell><cell></cell><cell></cell><cell>Far</cell><cell>Cognitive</cell></row><row><cell>δ</cell><cell>Near</cell><cell></cell><cell>δ</cell><cell>Near</cell><cell></cell><cell></cell><cell>δ</cell><cell>Near</cell></row><row><cell></cell><cell>Better Same</cell><cell>Same φ</cell><cell>Worse</cell><cell>Better Same</cell><cell>Same φ</cell><cell>Worse</cell><cell cols="2">Better Same</cell><cell>Same φ</cell><cell>Worse</cell></row><row><cell></cell><cell cols="2">LOW MEDIUM</cell><cell>HIGH</cell><cell>LOW</cell><cell>MEDIUM</cell><cell>HIGH</cell><cell></cell><cell>LOW</cell><cell>MEDIUM</cell><cell>HIGH</cell></row><row><cell></cell><cell>Far</cell><cell>L</cell><cell></cell><cell>Far</cell><cell>U</cell><cell></cell><cell></cell><cell></cell></row><row><cell>δ</cell><cell>Near</cell><cell></cell><cell>δ</cell><cell>Near</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Better Same</cell><cell>Same φ</cell><cell>Worse</cell><cell>Better Same</cell><cell>Same φ</cell><cell>Worse</cell><cell></cell><cell></cell></row><row><cell></cell><cell>LOW</cell><cell></cell><cell>HIGH</cell><cell>LOW</cell><cell>MEDIUM</cell><cell>HIGH</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Benchmark functions</figDesc><table><row><cell>Function</cell><cell>Equation</cell><cell>Search space</cell><cell>Value in global minimum  *</cell></row><row><cell>Ackley</cell><cell>f Ack (x) = 20 + e -20 exp(-.2 1</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Convergence speed measured as the integral of the ABF curves, calculated on every benchmark function during 400 iterations of each optimization algorithm PSO outperforms the other algorithms in the case of Rastrigin and Xin-She Yang functions, and it ranks second in 7 out of 12 test cases, that is, Ackley, Alpine, Bohachevsky, Griewank, Quintic, Rosenbrock and Vincent functions. Figure6also shows that CMA-ES and FST-PSO achieve very similar ABF in the case of Bohachevsky, Griewank, Quintic and Rosenbrock functions. Regarding the Ackley function, CMA-ES is the only algorithm able to find the global optimum within 400 iterations, while FST-PSO ranks second.</figDesc><table><row><cell>Function</cell><cell>PSO</cell><cell>PPSO</cell><cell>FST-PSO</cell><cell>ABC</cell><cell>CMA-ES</cell><cell>DE</cell><cell>GA</cell></row><row><cell>Ackley</cell><cell>5.19 • 10 3</cell><cell>4.52 • 10 3</cell><cell>2.84 • 10 3</cell><cell>6.23 • 10 3</cell><cell>1.63 • 10 3</cell><cell>6.27 • 10 3</cell><cell>4.52 •</cell></row><row><cell>Alpine</cell><cell>3.16 • 10 4</cell><cell>2.48 • 10 4</cell><cell>1.05 • 10 4</cell><cell>3.24 • 10 4</cell><cell>1.41 • 10 4</cell><cell>4.88 • 10 4</cell><cell>2.66 •</cell></row><row><cell>Bohachevsky</cell><cell>6.67 • 10 5</cell><cell>4.99 • 10 5</cell><cell>2.00 • 10 5</cell><cell>2.02 • 10 6</cell><cell>4.27 • 10 5</cell><cell>2.22 • 10 6</cell><cell>1.07 •</cell></row><row><cell>Griewank</cell><cell>8.49 • 10 4</cell><cell>6.48 • 10 4</cell><cell>2.44 • 10 4</cell><cell>2.69 • 10 5</cell><cell>5.59 • 10 4</cell><cell>2.96 • 10 5</cell><cell>1.41 •</cell></row><row><cell>Michalewicz</cell><cell>-1.24 • 10 4</cell><cell>-1.21 • 10 4</cell><cell>-1.82 • 10 4</cell><cell>-1.83 • 10 4</cell><cell>-1.04 • 10 4</cell><cell>-1.37 • 10 4</cell><cell>-2.17 • 10 4</cell></row><row><cell>Plateau</cell><cell>-1.65 • 10 5</cell><cell>-1.64 • 10 5</cell><cell>-1.09 • 10 5</cell><cell>-1.16 • 10 5</cell><cell>-1.44 • 10 5</cell><cell>-9.44 • 10 4</cell><cell>-1.35 • 10 5</cell></row><row><cell>Quintic</cell><cell>7.46 • 10 6</cell><cell>6.17 • 10 6</cell><cell>2.31 • 10 6</cell><cell>9.40 • 10 7</cell><cell>1.58 • 10 7</cell><cell>6.55 • 10 7</cell><cell>3.28 •</cell></row><row><cell>Rastrigin</cell><cell>3.19 • 10 5</cell><cell>2.57 • 10 5</cell><cell>1.44 • 10 5</cell><cell>2.73 • 10 5</cell><cell>3.18 • 10 5</cell><cell>3.87 • 10 5</cell><cell>2.48 •</cell></row><row><cell>Rosenbrock</cell><cell>8.51 • 10 7</cell><cell>7.64 • 10 7</cell><cell>4.06 • 10 7</cell><cell>7.41 • 10 8</cell><cell>1.17 • 10 8</cell><cell>4.38 • 10 8</cell><cell>2.34 •</cell></row><row><cell>Shubert</cell><cell>-1.89 • 10 65</cell><cell>-1.63 • 10 64</cell><cell>-3.51 • 10 75</cell><cell>-3.32 • 10 100</cell><cell>-4.22 • 10 79</cell><cell>-2.12 • 10 78</cell><cell>-3.57 •</cell></row><row><cell>Vincent</cell><cell>-2.39 • 10 4</cell><cell>-3.16 • 10 4</cell><cell>-3.40 • 10 4</cell><cell>-3.02 • 10 4</cell><cell>-3.09 • 10 4</cell><cell>-2.28 • 10 4</cell><cell>-3.32 • 10 4</cell></row><row><cell>Xin-She Yang</cell><cell>1.36 • 10 7</cell><cell>1.03 • 10 7</cell><cell>6.74 • 10 8</cell><cell>8.25 • 10 8</cell><cell>3.57 • 10 8</cell><cell>3.02 • 10 7</cell><cell>3.13 •</cell></row><row><cell>6, FST-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Computational time (expressed in seconds) required to execute 400 iterations of FST-PSO and CMA-ES on the Plateau, Rastrigin and Vincent functions, with an increasing number of dimensions M</figDesc><table><row><cell></cell><cell cols="2">Plateau</cell><cell cols="2">Rastrigin</cell><cell cols="2">Vincent</cell></row><row><cell>M</cell><cell>CMA-ES</cell><cell>FST-PSO</cell><cell>CMA-ES</cell><cell>FST-PSO</cell><cell>CMA-ES</cell><cell>FST-PSO</cell></row><row><cell>1</cell><cell>15.04</cell><cell>1.13</cell><cell>1.24</cell><cell>1.21</cell><cell>6.42</cell><cell>1.19</cell></row><row><cell>10</cell><cell>26.04</cell><cell>1.81</cell><cell>5.41</cell><cell>2.04</cell><cell>28.11</cell><cell>1.92</cell></row><row><cell>20</cell><cell>39.65</cell><cell>2.41</cell><cell>12.26</cell><cell>2.82</cell><cell>46.06</cell><cell>2.60</cell></row><row><cell>30</cell><cell>58.81</cell><cell>3.16</cell><cell>26.70</cell><cell>3.78</cell><cell>72.67</cell><cell>3.36</cell></row><row><cell>50</cell><cell>134.90</cell><cell>4.77</cell><cell>88.03</cell><cell>5.94</cell><cell>159.69</cell><cell>5.08</cell></row><row><cell>100</cell><cell>703.22</cell><cell>9.14</cell><cell>702.07</cell><cell>10.16</cell><cell>785.96</cell><cell>9.68</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Comparison of the optimization performances (ABF ± standard deviation) of CMA-ES and FST-PSO, given the same amount of execution time, for the optimization of the Plateau, Rastrigin and Vincent benchmark functions</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Analysis of FST-PSO settings and input variables</head><p>In order to determine the robustness of the FST-PSO algorithm with respect to the numerical values used for the defuzzification of the output variables (Table <ref type="table">2</ref>), we performed a systematic analysis consisting in the variation of each defuzzification value for each output variable. Namely, the three crisp numerical values associated with the linguistic values Low, Medium and High, were sampled from a normal distribution, clamped in</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE International Conference on Neural Networks</title>
		<meeting>IEEE International Conference on Neural Networks</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A survey of techniques for characterising fitness landscapes and some possible ways forward</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Malan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Engelbrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">241</biblScope>
			<biblScope unit="page" from="148" to="163" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Clerc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Scientific and Technical Encyclopaedia</title>
		<meeting><address><addrLine>Hoboken, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Parameter-less algorithm for evolutionary-based optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Papa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Optimization and Applications</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="209" to="229" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A new technique for dynamic size populations in genetic programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tomassini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vanneschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cuendet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fernández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="486" to="493" />
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An adaptive particle swarm optimization with multiple adaptive methods</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Weir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="705" to="720" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Langari</surname></persName>
		</author>
		<title level="m">Fuzzy Logic: Intelligence, Control, and Information</title>
		<meeting><address><addrLine>Upper Saddle River, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fuzzy adaptive particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="101" to="106" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Fuzzy Rule-Based Systems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Magdalena</surname></persName>
		</author>
		<editor>J. Kacprzyk, W. Pedrycz</editor>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="203" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Turbulent particle swarm optimization using fuzzy parameter tuning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations of Computational Intelligence</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A.-E</forename><surname>Hassanien</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Siarry</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Engelbrecht</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="291" to="312" />
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fuzzy particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings JCAI&apos;09. International Joint Conference on Artificial Intelligence</title>
		<meeting>JCAI&apos;09. International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="263" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Fuzzy Logic Augmentation of Nature-Inspired Optimization Metaheuristics</title>
		<editor>O. Castillo, P. Melin</editor>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Parameter selection in particle swarm optimisation: a survey</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Rezaee</forename><surname>Jordehi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jasni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental and Theoretical Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="527" to="542" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Proactive particles in swarm optimization: a self-tuning algorithm based on fuzzy logic</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nobile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cazzaniga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Besozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mauri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 2016 IEEE International Conference on Fuzzy Systems</title>
		<meeting>2016 IEEE International Conference on Fuzzy Systems</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A powerful and efficient algorithm for numerical function optimization: artificial bee colony (ABC) algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Basturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="459" to="471" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adapting arbitrary normal mutation distributions in evolution strategies: The covariance matrix adaptation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ostermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1996 IEEE International Conference on Evolutionary Computation</title>
		<meeting>1996 IEEE International Conference on Evolutionary Computation</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="312" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Adaptation in Natural and Artificial Systems, The University of</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>Michigan Press</publisher>
			<pubPlace>Ann Arbor, Michigan, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">No free lunch theorems for optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Macready</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="82" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The impact of particles initialization in PSO: Parameter estimation as a case in point</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cazzaniga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nobile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Besozzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)</title>
		<meeting>the 2015 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Poli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Blackwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="57" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Boundary conditions in particle swarm optimization revisited</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rahmat-Samii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Antennas and Propagation</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="760" to="765" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Impacts of invariance in search: When CMA-ES and PSO face ill-conditioned and non-separable problems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mauny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="5755" to="5769" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Proactive Particles in Swarm Optimization: a settings-free algorithm for real-parameter single objective optimization problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tangherloni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rundo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nobile</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Computation (CEC)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="1940" to="1947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Why triangular membership functions?</title>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fuzzy Sets and Systems</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="30" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Industrial Applications of Fuzzy Control</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sugeno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Elsevier Science Inc</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
		<title level="m">Practical Methods of Optimization</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Python for scientific computing</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Oliphant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science and Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="10" to="20" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">PyGMO and PyKEP: open source tools for massively parallel optimization in astrodynamics (the case of interplanetary trajectory optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Izzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Astrodynamics Tools and Techniques</title>
		<meeting>the Fifth International Conference on Astrodynamics Tools and Techniques</meeting>
		<imprint>
			<publisher>ICATT</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Comparing results of 31 algorithms from the black-box optimization benchmarking BBOB-2009</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Finck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pošík</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th annual conference companion on Genetic and evolutionary computation</title>
		<meeting>the 12th annual conference companion on Genetic and evolutionary computation</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1689" to="1696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The CMA evolution strategy: a comparing review</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Towards a New Evolutionary Computation. Advances on Estimation of Distribution Algorithms</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Lozano</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Larranaga</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Inza</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Bengoetxea</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="75" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A comparative study of differential evolution variants for global optimization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mezura-Montes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Velázquez-Reyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Coello Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation</title>
		<meeting>the 8th Annual Conference on Genetic and Evolutionary Computation</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="485" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Reboot strategies in particle swarm optimization and their impact on parameter estimation of biochemical systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Spolaor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tangherloni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rundo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nobile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cazzaniga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics and Computational Biology (CIBCB)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Accepted</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Saltelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ratto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Campolongo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cariboni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gatelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saisana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tarantola</surname></persName>
		</author>
		<title level="m">Global Sensitivity Analysis: The Primer</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley-Interscience</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Analysis of the publications on the applications of particle swarm optimisation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Poli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Evolution and Applications</title>
		<imprint>
			<biblScope unit="page" from="2" to="10" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A comparison of genetic algorithms and particle swarm optimization for parameter estimation in stochastic biochemical systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Besozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cazzaniga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mauri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pescini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vanneschi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Computation, Machine Learning and Data Mining</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Pizzuti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Ritchie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Giacobini</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5483</biblScope>
			<biblScope unit="page" from="116" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Modeling metabolic networks in C. glutamicum: a comparison of rate laws in combination with various parameter optimization strategies</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dräger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kronfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Ziller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Supper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Planatscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Magnus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Systems Biology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A GPUbased multi-swarm PSO method for parameter estimation in stochastic biological systems exploiting discrete-time target series</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nobile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Besozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cazzaniga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mauri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pescini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation, Machine Learning and Data Mining in Bioinformatics</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Giacobini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Vanneschi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Bush</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">7246</biblScope>
			<biblScope unit="page" from="74" to="85" />
			<date type="published" when="2012">2012</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
