<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Domain Transformation-Based Efficient Cost Aggregation for Local Stereo Matching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Cuong</forename><forename type="middle">Cao</forename><surname>Pham</surname></persName>
							<email>cuongpc@skku.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Sungkyunkwan University</orgName>
								<address>
									<postCode>440-746</postCode>
									<settlement>Suwon</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Jae</forename><forename type="middle">Wook</forename><surname>Jeon</surname></persName>
							<email>jwjeon@yurim.skku.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Communication Engineering</orgName>
								<orgName type="institution">Sungkyunkwan University</orgName>
								<address>
									<postCode>440-746</postCode>
									<settlement>Suwon</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Domain Transformation-Based Efficient Cost Aggregation for Local Stereo Matching</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6D8CFF93267837E25E0478A620A50FF2</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Domain transformation</term>
					<term>local stereo matching</term>
					<term>cost aggregation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Binocular stereo matching is one of the most important algorithms in the field of computer vision. Adaptive support-weight approaches, the current state-of-the-art local methods, produce results comparable to those generated by global methods. However, excessive time consumption is the main problem of these algorithms since the computational complexity is proportionally related to the support window size. In this paper, we present a novel cost aggregation method inspired by domain transformation, a recently proposed dimensionality reduction technique. This transformation enables the aggregation of 2D cost data to be performed using a sequence of 1D filters, which lowers computation and memory costs compared to conventional 2D filters. Experiments show that the proposed method outperforms the state-of-the-art local methods in terms of computational performance, since its computational complexity is independent of the input parameters. Furthermore, according to the experimental results with the Middlebury dataset and realworld images, our algorithm is currently one of the most accurate and efficient local algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>B INOCULAR stereo matching has attracted much interest over the past few decades and remains one of the most active research areas. The problem is to estimate the disparity maps from two rectified images of the same scene taken from different viewpoints. Intuitively, the disparity map represents the displacement vectors between corresponding pixels that horizontally shift from the left image to the right image. A large number of studies have been conducted to solve this problem to provide high accuracy and fast execution. Extensive reviews of the state-of-the-art methods can be found in <ref type="bibr" target="#b0">[1]</ref> <ref type="bibr" target="#b1">[2]</ref>, and the Middlebury website <ref type="bibr" target="#b2">[3]</ref> also gives a review of the latest methods. According to their strategy used for estimation, these methods can be categorized into global and local approaches. Generally, global methods produce more precise results, whereas the computational performance of local methods is more efficient.</p><p>The key to understanding local algorithms lies in the cost aggregation step in which each cost slide corresponding to each possible disparity d is aggregated before computing the disparity map. Information about neighboring pixels within a finite-size support window will be propagated toward the candidate pixel. The use of local support windows is due to the fronto-parallel surfaces assumption in which all pixels belonging to the same region are supposed to have the same depth. Numerous local methods have been proposed in the literature, and adaptive support-weight approaches <ref type="bibr" target="#b3">[4]</ref> <ref type="bibr" target="#b4">[5]</ref> currently represent the state-of-the-art local algorithms. These approaches produce results comparable to those generated by global methods. The key idea behind their success is the use of locally adaptive support-weights to compute the probability that the center pixel and a neighbor pixel might belong to the same region. In particular, in the original method proposed by Yoon and Kweon <ref type="bibr" target="#b3">[4]</ref>, this probability is computed using the bilateral filter weight <ref type="bibr" target="#b5">[6]</ref>, whereas the geodesic distance was used by Hosni et al. <ref type="bibr" target="#b4">[5]</ref>.</p><p>Although they are implemented efficiently, excessive time consumption is the main concern of adaptive support-weight algorithms. The computational complexity is quadratically related to the support window size. This creates a bottleneck in CPUs and commercially available hardware. Several acceleration techniques have been proposed in an attempt to reduce processing time <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b12">[13]</ref>. However, this was all done at the expense of reducing estimation accuracy.</p><p>In this paper, we present a novel cost aggregation technique that is able to simultaneously achieve high precision and fast execution thanks to domain transformation, a recently proposed dimensionality reduction technique <ref type="bibr" target="#b13">[14]</ref>. The key contribution of this work is to integrate the appealing properties of this technique into the cost aggregation of stereo vision. Our algorithm is currently one of the best-performing local algorithms on the Middlebury ranking website <ref type="bibr" target="#b2">[3]</ref>. The algorithm also works very well with real-world images even with the presence of noise. Furthermore, the computational performance of our algorithm also outperforms the state-ofthe-art local methods since its computational complexity is independent of the input parameters.</p><p>The remainder of this paper is structured as follows. Section II presents the related local algorithms. Section III presents the proposed cost aggregation technique using domain transformation. Section IV presents the stereo matching algorithm involving pixel-wise cost computation, disparity optimization, and disparity refinement. Section V presents the experimental results with the Middlebury dataset and real-world images captured from camcorders to compare our method to those in the literature. Section VI concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED LOCAL ALGORITHMS</head><p>A stereo algorithm generally consists of four steps: cost computation, cost aggregation, disparity optimization, and refinement <ref type="bibr" target="#b0">[1]</ref> <ref type="bibr" target="#b1">[2]</ref>. Among these steps, cost aggregation is the core component that determines the estimated disparity map precision. Various cost aggregation types have been proposed, and were recently evaluated <ref type="bibr" target="#b14">[15]</ref> <ref type="bibr" target="#b15">[16]</ref>.</p><p>The multiple-and variable-window approaches were introduced in the early development stage of the local algorithm. In brief, the strategy used to aggregate costs in the multiplewindow approach <ref type="bibr" target="#b16">[17]</ref> <ref type="bibr" target="#b17">[18]</ref> is to select the lowest-cost support window from a set of pre-defined windows, while computing an optimal support window for each pixel is the strategy of the variable-window approach <ref type="bibr" target="#b18">[19]</ref> <ref type="bibr" target="#b19">[20]</ref>. The results generated from these approaches are of low quality due to the edgefattening problem <ref type="bibr" target="#b3">[4]</ref> <ref type="bibr" target="#b20">[21]</ref>. A significant difference remains between the global and local approaches. This gap has actually been reduced since the innovation of Yoon and Kweon's method <ref type="bibr" target="#b3">[4]</ref>. This is the most well-known local method, and still represents the state-of-the-art local algorithm.</p><p>In order to express the formula representation of this approach, we first denote Ω p and Ω pd as the fixed-size support windows centered at pixels p and pd in the left image I and the right image Ī, respectively. The raw pixel-wise matching cost corresponding to each disparity d is also denoted by C d . According to Yoon and Kweon <ref type="bibr" target="#b3">[4]</ref>, each output value of the aggregated cost C ′ d is computed as a weighted mean of its neighbors. The weight represents the probability that two pixels lie within the same region. It is formally expressed as follows:</p><formula xml:id="formula_0">C ′ d (p) = ∑ q∈Ω p , qd ∈Ω pd w pq (I) w p qd ( Ī)C d (q) ∑ q∈Ω p , qd ∈Ω pd w pq (I) w p qd ( Ī)<label>(1)</label></formula><p>where w pq (I) is the probability as previously mentioned. It is computed based on the color difference and spatial information and is given by:</p><formula xml:id="formula_1">w pq (I) = exp ( - ( ∆s pq γ s + ∆I pq γ r ))<label>(2)</label></formula><p>where ∆s pq and ∆I pq are the Euclidean distances of the spatiality and color difference between two pixels in the CIELab color space, respectively. Accordingly, higher weights are assigned to pixels that are closer and similar to the center pixel, while lower weights are assigned to distant pixels and to pixels that differ from the center pixel. Two constant parameters γ s and γ r control the influence of the weights in the aforementioned distances. Hosni et al. <ref type="bibr" target="#b4">[5]</ref> utilized the geodesic distance to compute the support weights. The accuracy of the estimated disparity maps is reportedly better than that of Yoon and Kweon's algorithm. Even though it is not explicitly stated it in the paper <ref type="bibr" target="#b3">[4]</ref>, we can easily observe that the weighting function expressed in equation ( <ref type="formula" target="#formula_1">2</ref>) is identical to that of the bilateral filter weight <ref type="bibr" target="#b5">[6]</ref> in which the standard deviation parameters σ s (γ s = 2σ 2 s ) and σ r (γ r = 2σ 2 r ) control the influence of the weights in the spatial and intensity domain, respectively. The computational complexity of the bilateral filter is quadratically related to the filter kernel size. As a consequence, this algorithm performs very slowly since the support window must be sufficiently large <ref type="bibr">(35 × 35 in [4]</ref>) to achieve accurate results.</p><p>To address this time consumption problem, several acceleration techniques for adaptive-weight approaches have been proposed in an attempt to reduce the processing time. For instance, Wang et al. <ref type="bibr" target="#b6">[7]</ref> first introduced a two-pass aggregation scheme using adaptive-weight cost aggregation along with the vertical and horizontal directions. Zhang et al. <ref type="bibr" target="#b7">[8]</ref> also separately performed horizontal and vertical passes for cost aggregation using orthogonal integral images. Yu et al. <ref type="bibr" target="#b8">[9]</ref> proposed another two-pass approximation approach using exponential step-size adaptive weights that drastically reduces the computational complexity of cost aggregation. Mattoccia et al. <ref type="bibr" target="#b9">[10]</ref> combined the efficiency of the "Summed-Area Table" <ref type="bibr" target="#b21">[22]</ref> and the adaptive-weight approach to propose fast bilateral stereo. Most recently, Richardt et al. <ref type="bibr" target="#b10">[11]</ref> extended the principle of the bilateral grid <ref type="bibr" target="#b22">[23]</ref> to propose the dual-crossbilateral grid for approximately and quickly computing the bilateral filter weights on a GPU. The computation time of the aforementioned methods is effectively reduced compared to that of the conventional adaptive-weight algorithm. However, all this has been done at the expense of reducing the output quality. This is also the case for the accelerated version of the geodesic support-weight algorithm <ref type="bibr" target="#b11">[12]</ref> proposed by the same author.</p><p>In contrast to the bilateral filter <ref type="bibr" target="#b5">[6]</ref>, which inspired the early development of local stereo matching, the use of anisotropic diffusion <ref type="bibr" target="#b23">[24]</ref>[25] was later discovered <ref type="bibr">[26][27]</ref>. This is an iterative image filtering technique originally used for image restoration and image segmentation. The direct implementation of anisotropic diffusion using the Geman and McClure diffusivity function <ref type="bibr" target="#b27">[28]</ref> has been tested <ref type="bibr" target="#b25">[26]</ref>. Nevertheless, the disparity maps generated from this implementation are imprecise. Instead, the author proposed another iterative solution for improving the estimation accuracy. Most recently, De-Maeztu et al. <ref type="bibr" target="#b26">[27]</ref> modified the Penora-Malik model <ref type="bibr" target="#b23">[24]</ref> to propose geodesic diffusion, which diffuses both costs and weights in the aggregation stage to improve the disparity map precision. The convergence time (number of iterations) of this approach is also reported to be less than that of the original Penora-Malik model.</p><p>Currently, one of the most accurate local algorithms is fast cost-volume filtering. Rhemann et al. <ref type="bibr" target="#b20">[21]</ref> utilized the guided filter <ref type="bibr" target="#b28">[29]</ref> to asymmetrically perform the aggregation procedure. De-Maeztu et al. <ref type="bibr" target="#b29">[30]</ref> also proposed a very similar guided filter-based approach for symmetrically aggregating costs. Since the computational complexity of the guided filter is independent of the support window size, the computational performance of these methods is obviously better than the conventional adaptive-weight algorithms. Specifically, in costvolume filtering <ref type="bibr" target="#b20">[21]</ref>, the locally adaptive support-weight is computed by:</p><formula xml:id="formula_2">w pq (I) = 1 |Ω| 2 ∑ k:(p,q)∈Ω k ( 1 + (I p -Īk ) T ( ∑ k + εU ) -1 (I q -Ī) )</formula><p>(3) where ∑ k and Īk are the covariance and mean matrices of the left image I within the window Ω k centered at pixel k, respectively. |Ω| is the total number of pixels in the support window, while ε is the smoothing parameter. Despite the computational complexity of this method being independent of the support window size, we must perform a sequence of 18 box filters and one 3 × 3 matrix inversion operation for each pixel. This cost is even more expensive for the symmetric approach <ref type="bibr" target="#b29">[30]</ref>, in which 51 box filters are required and the covariance matrices are 6 × 6.</p><p>Finally, the information permeability algorithm is the method most related to our work. Cigla et al. <ref type="bibr" target="#b30">[31]</ref> separately performed horizontal and vertical aggregations using a similar 1D filter model with separable successive weighted summation along each direction. A simple exponential function is utilized for computing the similarity between two neighboring pixels. Nevertheless, our method with the use of domain transformation <ref type="bibr" target="#b13">[14]</ref> yields higher estimation accuracy. Domain transformation is a dimensionality reduction technique used in image processing. By exploiting the geodesic distance computed from the transformed domain, we perform a sequence of 1D operations to accomplish the aggregation step. The results generated by our method are superior to those generated by the state-of-the-art local methods with lower computational requirements. It will be formalized in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED COST AGGREGATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Aggregating 1D Cost Data</head><p>As we briefly mentioned above, our work is directly inspired by the novel domain transformation technique <ref type="bibr" target="#b13">[14]</ref>. This is a dimensionality reduction technique that defines a geodesic distance-preserving representation of a 2D image embedded in 5D (x, y, I r , I g , I b ) spatial-color space as a real line. The transformation enables the aggregation of 2D cost data to be accomplished using a sequence of 1D filters. The major advantage of 1D operations compared to conventional 2D operations is their lower computational requirements <ref type="bibr" target="#b13">[14]</ref>, which is the main motivation of our work. The entire proposed algorithm involving cost computation, cost aggregation, disparity optimization, and post-processing is shown in the block diagram representation in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>To begin with, we first express the 1D discrete signal plotted from each row along the x direction of the cost slide C d as C d,y [n] = C d (x n , y). As published previously <ref type="bibr" target="#b31">[32]</ref>, the feedback comb filter applied to this signal can be expressed as follows: where C ′ d,y denotes the output signal and a ∈ [0, 1] is the feedback coefficient as it is weighted on the past output values. When there is no feedback (a = 0), the filter has a finite impulse response, and the input and output signals are identical. Conversely, when a ̸ = 0, the filter is recursive and has an infinite impulse response.</p><formula xml:id="formula_3">C ′ d,y [n] = C d,y [n] + aC ′ d,y [n -1]<label>(4)</label></formula><p>Let us give our general point of view. It is desirable to smooth the cost data using an edge-aware filter. In this context, the conventional adaptive-weight algorithm <ref type="bibr" target="#b3">[4]</ref> utilized the symmetric bilateral filter to perform this procedure. Correspondingly, the geodesic diffusion <ref type="bibr" target="#b26">[27]</ref> and cost-volume filtering <ref type="bibr" target="#b20">[21]</ref> algorithms utilized the anisotropic diffusion <ref type="bibr" target="#b23">[24]</ref> and guided filter <ref type="bibr" target="#b28">[29]</ref>, respectively. The current filter expressed in equation ( <ref type="formula" target="#formula_3">4</ref>) is a non-edge-aware filter, since the coefficient a is consistently applied across the entire signal. Ideally, we can set a high value of a for increasing the propagation between two similar samples, x n-1 and x n . On the other hand, while the two samples are different, such as at the discontinuities of the signal, the value of a should be sufficiently small for preventing the propagation chain, so that the discontinuities can be preserved. Letting g be some chosen metric representing the dissimilarity between two samples, the edge-aware feedback comb filter is then given by:</p><formula xml:id="formula_4">C ′ d,y [n] = C d,y [n] + a g C ′ d,y [n -1]<label>(5)</label></formula><p>Here, we compute the metric g as the distance between two samples in the 1D domain that is transformed from the corresponding row of the guidance image I, which is the left image in our case. In general, each cost slide C d of the raw matching costs is aggregated under the guidance of the left image for the asymmetric approach <ref type="bibr" target="#b4">[5]</ref>[21], or both the left and right images for the symmetric approach <ref type="bibr" target="#b3">[4]</ref>[27] <ref type="bibr" target="#b29">[30]</ref>. Our proposed method is therefore an asymmetric one. The derivation procedure of the domain transform for computing the metric g is presented in the next subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Domain Transform</head><p>To address the computation of the distance g expressed in equation ( <ref type="formula" target="#formula_4">5</ref>), we first present the geodesic distance-preserving transforming procedure of a 1D signal I embedded in 2D (x, I (x)) space into a new 1D domain via a transformation t: R 2 → R, for simplicity. The input signal is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>. The domain transform <ref type="bibr" target="#b13">[14]</ref> states that the L 1 distance between two neighboring points in the original domain R 2 and the distance between two corresponding samples in the new dimensionality reduction domain R must be equal:</p><formula xml:id="formula_5">gt (x + h) -gt (x) = h + |I (x + h) -I (x)|<label>(6)</label></formula><p>where gt (x) = t (x, I (x)) represents the transformation operator at point x. Following the derived strategy presented in <ref type="bibr" target="#b13">[14]</ref>, we divide both sides of equation ( <ref type="formula" target="#formula_5">6</ref>) by h and take the limit as h → 0. The obtained result is the derivative of gt (x) with respect to x:</p><formula xml:id="formula_6">gt ′ (x) = 1 + I ′ (x)<label>(7)</label></formula><p>Therefore, the value at any point u in the transformed domain can easily be computed by taking the integral of gt ′ (x) from 0 to u and is given by:</p><formula xml:id="formula_7">gt (u) = ∫ u 0 1 + I ′ (x) dx<label>(8)</label></formula><p>The distance between any two points u and v in the transformed domain, which corresponds to the arc length from u to v of the signal I, is also subsequently computed by:</p><formula xml:id="formula_8">gt (v) -gt (u) = ∫ v u 1 + I ′ (x) dx (9)</formula><p>The analysis presented in <ref type="bibr" target="#b13">[14]</ref> shows that we can also control the influence of spatial and intensity range information similar to the bilateral filter <ref type="bibr" target="#b5">[6]</ref> by embedding the values of σ s and σ r in the transformation:</p><formula xml:id="formula_9">gt (u) = ∫ u 0 1 + σ s σ r I ′ (x) dx (10)</formula><p>This is an excellent property since we do not lose the controllability of spatial and intensity information in spite of using lower dimensionality. For multichannel signals such as 1D signals embedded in 4D (x, I r , I g , I b ) space plotted from each row of a color image, the transformation is possibly expressed as:</p><formula xml:id="formula_10">gt (u) = ∫ u 0 1 + σ s σ r max ( I ′ r (x) , I ′ g (x) , I ′ b (x) ) dx (11)</formula><p>Here we select the maximum absolute difference to define the distance between two points in the original domain, and other metrics such as the sum of absolute difference are also applicable <ref type="bibr" target="#b13">[14]</ref>. Consequently, the final distance g used in this work is then computed by:</p><formula xml:id="formula_11">g = ∫ v u 1 + σ s σ r max ( I ′ r (x) , I ′ g (x) , I ′ b (x) ) dx (12)</formula><p>To illustrate the efficiency of the edge-aware filter with the participation of the distance g given in equation ( <ref type="formula" target="#formula_4">5</ref>) over the non-edge-aware filter given in equation ( <ref type="formula" target="#formula_3">4</ref>), we show some sample disparity maps generated by the proposed method using the two filters in Fig. <ref type="figure" target="#fig_2">3</ref>. It is evident that when the In contrast, the edge-aware filter is more robust in handling the disparity discontinuities. The obtained disparity maps are more accurate, as shown in Fig. <ref type="figure" target="#fig_2">3(c)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Aggregating 2D Cost Data</head><p>We have so far presented the edge-aware 1D filtering and the transformation t: R d+1 → R. To actually perform 2D filtering, we need to derive a 2D transformation t ′ : R d+2 → R 2 . However, as discussed in <ref type="bibr" target="#b13">[14]</ref> <ref type="bibr" target="#b32">[33]</ref>, such transformations do not generally exist. Instead, Gastal et al. <ref type="bibr" target="#b13">[14]</ref> suggested that we can filter 2D signals using a chain of 1D operations by performing separate filtering. The horizontal and vertical passes are conducted for each row and column, respectively. More precisely, the horizontal pass is first performed using the initial input signals, and the vertical pass is then carried out using the horizontal filtered output.</p><p>Applying the aforementioned strategy to the cost aggregation step of the stereo algorithm, vertical aggregation is followed by horizontal aggregation. The raw matching costs are aggregated using horizontal aggregation, and the horizontal aggregated costs are used as the input matching vertical aggregation costs.</p><p>The current edge-aware feedback comb filter expressed in equation ( <ref type="formula" target="#formula_4">5</ref>) is a causal filter, as the computation of the current output depends only on the past and current inputs <ref type="bibr" target="#b33">[34]</ref>. Therefore, its impulse response is asymmetric. To exploit the symmetric nature of the image, we follow the strategy derived in <ref type="bibr" target="#b13">[14]</ref> by respectively performing the filter from left-to-right (L) and from right-to-left (R) for horizontal aggregation. The procedure is formally expressed as follows:</p><formula xml:id="formula_12">C L d,y [n] = C d,y [n] + a g n C L d,y [n -1] (13) C R d,y [n] = C L d,y [n] + a g n+1 C R d,y [n + 1]<label>(14)</label></formula><p>Correspondingly, the vertical aggregation is then carried out from top-to-bottom (T ) and from bottom-to-top (B):  -calculate the gradient dX and dY for three color</p><formula xml:id="formula_13">C T d,x [m] = C R d,x [m] + a g m C T d,x [m -1]<label>(15)</label></formula><formula xml:id="formula_14">5 channels R, G, B; gH (x, y) = 1 + σ max (dX R , dX G , dX B ) 6 gV (x, y) = 1 + σ max (dY R , dY G , dY B ) 7 a ← exp ( -1 / σ H ) ; // σ H = σ s 8 foreach cost slide C d in C do 9 C L d ← ApplyFeedbackFilterL (C d , gH, a); 10 C R d ← ApplyFeedbackFilterR ( C L d , gH, a ) ; 11 CT R d = Transpose ( C R d ) ; 12 C T d ← ApplyFeedbackFilterL ( CT R d , gV, a ) ; 13 C B d ← ApplyFeedbackFilterR ( C T d , gV, a ) ; 14 C ′ d = Transpose ( C B d ) ; 15 end 16 C B d,x [m] = C T d,x [m] + a g m+1 C B d,x [m + 1]<label>(16)</label></formula><p>where</p><formula xml:id="formula_15">C d,x [m] = C d (x, y m )</formula><p>is the 1D discrete signal plotted from each column along the y direction of the cost slide C d . Last, the value of coefficient a is consistently configured as:</p><formula xml:id="formula_16">a = exp ( -1 / σ H )<label>(17)</label></formula><p>where σ H is the kernel standard deviation that is implicitly set to σ s <ref type="bibr" target="#b13">[14]</ref>. Based on the configured parameters that were analyzed and experimentally examined in <ref type="bibr" target="#b13">[14]</ref>, we empirically found that the combination of σ s ∈ [10, 300] and σ r ∈ [0.01, 0.3] can yield good visual disparity results. More precisely, we can set small values of σ r to enforce edge preservation, since only a small difference between two pixels is sufficient to allow the propagation to proceed. Similarly, we are able to control the amount of smoothing by adjusting the value of σ s , since small or large values of σ s will result in the decrement or increment of the smoothing effect. It is interestingly noted that the disparity results with σ s approaching infinity are very similar. Hence, we set the maximum value of σ s to 300 as an upper bound for simplicity. Furthermore, when either σ r or σ s equals zero, no aggregation is performed, and the aggregated costs are identical to the raw matching costs.</p><p>The process with separate horizontal and vertical filtering is illustrated in Fig. <ref type="figure" target="#fig_3">4</ref>, and the entire procedure of the proposed cost aggregation is shown in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. STEREO MATCHING ALGORITHM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Pixel-wise Cost Computation</head><p>Regarding the matching costs, we briefly analyze the computation in this subsection. As mentioned in the beginning of Section II, pixel-wise cost computation is the very first step of a stereo algorithm. It also plays an essential role in determining the disparity map precision. One of the simplest measures is the truncated absolute difference (TAD) of the color. For each pixel, the cost is intuitively computed as the minimum value between the sum of absolute difference of the color and the user-defined truncation value. It is formally expressed as follows:</p><formula xml:id="formula_17">C COLOR d (p) = min ( 3 ∑ i=1 |I i (p) -Īi (p -d)|, T c )<label>(18)</label></formula><p>where I i (p) is the intensity value of the i-th color channel in the RGB color space at pixel p of the image I, and T c is the color truncation value. This measure has been widely used due to its computational simplicity. However, it does not cope well with the illumination distortion that usually occurs. Several advanced metrics were recently evaluated <ref type="bibr" target="#b34">[35]</ref>. For instance, the entropy-based hierarchical mutual information (HMI) <ref type="bibr" target="#b35">[36]</ref> has been proven to be more robust against the distortion of illumination. However, the computation of mutual information requires the presence of the disparity map that is actually being computed. The hierarchical approach has been deployed to solve this problem by computing the disparity from down-scaled images. A coarse disparity map is randomly generated in the beginning. The concern is that this approach is not suitable for large images that are common today.</p><p>In this work, we adopt the metric proposed in <ref type="bibr" target="#b20">[21]</ref> that combines the TAD of the color and the gradient at the matching pixels. The participation of the gradient in the matching measure makes this metric become more robust to illumination distortion, similar to HMI. The computation is simple and suitable, even for arbitrarily large images. In a manner similar to equation ( <ref type="formula" target="#formula_17">18</ref>), the TAD of the gradient is given by:</p><formula xml:id="formula_18">C GRAD d (p) = min (|∇ x (I (p)) -∇ x ( Ī (p -d))| , T g )<label>(19)</label></formula><p>where ∇ x (I (p)) is the gradient in the x direction at pixel p taken from the image I. T g is the gradient truncation value.</p><p>The final cost data is subsequently computed by</p><formula xml:id="formula_19">C d (p) = λ •C COLOR d (p) + (1 -λ ) •C GRAD d (p)<label>(20)</label></formula><p>where λ controls the trade-off between the two metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Disparity Optimization and Refinement</head><p>The disparity optimization step is performed using the most well-known winner-take-all (WTA) strategy in which each disparity is selected to correspond to the minimum aggregated costs as follows:</p><formula xml:id="formula_20">d p = arg min d∈S d C ′ d (p)<label>(21)</label></formula><p>where S d is the set of all possible disparities. The disparity maps obtained at this stage contain errors in the occluded regions. To handle occlusion, we perform the common left-right consistency check since the disparity is computed for both the left view and the right view. A pixel in the left disparity map is marked as invalidated when its value differs from the corresponding value of the pixel in the right disparity map by a value greater than one. To fill the detected invalidated pixels, we assign the minimum value between two closest validated pixels to the left and to the right of the pixel being computed. This is due to the nature of the occlusion in which the occluded pixels belong primarily to the background objects.</p><p>Finally, we smooth the disparity map using a weighted median filter to remove streak-like artifacts that usually occur in the occlusion handling step, and a median filter for removing the small amount of remaining noise. In a manner similar to cost-volume filtering <ref type="bibr" target="#b20">[21]</ref>, we select the bilateral filter weight <ref type="bibr" target="#b5">[6]</ref> expressed in equation ( <ref type="formula" target="#formula_1">2</ref>) to compute the weighted median filter. The validated pixels are not affected by this operation. Fig. <ref type="figure" target="#fig_5">5</ref> shows a sample consistency map and the post-processed result of the Venus image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL RESULTS AND DISCUSSIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Middlebury Dataset</head><p>In this subsection, we present the experimental results using four stereo pairs (Tsukuba, Venus, Teddy, and Cones) obtained from the Middlebury stereo evaluation website <ref type="bibr" target="#b2">[3]</ref>. We evaluated the results using the percentage of bad pixels that is computed according to <ref type="bibr" target="#b0">[1]</ref> <ref type="bibr" target="#b2">[3]</ref>.</p><p>Currently, the results published on the Middlebury evaluation website were generated using different cost computation and post-processing techniques. Therefore, apart from comparing the results of our algorithm to these published results of related local algorithms, we first compare the performance of the raw cost aggregation methods used in these studies. The same pixel-wise cost computation and disparity optimization steps were installed to ensure fair comparison. Additionally, no occlusion handling or post-processing steps were conducted in this test. We compare our approach with the original adaptive support-weight method (AdaptWeight) <ref type="bibr" target="#b3">[4]</ref>, geodesic diffusion (GeoDif) <ref type="bibr" target="#b26">[27]</ref>, fast cost-volume filtering (CostFilter) <ref type="bibr" target="#b20">[21]</ref>, and information permeability (InfoPermeable) <ref type="bibr" target="#b30">[31]</ref> in this test. The reason for this choice is that these methods are not only the best-performing local methods, the cost aggregations used in these algorithms were also inspired by several well-known edge-aware filters as previously mentioned. For instance, the first three methods utilized the bilateral filter <ref type="bibr" target="#b5">[6]</ref>, anisotropic diffusion <ref type="bibr" target="#b23">[24]</ref>, and guided filter <ref type="bibr" target="#b28">[29]</ref>, respectively. The last method was selected as it is related to our algorithm.</p><p>Throughout all the experiments in this paper, we selected the TAD of the color and the gradient for computing matching costs as presented in Section IV-A. The cost computation's parameters were also consistently configured as { λ , T c , T g } = {0.1, 7/255, 2/255}. The parameters of the five aggregation techniques were empirically found to obtain optimal results that yield good trade-off between four stereo pairs in this first test. Although different parameters can be set dynamically for each stereo pair to achieve better results, consistent parameters were exploited for fair comparison and simplicity. For the AdaptWeight, the chosen parameters are a 35 × 35 support window with γ s = 17 and γ r = 7.5. The GeoDif aggregation was iterated n = 24 times with γ c = 40 and l 0 = 0.15. For the CostFilter, the parameter values are a 19 × 19 support window and ε = 0.0004. The exponential function with σ = 25 was used for InfoPermeable. Finally, our algorithm's parameters were set to {σ s , σ r } = {25, 0.1}. The guidance images used for the aggregation stage were filtered using a 3 × 3 median filter to reduce the high-frequency information that is not actually useful for cost aggregation as the two slightly different pixels are still expected to have the same depth.</p><p>As the occlusion handling and post-processing were not installed in this test, the disparity maps in occluded regions still contain errors. Therefore, we compared only the percentage of erroneous pixels at the non-occluded and discontinuity regions. The Middlebury stereo website <ref type="bibr" target="#b2">[3]</ref> provides the "nonocc" and "disc" groundtruth images for the four stereo pairs. Therefore, computing the errors in those regions is straightforward. Under these circumstances, the percentage of bad pixels of the five competitive algorithms are shown in Tables <ref type="table" target="#tab_0">I</ref> and<ref type="table" target="#tab_0">II</ref>, and the  raw disparity maps are shown in Fig. <ref type="figure" target="#fig_7">6</ref>. In general, the visual results show that all competitive methods produced comparable results for most cases. Actually, we can dynamically select different parameters for each stereo pair to obtain better results as previously mentioned. For instance, our proposed method can yield better results for the Tsukuba image by choosing different parameters. However, we reported only the results with consistent parameters for fair comparison and simplicity. Nevertheless, for quantitative evaluation, our proposed method yielded the smallest average percentage of erroneous pixels in non-occluded regions, while AdaptWeight yielded the smallest errors in discontinuity regions. Accordingly, the InfoPermeable produced less accurate results compared to those generated by our algorithm, and the GeoDif yielded the largest errors in both regions. It is interesting to note that even though the GeoDif outperforms AdaptWeight on the Middlebury ranking website, the performance of AdaptWeight was better than GeoDif in this test. This can be explained by the fact that the published AdaptWeight results were generated using the simple TAD of the color for computing costs, whereas the GeoDif utilized the more robust HMI. Finally, the CostFilter produced results comparable to those generated from our method, since each algorithm performed better for different images. Nevertheless, our algorithm is more robust in handling noise, as will be shown in Section V-B. Next, we plot our algorithm on the Middlebury stereo evaluation website <ref type="bibr" target="#b2">[3]</ref>. Specifically, we plot the two results that were generated with and without the refinement step using the weighted median filter to clarify the amount of performance gain due to the use of the refinement procedure. We denote the algorithm without the refinement step as DTAggr, while DTAggr-P is referred as the full chain of the stereo matcher.  refinement stages. The median filters were also applied after the disparity optimization and the weighted filter for removing noise. Fig. <ref type="figure" target="#fig_8">7</ref> shows the results generated using our algorithm with the aforementioned parameter settings, while Tables III and IV show the comparison between our method and related methods studied in this paper using default error threshold 1.0 and sub-pixel error threshold 0.5, respectively. There were approximately 135 competitive algorithms on the Middlebury website at the time of submission. For review purposes, we plot eight other local methods that were previously mentioned in Section II in addition to the five compared algorithms to highlight the overview of the local approaches.</p><p>Considering the default error threshold 1.0, the non refined DTAggr produced 5.88% erroneous pixels, while the refined DTAggr-P reduced this error to 5.24%. The DTAggr-P is the method that yields the smallest average erroneous pixels in Table <ref type="table" target="#tab_2">III</ref>. The performance of the DTAggr-P is not better than several other methods for the Tsukuba and Venus stereo pairs, but it outperforms the other methods for the Teddy and Cones images. Furthermore, the DTAggr-P also outperforms other methods in terms of rank, and it eventually becomes the best-performing local algorithm in the default Middlebury ranking table. Considering the sub-pixel error threshold 0.5, our algorithm still shows stability, while the DTAggr and DTAggr-P rank 5th and 3rd among local methods, respectively. It is interestingly noted that the rank of the DTAggr is relatively high even though the refinement process has not been exploited. This shows the efficiency of the proposed algorithm. In contrast, the performance of InfoPermeable is drastically degraded since it ranks 73rd in the Middlebury ranking table, and 10th among aforementioned local methods in this table. This shows the appealing properties of domain transformation used in our proposed method versus the simple    exponential function used in the information permeability algorithm. Accordingly, the CostFilter is the best-performing local algorithm in the sub-pixel Middlebury ranking table in terms of both rank and average percent of bad pixels.</p><p>Nevertheless, from a practical point of view, the Middlebury benchmark may not reflect the overall performance of these algorithms when working with camcorder data. This can be explained by the fact that the standard dataset which consists of these four stereo pairs is relatively small, and the images are of high quality. For this reason, we perform further experiments for testing on real-world images captured from camcorders to illustrate the efficiency of the proposed method. Images with some noise level are also included to demonstrate the robustness to noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Camcorder Data</head><p>We conducted the tests on real-world images using three stereo sequences. The first one is the "Book Arrival" sequence (512 × 384, 60 possible disparities) obtained from the HHI database <ref type="bibr" target="#b36">[37]</ref>, and the other two are the "Newspaper" (512 × 384, 32 possible disparities) and "Cafe" (640 × 360, 32 possible disparities) sequences obtained from GIST <ref type="bibr" target="#b37">[38]</ref>. We report the results after the left-right consistency check, and no disparity refinement step using the weighted median filter was carried out. As in the first test, we compared our method, which is the DTAggr in this case, with the GeoDif, AdaptWeight, InfoPermeable, and CostFilter. The parameters of these methods were consistently adjusted to achieve optimal results that provided good trade-off for the three sequences. Under these circumstances, the disparity maps of one of these frames are shown in Fig. <ref type="figure" target="#fig_9">8</ref>. According to the visual results, these methods yielded comparable results for the "Cafe" sequence. However, for the "Newspaper" and "Book Arrival" sequences, the InfoPermeable and our method outperform other methods since they yielded fewer visible artifacts. For the CostFilter, even though it performs better than the GeoDif and AdaptWeight, its disparity maps are qualitatively observed to be less accurate compared to those generated from our method. This can be explained that the guided filter used in the CostFilter algorithm is a Euclidean filter that allows the information of neighboring pixels lying on different sides of an edge to be integrated to the candidate pixel, while our edge-aware filter is a geodesic filter that does not allow this integration <ref type="bibr" target="#b38">[39]</ref>. Indeed, each output value of the guided filter is simply computed by averaging the multipoint estimators from different support windows, without any weighting concept, while the integration between two neighboring pixels in our proposed method is determined by the distance g as previously explained.</p><p>To further experimentally illustrate the efficiency of the geodesic filter over the Euclidean filter, we directly compared our method with the CostFilter using the "Book Arrival" stereo sequence with some noise level. Specifically, we created three different sequences by adding Gaussian white noise with variances of σ 2 = 10, σ 2 = 20 and σ 2 = 40, respectively, to each frame of the original sequence. The input frames were not pre-processed using robust image denoising techniques. Instead, only a 5 × 5 median filter was exploited. The same parameter settings in the previous test were deployed for both algorithms. Consequently, Fig. <ref type="figure" target="#fig_10">9</ref> shows the disparity maps generated from the two methods. Accordingly, our method is shown to be more robust in handling noise compared to the CostFilter since it produced fewer visible artifacts.</p><p>In summary, our method yields better results compared to the CostFilter, which is the current best local algorithm. The  proposed method also outperforms AdaptWeight, the most well-known local algorithm, since the disparity maps produced from our method are more precise. This is in contrast to the existing adaptive-weight approximation techniques, which reduce the estimation precision. Furthermore, our algorithm is more attractive in terms of fast runtime, which will be shown in the next subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Execution Time</head><p>We implemented all five competitive algorithms in the previous tests using C++ and measured the processing time on four Middlebury stereo pairs to compare their computation performances. Similar to the first test in subsection A, we measured only the execution time of the aggregation performing on the left view, and no occlusion handling or post-processing times were included. The measurement was carried out on a PC with an AMD Athlon 64 X2 Dual Core 3800+ 2.00 Ghz. The results reported in Table V show that our proposed method and InfoPermeable are the fastest choices, being approximately 19× and 16× faster than CostFilter, respectively. Both GeoDif and AdaptWeight require too much time to accomplish the task due to the large number of iterations (n = 24) and the support window size <ref type="bibr">(35 × 35)</ref>, respectively.</p><p>It is essentially noted that the computational complexity of our algorithm is independent of the input parameters, similar to CostFilter and InfoPermeable, while the complexities of GeoDif and AdaptWeight are increased with respect to the number of iterations and the support window size, respectively. To demonstrate this property, we compare the execution time of the five algorithms on the Tsukuba stereo pair versus n = <ref type="bibr">[5, 6, . . . , 15]</ref>. For each n, the support window size of the CostFilter and AdaptWeight was set to 2n + 1 × 2n + 1, and the GeoDif aggregation was iterated n times. The performance of our algorithm is affected by neither the iteration number nor the window size, as it propagates the costs across the entire image lattice at once. Fig. <ref type="figure" target="#fig_11">10</ref> presents this comparison. We can observe that the execution times of the GeoDif and AdaptWeight were proportionally increased versus n as expected, whereas the execution times of the CostFilter, In-foPermeable, and our algorithm are almost constant.</p><p>We also implemented the proposed algorithm on a massively data parallel architecture using CUDA <ref type="bibr" target="#b39">[40]</ref> in this work. Our GPU implementation runs in about 9.5 milliseconds for the Tsukuba stereo pair on an NVIDIA GeForce GTX 460 graphics card, which is approximately 6× faster than the GPU implementation of GeoDif, which runs in about 60 milliseconds on a GeForce GTX 480 card <ref type="bibr" target="#b26">[27]</ref>. For the 400 × 300 images with 64 disparities, the CostFilter takes about 41 milliseconds for accomplishing the task on a GeForce GTX 480 card <ref type="bibr">[21][41]</ref>. Our algorithm runs in an equivalent time on a GeForce GTX 460 card. Nevertheless, its fast runtime on both CPU and GPU platforms and its robustness to noise are great advantages compared to the CostFilter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>We have presented a novel efficient cost aggregation method for local stereo matching. The proposed algorithm integrates the appealing properties of domain transformation into the cost aggregation for accomplishing the task using a sequence of 1D operations, which lower computational requirements and memory costs. The excessive time consumption bottleneck of adaptive-weight algorithms has been solved completely. The experimental results showed that our proposed method outperforms the state-of-the-art methods in terms of both computational performance and estimation accuracy. The computational complexity is independent of the input parameters. According to the Middlebury ranking website, our algorithm is currently one of the best-performing local algorithms. Furthermore, it works very well with real-world images even with the presence of noise.</p><p>The efficiency of the proposed algorithm, which is both fast and accurate, makes it particularly useful in many circumstances. We highly anticipate that our contributions will be used in the development of stereo vision.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Block diagram representation of the proposed local stereo algorithm.</figDesc><graphic coords="3,50.56,53.88,510.30,89.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The input signal and its arc length in the interval [u, v]</figDesc><graphic coords="3,321.51,183.33,114.18,74.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The sample disparity maps. (a) Left image. (b) Non-edge-aware filter. (c) Edge-aware filter. The red arrows point to several edge-fattening artifacts.</figDesc><graphic coords="4,322.05,53.53,74.24,144.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Illustration of the proposed cost aggregation process with separate horizontal and vertical filtering.</figDesc><graphic coords="5,66.32,53.23,116.78,92.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 1 : 1 - 2 domain taken in x and y directions; σ ← σ s / σ r ; 3 foreach</head><label>1123</label><figDesc>Proposed Cost Aggregation Algorithm: AggregateCost Input: C: the raw matching costs I: the left input image σ s : the spatial parameter σ r : the intensity range parameter Output: C ′ : the aggregated costs begin Initialize buffer gH and gV as the transformed pixel (x, y) in I do 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The sample consistency map and the post-processed disparity map of the Venus image. The invalidated pixels are marked by red pixels.</figDesc><graphic coords="6,53.17,53.41,119.31,105.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>The parameters are consistently configured for the four stereo pairs as { λ , T c , T g , σ s , σ r } = {0.1, 7/255, 2/255, 45, 0.06}. The aggregation guidance images were also filtered using a 3 × 3 median filter as explained earlier. The weighted median filter with r = 21, γ s = 81, and γ r = 0.04 was used in the disparity</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. The raw disparity maps produced from our proposed method and competitive methods.</figDesc><graphic coords="7,387.15,53.44,52.77,235.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. The results of our algorithm using four Middlebury stereo pairs (Tsukuba, Venus, Teddy, and Cones). The first and second columns show the left and groundtruth images corresponding to each stereo pair, respectively. The third column shows the generated disparity maps without the refinement step (DTAggr), while the final disparity maps with the refinement step (DTAggr-P) are shown in the fourth column. The error maps representing erroneous pixels considering the default error threshold 1.0 are shown in the last column.</figDesc><graphic coords="8,51.22,59.80,98.83,332.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. The disparity maps of the "Cafe", "Newspaper" and "Book Arrival" stereo sequences produced from our method and competitive algorithms. The parameters of these methods were consistently configured as follows: (b) GeoDif: n = 30, γ c = 40, l 0 = 0.15; (c) AdaptWeight: Ω p = 35 ×35, γ s = 17, γ r = 17.5; (d) InfoPermeable: σ = 30; (e) CostFilter: Ω p = 25 × 25, ε = 0.0004; (f) DTAggr: σ s = 45, σ r = 0.1.</figDesc><graphic coords="9,140.24,333.42,81.81,170.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. The disparity maps of the "Book Arrival" sequence with some noise level produced from the CostFilter and our method. The images with noise variances σ 2 = 10, σ 2 = 20, and σ 2 = 40 are shown from the first row to the last row, respectively.</figDesc><graphic coords="10,52.75,53.40,82.43,174.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Execution time of the five algorithms on the Tsukuba stereo pair with respect to n, which represents the support window size or number of iterations. The red line (proposed method) and the light blue line (InfoPermeable) are almost identical.</figDesc><graphic coords="10,330.08,53.47,214.61,135.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I THE</head><label>I</label><figDesc>PERCENTAGE OF BAD PIXELS IN NON-OCCLUDED REGIONS</figDesc><table><row><cell>Algorithm</cell><cell cols="5">Tsukuba Venus Teddy Cones Average</cell></row><row><cell>GeoDif [27]</cell><cell>3.16</cell><cell cols="3">3.04 10.38 6.73</cell><cell>5.83</cell></row><row><cell>AdaptWeight [4]</cell><cell>2.67</cell><cell>1.47</cell><cell>9.56</cell><cell>6.36</cell><cell>5.02</cell></row><row><cell>InfoPermeable [31]</cell><cell>2.13</cell><cell>1.99</cell><cell>8.47</cell><cell>6.21</cell><cell>4.71</cell></row><row><cell>CostFilter [21]</cell><cell>2.41</cell><cell>1.80</cell><cell>8.09</cell><cell>3.37</cell><cell>3.92</cell></row><row><cell>Proposed method</cell><cell>2.38</cell><cell>1.46</cell><cell>7.37</cell><cell>4.31</cell><cell>3.88</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III QUANTITATIVE</head><label>III</label><figDesc>MIDDLEBURY EVALUATION OF THE ALGORITHMS STUDIED IN THIS PAPER USING DEFAULT ERROR THRESHOLD 1.0.</figDesc><table><row><cell>Algorithm</cell><cell>Rank</cell><cell cols="2">Tsukuba</cell><cell></cell><cell></cell><cell>Venus</cell><cell></cell><cell></cell><cell>Teddy</cell><cell></cell><cell>Cones</cell><cell>Average percent of</cell></row><row><cell></cell><cell></cell><cell>nonocc</cell><cell>all</cell><cell cols="2">disc nonocc</cell><cell>all</cell><cell cols="2">disc nonocc</cell><cell>all</cell><cell cols="2">disc nonocc</cell><cell>all</cell><cell>disc bad pixels</cell></row><row><cell>DTAggr-P</cell><cell>18</cell><cell>1.75</cell><cell cols="2">2.10 7.09</cell><cell>0.24</cell><cell cols="2">0.45 2.59</cell><cell>5.70</cell><cell cols="2">11.5 13.9</cell><cell>2.49</cell><cell>7.82 7.30</cell><cell>5.24</cell></row><row><cell>CostFilter [21]</cell><cell>20</cell><cell>1.51</cell><cell cols="2">1.85 7.61</cell><cell>0.20</cell><cell cols="2">0.39 2.42</cell><cell>6.16</cell><cell cols="2">11.8 16.0</cell><cell>2.71</cell><cell>8.24 7.66</cell><cell>5.55</cell></row><row><cell>InfoPermeable [31]</cell><cell>21</cell><cell>1.06</cell><cell cols="2">1.53 5.64</cell><cell>0.32</cell><cell cols="2">0.88 4.15</cell><cell>5.60</cell><cell cols="2">13.0 14.5</cell><cell>2.65</cell><cell>9.16 7.69</cell><cell>5.51</cell></row><row><cell>GeoSup [5]</cell><cell>28</cell><cell>1.45</cell><cell cols="2">1.83 7.71</cell><cell>0.14</cell><cell cols="2">0.26 1.90</cell><cell>6.88</cell><cell cols="2">13.2 16.1</cell><cell>2.94</cell><cell>8.89 8.32</cell><cell>5.80</cell></row><row><cell>P-LinearS [30]</cell><cell>29</cell><cell>1.10</cell><cell cols="2">1.67 5.92</cell><cell>0.53</cell><cell cols="2">0.89 5.71</cell><cell>6.69</cell><cell cols="2">12.0 15.9</cell><cell>2.60</cell><cell>8.44 6.71</cell><cell>5.68</cell></row><row><cell>GeoDif [27]</cell><cell>34</cell><cell>1.88</cell><cell cols="2">2.35 7.64</cell><cell>0.38</cell><cell cols="2">0.82 3.02</cell><cell>5.99</cell><cell cols="2">11.3 13.3</cell><cell>2.84</cell><cell>8.33 8.09</cell><cell>5.49</cell></row><row><cell>DTAggr</cell><cell>52</cell><cell>1.90</cell><cell cols="2">2.26 7.49</cell><cell>0.49</cell><cell cols="2">0.73 3.44</cell><cell>6.40</cell><cell cols="2">12.1 14.3</cell><cell>3.37</cell><cell>8.87 9.31</cell><cell>5.88</cell></row><row><cell>CostAggr+occ [26]</cell><cell>58</cell><cell>1.38</cell><cell cols="2">1.96 7.14</cell><cell>0.44</cell><cell cols="2">1.13 4.87</cell><cell>6.80</cell><cell cols="2">11.9 17.3</cell><cell>3.60</cell><cell>8.57 9.36</cell><cell>6.20</cell></row><row><cell>AdaptWeight [4]</cell><cell>67</cell><cell>1.38</cell><cell cols="2">1.85 6.90</cell><cell>0.71</cell><cell cols="2">1.19 6.13</cell><cell>7.88</cell><cell cols="2">13.3 18.6</cell><cell>3.97</cell><cell>9.79 8.26</cell><cell>6.67</cell></row><row><cell>FastBilateral [10]</cell><cell>74</cell><cell>2.38</cell><cell cols="2">2.80 10.4</cell><cell>0.34</cell><cell cols="2">0.92 4.55</cell><cell>9.83</cell><cell cols="2">15.3 20.3</cell><cell>3.10</cell><cell>9.31 8.59</cell><cell>7.31</cell></row><row><cell>HistoAggr [13]</cell><cell>75</cell><cell>2.47</cell><cell cols="2">2.71 11.1</cell><cell>0.74</cell><cell cols="2">0.97 3.28</cell><cell>8.31</cell><cell cols="2">13.8 21.0</cell><cell>3.86</cell><cell>9.47 10.4</cell><cell>7.33</cell></row><row><cell>VariableCross [8]</cell><cell>81</cell><cell>1.99</cell><cell cols="2">2.65 6.77</cell><cell>0.62</cell><cell cols="2">0.96 3.20</cell><cell>9.75</cell><cell cols="2">15.1 18.2</cell><cell>6.28</cell><cell>12.7 12.9</cell><cell>7.60</cell></row><row><cell>ESAW [9]</cell><cell>91</cell><cell>1.92</cell><cell cols="2">2.45 9.66</cell><cell>1.03</cell><cell cols="2">1.65 6.89</cell><cell>8.48</cell><cell cols="2">14.2 18.7</cell><cell>6.56</cell><cell>12.7 14.4</cell><cell>8.21</cell></row><row><cell>DCBGrid [11]</cell><cell>111</cell><cell>5.90</cell><cell cols="2">7.26 21.0</cell><cell>1.35</cell><cell cols="2">1.91 11.2</cell><cell>10.5</cell><cell cols="2">17.2 22.2</cell><cell>5.34</cell><cell>11.9 14.9</cell><cell>10.9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV QUANTITATIVE</head><label>IV</label><figDesc>MIDDLEBURY EVALUATION OF THE ALGORITHMS STUDIED IN THIS PAPER USING SUB-PIXEL ERROR THRESHOLD 0.5.</figDesc><table><row><cell>Algorithm</cell><cell>Rank</cell><cell cols="2">Tsukuba</cell><cell></cell><cell></cell><cell>Venus</cell><cell></cell><cell></cell><cell>Teddy</cell><cell></cell><cell>Cones</cell><cell>Average percent of</cell></row><row><cell></cell><cell></cell><cell>nonocc</cell><cell>all</cell><cell cols="2">disc nonocc</cell><cell>all</cell><cell cols="2">disc nonocc</cell><cell>all</cell><cell cols="2">disc nonocc</cell><cell>all</cell><cell>disc bad pixels</cell></row><row><cell>CostFilter [21]</cell><cell>21</cell><cell>11.2</cell><cell cols="2">11.7 15.6</cell><cell>5.99</cell><cell cols="2">6.43 10.8</cell><cell>11.3</cell><cell cols="2">18.1 25.3</cell><cell>7.71</cell><cell>13.7 15.1</cell><cell>12.8</cell></row><row><cell>P-LinearS [30]</cell><cell>24</cell><cell>19.5</cell><cell cols="2">20.1 17.8</cell><cell>5.02</cell><cell cols="2">5.60 10.9</cell><cell>11.8</cell><cell cols="2">18.5 25.2</cell><cell>5.01</cell><cell>11.6 11.9</cell><cell>13.6</cell></row><row><cell>DTAggr-P</cell><cell>27</cell><cell>15.1</cell><cell cols="2">15.6 17.5</cell><cell>6.49</cell><cell cols="2">7.05 12.9</cell><cell>10.7</cell><cell cols="2">17.6 22.8</cell><cell>7.42</cell><cell>13.3 14.3</cell><cell>13.4</cell></row><row><cell>CostAggr+occ [26]</cell><cell>31</cell><cell>18.7</cell><cell cols="2">19.2 20.1</cell><cell>4.17</cell><cell cols="2">4.93 12.6</cell><cell>13.6</cell><cell cols="2">19.8 29.1</cell><cell>6.23</cell><cell>12.3 14.2</cell><cell>14.6</cell></row><row><cell>DTAggr</cell><cell>33</cell><cell>15.8</cell><cell cols="2">16.3 18.4</cell><cell>6.95</cell><cell cols="2">7.48 13.5</cell><cell>11.5</cell><cell cols="2">18.4 23.2</cell><cell>8.27</cell><cell>14.5 16.0</cell><cell>14.2</cell></row><row><cell>GeoSup [5]</cell><cell>50</cell><cell>22.9</cell><cell cols="2">23.1 20.4</cell><cell>6.81</cell><cell cols="2">7.11 11.5</cell><cell>13.5</cell><cell cols="2">20.4 26.8</cell><cell>8.17</cell><cell>15.0 15.5</cell><cell>15.9</cell></row><row><cell>GeoDif [27]</cell><cell>55</cell><cell>26.3</cell><cell cols="2">26.8 21.7</cell><cell>7.17</cell><cell cols="2">7.85 12.5</cell><cell>12.6</cell><cell cols="2">19.2 23.9</cell><cell>8.15</cell><cell>14.2 14.8</cell><cell>16.3</cell></row><row><cell>HistoAggr [13]</cell><cell>56</cell><cell>10.9</cell><cell cols="2">11.4 21.4</cell><cell>6.94</cell><cell cols="2">7.36 12.2</cell><cell>16.3</cell><cell cols="2">22.5 33.3</cell><cell>10.4</cell><cell>16.2 19.4</cell><cell>15.7</cell></row><row><cell>FastBilateral [10]</cell><cell>68</cell><cell>21.5</cell><cell cols="2">22.4 22.9</cell><cell>5.71</cell><cell cols="2">6.66 14.9</cell><cell>16.2</cell><cell cols="2">23.3 32.1</cell><cell>9.10</cell><cell>15.8 18.1</cell><cell>17.4</cell></row><row><cell>InfoPermeable [31]</cell><cell>73</cell><cell>25.7</cell><cell cols="2">26.2 21.2</cell><cell>8.64</cell><cell cols="2">9.34 15.0</cell><cell>15.0</cell><cell cols="2">22.1 29.2</cell><cell>7.68</cell><cell>15.1 15.1</cell><cell>17.5</cell></row><row><cell>DCBGrid [11]</cell><cell>79</cell><cell>21.7</cell><cell cols="2">22.8 29.6</cell><cell>2.85</cell><cell cols="2">3.97 16.5</cell><cell>16.1</cell><cell cols="2">24.0 33.0</cell><cell>10.8</cell><cell>18.2 22.6</cell><cell>18.5</cell></row><row><cell>AdaptWeight [4]</cell><cell>81</cell><cell>18.1</cell><cell cols="2">18.8 18.6</cell><cell>7.77</cell><cell cols="2">8.40 15.8</cell><cell>17.6</cell><cell cols="2">23.9 34.0</cell><cell>14.0</cell><cell>19.7 20.6</cell><cell>18.1</cell></row><row><cell>VariableCross [8]</cell><cell>99</cell><cell>24.5</cell><cell cols="2">25.1 21.5</cell><cell>9.03</cell><cell cols="2">9.59 13.8</cell><cell>18.8</cell><cell cols="2">25.1 31.4</cell><cell>16.1</cell><cell>22.1 22.4</cell><cell>19.9</cell></row><row><cell>ESAW [9]</cell><cell>105</cell><cell>19.2</cell><cell cols="2">19.7 22.8</cell><cell>11.0</cell><cell cols="2">11.7 18.4</cell><cell>19.4</cell><cell cols="2">25.9 33.6</cell><cell>18.5</cell><cell>24.0 28.8</cell><cell>21.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V EXECUTION</head><label>V</label><figDesc>TIME (S) MEASURED ON FOUR STEREO PAIRS OF THE FIVE</figDesc><table><row><cell cols="4">COST AGGREGATION TECHNIQUES</cell><cell></cell></row><row><cell>Algorithm</cell><cell>Tsukuba</cell><cell>Venus</cell><cell>Teddy</cell><cell>Cones</cell></row><row><cell>GeoDif [27]</cell><cell>24.071</cell><cell>44.991</cell><cell>139.121</cell><cell>139.142</cell></row><row><cell>AdaptWeight [4]</cell><cell>38.481</cell><cell>66.503</cell><cell>150.197</cell><cell>150.634</cell></row><row><cell>InfoPermeable [31]</cell><cell>0.147</cell><cell>0.369</cell><cell>1.053</cell><cell>1.051</cell></row><row><cell>CostFilter [21]</cell><cell>2.482</cell><cell>5.622</cell><cell>17.371</cell><cell>17.369</cell></row><row><cell>Proposed method</cell><cell>0.122</cell><cell>0.324</cell><cell>0.904</cell><cell>0.901</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This research was supported in part by MKE, Korea, under ITRC NIPA-2012-(H0301-12-3001) and in part by PRCP through NRF of Korea, funded by MEST (2012-0005861).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Taxonomy and Evaluation of Dense Two-Frame Stereo Correspondence Algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="7" to="42" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Computer Vision: Applications and Algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<ptr target="http://vision.middlebury.edu/stereo/eval" />
		<title level="m">Middlebury Stereo Evaluation -Version 2</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adaptive Support-Weight Approach for Correspondence Search</title>
		<author>
			<persName><forename type="first">K.-J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I.-S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="650" to="656" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Local Stereo Matching Using Geodesic Support Weights</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hosni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bleyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gelautz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rhemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intl. Conf. Image Process</title>
		<meeting>IEEE Intl. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2093" to="2096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bilateral Filtering for Gray and Color Images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manduchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intl. Conf. Comput. Vis. (ICCV)</title>
		<meeting>Intl. Conf. Comput. Vis. (ICCV)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="839" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">High-Quality Real-Time Stereo using Adaptive Cost Aggregation and Dynamic Programming</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nistér</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third International Symposium on 3D Data Processing</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>Visualization and Transmission (3DPVT</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cross-Based Local Stereo Matching Using Orthogonal Integral Images</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lafruit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1073" to="1079" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">High Performance Stereo Vision Designed for Massively Data Parallel Platforms</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Franchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1509" to="1519" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Accurate and Efficient Cost Aggregation Strategy for Stereo Correspondence based on Approximated Joint Bilateral Filtering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mattoccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Giardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gambini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Ninth Asia Conf. Comput. Vis. (ACCV)</title>
		<meeting>Ninth Asia Conf. Comput. Vis. (ACCV)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="371" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Realtime Spatiotemporal Stereo Matching Using the Dual-Cross-Bilateral Grid</title>
		<author>
			<persName><forename type="first">C</forename><surname>Richardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Dodgson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV2010</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6313</biblScope>
			<biblScope unit="page" from="510" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Near Real-Time Stereo with Adaptive Support Weight Approaches</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hosni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bleyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gelautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intl. Symp. 3D Data Process. Visual. Trans. (3DPVT)</title>
		<meeting>Intl. Symp. 3D Data ess. Visual. Trans. (3DPVT)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2093" to="2096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Revisit to Cost Aggregation in Stereo Matching: How Far Can We Reduce Its Computational Redundancy</title>
		<author>
			<persName><forename type="first">D</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Do</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intl. Conf. Comput. Vis. (ICCV)</title>
		<meeting>Intl. Conf. Comput. Vis. (ICCV)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1567" to="1574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Domain Transform for Edge-Aware Image and Video Processing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Eduardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><forename type="middle">M</forename><surname>Gastal</surname></persName>
		</author>
		<author>
			<persName><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Performance Study on Different Cost Aggregation Approach Used in Real-Time Stereo Matching</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="283" to="296" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Classification and Evaluation of Cost Aggregation Methods for Stereo Correspondence</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mattoccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Stefano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Addimanda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intl. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Intl. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient Stereo with Multiple Windowing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fusiello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Roberto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Trucco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intl. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Intl. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="858" to="863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Large Occlusion Stereo</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Bobick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Intille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="200" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Variable Window Approach to Early Vision</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Zabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1283" to="1294" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fast Variable Window for Stereo Correspondence Using Integral Images</title>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intl. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Intl. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="556" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fast Cost-Volume Filtering for Visual Correspondence and Beyond</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rhemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hosni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bleyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gelautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intl. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Intl. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="3017" to="3024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Summed-Area Tables for Texture Mapping</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Crow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Real-time Edge-Aware Image Processing with the Bilateral Grid</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scale-Space and Edge Detection Using Anisotropic Diffusion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Penora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Anisotropic Diffusion in Image Processing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
		<editor>B. G. Teubner Stuttgart</editor>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cost Aggregation and Occlusion Handling with WLS in Stereo Matching</title>
		<author>
			<persName><forename type="first">D</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1431" to="1442" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Near Real-Time Stereo Matching Using Geodesic Diffusion</title>
		<author>
			<persName><forename type="first">L</forename><surname>De-Maeztu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Villanueva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cabeza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="410" to="416" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bayesian Image Analysis: An Application to Single Photon Emission Tomography</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Mcclure</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Statist</title>
		<meeting>Statist</meeting>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="12" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Guided Image Filtering</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV2010</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6311</biblScope>
			<biblScope unit="page">114</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Linear Stereo Matching</title>
		<author>
			<persName><forename type="first">L</forename><surname>De-Maeztu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mattoccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Villanueva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cabeza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intl. Conf. Comput. Vis. (ICCV)</title>
		<meeting>Intl. Conf. Comput. Vis. (ICCV)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Efficient Edge-Preserving Stereo Matching</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cigla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Alatan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV Workshop on LDRMV</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Introduction to Digital Filters with Audio Applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>W3K Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Elementary Differential Geometry</title>
		<author>
			<persName><forename type="first">B</forename><surname>O'neill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AP</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Linear System Theory and Design</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Evaluation of Cost Functions for Stereo Matching</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hirschmüller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intl. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Intl. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Stereo Processing by Semiglobal Matching and Mutual Information</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hirschmüller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="328" to="341" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<ptr target="http://sp.cs.tut.fi/mobile3dtv/stereo-video/" />
		<title level="m">FhG-HHI 3DV data</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Multiview video test sequence and camera parameters</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISO/IEC JTC1/SC</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">15419</biblScope>
			<date type="published" when="2008-04">April 2008</date>
		</imprint>
	</monogr>
	<note>WG</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Adaptive Manifolds for Real-Time High-Dimensional Filtering</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Eduardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><forename type="middle">M</forename><surname>Gastal</surname></persName>
		</author>
		<author>
			<persName><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">CUDA C Programming Guide 3.2</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>NVIDIA Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Temporally Consistent Disparity and Optical Flow via Efficient Spatio-temporal Filtering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hosni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rhemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bleyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gelautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008, and the M.S. degree in electrical and computer engineering from Sungkyunkwan University</title>
		<meeting><address><addrLine>Ho Chi Minh City, Vietnam; Suwon, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="volume">7087</biblScope>
			<biblScope unit="page" from="323" to="334" />
		</imprint>
	</monogr>
	<note>PSIVT2011. where he is currently working toward the Ph.D. degree in the School of Information and Communication Engineering. His research interests include computer vision, image processing, and GPGPU programing</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">From 1990 to 1994, he was a Senior Researcher at Samsung Electronics, Suwon, Korea. Since 1994, he has been with Sungkyunkwan University, Suwon, where he was first an Assistant Professor with the School of Electrical and Computer Engineering and is currently a Professor with the School of Information and Communication Engineering</title>
		<author>
			<persName><forename type="first">Jae</forename><surname>Wook</surname></persName>
			<affiliation>
				<orgName type="collaboration">S&apos;82-M&apos;84) received the B.S. and M</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Jeon</forename></persName>
			<affiliation>
				<orgName type="collaboration">S&apos;82-M&apos;84) received the B.S. and M</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="m">respectively, and the Ph.D. degree in electrical engineering from Purdue University</title>
		<meeting><address><addrLine>West Lafayette, IN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1984">1984. 1986. 1990</date>
		</imprint>
		<respStmt>
			<orgName>Seoul National University, Seoul, Korea</orgName>
		</respStmt>
	</monogr>
	<note>His research interests include robotics, embedded systems, and factory automation</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
