<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Text Localization in Natural Scene Images based on Conditional Random Field</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yi-Feng</forename><surname>Pan</surname></persName>
							<email>yfpan@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">National Laboratory of Pattern Recognition Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>95 Zhongguancun East Road</addrLine>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinwen</forename><surname>Hou</surname></persName>
							<email>xwhou@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">National Laboratory of Pattern Recognition Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>95 Zhongguancun East Road</addrLine>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cheng-Lin</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">National Laboratory of Pattern Recognition Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>95 Zhongguancun East Road</addrLine>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Text Localization in Natural Scene Images based on Conditional Random Field</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">88231E6A6BB7A35705F2DD43DE8DC205</idno>
					<idno type="DOI">10.1109/ICDAR.2009.97</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>This paper proposes a novel hybrid method to robustly and accurately localize texts in natural scene images. A text region detector is designed to generate a text confidence map, based on which text components can be segmented by local binarization approach. A Conditional Random Field (CRF) model, considering the unary component property as well as binary neighboring component relationship, is then presented to label components as "text" or "non-text".</head><p>Last, text components are grouped into text lines with an energy minimization approach. Experimental results show that the proposed method gives promising performance comparing with the existing methods on ICDAR 2003 competition dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the widely use of digital image capturing devices, text localization/detection, as a key part of the image text information extraction system <ref type="bibr" target="#b2">[3]</ref>, has been studied intensively. Though many efforts have been devoted to, it remains a challenge due to variations of texts' size, font, array orientation and degraded images with the cluttered background and noises <ref type="bibr" target="#b4">[5]</ref>. The existing methods can be categorized into two classes: region-based methods and connected component (CC)-based ones.</p><p>Region-based methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b13">14]</ref> are based on observations that text regions have distinct characteristics from nontext regions such as distinctive gradient distribution, texture and structure. These methods generally consist of two stages: text detection and text localization. For text detection, features of local regions are extracted to determine if they contain texts. Then specific grouping or clustering approaches are employed to localize text regions accurately.</p><p>CC-based methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b13">14]</ref> are based on observations that texts can be seen as sets of separate connected components, each of which has distinct intensity, color distri-butions and enclosed contours. These methods generally contain three stages: 1) CC extraction to segment CCs from images, 2) CC analysis to determine whether or not they are text components by heuristic rules or classifiers and 3) postprocessing to group text components into text regions (e.g. words, lines).</p><p>Although some existing methods have reported promissing results, there still remains several problems difficult to be solved. For CC-based methods, text components are hard to be segmented accurately without prior information of text position and scale. Furthermore, designing fast and reliable CC analysis method is also difficult since there are too many text-like components in images. On the other hand, the performance of region-based methods is sensitive to the text orientation and cluster number. Most of these methods can only localize texts containing many characters in horizontal alignment.</p><p>To overcome these difficulties, we propose a hybrid method to robustly and accurately localize texts in natural scene images. A text region detector is designed to generate a text confidence map, based on which components are segmented with local binarization. Then a Conditional Random Field (CRF) model considering of both the unary component property and neighboring component relationship is presented for component analysis. Finally, a energy minimization based approach is used to group text components into text lines. We evaluate our method on ICDAR 2003 competition dataset and the results show that the text localization accuracy is improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">System Overview</head><p>For scene texts localization, the process of our method consists of three stages: 1) pre-processing, designing a text region detector to generate the text confidence map, based on which text components can be segmented by local binarization, 2) CC analysis, presenting a CRF model to formulate component analysis into component labeling problem, which is solved by minimum classification error (MCE) learning and graph cuts inference algorithm and 3) text line grouping, where component minimum spanning tree is built with a learned distance metric and inter-line edges are cut off with an energy minimization model. The flawchat of the proposed method is shown in Fig. <ref type="figure">1</ref> and detailed descriptions will be given in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input image</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-processing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text region detector Text confidence map Local binarization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Connected component analysis</head><p>Component labeling with a CRF model</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text line grouping</head><p>Minimum spanning tree Edge cut</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output localization results</head><p>Figure <ref type="figure">1</ref>. Flowchat of the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Pre-processing</head><p>For utilizing region information, a text region detector is designed to measure confidences of containing texts for local image regions, based on which components can be segmented and analyzed accurately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Text Region Detector</head><p>The color image is first converted into the gray-level image, on which image pyramids are built with nearest interpolation to capture texts with various sizes. Motivated by our previous work <ref type="bibr" target="#b7">[8]</ref>, a text region detector is designed by integrating Histograms of Oriented Gradients (HOG) feature extractor and boosted cascade classifier. For each local region in one image of pyramids, HOG features are extracted as an input to a variation of cascade boosting classifier, WaldBoost <ref type="bibr" target="#b9">[10]</ref>, to estimate whether this region contains texts. The major difference between WaldBoost and other cascade boosting classifiers is that it directly ensemble weak learners to build a strong classifier and each of them can be used to filter out negative objects individually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Text Confidence Map</head><p>To measure the confidence that one region contains texts, we translate the Waldboost output, no matter accepted or rejected, into posterior probability based on a boosted classifier calibration method <ref type="bibr" target="#b11">[12]</ref>. Posterior probabilities of the observation variable x, x ∈{text,non-text}, conditioned on the state variable s, s ∈{accept,reject}, at stage t can be estimated based on the Bayes' formula as P t (x|s) = P t (s|x)P t (x)</p><p>x P t (s|x)P t (x) = P t (s|x)P t-1 (x|accept)</p><formula xml:id="formula_0">x P t (s|x)P t-1 (x|accept) , (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where all likelihoods P t (s|x) are calculated on the validation set during the training procedure. In this way, each confidence map of the image pyramid can be calculated, whose pixel confidence and scale values are then projected back into corresponding pixels of the text confidence map for the original image which is used for subsequent stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Image Segmentation</head><p>Niblack's binarization algorithm <ref type="bibr" target="#b6">[7]</ref> is adopted to segment connected components from the image. The formula to binarize each pixel is defined as</p><formula xml:id="formula_2">b(x) = 0, if gray(x) &lt; μ r (x) -k • σ r (x); 255, if gray(x) &gt; μ r (x) + k • σ r (x); 100, other,<label>(2)</label></formula><p>where μ r (x) and σ r (x) are the intensity mean and STD within a r radius window centered on the pixel x and the smoothing term k is set to 0.4 in practical. It is noted that the value of window radius r for each pixel is calculated based on the corresponding pixel value of the text confidence map. For a binarized image, components with 0 or 255 value are extracted as candidate text components while 100 ones are not considered further. An example of the preprocessing stage is shown in Fig. <ref type="figure" target="#fig_1">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Connected Component Analysis</head><p>For CCA, a Conditional Random Field (CRF) model is proposed to label components as "text" or "non-text" by considering of both the unary component property and neighboring component relationship.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Brief Introduction to CRF</head><p>CRF <ref type="bibr" target="#b3">[4]</ref> is a undirected graphical model to estimate probability distribution global conditioned on observations. Formally, Let G = (X, E) be a graph constructed on random variables X = (x 1 , ..., x n ) with labels Y = (y 1 , ..., y n ). Then (X, Y ) is a CRF when probability of Y conditioned on X obeys the Markov property:</p><formula xml:id="formula_3">P (y i |x, y j , j = i) = P (y i |x, y j , j ∈ n i ), where n i is the neighborhood set (clique) for x i .</formula><p>In implementation, P (Y |X) can be approximated by arbitrary real-valued energy function E(X, Y, N, Λ) with clique set N and parameters Λ as</p><formula xml:id="formula_4">P (Y |X) = 1 Z(X) exp(-E(X, Y, N, λ)), (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>where Z(X) is the normalization constant which could not be considered if ignoring the probability explanation. Then the best label Y * can be found from maximizing conditional probability P (Y |X) to minimizing the total graph energy: </p><formula xml:id="formula_6">Y * = arg max Y P (Y |X) = arg min Y E(X, Y, N, λ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">CC labeling with CRF</head><p>Based on the definition of CRF, we formulate CC analysis into CC labeling problem: given the component set X = (x 1 , x 2 , ...), on which a 2D undirected graph is constructed, the objective is to find the best component label Y * = (y * 1 , y * 2 , ...) to minimize the total graph energy E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Neighborhood Graph</head><p>Considering the geometric and spatial relationship of components, we construct the neighborhood graph with a component linkage rule defined as</p><formula xml:id="formula_7">dist(x i , x j ) &lt; 2 * min( max( w i , h i ), max( w j , h j ) ),<label>(4)</label></formula><p>where dist(•, •) is the centroid distance between two components and w and h are component width and height respectively. Any two components whose spatial relationship obeys this rule can be linked together by an edge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Energy Function</head><p>Considering the effectiveness and efficiency, we utilize unary and binary cliques on the graph to construct the CRF model, where multi-layer perceptron (MLP) is selected to approximate the unary and binary energy function. The total energy function is defined as</p><formula xml:id="formula_8">E(X, Y, N, λ) = i ( (E un (x i , y i , ω un ) + ω c • c i E bi (x i , x j , y i , y j , j ∈ n i , ω bi ) ),<label>(5)</label></formula><p>where values of E un (•, ω un ) and E bi (•, ω bi ) are outputs of two-class ("text", "non-text") and three-class (both texts, both non-texts and different style) MLPs on unary and binary features, and ω c is a combination coefficient. Unary and binary features (defined in Table <ref type="table" target="#tab_0">1</ref>, refer to <ref type="bibr" target="#b10">[11]</ref>), some of which are calculated with the text confidence map, are extracted to represent the component property and component neighboring relationship. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Learning and Inference</head><p>For parameter estimation of the CRF model, we use Minimum Classification Error (MCE) criterion <ref type="bibr" target="#b1">[2]</ref> since it can be directly integrated with the MLP optimization. In MCE training, the misclassification measure can be approximated by d(X, Λ) = -E(X, Y c , N, Λ) + E(X, Y r , N, Λ), where Y c and Y r are the true and rival label respectively and Λ represents CRF model parameters {ω un , ω bi , ω c }. The measurement can be transformed into loss function</p><formula xml:id="formula_9">L(X, Λ) = 1 1 + exp(-ξ(d(X, Λ))) , (<label>6</label></formula><formula xml:id="formula_10">)</formula><p>based on which parameters can be iteratively optimized by stochastic gradient decent algorithm as</p><formula xml:id="formula_11">Λ t+1 = Λ t -ε t • ∂L(X, Λ) ∂Λ | Λ=Λ t . (<label>7</label></formula><formula xml:id="formula_12">)</formula><p>When energy function parameters are learned fixed, graph cuts (α-expansion) algorithm <ref type="bibr" target="#b0">[1]</ref> is selected to find the best label Y * of components to minimize the total energy since it can achieve approximate optimal results and is much efficient than other inference algrothms.</p><p>During the training procedure, we use coupling strategy to learn energy function parameters: at each time, the energy function is first fixed and graph cuts is used to label components, then the total energy value for fixed graph labels is used to optimize parameters based on MCE criterion. This updating process continues until the total energy only have very few changes. During the test procedure, to speed up the process, some apparent non-text components are firstly filtered out based on unary feature thresholds before using the CRF model. Values of these thresholds are set very weak to accept all text components in the training set. Fig. <ref type="figure" target="#fig_2">4</ref> gives an example of the CC analysis stage. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Text Line Grouping</head><p>To group text components into text lines, we presented a learning based method by building neighboring components into minimum spanning tree (MST) and cutting off interline edge with an energy minimization model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">MST Building</head><p>Based on observations that components belonging to one text line are adjacent along specific orientation, we cluster text components into a MST. Motivated by Yin's work <ref type="bibr" target="#b12">[13]</ref>, we define a linear distance metric whose parameters are learned with the perceptron algorithm to estimate the similarity measurement between two components, where features are defined as Table <ref type="table" target="#tab_2">2</ref>. Then a MST can be built with the learned distance metric by Kruskal's algorithm <ref type="bibr" target="#b8">[9]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Edge Cut</head><p>To separate MST into text lines with irregular alignments, we formulate edge cut into edge labeling problem which is solved in the similar way as CC analysis in Section 4. Briefly, for a MST graph G MST (X, Y ) on edges X with labels Y , a learned energy function is defined as E MST (X, Y ) = i ω i •f i , where {f i } are text line features defined as in Table <ref type="table" target="#tab_2">2</ref> (refer to <ref type="bibr" target="#b14">[15]</ref>), and {ω i } are classifier weight coefficients, whose values are learned with MCE criterion.</p><p>A recursive strategy is employed to inference edge labels: initially, edges are all labeled as "link". At each time, one edge is labeled as "cut" if the new energy is minimized and smaller than the last time. This process continues until the energy is minimal. Although this recursive approach can not be proved to find the optimal labels, experimental results are still satisfactory. Finally, text lines corresponding to sub-trees can be extracted and those containing too small components are removed. An example of the text line grouping stage is shown in Fig. <ref type="figure">5</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Results</head><p>To evaluate the performance of the proposed method, we have done experiments on ICDAR 2003 text locating competition dataset which includes 258 training images and 249 test images with English and Arab number texts.</p><p>For training text region detector, 5000 text samples were collected by manually and non-text samples are extracted randomly from training images. The size of detector was fixed to 16×16 and 4-orientation HOG were used to extract region features. Interval step was fixed to 1.2 to generate image pyramid and totally 612 weak learners were selected to build WaldBoost. For more details, please refer to <ref type="bibr" target="#b7">[8]</ref>.</p><p>4900 text components and 13000 non-text components were labeled from segmented images to train the CRF model. In order to achieve the optimal performance, parameters of two MLPs were initialized with standard back propagation algorithm and then the CRF model was jointly optimized with coupling training strategy. 10000 neighboring edges and 80000 non-neighboring edges were selected to train the MST distance metric and 550 text lines was labeled to train the energy function for edge cuts.</p><p>Our system was coded with C++ language and all experiments evaluated on a Pentium 4 3.4GHz desktop computer with Window XP OS.</p><p>To evaluate the proposed CRF model, we compared component classification performance with three different classifier settings: 1) MLP, only unary energy function is used, 2) CRF-ω c , unary and binary functions were all used but only combination coefficient ω c was optimized with MCE criterion and 3) CRF-Λ, all energy function parameters Λ(ω un , ω bi , ω c ) were optimized with MCE criterion. Results in Table <ref type="table" target="#tab_4">3</ref> shows that the CRF model is better than unary MLP as considering relationship between neighboring components and parameters fully learned with MCE is better than only optimizing the combination coefficient.  To evaluate the proposed text localization method, we compared our method with several existing methods: the top two participants of ICDAR 2005 text location competition <ref type="bibr" target="#b5">[6]</ref> and our previous method <ref type="bibr" target="#b7">[8]</ref>. We adopted the performance evaluation criterion by defining precision rate and recall rate based on area matching ratio as the ICDAR 2005 competition. As shown in Table <ref type="table" target="#tab_6">4</ref>, the proposed method is still comparative with the existing methods and the recall rate is improved than our previous region-based work, even there are different test images and evaluation units (word vs. line) between ours and competition methods.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In this paper, we present a hybrid method to localize scene texts by using region as well as component information. Furthermore, the neighboring component relationship, in addition to the unary component property, is used to construct a CRF model for CC analysis, whose model parameters are optimized with MCE learning and graph cuts inference algorithms. Experimental results have demonstrated that our method is meaningful for unconstrained scene text localization. However, until now, we just implemented a primary version of the proposed method which need to be investigated and improved further.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Example of the pre-processing stage. (a) the original image. (b) text confidence maps for the image pyramid (brightness of pixels represents the probability as "text"). (c) the text confidence map for the original image. (d) binarized image.</figDesc><graphic coords="3,93.69,75.05,89.23,66.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Example of the CC analysis stage. (a) components pass through unary thresholds. (b) component neighborhood graph (with blue edges). (c) components labeled as "text" with the learned CRF model.</figDesc><graphic coords="4,321.18,243.90,73.71,55.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Example of the text line grouping stage (a) building MST with the learned distance metric. (b) edge cut with an energy minimization model. (c) final text localization results.</figDesc><graphic coords="4,401.46,243.90,73.71,55.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 : Unary and binary features.</head><label>1</label><figDesc></figDesc><table><row><cell>Unary feature</cell><cell>Binary feature</cell></row><row><cell>normalized width</cell><cell>centroid distance</cell></row><row><cell>normalized height</cell><cell>scale ratio</cell></row><row><cell>aspect ratio</cell><cell>shape difference</cell></row><row><cell>occupy ratio</cell><cell>(horizontal and vertical)</cell></row><row><cell>compactness</cell><cell>overlap degree</cell></row><row><cell>confidence</cell><cell>(horizontal and vertical)</cell></row><row><cell>contour gradient (R,G,B)</cell><cell>color difference (R,G,B)</cell></row><row><cell>average run-length</cell><cell>confidence</cell></row><row><cell>number</cell><cell>(minimum and maximum)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 : Distance metric and text line features.</head><label>2</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 : Component classification results for different classifier settings.</head><label>3</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 : Text localization results of different methods.</head><label>4</label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>978-0-7695-3725-2/09 $25.00 © 2009 IEEE DOI 10.1109/ICDAR.2009.97</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgements</head><p>This work is supported by the National Natural Science Foundation of China (NSFC) under grant no.60775004 and no.60825301. The authors thank the anonymous reviewers for valuable comments and Xiang-Dong Zhou and Fei Yin for their helpful discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast approximate energy minimization via graph cuts</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1222" to="1239" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Discriminative learning for minimum error classification</title>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3043" to="3054" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Text information extraction in images and video: A survey</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogntion</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="977" to="997" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eighteenth Int.l Conf. Machine Learning (ICML&apos;01)</title>
		<meeting>Eighteenth Int.l Conf. Machine Learning (ICML&apos;01)<address><addrLine>San Francisco, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Camera-based analysis of text and documents: a survey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Document Analysis and Recognition</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="84" to="104" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ICDAR 2005 text locating competition results</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lucas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eighth Int.l Conf. Document Analysis and Recognition (ICDAR&apos;05)</title>
		<meeting>Eighth Int.l Conf. Document Analysis and Recognition (ICDAR&apos;05)<address><addrLine>Seoul, South Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="80" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">An Introduction to Digital Image Processing</title>
		<author>
			<persName><forename type="first">W</forename><surname>Niblack</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Strandberg Publishing Company</publisher>
			<pubPlace>Birkeroed, Denmark</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A robust system to detect and localize texts in natural scene images</title>
		<author>
			<persName><forename type="first">Y.-F</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">W</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eighth IAPR Workshop on Document Analysis Syetems (DAS&apos;08)</title>
		<meeting>Eighth IAPR Workshop on Document Analysis Syetems (DAS&apos;08)<address><addrLine>Nara, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Algorithms in C, Part 5: Graph Algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sedgewick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Addison-Wesley Professional</publisher>
		</imprint>
	</monogr>
	<note>Third Edition</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Waldboost -learning for time constrained sequential detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sochman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR&apos;05)</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition (CVPR&apos;05)<address><addrLine>San Diego, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="150" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Region graph based text extraction from outdoor images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Takahashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Third Int.l Conf. Information Technology and Applications (ICITA&apos;05)</title>
		<meeting>Third Int.l Conf. Information Technology and Applications (ICITA&apos;05)<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="680" to="685" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Distributionbased face detection using calibrated boosted cascade classifier</title>
		<author>
			<persName><forename type="first">H</forename><surname>Takatsuka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Okutomi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th Int.l Conf. Image Analysis and Processing (ICIAP&apos;07)</title>
		<meeting>14th Int.l Conf. Image Analysis and essing (ICIAP&apos;07)<address><addrLine>Modena, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="351" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Handwritten text line segmentation by clustering with distance metric learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l Conf. Frontiers in Handwriting Recognition (ICFHR&apos;08)</title>
		<meeting><address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="229" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Extraction of text objects in video documents: Recent progress</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kasturi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eighth IAPR Workshop on Document Analysis Syetems (DAS&apos;08)</title>
		<meeting>Eighth IAPR Workshop on Document Analysis Syetems (DAS&apos;08)<address><addrLine>Nara, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Grouping text lines in online handwritten Japanese documents by combining temporal and spatial information</title>
		<author>
			<persName><forename type="first">X.-D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eighth IAPR Workshop on Document Analysis Syetems (DAS&apos;08)</title>
		<meeting>Eighth IAPR Workshop on Document Analysis Syetems (DAS&apos;08)<address><addrLine>Nara, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="61" to="68" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
