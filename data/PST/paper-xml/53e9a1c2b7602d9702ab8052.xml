<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Image segmentation by iterated region merging with localized graph cuts $</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011-03-29">29 March 2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bo</forename><surname>Peng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<email>cslzhang@comp.polyu.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jian</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Nanjing University of Science and Technology</orgName>
								<address>
									<postCode>210094</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Image segmentation by iterated region merging with localized graph cuts $</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2011-03-29">29 March 2011</date>
						</imprint>
					</monogr>
					<idno type="MD5">C6846CF1894F24750AF4B575AE47C6E2</idno>
					<idno type="DOI">10.1016/j.patcog.2011.03.024</idno>
					<note type="submission">Received 28 May 2010 Received in revised form 4 March 2011 Accepted 16 March 2011</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Image segmentation Graph cuts Region merging</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents an iterated region merging-based graph cuts algorithm which is a novel extension of the standard graph cuts algorithm. Graph cuts addresses segmentation in an optimization framework and finds a globally optimal solution to a wide class of energy functions. However, the extraction of objects in a complex background often requires a lot of user interaction. The proposed algorithm starts from the user labeled sub-graph and works iteratively to label the surrounding un-segmented regions. In each iteration, only the local neighboring regions to the labeled regions are involved in the optimization so that much interference from the far unknown regions can be significantly reduced. Meanwhile, the data models of the object and background are updated iteratively based on high confident labeled regions. The sub-graph requires less user guidance for segmentation and thus better results can be obtained under the same amount of user interaction. Experiments on benchmark datasets validated that our method yields much better segmentation results than the standard graph cuts and the Grabcut methods in either qualitative or quantitative evaluation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>While it has been widely studied for many decades, automatic image segmentation is still a big challenge due to the complexity of image content. A lot of work shows that the user guidance can help to define the desired content to be extracted and thus reduce the ambiguities produced by the automatic methods. In this paper we consider the most common type of interactive segmentation: segmenting the object of interest from its background.</p><p>In the past few years, various approaches to interactive segmentation have been proposed. For example, livewire <ref type="bibr" target="#b0">[1]</ref> allows the user to interactively select certain pixels where the segmentation boundary should pass. However, high complexities of object shapes (e.g. intricate shapes with lots of protrusions and indentations) might lead to many interactions for an acceptable segmentation. And images with the large size will require more computational time. To obtain real time response to the user's actions, independent of the image size, Falc ão <ref type="bibr" target="#b1">[2]</ref> proposed a modified livewire method, which exploits three properties of Dijkstra's algorithm to compute minimum-cost paths in sublinear time. Active contour, or snake <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>, is defined as an energy-minimizing spline. After initializing the contour close to the original object boundary, the contour will fit the actual object boundary iteratively. Level sets-based segmentation method <ref type="bibr" target="#b5">[6]</ref> uses implicit active contour models, in which the numerical computation involving curves and surface is performed without having to parameterize the objects.</p><p>Another preferable interactive segmentation method based on combinatorial optimization is graph cuts <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>. It addresses segmentation in a global optimization framework and guarantees a globally optimal solution to a wide class of energy functions. In addition, the user interface of graph cuts is convenient-seeds can be loosely positioned inside the object and background regions, which is easier compared to placing seeds exactly on the boundary, like in livewire <ref type="bibr" target="#b0">[1]</ref>. Because graph cuts can involve a wide range of visual cues, a number of recent literature further extended the original work of Boykov and Jolly <ref type="bibr" target="#b6">[7]</ref> and developed the use of regional cues <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12]</ref>, geometric cues <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>, shape cues <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>, stereo cues <ref type="bibr" target="#b11">[12]</ref>, or even topology priors <ref type="bibr" target="#b17">[18]</ref> as global constraints in the graph cuts framework. When foreground and background color distributions are not well separated, the traditional graph cuts <ref type="bibr" target="#b6">[7]</ref> cannot achieve satisfying segmentation. Some advanced versions of graph cuts are developed <ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b18">19]</ref>, which are more robust and substantially simplify the user interaction. In <ref type="bibr" target="#b9">[10]</ref>, the user interaction can be applied on both coarse and fine scales, which inherit the advantages in region and boundary-based methods for image segmentation. The work proposed in <ref type="bibr" target="#b10">[11]</ref> makes a progressive local selection on the object of interest. Instant visual feedback is provided to the user for a quick and effective image editing.</p><p>In the classical graph-based framework, most of segmentation methods consider pixels or groups of pixels as the nodes in a graph. The edge weight estimation usually takes into account image attributes, for example color, gradient and texture. An efficient edge weight assignment method was proposed by Miranda et al. <ref type="bibr" target="#b19">[20]</ref>, where the object information obtained from user interaction as well as the image attributes are both used for estimating edge weights. Separating from the image segmentation process, it can act as a basic step for high accuracy image segmentation. Some other works studied graph structures for designing image processing operators. Image foresting transform (IFT) <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, for example, defines a minimum-cost path forest in a graph, and provides a mathematically sound framework for many image processing operations. Based on similar graphs, a theoretical analysis between optimum-path forests and minimum cut was given in <ref type="bibr" target="#b22">[23]</ref>. Under some conditions, the two algorithms were proven to produce the same result.</p><p>In our preliminary work <ref type="bibr" target="#b18">[19]</ref>, we explore the graph cuts algorithm by extending it to a region merging scheme. Starting from seed regions given by the user, graph cuts is conducted on a propagated sub-graph where the regions are regarded as the nodes of the graph. An iterated conditional mode (ICM) is studied and the maximum a posterior (MAP) estimation is obtained by virtual of graph cuts on each growing sub-graph. The segmentation process is stopped when all the regions are labeled. In <ref type="bibr" target="#b18">[19]</ref>, the initial segmentation is obtained by meanshift algorithm, which is a sophisticated segmentation technique. While in this paper, the initial segmentation is obtained by the simple watershed algorithm <ref type="bibr" target="#b23">[24]</ref>. In each iteration, a semi-supervised algorithm is applied to learn a classifier. Consequently, the most confident labels will contribute for new seed regions in the next iteration.</p><p>The proposed method is a novel extension of the standard graph cuts algorithm. Rather than segmenting the entire image all at once, the segmentation is performed incrementally. It has many advantages to do this. First of all, using sub-graph significantly reduce the complexity of background content in the image. The many unlabeled background regions in the image may have unpredictable negative effect on graph cuts optimization. This is why the global optimum obtained by graph cuts often does not lead to the most desirable result. However, by using a subgraph and blocking those unknown regions far from the labeled regions, the background interference can be much reduced, and hence better results can be obtained under the same amount of user interaction. Second, the algorithm is run on the sub-graph that comprises object/background regions and the surrounding un-segmented regions, thus the computational cost is significantly less than running graph cuts on the whole graph which is based on image pixels. Third, as a graph cuts-based region merging algorithm, our method obtains the optimal segmentation on each sub-graph. In interactive image segmentation, user input information helps to enhance the discontinuities between object and background by constructing color data models <ref type="bibr" target="#b8">[9]</ref>, which represent object and background, respectively. Some simple methods such as color histograms can be used to calculate these models. In this work, the construction of the object and the background color models are obtained from the most confident labels by a learned classifier. This scheme automatically collects more reliable information for the next round of segmentation.</p><p>Although the user input is helpful in steering the segmentation process to reduce the ambiguities, too much interaction will lead to a tedious and time-consuming work. If the object is in a complex environment from which the background cannot be trivially subtracted, a significant amount of interaction may be required. Moreover, the complex content of an image also makes it hard to provide user guidance for accurate segmentation while keeping the interaction as less as possible. Therefore, some algorithms allow further user edit based on the previous segmentation results <ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b24">25]</ref> until the desired result is achieved. In comparison to the traditional graph cuts algorithm, the proposed method is able to reduce the amount of user interaction needed for a desirable segmentation result, or that given a fixed amount of user interaction it increases the quality of the final segmentation result. Experiments show that with poor initialization (i.e. user inputs), the segmentation results of standard graph cuts algorithm might be far from what we expect, while the proposed method can still offer good results. In addition, much better segmentation results can be achieved by the proposed method for images with complex background.</p><p>The rest of this paper is organized as follows. A brief review of standard graph cuts algorithm is in Section 2. An iterated conditional mode (ICM) on graph cuts is proposed in Section 3, followed by the region merging-based localized graph cuts algorithm. Section 4 presents experimental results of the proposed method on 50 benchmark images in comparison with standard graph cuts and Grabcut. Finally the conclusion is made in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Image segmentation by graph cuts</head><p>Image segmentation can be naturally taken as a labeling problem. Given a set of labels L and a set of sites S (e.g. image pixels or regions),our goal is to assign each of the sites p A S a label f p A L. The graph cuts framework proposed by Boykov and Jolly <ref type="bibr" target="#b6">[7]</ref> addresses the segmentation on binary images, which solves a labeling problem with two labels. The label set is L ¼ f0,1g, where 0 corresponds to the background and 1 corresponds to the object. Therefore, labeling is a mapping from S to L and is denoted by f ¼ ff p jf p A Lg, i.e. label assignments to all pixels <ref type="bibr" target="#b25">[26]</ref>. An energy function in a ''Gibbs'' form is formulated as</p><formula xml:id="formula_0">Eðf Þ ¼ E data ðf ÞþlE smooth ðf Þ ð<label>1Þ</label></formula><p>The data term E data consists of constraints from the observed data and measures how sites like the labels that f assigns to them. It is usually defined to be</p><formula xml:id="formula_1">E data ðf Þ ¼ X p A S D p ðf p Þ ð<label>2Þ</label></formula><p>where D p measures how well label f p fits site p. For example, we can use intensities of marked sites (seeds) to learn the histograms for the object and the background intensity distributions PrðIj''obj'' Þ and PrðIj''bkg'' Þ. Then D p can be expressed as follows:</p><formula xml:id="formula_2">D p ð''obj'' Þ ¼ ÀlnPrðI p j''obj'' Þ ð<label>3Þ</label></formula><p>and</p><formula xml:id="formula_3">D p ð''bkg'' Þ ¼ ÀlnPrðI p j''bkg'' Þ ð<label>4Þ</label></formula><p>D p is the penalty of assigning the label f p to site p A S. The negative log-likelihoods should be small if p likes f p and vice versa. E smooth is called the smoothness term and measures the extent to which f is not piecewise smooth. The typical form of E smooth is</p><formula xml:id="formula_4">E smooth ¼ X fp,qg A N V pq ðf p ,f q Þ ð<label>5Þ</label></formula><p>where N is a neighborhood system, such as a 4-connected neighborhood system or an 8-connected neighborhood system. The smoothness term typically used for image segmentation is the Potts Model <ref type="bibr" target="#b33">[34]</ref>, which is</p><formula xml:id="formula_5">V pq ðf p ,f q Þ ¼ o pq Â Tðf p a f q Þ ð<label>6Þ</label></formula><p>where</p><formula xml:id="formula_6">Tðf p a f q Þ ¼ 1 if f p af q 0 otherwise</formula><p>The model ( <ref type="formula" target="#formula_5">6</ref>) is a piecewise constant model because it encourages labelings consisting of several regions where sites in the same region have the same labels. In image segmentation, we want the boundary to lie on the intensity edges in the image. A typical choice for o p,q is as follows:</p><formula xml:id="formula_7">o pq ¼ e ÀðjIpÀIqj 2 =2d 2 Þ Á 1 distðp,qÞ<label>ð7Þ</label></formula><p>For gray images, I p and I q are the intensities of site p and q. For color images, they are taken placed by the notations of Ĩp and Ĩq , which can be the LAB color vectors of sites p and q. distðp,qÞ is the distance between sites p and q. Parameter d is related to the level of variation between neighboring sites within the same object.</p><p>The parameter l is used to control the relative importance of the data term versus the smoothness term. If l is very small, only the data term matters. In this case, the label of each site is independent from the other sites. If l is very large, all the sites will have the same label. Minimization of the energy function can be done using the min-cut/max-flow algorithm as described in <ref type="bibr" target="#b6">[7]</ref>. Now we need to construct a graph corresponding to the energy function <ref type="bibr" target="#b0">(1)</ref>. There are two additional nodes: the source terminal s and the sink terminal t, representing the object and the background, respectively. Each node in the graph is connected to s and t by two t-links. And each pair of neighboring nodes is connected by an n-link. The weights of t-links for seed pixels can be seen as hard constraint imposed on the segmentation. In initialization, the user will mark some pixels as the object or the background so that these pixels will keep their initial labels in the final result. If pixel p is marked as an object label, the edge between p and s should be set to infinity and the edge between p and t should be set to zero. N-links correspond to the penalty for discontinuity between the two neighboring pixels. They are derived from the smoothness term E smooth in energy function <ref type="bibr" target="#b0">(1)</ref>. And the weight of a t-link corresponds to a penalty for assigning the label to the pixel. It will be derived from the data term E data in the energy function (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Iterated region merging with localized graph cuts</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Initial segmentation by modified watershed algorithm</head><p>In the original graph cuts algorithm <ref type="bibr" target="#b6">[7]</ref>, the segmentation is directly performed on the image pixels. There are two problems for such a processing. First, each pixel will be a node in the graph so that the computational cost will be high; second, the segmentation result may not be smooth, especially along the edges. Fig. <ref type="figure" target="#fig_0">1</ref> shows an example of the graph cuts segmentation result. It can be seen that although there should be clear boundary between the object and background, the graph cuts fails to give a smooth segmentation map by labeling some object pixels as background, or vice versa. Actually, in the early work of Wu and Leahy <ref type="bibr" target="#b30">[31]</ref>, it was noticed that the minimum cut criteria favored cutting small sets of isolated nodes in the graph.</p><p>To alleviate this problem, Veksler <ref type="bibr" target="#b16">[17]</ref> included a shape constraint in the graph cuts energy function, which encourages a long object boundary. Some other segmentation criterions were also proposed to solve this problem, such as normalized cuts <ref type="bibr" target="#b31">[32]</ref> and ratio cut <ref type="bibr" target="#b32">[33]</ref>. In this paper, we adopted a relatively simple but effective strategy to solve this problem by introducing some low level image processing techniques to graph cuts. In <ref type="bibr" target="#b24">[25]</ref>, Li et al. used watershed <ref type="bibr" target="#b23">[24]</ref> for initial segmentation to speed up the graph cuts optimization process in video segmentation. With such initialization, the image can be partitioned into many small homogenous regions, and then each region, instead of each pixel, is taken as a node in the graph. In this way the computational cost can be reduced significantly, while the object boundary can be better preserved. The watershed technique is also used in this paper with some modification.</p><p>Watershed algorithm produces coherent over-segmented regions which preserve most structures of the interest object. However, the standard watershed algorithm is very sensitive to noise and thus leads to severe over-segmentation (see Fig. <ref type="figure" target="#fig_1">2</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b)).</head><p>There are some edge-preserving smoothing techniques, such as median filtering, can help to reduce noise and trivial structures. Therefore, to reduce over-segmentation, we apply median filtering on the gradient image before conducting the watershed algorithm. Fig. <ref type="figure" target="#fig_1">2</ref> shows an example. Fig. <ref type="figure" target="#fig_1">2</ref>(a) is the gradient image of the original image in Figs. <ref type="figure" target="#fig_0">1(a</ref>) and 2(b) is the watershed segmentation of it. Clearly, there is a severe over-segmentation in Fig. <ref type="figure" target="#fig_1">2(b)</ref>. Such small regions are not reliable for calculating the region statistics and they will also increase the computational cost in our region merging algorithm. Fig. <ref type="figure" target="#fig_1">2(c</ref>) is the median filtering output of the gradient image in Figs. <ref type="figure" target="#fig_1">2(a)</ref> and<ref type="figure">(d)</ref> is the watershed segmentation result on it. We see that the oversegmentation is significantly reduced, while the contour of the object is well preserved. Note that we can use more sophisticated initial segmentation techniques in the proposed method. To weaken the importance of initial segmentation, the watershed algorithm is adopted for its simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Iterated conditional mode</head><p>Although graph cuts technique provides an optimal solution to the energy function (1) for image segmentation, the complex content of an image makes it hard to precisely segment the whole image all at once. In the proposed region merging-based segmentation algorithm, the one-shot minimum cut estimation algorithm is replaced by a novel iterative procedure, in which the object/ background distributions are updated according to the previous segmentation results and new nodes are added until the whole image is segmented. This problem is studied in a way like the iterated conditional mode (ICM) proposed by Besag <ref type="bibr" target="#b26">[27]</ref>, where the local conditional probabilities is maximized sequentially.</p><p>In computer vision, an image can be represented by a graph G ¼ /V,ES, where V is a set of nodes corresponding to image elements (e.g. pixels, regions), and E is a set of edges connecting the pairs of nodes. We say two nodes are incident with an edge and that these nodes are adjacent or neighbors of each other. Edge weights of the graph are computed as the dissimilarity between the connected nodes (e.g. the distance of region histograms). A sub-graph G 0 ¼ /V 0 ,E 0 S can be defined such that V 0 DV and E 0 D E. In this paper, we consider image regions as the graph nodes, and the neighborhood of a node in V' corresponds to its adjacent regions in the image. Inspired by ICM, we consider the graph cuts algorithm in a ''divide and conquer'' style: finding the minima on the sub-graph and extending the sub-graph successively until reach the whole graph. The proposed method works iteratively, in place of the previous one-shot graph cuts algorithm <ref type="bibr" target="#b6">[7]</ref>.</p><p>Given the observed data d p of site p, the label f p of site p and the set of labels f SÀfpg which is at the site in S Àfpg, where f p A L and S Àfpg is the set difference. We sequentially assign each f i by maximizing conditional probability Pðf p jd p ,f S-fpg Þ under the MAP-MRF framework. There are two assumptions in calculating Pðf p jd p ,f SÀfpg Þ. First, the observed data d 1 , . . . ,d m are conditionally independent given f and that each d p depends only on f p . Second, f depends on labels in the local neighborhood, which is Markovianity, i.e. Pðf p jd p ,f SÀfpg Þ ¼ Pðf p jf Np Þ, where N p is a neighborhood system of site p. Markovianity depicts the local characteristics of labeling. With the two assumptions we have</p><formula xml:id="formula_8">Pðf p jd p ,f SÀfpg Þ ¼ Pðd p jf p Þ Á Pðf p jf Np Þ PðdÞ<label>ð8Þ</label></formula><p>where P(d) is a normalizing constant when d is given. There is</p><formula xml:id="formula_9">Pðf p jd p ,f SÀfpg ÞpPðd p jf p Þ Á Pðf p jf Np Þ ð<label>9Þ</label></formula><p>where p denotes the relation of direct proportion. The posterior probability satisfies</p><formula xml:id="formula_10">Pðf p jd p ,f SÀfpg Þpe ÀUðfpjdp,f Np Þ<label>ð10Þ</label></formula><p>where Uðf p jd p ,f Np Þ is the posterior energy and satisfies</p><formula xml:id="formula_11">Uðf p jd p ,f Np Þ ¼ Uðd p jf p ÞþUðf p jf Np Þ ¼ Uðd p jf p Þþ X p 0 A Np Uðf p jf p 0 Þ ð<label>11Þ</label></formula><p>Uðd p jf p Þ is the data term corresponding to function (1), and P p 0 A Np Uðf p jf p 0 Þ is the smoothness term which relates to the number of neighboring sites whose labels f p' differ from f p . The MAP estimate is equivalently found by minimizing the posterior energy:</p><formula xml:id="formula_12">f k þ 1 ¼ argmin f Uðf jd,f k N Þ ð<label>12Þ</label></formula><p>where f k N is the optimal labeling of graph nodes obtained in previous k iterations. The labeling result in each iteration is reserved for later segmentation. This process is done until the whole image is labeled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Iterated region merging</head><p>The proposed iterated region merging method starts from the initially segmented image by the modified watershed algorithm in Section 3.1. Fig. <ref type="figure" target="#fig_3">3</ref> illustrates the iterative segmentation process by using an example. In each iteration, new regions which are in the neighborhood of newly labeled object and background regions are added into the sub-graph, while the other regions keep their labels unchanged.</p><p>The proposed algorithm is summarized in Table <ref type="table">1</ref>. The inputs consist of the initial segmentation from watershed segmentation and user marked seeds. The object and background data models are updated based on the labeled regions from the previous iteration. In <ref type="bibr">Section 3.4</ref>, the algorithm to construct data models will be discussed in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Update object/background models</head><p>Incorporating user input information in segmentation is one of the most interesting features of graph cuts method <ref type="bibr" target="#b7">[8]</ref>. There is a lot of flexibility in how the information can be used to adjust the algorithm for a desired segmentation, for example, initializing the algorithm or editing the results. With the given information, the object and background models can be learned for formulating the data term in function <ref type="bibr" target="#b0">(1)</ref>, which describes how well label f p fits site p. In step 2 of the proposed Algorithm 1, the models are updated based on the previously labeled regions. However, if all the labeled regions are used to update the models, the misclassified regions will probably reinforce themselves in the next round of iteration. Therefore, we propose a semi-supervised approach in which the labeled regions in the ðiÀ1Þth iteration are partially selected to be the seeds for the ith iteration. This model updating process is independent of the graph cuts optimization algorithm, aiming is to increase the confidence levels of the color models. The main idea of our object/background models updating process can be summarized as follows: in each iteration, a set of confident labels is chosen by a semi-supervised approach, such that the corresponding regions are taken as confident regions. Based on these confident regions, new object/background models are constructed for the graph cuts segmentation, as an integral step of the proposed Algorithm 1.</p><p>There are a number of semi-supervised algorithms which use both labeled and unlabeled data to build classifiers. With the merits of less human effort and higher accuracy, they are of great interest in practice. The Yarowsky algorithm <ref type="bibr" target="#b27">[28]</ref> is a well-known semi-supervised algorithm, which is widely used in computational linguistics. Some variants of the original Yarowsky algorithm <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> were also developed to optimize specific objective functions. In this section, we adopt it to build better object/ background models for the proposed iterated segmentation algorithm.</p><p>Suppose f x ðjÞ is the probability that instance x belongs to the jth class, and p x ðjÞ is the score of the model in predicting label j for the region x. An object function based on cross-entropy is defined as <ref type="bibr" target="#b28">[29]</ref> lðf,pÞ ¼ X</p><formula xml:id="formula_13">x A X Hðf x jjp x Þ ¼ X x A X X j f x ðjÞlog 1 p x ðjÞ<label>ð13Þ</label></formula><p>The minimization of function <ref type="bibr" target="#b12">(13)</ref> encourages the unlabeled data becomes labeled, and its assigned label agrees with the model prediction. Since the goal is to build color models based on previously labeled regions, we would like to choose the regions whose predictions are most confident according to the Yarowsky algorithm. With the fact that seeds regions in the ðiÀ1Þth iteration are confident for the graph cut segmentation, we only have to decide which are the confident regions resulting from the graph cut in the ðiÀ1Þth iteration. The Algorithm 2 in Table <ref type="table">2</ref> describes the process of how to choose the labeled regions in the ðiÀ1Þth iteration for constructing color models of the ith iteration, which is corresponding to step 3 in Algorithm 1.  -Labeled regions X after the 1 st iteration, which contain Y 0 and their adjacent regions ?.</p><p>Output: labeling Y i þ 1 . 1. For i A f0,1, . . .g do. 2. 4 i ¼ fx A XjY i a ?g.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>Train classifier on ð4 i ,Y i Þ; resulting in p i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">For each example</head><formula xml:id="formula_14">x A X 4.1 set ŷ ¼ argmax j p i þ 1 x ðjÞ 4.2 set Y i þ 1 ¼ Y 0 x if x A 4 0 ŷ if x A p i 3p i þ 1 x ð ŷÞ4 1=L ? otherwise 8 &gt; &lt; &gt; : 5. If Y i þ 1 ¼ Y i , stop. Otherwise, go 1. 6. return Y i .</formula><p>In Algorithm 2, the outer loop is given a seed set Y 0 to start with. In step 2, a labeled training set 4 i is constructed from the most confident predictions Y i . The score p x ðjÞ is related to all the feature values in a sample x, and is given by</p><formula xml:id="formula_15">p x ðjÞ ¼ 1 jF x j X f A F i y fj<label>ð14Þ</label></formula><p>where y fj ¼ ðj4 fj jþ1=LjV f jÞ=ðj4 f jþjV f jÞ, jF x j is the number of features of a region x, L is the number of labels, j4 fj j is the number of regions with label j and feature f; jV f j and j4 f j are, respectively, the numbers of unlabeled and labeled regions that have feature f. The feature used here is the average RGB color of a region. Abney <ref type="bibr" target="#b28">[29]</ref> proved that the definition of score p x ðjÞ can promise the object function ( <ref type="formula" target="#formula_13">13</ref>) to decrease with the iteration number until it reaches a minimum. The predicted label for region is given in step 4.1 in Algorithm 2, where it is assumed that the classifier makes confidence-weighted predictions.</p><p>To check the relationship between the object and background distributions, we use the relative entropy to evaluate the distance between them. It is defined as the Kullback-Leibler distance from the distribution of foreground to that of the background, i.e. D KL ðpjjqÞ ¼ P</p><p>x A X pðxÞlogðpðxÞ=qðxÞÞ, where p(x) and q(x) are the probability density functions of the object and background, respectively. Fig. <ref type="figure">4</ref> shows the value of relative entropy in all the seven iterations for the image in Fig. <ref type="figure" target="#fig_3">3</ref>. As the value of relative entropy goes up from the first iteration, the data models of the object and background become more and more distinguishable. This leads to a higher probability of well separating the object from the background.</p><p>In the proposed algorithm, segmentation is obtained on different levels of sub-graphs. In light of graph cuts, the segmentation keeps the property of global optimality on each sub-graph. Adding new seeds according to the previous optimal labeling, it increases the amount of useful information that can be used for further segmentation while avoiding introducing much interference information from unknown regions. Fig. <ref type="figure">5</ref> shows the energy evolution of the image segmentation process in Fig. <ref type="figure" target="#fig_3">3</ref>. Fig. <ref type="figure" target="#fig_4">6</ref> shows 4. Relative entropy of the object and background distributions (Fig. <ref type="figure" target="#fig_3">3</ref>) in different iterations. The three plots represent the red, green and blue color channels, respectively. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) Fig. <ref type="figure">5</ref>. The energy evolution of the segmentation results in Fig. <ref type="figure" target="#fig_3">3</ref>. Graph cuts energy decreases in the iterated segmentation process. another example. With the user input seeds (Fig. <ref type="figure" target="#fig_4">6</ref>), the amount of object and background seeds increases automatically based on the segmentation result in each iteration. It is straightforward that our algorithm guarantees the monotonic decrease of energy because iterative minimization can be taken as a multi-step minimization of the total energy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results</head><p>We evaluate the segmentation performance of the proposed method in comparison with the graph cuts algorithm <ref type="bibr" target="#b6">[7]</ref> and GrabCut <ref type="bibr" target="#b8">[9]</ref>. Since we use watershed for initial segmentation, for a fair comparison, we also extend the standard graph cuts to a region-based scheme, i.e. we use the regions segmented by watershed, instead of the pixels, as the nodes in the graph. GrabCut algorithm is also an interactive segmentation technique based on graph cuts and has the advantage of reducing user's interaction under complex background. It allows the user to drag a rectangle around the desired object. Then the color models of the object and background are constructed according to this rectangle. Hence in total we have four algorithms in the experiments: the pixel-based graph cuts (denoted by GC p ), the regionbased graph cuts (GC r ), the GrabCut and the proposed iterated region merging method with localized graph cuts (denoted by IRM-LGC). The software of the proposed method can be downloaded at http://www.comp.polyu.edu.hk/~cslzhang/code.htm.</p><p>In Sections 4.1 and 4.2, the four algorithms are evaluated qualitatively. In Section 4.3, the segmentation results are evaluated quantitatively. Some discussions are made in Section 4.4. Our experiment database contains 50 benchmark test images selected from online resources,<ref type="foot" target="#foot_1">1</ref>,<ref type="foot" target="#foot_2">2</ref> where 10 of them contain objects with simple background and the others are images with relatively complex background. Every image in our database has a figure-ground assignment labeled by human subjects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Comparison with graph cuts</head><p>In this subsection, the segmentation results are compared between the proposed algorithm and algorithms GC p and GC r . Note that GC r algorithm is used as the first step in lazy snapping <ref type="bibr" target="#b9">[10]</ref>. This experiment can thus partially compare the performance of lazy snapping and IRM-LGC. However, a direct comparison of the two methods is not a fair choice, since lazy snapping has another refinement step which adjusts the mis-located boundaries produced by the first step. Fig. <ref type="figure">7</ref> shows some images with simple background. In these examples, it is relatively easy to extract the objects from the background. Therefore, some of the results by GC p or GC r are not too bad, while the proposed method works better.</p><p>Extracting objects of interest from complex background is a more challenging task. Fig. <ref type="figure">8</ref> shows some images with relatively complex background and their segmentation results. In these images, the objects contain weak boundaries due to poor contrast and noise, and the colors of some background regions are very close to those of the objects. Given the same amount of user input, the proposed IRM-LGC achieves much better segmentation results than the GC p and GC r algorithms. When the objects to be segmented contain similar colors with the background, GrabCut might fail to correctly segment them. Although our algorithm uses more user interaction than GrabCut, this tradeoff leads to more precise segmentation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison with GrabCut</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Quantitative evaluation</head><p>To better evaluate our algorithm, a quantitative evaluation of the segmentations is given by comparing with ground truth labels in the database. The qualities of segmentation are calculated by using four measures: the true-positive fraction (TPF), false-positive fraction (FPF), true-negative fraction (TNF) and false-negative fraction (FNF):</p><formula xml:id="formula_16">TPF ¼ jA A \ A G j jA G j , FPF ¼ jA A ÀA G j jA G j TNF ¼ jA A [ A G j jA G j , FNF ¼ jA G ÀA A j jA G j</formula><p>where A G represents the area of the ground truth of foreground and its complement is A G ; A A represents the area of segmented foreground by the tested segmentation method. Table <ref type="table" target="#tab_0">3</ref> lists the results of TPF, FNF, TNF and FPF by the three methods over the 50 test images. We see the proposed method achieves the best TPF, FNF, TNF and FPF results.</p><p>As mentioned, the proposed IRM-LGC image segmentation method uses a modified watershed algorithm for initial segmentation. The median filtering of the gradient image controls the watershed segmentation output. To examine how the initial segments affect the final result of IRM-LGC, we applied the algorithm to different initial segmentation with different granularities, i.e. different numbers and sizes of regions in the initial segmentation. This can be done by changing the filtering times and using different sizes of filter windows. Fig. <ref type="figure" target="#fig_8">10</ref> shows an example. The first row shows three initial segmentations by the modified watershed algorithm, where the number of regions is 203, 372 and 1296, respectively. The second row shows the final segmentation results. We can see that segmentation quality is not sensitive to the initial segmentation. Fig. <ref type="figure" target="#fig_9">11</ref> compares the segmentation quality of the same image with 42 different initial segmentations, from which we can clearly see that the segmentation results are not influenced much by the initialization.   We use the max-flow algorithm <ref type="bibr" target="#b36">[37]</ref> to implement the proposed IRM-LGC method. The worst case running time complexity for this algorithm is Oðmn 2 jCjÞ, where n is the number of nodes, m is the number of edges and jCj is the cost of the minimum cut in the graph. In each iteration of IRM-LGC, the number of nodes and edges are largely reduced in comparison of the pixel-based graph cuts algorithm. Our experiment is implemented on a PC with Intel Core 2 Duo 2.66 GHz CPU, 2 GB memory. The running time to perform min-cut/max-flow algorithm on the whole graph which is based on image pixels is around 10-20 ms, while the proposed IRM-LGC takes far less than 1 ms. However, it should be noted that the majority of time for our algorithm is spent on constructing color models and updating the graph ( $ 0:3 s per iteration), thus the speedup on the mincut/max-flow part would be relatively modest for the overall algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Discussion</head><p>In graph cuts-based segmentation, parameter l is used to weight the data and smoothness terms. In recent years, some literature <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref> has studied the parameter selection for graph cuts. There are two problems in graph cuts algorithm about the selection of l. First, given different images, graph cuts with a fixed value of l cannot lead to satisfactory segmentation. The appropriate l values would vary largely among different images, so the user may have to spend a significant amount of time searching for it. Fortunately, the proposed IRM-LGC is not sensitive to the selection of l across different images. This can be illustrated by the following experiments. In practice we found that the regionbased graph cuts (i.e. GC r ) has similar property to pixel-based graph cuts(i.e. GC p ) in parameter selection. Sometimes, GC r may not lead to satisfying segmentation result throughout the searching space of l. Thus to study on a more general case, the GC p is used in the following experiments. Fig. <ref type="figure" target="#fig_10">12</ref> shows some examples of the segmentation by GC p and IRM-LGC. For a comparable quality of the segmentation results by the two methods, the best value of parameter l in GC p varies a lot for different images (2nd row in Fig. <ref type="figure" target="#fig_10">12</ref>); however, a constant l in IRM-LGC can lead to satisfying segmentations across different images (3rd row in Fig. <ref type="figure" target="#fig_10">12</ref>).</p><p>The second problem of standard graph cuts is that different values of l will result in very different segmentation results for the same image. Fig. <ref type="figure" target="#fig_12">13</ref> compares GC p and IRM-LGC by increasing the value of parameter l. The original image with user input seeds is in Fig. <ref type="figure" target="#fig_10">12</ref>(a). In Fig. <ref type="figure" target="#fig_12">13</ref>(a), GC p produces a relatively good segmentation with l ¼ 2. In Figs. <ref type="figure" target="#fig_12">13(b</ref>) and (c), it produces big segmentation errors with l ¼ 50 and 150, respectively. However, by using IRM-LGC, we can obtain similar and good segmentation results for a wide range of values: l ¼ 2, 50 and 150. IRM-LGC can reduce greatly the search range of l. On most of the test images in our database, l is roughly between 50 and 100 for the proposed method, while for GC p , the values vary from 10 to 200. An explanation for this is that if the data term in energy function can provide sufficient information for labeling, the graph node does not need a strong relationship with its neighbors. The proposed method gives good object/background models as iteration process goes on, thus the changes of l for various image can be reduced. This brings much benefit for users in real applications.</p><p>Although graph cuts algorithm has relaxed the user input compared with some other algorithms, such as livewire <ref type="bibr" target="#b0">[1]</ref>, the input seeds cannot always efficiently indicate the background regions, therefore, when the connecting regions of the object and background have similar colors, they are still hard to be segmented correctly. It is empirically found that if the input seeds can cover the main features of the object and background, good segmentation result can be obtained. Some promising work <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b22">23]</ref> has exploited effective methods for arc weight estimation during the seeds marking process. Their work takes into account image attributes and object information in order to enhance the discontinuities between object and background, whereas a visual feedback can be provided to the user for the next action. We will investigate how to incorporate these methods into our work in the future. Fig. <ref type="figure" target="#fig_11">14</ref> shows a failure example. The regions circled in red only connect to object regions on the sub-graph, so they are easily assigned to the same label. Moreover, our method uses an initial segmentation to partition the image into regions, incorrect partition in initialization will also affect the final segmentation result.</p><p>IRM-LGC is independent of the initial segmentation step. However, under-segmented regions from the naive watershed algorithm cannot be re-partitioned due to the region merging style of IRM-LGC. To reduce the over-segmentation and well keep the coherence of regions, more sophisticated pre-segmentation algorithms can be adopted for the initialization. For example, connected filters with morphological reconstruction operators can eliminate or merge connected components produced by watershed algorithm <ref type="bibr" target="#b20">[21]</ref>. Hence they might be used as a more suitable tool for improving the initial segmentation quality than median filters.</p><p>As in traditional graph cuts algorithm, in the proposed IRM-LGC the user input information is also crucial for obtaining desirable segmentation. Since the newly added seeds in each iteration depend on the segmentation results in the previous iteration, the misclassified regions will probably destroy the rest part of segmentation. In the future work, other strategies of seeds selection will be taken into account. For example, the work in <ref type="bibr" target="#b19">[20]</ref> does not use the seeds from previous delineation to re-compute the edge weights. It makes the well-segmented regions unchanged and, therefore, the segmentation process becomes more traceable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This paper proposed an iterative region merging-based image segmentation algorithm by using graph cuts for optimization. The proposed algorithm starts from the user labeled sub-graph and works iteratively to label the surrounding un-segmented regions. It can reduce the interference of unknown background regions far from the labeled regions so that more robust segmentation can be obtained. With the same amount of user input, our algorithm can achieve better segmentation results than the standard graph cuts, especially when extract the object from complex background. Qualitative and quantitative comparisons with standard graph cuts and GrabCut show the efficiency of the proposed method.</p><p>Moreover, the search space of parameter l in graph cuts is also reduced greatly by the iterated region merging scheme.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) Original image with user input seeds. The background seeds are in green, and object seeds are in red. (b) The segmentation results by standard graph cuts. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)</figDesc><graphic coords="3,51.08,607.00,234.00,97.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Initial segmentation using modified watershed algorithm. (a) is the gradient image of Fig. 1(a); (c) is the median filtering result of (a); (b) and (d) are the watershed segmentation results of (a) and (c), respectively. We see that the over-segmentation is significantly reduced in (d).</figDesc><graphic coords="4,136.72,58.64,312.12,259.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Table 1 3 . 5 .</head><label>135</label><figDesc>Iterated region merging with localized graph cuts. Algorithm1 : RegionMergingGraphCuts() Input: -Initial segmentation of the given image. -User labeled object regions R o and background regions R b . Output: Segmentation result. 1. Build object and background data models based on labeled regions R o and R b . 2. Build sub-graph G 0 ¼ /V 0 ,E 0 S, where V' consist of R o , R b and their adjacent regions. Update object and background data models using the SelectLabels() algorithm (refer to section 3.4). 4. Use graph cuts algorithm to solve the min-cut optimization on G', i.e. Update object regions R o and background regions R b according to the labeling results from step 4. 6. Go back to step 2, until no adjacent regions of R o and R b can be found. 7. Return the segmentation results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The iterative segmentation process. (a) Initial segmentation. (b)-(e) show the intermediate segmentation results in the 1st, 2nd, 3rd and 4th iterations. The newly added regions in the sub-graphs are shown in red color and the background regions are in blue color. We can see the target object is well segmented from the background in (f). (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)</figDesc><graphic coords="5,146.53,58.64,312.12,180.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Another example of energy evolution. (a)-(f) show the object and background seeds in different iterations based on the user input seeds shown in (g). (h) shows the final segmentation result, and (i) shows the energy values, which are calculated on the whole graphs by using the seeds obtained in each iteration. We see that the energy decreases monotonically.</figDesc><graphic coords="6,112.77,471.69,360.00,275.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig. 7. Segmentation results of images with simple background. The first row shows the original images with seeds. Red strokes are for the object and the green strokes are for the background. The second to the forth row show the segmentation results by GCp, GCr and IRM-LGC, respectively. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)</figDesc><graphic coords="7,146.57,58.64,312.12,302.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Segmentation results by GrabCut and the proposed method. The left column shows the original images with seeds. The blue rectangle is the interaction used in GrabCut, while the red and green strokes are the object and background seeds used in the proposed algorithm. The middle column shows the results of GrabCut. The right column shows results of IRM-LGC. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)</figDesc><graphic coords="8,112.77,58.64,360.00,427.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9</head><label>9</label><figDesc>Fig. 9 compares the results of IRM-LGC and GrabCut. The left column shows the original images with the seeds points. The middle column shows the segmentation results of GrabCut. Implementation of GrabCut uses 5 GMMs to model RGB color data and parameter l is set to be 50. The right column is results of IRM-LGC. When the objects to be segmented contain similar colors with the background, GrabCut might fail to correctly segment them. Although our algorithm uses more user interaction than GrabCut, this tradeoff leads to more precise segmentation results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Initial segmentation of an image with different numbers of regions. In the first row, from the left to the right, there are 203, 372 and 1296 regions in the initial segmentation, respectively. The second row shows the final segmentation results.</figDesc><graphic coords="9,122.58,562.46,360.00,159.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Segmentation qualities versus initial segmentation in different granularities. For the original image used in Fig. 10, 42 different initial segmentations are obtained and used in the proposed algorithm. The segmentation quality is measured by TPF, FPF, TNF and FNF scores.</figDesc><graphic coords="9,320.07,346.20,234.00,159.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. The values of parameter l in GCp and IRM-LGC for different images. (a) Images with user input seeds, (b) Gcp,l ¼ 18, (c) Gcp,l ¼ 50, (d) Gcp,l ¼ 170, (e) IRM-LGC,l ¼ 50, (f) IRM-LGC,l ¼ 50, (g) IRM-LGC,l ¼ 50.</figDesc><graphic coords="10,112.77,446.04,360.00,276.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. A failure example of the proposed method.</figDesc><graphic coords="11,50.48,288.77,235.44,76.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Image segmentation with different parameter values. (a-c) show the segmented objects by GCp and (d-f) show the segmented objects by IRM-LGC.</figDesc><graphic coords="11,122.58,58.64,360.00,192.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 3</head><label>3</label><figDesc>The TNF, TPF, FNF and FPF results by different methods.</figDesc><table><row><cell>Algorithms</cell><cell>TPF (%)</cell><cell>FNF (%)</cell><cell>TNF (%)</cell><cell>FPF (%)</cell></row><row><cell>GrabCut</cell><cell>83.65</cell><cell>16.35</cell><cell>96.59</cell><cell>3.41</cell></row><row><cell>GC p</cell><cell>82.72</cell><cell>17.28</cell><cell>92.37</cell><cell>7.63</cell></row><row><cell>GC r</cell><cell>88.01</cell><cell>11.99</cell><cell>93.78</cell><cell>6.22</cell></row><row><cell>IRM-LGC</cell><cell>91.29</cell><cell>8.71</cell><cell>97.75</cell><cell>2.25</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>B. Peng et al. / Pattern Recognition 44 (2011) 2527-2538</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>http://www.research.microsoft.com/vision/cambridge/segmentation/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>http://www.cs.berkeley.edu/projects/vision/grouping/segbench/</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This research is supported by the Hong Kong SAR General Research Fund (GRF) under Grant no. PolyU 5330/07E and the National Science Foundation Council (NSFC) of China Grant no. 60973098.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">User steered image segmentation paradigms, live wire and live lane</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Falcão</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Udupa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Samarasekara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Graphical Models and Image Processing</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="233" to="260" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An ultra-fast user-steered image segmentation paradigm: live-wire-on-the-fly</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Falcão</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Udupa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Miyazawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="62" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Active contours with selective local or global segmentation: a new formulation and level set method</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="668" to="676" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Active contours driven by local image fitting energy</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1199" to="1206" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Snakes: active contour models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="321" to="331" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fronts propagating with curvature dependent speed: algorithm based on hamilton jacobi formulations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Sethian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="12" to="49" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Interactive graph cuts for optimal boundary and region segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Jolly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision I</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Graph cuts and efficient n-d image segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Funka</forename><surname>Lea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="131" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Grabcut-interactive foreground extraction using iterated graph cuts</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="page" from="309" to="314" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
		<title level="m">Lazy snapping, SIGGRAPH</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="303" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Paint selection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>SIGGRAPH</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bi-layer segmentation of binocular stereo video</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference of Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="407" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Computing geodesics and minimal surfaces via graph cuts</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="26" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">What metrics can be approximated by geo-cuts, or global optimization of length/area and flux</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="564" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Interactive graph cut based segmentation with shape prior</title>
		<author>
			<persName><forename type="first">D</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="755" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semiautomatic segmentation with compact shape prior</title>
		<author>
			<persName><forename type="first">P</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zavadsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="206" to="219" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Star shape prior for graph-cut image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th European Conference on Computer Vision</title>
		<meeting>the 10th European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">III</biblScope>
			<biblScope unit="page" from="454" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Topology cuts: a novel min-cut/maxflow algorithm for topology preserving segmentation in N-D images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Samaras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="90" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Iterated graph cuts for image segmentation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Ninth Asian Conference on Computer Vision (ACCV)</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Synergistic arc-weight estimation for interactive image segmentation using graphs</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A V</forename><surname>Miranda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Falcão</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Udupa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="85" to="99" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The image foresting transform: theory, algorithms, and applications</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Falcão</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stolfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Lotufo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="29" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Interactive volume segmentation with differential image foresting transforms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Falcão</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P G</forename><surname>Bergo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1100" to="1108" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Links between image segmentation based on optimum-path forest and minimum cut in graph</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A V</forename><surname>Miranda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Falcão</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="128" to="142" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Watersheds in digital spaces: an efficient algorithm based on immersion simulations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Soille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="583" to="598" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Video object cut and paste</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="595" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Efficient approximate energy minimization via graph cuts</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1222" to="1239" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On the statistical analysis of dirty pictures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Besag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series B</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="259" to="302" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unsupervised word sense disambiguation rivaling supervised methods</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 33rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="189" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Understanding the Yarowsky algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Abney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="365" to="395" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Analysis of semi-supervised learning with the Yarowsky algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Haffari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sarkar</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="2007" to="2007" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An optimal graph theoretic approach to data clustering Theory and its application to image segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leahy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1101" to="1113" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference of Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="731" to="737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Image segmentation with ratio cut</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Siskind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="675" to="690" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Markov random fields with efficient approximations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="648" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Applications of parametric maxflow in computer vision</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 11th International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Parameter selection for graph cut based image segmentation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<publisher>BMVC</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1124" to="1137" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">She received the second M.Sc. degree in University of Western Ontario in 2008. Now she is a Ph.D. candidate in the Department of Computing, The Hong Kong Polytechnic University. Her research interests include Computer Vision, Graph Based Optimization, Pattern Recognition</title>
	</analytic>
	<monogr>
		<title level="m">Lei Zhang received the B.S. degree in 1995 from Shenyang Institute of Aeronautical Engineering</title>
		<meeting><address><addrLine>Shenyang; Xi&apos;an, P.R. China, respectively</addrLine></address></meeting>
		<imprint>
			<publisher>Bo Peng received the B.S. and M.Sc. degrees from University of electronic science and technology of China</publisher>
			<date type="published" when="1998">2003. 2006. 1998. 2001. 2001 to 2002. January 2003 to January 2006. January 2006</date>
		</imprint>
		<respStmt>
			<orgName>Northwestern Polytechnical University ; The Hong Kong Polytechnic University ; Department of Electrical and Computer Engineering, McMaster University, Canada. Since ; The Hong Kong Polytechnic University</orgName>
		</respStmt>
	</monogr>
	<note>Pattern Recognition, Multisensor Data Fusion and Optimal Estimation Theory. Dr. Zhang is an associate editor of IEEE Trans. on SMC-C</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The Kluwer International Series on Biometrics, and an Associate Editor of several international journals. His research interests include automated biometrics-based authentication, pattern recognition, biometric technology and systems. As a principal investigator</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Harbin</surname></persName>
		</author>
		<author>
			<persName><surname>China</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Image and Graphics</title>
		<editor>
			<persName><forename type="first">)</forename><surname>Ijig</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Book</forename><surname>Editor</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1983">1983. 1985. 1994. 1986 to 1988</date>
			<pubPlace>Waterloo, Canada; Beijing, China; Beijing, China</pubPlace>
		</imprint>
		<respStmt>
			<orgName>David Zhang graduated in computer science from Peking University in 1974 and received his M.Sc. and Ph.D. degrees in Computer Science and Engineering from the Harbin Institute of Technology (HIT ; Postdoctoral Fellow at Tsinghua University</orgName>
		</respStmt>
	</monogr>
	<note>Currently, he is a Professor with the Hong Kong Polytechnic University, Hong Kong. He is Founder and Director of Biometrics Research Centers supported by the Government of the Hong Kong SAR (UGC/CRC). he has finished many biometrics projects since 1980. So far, he has published over 200 papers and 10 books</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Jian Yang received B.S. degree from Xuzhou Normal University in 1995 and received his M.S. degree from Changsha Railway University in 1998. He received the Ph.D. degrees in Pattern Recognition and Intelligence System at Nanjing University of Science and Technology in 2002. His current interests include pattern recognition, biometrics, dimensionality reduction, discriminant analysis, machine learning, and image processing</title>
		<imprint/>
		<respStmt>
			<orgName>Nanjing University of Science and Technology</orgName>
		</respStmt>
	</monogr>
	<note>He is an associate editor of Pattern Recognition Letters and Neurocomputing. Now he is a professor in school of computer science and technology</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
