<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Stochastic Optimization for PCA and PLS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Raman</forename><surname>Arora</surname></persName>
							<email>arora@ttic.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
								<address>
									<addrLine>6045 S. Kenwood Ave. Chicago</addrLine>
									<postCode>60637</postCode>
									<region>Illinois</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Cotter</surname></persName>
							<email>cotter@ttic.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
								<address>
									<addrLine>6045 S. Kenwood Ave. Chicago</addrLine>
									<postCode>60637</postCode>
									<region>Illinois</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Karen</forename><surname>Livescu</surname></persName>
							<email>klivescu@ttic.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
								<address>
									<addrLine>6045 S. Kenwood Ave. Chicago</addrLine>
									<postCode>60637</postCode>
									<region>Illinois</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nathan</forename><surname>Srebro</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
								<address>
									<addrLine>6045 S. Kenwood Ave. Chicago</addrLine>
									<postCode>60637</postCode>
									<region>Illinois</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Stochastic Optimization for PCA and PLS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7ADF2511B176D2728EDE95EA9382063A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We study PCA, PLS, and CCA as stochastic optimization problems, of optimizing a population objective based on a sample. We suggest several stochastic approximation (SA) methods for PCA and PLS, and investigate their empirical performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>In this paper we consider the Principal Component Analysis (PCA), Partial Least Squares (PLS), and Canonical Correlation Analysis (CCA) problems as stochastic optimization problems, of optimizing an objective functional of an unknown distribution based on i.i.d. draws from the distribution.</p><p>In PCA, we consider an unknown source distribution D over R d and would like to find the k-dimensional subspace maximizing the (uncentered) variance of D inside the subspace. For PLS and CCA we consider covariances and correlations of a joint distribution over a pair of vectors; this will be formalized in Section IV. In all cases, our true objective refers to D itself, and we can never actually calculate it, instead estimating the objective based on i.i.d. samples. We focus on the "data-laden" regime, where we have access to effectively as many samples as we would like, and the bottleneck is the required runtime to process these samples. That is, we focus on the runtime required to achieve a good objective value.</p><p>The straightforward approach is "Sample Average Approximation" (SAA), where we collect a sample of data points, and then optimize an empirical version of the objective on the sample using standard deterministic techniques (in this case linear algebra). In the case of uncentered PCA, this amounts to computing the empirical second-moment matrix of the sample, and then seeking the best rank-k approximation to it, e.g. by computing the leading components of its eigendecomposition. The success of this approach is measured not by how well we approximate the empirical second-moment matrix, but rather how well the subspace we obtain captures the unknown source distribution (i.e. the population secondmoment matrix).</p><p>The alternative, which we advocate here, is a "Stochastic Approximation" (SA) approach. A SA algorithm is an iterative algorithm, where in each iteration a single sampled point is used to perform an update, as in Stochastic Gradient Descent (SGD, the classic stochastic approximation algorithm). In the context of PCA this means iteratively using vectors sampled from D to update the subspace being considered.</p><p>Stochastic approximation has been shown to be computationally preferable to statistical average approximation (i.e. to "batch" methods) both theoretically and empirically for learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> and more broadly for stochastic optimization <ref type="bibr" target="#b2">[3]</ref>. Accordingly, SA approaches, mostly variants of SGD, are often the methods of choice for many learning problems, especially when very large data sets are available <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref>.</p><p>Our goal is to formalize PCA and PLS as stochastic optimization problems, study the runtime needed to achieve an accuracy goal on the population objective, and investigate different SA approaches. We also consider CCA as a stochastic optimization problem, and discuss why it is not amenable to the same type of stochastic optimization approaches as we use for PCA and PLS. In particular, we present three SA approaches to PCA-a stochastic power method related to the popular generalized Hebbian algorithm <ref type="bibr" target="#b6">[7]</ref>, a novel truncated incremental SVD approach, and an adaptation of an online method by Warmuth and Kuzmin <ref type="bibr" target="#b7">[8]</ref>. We then adapt the methods to PLS and study their empirical behavior for both PCA and PLS, as well as compare them to the SAA (empirical optimization) approaches to these problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. STOCHASTIC OPTIMIZATION FOR PCA</head><p>We consider PCA as a problem of finding the maximal (uncentered) variance k-dimensional subspace with respect to a distribution over x ∈ R d . Parameterizing the subspace through a matrix U ∈ R d×k with columns spanning it, we consider the following specification of PCA: maximize</p><formula xml:id="formula_0">U :E x tr(U T xx T U )<label>(1)</label></formula><p>subject to :</p><formula xml:id="formula_1">U T U I,</formula><p>where the expectation is taken with respect to the distribution of interest. Note that at the optimum, all eigenvalues of U would be equal to one, and the columns of U would be orthonormal, but in order to obtain a convex constraint without changing the optimum, we consider all U with eigenvalues at most one to be feasible. The situation we consider here, which we argue is the typical situation in practice, is where we do not have direct knowledge of the distribution over x ∈ R d and so cannot exactly calculate the (population) objective specified in Problem 1, let alone optimize it. Instead, we only have access to i.i.d. samples from this distribution-these can be thought of as "training samples". The regime we consider in this paper is where we have an essentially unlimited supply of training examples, and would like to obtain an -suboptimal solution in the least possible runtime.</p><p>One possible approach to optimizing Problem 1 is through Sample Average Approximation (SAA): we collect T i.i.d. samples x 1 , . . . , x T and solve the empirical version of Problem 1, where the expectation is replaced with its empirical (sample average) approximation 1 T i tr(U T x i x T i U ). This can be done by calculating the sample second-moment matrix Σ = 1 T T t=1 x t x T t , and taking U to have columns equal to the top k eigenvectors of Σ.</p><p>Let us consider the computational cost of the SAA approach: The eigendecomposition of Σ can be computed in time O(d 3 ) using the algebraic QR algorithm, or via iterative methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. But the more significant cost is calculating Σ itself, which requires O(T d 2 ) time and O(d 2 ) memory. Now, even if the empirical problem is solved exactly, recall that we are interested in the population objective of Problem 1, and so using a finite sample T we obtain only an approximate solution. The runtime of the SAA approach is then O(T d 2 ) where T is the number of samples required to ensure the empirical minimizer is -suboptimal.</p><p>Recently, Tropp has developed a number of generalizations of familiar probabilistic inequalities to the matrix setting. His matrix Hoeffding bound <ref type="bibr" target="#b10">[11,</ref><ref type="bibr">Theorem 1.3</ref>] can be used to show that with probability 1 -δ:</p><formula xml:id="formula_2">T = O M 2 k 2 2 log d δ ,<label>(2)</label></formula><p>where xx T -Σ 2 ≤ M (this is the spectral norm) with probability 1. Although we believe that this bound could be improved (particularly its k-dependence), it provides a natural baseline for evaluating the rate of convergence of other approaches for solving Problem 1.</p><p>An alternative is a Stochastic Approximation (SA) approach, where samples x i are considered sequentially, and only a simple computation, perhaps linear in the size of U (i.e. in dk), is performed at each iteration in order to update U . Even if such an approach might require more samples to obtain an -suboptimal solution, the hope is that the shorter runtime-per-sample will result in lower total runtime being required to obtain a solution of the same quality.</p><p>In the next section, we consider three stochastic approximation approaches to PCA. In Section VII, we will empirically compare both the number of samples and the overall runtime required to obtain a good solution to Problem 1, both with the SA approaches and with the SAA approach discussed above. As we will see, although the number of samples required by the SA approaches is higher, the computational cost is substantially lower.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PCA ALGORITHMS</head><p>In this Section we present three stochastic approximation approaches to Problem 1. In Section III-A we present the stochastic power method as a stochastic gradient descent approach, and discuss how it could be implemented more efficiently while still maintaining the same sequence of updates. In Section III-B we derive a novel truncated incremental approach, which relies on recent work on incremental SVD.</p><p>Finally, in Section III-C we consider an efficient implementation of Warmuth and Kuzmin's online PCA algorithm <ref type="bibr" target="#b7">[8]</ref> as another alternative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Stochastic Power Method and Variants</head><p>For convex optimization problems, stochastic gradient descent is a simple and often highly efficient optimization technique. The PCA objective function is convex, as is the constraint (as in Equation <ref type="formula" target="#formula_0">1</ref>), but as the goal is maximization of this objective, the formulation of Equation 1 is not convex as an optimization problem. However, gradient descent is still a viable algorithm. If Σ were known exactly, then the gradient of the PCA objective function tr(U T ΣU ) with respect to U would be 2ΣU , leading one to consider updates of the form U (t+1) = P orth U (t) + η t ΣU (t) , where P orth (U ) performs a projection with respect to the spectral norm of U U T onto the set of d×d matrices with k eigenvalues equal to 1 and the rest 0 (calling this a "projection" is a slight abuse of terminology, since it is U U T which is projected, not U itself).</p><p>If one analytically performs an exact line search in order to determine the best positive η, then one finds that the optimal step size is essentially infinite, yielding the update U (t+1) = P orth ΣU (t) -this is the power method. As an alternative to performing an exact line search along the direction of the overall gradient, one could instead notice that E xx T = Σ, and take a step in the stochastic gradient direction:</p><formula xml:id="formula_3">U (t+1) = P orth U (t) + η t x t x T t U (t) .<label>(3)</label></formula><p>Notice that, whereas calculating ΣU would require O(kd 2 ) operations, finding xx T U requires only O(kd). The renormalization step represented by P orth (which can be performed in O(k 2 d) operations using, e.g., the Gram-Schmidt procedure) does not affect the correctness of the solution-even if we do not perform it at all, each iterate will span the same subspace as it would have otherwise. To see this, suppose that we do renormalize U (t) after each iteration. We may then write</p><formula xml:id="formula_4">U (t) = Q (t) R (t) with Q (t)</formula><p>having orthonormal columns and R (t) being a nonsingular k × k matrix (this is not necessarily a QR factorization, although it may be, if one renormalizes using Gram-Schmidt). The matrix Q (t) is then the renormalized version of U (t) . With this representation of renormalization, the 1-step SGD update of Equation 3 is:</p><formula xml:id="formula_5">U (t+1) =Q (t) + η t x t x T t Q (t) , U (t+1) R (t) =U (t) + η t x t x T t U (t) .</formula><p>From this equation, it is easy to prove by induction on t that if V (t) is the sequence of iterates which would result if renormalization was not performed, then</p><formula xml:id="formula_6">V (t) = Q (t) R (t) R (t-1) • • • R (1) . Because R (t) R (t-1) • • • R (1)</formula><p>is a product of nonsingular matrices, it is nonsingular, showing that V (t) and Q (t) span the same subspace.</p><p>As a result of this observation, renormalization may be performed for purely numerical reasons, and only very infrequently. Hence, the computational cost of renormalization may be ignored, showing that performing T iterations of SGD costs only O(T kd) operations and O (kd) memory, both of which are better by a factor of d/k than merely calculating the empirical second-moment matrix over T samples (costing O(T d 2 ) operations and O d 2 memory). For small k and large d, this represents an enormous potential performance difference over non-stochastic linear algebra-based methods.</p><p>Although not presented as instances of SGD, there are a number of algorithms in the literature that perform precisely the above SGD update, differing only in how they renormalize. For example, Oja and Karhunen <ref type="bibr" target="#b11">[12]</ref> perform Gram-Schmidt orthonormalization after every iteration, while the popular generalized Hebbian algorithm <ref type="bibr" target="#b6">[7]</ref>, which was later generalized to the kernel PCA setting by Kim et al. <ref type="bibr" target="#b12">[13]</ref>, performs a partial renormalization. Both of these algorithms converge with probability 1 (under certain conditions on the distribution of x and step sizes η t ). However, the rate of convergence is not known.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Incremental PCA</head><p>Another approach to PCA in the stochastic setting is inspired by an incremental algorithm for finding the singular value decomposition (SVD) <ref type="bibr" target="#b13">[14]</ref>, although the linear algebra used by our approach is more similar to the technique of Bunch et al. <ref type="bibr" target="#b14">[15]</ref>. The problem of incremental SVD has been studied recently in many areas, with application to face recognition <ref type="bibr" target="#b15">[16]</ref>, scalable recommender systems <ref type="bibr" target="#b16">[17]</ref>, timeseries segmentation <ref type="bibr" target="#b17">[18]</ref>, and data imputation <ref type="bibr" target="#b13">[14]</ref>.</p><p>Whereas Brand <ref type="bibr" target="#b13">[14]</ref> is interested in the SVD of a data matrix X = [x 1 , x 2 , . . . , x T ], we are interested in the eigendecomposition of the matrix of second moments E[xx T ]. Like Brand, we consider the setting where the examples are processed one at a time, resulting in a rank-one update to the unnormalized empirical second-moment matrix at each iteration. The update we propose can be expressed as:</p><formula xml:id="formula_7">C (t) = P rank-k C (t-1) + x t x T t .<label>(4)</label></formula><p>The projection P rank-k projects its argument onto the set of rank-k matrices with respect to the spectral norm. This can be accomplished by setting all but the k largest eigenvalues to 0.</p><p>The update of Equation 4 can be performed efficiently. Suppose that C (t-1) is a rank-approximation to the matrix t-1 s=1 x s x T s with its eigendecomposition being C (t-1) = U SU T , where U ∈ R d× and U T U = I. Given a new observation, x t , define x = U T x t as the coefficients of the projection of x t onto the columns of U , and x ⊥ = x t -U U T x t as its orthogonal component. Then the updated matrix C(t) = C (t-1) + x t x T t of Equation 4 can be written as:</p><formula xml:id="formula_8">U x ⊥ x ⊥ 2   S + x xT x ⊥ 2 x x ⊥ 2 xT x ⊥ 2 2   Q∈R ( +1)×( +1) U T x T ⊥ / x ⊥ 2 .</formula><p>Notice that we have named the middle matrix in the above expression Q. The eigendecomposition of Q = U S U T may be found in O k 3 time, and the eigendecomposition of C(t) is Ũ S Ũ T , where:</p><formula xml:id="formula_9">Ũ = U x ⊥ x ⊥ 2 U , S = S .</formula><p>If the rank of C(t) grows beyond k, then we truncate S and Ũ to retain the top k eigenvalues and eigenvectors, resulting in the iterate C (t) . One advantage of the incremental approach is its low space complexity of O(kd), compared to O(d 2 ) for classical approaches to PCA. The dominant computation in our update is the matrix multiplication defining Ũ , which has a cost of O(k 2 d) operations, leading to an overall runtime of O(T k 2 d), which is worse by a factor of k than the SGD approach of Section III-A, but is better by a factor of d/k 2 than the cost of calculating the empirical second-moment matrix (under the assumption that k d). The incremental approach has another advantage over SGD: it is parameterfree, whereas the use of SGD may require tuning of the stepsize parameter η t .</p><p>There do exist situations in which this algorithm fails to converge. For example, if the data are drawn from the distribution which samples (3, 0) with probability 1/3 and (0, 2) with probability 2/3, and we use the incremental algorithm to search for a 1-dimensional maximal subspace, then it will converge to (1, 0) with probability 5/9, despite the fact that the maximal eigenvector is (0, 1). This example relies on the data being orthogonal (a situation which is unlikely to arise in practice), but does illustrate that the convergence properties of the incremental approach are not well-understood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Online PCA</head><p>Warmuth and Kuzmin <ref type="bibr" target="#b7">[8]</ref> introduced an online algorithm for solving the PCA problem. A full derivation of their algorithm is beyond the scope of this paper, but we will give a high-level overview of their algorithm, and describe a novel technique for improving its computational efficiency dramatically.</p><p>As we have seen, one may formulate PCA as the optimization problem of finding a U ∈ R d×k with orthonormal columns maximizing E x tr(U T xx T U ) . Equivalently, one could seek not a matrix U of k column vectors spanning the maximal subspace, but instead a matrix U of d -k columns spanning the minimal subspace. From this matrix, the orthogonal complement (U ) could easily be derived. We could go further, and seek instead a projection matrix M onto the d -k dimensional minimal subspace (we may think of M as satisfying M = U U T = I -U U T ). Because M is a rank d -k projection matrix, it must have have exactly d -k eigenvalues equal to 1, and k equal to 0-this will be a constraint which is imposed during optimization. Unfortunately, this is not a convex constraint, but if we relax it by taking the convex hull, then the result is a convex optimization problem: minimize</p><formula xml:id="formula_10">M :E x tr(M xx T ) (5) subject to :M 0, M 2 ≤ 1 d -k , tr(M ) = 1.</formula><p>Here, • 2 is the spectral norm, and we have scaled M by 1/(d -k). This is precisely the PCA formulation proposed by Warmuth and Kuzmin <ref type="bibr" target="#b7">[8]</ref>. Their update rule (which is targeted towards the online setting, rather than the easier stochastic setting which we consider) is an instance of the Mirror Descent algorithm <ref type="bibr" target="#b18">[19]</ref>, with distance generating function Ψ(M ) = tr ln M (the von Neumann entropy) and the Frobenius inner product and norm:</p><formula xml:id="formula_11">M (t+1) = P RE exp ln M (t) -η t x t x T t .<label>(6)</label></formula><p>These are matrix logarithms and exponentials. The projection P RE onto the constraints is performed with respect to the quantum relative entropy, which turns out to be a straightforward operation: let k be the largest number such that setting the largest d -k eigenvalues of M to 1/(d -k), and scaling the remaining k eigenvalues so as to satisfy the normalization constraint tr(M ) = 1, results in all eigenvalues of M being bounded above by 1/(d -k). Then perform this capping-and-scaling. Please see Warmuth and Kuzmin <ref type="bibr" target="#b7">[8]</ref> for details.</p><p>Of the stochastic algorithms that we consider, only Warmuth and Kuzmin's enjoys a satisfactory convergence guarantee. Using a certain constant step size η t = η, assuming that x t 2 ≤ 1 uniformly, and for any M * satisfying the constraints of Problem 5, Warmuth and Kuzmin [8, Equation 5.1] gives that after performing T iterations, where T satisfies:</p><formula xml:id="formula_12">T ≥ O (d -k) tr (M * Σ) + k log d k ,</formula><p>the iterates M (t) will satisfy:</p><formula xml:id="formula_13">E 1 T T t=1 tr (d -k) M (t) Σ -tr ((d -k) M * Σ) ≤ ,<label>(7)</label></formula><p>where M * is the optimum of Problem 5, and both M * and M (t) are scaled by d -k to compensate for the fact that the objective of Problem 5 was scaled by 1/(d -k) relative to the original PCA objective. Equation 7 is not directly comparable to the SAA bound of Equation 2, due to its dependence on M * . In the "optimistic" setting in which the d -k dimensional minimal subspace contains total variance on the order of , the first term of Equation III-C is of order 1, and this bound is superior to Equation 2 by a factor of k/ . The bounds are comparable when this d -k dimensional subspace contains total variance of order k, and in more "pessimistic" settings the bound on the SAA algorithm is superior.</p><p>The biggest drawback of Warmuth and Kuzmin's algorithm is computational cost. As written, performing a single iteration (Equation <ref type="formula" target="#formula_11">6</ref>) requires two full-rank eigendecompositions: one for the matrix logarithm, and another for the exponential and projection. As was pointed out by Tsuda et al. <ref type="bibr" target="#b19">[20]</ref>, one may reduce this cost by maintaining an up-to-date eigendecomposition of M throughout a run of the algorithm. Each update to this eigendecomposition will take the form of either a rank-one update (when we add η t x t x T t ) or a simple operation on the eigenvalues (the matrix logarithm and exponential, as well as the projection).</p><p>This optimization only partially addresses the algorithm's performance shortcomings, since M is still a full-rank d × d matrix. There is one more significant property of M which remains to be exploited: the projection step will set many of the eigenvalues of M to be exactly 1/(d -k). Let k be the number of eigenvalues which are less than 1/(d -k), so that M has d -k repeated eigenvalues. Using the same technique as the incremental PCA algorithm of Section III-B, one may find the eigendecomposition of M + ηxx T given an eigendecomposition of M in O k 2 d time. Furthermore, the eigenvectors corresponding to these repeated eigenvalues need not be stored, reducing the memory cost to O (k d).</p><p>Of course, these results depend crucially on the value of k , which varies from iteration to iteration, and could potentially be as small as k +1 or as large as d-1. In practice, however, this change leads to significant savings. One final issue with Warmuth and Kuzmin's algorithm is that it solves not the true PCA objective, but instead a relaxation of it. The eigenvalues of the state matrices M (t) are nonnegative and sum to 1, which suggests finding a minimal subspace of rank d -k via sampling, and taking its orthogonal component to be our rank-k maximal subspace. Indeed, this is precisely the solution suggested by Warmuth and Kuzmin. In our experiments (Section VII), we use the less-"correct" but simpler (and empirically superior) approach of taking the eigenvectors corresponding to the minimal k eigenvalues of M (T ) . We use only the last iterate M (T ) , not the average over all iterates, as would be suggested by Equation <ref type="formula" target="#formula_13">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. STOCHASTIC OPTIMIZATION FOR PLS</head><p>Many machine learning problems benefit from multiple "views" of the data, possibly from different measurement modalities. In such multi-view learning problems, a common representation of the two views is provided by the shared semantic space. A common approach to extracting this space is through canonical correlation analysis (CCA), which finds pairs of maximally correlated projections of the data in the two views. CCA has been successfully applied to various tasks in speech <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref>, natural language processing <ref type="bibr" target="#b26">[27]</ref>, and computer vision <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>. A closely related technique is Partial Least Squares (PLS), which finds pairs of maximally covarying projections of the data in the two views. We begin by considering PLS, and return to CCA in Section VI.</p><p>In order to formulate PLS as a stochastic optimization problem, consider a joint distribution over pairs of vectors x ∈ R dx and y ∈ R dy . A k-dimensional PLS solution can be parameterized by a pair of matrices U ∈ R dx×k and V ∈ R dy×k , where the corresponding columns of U and V represent corresponding covarying directions. The PLS problem can now be expressed as: maximize</p><formula xml:id="formula_14">U,V :E x,y tr U T xy T V (8) subject to :U T U = I, V T V = I.</formula><p>The columns of U and V are singular vectors of Σ XY . Like the PCA objective and most other learning problems, PLS is an optimization of an expectation subject to fixed constraints, and is therefore amenable to a stochastic approximation approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. PLS ALGORITHMS</head><p>We now show how the SA methods presented in Section III can be modified to solve the (uncentered) PLS Problem 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. SGD for PLS</head><p>It is fairly straightforward to extend the SGD algorithm of Section III-A to PLS. The difference is that we now observe a pair of examples x t , y t at each iteration, with E[xy T ] = Σ XY , and seek to maximize tr U T Σ XY V , which has gradients Σ XY V with respect to U and Σ T XY U with respect to V . This suggests the following stochastic gradient update:</p><formula xml:id="formula_15">U (t+1) =P orth U (t) + η t x t y T t V (t) , V (t+1) =P orth V (t) + η t y t x T t U (t) ,</formula><p>where, as in Section III-A, the projection P orth orthonormalizes the columns of its argument, and needs to be performed only infrequently, for purely numerical reasons. The space complexity of the resulting algorithm is the sum of the sizes of U and V : O (k (d x + d y )). Neglecting the cost of the projection, the computational cost is dominated by the matrix-vector multiplications of the update equation, costing</p><formula xml:id="formula_16">O (k (d x + d y )) per iteration, for a total of O (T k (d x + d y )).</formula><p>As before, these are superior to the O (d x d y ) space complexity and O (T d x d y ) computational cost of calculating ĈXY .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Incremental PLS</head><p>As in Section III-B, one may perform an incremental PLS update by maintaining a rank-k estimate C (t-1) XY of the SVD of the empirical cross-second-moment matrix t-1 s=1 x s y T s , and performing a rank-one update and projection after observing each sample pair x t , y t , according to C (t)</p><formula xml:id="formula_17">XY = P rank-k C (t-1) XY + x t y T</formula><p>t , where P rank-k projects onto the set of rank-k matrices with respect to the spectral norm.</p><p>The efficient implementation of this update follows broadly the same lines as that for PCA. Supposing that C (t-1) XY has the rank-SVD U SV T , we define:</p><formula xml:id="formula_18">x = U T x t , x ⊥ = x t -U U T x t , ŷ = V T y t , y ⊥ = y t -V V T y t ,</formula><p>The matrix C(t) XY = C</p><p>(t-1) XY + x t y T t can then be written as:</p><formula xml:id="formula_19">U x ⊥ x ⊥   S + x ŷT y ⊥ x x ⊥ ŷT x ⊥ y ⊥   Q∈R ( +1)×( +1) V T y T ⊥ / y ⊥ .</formula><p>Finding the SVD of C(t) XY requires an "inner" SVD on the smaller matrix Q, with a computational cost of O( 3 ). Given the SVD Q = U S V T , the SVD of C(t) XY is Ũ S Ṽ T , where:</p><formula xml:id="formula_20">Ũ = U x ⊥ x ⊥ U , S = S , Ṽ = V y ⊥ y ⊥ V .</formula><p>Once more, we ensure that the rank of</p><formula xml:id="formula_21">C (t)</formula><p>XY does not exceed k by taking only the top k singular values and vectors of C(t) XY . This algorithm has the same space complexity as SGD: O (k (d x + d y )). The computational cost is dominated by the matrix multiplications defining Ũ and Ṽ , costing O k 2 (d x + d y ) operations, which is a factor of k worse than SGD, but still better, for sufficiently small k, than that of calculating the empirical cross-second-moment matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Online PLS</head><p>Adapting the online algorithm of Warmuth and Kuzmin <ref type="bibr" target="#b7">[8]</ref> to work on the PLS objective is less straightforward than it is for either SGD or the incremental algorithm, since it works in the matrix log domain, and therefore depends on symmetry. We may, however, symmetrize the PLS objective by making use of a self-adjoint dilation <ref type="bibr" target="#b10">[11]</ref> of the matrix Σ XY :</p><formula xml:id="formula_22">Γ = 0 Σ XY Σ Y X 0 = E x,y 0 xy T yx T 0 .</formula><p>Provided that Σ XY has no repeated nonzero singular values, the nonzero eigenvalues of this matrix will be the singular values of Σ XY and their negations, with the corresponding matrix of eigenvectors being (up to sign differences):</p><formula xml:id="formula_23">W = 1 √ 2 U U V -V ,</formula><p>where U and V are the left and right singular vectors of Σ XY , respectively. Hence, if we let W k ∈ R (dx+dy)×k be a matrix with the top k ≤ d x , d y eigenvectors of Γ in its columns, then √ 2 times the first d x rows of W k will be the top k left singular vectors of Σ XY , and likewise √ 2 times the last d y rows of W k will be the top k right singular vectors of Σ XY . This suggests that we modify Equation 5 to be: minimize</p><formula xml:id="formula_24">M :E x,y tr M 0 xy T yx T 0 subject to :M 0, M 2 ≤ 1 d -k , tr (M ) = 1,</formula><p>which leads us to change the update of Equation 6 to:</p><formula xml:id="formula_25">M (t+1) = P RE exp ln M (t) -η t Z t ,</formula><p>where:</p><formula xml:id="formula_26">Z t = 0 x t y T t y t x T t 0 = 1 2 x t y t x t y t T - 1 2 x t -y t x t -y t T .</formula><p>Notice that Z t is a rank-2 matrix. The analysis of Warmuth and Kuzmin no longer applies to this modification of their algorithm, since Γ and Z t have negative eigenvalues. However, the interpretation of the algorithm as exponentiated stochastic gradient descent is unchanged. The implementation of the algorithm is almost identical: the only difference is that a rank-2 update is performed at every iteration, instead of rank-1.</p><p>As we did in Section III-C, we find a rank-k maximal subspace by taking the eigenvectors corresponding to the k minimal eigenvalues of M (T ) . There is one additional wrinkle, however: although the top d x and bottom d y rows of the matrix containing the optimal k eigenvectors of Γ immediately give a SVD of Σ XY , for suboptimal solutions it may not be the case that the resulting U and V will have orthogonal columns. In our experiments, we resolve this by the simple expedient of taking the orthonormalized U U T U -1/2 and V V T V -1/2 as our approximate singular vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. STOCHASTIC OPTIMIZATION FOR CCA</head><p>We now return to the question of formulating CCA as a stochastic optimization problem. We again consider a joint distribution over pairs of vectors x ∈ R dx and y ∈ R dy . As in PLS, a k-dimensional CCA solution is parameterized by a pair of matrices U ∈ R dx×k and V ∈ R dy×k , where the corresponding columns of U and V now represent corresponding correlated directions. The CCA problem can be expressed as: maximize</p><formula xml:id="formula_27">U,V :E x,y tr U T xy T V (9) subject to :E x U T xx T U = I, E y V T yy T V = I.</formula><p>It is straightforward to show <ref type="bibr" target="#b27">[28]</ref> that the CCA optimum can be obtained from a generalized eigenvalue problem, where the u k are eigenvectors of</p><formula xml:id="formula_28">Σ -1 XX Σ XY Σ -1 Y Y Σ Y X with corresponding v k = Σ -1 Y Y Σ Y X u k</formula><p>, where Σ XY is the crosssecond-moment matrix between X and Y and Σ XX , Σ Y Y are the matrices of second moments of X and Y .</p><p>This suggests the immediate SAA approach where the matrices Σ XX , Σ XY and Σ Y Y are replaced with their empirical (sample based) approximations, and the generalized eigenvalue problem is solved. This approach is applicable to both CCA and PLS, and is frequently applied to both.</p><p>A more careful look at the CCA problem 9 reveals that this is a difficult stochastic optimization problem, and that many stochastic approximation approaches might not be valid here. The difficulty stems from the fact that unlike the PCA and PLS problems, and many other stochastic optimization problems encountered in learning, the constraints also involve the unknown distribution. That is, not only can we not evaluate the objective value precisely, but we also cannot know which matrices are feasible. In order to appreciate this difficulty, consider the simple k = 1 case, in which we seek the two most correlated directions u and v. The normalization constraints can be removed and instead we can normalize u and v in the objective by dividing by the square roots of the second moments of the directions u and v, obtaining the following population objective:</p><formula xml:id="formula_29">ρ(u T x, v T y) = E x,y u T xy T v E x [u T xx T u] E y [v T yy T v] .<label>(10)</label></formula><p>This is now an unconstrained optimization problem, but the objective is no longer an expectation, but rather a ratio of expectations. This creates a difficult situation and departs significantly from the typical stochastic approximation scenario. For example, it is not at all clear how to obtain unbiased estimates of the gradient of Equation <ref type="formula" target="#formula_29">10</ref>.</p><p>In this regard the PLS problem seems much more amenable to stochastic approximation approaches-it is, like the PCA objective and most other learning problems, an optimization of an expectation subject to fixed constraints. We thus focus on PLS, rather than CCA, in this initial study.</p><p>We note that CCA is equivalent to PLS after a normalization by the matrices Σ XX and Σ Y Y , i.e. to PLS on the transformed x = Σ -1/2 XX x and ỹ = Σ -1/2 Y Y y. Thus, in applications where it is feasible to normalize the data in this way (i.e., Σ XX and Σ Y Y are identity matrices, are known, or have a dominant diagonal that can be relatively easily estimated), CCA can be reduced to PLS by normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. EXPERIMENTAL RESULTS</head><p>In this section we compare the performance of the algorithms of Sections III and V in terms of progress made on the objective as a function of iteration number and CPU runtime.</p><p>For PCA experiments we use the MNIST dataset, consisting of 70, 000 binary images of handwritten digits. For PLS experiments, we use the Wisconsin X-Ray Micro-Beam (XRMB) data, consisting of acoustic and articulatory measurements of English speech <ref type="bibr" target="#b29">[30]</ref>. We use roughly 225, 000 examples from four speakers (JW11, JW13, JW24, JW30).</p><p>All experiments include pre-normalization, consisting of mean-centering the feature vectors and then dividing each coordinate by its standard deviation times the square root of the length of the feature vector.</p><p>Our implementations are written in Matlab. In order to ensure a fair comparison with the parameter-free incremental algorithm, we deliberately made little effort to find optimal step sizes for SGD and Warmuth and Kuzmin's algorithms, choosing η t = 1/ √ t uniformly for all experiments. All algorithms were run for only one "pass" over the training data, resulting in some algorithms being far from convergence at termination, but ensuring that all training samples were drawn independently from the population.</p><p>Our experiments compare performance in terms of the objective function value. Because we cannot evaluate the true population objective for Problems 1 and 8, we instead approximate them by evaluating on a held-out testing sample (half of the dataset, with the other half being used for training). All results are averaged over 50 random train/test splits.</p><p>Figures <ref type="figure">1</ref> and<ref type="figure">2</ref> show the PCA and PLS objectives, respectively, as a function of the number of samples processed (iterations) as well as CPU runtime, for ranks k = 1, 4 and 8. As expected, SGD is the fastest, but also makes the least progress, per iteration. The online algorithm makes better progress per iteration on PLS but performs poorly in terms of runtime. Amongst the stochastic algorithms, the incremental algorithm is consistently the best in terms of both runtime and progress-per-iteration, and generally attains an objective close to the optimum faster than the batch algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSIONS AND DISCUSSION</head><p>We believe that in data-driven applications, the stochastic optimization view is often the correct view of PCA, PLS, and CCA, rather than a more conventional empirical optimization or linear-algebra view. In this paper we have taken our first steps at formalizing these problems as problems of optimizing a population objective and studying it as such, and we hope this will be the seed of future work with this view in mind. We have not been able to provide any quantitative theoretical guarantee on the performance of the stochastic power method or the truncated incremental method, and thus cannot analytically compare them with the SAA approach. The difficulty of providing such guarantees is highlighted by the lack of guarantees for the variants of the stochastic power method mentioned in Section III-A. Nevertheless, we hope to progress toward such a theoretical understanding. Beyond PCA and PLS, another outstanding challenge is obtaining a good stochastic optimization method for CCA-as discussed in Section VI, the stochastic constraints make this problem much more challenging, and we do not have a satisfying solution to the problem at this stage.</p><p>With that said, the stochastic optimization view allows us to see the advantages of a SA approach over the standard SAA (empirical optimization) approach, and we have demonstrated this advantage empirically for both PCA and PLS. In particular, for PCA:</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>(a) k = 1 (Fig. 1 .Fig. 2 .</head><label>112</label><figDesc>Fig. 1. Comparison of the incremental, SGD and online algorithms for stochastic PCA optimization on the MNIST dataset, in terms of the objective value as a function of iteration (top row) and as a function of CPU runtime (bottom row). The "Batch" curve is for the Sample Average Approximation (SAA) approach. (a) k = 1 (b) k = 4 (c) k = 8</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>• We have presented a novel truncated incremental approach (Section III-B) • We have presented a novel method for obtaining the iterates of Warmuth and Kuzmin <ref type="bibr" target="#b7">[8]</ref>, which is orders of magnitude faster and more memory efficient, and is thus practical in large-scale applications (Section III-C). • We have pointed out that a renormalization at every iteration of the stochastic power method is redundant and yields the same iterates, in terms of the subspace spanned (Section III-A), thus allowing for a faster implementation. We have also extended these methods to PLS, describing, we believe for the first time, SA approaches for this problem. We also report on an empirical comparison of the three SA approaches, as well as SAA, for PCA and for PLS. For PCA, both the stochastic power method and the truncated incremental approach outperform the SAA approach, with each method preferable in a different regime.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The tradeoffs of large scale learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;07</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="161" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SVM optimization: Inverse dependence on training set size</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;08</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="928" to="935" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robust stochastic approximation approach to stochastic programming</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nemirovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Juditsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1574" to="1609" />
			<date type="published" when="2009-01">January 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pegasos: Primal Estimated sub-GrAdient SOlver for SVM</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;07</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Exponentiated gradient algorithms for conditional random fields and max-margin markov networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Globerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1775" to="1822" />
			<date type="published" when="2008-06">Jun. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Stochastic methods for l1 regularized loss minimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning, ser. ICML&apos;09</title>
		<meeting>the 26th Annual International Conference on Machine Learning, ser. ICML&apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="929" to="936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optimal unsupervised learning in a single-layer linear feedforward neural network</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Sanger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="459" to="473" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Randomized PCA algorithms with regret bounds that are logarithmic in the dimension</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Warmuth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kuzmin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;06</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">in Templates for the solution of algebraic eigenvalue problems: a practical guide</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gu ; Bai</surname></persName>
		</author>
		<author>
			<persName><surname>Zhaojun</surname></persName>
		</author>
		<author>
			<persName><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName><surname>James</surname></persName>
		</author>
		<author>
			<persName><surname>Dongarra</surname></persName>
		</author>
		<author>
			<persName><surname>Jack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Axel</forename><surname>Ruhe</surname></persName>
		</author>
		<author>
			<persName><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName><surname>Vorst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Society for Industrial and Applied Mathematics</publisher>
			<pubPlace>Philadelphia, PA</pubPlace>
		</imprint>
	</monogr>
	<note>Single-and multiple-vector iterations. ch. 4.3.</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Templates for the solution of algebraic eigenvalue problems: a practical guide</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ruhe</surname></persName>
		</author>
		<author>
			<persName><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><surname>Zhaojun</surname></persName>
		</author>
		<author>
			<persName><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName><surname>James</surname></persName>
		</author>
		<author>
			<persName><surname>Dongarra</surname></persName>
		</author>
		<author>
			<persName><surname>Jack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Axel</forename><surname>Ruhe</surname></persName>
		</author>
		<author>
			<persName><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName><surname>Vorst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Society for Industrial and Applied Mathematics</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<pubPlace>Philadelphia, PA</pubPlace>
		</imprint>
	</monogr>
	<note>Lanczos method. ch. 4.4.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">User-friendly tail bounds for sums of random matrices</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Tropp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations of Computational Math</title>
		<imprint>
			<date type="published" when="2011-08">Aug 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On stochastic approximation of the eigenvectors and eigenvalues of the expectation of a random matrix</title>
		<author>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Karhunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="69" to="84" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Iterative kernel principal component analysis for image modeling</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1351" to="1366" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Incremental singular value decomposition of uncertain data with missing values</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rankone modification of the symmetric eigenproblem</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Bunch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Sorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numerische Mathematik</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="48" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Incremental kernel SVD for face recognition with image sets</title>
		<author>
			<persName><forename type="first">T.-J</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th Intl. Conf. Automatic Face and Gesture Recog</title>
		<meeting>7th Intl. Conf. Automatic Face and Gesture Recog</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Incremental singular value decomposition algorithms for highly scalable recommender systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth International Conference on Computer and Information Science</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A fast on-line generalized eigendecomposition algorithm for time series segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Principe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mirror descent and nonlinear projected subgradient methods for convex optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research Letters</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="167" to="175" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Matrix exponentiated gradient updates for on-line learning and bregman projection</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tsuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rätsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Warmuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="page" from="995" to="1018" />
			<date type="published" when="2005-12">Dec. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Spectral transformations through canonical correlation analysis for speaker adptation in ASR</title>
		<author>
			<persName><forename type="first">K</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Grenier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multi-view clustering via canonical correlation analysis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Livescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sridharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;09</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Multi-view learning of acoustic features for speaker recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Livescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stoehr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>ASRU</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adaptive kernel canonical correlation analysis for estimation of task dynamics from acoustics</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rudzicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multiview acoustic feature learning using articulatory measurements</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bharadwaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Livescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hasegawa-Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Workshop on Stat. Machine Learning for Speech Recognition (IWSML)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Kernel CCA for multi-view learning of acoustic features using articulatory measurements</title>
		<author>
			<persName><forename type="first">R</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symp. on Machine Learning in Speech and Language Processing</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning bilingual lexicons from monolingual corpora</title>
		<author>
			<persName><forename type="first">A</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Canonical correlation analysis: An overview with application to learning methods</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Hardoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Szedmak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2639" to="2664" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Correlational spectral clustering</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">X-ray microbeam speech production database user&apos;s handbook</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Westbury</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994-06">June 1994</date>
			<pubPlace>Madison, WI, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Waisman Center on Mental Retardation &amp; Human Development, University of Wisconsin</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
