<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Convolutional Neural Networks for So -Matching N-Grams in Ad-hoc Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
							<email>zhuyund@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
							<email>callan@cs.cmu.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Technology Tsinghua University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Convolutional Neural Networks for So -Matching N-Grams in Ad-hoc Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3159652.3159659</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>is paper presents Conv-KNRM, a Convolutional Kernel-based Neural Ranking Model that models n-gram so matches for ad-hoc search. Instead of exact matching query and document n-grams, Conv-KNRM uses Convolutional Neural Networks to represent ngrams of various lengths and so matches them in a uni ed embedding space. e n-gram so matches are then utilized by the kernel pooling and learning-to-rank layers to generate the nal ranking score. Conv-KNRM can be learned end-to-end and fully optimized from user feedback. e learned model's generalizability is investigated by testing how well it performs in a related domain with small amounts of training data. Experiments on English search logs, Chinese search logs, and TREC Web track tasks demonstrated consistent advantages of Conv-KNRM over prior neural IR methods and feature-based methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A recent success of neural methods in information retrieval (neural IR) is the development of interaction based models <ref type="bibr" target="#b22">[13,</ref><ref type="bibr" target="#b31">21,</ref><ref type="bibr" target="#b39">29]</ref>. Interaction based models thrive with encoding word-word translations using word embeddings, and utilizing new pooling methods to be er summarize the word translations into ranking signals <ref type="bibr" target="#b20">[11,</ref><ref type="bibr" target="#b22">13,</ref><ref type="bibr" target="#b39">29]</ref>. Learned end-to-end from user feedbacks <ref type="bibr" target="#b33">[23,</ref><ref type="bibr" target="#b39">29]</ref>, the word embeddings can encode so matches tailored for relevance ranking, which has signi cant advantages over traditional feature-based methods <ref type="bibr" target="#b39">[29,</ref><ref type="bibr" target="#b40">30]</ref>. ese initial successes of neural IR were mainly from so matching individual words. On the other hand, the query and document o en match at n-grams, such as phrases <ref type="bibr" target="#b28">[18]</ref>, concepts <ref type="bibr" target="#b11">[2]</ref>, and entities <ref type="bibr" target="#b38">[28]</ref>; how to e ectively model n-gram so -matches remains an open question in neural IR.</p><p>is paper presents a new Convolutional Kernel-based Neural Ranking Model(Conv-KNRM). We rst embed words in continuous vectors (embeddings), and then employ Convolutional Neural Networks (CNN) to compose adjacent words' embeddings to n-gram embeddings. In the n-gram embedding space, so -matching ngrams is as simple as calculating the similarity of two n-grams' embeddings. e current state-of-the-art kernel pooling and learningto-rank techniques are then used to combine the n-gram somatches to the nal ranking score <ref type="bibr" target="#b39">[29]</ref>.</p><p>e CNN is the key to modeling n-grams. Typical IR approaches treat n-grams as discrete terms and use them the same as unigrams. For example, a document bigram 'white house' is one term, has its own term frequency, and can only be matched to 'white house' in queries. However, treating n-grams atomically in neural IR will explode the parameter space, and su er from data sparsity. is work avoids the problem by learning a convolutional layer that forms n-grams from individual words' embeddings. e convolutional layer projects all n-grams into a uni ed embedding space, allowing matching n-grams of di erent lengths. For instance, 'white house' in the document can provide partial evidence for the query 'George Walker Bush'.</p><p>e whole Conv-KNRM model can be trained end-to-end with relevance signals such as clicks, so that the n-gram so matches are fully optimized towards search accuracy. We also present a simple yet e ective domain adaptation method for applying Conv-KNRM to search domains where large scale training data is not available. We rst train the word embedding and convolutional layers in the source domain that has su cient training labels. e trained Conv-KNRM is then adapted to a target domain with limited annotations by only re-training the learning-to-rank layer. e assumption is that the so matching pa erns learned on one domain are likely to generalize to similar domains, while the importance of each type of so match can vary across domains.</p><p>Our experiments on an English search log from Bing and a Chinese search log from Sogou show the advantages of so -matching ngrams. As a precision oriented method, Conv-KNRM almost doubled the NDCG@1 of standard feature-based learning-to-rank methods. On the English log, Conv-KNRM outperformed state-of-the-art neural methods by over 30%; in the Chinese log where many unigrams Technical Presentation WSDM'18, February 5-9, 2018, Marina Del Rey, CA, USA are already compound word, so -matching n-grams still provided signi cant improvements. Our further study reveals that the key to Conv-KNRM's advantages is its ability to cross-match n-grams with di erent lengths in a uni ed space. Our domain adaptation experiment shows that the n-gram so matches are generalizable. When adapted to the TREC Web Track task, the pre-trained Conv-KNRM from Bing's log outperformed two strong learning-to-rank baselines. A case study found that some connections between queries and their relevant documents can only be made by so -matching n-grams, for example, 'atypical squamous cells' and 'cervical cancer'. To the best of our knowledge, this is the rst time such cross-domain generalization ability has been achieved by neural methods in ad hoc search 1 .</p><p>In the rest of this paper, Section 2 discusses related work; Section 3 describes our model architecture; Section 4 describes the domain adaptation method; Experimental setups and evaluation results are presented in Section 5 and Section 6. We conclude in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>e current neural IR methods can be categorized into two classes: representation based and interaction based <ref type="bibr" target="#b22">[13]</ref>. e earlier a empts of neural IR research were mainly about how to learn good representation of the query and document, and the ranking was simply done by their representations' similarities, for example, DSSM <ref type="bibr" target="#b24">[15]</ref> and its convolution version CDSSM <ref type="bibr" target="#b36">[26]</ref>. A more recent example is the weakly supervised ranking model in which all word embeddings of a query or document are combined into one vector, and the match of two vectors is done by deep neural networks <ref type="bibr" target="#b18">[9]</ref>.</p><p>e interaction based methods, on the other hand, directly model query-document matches at the word level.</p><p>ey are rooted in statistical translation models, which construct a translation matrix of word pairs between query and document, and summarize it to a ranking score <ref type="bibr" target="#b13">[4]</ref>. e main challenge of translation models is that the word-pair translations are too sparse to learn. To overcome this problem, word embeddings <ref type="bibr" target="#b30">[20]</ref> are introduced to calculate the translation scores <ref type="bibr" target="#b21">[12]</ref>. How to combine the word-level translation scores to generate query-document ranking scores has also been improved by neural methods such as Convolutional Neural Networks <ref type="bibr" target="#b23">[14,</ref><ref type="bibr" target="#b33">23]</ref>.</p><p>A later study found that the CNN lters tend to mix the match signals in the translation matrix at various levels and are suboptimal for ad hoc search <ref type="bibr" target="#b32">[22]</ref>.</p><p>e DRMM model introduces the histogram pooling (pyramid pooling <ref type="bibr" target="#b20">[11]</ref>) technique to summarize the translation matrix; it demonstrated that it is more e ective to 'count' the word-level translation scores at di erent so match levels, instead of to weight-sum them <ref type="bibr" target="#b22">[13]</ref>. e interaction based model and the representation based model can also be combined in a duet architecture <ref type="bibr" target="#b31">[21]</ref>.</p><p>Another trend of neural IR research is to learn customized word embeddings by and for ad-hoc ranking. e surrounding text based word embeddings, e.g. word2vec <ref type="bibr" target="#b30">[20]</ref> and GloVe <ref type="bibr" target="#b34">[24]</ref>, have been questioned about their suitability for ad hoc search <ref type="bibr">[1,</ref><ref type="bibr" target="#b35">25]</ref>. Diaz et al. train word embeddings using pseudo relevance feedback (PRF) documents, which are more e ective than globally trained 1 Trained models available at: h p://boston.lti.cs.cmu.edu/appendices/WSDM2018-ConvKNRM/ word2vec in query expansion <ref type="bibr" target="#b19">[10]</ref>. e relevance feedback based word embeddings are then also found to be more e ective in ad hoc ranking <ref type="bibr" target="#b40">[30]</ref>.</p><p>K-NRM uni ed the progress of IR customized embeddings and interaction based model <ref type="bibr" target="#b39">[29]</ref>. It rst embeds words and builds the translation matrix using the similarities between query and document words' embeddings. en it uses kernel-pooling to summarize the word embeddings and provide so match signals for learning to rank. e kernel-pooling shares the advantage of pyramid pooling <ref type="bibr" target="#b22">[13]</ref> that it 'counts' the so matches at multiple levels, while also being di erentiable so that word embeddings and ranking parameters can be learned together. When trained with user feedback in a search log, K-NRM outperforms both neural IR methods and feature-based learning-to-rank by a large margin <ref type="bibr" target="#b39">[29]</ref>.</p><p>ough the so matching of n-grams in information retrieval remains an open topic, there has been a large amount of research that utilizes n-gram exact matches. e sequential dependency model (SDM) that includes n-gram phrase matches has been a standard in many IR systems <ref type="bibr" target="#b28">[18]</ref>. ere is also much work about how to be er weight n-grams in SDM, for example, by emphasizing frequent and meaningful concepts <ref type="bibr" target="#b12">[3,</ref><ref type="bibr" target="#b42">32]</ref>. A more recent trend is to use entities to introduce explicit semantics from knowledge graphs to search systems <ref type="bibr" target="#b38">[28]</ref>. e majority of these work focuses on exact matching n-grams, because learning a good statistical translation model score for every possible n-gram pair inevitably faces data sparsity and parameter explosion.</p><p>Modeling n-grams is much easier in the embedding space. Neural methods have shown the bene ts of modeling n-grams in some related text processing tasks, especially with Convolutional Neural Networks. For example, in sentence classi cation, CNN has been used to compose word embeddings into n-gram representations, which are then max-pooled and combined by a feed-forward neural network to classify the sentence <ref type="bibr" target="#b27">[17]</ref>. at research demonstrated CNN's ability of composing n-gram embeddings, while its ability in relevance ranking is still being explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">CONVOLUTIONAL N-GRAM RANKING</head><p>is section presents our convolutional kernel-based neural ranking Model (Conv-KNRM), shown in Figure <ref type="figure">1</ref>. It rst composes ngram embeddings using CNN, and constructs translation matrices between n-grams of di erent lengths in the n-gram embedding space (Section 3.1).</p><p>en it ranks with the n-gram so matches using kernel-pooling and learning to rank (Section 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">N-gram Composing and Cross-matching</head><p>Given a query q and document d, Conv-KNRM embeds their words by a word embedding layer, composes n-grams with a CNN layer, and cross-matches query n-grams and document n-grams of variant lengths to the translation matrices.</p><p>e word embedding layer maps each word t of a text to an L-dimensional continuous vector (embedding): t → ì t. A query q or document d is treated as a text sequence of m words {t 1 , ..., t m }, and is modeled as an m × L matrix:</p><formula xml:id="formula_0">T =       ì t 1 ... ì t m      </formula><p>.</p><p>(1)  </p><formula xml:id="formula_1">&lt; ⃗ 3 3 … &lt; ⃗ = 3 &lt; ⃗ 3 &gt; ... &lt; ⃗ = &gt; &lt; ⃗ 3 3 … … &lt; ⃗ ? 3 &lt; ⃗ 3 &gt; … … &lt; ⃗ ? &gt; @ 4 A B3,C A B3 … … … … Final</formula><formula xml:id="formula_2">I 8 H (bigrams) @ 4 A B3,C A B&gt; @ 4 A B&gt;,C A B3 @ 4 A B&gt;,C A B&gt; &lt;PAD&gt; Kernel Pooling Kernel Pooling Kernel Pooling Kernel Pooling</formula><p>Figure <ref type="figure">1</ref>: e Conv-KNRM Architecture. Given input query and document, the embedding layer maps their words into distributed representations, the convolutional layer generates n-gram embeddings ; the cross-match layer matches the query n-grams and document n-grams of di erent lengths, and forms the translation matrices; the kernel pooling layer generates so -TF features and the learning-to-rank (LeToR) layer combines them to the ranking score. e case with Unigrams and Bigrams (h max = 2) is shown.</p><p>We denote the embedding matrix of the query and the document by T q and T d respectively.</p><p>e convolutional layer applies convolution lters to compose n-grams from the text (T q or T d ). A convolution lter slide over the text like a sliding window. For each window of h words, the lter sums up all elements in the h words' embeddings T i:i+h , weighted by the lter weights w ∈ R hL ,and produces a continuous score:</p><formula xml:id="formula_3">= w • T i:i+h , ∈ R.<label>(2)</label></formula><p>Using F di erent lters w 1 , ..., w F gives F scores, each describing T i:i+h in a di erent perspective. en we add a bias and apply a nonlinear activation function, and obtain an F -dimensional embedding for the h-gram:</p><formula xml:id="formula_4">ì h i = relu W h • T i:i+h + ì b h , i = 1...m.<label>(3)</label></formula><formula xml:id="formula_5">ì h i ∈ R F is the embedding of the i-th h-gram. e f -th element in ì h i is the score of the f -th lter. W h and ì b h are the weights of the F convolution lters. |W h | = (hL) × F and | ì b h | = F .</formula><p>When a convolution lter slides across the boundary of the text, we append up to h − 1 '&lt;PAD&gt;' symbols for padding.</p><p>us, for each n-gram length h ∈ {1, .., h max }, the CNN layer converts the text embedding T into h-gram embedding G h .</p><formula xml:id="formula_6">G h = CNN h (T ) =       ì h 1 ... ì h m       (4) |G h | = m × F .</formula><p>Each of its rows correspond to a h-gram vector of length F . h-gram embeddings for the query and the document are denoted as G h q and G h d respectively. e 'convolution' assumption is applied in the n-gram compositions: the same set of convolution lters is used to compose all n-grams. us, instead of learning an individual embedding for each n-gram in the corpus, the model only needs to learn the CNN weights for combining word-level embeddings, which have much fewer parameters.</p><p>e cross-match layer matches query n-grams and document n-grams of di erent lengths. For query n-grams of length h q and document n-grams of length h d , a translation matrix M h q ,h d is constructed. Its elements are the similarity scores between the corresponding query-document n-gram pairs.</p><formula xml:id="formula_7">M h q ,h d i, j = cos ì h q i , ì h d j (5)</formula><p>e uni ed embedding representations allow cross-matching n-grams of di erent lengths, e.g., the query trigram"convolutional neural networks" and the document bigram "deep learning". It generates h 2 max translation matrices.</p><formula xml:id="formula_8">M = M h q ,h d |1 ≤ h q ≤ h max , 1 ≤ h d ≤ h max (6)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Ranking with N-gram Translations</head><p>Conv-KNRM uses the kernel-pooling technique and a learning-torank layer to calculate the ranking score using the n-gram translations M. is part extends K-NRM <ref type="bibr" target="#b39">[29]</ref> to n-grams. Kernel-pooling is a pooling technique that uses K Gaussian kernels to count the so matches of word or n-gram pairs at K di erent strength levels. Each kernel K k summarizes the translation scores as so -TF counts in the region de ned by its mean µ k and width δ k . As a result, a translation matrix M is pooled to a K-dimensional so -TF feature vector ϕ (M) = {K 1 (M), ..., K K (M)}. Such counting-based pooling methods have shown be er performance than score-based ones like mean-pooling or max-pooling <ref type="bibr" target="#b22">[13,</ref><ref type="bibr" target="#b39">29]</ref>.</p><p>Kernel-pooling is applied to each M h q ,h d matrix in M to generate the so -TF feature vector ϕ M h q ,h d , which describes the distribution of match scores between query h q -grams and document h d -grams. is leads to the ranking features as follows.</p><formula xml:id="formula_9">Φ (M) = ϕ M 1,1 ⊕ ... ⊕ ϕ M h q ,h d ⊕ ... ⊕ ϕ M h max ,h max Φ(M) has K × h 2 max dimensions, K so -TF features for each of the h 2 max translation matrices in M.</formula><p>e learning-to-rank (LeToR) layer combines the so -TF ranking features Φ(M) into a ranking score: Standard pairwise learning-to-rank is used to train the model.</p><formula xml:id="formula_10">f (q, d) = tanh w T r Φ(M) + b r<label>(7)</label></formula><formula xml:id="formula_11">l = q d + ,d − ∈D +, − q max(0, 1 − f (q, d + ) + f (q, d − ))<label>(8)</label></formula><p>D +,− q are q's pairwise preferences: d + ranks higher than d − . All of Conv-KNRM layers are di erentiable; the whole model, including word embeddings (V), CNN lters (W h , b h ), and learningto-rank layers (w r , b r ) can be learned end-to-end from training data. For a model with vocabulary size |V |, L-dimensional word embeddings, F lters, h max maximum n-gram length and K kernels, the embedding layer has |V | × L parameters, the CNN layer has O(|h max |LF ) parameters, and the learning-to-rank layer has K × h max + 1 parameters.</p><p>e main capacity of the model is in the word embedding and CNN lters. ey are expected to learn the word embeddings and n-gram compositions from training data and provide desired multilevel n-gram so matches. e learning-to-rank layer serves as a linear feature combiner as in standard feature-based ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Summary</head><p>Conv-KNRM adds the ability of so matching n-grams to the recent state-of-the-art K-NRM model <ref type="bibr" target="#b39">[29]</ref> with convolutional neural networks (CNNs). Without CNNs, Conv-KNRM withdraws to K-NRM.</p><p>Matching n-grams is a well-established idea in information retrieval. However, n-grams are usually treated identically to words: they are atomic index terms, have distinct term frequencies, use the same weighting function as unigrams, and must match exactly in query and document <ref type="bibr" target="#b16">[7]</ref>. If that approach is used by a neural ranker, the number of parameters to be learned can grow very large.</p><p>e neural model has to deal with data sparsity and low e ciency problems, which are even harder for longer n-grams. Conv-KNRM avoids these problems by using CNNs to compose n-grams without dramatically enlarging the parameter space. It makes so -matching n-grams convenient and e cient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DOMAIN ADAPTATION</head><p>End-to-end training Conv-KNRM requires large-scale training data, for example, user clicks in a commercial search log <ref type="bibr" target="#b39">[29]</ref> or industryscale annotations <ref type="bibr" target="#b31">[21]</ref>. However, for many search domains such as TREC benchmarks, such data are not available. We propose a domain adaption strategy that learns Conv-KNRM from a source domain that has su cient training data, and then re-trains its learning-torank layer in the target domain with limited labels.</p><p>e parameters of the embedding and convolution layers are learned in the source domain to absorb the rich relevance signals in the training data. ey are then used in the target domain to generate so -TF features Φ(M). Xiong, et al. <ref type="bibr" target="#b39">[29]</ref> showed that kernel-pooled so -TF features reveal di erent types of so match. For example, one kernel may count synonyms (e.g., 'oppor9' and 'OPPOR'); another kernel may count word pairs from the same concept class (e.g., 'son' and 'daughter', 'Java' and 'C++'). ese so match pa erns are likely to be stable across related domains.</p><p>e learning-to-rank parameters indicate the importance of each kernel.</p><p>ey are re-trained on the target domain, because the importances of each type of so matches can change over domains. For instance, the synonym kernel is of low importance in search logs as all candidate documents already contain the query words <ref type="bibr" target="#b39">[29]</ref>; however, synonyms can be a strong signal in a recall-oriented domain.</p><p>Re-training the ranking layer in the target domain is a standard feature based learning-to-rank tasks. is allows one to add domainspeci c features from the target domain. ere is also no limitation on which learning to rank model to use in the target domain. One can leverage the power of any learning-to-rank model such as RankSVM <ref type="bibr" target="#b25">[16]</ref> or LambdaMART <ref type="bibr" target="#b37">[27]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL METHODOLOGY</head><p>is section describes our datasets, how training and testing were performed, our baseline algorithms, and implementation details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>Conv-KNRM was evaluated using two search logs in di erent languages (Sogou, Bing), and a TREC dataset (ClueWeb09-B).</p><p>Sogou-Log: Sogou.com is a major Chinese commercial search engine.</p><p>e same se ings as K-NRM were used <ref type="bibr" target="#b39">[29]</ref>. e same sample of Sogou log and training-testing splits are used (Table <ref type="table" target="#tab_2">1</ref>).</p><p>e testing queries were sampled from queries with more than 1000 sessions (the head); none of them were in the training set.</p><p>Documents were represented by titles. e search log did not contain document body text. Testing document's body texts were crawled, and were used by the traditional IR baselines for stronger baseline performance. Body texts of training documents were not available <ref type="bibr" target="#b39">[29]</ref>. e Chinese text was segmented by ICTCLASS <ref type="bibr" target="#b41">[31]</ref>; then Chinese words were treated like English words.</p><p>Bing-Log: We used a one-month sample of a 2006 Bing log from the WSDM 2009 Web Search Click Data Workshop. It contained the top 50 URLs for each query, and clicked URLs in each session. Following Sogou-Log, we split the Bing sessions into training and testing sets with no overlapping queries (Table <ref type="table" target="#tab_2">1</ref>). Test queries were sampled uniformly because the log contained few head queries.</p><p>Bing-Log includes documents' titles and snippets. Most snippets had 30-50 words. We can not crawl enough body texts because URLs were from 2006. All texts were tokenized and lower-cased.</p><p>ClueWeb09-B is used for domain adaptation experiments. e ClueWeb09-B corpus contains about 50 million English web documents from 2009. e TREC 2009-2012 Web Tracks created 200 queries and corresponding relevance judgments. We followed a standard re-ranking methodology in prior research <ref type="bibr" target="#b17">[8,</ref><ref type="bibr" target="#b38">28]</ref>: re-rank the top 100 candidate documents retrieved by Galago using sequential dependency model queries; the INQUERY stopword list augmented with web-speci c stop words; KStemming; and spam ltering using Waterloo spam score with threshold 60. Documents were parsed by Boilerpipe using the 'KeepEverytingExtractor'. e title and the rst 50 words in the body eld were used to be more consistent with the source domain (Bing-Log)'s title and snippet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">In-Domain Training and Testing</head><p>Training and testing labels on Sogou-Log and Bing-Log were generated following prior research <ref type="bibr" target="#b39">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Technical Presentation</head><p>WSDM'18, February 5-9, 2018, Marina Del Rey, CA, USA  <ref type="bibr" target="#b14">[5]</ref>, and training preference pairs were constructed accordingly. DCTR uses the click through rate for each query-document pair as the relevance score. DCTR is a strong baseline in click model competitions <ref type="bibr" target="#b14">[5]</ref>.</p><p>Testing-SAME: is set of testing labels was generated by DCTR, as described for training data. is se ing evaluates the model's ability to t explicit user preferences.</p><p>Testing-RAW: is set of testing labels was motivated by the cascade assumption <ref type="bibr" target="#b14">[5]</ref>. Only the clicked document in a single-click session was considered relevant. 57% of Sogou testing sessions had only one click. 92% of Bing testing sessions had only one click. e Testing-DIFF condition was omi ed due to space limits; it produced results similar to Testing-RAW.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Domain Adaptation Training and Testing</head><p>NIST provides 200 queries and corresponding relevance judgments for ClueWeb09-B. e domain adaptation experiment tests how well the n-gram so matches trained from one domain (Bing) generalize to a similar domain (ClueWeb09-B). Both datasets contain English web documents, the timespans are somewhat similar (2006 vs. 2009), and TREC queries are similar to Bing queries<ref type="foot" target="#foot_0">2</ref> . However, the two datasets have di erent documents, di erent indexing methods, and di erent the initial rankers (Bing vs. Galago); the relevance labels are also rather di erent (clicks vs. manual assessments).</p><p>On ClueWeb09-B, Conv-KNRM was rst trained with the Bing log (as described above). en the embeddings and convolution lters were 'frozen' and so TF-features Φ (M) were extracted using the same kernels for ClueWeb09-B. We also included the initial retrieval score from Galago with sequential dependency model (Galago-SDM) to provide whole-document information as Conv-KNRM only uses the title and the rst 50 words of the body.</p><p>e learning-to-rank parameters were retrained and tested using TREC relevance judgments (Table <ref type="table" target="#tab_3">2</ref>), 10-fold cross-validation, and RankSVM to add regularization (as discussed in Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Baselines</head><p>Traditional IR baselines included standard unsupervised retrieval models and feature-based learning-to-rank models. Unsupervised methods included BM25 and language model with Dirichlet smoothing (Lm), applied on the full text of Sogou documents, or the title plus snippet of Bing documents. Learning-to-rank baselines were RankSVM <ref type="bibr" target="#b25">[16]</ref> and coordinate ascent ( Coor-Ascent) <ref type="bibr" target="#b29">[19]</ref> ey used 20 features: Boolean AND; Boolean OR; Coordinate match; Cosine similarity of bag-of-words vectors; TF-IDF; BM25; language models with no smoothing, Dirichlet smoothing, JM smoothing, and two-way smoothing; all applied on the title and body (or snippet). Default parameters were used in feature extraction.</p><p>For ClueWeb09-B, we used state-of-the-art baselines from prior research <ref type="bibr" target="#b38">[28]</ref> 3 .</p><p>e baselines include Indri's language model (Indri), Galago with sequential dependency model queries (Galago-SDM), and learning-to-rank models: RankSVM and Coor-Ascent. Neural IR baselines included CDSSM <ref type="bibr" target="#b36">[26]</ref>, MatchPyramid (MP) <ref type="bibr" target="#b33">[23]</ref>, DRMM <ref type="bibr" target="#b22">[13]</ref>, and K-NRM <ref type="bibr" target="#b39">[29]</ref>.</p><p>CDSSM <ref type="bibr" target="#b36">[26]</ref> is uses CNNs to build query and document representations on their words' le er-tri-grams (or Chinese characters in Sogou-Log <ref type="bibr" target="#b39">[29]</ref>). e ranking scores are calculated by the similarity between the representations.</p><p>MP <ref type="bibr" target="#b33">[23]</ref> and DRMM <ref type="bibr" target="#b22">[13]</ref> are both interaction based models built upon the embedding translation matrix. MP uses CNNs to directly combine the translation scores to the ranking score, while DRMM uses histogram pooling to count multiple levels of so -TF, and use learning-to-rank a erwards.</p><p>K-NRM is a state-of-the-art neural model previously tested on the Sogou-Log dataset <ref type="bibr" target="#b39">[29]</ref>. It uses kernel-pooling instead of DRMM's histogram pooling, and learns the word embeddings and the ranking layers end-to-end. It is the main baseline in our experiments.</p><p>Among these neural IR baselines, DRMM and K-NRM were compared on the ClueWeb09-B dataset. DRMM uses xed embeddings and only learns the learning-to-rank layers, and can be trained with limited training data. K-NRM was tested the same as Conv-KNRM in the domain adaption fashion. MP and CDSSM performed worse than DRMM on TREC data in previous studies <ref type="bibr" target="#b22">[13,</ref><ref type="bibr" target="#b32">22]</ref>.</p><p>It is unfair for unsupervised <ref type="bibr" target="#b40">[30]</ref> or pseudo-supervised <ref type="bibr" target="#b18">[9]</ref> neural IR methods to compete with Conv-KNRM, which is trained end-toend with large amount of supervisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Implementation Details</head><p>Model Training: All supervised traditional IR models were trained and tested using cross-validation on the testing data. On search logs, 5-fold cross validation were used to be consistent with the previous study on Sogou-Log <ref type="bibr" target="#b39">[29]</ref>. On ClueWeb09-B, the 10-fold cross validation splits from the provided baselines were used. All RankSVM's used the linear kernel with the hyper-parameter C selected from the range [0.0001, 10] on the development set. Recommended se ings of Coor-Ascent were kept. All neural IR methods are trained on the training splits. On ClueWeb09-B, DRMM was cross-validated; K-NRM and Conv-KNRM was pretrained on Bing-Log, then used RankSVM with cross-validation to retrain the learning-to-rank layer. Document Fields: On Sogou-Log, traditional IR methods used both title and body, and neural IR methods only used title <ref type="bibr" target="#b39">[29]</ref>, as discussed in section 5.1. On Bing-Log, all methods used the title and snippets. On ClueWeb09-B, all methods used title and body, except K-NRM and Conv-KNRM which used title and rst 50 words 3 h ps://boston.lti.cs.cmu.edu/appendices/SIGIR2017 word entity duet/ Technical Presentation WSDM'18, February 5-9, 2018, Marina Del Rey, CA, USA in the body as snippets, to be consistent with the source domain.</p><p>When multiple elds were used, a separate set of features from each eld was generated; the combination weights were learned as well.</p><p>Word Embeddings: DRMM used pre-trained word2vec embeddings from the candidate documents in the search log, or the ClueWeb corpus. MP, K-NRM, and Conv-KNRM embeddings were all learned end-to-end using the query logs. For Sogou-log, we set embedding dimension L = 300 <ref type="bibr" target="#b39">[29]</ref> . For Bing-Log, we set L = 100 because our pilot study showed that L = 100 has similar performance with L = 300 but the training is 3 times faster.</p><p>Hyper Parameters: n-gram lengths were h = 1, 2, 3. Longer ngrams with h &gt; 3 usually exceed the length of web search queries. e number of CNN lters F was 128; we found that F in the range of (50, 300) give similar results. e kernel pooling layers in K-NRM and Conv-KNRM and the histogram pooling layer in DRMM all used 11 kernels/bins. e rst one is the exact match kernel µ = 1, σ = 10 −3 , or bin [1, 1]. e other 10 kernels/bins equally split the cosine range [−1, 1]: the µ or bin centers were: µ 1 = 0.9, µ 2 = 0.7, ..., µ 10 = −0.9.</p><p>e σ of the so match bins were set to be 0.1 <ref type="bibr" target="#b39">[29]</ref>. Model Implementation and E ciency: e model was implemented with Tensor ow.</p><p>e optimization used the Adam optimizer, with batch size 16, learning rate 0.001, and early stopping with the patience of 5 epochs.</p><p>e training of Conv-KNRM took about 12 hours on an AWS GPU machine. e training time is similar with prior work using only unigrams <ref type="bibr" target="#b39">[29]</ref>. Most computation time was spent on the embedding layer; the convolutional layer was very e cient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION RESULTS</head><p>ree experiments were conducted to analyze Conv-KNRM's performance: its ranking accuracy when trained end-to-end, contributions of n-gram so match, and the e ectiveness when adapted to new domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">End-to-End Accuracy</head><p>e ranking accuracies of each ranking method on the Sogou-Log and Bing-Log datasets are shown in Table <ref type="table">3</ref>.</p><p>On Testing-SAME, Conv-KNRM outperformed all feature-based and neural IR baselines by large margin with statistical signi cance. e closest baseline is K-NRM, the non-convolutional version of Conv-KNRM, but the di erences were still large. Conv-KNRM performed be er in higher ranking positions: its NDCG@1 almost doubled Coor-Ascent . ese results show Conv-KNRM's e ectiveness when trained and tested on the same labeling scenario.</p><p>Testing-Raw evaluates the model's performance by raw user clicks. e same stable improvements of Conv-KNRM over all baselines were observed. Since this evaluation uses sessions with only one click, the MRR scores directly re ect the reciprocal rank of userclicked documents. On Sogou-Log, the average rank of clicked documents of all methods except K-NRM and Conv-KNRM was below rank 5. K-NRM pulled the clicked document to rank 3, and Conv-KNRM further promoted it to rank 2.7. On Bing-Log, Conv-KNRM pulled the clicked document of all methods more than 1 position higher.</p><p>e only neural IR baselines that outperformed feature-based learning-to-rank are the two interaction based and end-to-end trained ones: MP and K-NRM. Although other neural IR methods can improve over unsupervised baselines, feature-based learning-to-rank methods are harder to beat; end-to-end learned embeddings and matchbased techniques are necessary for current neural IR methods to provide additional improvements <ref type="bibr" target="#b32">[22,</ref><ref type="bibr" target="#b39">29,</ref><ref type="bibr" target="#b40">30]</ref> Comparing the two strong neural IR baselines, K-NRM outperforms MP by a large margin. Both methods use end-to-end learned word embeddings to build the translation matrix. e di erence is that K-NRM uses kernel-pooling to summarize 'so -TF' counts from the translation matrix, while MP directly applies the CNN to combine the translation scores. CNN in MP only has access to the translation scores in the translation matrix, for example, a 2×2 CNN lter sees the similarity scores between two adjacent query words and two adjacent document words, but not their embeddings. Our experiments and prior studies show that counting the frequencies of multi-level so matches are more e ective than weight-summing the similarities <ref type="bibr" target="#b22">[13,</ref><ref type="bibr" target="#b39">29]</ref>-"similarity does not necessarily mean relevance" <ref type="bibr" target="#b15">[6]</ref>.</p><p>Recall that Conv-KNRM is a richer model than K-NRM only because it leverages convolutional neural networks to learn the n-gram compositions and thus enable n-gram so matches. e improvements of Conv-KNRM over K-NRM reveal the advantage of n-gram so matches. e relative improvements on Sogou and Bing also correlate with our intuitions of n-gram's importance in Chinese and English. In Chinese, words are segmented by word segmentation tools. An important goal of Chinese word segmentation research is to cut meaningful phrases into one word. For example, 'information retrieval', 'deep learning', and ' e People's Republic of China' are all unigrams in Chinese. As a result, the gains are much larger on English than on Chinese.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Contribution of N-Gram So -match</head><p>is experiment studied the contribution of n-gram so matches by comparing several Conv-KNRM's variations. Conv-KNRM composes ngrams with lengths up to h max and cross-matches them in a uni ed embedding space. We started with K-NRM, which is Conv-KNRM without CNNs, and incrementally added bigram matches (+Bigram), trigram matches (+Trigram), cross unigram-bigram matches (+Unix-Bi), and cross all three n-grams' matches which is the Full Model. Results are shown in Table <ref type="table">4</ref>.</p><p>Longer n-gram were more e ective in English. On the Bing-Log, trigrams were be er than bigrams, and bigrams were be er than unigrams. e e ect was weaker in Chinese, with mixed performances on di erent se ings. Presumably it is because many Chinese phrases were glued to one word by word segmentation.</p><p>Cross matching n-grams of di erent lengths boosted accuracy in both languages. +Uni-x-Bi performed signi cantly be er than +Bigram on most metrics, and Full Model outperformed all other variants signi cantly. Cross matching is e ective because related concepts do not necessarily have the same length, e.g. 'FIFA' and 'world cup'. Composing n-grams using CNNs makes cross matching simple: all n-grams, despite with di erent lengths, are represented and matched in the same embedding space.  weights would share a reasonable chunk of learning to rank weights in the adapted model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Domain Adaption</head><p>We veri ed this by analyzing the weights RankSVM assigned to di erent groups of ranking features, as shown in Figure <ref type="figure" target="#fig_2">2</ref>. Each analysis divides features into two groups, e.g. exact-match features and so -match features. It then calculates the percentage of weight given to each type of features by summing up the absolute weight values of the feature set. In Figure <ref type="figure" target="#fig_2">2</ref>, most of the weight goes to so matches (Exact v.s. So ); N-gram matches have more weight than unigram matches (Unigram vs. N-gram); and matching n-grams of di erent lengths is important compared to matching n-grams with same length (Same-length v.s. Cross-length). e high feature weights on so n-gram match features reveals that these features do provide useful information to the learning-to-rank model-more useful than n-gram exact matches, despite that the n-gram so matches were trained and tested on two rather di erent domains: di erent labels, di erent documents, and non-overlapping queries.</p><p>Case Studies: We performed case studies to be er understand the so n-gram matching. Table <ref type="table" target="#tab_4">6</ref> shows examples of relevant documents that are correctly placed at rank 1 by Conv-KNRM, but not by RankSVM and KNRM. By sorting n-gram pairs according to each feature's individual performance, we can nd the most important so match that makes the document ranked highly, as highlighted in Table <ref type="table" target="#tab_4">6</ref>. ese cases demonstrated the e ectiveness in Conv-KNRM. First, Conv-KNRM overcomes the lexical mismatch, and nds query-document connections that are di cult for exactmatch-based approaches, e.g. 'sewing instructions' and 'quilting 101'. Second, Conv-KNRM captures n-gram matches that are di erent with word matches like K-NRM. For example, ('atypical squamous', 'cervical cancer') is a strong match, but the connection between their unigram pairs, e.g. ('atypical', 'cervical'), are much weaker.</p><p>ese examples also illustrates Conv-KNRM's generalizability: the matchings make sense in various contexts than just in one dataset.</p><p>In summary, the domain adaptation experiment provides a thorough view of the generalization ability of Conv-KNRM. e evaluations on ClueWeb09-B shows that the cross-domain so n-gram matching provides signi cant gains over in-domain feature-based learning-to-rank. Feature weight analysis demonstrates that the adapted model puts the majority of feature weights on n-gram so match signals. Case studies prove that the learned so -matches are intuitive and cover universally meaningful information needs. To the best of our knowledge, this is the rst time we have seen such generalization ability in neural IR models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>is paper presents Conv-KNRM, a convolutional kernel-based neural ranking model that models n-gram so matches for ad hoc search. Treating n-grams as discrete index terms faces the problem of dimension explosion and data sparsity. In contrast, Conv-KNRM uses Convolutional Neural Networks to compose n-gram embeddings from word embeddings, and cross-matches n-grams of various lengths in the uni ed embedding space. It then applies kernel pooling to extract ranking features, and uses learning-to-rank to obtain the nal ranking score.</p><p>Our experiments on Chinese and English search logs demonstrate the advantages of so -matching n-grams in relevance ranking. Gonv-GRAM almost doubled the NDCG@1 scores compared to feature-based ranking approaches, and outperformed the previous state-of-the-art model by over 30% at the top. Trained end-to-end with user feedback, Conv-KNRM learns n-gram so match pa erns tailored for matching queries and relevant documents, for example, the query 'farm' is matched to 'eat &amp; drink'. Such IR-customized n-gram so -match has not been seen much in previous work.</p><p>Based on our analysis, the key to Conv-KNRM's advantages is cross-matching n-grams of di erent lengths. Cross-matching consistently outperformed its non-cross-matching variants. On the Chinese search log, Conv-KNRM without cross-matching is about the same as its unigram competitor K-NRM, due to the phrase-like characteristics of Chinese unigrams. Cross-matching is important because related concepts do not necessarily have the same number of words, for instance, 'deep learning' and 'convolutional neural network'. But there has been li le study on it due to the limitation of discrete n-gram representation. e CNN approach of modeling n-grams makes cross-matching feasible, e cient, and e ective.</p><p>Beyond the good performance when trained end-to-end in domain, we show that the model trained on one domain is also generalizable to a related search domain.</p><p>e model learned from Bing-log signi cantly outperformed strong learning-to-rank baselines when adapted to TREC Web Track task, despite important domain di erences including corpus, queries and evaluation conditions. Experiments show that the embedding and CNN layers can be directly used in another related domain to generate n-gram so -matching features. Further analysis explains the generalizability: the learned n-gram so -matching pa erns encode universal properties of language usage in ad hoc search tasks, and provide important evidences for relevance ranking even when used across domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">ACKNOWLEDGMENTS</head><p>is research was supported by National Science Foundation (NSF) grant IIS-1422676. We thank Shane Culpepper and RMIT for providing the computational environment that enabled this work. Any opinions, ndings, and conclusions in this paper are the authors' and do not necessarily re ect those of the sponsors.</p><p>Technical Presentation WSDM'18, February 5-9, 2018, Marina Del Rey, CA, USA </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>w</head><label></label><figDesc>r and b r are the linear ranking parameters to learn. |w r | = |Φ(M)| and |b r | = 1. tanh() is the activation function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Our third experiment examined the e ectiveness of Conv-KNRM when adapted to a domain where large scale training data is not Technical Presentation WSDM'18, February 5-9, 2018, Marina Del Rey, CA, USA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Learned weights of di erent parts of ranking features on ClueWeb09-B. e percentage is the fraction of absolute weights on each side learned by linear RankSVM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>ery log datasets. Sogou-Log is a sample of Chinese query logs from Sogou.com in 2016. Bing-Log is a sample of English query logs from Bing.com in 2006</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Sogou-Log</cell><cell cols="2">Bing-Log</cell></row><row><cell></cell><cell></cell><cell cols="4">Training Testing Training Testing</cell></row><row><cell>Language</cell><cell></cell><cell>Chinese</cell><cell></cell><cell>English</cell><cell></cell></row><row><cell>Fields</cell><cell></cell><cell>Title</cell><cell></cell><cell cols="2">Title, Snippet</cell></row><row><cell>eries</cell><cell></cell><cell>95,229</cell><cell>1,000</cell><cell>99,043</cell><cell>1,000</cell></row><row><cell>Docs Per</cell><cell>ery</cell><cell>12.17</cell><cell>30.50</cell><cell>50</cell><cell>50</cell></row><row><cell cols="2">Search Sessions</cell><cell>31M</cell><cell>4.1M</cell><cell>2.10M</cell><cell>0.14M</cell></row><row><cell cols="2">Vocabulary Size</cell><cell>165,877</cell><cell>19,079</cell><cell>131,225</cell><cell>41,940</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Training and testing labels for each dataset. DCTR used the DCTR click model to infer scores that were mapped to 5 Likert scales<ref type="bibr" target="#b14">[5]</ref>. Clicks used the sole click in a session as the binary label. TREC labels were the 5 o cial grades.</figDesc><table><row><cell>Dataset</cell><cell>Train</cell><cell>Test</cell></row><row><cell>Sogou-Log</cell><cell>DCTR</cell><cell>Testing-SAME: DCTR Testing-RAW: Clicks</cell></row><row><cell>Bing-Log</cell><cell>DCTR</cell><cell>Testing-SAME: DCTR Testing-RAW: Clicks</cell></row><row><cell></cell><cell>Embedding &amp; CNN:</cell><cell></cell></row><row><cell>ClueWeb09-B</cell><cell>Bing-Log, DCTR</cell><cell>TREC labels</cell></row><row><cell></cell><cell>LeToR: TREC labels</cell><cell></cell></row><row><cell cols="3">Training Labels: e training labels for the Sogou and Bing</cell></row><row><cell cols="3">logs were generated by the DCTR click model from user clicks</cell></row><row><cell cols="2">in the training sessions</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 :</head><label>6</label><figDesc>Examples of matched n-grams between query and snippets. Black phrases contribute more to the relevance score than gray ones. ery Snippet sewing instructions …home free resources! newsle er sewing ideas…quilting 101 what is a quilt… atypical squamous cells …treatment decision tools cervical cancer : prevention and early detection… moths … grouping of moth families commonly known as the 'smaller moths ' ( micro , lepidoptera)… ckle creek farm .. bed &amp; breakfast inns extended stay lodging rv parks where to eat &amp; drink nightlife … university phoenix campus locations programs : bachelor degree masters degrees account degrees business degree… wedding budget calculator …planning tips photographs bridal board my perfect planner tools my check lists…</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">NIST sampled the TREC queries from a Bing search log. We removed TREC queries from our Bing training data. Our training and testing data have no queries in common.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Table 3: Ranking accuracy of Conv-KNRM and baseline methods. Relative performances compared with K-NRM are in percentages</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">†</forename></persName>
		</author>
		<author>
			<persName><forename type="first">‡</forename></persName>
		</author>
		<author>
			<persName><forename type="first">§</forename></persName>
		</author>
		<author>
			<persName><forename type="first">¶</forename><surname>Ast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">†</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Drmm</forename><forename type="middle">‡</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Cdssm</forename><forename type="middle">§</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename></persName>
		</author>
		<author>
			<persName><forename type="first">K-Nrm *</forename><surname>Respectively</surname></persName>
		</author>
		<title level="m">Method Sogou-Log Bing-Log Testing-SAME Testing-Raw Testing-SAME Testing-RAW NDCG@1 NDCG@10 MRR NDCG@1 NDCG@10 MRR BM25</title>
				<imprint/>
	</monogr>
	<note>* indicate statistically signi cant improvements over Coor-</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m">336 † ‡ § ¶ * +30% 0.481 † ‡ § ¶ * +11% 0.358 † ‡ § ¶ * +5% 0.300 † ‡ § ¶ * +44% 0.437 † ‡ § ¶ * +31% 0.354 † ‡ § ¶ * +34% Table 4: Ranking accuracy of Conv-KNRM variants. Relative performances compared with Unigram-only model (K-NRM) are in percentages. †, ‡, §, ¶ indicate statistically signi cant improvements over Unigram † , +Bigram ‡ , +Trigram § and +Uni-x-Bi ¶ , respectively. Sogou-Log Bing-Log Conv-KNRM Testing-SAME Testing-Raw Testing-SAME Testing-RAW Variant NDCG@1 NDCG@10 MRR NDCG@1 NDCG@10 MRR Unigram</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">† ‡ § ¶</forename></persName>
		</author>
		<idno>+30% 0.481 † ‡ § ¶ +11% 0.358 † ‡ § +5% 0.300</idno>
		<title level="m">† ‡ § ¶ +44% 0.437 † ‡ § ¶ +31% 0.354 † ‡ § ¶ +34% Table 5: Performance on ClueWeb09-B using domain adaptation. Relative performance in percentages are compared to Coor-Ascent. W(in)/T(ie)/L(oss) to Coor-Ascent are compared at NDCG@20. †, ‡, §, ¶ * indicate statistically signi cant improvements over Indri † , Galago SDM ‡ , RankSVM § , Coor-Ascent ¶ and DRMM+SDM *</title>
				<imprint/>
	</monogr>
	<note>Method ClueWeb09-B</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">-Sdm</forename><surname>Galago</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">† ‡ * −</forename></persName>
		</author>
		<idno>5% 0.270 † ‡ * +1% 0.155 † ‡ * −4% 78/42/80</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Conv-Knrm 0</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">† ‡ § ¶ *</forename></persName>
		</author>
		<idno>+12% 88/38/74</idno>
		<title level="m">† ‡ § ¶ * +31% 0.289 † ‡ § ¶ * +8% 0.172 † ‡ § ¶ * +12% 0.287 † ‡ § ¶ * +7% 0.181 † ‡ § ¶ *</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">We trained Conv-KNRM&apos;s word embeddings and convolution lters in Bing-Log with a large amount of user preference labels from clicks, and re-trained the learning-to-rank part on ClueWeb09-B&apos;s TREC ranking labels. Results are shown in Table 5. Indri and Galago-SDM are two unsupervised baselines. RankSVM, Coor-Ascent, and DRMM+SDM are supervised baselines. ey used in-domain training with cross-validation, because their parameters can be learned with TREC-scale training labels. DRMM+SDM is a variant of DRMM that uses Galago-SDM score as an additional feature; it showed higher performance than the standard DRMMM. Conv-KNRM and K-NRM were both trained using domain adaption. We also examined Conv-KNRM-exact which only uses exact-matches of n-grams, e.g. &apos;world cup&apos; can only be matched to &apos;world cup&apos;. As shown in Table 5, K-NRM was not able to beat DRMM+SDM, meaning that the e ectiveness of unigram level so matches was weakened by domain di erences. Conv-KNRM-exact performed about the same, and was weaker than learning-to-rank approaches</title>
		<imprint/>
	</monogr>
	<note>It does no more than exact phrase matching as in SDM. Conv-KNRM differs from K-NRM and Conv-KNRM-exact by so -matching n-grams</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">it outperformed the two strong traditional learning-to-rank models. e results demonstrate that the learned n-gram so matches of Conv-KNRM can generate to a di erent domain. Feature Weight Analysis: to further study the domain adaption</title>
		<imprint/>
	</monogr>
	<note>we investigated the importance of Conv-KNRM so -TF features</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Analysis of the paragraph vector model for information retrieval</title>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cro</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM on International Conference on the eory of Information Retrieval</title>
				<meeting>the 2016 ACM on International Conference on the eory of Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Parameterized concept weighting in verbose queries</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Cro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th annual international ACM SIGIR conference on Research and Development in Information Retrieval</title>
				<meeting>the 34th annual international ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">E ective query formulation with multiple information sources</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cro</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fi h ACM International Conference on Web Search and Data Mining</title>
				<meeting>the Fi h ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="443" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Information Retrieval as statistical translation</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>La Erty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</title>
				<meeting>the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="222" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Click Models for Web Search</title>
		<author>
			<persName><forename type="first">Aleksandr</forename><surname>Chuklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Information Concepts, Retrieval, and Services</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="115" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Cro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitra</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<title level="m">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</title>
				<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Report on the SIGIR 2016 Workshop on Neural Information Retrieval (Neu-IR</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Search Engines: Information Retrieval in Practice</title>
		<author>
			<persName><forename type="first">Donald</forename><surname>Bruce Cro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><surname>Strohman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Addison-Wesley Reading</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Entity ery Feature Expansion using Knowledge Base Links</title>
		<author>
			<persName><forename type="first">Laura</forename><surname>Je Rey Dalton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 37th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="365" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural Ranking Models with Weak Supervision</title>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Crof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</title>
				<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">ery Expansion with Locally-Trained Word Embeddings</title>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitra</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational (ACL)</title>
				<meeting>the 54th Annual Meeting of the Association for Computational (ACL)</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">e pyramid match kernel: Discriminative classi cation with sets of image features</title>
		<author>
			<persName><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tenth IEEE International Conference on Computer Vision (ICCV)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1458" to="1465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semantic Matching by Non-Linear Word Transportation for Information Retrieval</title>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cro</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management (CIKM)</title>
				<meeting>the 25th ACM International on Conference on Information and Knowledge Management (CIKM)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Deep Relevance Matching Model for Ad-hoc Retrieval</title>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ai</forename><surname>Qingyao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Cro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management (CIKM)</title>
				<meeting>the 25th ACM International on Conference on Information and Knowledge Management (CIKM)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Convolutional neural network architectures for matching natural language sentences</title>
		<author>
			<persName><forename type="first">Baotian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning deep structured semantic models for web search using click through data</title>
		<author>
			<persName><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management (CIKM)</title>
				<meeting>the 22nd ACM international conference on Conference on information &amp; knowledge management (CIKM)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2333" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Optimizing search engines using clickthrough Data</title>
		<author>
			<persName><forename type="first">Joachims</forename><surname>Orsten</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m">Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classi cation</title>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2014" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Markov random eld model for term dependencies</title>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cro</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Linear feature-based models for information retrieval</title>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cro</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Je</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2 h Advances in Neural Information Processing Systems 2013 (NIPS)</title>
				<meeting>the 2 h Advances in Neural Information Processing Systems 2013 (NIPS)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning to Match Using Local and Distributed Representations of Text for Web Search</title>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Bhaskar Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web (WWW)</title>
				<meeting>the 25th International Conference on World Wide Web (WWW)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Liang</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04648</idno>
		<title level="m">A study of matchpyramid models on ad-hoc retrieval</title>
				<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Text Matching As Image Recognition</title>
		<author>
			<persName><forename type="first">Liang</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengxian</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the irtieth AAAI Conference on Arti cial Intelligence (AAAI)</title>
				<meeting>the irtieth AAAI Conference on Arti cial Intelligence (AAAI)</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">GloVe: Global Vectors for Word Representation</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Je Rey Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Word Embedding Causes Topic Shi ing; Exploit Global Context!</title>
		<author>
			<persName><forename type="first">Navid</forename><surname>Rekabsaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</title>
				<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning semantic representations using convolutional neural networks for web search</title>
		<author>
			<persName><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grégoire</forename><surname>Mesnil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on World Wide Web (WWW)</title>
				<meeting>the 23rd International Conference on World Wide Web (WWW)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Adapting boosting for information retrieval measures</title>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krysta</forename><forename type="middle">M</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Svore</surname></persName>
		</author>
		<author>
			<persName><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Word-Entity Duet Representations for Document Ranking</title>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual international ACM SIGIR conference on Research and Development in Information Retrieval</title>
				<meeting>the 40th annual international ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">End-to-end neural ad-hoc ranking with kernel pooling</title>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual international ACM SIGIR conference on Research and Development in Information Retrieval</title>
				<meeting>the 40th annual international ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Relevance-based Word Embedding</title>
		<author>
			<persName><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</title>
				<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">HHMM-based Chinese lexical analyzer ICTCLAS</title>
		<author>
			<persName><forename type="first">Hua-Ping</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong-Kui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De-Yi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second SIGHAN workshop on Chinese language processing</title>
				<meeting>the second SIGHAN workshop on Chinese language processing</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning to Reweight Terms with Distributed Representations</title>
		<author>
			<persName><forename type="first">Guoqing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
