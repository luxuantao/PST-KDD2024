<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Constrained Joint Source/Channel Coder Design</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Khalid</forename><surname>Sayood</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Fuling</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Jerry</forename><forename type="middle">D</forename><surname>Gibson</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">University of Nebraska</orgName>
								<address>
									<postCode>68588</postCode>
									<settlement>Lincoln</settlement>
									<region>NE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Western Atlas Inc</orgName>
								<address>
									<postCode>77042</postCode>
									<settlement>Houston</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Electrical Engineering</orgName>
								<orgName type="department" key="dep2">Texas A&amp;M IEEE Log Number 9405941. University</orgName>
								<address>
									<postCode>77843</postCode>
									<settlement>College Station</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Constrained Joint Source/Channel Coder Design</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3E21715E06662A582F7EEE61FF4B6E4F</idno>
					<note type="submission">received September 14, 1993; revised July 7, 1994.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The design of joint source/channel coders in situations where there is residual redundancy at the output of the source coder is examined. It has previously been shown that this residual redundancy can be used to provide error protection without a channel coder. In this paper, this approach is extended to conventional source codedconvolutional coder combinations. A family of nonbinary encoders is developed which more efficiently use the residual redundancy in the source coder output. It is shown through simulation results that the proposed systems outperform conventional source-channel coder pairs with gains of greater than 9 dB in the reconstruction SNR at high probability of error.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>NE of Shannon's many fundamental contributions was 0 his result that source coding and channel coding can be treated separately without any loss of performance as compared to an optimum system <ref type="bibr">[l]</ref>. The basic design procedure implied by Shannon's theorems consists of designing a source encoder which changes the source sequence into a series of (approximately) independent equally likely binary digits followed by a channel encoder which accepts binary digits and puts them into a form suitable for reliable transmission over the channel <ref type="bibr">[I]</ref>. One aspect of the overall optimum system not addressed by Shannon is any increase in system complexity that results from this separation. <ref type="bibr">Massey [2]</ref> and Anchetta 131 showed that for distortionless transmission of the source under the constraint of linear source and channel coders, a significant reduction in complexity with equivalent performance can be achieved using a joint sourcelchannel coder. Their scheme also differs from most data compression schemes in that the bulk of the system complexity is transferred to the receiver.</p><p>The theorem that provides justification for the separate design of the source coder and the channel coder, often called the information transmission theorem [ 11, assumes that both the source encoder/decoder pair and the channel encoder/decoder pair are operating in an optimal fashion. Specifically, the source encoder is assumed to present the channel encoder an independent sequence for optimal channel coding, and the channel encoder/decoder pair is assumed to reproduce the source encoder output at the source decoder input with negligible distortion. Unfortunately, there are practical situations in which these assumptions are violated-namely, when the source encoder output contains redundancy, which occurs when the source encoder is suboptimal, and when the source decoder input differs from the source encoder output, which is a result of channel errors. These two situations are common occurrences in practical communication systems where source and/or channel models are imperfectly known, complexity is a serious issue, or significant delay is not tolerable. Various approaches have been developed to handle these situations, and they are usually grouped under the general heading of joint sourcelchannel coding.</p><p>We have attempted to develop a more precise nomenclature by distinguishing three classes of coders. One class of coders we designate as joint source/channel coders because the source and channel coding operations are truly integrated, and in this class we include the work of Anchetta [3] and Massey 121, the work of Dunham and Gray 141, who proved the existence of joint source/channel trellis coders for certain fidelity criteria, and the joint source/channel coder designs of Ayanoglu and Gray 151.</p><p>In a second class, denoted as concatenated source/channel coders, we place coders that cascade known source coders and known channel coders, and allocate the fixed bit rate between the source coder and the channel coder to maximize the system performance. Work in this class includes that of <ref type="bibr">Modestino and Daut [6]</ref> who investigated two-dimensionalklifferential pulse code modulation (2-D-DPCM) for image coding combined with short constraint length convolutional codes, <ref type="bibr">Modestino,</ref><ref type="bibr">Daut,</ref><ref type="bibr">and Vickers [7]</ref>  Constrained joint source/channel coding is our third class of coders and is so named because the source coder and/or receiver are modified to account for the presence of a given noisy channel. In this class of coders, we place source coders which have been  Another subset in the class of constrained joint source/channel coders are those coders that use some knowledge of the source or source coder properties to detect channel errors and compensate for their effects. In this group we include the work by <ref type="bibr">Steele and Goodman,</ref><ref type="bibr">and Steele,</ref><ref type="bibr">Goodman,</ref><ref type="bibr">and McGonegal [21]</ref>, <ref type="bibr">[22]</ref> who detect errors in a speech coder output by monitoring the sample-to-sample differences in the reconstructed values and replacing those reconstructed values whose differences are too large by the output of a smoothing circuit, the work of Ngan and Steele <ref type="bibr" target="#b17">[23]</ref>, and <ref type="bibr">Pitt,</ref><ref type="bibr">Swanson,</ref><ref type="bibr">and Yuen [24]</ref> who use similar ideas to motivate the development of a method to recover from errors in an image transmission system, the work of Reininger and Gibson <ref type="bibr" target="#b19">[25]</ref> who use coefficients from neighboring blocks in a 2-D-DCT image coding system to detect errors and smooth out their effects, and the work of Sayood and Borkenhagen <ref type="bibr" target="#b20">[26]</ref>, <ref type="bibr" target="#b21">[27]</ref> who use redundancy in the coder output to perform sequence estimation. <ref type="bibr">Hellman [28]</ref>, <ref type="bibr" target="#b23">[29]</ref> also suggests using the natural redundancy to corrent errors in joint source/channel coding, and proposes a rate 1 catastrophic code to aid the process. The research described in this work is an extension of the work of Sayood and Borkenhagen <ref type="bibr" target="#b20">[26]</ref>, <ref type="bibr" target="#b21">[27]</ref>, and generalizes the approach of <ref type="bibr" target="#b15">[21]</ref>- <ref type="bibr" target="#b19">[25]</ref>. An earlier version of this work was presented in <ref type="bibr" target="#b24">[30]</ref>.</p><p>In the following section, we describe the design criterion that is used for the various approaches presented in this paper. This is used in the following section to motivate some modification of existing source coder/convolutional coder design. The proposed modifications are evaluated using simulations, and the results of the evaluations are used to propose a class of nonbinary convolutional encoders. Simulation results are presented which show that the proposed designs substantially outperform conventional systems in the assumed scenario.  This result addresses the situation in which the source coder output (which is also the channel input sequence) contains redundancy. In [27], we have shown that for a differential encoding system, even the slightest mismatch can lead to redundancy in the coder output. This is true even when the input is a well-behaved synthetic source. Motivated by this result, we can use (1) to design a decoder which will take advantage of dependence in the channel input sequence. The physical structure of the decoder can be easily obtained by examing the quantity to be maximized. which is similar in form to the path metric of a convolutional decoder. Error correction using convolutional codes is made possible by explicitly limiting the possible codewordto-codeword transitions, based on the previous code input and the coder structure. At the receiver, the decoder compares the received data stream to the a priori information about the code structure. The output of the decoder is the sequence that is most likely to be the transmitted sequence. In the case where there is residual structure. in the source coder output, the structure makes some sequences more likely to be the transmitted sequence, given a particular received sequence. In other words, even when there is no structure being imposed by the encoder, there is sufficient residual structure in the source coder output that can be used for error correction. The structure is reflected in the conditional probabilities, and can be used via the path metric in (2) in a decoder similar in structure to a convolutional decoder. However, to implement this decoder we need to be able to compute the path metric.</p><p>Examining the branch metric, we see that it consists of two terms log P(&amp;ly;) and log P(y;lyi-l). The first term depends strictly on our knowledge of the channel. The second term depends only on the statistics of the source sequence. Therefore knowledge of both the channel and source statistics is necessary for implementing this path metric. In our simulations, we have obtained the channel statistics by assuming that the channel is a binary symmetric channel with known probability of error. We have obtained the second term using a training sequence. The sequence used for testing the proposed approach is different from the training sequence.</p><p>In <ref type="bibr" target="#b20">[26]</ref>, we showed that the use of the decoder led to dramatic improvements under high-error-rate conditions. However, at low error rates, the performance improvement was from nonexistent to minimal. This is in contrast to standard error correcting approaches, in which the greatest performance improvements are at low-error rates, with a rapid deterioration in performance at high-error rates. In this work, we combine the two approaches to develop a joint source/channel coder which provides protection equal to the standard channel encoders at low-error rates while also providing significant error protection at high-error rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">CONVOLUTIONAL ENCODERS AND</head><p>JOINT SOURCE/CHANNEL DECODER</p><p>In <ref type="bibr" target="#b21">[27]</ref> the output sequence of the source coder was taken as the sequence {yi}. The received sequence {ai} formed the input to the joint source/channel (JSC) decoder which was simply a Viterbi decoder with a path metric similar to (2).</p><p>The output of the JSC decoder was then passed to the source decoder. As mentioned previously, this approach provided signifiGant improvements only at high-error rates. If we had used a standard convolutional encoder with the source coder, this would have provided excellent error protection at lowerror rates (of course with an increase in the transmission rate). However, in spite of the increase in transmission rate, the convolutional coder still does not provide any protection at high-error rates.</p><p>The convolutional decoder uses the structure imposed by the encoder and the Hamming metric to provide error protection. The decoder does not use any of the residual structure from the source coder output. We can make use of the residual structure by noting that the path labels transmitted by the convolutional encoder comprise the channel input alphabet {yi}. We can then use a training sequence to obtain the transition probabilities {P(y;/yi-~)}, and an estimate of the channel error probability to obtain { P(y; \vi)}. These can be used to compute the branch metric L .</p><p>(3) which can be used instead of the Hamming metric in the decoder.</p><p>We simulated this approach using a two-bit DPCM system as the source encoder. We used the three images shown in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>/ .</head><p>Fig. <ref type="figure" target="#fig_1">1</ref> as the source. The USC girl image was used for training (obtaining the requisite transition probabilities and later, codeword assignments) and the USC couple and tree images were used for testing. The output of the DPCM system was encoded using various convolutional encoders obtained from <ref type="bibr" target="#b26">[32]</ref>. The performance of the different systems was evaluated using two different measures. One was the reconstruction signal-to-noise ratio (RSNR) defined as where U ; is the input to the source coder (source image), u i is the output of the source decoder (reconstructed image), and up is the peak value taken on by the input (in the case of the images used in this work up is 255). The other performance measure was the decoded error probability which was the ratio of the number of bits in error after decoding and the total number of bits. The received sequence was decoded using a standard convolutional decoder and the JSC decoder. A block diagram of the system is shown in Fig. <ref type="figure" target="#fig_2">2</ref>. The use of the JSC decoder is predicated on the assumption that there is some structure in the source coder output. The convolutional coder has to be selected in accordance with this assumption. In order to do this, the input alphabet of the convolutional encoder has to match the output alphabet of the source coder. In our example, the DPCM coder outputs are two bit labels. We found that convolutional coders that used an input wordlength k of two were able to utilize the residual redundancy. Convolutional coders, with k different from two (in this example), provided little or no improvement.</p><p>We simulated our approach with rate 1/2 and a rate 2/3 codes and present results for a (4, 2, 1) code and a (3, 2, 2) code. The connection vectors for the rate 1/2 (4, 2, 1) coder are <ref type="bibr" target="#b26">[32]</ref> and the connection vectors for the rate 2/3 (3, 2, 2) convolutional coder are <ref type="bibr" target="#b26">[32]</ref> gy = 7 gp = 1 gy) = 4 gp = 2 9 p = 5 g f ) = 7.</p><p>The results are shown in Figs. <ref type="figure" target="#fig_4">3</ref> and<ref type="figure" target="#fig_6">4</ref>.</p><p>In Fig. <ref type="figure" target="#fig_4">3</ref>, we compare the performance of the (4, 2, 1) encoder with the convolutional decoder and the JSC decoder. The system with the JSC decoder has comparable performance at low-error rates, while at high-error rates the performance of the system with the JSC decoder is substantially better. The RSNR performance at high-error rates is about 6 dB better for the system with the JSC decoder. A similar performance improvement can be seen in the decoded probability of error curves.</p><p>In Fig. <ref type="figure" target="#fig_6">4</ref>, we compare the performance of the (3, 2, 2) systems. In this case, there is some drop in the performance of the system with the JSC decoder in the low-error region. However, the performance in the high-error region is more than 9 dB better! A similar behavior can also be seen for the decoded probability of error curves. The drop in performance in the low-error region is some cause for concern here, as one is most likely to be operating in the lower error regions. In Section IV, we will present an alternate design which takes care of this problem.</p><p>In this section, we have shown how the use of the residual redundancy in the source coder output can improve the performance of conventional source coder/convolutional coder systems. In order to make use of this redundancy, the channel coder input characteristics have to match the source coder output characteristics. In the next section, we take this approach one step further and design channel coders with the specific goal of taking advantage of the redundancy in the source coder output. An additional advantage of the coders described in the next section is that there is an automatic match between the source coder output and the channel coder input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. A MODIFTED CONVOLUTIONAL ENCODER</head><p>Given that the preservation of the structure in the source coder output requires the channel coder input alphabet to have a one-to-one match with the generally nonbinary source coder, we propose a general nonbinary convolutional encoder (NCE) whose input alphabet has the requisite property.</p><p>Let x,, the input to the NCE, be selected from the alphabet A = (0, 1,2, . . . , N -l}, and let y , , the output alphabet of the NCE, be selected from the alphabet S = (0, 1,2, . . . , M -1).</p><p>Then the proposed NCEs can be described by the following mappings:</p><p>1 )</p><formula xml:id="formula_0">M = N 2 ; 9, = N x , -~ f ~, .</formula><p>The number of bits required to represent the output alphabet using a fixed length code is Therefore, in terms of rate, this coder is equivalent to a rate 1/2 convolutional encoder. The encoder memory in bits is 2 [log, ( N ) ] as each output value depends on two input values.</p><p>As an example, consider the situation when N = 4.</p><p>Then A = {0,1,2,3} and S = {0,1,2,...,15} . Given the input sequence 5,: 0 1 3 0 2 1 1 0 3 3 and assuming the encoder is initialized with zeros, the output sequence will be y , : 0 17 12 29543 15.</p><p>The encoder memory is four bits. Notice that while the encoder output alphabet is of size N 2 , at any given instant the encoder can only emit one of N different symbols as should be the case for a rate 1/2 convolutional encoder. For example, if yn-l = 0, then y , will take on a value from (0, 1,2,. . . , ( N -</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1)).</head><p>In general, given a value for yn-1,yn will take on a value from { a N , a N + 1, a N + 2,. . . , aN + N -l}, where cy = yn-l( mod N ) . This structure can be used by the decoder to provide error protection. The encoder is shown in Fig. <ref type="figure">5(a)</ref>. This encoder is equivalent to a rate 113 convolutional encoder with an encoder memory in bits of 3rlog2 ( N ) ] . Given the same input as the previous example, the output alphabet for the NCE is</p><formula xml:id="formula_1">S zz { 0 , 1 , 2 , . . . ,63}</formula><p>. and the output sequence for the same input sequence is yn: 0 1728 50 93720 19 15.</p><p>The encoder memory is six bits. In this case, even though the encoder output alphabet is of size N3, at any instant the encoder can only emit one of N symbols. In general, given a value for yn-l, y , will take on a value from { P N , P N + l , . . . , P N + N -l}, where ,l 3 = y,-l(modN2). A block diagram of the encoder is shown in Fig. <ref type="figure">5(b)</ref>.</p><p>3)</p><formula xml:id="formula_2">M = N 3 ~n + N X 2 n -1 + 1 ~2 n -2 .</formula><p>The final encoder we consider is equivalent to a rate 213 convolutional coder. Notice that while the input-output relationship looks similar to a rate 1/3 encoder, we generate one output for every two inputs. Thus, while the number of bits needed to represent one letter from the output alphabet is three times the bits needed to represent a letter from the input alphabet, the rate is 213 because two input letters are represented by a single output letter. This coder could be viewed as a rate 213 punctured nonbinary convolutional coder. Again, assuming a value of 4 for N , the output alphabet is of size 64, and for the input sequence used previously, the output sequence is yn: 0 52 35 22 49 3.. The encoder memory is again 6 bits. The rate of the encoder can also be inferred from the fact that while the encoder output alphabet is of size N3, at any instant the encoder can transmit one of N 2 (instead of N) symbols. Given a value for y,-1, yn can take on a value from the alphabet {yN2, y N 2 + 1 , . . . , y N 2 + ( N 2 -1)) where y = y,-l(modN). A block diagram of the encoder is shown in Fig. <ref type="figure">5(c)</ref>.</p><p>All of these encoders can be designed for any value of N . Furthermore, their input and output alphabets as described above can easily be seen as indexes to tables of codewords. We will exploit this latter property in the next section for allocating codewords to the NCE outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Binary Encoding of the NCE Output</head><p>We will make use of the residual structure in the source coder output (which is preserved in the NCE output) at the receiver. However, we can also make use of this structure in selecting binary codes for the NCE output. An intelligent assignment of binary codes can improve the error correcting performance of the system. When each allowable sequence is equally likely, there is little reason to prefer one particular assignment over others. However, when certain sequences are more likely to occur than others, it would be useful to make assignments which increase the "distance" between likely sequences. While, for small alphabets it is a simple matter to assign the optimum binary codewords by inspection, this becomes computationally impossible for larger alphabets. We use a rather simple heuristic which, while not optimal, provides good results.</p><p>The number of M bits codewords that have to be assigned are exactly 2M. Our strategy is therefore to try to maximize the Hamming distance between codewords that are likely to be mistaken for one another.</p><p>First, we obtain a partition of the alphabet based on the fact that given a particular value for yn-l,yn can only take on values from a subset of the full alphabet. To see this, consider the rate 1/2 NCE; then the alphabet S can be partitioned into the following subalphabets 1100 n if = yn-l(modN). Now for each subalphabet, we have to pick N codewords out of M ( = N 2 ) possible choices. We first pick the subalphabet containing the most likely letter.</p><p>The letters in the subalphabet are ordered according to their probability of occurrence. We assign a codeword a from the list of available codewords to the most probable symbol. Then, assign the complement of a to the next symbol on the list. Therefore, the distance between the two most likely symbols in the list is K = [log, M ] bits. We then pick a codeword b from the list which has maximum distance from a such that the Hamming distance from a and the Hamming distance from the complement of a differ by at most one. We assign it and its complement to the next two elements on the list. This process is continued until all letters in the subalphabet have a codeword assigned to them.</p><p>As an example, consider the case where N = 4. The partitions are <ref type="bibr">12,</ref><ref type="bibr">13,</ref><ref type="bibr">14,</ref><ref type="bibr">15)</ref>.</p><formula xml:id="formula_3">I 1 \ s o = (0,1,2,3) s1 = (4,57677) i 5'2 = (8,9,10,11) S3 = (</formula><p>Assuming that 0 is the most probable symbol, we start by assigning codewords to the SO subalphabet. Suppose P(0) 2 P(3) 2 P(1) 2 P(2).</p><p>We first pick a 4-bit codeword for 0 as 0000. The next most probable symbol in this subalphabet is 3; therefore the codeword for 3 is the complement of the codeword for 0; 3:1111. The codeword for 1 is at a Hamming distance of two from the codeword for 0 and the codeword for 3.</p><p>The codeword 001 1 satisfies this requirement; therefore the codeword for 1 is 0011 and the codeword for 2 is 1100. Suppose the next symbol which is close in probability to the symbol 0 is 4. We select the subalphabet containing that symbol which is SI. To the symbol 4 we assign a codeword from the list of unassigned codewords which is furthest from the codeword for 0. There are several possibilities for this; we pick 1110 . We then follow the same procedure for the S1 subalphabet. Continuing in this manner, we get the assignments shown in Table <ref type="table" target="#tab_0">I</ref>.</p><p>s o = ( 0 , 1 , 2 , . . . , N -l )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Simulation Results</head><formula xml:id="formula_4">S1 = ( N , N + 1, N + 2.. . . , 2N -1)</formula><p>The proposed nonbinary convolutional encoders were simulated using the same setup as was used in the previous simulations. The binary assignments were made using the statistics of the training image which again was the USC girl image. The test images were once more the USC couple image</p><formula xml:id="formula_5">SN-l = ( N ( N -'1: N ( N -') + l 7 N ( N -'I7 +2, ' . . ' N 2 -1)</formula><p>where the encoder will select letters from alphabet Sj at time In Fig. <ref type="figure">6</ref>, we compare the performance of the rate 2/3 coders. Recall that the (3, 2, 2) with the JSC decoder performed significantly better than the conventional system at high error rates, there was a relative dip in performance at low-error rates. From Fig. <ref type="figure">6</ref>(a), we can see that the rate 2/3 NCE does not have this problem. Furthermore, the rate 2/3 NCE performs uniformly better than the (3, 2, 2) coder, even with the JSC decoder, at all error rates. To see how these numbers translate to subjective quality, in Fig. <ref type="figure" target="#fig_9">7</ref>, we show the reconstructed image with no errors and with a channel probability of error of 10-1 with all three systems. A channel error probability of 10-1 is a rather severe channel condition, and the conventional system breaks down as is evident from Fig. <ref type="figure" target="#fig_9">7(b</ref>). If we did not know what the reconstructed image looks like, it would be difficult to figure it out from the output of the standard system. If we use a JSC decoder instead of the Viterbi decoder, we get the reconstructed image of Fig. <ref type="figure" target="#fig_9">7(c</ref>). It is obvious from this picture what the image in the picture is. Finally, in Fig. <ref type="figure" target="#fig_9">7(d)</ref>, we show the reconstructed image obtained when using the rate 2/3 NCE. Even though the effect of channel errors can be made out, this image is quite close to the reconstructed image without channel errors shown in Fig. <ref type="figure" target="#fig_9">7(a)</ref>. As reconstructions of this quality could be quite useful in a number of applications, this approach significantly extends the usable range of channel conditions.</p><p>In Fig. <ref type="figure">8</ref>, we compare the performance of the rate 1/2 coders. Recall that in the previous simulations the (4, 2, 1) coder with the JSC decoder substantially outperformed the (4, 2, 1) coder with the Viterbi decoder. From Fig. <ref type="figure">8</ref>, we can see that the rate 1/2 NCE provides a further improvement over the (4, 2, 1) coder with the JSC decoder at all error rates. While the improvement is slight, it is perceptible as can be seen from the reconstructed images in Fig. <ref type="figure">9</ref>. In Fig. <ref type="figure">9</ref>(a), we show the reconstructed image at the output of the (4, 2, 2 ) coder with the standard Viterbi decoder when the channel error probability is 0.15. As can be expected, at this very high probability of error, the channel is not usable, and the reconstructed image is a blur. However, the image is clearly recognizable in Fig. <ref type="figure">9(b</ref>) which shows the reconstructed image obtained with the (4, 2, . 1) coder and the JSC decoder at the same probability of error. This reconstruction is further improved upon when we use the rate 1/2 NCE coder as can be seen from Fig. <ref type="figure">9(c</ref>). With the rate 2/3 NCE we extended the usable channel error range to 10-l. With the rate 1/2 NCE we can extend this range even further to 0.15! V. CONCLUSION In this paper, we have presented two ways of using the structure in the source coder output for forward error correction. The first approach simply modifies the decoder in a conventional source coder/convolutional coder system to take advantage of the residual redundancy. This approach would be especially useful in situations where a conventional system was already in place and a change in channel characteristics or transmission requirements required that the system be "updated." The modifications in this case would be relatively modest and would only need to be performed at the decoder. The simulation results show improvements of more than 6 dB at high-error rates. The second approach involves a new design of the channel encoder. The simulation results pertaining to this design show excellent performance over a wide range of channel error probabilities, from 0.0 to 0.15. When compared with conventional systems, the performance improvements range as high as 9 dB at high-error rates. These designs might be especially useful in the codecs designed for the mobile radio communication channel.</p><p>While we feel that this approach is a very useful one, its utility would be further improved if some outstanding issues were resolved. An issue that has not been considered in this paper is the effect of mismatch between the actual and assumed channel statistics. Another important area of future research is the development of a theoretical measure analogous to dfree for use in predicting and classifying performance of the coders developed in this paper.</p><p>Finally, there is no explicit (numerical) relationship between the redundancy in the output of the source coder, and the increase in the amount of error protection capability obtained when we use the approaches described in this paper. A major reason for this is the difficulty in characterizing "redundancy."</p><p>Often, when we talk about redundancy, we mean some function of correlation. In [27], we showed that the amount of improvement available by the use of the JSC approach is not related to the correlation in the output of the source coder. In <ref type="bibr" target="#b21">[27]</ref>, we defined a quantity called the error correction capability index I as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>( 5 )</head><p>where H(Y,IY,-l) is the conditional entropy at the output of the source coder. This quantity did show some correlation with the improvement available, however, despite its impressive name, the correlation was more qualitative than quantitative.</p><p>While the proposed techniques provides a useful and effective approach to the use of residual redundancy in the output of source coders, resolution of these issues will further enhance their utility.</p><p>Fuling Liu (S'91-M'92) received the B.S. degree in chemical engineenng from the National Taiwan University, Taipei, in 1982, and the M.S. and Ph.D. degrees in electrical engineenng from the University of <ref type="bibr">Nebraska, Lincoln, in 1987 and</ref><ref type="bibr">1992, respectively.</ref> He is currently a Senior Research Engineer at Western Atlas, Inc., Houston, TX, working on trellis coded modulation and real-time Manchester signal decoding. His research interests include digital signal processing, image and video compression, modulation, and coding.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>who investigated 2-D discrete cosine transform (DCT) of images with convolutional codes, Modestino, Bhaskaran, and Anderson [SI who studied tree encoding of images with convolutional coding, Comstock and Gibson [9] who considered 2-D-DCT coding of images in conjunction with Hamming codes, Moore and Gibson [lo] who evaluated DPCM speech encoding with self-orthogonal convolutional codes, Reininger and Gibson 1111 who studied backward adaptive prediction in DPCM speech coding along with highrate convolutional codes, and Goodman and Sundberg [ 121, [ 131 who developed embedded DPCM speech encoding and punctured convolutional codes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Training image and test images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. System block diagram.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>11.</head><label></label><figDesc>THE DESIGN CRITERION For a discrete memoryless channel (DMC), let the channel input alphabet be denoted by A = { a o , a l ; . . , a ~-~, } , and the channel input and output sequences by Y =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. (a) RSNR performance of (4, 2, 1) coder with conventional and JSC decoders. (b) Error performance of ( 4 . 2 , 1) coder with conventional and JSC decoders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. (a) RSNR performance of (3, 2, 2) coder with conventional and JSC decoders. (b) Error performance of (3, 2, 2) coder with conventional and JSC decoders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Fig. 5. Nonbinary convolutional encoders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Fig. 6. (a) RSNR performance of rate 2/3 coders with conventional and JSC decoders. (b) Error performance of rate 2/3 coders with conventional and JSC decoders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Performance of rate 2/3 systems at P ( f ) = 0.10. (a) Reconstructed image with no channel error, (b) (3, 2, 2 ) encoder with Viterbi decoder. (cy ( 3 , 2, 2) encoder with JSC decoder. (d) Rate 2/3 NCE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Fig. 8. (a) RSNR performance of rate 1/2 coders with conventional and JSC decoders. (b) Error performance of rate 1/2 coders with conventional and JSC decoders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Fig. 9 JSC decoder. (c) Rate 1/2 NCE. Performance of rate 1/2 systems at channel error probability of 0.15. (a) (4, 2, 1 ) encoder with Viterbi decoder. (b) (4, 2, 1 ) encoder wlth</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I CODE -WORD ASSIGNMENTS -Symbol &amp;&amp;</head><label>I</label><figDesc></figDesc><table><row><cell>so SI</cell><cell>0000 0011</cell><cell cols="2">Symbol Code se 1101 s9 0110</cell></row><row><cell>s 2 s,</cell><cell>0111 1011</cell><cell>5.10 SI1</cell><cell>0001 0100</cell></row><row><cell>s 4</cell><cell>1111</cell><cell>S I 2</cell><cell>1110</cell></row><row><cell>s g</cell><cell>1001</cell><cell>SI3</cell><cell>0010</cell></row><row><cell>S6</cell><cell>0101</cell><cell>S I 4</cell><cell></cell></row><row><cell>SI</cell><cell>1010</cell><cell>S I 5</cell><cell>0100</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by NASA Lewis Research Center under Grant NAG 3-806 and NASA Goddard Space Flight Center under Grant NAG 5-1612.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr">(New York: Macmillan, 1993)</ref><p>. His research interests include data compression, digital communications, information theory, speech processing, and image processing.</p><p>Dr. Gibson received the 1990 Frederick Emmons Terman Award from the American Society for Engineering Education and in 1992 was elected Fellow of the IEEE "for contributions to the theory and practice of adaptive prediction and speech waveform coding." He was corecipient of the 1993 IEEE Signal Processing Society Senior Paper Award for the Speech Processing Area. He is a member of the IEEE Information Theory Society Board of <ref type="bibr">Governors (1990-95)</ref>, the Speech Technical Committee of the IEEE Signal Processing Society (1992-95), and the Editorial Board for the Proceedings of the IEEE  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The mathematical theory of communication</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BSTJ</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="379" to="423" />
			<date type="published" when="1949-10">Oct. 1949</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Joint source and channel coding</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Massey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communication Systems and Random Process Theory</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Skwirzynski</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1978">1978</date>
			<biblScope unit="page" from="279" to="293" />
		</imprint>
	</monogr>
	<note>The Netherlands: Sijthoff and Nordhoff</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Joint source channel coding</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Ancheta</surname><genName>Jr</genName></persName>
		</author>
		<imprint>
			<date type="published" when="1977-08">Aug. 1977</date>
			<pubPlace>Notre Dame, IL</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Univ. Notre Dame</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The design of joint source and channel trellis waveform coders</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Dunham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ayanoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="516" to="519" />
			<date type="published" when="1981-07">July 1981</date>
		</imprint>
	</monogr>
	<note>IEEE Trans. Inform. Theory</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Combined source channel coding of images using the block cosine transform</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Modestino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Daut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Modestino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Daut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Vickers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1262" to="1274" />
			<date type="published" when="1979-11">Nov. 1979. Sept. 1981</date>
		</imprint>
	</monogr>
	<note>IEEE Trans. Commun.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hamming coding of DCT compressed images over noisy channels</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Modestino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bhaskaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Comstock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Gibson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="856" to="861" />
			<date type="published" when="1984-07">July 1984</date>
		</imprint>
	</monogr>
	<note>IEEE Trans. Commun.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Self-orthogonal convolutional coding for the DPCM-AQB speech encoder</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Gibson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comrnun</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Backward adaptive lattice and transversal predictors in ADPCM</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Reininger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Gibson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="74" to="82" />
			<date type="published" when="1985-01">Jan. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Combined source and channel coding for variable bit-rate speech transmission</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Sundberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Sysr. Tech. J</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="2017" to="2036" />
			<date type="published" when="1983-09">Sept. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Transmission errors and forward error correction in embedded differential PCM</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Wintz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun. Technol</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="291" to="302" />
			<date type="published" when="1969-04">Nov. 1983. Apr. 1969</date>
		</imprint>
	</monogr>
	<note>Bell Sysr. Tech. J .</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Optimal quantizer design for noisy channels: An approach to combined source-channel coding</title>
		<author>
			<persName><forename type="first">N</forename><surname>Farvardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vaishampayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="827" to="838" />
			<date type="published" when="1987-11">Nov. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Analysis, optimization, and sensitivity study of differential PCM systems operating on noisy communication channels</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Vaishampayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Farvardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">; K.-Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Donaldson</surname></persName>
		</author>
		<idno>NOV. 1981. COM-32</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comrnun</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="327" to="336" />
			<date type="published" when="1181">June 1972. 855-865, NOV. 1987. Aug. 1984. Mar. 1990. 1181</date>
		</imprint>
	</monogr>
	<note>IEEE Trans. Commun.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Analysis of digital errors in nonlinear PCM systems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rydbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-E</forename><surname>Sundberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cornrnun</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5 9 4 5</biblScope>
			<date type="published" when="1976-01">Jan. 1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An algorithm for assigning binary indices to the codevectors of a multidimensional quantizer</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R B</forename><surname>Demarca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Jayant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICC&apos;87</title>
		<meeting>IEEE ICC&apos;87</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page">132</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Vector quantizer design for memoryless noisy channels</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gersho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICC &apos;88</title>
		<meeting>IEEE ICC &apos;88</meeting>
		<imprint>
			<date type="published" when="1988-06">June 1988</date>
			<biblScope unit="page" from="1593" to="1597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Detection and selective smoothing of transmission errors in linear PCM</title>
		<author>
			<persName><forename type="first">R</forename><surname>Steele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Syst. Tech. J</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="399" to="409" />
			<date type="published" when="1977-03">Mar. 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A difference detection and correction scheme for combatting DPCM transmission errors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Steele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="252" to="255" />
			<date type="published" when="1979-01">Jan. 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Enhancement of PCM and DPCM images corrupted by transmission errors</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Ngan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Steele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="257" to="269" />
			<date type="published" when="1982-01">Jan. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Image statistics decoding for convolutional codes</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Pitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Yuen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JPL</title>
		<imprint>
			<date type="published" when="1987-06">Apr.-June 1987</date>
			<pubPlace>Pasadena, CA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep. TDA Progress Rep. 42-90</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Soft decision demodulation and transform coding</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Reininger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Gibson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="572" to="577" />
			<date type="published" when="1983-04">Apr. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Utilization of correlation in low rate DPCM systems for channel error protection</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sayood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Borkenhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ZEEE ICC</title>
		<meeting>ZEEE ICC</meeting>
		<imprint>
			<date type="published" when="1986-06">June 1986</date>
			<biblScope unit="page" from="1888" to="1892" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Use of residual redundancy in the design of joint source channel coders</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="838" to="846" />
			<date type="published" when="1991-03">Mar. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On using natural redundancy for error detection</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Hellman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1690" to="1693" />
			<date type="published" when="1974-10">Oct. 1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Convolutional source encoding</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="651" to="656" />
			<date type="published" when="1975-11">Nov. 1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A joint source/channel coder design</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sayood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Gibson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICC</title>
		<meeting>IEEE ICC</meeting>
		<imprint>
			<date type="published" when="1993-05">May 1993</date>
			<biblScope unit="page" from="727" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Optimal detection of discrete Markov sources over discrete memoryless channels-Applications to combined source channel coding</title>
		<author>
			<persName><forename type="first">N</forename><surname>Phamdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Farvardin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint/>
	</monogr>
	<note>to be published</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Error Control Coding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Costello</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">College Station, in 1977, 1979, and 1982, respectively, all in electrical engineering. He joined the University of Nebraska-Lincoln in 1982 where he is now a Professor of Electrical Engineering. His current research interests include data compression, joint source/channel coding, communication networks, and remote sensing and biomedical applications</title>
		<author>
			<persName><forename type="first">Khalid</forename><surname>Sayood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">He received the B.S. and M.S. degrees from the University of Rochester and the Ph.D. degree from Texas A&amp;M University</title>
		<editor>
			<persName><forename type="first">Eta</forename><surname>Kappa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nu</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sigma</forename><surname>Xi</surname></persName>
		</editor>
		<meeting><address><addrLine>Rochester, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1956">1956</date>
		</imprint>
		<respStmt>
			<orgName>Middle East Technical University, Ankara, Turkey, and the University of Rochester</orgName>
		</respStmt>
	</monogr>
	<note>He received his undergraduate education at the</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
