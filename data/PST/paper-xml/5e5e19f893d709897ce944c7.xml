<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A novel reinforcement learning based grey wolf optimizer algorithm for unmanned aerial vehicles (UAVs) path planning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chengzhi</forename><surname>Qu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shandong University of Science and Technology</orgName>
								<address>
									<postCode>266590</postCode>
									<settlement>Qingdao</settlement>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Shandong University of Science and Technology</orgName>
								<address>
									<postCode>266590</postCode>
									<settlement>Qingdao</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wendong</forename><surname>Gai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shandong University of Science and Technology</orgName>
								<address>
									<postCode>266590</postCode>
									<settlement>Qingdao</settlement>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Shandong University of Science and Technology</orgName>
								<address>
									<postCode>266590</postCode>
									<settlement>Qingdao</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maiying</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shandong University of Science and Technology</orgName>
								<address>
									<postCode>266590</postCode>
									<settlement>Qingdao</settlement>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Shandong University of Science and Technology</orgName>
								<address>
									<postCode>266590</postCode>
									<settlement>Qingdao</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shandong University of Science and Technology</orgName>
								<address>
									<postCode>266590</postCode>
									<settlement>Qingdao</settlement>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Shandong University of Science and Technology</orgName>
								<address>
									<postCode>266590</postCode>
									<settlement>Qingdao</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A novel reinforcement learning based grey wolf optimizer algorithm for unmanned aerial vehicles (UAVs) path planning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">66BA19D80F53492586E537B37358F7E9</idno>
					<idno type="DOI">10.1016/j.asoc.2020.106099</idno>
					<note type="submission">Received date : 21 February 2019 Revised date : 20 November 2019 Accepted date : 14 January 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Unmanned aerial vehicles (UAVs)</term>
					<term>Three-dimensional Path planning</term>
					<term>Reinforcement learning</term>
					<term>Grey wolf optimizer</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is a PDF file of an article that has undergone enhancements after acceptance, such as the addition of a cover page and metadata, and formatting for readability, but it is not yet the definitive version of record. This version will undergo additional copyediting, typesetting and review before it is published in its final form, but we are providing this version to give early visibility of the article. Please note that, during the production process, errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>In aerospace domain, unmanned aerial vehicles (UAVs) have been demonstrated as the representation of high potential and challenging technologies in recent years <ref type="bibr" target="#b0">[1]</ref>. As a kind of modern aerial equipment, UAVs have been used in various areas, such as search, rescue, mapping and surveillance <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref>. However, threats like buildings, trees, mountains, i.e., make it very difficult for UAVs to accomplish missions efficiently <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>. Therefore, a predefined path is needed for UAVs to satisfy mission requirement, and path planning methods are required to acquire feasible and efficient solutions. Traditional methods, such as A* algorithm <ref type="bibr" target="#b5">[6]</ref>, artificial <ref type="bibr" target="#b7">[7]</ref>, linear programming <ref type="bibr" target="#b8">[8]</ref> and random trees <ref type="bibr" target="#b9">[9]</ref> are raised to solve the path planning problem. But most of these methods suffer from the high time complexity and local minima trapping when UAVs plan path with multiple constraints.</p><p>As a set of nature-inspired algorithms, meta-heuristic algorithms are originated from imitating biological interactive behaviors or physical phenomena <ref type="bibr" target="#b10">[10]</ref><ref type="bibr" target="#b11">[11]</ref>. The complicated real-world optimization problems for which traditional methods are not useful can be solved by the meta-heuristic algorithms <ref type="bibr" target="#b12">[12]</ref>. Recently, series of meta-heuristic algorithms have been used to solve the UAVs path planning problem by considering the path planning problem as the optimization problem <ref type="bibr" target="#b13">[13]</ref>. For example, Ref. <ref type="bibr" target="#b14">[14]</ref> presented an improved bat algorithm When the dimensions of optimization problem increase, the performance of the GWO algorithm drops like other meta-heuristic algorithms. However, the UAVs path planning problems usually own high dimensions in complex flight environment.</p><p>Reinforcement learning (RL) is a branch of machine learning <ref type="bibr" target="#b27">[26]</ref>. The essence of RL is that an agent discovers an optimal policy autonomously by interacting with the environment to maximize a long-term reward <ref type="bibr" target="#b28">[27]</ref>. The RL agent can receive evaluative reward from the environment after adopting an action in some state, and the performance of subsequent actions will be improved, which is closer to the human learning process <ref type="bibr" target="#b29">[28]</ref>. Since the pioneering work of Ref. <ref type="bibr" target="#b30">[29]</ref>, reinforcement learning has attracted increasing attention. Ref. <ref type="bibr" target="#b31">[30]</ref> presented a deterministic improved Q-learning method to solve the mobile robot path planning problems. Compared to the classical Q-learning, the proposed algorithm has a smaller time complexity. To solve the problem of unmanned ground vehicle (UGV) trajectory tracking, Ref. <ref type="bibr" target="#b32">[31]</ref> developed a reinforcement learning based deterministic policy gradient (DPG) algorithm to model the controller for tracking the optimal path. A modified reinforcement learning algorithm was presented by Ref. <ref type="bibr" target="#b33">[32]</ref> to solve the multi-agent systems path planning problem in unknown environment. The environment is estimated by the greedy actions using neural networks and kernel smoothing method. Ref. <ref type="bibr" target="#b34">[33]</ref> used the deep reinforcement learning paradigm as a framework to achieve the adaptive control of autonomous underwater vehicles (AUVs). The experiment results show that the deep reinforcement learning approach owns strong applicability for the autonomous robot control problem.</p><p>To overcome the defects of the GWO algorithm, this paper proposes a novel reinforcement learning-based grey wolf optimizer algorithm (called RLGWO) to solve UAVs path planning problem. The optimal path is computed by the proposed algorithm off-line, and it is smoothed by the cubic B-spline curve. The proposed algorithm integrates the essential characteristics of RL and GWO. The individuals of the GWO are defined as agents in RL and the cost function values are regarded as the evaluative signals.</p><p>Comparing with other improved GWO algorithm, this paper differs in the form that reinforcement learning method is inserted into RLGWO to choose the operation of each individual. Meanwhile, considering that the proposed algorithm is designed to serve for UAVs path planning, four operations have been developed for each individual: exploration, exploitation, geometric adjustment, and optimal adjustment. The geometric adjustment operation is developed to ensure the feasibility and the smoothness of the UAVs flight path. And the optimal adjustment operation is introduced to make the current trajectory jump out of local optimum. In addition, each operation will generate a positive or negative reward according to its result. The main contributions of this paper are summarized as follows:</p><p>(1) A novel reinforcement learning-based grey wolf optimizer algorithm called RLGWO is proposed to solve the UAVs three-dimensional path planning problem.</p><p>(2) The RLGWO includes four operations: exploration, exploitation, geometric adjustment and optimal adjustment. Each individual in RLGWO perform their operations independently.</p><p>(3) The geometric adjustment and optimal adjustment operations are developed to solve the problem of trapping in local optimization and unsmooth for UAVs path planning.</p><p>The structure of this paper is organized as follows. The mathematical model of UAV path planning is described in Section 2. Section 3 explains the principles of the basic GWO algorithm and the reinforcement learning. The detailed implementation of the proposed RLGWO algorithm is described in Section 4. Section 5 describes the route smoothing method by the cubic B-spline curve. In Section 6, the comparison experiments are finished. Finally, Section 7 summarizes the conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mathematical Model in UAVs Path Planning</head><p>Path planning is a critical component of UAVs mission planning, and it is used to find the optimal flight route under the constraints such as mountains, buildings, and other threats. In this paper, we assume that the UAVs maintains constant speed during its mission, and the mathematical model is described as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Threat resource model in UAVs path planning</head><p>The optimal route of UAVs path planning acquired from start point to target point need to consider all the threats and mission requirements. Motivated by the Ref. <ref type="bibr" target="#b35">[34]</ref>, the starting point has been defined as and the target point has been defined as , which is illustrated in Figure <ref type="figure" target="#fig_2">1</ref>. The threat obstacles are represented in the form of cylinders. x n x t x s ... First, the coordinate of S is set as ( , , )   s s s</p><p>x y z and the coordinate of T is set as ( , , )   </p><formula xml:id="formula_0">t t t</formula><p>x y z . The x-axis range has been divided into n+1 equal portions according to the point s x and t</p><p>x , the corresponding split points are defined as </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Cost function and performance constraints</head><p>It is known that the best flight route of UAVs path planning is often related to the straight path between S and T. Considering this characteristic, the UAVs path planning cost function cost J is defined as follows: </p><formula xml:id="formula_1">th ia i J J J J W l W l + W l (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>where fuel is the fuel cost, threat is the threat cost, J deviation is the deviation cost, ,<ref type="foot" target="#foot_0">1</ref>,<ref type="foot" target="#foot_1">2</ref>,<ref type="foot" target="#foot_2">3</ref> i i is a weighting parameter between 0 and 1, l presents the line segment of the whole route {l , k=1,2,...,n,n+1}. W fuel , W threat and W deviation represent the fuel cost, threat cost and the deviation cost on each path segment, and length denotes the length of the created</p><p>The deviation cost of the segment l k is calculated as follows:</p><formula xml:id="formula_3">2 2 , ( ) ( ) k deviation l k kl k kl W y y z z (2)</formula><p>where , ,</p><formula xml:id="formula_4">k k l k l</formula><p>x y z is the corresponding coordinate of the split point x k projected onto the straight path between S and T.</p><p>The threat cost of the segment l k is calculated at five points (include the start point and target point of l k ), as shown in Figure <ref type="figure" target="#fig_4">2</ref>.</p><formula xml:id="formula_5">X Y Z 0 威胁中心i ( , , ) k k k x y z 1 1 1 ( , , ) k k k</formula><p>x y z ( ' , ' , ' ) </p><formula xml:id="formula_6">k m k k threat l i i i k k k k i i i i i i i i l W d -r d -r + d -r + d -r + d -r<label>(3)</label></formula><p>where m denotes the number of threatening circles, 0.25,</p><formula xml:id="formula_7">k i d</formula><p>denotes the distance between the ith threat center and the 0.25 point on the segment, ri refers to the radius of the ith threat. It is assumed that the speed of the UAVs is a constant, therefore, the fuel can be considered as the length of the path. Considering generating a suitable route for the UAVs, the yawing angle and the pitch angle constraints are introduced as follows:</p><formula xml:id="formula_8">max 1 1 arctan , 1, 2, 3,..., 1 k+ k k k+ k y y = k n x x (4) max 1 1 arctan , 1, 2, 3,..., 1 k k k k k z z k n x x (<label>5</label></formula><formula xml:id="formula_9">)</formula><p>where max is the maximum yawing angle, max is the maximum pitch angle, k and k are the yawing angle and the pitch angle of the path point , ,</p><formula xml:id="formula_10">k k k x y z .</formula><p>Therefore, the UAVs path planning problem can be turned to the optimization problem to minimize cost J under the constraint conditions Eq. ( <ref type="formula">4</ref>) and Eq. ( <ref type="formula" target="#formula_8">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preliminary knowledge and basic idea</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The GWO algorithm</head><p>In the GWO algorithm, the individual with the best fitness is named wolf. The second and third individuals with better fitness are named wolf and wolf. These three wolves form the leader group. The rest of the individuals in the population are considered as . To model the encircling behavior that the grey wolves hunt the prey, Eq. ( <ref type="formula">6</ref>) and Eq. ( <ref type="formula" target="#formula_11">7</ref>) are designed as follows:</p><formula xml:id="formula_11">( ) ( ) i i p i D C X t X t (6) ( 1) ( ) i p i i X t X t A D (<label>7</label></formula><formula xml:id="formula_12">)</formula><p>where t is the current iteration, X i indicates the position of a grey wolf. X p denotes the position of the prey. The coefficient parameters A i and C i are shown as:</p><formula xml:id="formula_13">1 2 max 2 2 2 2 / i w i w A a r a C r a t t<label>(8)</label></formula><p>where r 1 and r 2 are random parameters in [0,1], a w is linearly decreased from 2 to 0. Each wolf updates its position according to the leader group ( wolf, wolf and wolf) as follows:</p><formula xml:id="formula_14">1 ( ) ( ) i D C X t X t (9) 2 ( ) ( ) i D C X t X t (10) 3 ( ) ( ) i D C X t X t (11) 1 1 ( ) X X t A D (12) 2 2 ( ) X X t A D (13) 3 3 ( ) X X t A D (14)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Reinforcement learning</head><p>Over the passage of time, many significant breakthroughs have been developed in reinforcement learning, and RL can be categorized into two groups: policy-based methods and value-based methods. Q-learning algorithm is a typical representative of value-based methods. During the learning, the agent performs action with the highest expected Q-values to estimate the optimal policy. The Q-table is updated based on the reward dynamically, and it is computed as follows: <ref type="bibr" target="#b16">(16)</ref> where t s is the current state, </p><formula xml:id="formula_15">1 1 1 ( , ) ( , ) [ max ( , ) ( , )] t t t t t t t t t a Q s a Q s a r + Q s a Q s a</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Basic idea of the proposed algorithm</head><p>To solve complex optimization problems, all the metaheuristic algorithms have been designed to find a proper balance between global exploration ability and local exploitation ability. In GWO, the search operations (exploration exploitation) are selected by the parameter A i . When the random values of A i are in [-1,1], the wolves move with smaller distance uniformly, which means a process of local search. When | A i | &gt; 1, the wolves are forced to make a global search uniformly. However, the global minimum will not be guaranteed by the unified search behavior. The independent search operation will become a better indicator to ensure the final success, and the embedding of reinforcement learning can accomplish this task well. Meanwhile, the geometric adjustment operation and the optimal adjustment operation are introduced to smooth the path and jump out of local optimum. Therefore, the novel reinforcement learning based grey wolf optimizer algorithm called RLGWO algorithm has been presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The development of the RLGWO algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The RLGWO structure</head><p>During the proceed of RLGWO, each individual is influenced by the leader group in the population on the base of their accumulated performance. The pseudocode of RLGWO is illustrated. This code will be repeated until meeting the maximum iteration. Figure <ref type="figure">3</ref> shows the whole structure of the RLGWO algorithm. Individuals of GWO are regarded as the train agents of reinforcement learning. The search space is regarded as the interactive environment. Four operations represented the states have been developed for each individual: exploration, exploitation, geometric adjustment, and optimal adjustment. And the change of action. According to the accumulated performance, the individual switches operation (state) adaptively. If the execution of operation results in a better performance, a positive reward will be given, otherwise the negative reward is given to complete the punishment. Perform the exploration operation using the Eq. ( <ref type="formula">15</ref> Perform the exploitation operation using the Eq. ( <ref type="formula">19</ref>)</p><p>Perform the geometric adjustment using the Eq. ( <ref type="formula">20</ref>) and Eq. ( <ref type="formula" target="#formula_20">21</ref>)</p><p>Perform the optimal adjustment using the Eq. ( <ref type="formula" target="#formula_26">27</ref> The parameter setting of the learning rate requires careful consideration in the Q-learning algorithm. When the learning rate approaches 1, the newly gained information is more valuable for the update of the Q-value in Q-table. And the existing information will not be ignored when a small value of is given. To maximize learning from the search space, can be reduced adaptively from a high value during the iteration process.</p><formula xml:id="formula_16">max cos 1 2 2 initial final initial final t t (<label>17</label></formula><formula xml:id="formula_17">)</formula><p>where initial represents the initial value of , final represents the final value of , t is defined as the current iteration number, t max is defined as the maximum iteration number. The reward r is set as follows:</p><p>1 1</p><formula xml:id="formula_18">,if the fitness improved r ,otherwise<label>(18)</label></formula><p>Figure <ref type="figure" target="#fig_8">4</ref> illustrates the update method of the Q-table. The Q-table is designed as a 4 × 4 matrix. The columns of the Q-table represent the action and the rows represent the state (exploration, exploitation, geometric adjustment, and optimal adjustment). Each individual has its own Q-table to ensure that the learning process is independent.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">The exploration and exploitation operations</head><p>In the classical GWO algorithm, the exploration operation is performed at the beginning of the iteration process. Towards the end of the iteration, the exploitation operation is executed. However, motivated by the description in <ref type="bibr" target="#b36">[35]</ref>, individuals need to have the capacity that any operations can be executed at any time during the iteration process. Reinforcement learning will become a better indicator to ensure that the best operation will be performed for each individual according to the accumulated performance.</p><p>The individual X i updates its position affected by the current leader group. Based on the descriptions of Section 3, the convergence parameter a w controls the movement of the individual. So, in the exploration operation, the parameter a w should be set a high value to force the individual make a global search. Moreover, the individual should be impacted by the current three best individuals uniformly in the exploration mode to weaken the influence of the wolf. After applying Eq. ( <ref type="formula">15</ref>), the result of the exploration operation is shown in Figure <ref type="figure">5</ref>.</p><p>In the exploitation operation, all individuals should move slowly towards the current best individual. Therefore, a w should be set a low value low to ensure a local search around the wolf. Moreover, the individual should be mainly impacted by wolf in the exploitation mode. Figure <ref type="figure" target="#fig_9">6</ref> shows the exploitation operation after applying Eq. ( <ref type="formula">19</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">The geometric adjustment operation</head><p>The movements of individuals are affected by the leader group and the convergence parameter a w . But the distribution of the individual elements is scattered under the premise of proper fitness. When the individual is regarded as a group of waypoints, the feasibility and the smoothness of the UAVs flight path are substantially affected.</p><p>Therefore, the geometric adjustment operation has been proposed in this paper to solve this problem. The pseudocode of the geometric adjustment operation is given. As shown in Figure <ref type="figure">7</ref>, this operation can result in a more efficient and direct path from position A to E in the form of creating a middle waypoint. The middle waypoint is calculated as: The pseudocode of the geometric adjustment For k=1 to n-1 Set X m =[y s , X i (1:n), y t , z s , X i (n+1:2n), z t ] Compute the X my (k) using Eq. ( <ref type="formula">20</ref>) Compute the X mz (k) using Eq. ( <ref type="formula" target="#formula_20">21</ref>)</p><formula xml:id="formula_19">( ) ( ( 1) ( 1)) / 2 my m m X k X k X k (20) ( ) (<label>( 1)</label></formula><formula xml:id="formula_20">( 3)) / 2 mz m m X k X k n X k n<label>(21)</label></formula><formula xml:id="formula_21">Set X m (k)=X my (k) Set X m (k+n+2)=X mz (k) Set X m =[X m (2:n+1), X m (n+4:2n+3)] Compute fitness f(X m ) If f(X m )&lt;f(X i ) X i =X m End If End For</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">The optimal adjustment operation</head><p>For the three-dimensional path planning problem of UAVs, it is known that the best flight route is often related to the straight path between start point and target point. When there are obstacles existing, the optimal route is the feasible path close to the straight path. Therefore, the influence of the optimal adjustment operation is followed. This operation updates all dimensions of the current individual, and starting from the y-axis and z-axis elements corresponding to the first waypoint, moving it the direction of the straight path. If a better result is obtained each time, the element is updated, otherwise the position is unchanged, and each waypoint is operated in turn.</p><p>The equation of the straight path has been acquired at the initialization stage of the algorithm. And the coordinates of the points on the line corresponding to the x-axis split points are defined as , ,</p><formula xml:id="formula_22">k k l k l</formula><p>x y z . The detail procedure of the optimal adjustment operation is introduced as follows:</p><p>Step 1 Set </p><p>0.2 0.1</p><formula xml:id="formula_24">zk zk zk V ,if fitness improved R V ,otherwise<label>(25)</label></formula><p>The position of ( , ) Step 3 Set the point ( , , )</p><formula xml:id="formula_25">k y k z k</formula><p>x P P as a provisional target point, compute the fitness of the path between the start point and the point ( , , ) k y k z k</p><p>x P P , and the variate ( ( ), ( ))</p><p>X k X k n is updated as follows:</p><p>( , <ref type="figure">( ( ),</ref><ref type="figure">(</ref> )) ( ( ), ( ))</p><formula xml:id="formula_26">yk zk P P ) ,if fitness improved X k X k n X k X k n ,otherwise (<label>27</label></formula><formula xml:id="formula_27">)</formula><p>Step 4 Repeat Step 2 and Step 3 T times (T=t max -t), then set k=k+1 and go to Step 1 until the termination condition k&gt;n is met.</p><p>The optimal adjustment operation is useful for UAVs path planning problem to escape the local optimization. However, this operation need to set a high cost at the beginning of the iteration, because much time consumed by executing this operation. Therefore, to prevent RLGWO from performing the optimal adjustment operation frequently at the beginning of the iteration process, an adaptive punishment r p is defined as follows:</p><p>, , , max ( ) 1 p pi n i t i a l pf i n a l pf i n a l t r r r r t <ref type="bibr" target="#b29">(28)</ref> where r p,initial represents the initial punishment parameter, r p,final represents the final punishment parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Computing complexity</head><p>As is shown in Figure <ref type="figure">3</ref>, the RLGWO algorithm can be divided into two phases. As the first phase of the program, the initialization phase is executed one time at the start, and the other phases are executed in each cycle. The is a vector with size of N. The dimension of each individual is N. The maximum iteration of the proposed algorithm is t max . The current iteration is t. The computational complexity is mostly affected by the phase of the algorithm. The computing complexity of each phase is shown as follows: , hence this phase runs in O N complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phase 2: Optimization</head><p>The optimization process of RLGWO includes four operations: exploration, exploitation, geometric adjustment, and optimal adjustment, Due to the character that each individual switches operation independently according to the accumulated performance, therefore, each operation is assumed to perform for all individuals to calculate the extreme computational complexity of each iteration.</p><p>In the exploration operation, all individuals should move fast to achieve global search impacted by the current three best individuals uniformly. In the exploitation operation, all individuals should move slowly towards the current best individual to ensure a local search. The computing complexity of exploration operation and exploitation operation are O N .</p><p>The geometric adjustment operation can ensure the feasibility and the smoothness of the planning path. The optimal adjustment operation updates all dimensions of the current individual to correct the planning path. The computing complexity of geometric adjustment operation is </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Path smoothing</head><p>In most cases, the routes planning by meta-heuristic algorithms are usually unsmooth for UAVs. Therefore, the cubic B-spline curve method is introduced to smooth the generated path in this paper. As shown in Figure <ref type="figure">8</ref>, the technique of cubic B-spline is introduced to ensure the flight route flyable and smooth <ref type="bibr" target="#b37">[36]</ref><ref type="bibr" target="#b38">[37]</ref>. The B-spline curve has evolved from Bezier curves and inherits the advantages of geometrical invariability, convexity preserving and affine invariance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">The three-dimension experiment comparison results</head><p>In this section, there are three simulation cases designed to evaluate the feasibility and effectiveness of the RLGWO algorithm. The size of the flight planning space is 2000 m * 2000 m * 1000 m. The start point is set to (0 m, 0 m, 0 m). The target point is set to (2000 m, 2000 m, 1000 m). The weighting parameters 1 , 2 , 3 are set as 0.2, 0.6, 0.2, respectively. To show the superiority of the proposed algorithm, the comparative results with the classical GWO IGWO <ref type="bibr" target="#b24">[23]</ref>, MGWO <ref type="bibr" target="#b25">[24]</ref> and EEGWO <ref type="bibr" target="#b26">[25]</ref> algorithms are also given. The maximum iteration number t max is set as 1000, and the initial parameters of the five algorithms are list in Table1. The simulation experiments of all cases are repeated for 30 times independently. In the planning space, the threats are denoted by eight cylinders. The related information of the threats is shown in Table <ref type="table" target="#tab_7">2</ref>. The results of the simulation are demonstrated in Figures 9 17. The comparison result is listed in Table <ref type="table" target="#tab_8">3</ref>. In this table, the mean, std, worst and optimal represent the mean fitness value, the standard deviation, worst fitness value and the optimal fitness value, respectively.</p><p>For the first case, Figure <ref type="figure">9</ref> shows that the experimental results of the five algorithms have some differences. The trajectory planned by the GWO and EEGWO have touched the edge of the threats, the trajectory planned by the MGWO is trapped in local optimization, and the result of the IGWO is oscillatory. The result of the RLGWO maintains significant performance. The convergence cures of the five algorithms in Case 1 are illustrated in Figures 10. It is obvious that the convergence effect of the proposed algorithm is better than the other algorithms. The RLGWO attains the global optimal value in iteration 60. The IGWO attains the local optimal value in iteration 160. The GWO and MGWO approach to their optimal value in iteration 680. The EEGWO finds its local optimal value in iteration 560. The statistical results are illustrated in Figure <ref type="figure" target="#fig_11">11</ref> and Table <ref type="table" target="#tab_8">3</ref>. The optimal value of the GWO is 1474.8, but the worst value is 2303.3, and the standard deviation is 319.5. These data indicate that GWO algorithm has poor result for multiple independent runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>The optimal value of MGWO is 1486.4, but the worst value is 3365.1, the standard deviation is 731.3. These data indicate that MGWO algorithm has lower success rate. The IGWO and EEGWO algorithms have similar poor result. Compared with the other algorithms, the simulation result of the proposed algorithm has smaller optimal, worst, and mean values. Meanwhile, the standard deviation of the RLGWO is 80.3, which proves that RLGWO can search for the optimal path stably.</p><p>For the second case, we have increased the complexity of the plan space slightly. Figure <ref type="figure" target="#fig_11">12</ref> shows that the RLGWO can find a feasible path to satisfy the path planning requirements with the smallest cost. The results of GWO, IGWO and EEGWO can satisfy the path planning requirements better. But the trajectory planned by the MGWO is trapped in local optimization. The convergence cures of the five algorithms in Case 2 are illustrated in Figures <ref type="bibr" target="#b13">13</ref>. From these curves it can be seen that the best convergence rate belongs to the RLGWO algorithm. The proposed algorithm attains the global optimal value in iteration 35. The EEGWO and GWO attain their local optimal value in iteration 920 and 660. The MGWO approaches to its optimal value in iteration 650. The convergence effect of the IGWO algorithm is preferable but worse than the proposed algorithm. For the statistical results shown in Figure <ref type="figure" target="#fig_11">14</ref> and Table <ref type="table" target="#tab_8">3</ref>, the RLGWO has the best performances for optimal, worst, mean and std values. The IGWO and EEGWO have close poor statistical results, and GWO has good results relatively. The MGWO has similar mean and optimal values with the IGWO and EEGWO, but the standard deviations of MGWO is larger. The standard deviation of the proposed algorithm is 80.1, which shows its superior performance.   In the third case, we have established a more complex flight environment to examine the performance of the five algorithms. Figure <ref type="figure" target="#fig_11">15</ref> shows that only RLGWO can complete the path planning mission perfectly. The trajectory planned by GWO, IGWO and EEGWO algorithm can not satisfy the path planning requirements. And the trajectory planned by the MGWO algorithm is trapped in local optimization. Figure <ref type="figure" target="#fig_11">16</ref> shows the convergence cures of the five algorithms in Case 3. The RLGWO has the faster convergence rate. The IGWO has a relatively fast convergence rate but worst result. The other three algorithms have poor convergence rates. As the statistical results shown in Figure <ref type="figure" target="#fig_11">17</ref> and Table <ref type="table" target="#tab_8">3</ref>, the proposed algorithm still provides the best results in optimal, worst, mean and std values. These results prove that RLGWO has excellent capability for UAV path planning in complex environment.</p><p>In summary, from the above experimental results it can be seen that the RLGWO algorithm can search for a satisfactory path stably, especially in the complex flight environment. And the favorable performance of the proposed algorithm is verified. In the whole iterative process of RLGWO, all operations participate in the optimization process. Each individual's global search behavior is embodied by the exploration operation, and its local search behavior is affected by the exploitation operation. The geometric adjustment operation is performed to ensure the feasibility and the smoothness of the planning path. The optimal adjustment operation updates all dimensions of the current individual to correct the planning path. The switching of the four operations is coordinated by RL, which finally makes the RLGWO algorithm has excellent performance in the simulation experiment of UAVs three-dimensional path planning.</p><p>J o u r n a l P r e -p r o o f</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Analysis of the RLGWO control parameters</head><p>The key control parameters of RLGWO are shown in Table <ref type="table" target="#tab_6">1</ref>. Compared to other algorithms, because the optimal adjustment operation owns higher computing complexity in earlier iteration, the population size N of RLGWO need to be set as a smaller value. Meanwhile, smaller N will not decrease the search performance because each individual owns independent search behavior. The values of convergence parameter w a and weighting parameter , 1,2,3 i i are set according to the characteristic of GWO. In GWO, the exploration and exploitation behaviors are selected by the parameter A i . When the random values of A i are in [-1,1], the wolves move with smaller distance, which means a process of exploitation. When | A i | &gt; 1, the wolves are forced to perform exploration operation. But the parameter A i is mainly affected by the convergence parameter w a . Thus, in the exploration operation of RLGWO, the parameter w a should be set a high value to force the individual make a global search. In the exploitation operation, w a should be set a low value to the decreasing weight , 1,2,3 i i represent that individuals should be mainly impacted by wolf in the exploitation operation.</p><p>The parameter setting of the learning rate is affected by the Q-learning algorithm. When the learning rate approaches 1, the newly gained information is more valuable for the update of the Q-value in Q-table. And the existing information will not be ignored when a small value of is given. Thus, is reduced adaptively from a high value to maximize learning rate from the search space. Therefore, the initial is set to a high value, and final is set to a low value. To prevent RLGWO from performing the optimal adjustment operation frequently at the beginning of the iteration process, an adaptive punishment r p is defined, and r p,initial represents the initial high cost, r p,final represents the final low cost.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>This work is supported by National Nature Science Foundation under Grant 61603220, 61873149, 61733009;; the Research Fund for the Taishan Scholar Project of Shandong Province of China;; SDUST Young Teachers Teaching Talent Training Plan under Grant BJRC20180503.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Schematic diagram of planning space</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Computation of threat costIf the path segment falls into a threat circle, the W threat is calculated as follows:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>J o u r</head><label></label><figDesc>n a l P r e -p r o o f</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 4</head><label>4</label><figDesc>Fig.4The Q-tableupdate</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6</head><label>6</label><figDesc>Fig. 5 The exploration operation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Fig. 7 The geometric adjustment operation</figDesc><graphic coords="7,282.34,559.75,273.16,167.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Phase 1 :</head><label>1</label><figDesc>InitializationThe population are initialized for the next work and the computing complexity of this phase is O N . Because the complexity of deciding on stopping criteria ended is 1 O</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>r n a l P r e -p r o o f iteration, which proves that this algorithm owns fast execution speed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig 10 . 2 Fig 13 3 Fig 16 .</head><label>10213316</label><figDesc>Fig 10. The convergence cures of the five algorithms in Case 1 Fig 11. The statistical results of the five algorithms in Case 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>End For Case 4: optimal adjustment For each dimension of X i</head><label></label><figDesc></figDesc><table><row><cell>Start</cell></row><row><cell>Initial  parameters,and  generate</cell></row><row><cell>the initial  population  randomly</cell></row><row><cell>Calculate  and compare  the  fitness  of</cell></row><row><cell>individuals, determine the  current</cell></row><row><cell>leader  group</cell></row><row><cell>The  RLGWO  algorithm  pseudocode Initialize Set  the  basic  parameters Set  the  state  s  ={s 1 ,  s 2 ,  s 3 ,  s 4 }  and  action  a  ={a 1 ,  a 2 ,  a 3 ,  a 4 } Set  the  initial  Q-table:  Q(s,  a)=0 Initialize  population  position , 1,2,..., i X i N Calculate  the  fitness  of  each  individual  f(X i ) Find  the  initial  leader  group:  X ,  X ,  X Set  t=0 Optimize While  t  &lt;  t max do Calculate  a Repeat  T  times Update  the  position  of  X i by  the  Eq.(27) Compute  fitness End  For Set  the  reward  to  a  negative  cost  value  r p by  the  Eq.(28) Update  the  position  of  X i End  Switch If  action  is  not  optimal  adjustment Update  fitness Get  the  reward  r  by  the  Eq.  (18) End  If Update  X ,  X ,  X Update  the  Q-table t=t+1 End  While Return  results Terminate Choose  the  best  a  for  the current s  from  Q-table J o u r n a l P r e -p r o o f All  individuals  visited?</cell></row></table><note><p>w , A, C, For each individual X i Choose the best a for the current s from Q-table Switch action Case 1: exploration Update the position of X i by the Eq.(15) Case 2: exploitation Update the position of X i by the Eq.(19) Case 3: geometric adjustment For each dimension of X i Update the position of X i by the Eq.(20) and Eq.(21)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>)</head><label></label><figDesc>Set the reward r p</figDesc><table><row><cell>Initial  the  state,  action  and  the</cell></row><row><cell>Q-table</cell></row><row><cell>Return the  best  individual</cell></row><row><cell>Update  the  current    leader  group</cell></row><row><cell>Update  the  Q-table  and  the  state</cell></row><row><cell>t=t+1</cell></row><row><cell>Fig.  3  The  flow  chart  of  the  RLGWO  algorithm</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 1 .</head><label>1</label><figDesc>The information of algorithms</figDesc><table><row><cell>Algorithm</cell><cell>Parameter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Value</cell></row><row><cell></cell><cell>Population  size  N</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50</cell><cell></cell></row><row><cell>GWO</cell><cell>Convergence  parameter</cell><cell cols="7">linearly  decreased  from  2</cell></row><row><cell></cell><cell>a w</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">to  0</cell></row><row><cell></cell><cell>Population  size  N</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50</cell><cell></cell></row><row><cell>IGWO</cell><cell>Convergence  parameter a w</cell><cell cols="7">1 -log(1 ( -1) / e t t</cell><cell>max</cell><cell>)</cell></row><row><cell></cell><cell>Inertia  weight  w</cell><cell>((</cell><cell>t</cell><cell>max</cell><cell cols="2">-) 0.8 / t</cell><cell>t</cell><cell>max</cell><cell>) 0.1</cell></row><row><cell></cell><cell>Population  size  N</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50</cell><cell></cell></row><row><cell>MGWO</cell><cell>Convergence  parameter a w</cell><cell cols="7">linearly  decreased  from  2 to  0</cell></row><row><cell></cell><cell>Control  parameter  C</cell><cell></cell><cell></cell><cell cols="2">2</cell><cell cols="3">-( /2 ) rand a</cell></row><row><cell></cell><cell>Population  size  N</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50</cell><cell></cell></row><row><cell>EEGWO</cell><cell>Convergence  parameter a w</cell><cell></cell><cell></cell><cell cols="5">max -t -t t 2 2( /</cell><cell>max</cell><cell>1.5 )</cell></row><row><cell></cell><cell>Constant  coefficient  b 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.8</cell></row><row><cell></cell><cell>Constant  coefficient  b 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.2</cell></row><row><cell></cell><cell>Population  size  N</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>10</cell><cell></cell></row><row><cell></cell><cell>Convergence  parameter a w (exploration)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2</cell><cell></cell></row><row><cell></cell><cell>Convergence  parameter a w (exploitation)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.5</cell></row><row><cell></cell><cell>Learning  rate  parameter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.9</cell></row><row><cell></cell><cell>initial</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>RLGWO</cell><cell>Weighting  parameter 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.6</cell></row><row><cell></cell><cell>Weighting  parameter 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.3</cell></row><row><cell></cell><cell>Weighting  parameter 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.1</cell></row><row><cell></cell><cell>Learning  rate  parameter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.1</cell></row><row><cell></cell><cell>final</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.5</cell></row><row><cell></cell><cell>Punishment  r p,initial</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">-10</cell></row><row><cell></cell><cell>Punishment  r p,final</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-2</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2 .</head><label>2</label><figDesc>The information of threat areas.</figDesc><table><row><cell cols="2">Case  number Threat  center</cell><cell>Height</cell><cell>Threat  radius</cell></row><row><cell></cell><cell>(600,300)</cell><cell>600</cell><cell>150</cell></row><row><cell></cell><cell>(500,1200)</cell><cell>800</cell><cell>200</cell></row><row><cell></cell><cell>(1200,200)</cell><cell>1000</cell><cell>200</cell></row><row><cell>1</cell><cell>(1000,1500) (1700,1100)</cell><cell>1200 1000</cell><cell>200 150</cell></row><row><cell></cell><cell>(900,60  0)</cell><cell>750</cell><cell>150</cell></row><row><cell></cell><cell>(1500,700)</cell><cell>900</cell><cell>100</cell></row><row><cell></cell><cell>(1400,1600)</cell><cell>1200</cell><cell>150</cell></row><row><cell></cell><cell>(500,200)</cell><cell>600</cell><cell>200</cell></row><row><cell></cell><cell>(600,1400)</cell><cell>800</cell><cell>200</cell></row><row><cell></cell><cell>(1200,200)</cell><cell>1000</cell><cell>250</cell></row><row><cell>2</cell><cell>(1100,1500) (1700,600)</cell><cell>1000 1000</cell><cell>250 150</cell></row><row><cell></cell><cell>(900,1000)</cell><cell>1200</cell><cell>200</cell></row><row><cell></cell><cell>(1300,1200)</cell><cell>1200</cell><cell>170</cell></row><row><cell></cell><cell>(1600,1600)</cell><cell>1200</cell><cell>150</cell></row><row><cell></cell><cell>(500,250)</cell><cell>600</cell><cell>250</cell></row><row><cell></cell><cell>(760,1000)</cell><cell>1200</cell><cell>300</cell></row><row><cell></cell><cell>(1100,200)</cell><cell>1000</cell><cell>200</cell></row><row><cell>3</cell><cell>(500,1500) (1500,900)</cell><cell>1000 1000</cell><cell>250 200</cell></row><row><cell></cell><cell>(1700,500)</cell><cell>750</cell><cell>250</cell></row><row><cell></cell><cell>(900,1400)</cell><cell>900</cell><cell>200</cell></row><row><cell></cell><cell>(1400,1600)</cell><cell>1200</cell><cell>300</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 .</head><label>3</label><figDesc>Results comparison of the three cases.</figDesc><table><row><cell></cell><cell></cell><cell cols="5">GWO IGWO MGWO EEGWO RLGWO</cell></row><row><cell></cell><cell>Mean</cell><cell cols="3">1900.4 3201.1 2494.5</cell><cell>3208.3</cell><cell>1542.4</cell></row><row><cell>Case</cell><cell>Std</cell><cell>319.5</cell><cell>374.2</cell><cell>731.3</cell><cell>367.1</cell><cell>80.3</cell></row><row><cell>1</cell><cell>Worst</cell><cell cols="3">2303.3 3611.8 3365.1</cell><cell>3587.9</cell><cell>1633.4</cell></row><row><cell></cell><cell cols="4">Optimal 1474.8 2613.3 1486.4</cell><cell>2634.2</cell><cell>1343.2</cell></row><row><cell></cell><cell>Mean</cell><cell cols="3">2542.3 2996.6 3064.2</cell><cell>3082.4</cell><cell>1841.9</cell></row><row><cell>Case</cell><cell>Std</cell><cell>438.8</cell><cell>734.3</cell><cell>1324.6</cell><cell>808.8</cell><cell>80.1</cell></row><row><cell>2</cell><cell>Worst</cell><cell cols="3">2985.9 4805.9 5546.3</cell><cell>4501.2</cell><cell>1933.7</cell></row><row><cell></cell><cell cols="4">Optimal 2098.5 2444.2 2380.6</cell><cell>2372.2</cell><cell>1670.9</cell></row><row><cell></cell><cell>Mean</cell><cell cols="3">3137.9 5042.8 3458.7</cell><cell>4901.6</cell><cell>1971.6</cell></row><row><cell>Case</cell><cell>Std</cell><cell cols="3">872.5 2241.6 1042.9</cell><cell>1427.1</cell><cell>476.1</cell></row><row><cell>3</cell><cell>Worst</cell><cell cols="3">5360.3 8347.8 5399.2</cell><cell>7617.2</cell><cell>3315.1</cell></row><row><cell></cell><cell cols="4">Optimal 2335.7 3170.6 2013.1</cell><cell>2555.1</cell><cell>1664.3</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>( 1) ( )/3 i X t X X X<ref type="bibr" target="#b15">(15)</ref> where X , X , and X denote the position of the leader group, X i is the position.J o u r n a l P r e -p r o o f</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The construction of the B-spline curves is based on blending functions, and the coordinates is defined as: , 0 ( ) ( ) <ref type="bibr" target="#b30">(29)</ref> where ( 0,1,..., ) i d i n are control points, N i,k (u) are the k-order normalized B-spline basic functions defined by the following Cox-deBoor recursion formulas:</p><p>The basic functions are determined by a non-decreasing sequence of parameters called parametric knots { 0 1 ... n+k u u u }. Compared with the Bezier curves, the B-spline curves method is particularly useful for smoothing path, and the degree of the polynomial will not be increased no matter how many points are added.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSIONS</head><p>In this paper, a novel reinforcement learning based grey wolf optimizer algorithm called RLGWO has been presented for UAVs path planning problem in three-dimensional flight environment. Firstly, the path planning problem is transformed into the optimization problem to acquire the optimal path by minimizing the cost function. Secondly, considering that the proposed algorithm is designed to serve for UAVs path planning, four operations have been developed for each individual: exploration, exploitation, geometric adjustment, and optimal adjustment. According to the accumulated performance controlled by the reinforcement learning, the individual switches operation adaptively. The geometric adjustment and optimal adjustment operations are developed to solve the problem of trapping in local optimization and unsmooth for UAVs path planning. Meanwhile, the cubic B-spline curve is used to smooth the generated flight route. Finally, the performance of the proposed algorithm has been tested with the GWO, IGWO, MGWO and EEGWO algorithms to generate an optimal path for UAVs in three-dimensional space. The effectiveness and superiority of these algorithms are compared based on the statistical results and convergence cures. The comparative results show that the RLGWO algorithm is superior to other four algorithms, and the proposed algorithm can solve the three-dimensional UAVs path planning problem successfully.</p><p>In the area of meta-heuristic optimization algorithms, the No Free Lunch (NFL) theorem was proposed that a universally applicable optimal algorithm independent of the specific application is not exist. It means that if one algorithm can solve a kind of problem effectively, then it will not be effective to solve another kind of problem. Thus, due to the addition of geometric adjustment operation and optimal adjustment operation, the proposed algorithm is more effective in solving path planning problems of intelligent agents (such as robots, unmanned aerial vehicles, underwater vehicles, etc.), which is also the limitation of this method. We will further solve and improve this problem in the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Research highlights:</head><p>A novel reinforcement learning-based grey wolf optimizer algorithm called RLGWO is proposed to solve the UAVs three-dimensional path planning problem.</p><p>The RLGWO includes four operations: exploration, exploitation, geometric adjustment and optimal adjustment. Each individual in RLGWO perform their operations independently.</p><p>The geometric adjustment and optimal adjustment operations are developed to solve the problem of trapping in local optimization and unsmooth for UAVs path planning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contribution Section</head><p>Chengzhi Qu carried out experiments and wrote the manuscript.</p><p>Wendong Gai proposed the idea and method.</p><p>Maiying Zhong and Jing Zhang J.S. analyzed experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>Journal Pre-proof Declaration of interests ☒ The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p><p>The authors declare the following financial interests/personal relationships which may be considered as potential competing interests:</p><p>J o u r n a l P r e -p r o o f</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social-class pigeon-inspired optimization and time stamp segmentation for multi-UAV cooperative path planning</title>
		<author>
			<persName><forename type="first">D F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="page" from="229" to="246" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unmanned aerial vehicle path following: a survey and analysis of algorithms for fixed-wing unmanned aerial vehicless[J]</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Sujit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saripalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sousa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Control Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="42" to="59" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">UAV path planning method for digital terrain model reconstruction -A debris fan example[J]</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automation in Construction</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="214" to="230" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Bi-level programming based real-time path planning for unmanned aerial vehicles[J]. Knowledge-Based Systems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Y</forename><surname>Cai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="34" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sampling-based path planning for UAV collision avoidance</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saripalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3179" to="3192" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Lifetime enhancement in wireless sensor networks using fuzzy approach and A-star algorithm</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Alshawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE Sensors Journal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3010" to="3018" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">UAV path planning using artificial potential field method updated by optimal control theory[J]</title>
		<author>
			<persName><forename type="first">Y B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y S</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Systems Science</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1407" to="1420" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Flight formation of UAVs in presence of moving obstacles using fast-dynamic mixed integer linear programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Radmanesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aerospace Science &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="149" to="160" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A probabilistically robust path planning algorithm for UAVs using rapidly-exploring random trees[J]</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kothari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Postlethwaite</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent &amp; Robotic Systems</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="231" to="253" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A survey on applications of the harmony search algorithm[J]</title>
		<author>
			<persName><forename type="first">D</forename><surname>Manjarres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Landatorres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gillopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1818" to="1831" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A survey of biogeography-based optimization</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Computing and Applications</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1909" to="1926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Hybrid meta-heuristic algorithms for independent job scheduling in grid computing</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Younis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="498" to="517" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Survey on computational-intelligence-based UAV path planning[J]. Knowledge-Based Systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="page" from="54" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Three-dimensional path planning for UCAV using an improved bat algorithm</title>
		<author>
			<persName><forename type="first">G G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aerospace Science &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="231" to="238" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">MVO-based 2D path planning scheme for providing quality of service in UAV environment[J]</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1698" to="1707" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Enhanced discrete particle swarm optimization path planning for UAV vision-based surface inspection[J]</title>
		<author>
			<persName><forename type="first">M D</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H Q</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Dinh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="25" to="33" />
		</imprint>
	</monogr>
	<note>Automation in Construction</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Path planning for solar-powered UAV in urban environment</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">275</biblScope>
			<biblScope unit="page" from="2055" to="2065" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Grey wolf optimizer[J]</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lewis</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="46" to="61" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Optimum laplacian wavelet mask based medical image using hybrid cuckoo search grey wolf optimization algorithm[J]. Knowledge-Based Systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Anitha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gnanaraj</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="58" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Load frequency control of interconnected power system using grey wolf optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P K</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="97" to="115" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Binary gray wolf optimization approaches for feature selection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Emary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Zawbaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassanien</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="371" to="381" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Grey wolf optimization based sense and avoid algorithm in a Bayesian framework for multiple UAV path planning in an uncertain environment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Radmanesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sarim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aerospace Science and Technology</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="168" to="179" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Inspired grey wolf optimizer for solving large-scale function optimization problems[J]</title>
		<author>
			<persName><forename type="first">W</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematical Modelling</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="112" to="126" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An astrophysics-inspired grey wolf algorithm for numerical optimization and its application to engineering design problems [J]</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="231" to="254" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An exploration-enhanced grey wolf optimizer to solve high-dimensional numerical optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="63" to="80" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Reinforcement learning in robotics: A survey[J]</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kober</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1238" to="1274" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A survey of actor-critic reinforcement learning: standard and natural policy gradients[J]</title>
		<author>
			<persName><forename type="first">I</forename><surname>Grondman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Busoniu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lopes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems Man &amp; Cybernetics Part C</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1291" to="1307" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Optimal and autonomous control using reinforcement learning: a survey[J]</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kiumarsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Vamvoudakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Modares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2042" to="2062" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to predict by the methods of temporal differences</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="9" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A deterministic improved Q-learning for path planning of a mobile robot[J]</title>
		<author>
			<persName><forename type="first">A</forename><surname>Konar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I G</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S J</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics: Systems</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1141" to="1153" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">UGV navigation optimization aided by reinforcement learning-based path tracking [J]</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE ACCESS</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="57814" to="57825" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Path planning of multi-agent systems in unknown environment with neural kernel smoothing and reinforcement learning[J]</title>
		<author>
			<persName><forename type="first">D L</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><forename type="middle">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">233</biblScope>
			<biblScope unit="page" from="34" to="42" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Adaptive low-level control of autonomous underwater vehicles using deep reinforcement learning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Carlucho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Paula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics &amp; Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="71" to="86" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Modified central force optimization (MCFO) algorithm for 3D UAV path planning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="page" from="878" to="888" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Adaptive particle swarm optimization[J]</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1362" to="1381" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A novel phase angle-encoded fruit fly optimization algorithm with mutation adaptation mechanism applied to UAV path planning</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="371" to="388" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Three-dimensional unmanned aerial vehicle path planning using modified wolf pack search algorithm</title>
		<author>
			<persName><forename type="first">Y B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y S</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J Q</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">266</biblScope>
			<biblScope unit="page" from="445" to="457" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Journal Pre-proof</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
