<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Inverse Halftoning Using Wavelets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zixiang</forename><surname>Xiong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">University of Hawaii</orgName>
								<address>
									<postCode>96822</postCode>
									<settlement>Honolulu</settlement>
									<region>HI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><forename type="middle">T</forename><surname>Orchard</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">University of Hawaii</orgName>
								<address>
									<postCode>96822</postCode>
									<settlement>Honolulu</settlement>
									<region>HI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kannan</forename><surname>Ramchandran</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">University of Hawaii</orgName>
								<address>
									<postCode>96822</postCode>
									<settlement>Honolulu</settlement>
									<region>HI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Prof</roleName><forename type="first">J</forename><forename type="middle">T</forename><surname>Mark</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<postCode>08544</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="middle">Z</forename><surname>Smith</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<postCode>08544</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Xiong</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<postCode>08544</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Inverse Halftoning Using Wavelets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">04FBE5BDBA071B2A2337B0C41468E828</idno>
					<note type="submission">received April 8, 1999; revised April 20, 1999.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T05:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Discrete wavelet transforms</term>
					<term>halftoning</term>
					<term>inverse halftoning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work introduces a new approach to inverse halftoning using nonorthogonal wavelets. The distinct features of this wavelet-based approach are: 1) edge information in the highpass wavelet images of a halftone image is extracted and used to assist inverse halftoning, 2) cross-scale correlations in the multiscale wavelet decomposition are used for removing background halftoning noise while preserving important edges in the wavelet lowpass image, and 3) experiments show that our simple wavelet-based approach outperforms the best results obtained from inverse halftoning methods published in the literature, which are iterative in nature.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Inverse halftoning addresses the problem of recovering a continuous-tone image from a halftoned binary image <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. Inverse halftoning has applications to image scaling, enhancement, facsimile image processing, and image compression <ref type="bibr" target="#b2">[3]</ref>. In the halftoning process <ref type="bibr" target="#b3">[4]</ref>, a continuous-tone image is rendered into a binary image for the purpose of display or printing. Although the inverse halftoning scheme presented here works with any halftoning process, this paper focuses on the most popular one: error diffusion. In error diffusion, the error between the continuous-tone input and binary output at each pixel is diffused over a causal neighborhood (or kernel). The simplest form of error diffusion kernel is the Floyd-Steinberg kernel <ref type="bibr" target="#b4">[5]</ref>.</p><p>Since the halftoning process is a many-to-one map, inverse halftoning is an ill-posed inverse problem with no unique solution. Iterative approaches (e.g., projection onto convex sets <ref type="bibr" target="#b5">[6]</ref>) have been studied for addressing the inverse problem by incorporating both spatial and frequency constraints <ref type="bibr" target="#b1">[2]</ref>. Assuming the error diffusion kernel is known a priori, the halftoned image itself provides an obvious spatial constraint, namely, that the recovered continuous-tone image should produce the given halftone image when it is error diffused. The frequency constraints, on the other hand, do not reflect known properties of the solution, but rather reasonable a priori assumptions about properties of images in general. Clearly, reconstruction quality depends heavily on the accuracy of these assumptions. A popular frequency constraint is to require inverse-halftoned images to be bandlimited <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. Algorithms based on lowpass frequency constraints recognize that the selection of bandwidth parameters plays a critical role in algorithm performance. Too much band limitation oversmooth edges, whereas too little band limitation results in noisy inverse-halftoned images. In the past, various lowpass filters have been used (e.g., halfband lowpass <ref type="bibr" target="#b0">[1]</ref>, Gaussian lowpass and optimal lowpass-based on singular value decomposition (SVD) <ref type="bibr" target="#b1">[2]</ref>).</p><p>A fundamental limitation of inverse halftoning algorithms based on global lowpass frequency constraints is that they are not able to extract useful highpass information from the halftoned image. Image edges consist of substantial highpass energy, and edges are often rendered reasonably well by good halftoning processes. Thus, global lowpass constraints ignore important highpass information embedded in the edges of the halftoned image. This work introduces a new approach to inverse halftoning using wavelets. <ref type="foot" target="#foot_0">1</ref> The wavelet representation offers a decomposition of the halftoned image that allows us to selectively choose appropriate information from all frequency bands (i.e., lowpass information in smooth regions augmented by highpass information around edges) for good inverse halftoning performance.</p><p>Our approach is motivated by recent results in signal denoising using wavelets <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, and we adopt a similar denoising perspective in developing our algorithm. A global frequency constraint assumes that wavelet coefficients of the signal (in our case, the desired image) decay exponentially with scale at some rate . Note: this corresponds to a Sobolev space signal model. Algorithms based on this assumption set some threshold beyond which coefficients are considered to be dominated by noise. In typical images, the vast majority of coefficients exhibit very fast decay rate in scale, while a few edge coefficients decay at a much slower rate (i.e., in any given band, the edge coefficients have much larger magnitudes). Thus, the Sobolev model is forced to choose between setting a low threshold that treats the fast decay coefficients properly at the cost of throwing away important edge coefficients, or setting a high threshold that preserves edge coefficients at the cost of including a large number of noisy coefficients with no significant energy. To address this problem, DeVore et al. <ref type="bibr" target="#b8">[9]</ref> have studied modeling signals as functions from Besov spaces, and have shown that wavelet bases have very natural and attractive properties for nonlinear approximation of functions in Besov spaces (they also allow the wavelet bases to be redundant, and give an example of wavelet approximation using overcomplete representations). Loosely speaking, a Besov space is the space of functions whose wavelet coefficients, ordered in decreasing order of magnitude, decay exponentially at some rate . The significance of the Besov model is that it characterizes a function by its N largest wavelet coefficients, in contrast with the Sobolev model which characterizes a function by its first (ordered in frequency) N coefficients. It can be shown that, for piecewise smooth functions with most coefficients decaying exponentially at some high rate , and a sufficiently small number of edge coefficients with much slower decay, the accuracy of the Besov approximation tracks the fast rate while the Sobolev approximation tracks the slow rate.</p><p>In denoising applications, if the signal is modeled as a function from a Besov space corrupted by Gaussian noise, an optimal reconstruction must both identify and estimate the N largest wavelet coefficients. It is significant that, unlike the signal, the Gaussian noise process does not generate isolated large coefficients among the highband coefficients. Thus, simple nonlinear strategies such as Donoho's <ref type="bibr" target="#b6">[7]</ref> thresholding scheme which identifies the N signal coefficients by selecting the largest coefficients give optimal reconstructions. Non-Gaussian noise (e.g., Cauchy) was also treated by Donoho <ref type="bibr" target="#b9">[10]</ref> using nonlinear multiresolutional analysis within his thresholding-based denoising framework.</p><p>In the case of halftoning noise, various local noise phenomena (e.g., false contouring, error diffusion oscillations, etc.) may also be responsible for isolated large energy highband coefficients. Thus, unlike the case of Gaussian noise, it may be wrong to conclude that isolated high energy highband coefficients must reflect signal components. Nevertheless, in this work we assume that good halftoning methods are successful at eliminating localized energy concentrations in regions where the signal is smooth, thus allowing us to assume that the largest isolated highband coefficients are due to signal components. While it is true that halftoning noise will also contribute localized energy concentration at image edges, these corrupt the signal components but should not cause us to miss or falsely identify the important coefficients. We are thus motivated to conjecture that wavelet-based denoising methods should be effective for inverse halftoning, though it may not be possible to prove the same optimality properties as in standard denoising settings.</p><p>Our proposed inverse halftoning algorithm is based on the overcomplete nonorthogonal wavelets introduced in <ref type="bibr" target="#b10">[11]</ref>. It adopts a frequency adaptive approach and demonstrates some noteworthy differences from previous algorithms. Another wavelet-based unscreening approach was taken by Luo et al. in <ref type="bibr" target="#b11">[12]</ref>, in which a critically sampled wavelet representation was used. The overcomplete image representation provided by the nonorthogonal wavelets in <ref type="bibr" target="#b10">[11]</ref> has certain advantages over a critically sampled wavelet representation for our problem of inverse halftoning. It characterizes an image by the local maxima of its wavelet transform modulus, and finding these local maxima is equivalent to the Canny edge detector <ref type="bibr" target="#b12">[13]</ref>. We will implicitly make use of this property when addressing noise removal of the lowpass wavelet image in Section III-B.</p><p>Our new inverse halftoning algorithm begins by applying a nonorthogonal, overcomplete wavelet transform to a given halftone image <ref type="bibr" target="#b13">[14]</ref>. The highpass wavelet images will be dominated by halftoning blue noise, whose power increases with respect to frequency <ref type="bibr" target="#b3">[4]</ref>. Any good inverse halftoning algorithm must eliminate this noise. However, conventional strategies of lowpass filtering <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref> (i.e., throwing away the highpass images) remove important edge information, and the soft thresholding scheme described in <ref type="bibr" target="#b6">[7]</ref> will not work well in this case either because the halftoning noise is not Gaussian. We take a novel lowpass approach to extract useful edge information in the highpass images while suppressing the blue noise, providing a significant performance boost for our inverse halftoning algorithm.</p><p>For intermediate highpass bands of the wavelet decomposition, we propose an explicit edge extraction algorithm based on crossscale correlations, and we use the resulting edges to perform spatially varying filtering of these images. This approach adaptively removes background halftoning noise while preserving important edge information in the bandpass bands.</p><p>Our proposed inverse halftoning approach is universal in the sense that no a priori knowledge about the halftoning process is assumed, yet the remarkable feature of this simple algorithm is that it outperforms the best results obtained from iterative methods in <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b1">[2]</ref>. When the a priori information of the error diffusion kernel is available, our inverse halftoning algorithm can take advantage of it, and achieve better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DISCRETE DYADIC WAVELET TRANSFORM</head><p>We describe the discrete dyadic wavelet transform from a signal processing point of view, referring the reader to <ref type="bibr" target="#b10">[11]</ref> for more mathematical details. Assume f (n) is a one-dimensional (1-D) discrete sequence of length N . The first stage of the dyadic wavelet transform decomposes f (n) into a lowpass sequence S 1 f (n) and a highpass sequence W 1 f (n) by passing f (n) through a lowpass filter h(n) and a highpass filter g(n) as shown in Fig. <ref type="figure" target="#fig_0">1(a)</ref>; the original sequence f (n) can be recovered from S 1 f(n) and W 1 f (n) (both  are of length N ) by using them as inputs to the system of Fig. <ref type="figure" target="#fig_0">1(b)</ref>, where h(0n) and k(n) are the reconstructing lowpass and highpass filters, respectively. The filters h(n), g(n), and k(n) are designed so that the perfect reconstruction condition jH(!)j<ref type="foot" target="#foot_1">2</ref> + G(!)K(!) = 1 is satisfied. These filters are connected with wavelet bases via the following three frequency domain relationships:</p><formula xml:id="formula_0">8(2!) = e 0j(!=2) H(!)8(!); (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9(2!) = e 0j(!=2) G(!)8(!);</head><p>(2) 0(2!) = e j(!=2) K(!)8(!)</p><formula xml:id="formula_1">(3)</formula><p>where (x) is the smoothing function, (x) the analysis wavelet, and (x) the synthesis wavelet. The filters we use are given in <ref type="bibr" target="#b10">[11]</ref>, the corresponding wavelet (x) is the derivative of a cubic spline which is close to a Gaussian function. To generate a multiscale discrete dyadic wavelet transform, we repeat the system of Fig. <ref type="figure" target="#fig_0">1</ref> on the lowpass sequences. All filters used at scale s(s &gt; 0) are upsampled by a factor of 2 s compared with those at scale zero.</p><p>It is straightforward to generalize the discrete dyadic wavelet transform from 1-D sequences to two-dimensional (2-D) images. Assume f (m; n) is an image of size M 2 N . At each scale s, with s &gt; 0 and S 0 f = f (m; n), the wavelet transform decomposes S s01 f into a lowpass image S s f, a horizontal highpass image W H s f and a vertical highpass image W V s f , from which the Ss01f can be reconstructed by the inverse wavelet transform. 2 Note that all three wavelet images S s f, W H s f , and W V s f at scale s are of size M 2N, which is the same as Ss01f.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. INVERSE HALFTONING USING WAVELETS</head><p>Let the given halftone image be f (m; n). Conventional lowpass techniques in inverse halftoning only use lowpass information (i.e., S 1 f) of f (m; n) <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. In our new wavelet approach, we use information of the wavelet representation of f (m; n) in all frequency bands. The block diagram of the proposed wavelet-based inverse halftoning scheme is shown in Fig. <ref type="figure" target="#fig_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Edge Extraction from Highpass Wavelet Images</head><p>In our wavelet approach, useful edge information can be extracted from highpass wavelet images W H 1 f and W V 1 f to assist inverse halftoning. We use a simple Gaussian lowpass filter to extract horizontal edges from W V 1 f and vertical edges from W H 1 f. Once this edge information is combined with the lowpass halftone image via the inverse wavelet transform, we get an inverse-halftoned image of much higher quality. The Gaussian filter takes the form of h(m; n) = ke 0((m +n )=2 ) , for 03 m; n 3, where k is a scaling factor so that the DC gain of the filter is one. 2 controls the frequency response of the Gaussian filter, which in turn determines the amount of useful edge information to be extracted. In our experiments, we choose 2 = 2 for all images as it gives the best inverse halftoning performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Edge-Preserving Noise Removal of the Lowpass Wavelet Image</head><p>After the first wavelet lowpass operation, some halftoning patterns are still visible in smooth regions of S 1 f. This is due to noise introduced in the lowpass band during the halftoning process. To remove the halftoning noise in S 1 f and at the same time protect important edges in its nonsmooth regions, we exploit cross-scale correlations among W O s f's (s = 2; 3; O 2 fH; V g) (see Fig. <ref type="figure" target="#fig_2">3</ref>) offered by the multiscale wavelet transform edge extraction <ref type="bibr" target="#b14">[15]</ref>. Locations with cross-scale correlation above a certain threshold are identified as edges, while low cross-scale correlation regions are treated as background, and noise in these regions are suppressed.</p><p>Two edge maps (one vertical, and another horizontal) are generated by directly multiplying cross-scale highpass wavelet coefficients as follows:</p><formula xml:id="formula_2">E H (m; n) = W H 2 f(m; n)W H 3 f(m; n); (4) E V (m; n) = W V 2 f(m; n)W V 3 f(m; n) (5)</formula><p>for 0 m M 0 1 and 0 n N 0 1. Finally, edge extraction is done by thresholding the sum of the two edge maps: E H and E V .</p><p>That is</p><formula xml:id="formula_3">E(m; n) = 1; if E H (m; n) + E V (m; n) &gt; T, 0; otherwise (<label>6</label></formula><formula xml:id="formula_4">)</formula><p>where E(m; n) = 1 means S 1 f(m; n) is an edge pixel, while E(m; n) = 0 means S1f(m; n) belongs to a background region.</p><p>The purpose of merging two directional edge maps into one is for better extraction of diagonal edges <ref type="bibr" target="#b15">[16]</ref>. The actual noise removal from S1f is carried out by setting</p><formula xml:id="formula_5">W H 2 f(m; n) = W V 2 f(m; n) = 0; if E(m; n) = 0: (7)</formula><p>This noise removal process from S1f is depicted in Fig. <ref type="figure" target="#fig_3">4</ref>. It certainly depends on the threshold T in ( <ref type="formula" target="#formula_3">6</ref>), but the overall inverse halftoning performance is not too sensitive to T . We experimentally determine the best value of T for inverse halftoning. For the results reported in the next section, T is set to be 60.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head><p>We experimented on the standard 512 2 512 Lena and peppers images. Fig. <ref type="figure" target="#fig_5">6</ref>(a) shows the halftoned Lena and peppers images using the Floyd-Steinberg error diffusion <ref type="bibr" target="#b4">[5]</ref>. PSNR between the original continuous-tone image and the inverse-halftoned image is used as the performance measure. For the sake of judging the visual quality, all images (in GIF format) related to the paper are available at http://spectra.eng.hawaii.edu˜/zx/paper/halftone.html.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Comparisons of Lowpass Filters</head><p>We first compare the performance of the wavelet lowpass filter with other filters that were previously used in inverse halftoning, namely, the 9 2 9 Gaussian filter <ref type="bibr" target="#b1">[2]</ref> and the halfband lowpass filter <ref type="bibr" target="#b0">[1]</ref>.</p><p>The error diffused Lena and peppers images are processed by using different lowpass filters, and PSNR numbers between the resulting images and the original continuous-tone Lena and peppers are shown in Table <ref type="table" target="#tab_0">I</ref>, which indicate that the wavelet lowpass filter is superior to others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Blind Inverse Halftoning Using Wavelets</head><p>Our inverse halftoning algorithm uses edge extraction for noise removal from the wavelet lowpass image and the useful information from the highpass images. The reconstructed Lena and peppers images obtained from our inverse halftoning algorithm are shown in Fig. <ref type="figure" target="#fig_5">6(b)</ref>. The PSNR's with respect to the original continuous-tone images are 31.50 dB for Lena and 30.43 dB for peppers, respectively. These PSNR's are higher that the best results obtained by the iterative method using halfband lowpass filtering and statistical smoothing in <ref type="bibr" target="#b0">[1]</ref> (see Table <ref type="table" target="#tab_1">II</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Inverse Halftoning Using Wavelets Assuming the Error Diffusion Kernel Is Known</head><p>Note that the above inverse halftoning results are obtained without using any a priori knowledge of the error diffusion kernel. If the error diffusion kernel is known, we can use this extra information and achieve better inverse halftoning performance. We first apply a MAP projection operator as used in <ref type="bibr" target="#b0">[1]</ref> to the continuous-tone image after blind inverse halftoning. Using information about the error diffusion kernel, the MAP projector makes minimum adjustment at the pixel level of the continuous-tone image so that the resulting image, once error diffused, gives the same original halftone image. The MAP projector is followed by a similar statistical smoothing operator as used in <ref type="bibr" target="#b0">[1]</ref> to give a final smooth continuous-tone image, as shown in Fig. <ref type="figure" target="#fig_4">5</ref>. The statistical smoothing operator is a nonlinear process that intends to "smooth out" the spiky noise introduced to the image background by the MAP projector. The inverse halftoning results after one MAP projection and smooth operation are given in Table <ref type="table" target="#tab_2">III</ref>, from which we see that using the kernel information gives about 0.2 dB gain over blind inverse halftoning. Finally, comparing Table <ref type="table" target="#tab_1">II</ref> and III, we see that, for the peppers image, even without knowing the error diffusion kernel, our wavelet-based inverse halftoning algorithm outperforms the best result achievably by the iterative method of <ref type="bibr" target="#b0">[1]</ref> which has access to the kernel information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS</head><p>In this work, we have introduced a new approach to inverse halftoning using nonorthogonal wavelets. It represents an improvement over the state-of-the-art of inverse halftoning. Although theoretical work in <ref type="bibr" target="#b6">[7]</ref> and <ref type="bibr" target="#b8">[9]</ref> indicates that wavelets play a fundamental role in inverse halftoning, the better performance of our wavelet-based approach is the real proof. Since we do not claim optimality in our proposed algorithm, future research directions include finding the best threshold T and new inverse halftoning approaches based on nonlinear multiresolutional analysis <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compression of Complex-Valued SAR Images</head><p>Paul Eichel and Robert W. Ives Abstract-Synthetic aperture radars (SAR) are coherent imaging systems that produce complex-valued images of the ground. Because modern systems can generate large amounts of data, there is substantial interest in applying image compression techniques to these products. In this work, we examine the properties of complex-valued SAR images relevant to the task of data compression. We advocate the use of transformbased compression methods but employ radically different quantization strategies than those commonly used for incoherent optical images. The theory, methodology, and examples are presented. Index Terms-Coherent imaging, complex-valued images, compression, quantization, SAR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION: COMPLEX SAR IMAGERY</head><p>A synthetic aperture radar (SAR) is an active, high-resolution, and coherent microwave imaging system with diverse applications in remote sensing <ref type="bibr" target="#b0">[1]</ref>. Modern systems are capable of very high area rates and real-time processing. Coupled with the high spatial resolution, these qualities ensure that the bandwidth requirements for transmission and storage of such data can be daunting. Data compression is a natural consideration for such systems.</p><p>Owing to their coherent nature, SAR images exhibit three attributes that set them apart from the incoherent, optical images to which compression algorithms are commonly applied. That is, they are complex, with phase as well as magnitude, they possess very high dynamic range, and they exhibit very little spatial correlation.</p><p>SAR images are fundamentally complex valued. A coherent illuminator, receiver, and image formation processor produce them. Historically, the phase components of SAR images have been discarded, a viewable image generally being produced from the magnitude information only. More recently, several powerful new techniques relying on the full complex nature of the imagery have come to the fore, including autofocus and interferometry <ref type="bibr" target="#b1">[2]</ref>. While it might be possible to separately compress the magnitude and phase components of such images, we will shortly show that some special properties of the original complex values can be fruitfully exploited for compression.</p><p>The high dynamic range of SAR images is also attributable to the coherent nature of the imaging process. Within a resolution cell of an image, the transduced image domain value is related to the radar cross section per unit area of the corresponding patch of illuminated terrain <ref type="bibr" target="#b2">[3]</ref>. This specific cross section can vary over a considerable range. Most natural terrain, being rough relative to the wavelengths employed, exhibit relatively low values of this parameter, in the vicinity of 015 dBsm/m </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Discrete dyadic wavelet transform. (a) First stage of the dyadic wavelet transform decomposes f (n) into sequences S 1 f (n) and W 1 f (n). (b) S 1 f (n) and W 1 f (n) are filtered and summed to reconstruct the original sequence f (n).</figDesc><graphic coords="2,307.20,59.58,248.88,52.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Block diagram of the proposed wavelet-based inverse halftoning scheme.</figDesc><graphic coords="2,307.20,173.70,248.88,91.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Multiscale discrete dyadic wavelet transform.</figDesc><graphic coords="3,77.94,59.58,181.20,76.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Edge-preserving noise removal of the lowpass wavelet image S 1 f.</figDesc><graphic coords="3,317.76,59.58,227.76,68.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Inverse halftoning using information about the error diffusion kernel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. (a) Error-diffused Lena and peppers images using Floyd-Steinberg kernel. (b) Reconstructed images using our proposed blind inverse halftoning algorithm. PSNR's with respect to the original continuous-tone images are 31.50 dB for Lena, and 30.43 dB for peppers, respectively.</figDesc><graphic coords="4,116.28,262.13,367.53,182.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I PERFORMANCE</head><label>I</label><figDesc>COMPARISON OF DIFFERENT LOWPASS FILTERS FOR THE PEPPERS IMAGE</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II COMPARISONS</head><label>II</label><figDesc>OF INVERSE HALFTONING PERFORMANCES, ASSUMING THE ERROR DIFFUSION KERNEL IS UNKNOWN</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III COMPARISION</head><label>III</label><figDesc>OF INVERSE HALFTONING PERFORMANCES, ASSUMING THE ERROR DIFFUSION KERNEL IS KNOWN</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>2 ;</head><label>2</label><figDesc>for example. Flat, smooth surfaces such Manuscript received August 28, 1997; revised March 16, 1999. This work was supported by the Defense Advanced Research Projects Agency for the Intelligent Bandwidth Compression Program. Sandia is a multiprogram laboratory operated by Sandia Corporation, a Lockheed Martin Company, for the United States Department of Energy under Contract DE-AC04-94AL85000. This work was performed at Sandia National Laboratories. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Mita Desai. P. Eichel is with Sandia National Laboratories, Albuquerque, NM 87185-1207 USA (e-mail: pheiche@sandia.gov). R. W. Ives is with the Naval Postgraduate School, Monterey, CA 93943-5121 USA (e-mail: rwives@monterey.nps.navy.mil) Publisher Item Identifier S 1057-7149(99)07559-4.</figDesc><table /><note><p>1057-7149/99$10.00 © 1999 IEEE</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In this work, we adopt the convention that we mean the use of discrete wavelet transforms whenever we mention the use of wavelets.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We omit the 2-D indices (m; n) in Ss f , W H s f , W Vs f , and S s01 f for the sake of notational simplicity.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>Z. Xiong would like to thank Dr. R. de Queiroz of Xerox Corporation for interesting discussions on inverse halftoning, and Dr. P. Wong from Hewlet Packard Laboratories for providing the original Lena and peppers images.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the ARO under Grant DAAH04-96-1-0227.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Inverse halftoning and kernel estimation for error diffusion</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="486" to="498" />
			<date type="published" when="1995-04">Apr. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Halftone to continuous-tone conversion of error-diffusion coded images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zakhor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="208" to="216" />
			<date type="published" when="1995-02">Feb. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Error-diffused image compression using a binary-to-gray-scale decoder and predictive pruned tree-structured vector quantization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Riskin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="854" to="857" />
			<date type="published" when="1994-11">Nov. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Ulichney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Digital</forename><surname>Halftoning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An adaptive algorithm for spatial grey scale</title>
		<author>
			<persName><forename type="first">R</forename><surname>Floyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Steinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SID Int. Symp</title>
		<imprint>
			<date type="published" when="1975">1975</date>
			<biblScope unit="page" from="36" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image restoration by the method of convex projections-Part I: Theory</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Youla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Webb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="81" to="94" />
			<date type="published" when="1982-10">Oct. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Denoising by soft-thresholding</title>
		<author>
			<persName><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="613" to="627" />
			<date type="published" when="1995-05">May 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Noise reduction using an undecimated discrete wavelet transform</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Lett</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="10" to="13" />
			<date type="published" when="1996-01">Jan. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Image compression through wavelet transform coding</title>
		<author>
			<persName><forename type="first">R</forename><surname>Devore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jawarth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lucier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="719" to="746" />
			<date type="published" when="1992-03">Mar. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Nonlinear wavelet methods for recovering signals, images, and densities from indirect and noisy data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993-07">July 1993</date>
			<pubPlace>Stanford, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Stanford Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. 437</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Characterization of signals from multiscale edges</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="710" to="732" />
			<date type="published" when="1992-07">July 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A robust technique for image descreening based on the wavelet transform</title>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>De Queiroz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1179" to="1184" />
			<date type="published" when="1998-04">April 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A computational approach to edge detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="679" to="698" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Inverse halftoning using wavelets</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Orchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICIP&apos;96</title>
		<meeting>ICIP&apos;96<address><addrLine>Lausanne, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-09">Sept. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Wavelet transform domain filters: A spatially selective noise filtration technique</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jr</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="747" to="758" />
			<date type="published" when="1994-11">Nov. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note>personal communication</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
