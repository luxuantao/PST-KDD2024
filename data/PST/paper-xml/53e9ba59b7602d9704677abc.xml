<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Heuristic for Domain Independent Planning and Its Use in an Enforced Hill-Climbing Algorithm</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jörg</forename><surname>Hoffmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Computer Science</orgName>
								<orgName type="institution">Albert Ludwigs University</orgName>
								<address>
									<addrLine>Am Flughafen 17</addrLine>
									<postCode>79110</postCode>
									<settlement>Freiburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Heuristic for Domain Independent Planning and Its Use in an Enforced Hill-Climbing Algorithm</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A1529F8CB8B0A872C774A4A9426278AE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a new heuristic method to evaluate planning states, which is based on solving a relaxation of the planning problem. The solutions to the relaxed problem give a good estimate for the length of a real solution, and they can also be used to guide action selection during planning. Using these informations, we employ a search strategy that combines Hill-climbing with systematic search. The algorithm is complete on what we call deadlock-free domains. Though it does not guarantee the solution plans to be optimal, it does find close to optimal plans in most cases. Often, it solves the problems almost without any search at all. In particular, it outperforms all state-of-the-art planners on a large range of domains.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The standard approach to obtain a heuristic is to relax the problem P at hand into some easier problem P . The optimal solution length to a situation in P can then be used as an admissible estimate for the optimal solution length of the same situation in P. An application of this idea to domain independent planning was first used in the HSP system <ref type="bibr" target="#b2">[3]</ref>. The planning problem P is relaxed by simply ignoring the delete lists of all operators. However, computing the optimal solution length for a planning problem without delete lists is still NP-hard, as was first shown by Bylander <ref type="bibr" target="#b3">[4]</ref>. Therefore, the HSP heuristic is only a rough estimate of the optimal relaxed solution length. In short, it is obtained by summing up the minimal distances of all atomic goals.</p><p>In this paper, we go one step further. We introduce a method that computes some, not necessarily optimal, solution to the relaxed problem. These solutions are helpful in two ways:</p><p>-their length provides an informative estimate for the difficulty of a situation; -one can use them as a guidance for action selection.</p><p>The solution length estimates are used to control a local search strategy similar to Hill-climbing, which is combined with systematic breadth first search in order to escape local minima or plateaus. The guidance information is employed to cut down the branching factor during systematic search. The method shows good behavior over all domains that are commonly used in the planning community. In particular, we will see that it is complete on the class of problems we call deadlock-free. Performing local search, the method can not guarantee its solution plans to be optimal. In spite of this, it finds close to optimal plans in most cases. As a benefit from the severe restriction of its search space, it shows very competitive runtime behavior. For example, logistics problems are solved faster than by any other domain independent planning system known to the author at the time of writing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Throughout the paper, we consider simple STRIPS domains. We briefly review two standard notations. An action o has the form o = pre(o) ⇒ add(o), del <ref type="bibr">(o)</ref> where pre(o), add(o) and del(o) are sets of ground facts. Plans P are sequences P = o 1 , . . . , o n of actions, i.e., we consider only linear plans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Heuristic</head><p>In this section, we introduce a method for heuristically evaluating planning states S. Basically, the method consists of two parts.</p><p>1. First, the relaxed fixpoint is built on S. This is a forward chaining process that determines in how many steps, at best, a fact can be reached from S, and with which actions. 2. Then, a relaxed solution is extracted from the fixpoint. This is a sequence of parallel action sets that achieves the goal from S, if their delete effects are ignored.</p><p>The first part corresponds directly to the heuristic method that is used in HSP <ref type="bibr" target="#b2">[3]</ref>.</p><p>The second part goes one step further: while in HSP, the heuristic is extracted as a side effect of the fixpoint, we invest some extra effort to find a relaxed plan, and use the plan to determine our heuristic value. The fixpoint process is depicted in Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>The algorithm can be seen as building a layered graph structure, where fact and action layers are interleaved in an alternating fashion. The process starts with the initial fact layer, which are the facts that are true in S. Then, the first action layer comprises the actions whose preconditions are contained in S. The effects of these actions lead us to the second fact layer, which, in turn, determines the next action layer and so on. The process terminates, and remembers the number max of the last layer, if all goals are reached or if the new fact layer is identical to the last one.</p><formula xml:id="formula_0">F 0 := S k := 0 while G ⊆ F k do O k := {o ∈ O | pre(o) ⊆ F k } F k+1 := F k ∪ o ∈ O k add(o) if F k+1 = F k then break endif k := k + 1 endwhile max := k</formula><p>The crucial information that the fixpoint process gives us are the levels of all facts and actions. These are defined as the number of the first fact-or action layer they are members of.</p><formula xml:id="formula_1">level(f ) := min{i | f ∈ Fi} ex. i : f ∈ Fi ∞ otherwise level(o) := min{i | o ∈ Oi} ex. i : o ∈ Oi ∞ otherwise</formula><p>We now show how to extract a relaxed plan from the fixpoint structure. This is done in a backward chaining manner, where we simply use any action with minimal level to make a goal true. The exact algorithm is depicted in Figure <ref type="figure">2</ref>. Note that we do not need to search, we can proceed right away to the initial state and are guaranteed to find a solution.</p><p>Before plan extraction starts, an array of goal sets G i is initialized by inserting all goals with corresponding level. The mechanism then proceeds down from layer max to layer 1, and selects an action o for each goal g at the current layer i, incrementing the plan length counter h. No actions are selected for goals that are marked true at the time being, as they are already added. The achiever o is required to have level(o) = i -1. This is minimal as the goal g has level i, i.e., the first action that achieved g in the fixpoint came in at level i -1. The preconditions of o are inserted as new goals into their corresponding goal sets. If the current layer is i, then the levels of o's preconditions are at most i -1, so these new goals will be made true later during the process.</p><formula xml:id="formula_2">for i := 1, . . . , max do G i := {g ∈ G | level(g) = i} endfor h := 0 for i := max, . . . , 1 do for all g ∈ G i, g not true at i do select o with g ∈ add(o) such that level(o) = i -1 h := h + 1 for all f ∈ pre(o), f not true at i -1 do G level(f) := G level(f) ∪ {f } endfor for all f ∈ add(o) do</formula><p>mark f as true at i -1 and i endfor endfor endfor Fig. <ref type="figure">2</ref>. The algorithm that extracts a relaxed solution to a state S after the fixpoint has been built.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Goal Distance</head><p>To obtain the heuristic goal distance value h(S) of a given planning state S, we now simply chain the two algorithms together. First, we perform the fixpoint computation from Figure <ref type="figure" target="#fig_0">1</ref>. If the process terminates without reaching the goals, we set h(S) := ∞. Otherwise, we extract a relaxed plan, Figure <ref type="figure">2</ref>, and use the plan length for evaluation, i.e., h(S) := h.</p><p>The overall structure of the relaxed planning process is quite similar to planning with planning graphs <ref type="bibr" target="#b0">[1]</ref>. It amounts to a very special case, as no negative interactions at all occur between facts or actions in the relaxed problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Helpful Actions</head><p>We can also use the extracted plan to determine a set of actions that seem to be helpful in reaching the goal. To do this, we turn our look on the actions that are contained in the first time step of the relaxed solution, i.e., the actions that are selected at level 0. These are often the actions that are useful in the given situation. Let us see a simple example for that, taken from the gripper domain, as it was used in the 1998 AIPS planning systems competition. We do not repeat the exact definition of the domain here, as it is easily understood intuitively. There are two rooms, A and B, and a certain number of balls, which shall be moved from room A to room B. The planner changes rooms via the move operator, and controls two grippers which can pick or drop balls. Each gripper can only hold one ball at a time. We look at a small problem where 2 balls must be moved into room B. A relaxed solution to the initial state that our heuristic might extract is</p><formula xml:id="formula_3">&lt; { pick ball1 A left, pick ball2 A left, move A B }, { drop ball1 B left, drop ball2 B left } &gt;</formula><p>This is a parallel relaxed plan consisting of two time steps. Note that the move A B action is selected parallel to the pick actions, as the relaxed planner does not notice that it can not pick balls in room A anymore once it has moved into room B. In a similar fashion, both balls are picked with the left gripper. Nevertheless, two of the three actions in the first step are helpful in the given situation: both pick actions are starting actions of an optimal sequential solution. Thus, one might be tempted to define the set H(S) of helpful actions as only those that are contained in the first time step of the relaxed plan. However, this is too restrictive in some cases. We therefore define our set H(S) as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H(S)</head><formula xml:id="formula_4">:= {o ∈ O 0 | add(o) ∩ G 1 = ∅}</formula><p>After plan extraction, O 0 contains the actions that are applicable in S, and G 1 contains the facts that were goals or subgoals at level 1. Thus, we consider as helpful those actions which add at least one fact that was a (sub)goal at the lowest time step of our relaxed solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Search</head><p>We now introduce a search algorithm that makes effective use of the heuristics we defined in the last section. The key observation that leads us to the method is the following. On some domains, like the gripper problems from the 1998 competition and Russel's tyreworld, it is sufficient to use our heuristic in a naive Hill-climbing strategy. In these problems, one can simply start in the initial state, pick, in each state, a best valued successor, and ends up with an optimal solution plan. This strategy is very efficient on the problems where it finds plans. However, the naive method does not find plans on most problems. Usually, it runs into an infinite loop. To overcome this problem, one could employ standard Hill-climbing variations, like restarts, limited plateau moves, or a memory for repeated states. We use an enforced Hill-climbing method instead, see the definition in Figure <ref type="figure" target="#fig_1">3</ref>.</p><p>The algorithm combines Hill-climbing with systematic breadth first search. Like standard Hill-climbing, it picks some successor of the current state at each stage of the search. Unlike in standard Hill-Climbing, this successor does not need to be a direct one, and, unlike in standard Hill-Climbing, we do not pick any best valued successor, but enforce the successor to be one that is strictly better than our current state.</p><p>More precisely, at each stage during search a successor state is found by performing breadth first search starting out from the current state S. For each search state S , all successors are generated and evaluated heuristically. Doubly occuring states are pruned from the search by keeping a hashtable of past states in memory, and the search stops as soon as it has found a state S that has a lower heuristic value than S. This way, the Hill-climbing search escapes plateaus and local minima by simply performing exhaustive search for an exit, i.e., a state with strictly better heuristic evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Helpful Actions</head><p>So far, we have only used the goal distance heuristic. We integrate the helpful actions heuristic into our search algorithm as follows. During breadth first search, we do not generate all successors of any search state S anymore, but consider only those that are obtained by applying actions from H(S ). This way, the branching factor for the search is cut down. However, considering only the actions in H(S ) might make the search miss a goal state. If this happens, i.e., if the search can not reach any new states anymore when restricting the successors to H(S ), we simply switch back to complete breadth first search starting out from the current state S and generating all successors of search nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Completeness</head><p>The Enforced Hill-climbing algorithm is complete on deadlock-free planning problems. We define a deadlock to be a state S that is reachable from the initial state I, and from which the goal can not be reached anymore. A planning problem is called deadlock-free, if it does not contain any deadlock state. We remark that a deadlock-free problem is also solvable, cause otherwise the initial state itself would already be a deadlock.</p><p>Theorem 1. Let P be a planning problem. If P is deadlock-free, then the Enforced Hill-climbing algorithm, as defined in Figure <ref type="figure" target="#fig_1">3</ref>, will find a solution.</p><p>Due to space restrictions, we do not show the (easy) proof of Theorem 1 here and refer the reader to <ref type="bibr" target="#b4">[5]</ref>. In short, if the complete breadth first search starting from a state S can not reach a better evaluated state, then, in particular, it can not reach a goal state, which implies that the state S is a deadlock in contradiction to the assumption.</p><p>In <ref type="bibr" target="#b4">[5]</ref>, it is also shown that most of the currently used benchmark domains are in fact deadlock-free. Any solvable planning problem that is invertible in the sense that one can find, for each action sequence P , an action sequence P that undoes P 's effects, does not contain deadlocks. One can always go back to the initial state first and execute an arbitrary solution thereafter. Moreover, planning problems that contain an inverse action o to each action o are invertible: simply undo all actions in the sequence P by executing the corresponding inverse actions. Finally, most of the current benchmark domains do contain inverse actions. For example in the blocksworld, we have stack and unstack. Similarly in domains that deal with logistics problems, for example logistics, ferry, gripper etc., one can often find inverse pairs of actions. If an action is not invertible, its role in the domain is often quite limited. A nice example is the inflate operator in the tyreworld, which can be used to inflate a spare wheel. Obviously, there is not much point in defining something like a deflate operator. More formally speaking, the operator does not destroy a goal or a precondition of any other operator in the domain. In particular, it does not lead into deadlocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Empirical Results</head><p>For empirical evaluation, we implemented the Enforced Hill-climbing algorithm, using relaxed plans to evaluate states and to determine helpful actions, in C. We call the resulting planning system ff, which is short for fast-forward planning system. All running times for ff are measured on a Sparc Ultra 10 running at 350 MHz, with a main memory of 256 M Bytes. Where possible, i.e., for those planners that are publicly available, the running times of other planners were measured on the same machine. We indicate run times taken from the Literature in the text. All planners were run with the default parameters, unless otherwise stated in the text, and all benchmark problems are the standard examples taken from the Literature. Some benchmark problems have been modified in order to show how planners scale to bigger instances. We explain the modifications made, if any, in the text. Dashes indicate that the corresponding planner failed to solve that problem within half an hour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">The Logistics Domain</head><p>This is a classical domain, involving the transportation of packets via trucks and airplanes. There are two well known test suites. One has been used in the 1998 AIPS planning systems competition, the other one is part of the blackbox distribution. The problems in the competition suite are very hard. In fact, they are so hard that, up to date, no planner has been reported to solve them all.</p><p>fast-forward is the first one that does. See Figure <ref type="figure">4</ref>, showing also the results for GRT <ref type="bibr" target="#b11">[12]</ref> and HSP-r <ref type="bibr" target="#b1">[2]</ref>, which are-as far as the author knows-the two best other domain independent logistics planners at the time being. Fig. <ref type="figure">4</ref>. Results of the three domain independent planners best suited for logistics problems on the 1998 competition suite. Times are in seconds, steps counts the number of actions in a sequential plan. For HSP-r, the weighting factor W is set to 5, as was done in the experiments described by Bonet and Geffner in <ref type="bibr" target="#b1">[2]</ref>.</p><p>The times for GRT in Figure <ref type="figure">4</ref> are from the paper by Refanidis and Vlahavas <ref type="bibr" target="#b11">[12]</ref>, where they are measured on a Pentium 300 with 64 M Byte main memory.</p><p>ff outperforms both HSP-r and GRT by an order of magnitude. Also, it finds shorter plans than the other planners.</p><p>We also ran ff on the benchmark problems from the blackbox distribution suite, and it solved all of them in less than half a second. Compared to the results shown by Bonet and Geffner <ref type="bibr" target="#b1">[2]</ref> for these problems, ff was between 2 and 10 times faster than HSP-r, finding shorter plans in all cases. 1 It is important to distinct the results shown in Figure <ref type="figure">4</ref> from those reported earlier for HSP-r <ref type="bibr" target="#b1">[2]</ref>. Those results were taken on the problems from the blackbox distribution, while our results are taken on the 1998 competition test suite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Mixed Classical Problems</head><p>fast-forward shows competitive behavior on all commonly used benchmark domains. To exemplify this, we show a table of running times on a variety of different domains in Figure <ref type="figure" target="#fig_2">5</ref>, comparing ff against a collection of state-of-theart planning systems: IPP <ref type="bibr" target="#b7">[8]</ref>, STAN <ref type="bibr" target="#b8">[9]</ref>, blackbox <ref type="bibr" target="#b6">[7]</ref>, and HSP <ref type="bibr" target="#b2">[3]</ref>.  In Figure <ref type="figure" target="#fig_2">5</ref>, the planning problems shown are the following. The tyreworld problem was originally formulated by Russell, and asks the planner to replace a flat tire. The problem is modified in a natural way so as to make the planner replace n flat tires. ff is the only planner that is capable of replacing more than three tires, scaling up to much bigger problems.</p><formula xml:id="formula_5">IPP</formula><p>The hanoi problems make the planner solve the well known Towers of Hanoi problem, with n discs to be moved. ff also outperforms the other planners on these problems.</p><p>The sokoban problem encodes a small instance of a well known computer game, where a single stone must be pushed to its goal position. Although the problem contains deadlocks, ff has no difficulties in solving it.</p><p>The manhattan domain was first introduced by McDermott <ref type="bibr" target="#b9">[10]</ref>. In these problems, the planner controls a robot which moves on a n × n grid world, and has to deal with different kinds of keys and locks. The original problem taken from <ref type="bibr" target="#b9">[10]</ref> corresponds to the mh-11 entry in Tabular 5, where the robot moves on a 11 × 11 grid. The other entries refer to problems that have been modified to encode 7 × 7, 15 × 15 and 19 × 19 grid worlds, respectively. ff easily handles all of them, finding slightly suboptimal plans.</p><p>Finally, the blocksworld problems in Figure <ref type="figure" target="#fig_2">5</ref> are benchmark examples taken from <ref type="bibr" target="#b5">[6]</ref>. ff outperforms the other planners in terms of running time as well as in terms of solution length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>The closest relative to the work described in this paper is, quite obviously, the HSP system <ref type="bibr" target="#b2">[3]</ref>. In short, HSP does Hill-climbing search, with the heuristic function h(S) := g∈G weight S (g)</p><p>The weight of a fact with respect to a state S is, roughly speaking, the minimum over the sums of the precondition weights of all actions that achieve it. The weights are obtained as a side effect of doing exactly the same fixpoint computation as we do. The main problem in HSP is that the heuristic needs to be recomputed for each single search state, which is very time consuming. Inspired by HSP, a few approaches have been developed that try to cope with this problem, like HSP-r <ref type="bibr" target="#b1">[2]</ref> and the GRT-planner <ref type="bibr" target="#b11">[12]</ref>. The authors of HSP themselves handle the problem by sticking to their heuristic, but changing the search direction, going backwards from the goal in HSP-r instead of forward from the initial state in HSP. This way, they need to compute a weight value for each fact only once, and simply sum the weights up for a state later during search.</p><p>The authors of <ref type="bibr" target="#b11">[12]</ref> invert the direction of the HSP heuristic instead. While HSP computes distances by going towards the goal, GRT goes from the goal to each fact, and estimates its distance. The function that then extracts, for each state during forward search, the state's heuristic estimate, uses the pre-computed distances as well as some information on which facts will probably be achieved simultaneously.</p><p>For the fast-forward planning system, a somewhat paradoxical extension of HSP has been made. Instead of avoiding the major drawback of the HSP strategy, we even worsen it, at first sight: the heuristic keeps being fully recomputed for each search state, and we even put some extra effort on top of it, by extracting a relaxed solution. However, the overhead for extracting a relaxed solution is marginal, and the relaxed plans can be used to prune unpromising branches from the search tree.</p><p>To verify where the enormous run time advantages of ff compared to HSP come from, we ran HSP using Enforced Hill-climbing search with and without helpful actions pruning, as well as ff without helpful actions on the problems from our test suite. Due to space restrictions, we can not show our findings in detail here. It seems that the major steps forward are our variation of Hillclimbing search in contrast to the restart techniques employed in HSP, as well as the helpful actions heuristic, which prunes most of the search space on many problems. Our different heuristic distance estimates seem to result in shorter plans and slightly, about a factor two, better running times, when one compares ff to a version of HSP that uses Enforced Hill-climbing search and helpful actions pruning. We did not yet find the time to do these experiments the other way round, i.e., integrate our heuristic into the HSP search algorithm, as this would involve modifying the original HSP code, which means a lot of implementation work.</p><p>There has been at least one more approach in the Literature where goal distances are estimated by ignoring the delete lists of the operators. In <ref type="bibr" target="#b9">[10]</ref>, Greedy Regression-Match Graphs are introduced. In a nutshell, these estimate the goal distance of a state by backchaining from the goals until facts are reached that are true in the current state, and then counting the estimated minimal number of steps that are needed to achieve the goal state.</p><p>To the best of our understanding, the action chains that lead to a state's heuristic estimate in <ref type="bibr" target="#b9">[10]</ref> are similar to the relaxed plans that we extract. However, the backchaining process seems to be quite costly. For example, building the Greedy Regression-Match Graph for the initial state of the manhattan world 11 × 11 grid problem is reported to take 25 seconds on a Sparc 2 station. For comparison, we ran ff on a Sparc 4 station. Finding a relaxed plan for the initial state takes less than one hundredth of a second, i.e., the time measured is 0.00 CPU seconds.</p><p>The helpful actions heuristic shares some similarities with what is known as relevance from the literature <ref type="bibr" target="#b10">[11]</ref>. The main difference is that relevance in the usual sense refers to what is useful for solving the whole problem. Being helpful, on the other hand, refers to something that is useful in the next step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion and Outlook</head><p>In this paper, we presented two heuristics for domain independent STRIPS planning, one estimating the distance of a state to the goal, and one collecting a set of promising actions. Both are based on an extension of the heuristic that is used in the HSP system. We showed how these heuristics can be used in a variation of Hill-climbing search, and we have seen that the algorithm is complete on the class of deadlock-free domains. We collected empirical evidence that the resulting planning system is among the fastest planners in existence nowadays, outperforming the other state-of-the-art planners on quite a range of domains, like the logistics, manhattan and tyreworld problems.</p><p>To the author, the most exciting question is this: Why is the heuristic information obtained in this simple manner so good? It is not really difficult to construct abstract examples where the approach produces arbitrarily bad plans, or uses arbitrarily much time, so why does it almost never go wrong on the benchmark problems? Why is the relaxed solution always so close to a real solution, except for the Tower of Hanoi problems? Is it possible to define a notion of "simple" planning domains, where relaxed solutions have desirable properties?</p><p>First steps into that direction seem to indicate that, in fact, there might be some underlying theory in that sense. In particular, it can be proven that the Enforced Hill-climbing algorithm finds optimal solutions when the heuristic used is goal-directed in the following sense:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>h(S) &lt; h(S ) ⇒ min(S) &lt; min(S )</head><p>Here, min(S) denotes the length of the shortest possible path from state S to a goal state, i.e., Enforced Hill-climbing is optimal when heuristically better evaluated states are really closer to the goal. It can also be proven that the length of an optimal relaxed solution is, in fact, a goal-directed heuristic in the above sense on the problems from the gripper domain that was used in the 1998 planning systems competition. We have not yet, however, been able to identify some general structural property that implies goal-directedness of optimal relaxed solutions.</p><p>Apart from these theoretical investigations, we want to extend the algorithms to handle richer planning languages than STRIPS, in particular ADL and resource constrained problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Computing the relaxed fixpoint on a planning state S. O and G denote the action set and goal state of the problem at hand, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The Enforced Hill-climbing algorithm. I denotes the initial state of the problem to be solved.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Running times and quality (in terms of number of actions) of plans for ff and state-of-the-art planners on various classical domains. All planners are run with the default parameters, except HSP, where loop checking needs to be turned on.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1   </figDesc><table><row><cell></cell><cell>HSP-r</cell><cell></cell><cell>GRT</cell><cell></cell><cell>FF</cell><cell></cell></row><row><cell>problem</cell><cell cols="2">time steps</cell><cell cols="2">time steps</cell><cell cols="2">time steps</cell></row><row><cell>prob-01</cell><cell>0.36</cell><cell>35</cell><cell>0.28</cell><cell>30</cell><cell>0.06</cell><cell>27</cell></row><row><cell>prob-02</cell><cell>3.13</cell><cell>36</cell><cell>1.32</cell><cell>34</cell><cell>0.19</cell><cell>32</cell></row><row><cell>prob-03</cell><cell>25.45</cell><cell>64</cell><cell>5.55</cell><cell>60</cell><cell>0.71</cell><cell>54</cell></row><row><cell>prob-04</cell><cell>50.13</cell><cell>63</cell><cell>19.28</cell><cell>69</cell><cell>0.98</cell><cell>58</cell></row><row><cell>prob-05</cell><cell>0.62</cell><cell>27</cell><cell>0.39</cell><cell>26</cell><cell>0.08</cell><cell>22</cell></row><row><cell cols="2">prob-06 293.60</cell><cell>83</cell><cell>14.39</cell><cell>80</cell><cell>1.95</cell><cell>73</cell></row><row><cell>prob-07</cell><cell>6.20</cell><cell>37</cell><cell>1.76</cell><cell>37</cell><cell>0.38</cell><cell>36</cell></row><row><cell>prob-08</cell><cell>-</cell><cell>-</cell><cell>16.37</cell><cell>48</cell><cell>2.04</cell><cell>41</cell></row><row><cell cols="2">prob-09 371.03</cell><cell>97</cell><cell>50.48</cell><cell>98</cell><cell>2.08</cell><cell>91</cell></row><row><cell cols="2">prob-10 287.64</cell><cell>121</cell><cell>23.13</cell><cell>117</cell><cell>3.20</cell><cell>103</cell></row><row><cell>prob-11</cell><cell>4.58</cell><cell>34</cell><cell>1.54</cell><cell>36</cell><cell>0.21</cell><cell>30</cell></row><row><cell>prob-12</cell><cell>-</cell><cell>-</cell><cell>43.06</cell><cell>48</cell><cell>2.01</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Z.W. Raś and S. Ohsuga (Eds.): ISMIS 2000, LNAI 1932, pp. 216-227, 2000. c Springer-Verlag Berlin Heidelberg 2000</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. The author thanks Bernhard Nebel for helpful discussions and suggestions on designing the paper.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast planning through planning graph analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Furst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="279" to="298" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Planning as heuristic search: New results</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bonet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Geffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th European Conference on Planning</title>
		<meeting>the 5th European Conference on Planning</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="359" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A robust and fast action selection mechanism for planning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bonet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Loerincs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Geffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th National Conference of the American Association for Artificial Intelligence</title>
		<meeting>the 14th National Conference of the American Association for Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="714" to="719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The computational complexity of propositional STRIPS planning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bylander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="165" to="204" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A heuristic for domain independent planning and its use in a fast greedy planning algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technical Report</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Albert-Ludwigs-University Freiburg</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pushing the envelope: Planning, propositional logic, and stochastic search</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Selman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th National Conference of the American Association for Artificial Intelligence</title>
		<meeting>the 14th National Conference of the American Association for Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="1194" to="1201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unifying SAT-based and graph-based planning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Selman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 16th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="318" to="325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Extending planning graphs to an ADL subset</title>
		<author>
			<persName><forename type="first">J</forename><surname>Koehler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dimopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th European Conference on Planning</title>
		<meeting>the 4th European Conference on Planning</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="273" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient implementation of the plan graph in STAN</title>
		<author>
			<persName><forename type="first">D</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="87" to="115" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A heuristic estimator for means-ends analysis in planning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mcdermott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Artificial Intelligence Planning Systems</title>
		<meeting>the 3rd International Conference on Artificial Intelligence Planning Systems</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="142" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ignoring irrelevant facts and operators in plan generation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Nebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dimopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Koehler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th European Conference on Planning</title>
		<meeting>the 4th European Conference on Planning</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="338" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">GRT: A domain independent heuristic for strips worlds based on greedy regression tables</title>
		<author>
			<persName><forename type="first">I</forename><surname>Refanidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Vlahavas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th European Conference on Planning</title>
		<meeting>the 5th European Conference on Planning</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="346" to="358" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
