<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Writer Identification Using GMM Supervectors and Exemplar-SVMs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2016-10-08">October 8, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Vincent</forename><surname>Christlein</surname></persName>
							<email>vincent.christlein@fau.de</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Pattern Recognition Lab</orgName>
								<orgName type="institution">Friedrich-Alexander-Universität Erlangen-Nürnberg</orgName>
								<address>
									<addrLine>Martensstr. 3</addrLine>
									<postCode>91058</postCode>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Bernecker</surname></persName>
							<email>david.bernecker@fau.de</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Pattern Recognition Lab</orgName>
								<orgName type="institution">Friedrich-Alexander-Universität Erlangen-Nürnberg</orgName>
								<address>
									<addrLine>Martensstr. 3</addrLine>
									<postCode>91058</postCode>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Florian</forename><surname>Hönig</surname></persName>
							<email>florian.hoenig@fau.de</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Pattern Recognition Lab</orgName>
								<orgName type="institution">Friedrich-Alexander-Universität Erlangen-Nürnberg</orgName>
								<address>
									<addrLine>Martensstr. 3</addrLine>
									<postCode>91058</postCode>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andreas</forename><surname>Maier</surname></persName>
							<email>andreas.maier@fau.de</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Pattern Recognition Lab</orgName>
								<orgName type="institution">Friedrich-Alexander-Universität Erlangen-Nürnberg</orgName>
								<address>
									<addrLine>Martensstr. 3</addrLine>
									<postCode>91058</postCode>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elli</forename><surname>Angelopoulou</surname></persName>
							<email>elli.angelopoulou@fau.de</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Pattern Recognition Lab</orgName>
								<orgName type="institution">Friedrich-Alexander-Universität Erlangen-Nürnberg</orgName>
								<address>
									<addrLine>Martensstr. 3</addrLine>
									<postCode>91058</postCode>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Writer Identification Using GMM Supervectors and Exemplar-SVMs</orgName>
								<address>
									<settlement>Pattern Recognition</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Writer Identification Using GMM Supervectors and Exemplar-SVMs</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-10-08">October 8, 2016</date>
						</imprint>
					</monogr>
					<idno type="MD5">079257EBA405A1A2BDC59D123CB9D2D4</idno>
					<idno type="DOI">10.1016/j.patcog.2016.10.005</idno>
					<note type="submission">Received date: 18 August 2015 Revised date: 5 June 2016 Accepted date: 5 October 2016 Preprint submitted to Journal of Pattern Recognition</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pattern Recognition Writer identification</term>
					<term>GMM supervectors</term>
					<term>Exemplar-SVM</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes a method for robust offline writer identification. We propose to use RootSIFT descriptors computed densely at the script contours. GMM supervectors are used as encoding method to describe the characteristic handwriting of an individual scribe. GMM supervectors are created by adapting a background model to the distribution of local feature descriptors. Finally, we propose to use Exemplar-SVMs to train a document-specific similarity measure. We evaluate the method on three publicly available datasets (ICDAR / CVL / KHATT) and show that our method sets new performance standards on all three datasets. Additionally, we compare different feature sampling strategies as well as other encoding methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Since handwritten text can be used as a biometric identifier like faces or speech, it plays an important role for law enforcement agencies in proving someone's authenticity. However, in such scenarios the decision is typically made by experts in forensic handwriting. In contrast, searching for similar scribes 1 in a large document database raises the need for an automated handwriting system (method). This topic has attracted significant attention recently, especially in the field of historical document analysis <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref>. In this application an automatic identification for particular writers can give new insights of life in the past.</p><p>The focus of this paper is writer identification. Given a document, writer identification is the task of finding the specific writer (author) of the text from a set of writers which are known to the system. Depending on the data at hand, one has to differentiate between offline and online writer identification. In online writer identification the data contains temporal information about the text formation. In contrast, offline writer identification deals only with the handwritten text itself without any additional information. Offline writer identification can be further categorized into two groups <ref type="bibr" target="#b3">[4]</ref>: textural methods and allograph-based methods. In the former group, handwriting is described by global statistics drawn from the style of the handwritten text, e. g., measurements of the ink width or the angles of stroke directions <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref> Conversely, in allograph-based methods, the writer is described by the distribution of features extracted from small letter parts (i. e., "allographs") <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>. A vocabulary needs to be trained in advance from feature descriptors of the training set. The hereinafter presented method belongs to the allograph-based methods. Please note also that the best contenders of the ICDAR 2013 writer identification competition stem from this group <ref type="bibr" target="#b10">[11]</ref>. Both approaches can also be combined to create a better descriptor <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref>.</p><p>Given some handwritten text, we propose to characterize its scribe by means of the distribution of local feature descriptors. Hereby, the distribution is modeled by a generative model, in particular a Gaussian Mixture model (GMM). We adapt the so-called GMM-UBM method <ref type="bibr" target="#b14">[15]</ref>, a well-known approach in the field of speech processing. It has shown to yield good results, e. g., for speaker identification <ref type="bibr" target="#b15">[16]</ref>, or age determination <ref type="bibr" target="#b16">[17]</ref>.</p><p>In speech analysis, a GMM models the distribution of short-time spectral feature vectors of all speakers. Since such a GMM reflects the domain's speech style in general, it is typically denoted as Universal Background Model (UBM). Each speaker of a particular utterance is described by means of a maximum-a-posteriori (MAP) adaptation of the UBM to the feature descriptors of that utterance <ref type="bibr" target="#b14">[15]</ref>. See Figure <ref type="figure" target="#fig_4">1</ref> for a schematic illustration of such representation for the case of a two-dimensional feature vector. Finally, the global feature descriptor is formed by stacking the parameters of the adapted GMM (i. e., means, covariances, and weights) in a so-called supervector.</p><p>For the adaptation of this approach to the image domain, we replace the short-time spectral feature descriptors with RootSIFT descriptors <ref type="bibr" target="#b17">[18]</ref>, a normalized version of scale invariant feature transform (SIFT) descriptors <ref type="bibr" target="#b18">[19]</ref>. Op-Writer samples Adapted Mixture UBM</p><p>x 2</p><p>x 1</p><p>Figure <ref type="figure" target="#fig_4">1</ref>: The Universal Background Model (blue) is adapted to samples from one document (red). Mixtures which are influenced more by the new samples are adapted more strongly than others.</p><p>tionally, the dimensionality of the feature vectors could be reduced by a principal component analysis (PCA). We show that the resulting GMM supervector encoding yields an excellent representation for individual handwriting. Additionally, we employ support vector machines (SVM) to build individual classifiers per query document. Such an SVM is a linear classifier trained by only one single positive sample and multiple negative samples, it is denoted as Exemplar-SVM <ref type="bibr" target="#b19">[20]</ref>. Among others, Exemplar-SVMs have been used successfully for object classification <ref type="bibr" target="#b19">[20]</ref>, and scene classification <ref type="bibr" target="#b20">[21]</ref>. For each class an ensemble of such Exemplar-SVMs is trained. The highest response of the individual Exemplar-SVMs is used to decide upon the class of an unknown image. Unlike these works, we employ a single Exemplar-SVM for each test document using all training documents as negatives. In this way, we change the similarity measure for each test document. We show that this framework outperforms the current state of the art on three publicly available datasets. This paper is an extension of the work initially published in WACV 2014 <ref type="bibr" target="#b21">[22]</ref>. Novel contributions include:</p><p>• the integration of Exemplar-SVMs <ref type="bibr" target="#b19">[20]</ref>, which greatly improve the recognition rate;</p><p>• a more thorough analysis of the RootSIFT descriptors, showing that their evaluation at contour edges improves the recognition rate;</p><p>• investigation of an additional encoding strategy, termed Gaussian supervector <ref type="bibr" target="#b22">[23]</ref> besides Fisher vectors and vectors of locally aggregated descriptors (VLAD).</p><p>• evaluation on the KHATT dataset <ref type="bibr" target="#b23">[24]</ref> containing 4000 Arabic handwritten documents of 1000 scribes in addtion to ICDAR13 and CVL.</p><p>The rest of the paper is organized as follows. Section 2 gives an overview of related work. In Section 3 we provide a detailed description of our framework. We evaluate our method on three datasets and compare our method with the current state of the art in Section 4. Section 5 gives a brief summary and outlook.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The advantage of textural methods is their interpretability in comparison to allograph-based methods. Furthermore, textural methods are typically faster to compute since no dictionary needs to be trained. A recent textural approach was presented by He and Schomaker <ref type="bibr" target="#b5">[6]</ref>. They propose to use the ∆-n Hinge feature which is a generalization of the Hinge feature <ref type="bibr" target="#b3">[4]</ref>. The method achieves state-of-the-art results on the ICDAR13 English and Greek subsets.</p><p>A mixture of allograph and texture-based methods is presented by Newell and Griffin <ref type="bibr" target="#b11">[12]</ref>. They exploit histograms of oriented basic image features (oBIF) and employ the delta encoding as feature descriptors, which encodes a mean oBIF histogram for each individual scribe. Despite yielding very good results on several benchmark datasets, the ICFHR 2014 competition <ref type="bibr" target="#b24">[25]</ref> revealed that our previous work using only GMM supervectors <ref type="bibr" target="#b21">[22]</ref> achieves higher accuracy.</p><p>Allograph-based methods rely on a dictionary trained from local descriptors. This dictionary is subsequently used to collect statistics from the local descriptors of the query document. These statistics are then aggregated to form the global descriptor that is used to classify the document. This procedure is denoted encoding.</p><p>Fiel and Sablatnig <ref type="bibr" target="#b6">[7]</ref> employ Fisher vectors as encoding method to encode local SIFT descriptors. A GMM serves as the vocabulary, i. e., a GMM is computed from SIFT descriptors of the training set. Using this vocabulary, the data of each document is encoded using improved Fisher vectors <ref type="bibr" target="#b25">[26]</ref>. The similarity between handwritten documents is computed using the cosine distance between the corresponding Fisher vectors. They show state-of-the-art results on the ICDAR 2011 and CVL dataset. The current best performing method evaluated on the ICDAR13 Greek and English subsets and the CVL dataset is a combination of several features and Fisher vectors <ref type="bibr" target="#b9">[10]</ref>. In that work, contour gradient descriptors are combined with K-adjacent segments (KAS), and SURF. Unlike these works, we employ MAP-adapted GMMs, i. e., each document is adapted to a global GMM. The statistics of the adapted GMM form our GMM supervector. Note that one can also compute completely individual codebooks per document or writer using k-means <ref type="bibr" target="#b8">[9]</ref> or GMMs <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref>. However, the use of a universal background model is much more common in image retrieval <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b28">29]</ref>. It simplifies the correspondence and distance computation, and typically outperforms solutions using individual codebooks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b21">22]</ref> SIFT, or SIFT-like descriptors are the most common features in allograph-based methods <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b13">14]</ref>. Wu et al. additionally make use of the scales and orientations given by the SIFT keypoints <ref type="bibr" target="#b13">[14]</ref>. In contrast, we evaluate SIFT descriptors densely at the contours while preserving their rotational dependency. Recently, a descriptor specifically developed for script was proposed by He et al. <ref type="bibr" target="#b7">[8]</ref>, where junctions of the handwriting are extracted and subsequently  encoded using self-organizing maps (SOM).</p><p>One interesting aspect of a texture-based method stems from Bertolini et al. <ref type="bibr" target="#b29">[30]</ref>. They employ a dissimilarity framework, i. e., a single SVM is trained which classifies whether two documents are similar to each other or not. In their approach, each document is first binarized and then compressed to form a texture. Local binary patterns (LBP) and local phase quantization (LPQ) are then used to describe the textures. Each such compressed texture image is divided in 9 parts which are individually evaluated with a trained SVM. Finally, the individual probabilities are merged using different merging techniques. In our approach the image does not need to be divided in parts. Since we employ Exemplar-SVMs, an individual similarity measure for each document is computed.</p><p>Closely related to our approach is the work by Schlapbach et al. <ref type="bibr" target="#b30">[31]</ref> on online writer identification. First, they build a UBM by estimating a GMM, and then adapt a GMM for each recorded handwriting. The similarity between two recordings is measured by using the sum of posterior probabilities of each mixture. Busch et al. <ref type="bibr" target="#b31">[32]</ref> use MAP-adaptation for script classification in conjunction with texture features such as gray-level co-occurence matrices, Gabor and Wavelet engery features. Unlike these works, we employ RootSIFT descriptors and construct GMM supervectors from the adapted GMMs, which are further used for the classification. <ref type="bibr" target="#b32">[33]</ref> compare different encoding schemes in the context of classifying whether images contain text or not. They employ SURF descriptors as their local descriptors. They show that GMM supervectors outperform Fisher Vectors in most scenarios. However, they tested the encoding methods only on an in-house dataset. We employ contour-based RootSIFT descriptors which are encoded by GMM supervectors. Additionally, we employ a different normalization scheme and train Exemplar-SVMs to encode the similarity of each test document to others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Smith and Kornelson</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>Figure <ref type="figure" target="#fig_1">2</ref> shows an overview of our entire encoding process. For each document local feature descriptors are computed, in particular RootSIFT descriptors evaluated at the contours. In a training step a dictionary, i. e., the UBM, is trained from the descriptors of an independent document dataset. Each document in question is then encoded using the dictionary and the local descriptors to form a high-dimensional image descriptor, which is then used for classification. The remainder of this section provides the details of the feature extraction, the construction of the UBM, the adaptation process, the normalization of the supervector and its classification using Exemplar-SVMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Features</head><p>SIFT descriptors are based on histograms of oriented gradients <ref type="bibr" target="#b18">[19]</ref>. Typically they are evaluated at specific keypoint locations, which may contain information about the orientation, scale or other characteristics like the gradient norm. SIFT descriptors have proven to be strong features for image retrieval <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b33">34]</ref>, as well as in the related field of image forensics <ref type="bibr" target="#b34">[35]</ref>, and have already been successfully used in the context of writer identification <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14]</ref>.</p><p>More specifically we use the Hellinger-normalized version of SIFT <ref type="bibr" target="#b17">[18]</ref> also known as RootSIFT. In practice, each SIFT descriptor is l 1 -normalized followed by an elementwise application of the square-root. For other normalization techniques the reader is referred to <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>We evaluate several different sampling strategies: a) SIFT descriptors computed at keypoints determined by the scale-space approach as proposed by Lowe <ref type="bibr" target="#b18">[19]</ref>; b) SIFT evaluated densely at four different scales, also known as pyramid histogram of visual words (PHOW) <ref type="bibr" target="#b37">[38]</ref>; c) SIFT evaluated at the contour points of the script.</p><p>Jégou et al. <ref type="bibr" target="#b28">[29]</ref> showed that it can be beneficial to reduce the dimensionality of the local SIFT descriptors by means of a principal component analysis (PCA). By retaining only the dimensions related to the largest eigenvalues, possible noise contained in the lower components is removed. Furthermore, transforming the data with a PCA decorrelates the feature descriptors, so that they can be modeled more accurately by a GMM with a diagonal covariance matrix. Moreover, eigenvalue decomposition can be used to whiten the descriptors, i. e., making the covariance equal to the identity matrix. This has been shown to be beneficial for the recognitioon accuracy <ref type="bibr" target="#b38">[39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">GMM Supervector Encoding</head><p>Encoding refers to the process of building a single global feature descriptor from many local descriptors. A widely used encoding method is known as bag of (visual) words (BoW).</p><p>Universal Background Model:. Similarly to k-means in the classical BoW approach, a global dictionary is constructed, which is denoted as universal background model (UBM). It is modeled by a Gaussian mixture model (GMM), since any continuous distribution can be modeled by a GMM with arbitrary precision. Let λ = {w k , µ k , Σ k |k = 1, . . . , K} be the parameters of the GMM with K mixture components, where w k , µ k , Σ k are the mixture weight, mean vector and covariance matrix of component k, respectively.</p><p>Given a feature vector x ∈ R D , its likelihood function is defined as</p><formula xml:id="formula_0">p(x | λ) = K k=1 w k g k (x) ,<label>(1)</label></formula><p>where the Gaussian density g k is:</p><formula xml:id="formula_1">g k (x) = g(x ; µ k , Σ k ) = 1 (2π) D |Σ k | e -1 2 (x-µ k ) Σ -1 k (x-µ k ) .</formula><p>(2) The mixture weights satisfy the constraint</p><formula xml:id="formula_2">K k=1 w k = 1 and w k ∈ R + .</formula><p>Finally, the posterior probability of a feature vector x j to be generated by the Gaussian mixture k follows as:</p><formula xml:id="formula_3">γ j (k) = p(k | x j ) = w k g k (x j ) K l=1 w l g l (x j ) .<label>(3)</label></formula><p>The GMM parameters are estimated using the Expectation-Maximization (EM) algorithm to optimize a Maximum Likelihood (ML) criterion <ref type="bibr" target="#b39">[40]</ref>. The parameters λ of the UBM are iteratively refined to increase the loglikelihood log p(X | λ) = M m=1 log p(x m | λ) of the model for the set of training samples X = {x 1 , . . . , x M }. For computational efficiency, the covariance matrix Σ k is assumed to be diagonal, and in the remainder of this paper, the vector of the diagonal elements of Σ k is denoted as σ k . Note that a GMM using full covariance matrices can equally well be approximated by a GMM using diagonal covariance matrices by using a larger number of Gaussian mixtures <ref type="bibr" target="#b14">[15]</ref>. GMM Adaptation and Mixing:. The final UBM is adapted to each document individually, using all T local descriptors computed for a document W , X W = {x 1 , . . . , x T }. This can be seen as a MAP adaptation of the UBM to the new samples. New statistics are computed. Let</p><formula xml:id="formula_4">n k = T t=1 γ k (x t ) ,<label>(4)</label></formula><p>then the zeroth, first and second order statistics are:</p><formula xml:id="formula_5">E 0 k = 1 T n k<label>(5)</label></formula><formula xml:id="formula_6">E 1 k = 1 n k T t=1 γ k (x t )x t<label>(6)</label></formula><formula xml:id="formula_7">E 2 k = 1 n k T t=1 γ k (x t )(x t x t )<label>(7)</label></formula><p>where</p><formula xml:id="formula_8">E 0 k ∈ R, E 1 k ∈ R D</formula><p>, and E 2 k ∈ R D , and denotes the Hadamard product.</p><p>Finally, these statistics are mixed together with the information contained in the UBM. Densities with high posteriors are adapted more strongly (cf. Figure <ref type="figure" target="#fig_4">1</ref>). This is controlled by a fixed relevance factor r τ for the adaptation coefficients</p><formula xml:id="formula_9">α τ k = n k n k + r τ<label>(8)</label></formula><p>for each parameter τ τ ∈ {w, µ, Σ} . We use the same r for each τ as suggested by Reynolds et al. <ref type="bibr" target="#b14">[15]</ref> (τ as a superscript is therefore omitted subsequently). The resulting mixture parameters follow as:</p><formula xml:id="formula_10">ŵk = δ α k E 0 k + (1 -α k ) w k (9) μk = α k E 1 k + (1 -α k )µ k (10) σk = α k E 2 k + (1 -α k ) σ k + µ 2 k -μ2 k (<label>11</label></formula><formula xml:id="formula_11">)</formula><p>where δ is a scaling factor ensuring that the weights of all components sum up to one. Note: µ 2 and μ2 is a shorthand notation for µ µ and μ μ, respectively. Finally, the supervector s is formed by concatenating all parameters from the adapted GMM:</p><formula xml:id="formula_12">s = ŵ1 , . . . , ŵK , μ 1 , . . . , μ K , σ 1 , . . . , σ K . (<label>12</label></formula><formula xml:id="formula_13">)</formula><p>The vector s represents the global feature descriptor, and consists of (1 + 2D)K elements. Note that often only the adapted mean components are used, which reduces the vector size to DK. The effects of this reduction are evaluated in Section 4.4.</p><p>Normalization:. Sanchez et al. <ref type="bibr" target="#b25">[26]</ref> propose a two step normalization for the resulting vector after an encoding with Fisher vectors. First, power-normalization is applied to each element, i. e.,</p><formula xml:id="formula_14">s i = sign(s i )|s i | ρ , ∀s i ∈ s , 0 &lt; ρ ≤ 1 .<label>(13)</label></formula><p>Typically, ρ is set to 0.5, which then equals the Hellinger normalization, cf. Section 3.1. Next, the vector is l 2normalized, i. e., s = s/ s 2 . Through these normalization steps image-independent information, like the background data, is discarded by reducing the influence of more frequent descriptors <ref type="bibr" target="#b25">[26]</ref>. Furthermore, Sánchez et al. <ref type="bibr" target="#b25">[26]</ref> showed that an l 2 -normalization is, in general, beneficial when used in combination with linear classifiers. Arandjelovic and Zisserman <ref type="bibr" target="#b33">[34]</ref> propose to use intranormalization for VLAD encodings. Similar to GMM supervectors, VLAD is composed of multiple components. They suggest to apply a component-wise l 2 -normalization which is followed by a global l 2 -normalization. This helps to reduce the influence of dominant components.</p><p>Both normalization strategies will be evaluated when applied on the proposed GMM supervectors. Moreover, we evaluate two different variants of the GMM supervectors by applying a feature mapping. This can also be seen as a form of normalization. Hereby, a feature mapping inspired by the symmetrized Kullback-Leibler divergence is applied <ref type="bibr" target="#b40">[41]</ref>. We refer to this mapping as KL-normalization. It is computed as:</p><formula xml:id="formula_15">μk = √ w k σ -1 2 k μk (14) σk = w k 2 σ -1 k σk .<label>(15)</label></formula><p>In the case of mean-adaptation only, the resulting supervector follows as:</p><formula xml:id="formula_16">sm = μ 1 , . . . , μ K ,<label>(16)</label></formula><p>or as suggested by Xu et al. <ref type="bibr" target="#b40">[41]</ref>, one can build a 2DK long supervector:</p><formula xml:id="formula_17">smv = μ 1 , . . . , μ K , σ 1 , . . . , σ K . (<label>17</label></formula><formula xml:id="formula_18">)</formula><p>In this way, properties of the UBM are incorporated implicitly into the normalized global descriptor (s m and smv ) that are normally not reflected in the supervector. Note that the KL-Kernel has also been used in conjunction with GMM supervectors and SVMs in the field of speaker verification <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Other Encoding Methods</head><p>Apart from the different variants of the GMM supervectors (choice of features and normalization strategies), several other encoding methods exist. The most popular one is certainly vector quantization, however it has been shown that it is inferior to other encoding methods <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b38">39]</ref>. We will compare the proposed method with other encoding methods concentrating on those which are derived from a GMM. More specifically, we will evaluate (improved) Fisher vectors (FV) <ref type="bibr" target="#b25">[26]</ref> and vector of locally aggregated vectors (VLAD) <ref type="bibr" target="#b28">[29]</ref>, in particular a probabilistic variant of VLAD <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b32">33]</ref>. We will also evaluate another encoding method derived from a GMM, namely the Gaussianized vector representation (GVR) <ref type="bibr" target="#b22">[23]</ref>. In the following paragraphs we will briefly present those three encoding methods.</p><p>Fisher Vectors:. This representation is in many ways similar to GMM supervectors <ref type="bibr" target="#b25">[26]</ref>. The distribution of samples is also described by a generative model (i. e., a GMM). Each sample is then transformed to the gradient space of the model parameters. The Fisher vectors are derived from Fisher kernels, in particular the Fisher score of the samples normalized by the square-root of the Fisher information matrix <ref type="bibr" target="#b25">[26]</ref>.</p><p>Similar to the proposed MAP-adapted GMM supervectors, Fisher vectors encode statistics up to the second order:</p><formula xml:id="formula_19">μk = 1 T √ w k T t=1 γ t (x t ) (x t -µ) σ k ,<label>(18) σk</label></formula><formula xml:id="formula_20">= 1 T √ 2w k T t=1 γ t (x t ) (x t -µ k ) (x t -µ k ) σ ,<label>(19)</label></formula><p>where and denote the element-wise multiplication and division, respectively. Finally, the concatenation of σk for k = 1, . . . , K form the 2DK-dimensional Fisher vector.</p><p>Probabilistic VLAD:. The non-probabilistic version of the VLAD representation <ref type="bibr" target="#b28">[29]</ref> achieved state of the art results on several benchmark datasets, especially when its representation was improved with intra-normalization <ref type="bibr" target="#b33">[34]</ref> or residual normalization <ref type="bibr" target="#b42">[43]</ref>.</p><p>In contrast to the hard assignment of codewords by determining the nearest cluster centers, we use a probabilistic version of VLAD <ref type="bibr" target="#b28">[29]</ref>, which uses weighted distances to nearby cluster centers. This allows for a better comparison to the other GMM-based representations, since the same posteriors can be used.</p><formula xml:id="formula_21">v k = T t=1 γ k (x t )(x t -µ k ) .<label>(20)</label></formula><p>For the non-probabilistic version, the µ k would be the cluster centers obtained by k-means. γ k (x) would be a Dirac function returning 1 if µ k is the nearest cluster center to x t and 0 otherwise. Similarly to the other representations, each v k is stacked together to form a supervector representation containing DK elements.</p><p>Gaussianized Vector Representation:. This representation is another form of supervector encoding <ref type="bibr" target="#b22">[23]</ref>. It can be seen as an extension of the probabilistic VLAD and is defined as:</p><formula xml:id="formula_22">z k = (n k σ k ) -1 2 v k ,<label>(21)</label></formula><p>where v k is computed as in the soft VLAD representation, Equation <ref type="bibr" target="#b19">(20)</ref>, and σ k is the diagonal of the covariance matrix of the UBM. Thus, more information about the background writers is incorporated, similarly to the KLnormalization. Again, all K components form the supervector representation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Exemplar-SVMs</head><p>Instead of using one SVM per object category, Malisiewicz et al. <ref type="bibr" target="#b19">[20]</ref> proposed to use an ensemble of Exemplar-SVMs for object detection. This means, that for each instance of all object classes in the training set an individual (linear) SVM is trained. For training each of these Exemplar-SVMs the current sample is used as the only instance of the positive class and all other training samples as negatives. The large margin formulation follows similarly to the standard SVM:</p><formula xml:id="formula_23">argmin w,b 1 2 w 2 +c p h(1-w x p -b)+c n xn∈N h(1+w x n +b) ,<label>(22)</label></formula><p>where h(x) = max(0, x) is the hinge loss function, x p is the single target positive sample and x n are the descriptors of the negative training set N , respectively. c p and c n are regularization parameters for balancing the positive and negative costs. This has the effect that a single SVM does not have to be able to recognize different views of the same object, but can concentrate on classifying a single view. The authors of <ref type="bibr" target="#b19">[20]</ref> showed that an ensemble of such Exemplar-SVMs generalizes well, although each single Exemplar-SVM has a very strict decision boundary. As each classifier solves a simplified problem compared to a full category classifier, a simple regularized linear SVM is sufficient.</p><p>Note that Exemplar-SVMs can be reformulated to Exemplar-One-Class SVMs <ref type="bibr" target="#b43">[44]</ref>. This has the advantage that no individual class weight has to be calibrated. Very popular is also the approximation of Exemplar-SVMs by Exemplar-LDA <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b43">44]</ref>, where the training set is approximated by a Gaussian. Furthermore, Exemplar-SVMs can also be used as feature encoders <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b43">44]</ref>, where the normalized computed weight vector w is directly used as new feature descriptor for the specific exemplar.</p><p>For our application we have to modify this approach, since the training and testing subsets of a typical writer identification dataset are disjoint, i. e., the writers of the test set are not part of the training set. Therefore, the normal recognition pipeline, i. e., learning a multi-class classifier by using samples from the training set which then predicts the class of the samples in the test set, can not be applied. However, by using Exemplar-SVMs we can circumvent this problem. We do not train Exemplar-SVMs on the classes (=writers), of the training set at all. Instead, we train an Exemplar-SVM during test time for each query document by using the query document as positive sample, and all training samples are used as negatives. This is illustrated in Figure <ref type="figure" target="#fig_2">3</ref>. Each other document is scored against the Exemplar-SVM of the query document and ranked according to the scores. The author associated with the document having the highest score is with high probability also the author of the query document. Intuitively, this can be seen as an adjustment of the similarity measure. Instead of finding the nearest neighbor according to the cosine distance, a document specific similarity is learned.</p><p>The global feature vectors are high-dimensional, in our case 6400-dimensional. In such a space, all points tend to lie at the periphery of the manifold. On one hand this is the curse of dimensionality, on the other hand it is a blessing since the exemplar needs to be separable enough from the negative descriptors <ref type="bibr" target="#b45">[46]</ref>. For the Exemplar-SVM computation, we employ LIBLINEAR <ref type="bibr" target="#b47">[48]</ref> that relies on coordinate descent. Another possibility would be to use stochastic gradient descent (SGD) as suggested by Zepeda et al. <ref type="bibr" target="#b46">[47]</ref>. However, we found LIBLINEAR to be fast and robust. Computing the 1000 E-SVMs of the ICDAR13 benchmark dataset takes about 2.3 minutes using a standard PC (Intel Xeon E3-1276 3.60GHz), see Section 4.8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Evaluation</head><p>In the following paragraphs we document which datasets and evaluation metrics we use for evaluating our approach. Subsequently, we show the impact of the feature sampling as well as the GMM parameters, normalization, and Exemplar-SVMs. Finally, we compare our method to other GMMbased encoding methods and the state of the art method for writer identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Benchmark Datasets</head><p>We use the publicly available CVL, ICDAR13, and KHATT datasets for evaluation. From the example lines in Figure <ref type="figure" target="#fig_3">4</ref>, one can see the large variation in visual appearance between these datasets.</p><p>ICDAR13 <ref type="bibr" target="#b10">[11]</ref> was part of the ICDAR 2013 writer identification competition. It consists of two disjoint datasets, an experimental dataset for training and a benchmark dataset for testing. The experimental dataset stems from the ICFHR 2012 writer identification contest <ref type="bibr" target="#b48">[49]</ref> and consists of 100 scribes. The benchmark set contains 250 scribes. In both subsets each scribe contributed four documents. Two documents were written in Greek, the other two in English. The documents of the dataset are all binarized.</p><p>CVL <ref type="bibr" target="#b49">[50]</ref> consists of 310 scribes. Twenty-seven of them contributed seven documents each, which form the training set. The other 283 scribes contributed five documents each, which form the test set. For each scribe, one document is written in German and the remaining ones are written in English. Note that we binarized the documents for the evaluation using Otsu's method <ref type="bibr" target="#b50">[51]</ref> to be more similar to the ICDAR13 dataset.</p><p>KHATT <ref type="bibr" target="#b23">[24]</ref> was part of the ICFHR 2014 Arabic writer identification competition. KHATT consists of Arabic handwritten documents from 1000 scribes, where each scribe wrote four documents. The database is divided into three disjoint sets for training (70%), validation (15%) and testing (15%), respectively. The document images are in grayscale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation Metrics</head><p>For evaluation, each document is tested against all remaining ones. The results for writer identification are expressed in terms of mean average precision (mAP) and TOP-k rates for different ranks k.</p><p>Mean average precision is a measure used in the context of information retrieval. Let us first specify average precision (aP). Consider a query that returns Q documents in a ranked sequence. Out of the Q documents, R are relevant, i. e., written by the queried author. aP is calculated by</p><formula xml:id="formula_24">aP = 1 R Q k=1 Pr(k) • rel(k) ,<label>(23)</label></formula><p>where rel(k) is a binary function that is 1 when the document at rank k is relevant, and 0 otherwise. Pr(k) is the precision at rank k of the query (i. e., number of relevant documents in the first k query items divided by k). The mAP is computed as the average over all aP values of all possible queries. In this way, if relevant documents are found at a lower rank, higher values are assigned. Note that the recently employed writer retrieval criterion <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b49">50]</ref> is closely related to the mAP. The identification rate is given by the soft and hard TOP-k rates. The soft TOP-k rates (abbreviated as Sk) give the probability that at least one document of the same writer is among the k highly ranked documents. In contrast, the hard TOP-k rates (abbreviated as H-k) denote the probability that among the k first documents exactly k documents are from the same writer. In the following sections we evaluate the influence of different parts of the pipeline. We begin with the feature extraction, followed by the evaluation of different encoding methods. Finally, we assess the influence of the normalization step and compare the results of the complete pipeline with other encoding methods and the state of the art method. The UBM-GMM is learned from 150000 randomly selected descriptors of the associated training set. Taking all descriptors would be computationally prohibitive. Unless otherwise specified, we use the values of our previous work <ref type="bibr" target="#b21">[22]</ref>: 100 components for the GMM, GMM supervectors as encoding method using a relevance factor r = 28 and the supervectors are normalized using power-normalization followed by an l 2 -normalization. The cosine distance is used for comparing two global descriptors as a fast similarity measure (only a dot product for l 2 normalized feature descriptors) following previous work on image retrieval <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b33">34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Influence of Feature Extraction Modalities</head><p>First, we evaluate the influence of the descriptor. More specifically, we look at the influence of the sampling strategy used in conjunction with SIFT. The baseline is given by our previous results in which we used Hellinger-normalized SIFT (R-SIFT) features evaluated at SIFT keypoints <ref type="bibr" target="#b21">[22]</ref>. We compare this baseline against a densely sampled version of RootSIFT (Dense-R-SIFT). We use the implementation provided by the VLFeat Toolbox <ref type="bibr" target="#b51">[52]</ref> using the standard bin sizes <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10)</ref>, and a step size of 3. Another sampling strategy was inspired by the contour-gradient descriptor proposed by Jain and Doermann <ref type="bibr" target="#b8">[9]</ref>, who proposed a SIFT-like descriptor evaluated only at the contour of the script. Instead we directly use RootSIFT descriptors with their standard size, i. e., a bin size of 4. However, we omit rotational invariance, i. e., setting the descriptor upright at each position. Fiel and Sablatnig <ref type="bibr" target="#b6">[7]</ref> showed that rotational-dependent SIFT descriptors are beneficial for writer identification. The first three rows in Table <ref type="table">1</ref> show that dense sampling is better than using SIFT keypoints. Computing SIFT at the contour of the handwriting (C-R-SIFT) achieves the highest rates.   all components and no normalization (SVwmc); all components and element-wise signed square root (SVssr); all components and intranormalization (SVwmc + intra); KL-normalized mean components (SVm + KL-norm); KL-normalized mean and covariances (SVmc + KL-norm). All rates are given in terms of mAP evaluated on the ICDAR13 training set.</p><p>Since we seek to have a compact representation for the subsequent steps of the pipeline, we evaluate the influence of reducing the dimensionality of the RootSIFT descriptors to 64 components as well as performing an additional whitening step. Table <ref type="table">1</ref> reveals that especially the whitening step is beneficial for the C-R-SIFT representation (applying a dimensionality reduction and whitening to the original RootSIFT representation gives 66.2 mAP). Note that the PCA-decorrelated versions are subsequently l 2normalized. For the rest of the paper, we use this compact representation (C-R-SIFT + PCA-64 + Wh.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">GMM Supervector parameters</head><p>GMM supervectors depend on: a) the relevance factor r, b) the adapted components, and thus the supervector representation, and c) the applied normalization. In general also the number of Gaussians for the GMM training is important, however we have found that the accuracy is quite stable for a number of Gaussians between 50 and 150 <ref type="bibr" target="#b21">[22]</ref>, thus using 100 Gaussians for the following experiments.</p><p>Figure <ref type="figure" target="#fig_5">5</ref> shows the influence of different relevance factors. In contrast to the relevance factor r = 28 of our previous work <ref type="bibr" target="#b21">[22]</ref>, it seems that a higher relevance factor of 64 is slightly better suited for C-R-SIFT descriptors. Although the relevance factor depends on n k (see Equation ( <ref type="formula" target="#formula_9">8</ref>)), and thus is dataset dependent, we found the chosen relevance factor to be working well for other datasets, too.</p><p>Next, we compare different supervector representations, i. e., we experiment with only weights (SV w ), means (SV m ), covariances (SV c ) or combinations of these three SV mc and SV wmc . Note that they were normalized using power normalization (ssr). Table <ref type="table" target="#tab_1">2a</ref> shows that using mean supervectors as the sole representation is superior to supervector consisting of the adapted covariances, or weights. Higher dimensional combinations do not seem to improve the recognition rate much to justify the increase in dimensionality. Thus, we stick to the more compact representation resulting in a 6400-dimensional supervector.</p><p>We also evaluated different normalization techniques. Table 2b shows that power-normalization is superior to intranormalization or just applying l 2 -normalization. Rows four and five of Table <ref type="table" target="#tab_1">2b</ref> show the results of using the normalization derived from the KL-kernel. This representation seems to further improve the recognition rate. Consequently, we chose to use this normalization for the subsequent evaluations, where we use mean-adapted GMM supervectors to save training time for the Exemplar-SVM denoted as SV m,kl .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Comparison with Other Encoding Methods</head><p>We compare our proposed encoding method, i. e., GMM supervectors, with other encoding techniques that use a GMM as background model. We present the results of the ICDAR13 test set so that they can be compared to the results of the state of the art. When comparing the different encoding methods, the GMM supervector encoding performs best, while Fisher vectors perform second best. Dimension-wise SV wmc has the largest feature dimension of 2KD + D, while Fisher vectors typically encode first and second order statistics resulting in a dimension of 2KD. The other encoding methods (PVLAD, GSV, Proposed) encode only first order statistics, thus having a lower dimension of KD (i. e., 6400-dimensional). This speeds up the subsequent parts of the pipeline, especially the use of the Exemplar-SVMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Exemplar-SVM Analysis</head><p>For each test document an individual E-SVM is created using all the documents of the training set as negative samples. We choose to use the same class weights as proposed by Malisiewicz et al. <ref type="bibr" target="#b19">[20]</ref>, i. e., c p = 0.5 and c n = 0.01, where c p is the class weight for the positive set and c n for the negative set. We scale these parameters by a complexity parameter C which is validated using the validation sets (for the ICDAR13 set, we split the training dataset in two subsets such that 75% is used to train the SVMs and 25% for validation; for the CVL dataset we used the same C as for the ICDAR13 dataset, since the training set was too small for splitting).</p><p>First we evaluated the influence of the number of available negatives used to train the Exemplar-SVMs. Figure <ref type="figure" target="#fig_7">6</ref> Method S-1 S-2 S-5 S-10 H-2 H-    (left) shows that with a growing number of negative training samples the retrieval rate raises. Even a low number of negatives has a positive influence on the mean average precision. The better accuracy comes with the prize of a higher runtime, see Figure <ref type="figure" target="#fig_7">6</ref> (right). However, this makes just a small part of the overall runtime, cf. Section 4.8,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Evaluation of Our Entire Pipeline</head><p>We compare our baseline <ref type="bibr" target="#b21">[22]</ref> with the proposed more compact representation, i. e., C-R-SIFT descriptors with mean-adapted GMM supervectors and KL-normalization (Proposed) and our extended pipeline, i. e., the integration of Exemplar-SVMs (Proposed + E-SVM). We show that this additional step sets new standards on all evaluated datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.1.">Results for ICDAR13</head><p>Interestingly, Table <ref type="table" target="#tab_5">4</ref> shows that all proposed encoding methods (Table <ref type="table" target="#tab_3">3</ref>) perform better than the methods currently considered the state of the art <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b8">9]</ref>. The work by Fiel et al. <ref type="bibr" target="#b6">[7]</ref> (SIFT + FV) and our previous work <ref type="bibr" target="#b21">[22]</ref> (R-SIFT + SV) are based on sparsely sampled SIFT and RootSIFT, respectively. In comparison with their contourbased versions, we can conclude that the feature sampling is indeed an important factor for a high mAP.</p><p>As can be seen in Table <ref type="table" target="#tab_5">4</ref>, using Exemplar-SVMs gives a further boost in terms of accuracy. For example, on the ICDAR13 dataset the hard TOP-2 and TOP-3 rates improve by about 13 and 15 percentage points, respectively. Thus, we are able to detect not even the document from the same language, but find with a high probability the documents of the same author even in a different script style.</p><p>As Table <ref type="table" target="#tab_6">5</ref> shows, if we evaluate the languages independently, our approach without Exemplar-SVMs performs worse than the feature combination approach of Jain and Doermann [10]<ref type="foot" target="#foot_0">2</ref> . However, using our extended pipeline, we even achieve a recognition rate of 100% for the Greek documents, and a TOP-1 accuracy of 99% for the English dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.2.">Results for CVL</head><p>The CVL dataset is evaluated in two different ways:    <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref> are taken from <ref type="bibr" target="#b10">[11]</ref>.</p><p>method without Exemplar-SVMs does not improve over our baseline approach <ref type="bibr" target="#b21">[22]</ref>. This might be related to the rather homogeneous CVL dataset, where a more dense sampling does not improve over a sparse sampling. However, the proposed supervector is much smaller than our baseline (KD vs. 2KD + K). Further note that the different UBM and PCA-transformation result in slightly worse results of "proposed" in B) compared to A).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.3.">Results for KHATT</head><p>The same holds true for the KHATT dataset, which we additionally evaluated<ref type="foot" target="#foot_1">3</ref> . Our strong baseline <ref type="bibr" target="#b21">[22]</ref> achieves slightly better results compared to the proposed system using C-R-SIFT descriptors and mean-adapted GMM supervectors (Proposed). However, when we apply the complete pipeline, i. e., using Exemplar-SVMs, we achieve recognition rates near 100%. This is related to the large training and validation sets provided by this dataset. This also indicates that larger training sets are needed for a further improvement in recognition rates. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8.">Runtime Evaluation</head><p>We measured the runtime of different steps of our proposed pipeline, see Figure <ref type="figure" target="#fig_8">7</ref>. GMM training takes the most time followed by the feature processing. Feature processing comprises the Hellinger normalization and PCA transformation. Interestingly, while the encoding step takes three times as long as the feature extraction part, the Exemplar-SVM part takes less time than the feature extraction using LIBLINEAR. The training of the 1000 Exemplar-SVMs of the ICDAR13 benchmark dataset takes only about 2. minutes. However note that the number of negatives is 400 (the ICDAR13 training dataset). With more negatives this step could take more time. The processing time for the ICDAR13 test set was about 27 minutes, i. e., each image took about 1.6s to process. Please note that our implementation has not been optimized regarding the runtime, and only some parts were parallelized. We see room for improvement, especially with the feature processing and encoding step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we have presented a new framework for offline writer identification setting new performance standards on three benchmark datasets. First, we proposed the use of SIFT descriptors computed densely at the script contour. We showed that this sampling strategy greatly improves the recognition rates in comparison to other strategies on the difficult bilingual ICDAR13 dataset. Similar to our previous work, we evaluated the influence of different encoding methods and showed that GMM supervectors are superior to other GMM-based encoding methods. We can further improve the recognition accuracy by using a normalization derived from the KL-kernel and at the same time reduce the dimensionality of the feature vector. Additionally, we extended our previous work <ref type="bibr" target="#b21">[22]</ref> by using Exemplar-SVMs and showed that this step boosts the recognition rate on all datasets. However, large datasets such as KHATT benefit the most, due to the significant size of the training set.</p><p>Since feature extraction was not the focus of this paper, it would be interesting to analyze, how features, specifically designed for script, e. g., the recently developed junclets <ref type="bibr" target="#b7">[8]</ref>, would perform in conjunction with GMM supervectors and Exemplar-SVMs. Recent improvements in the encoding step such as higher order VLAD <ref type="bibr" target="#b54">[55]</ref> or democratic aggregation <ref type="bibr" target="#b55">[56]</ref>, could further improve the writer identification rates. The current high identification rates also suggest the need for larger datasets. This would also widen the scope for techniques relying on more training data such as convolutional neural networks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overview of the entire pipeline. From the input document (left) features are extracted using RootSIFT features computed densely at the script contour. These features are subsequently PCA-whitened and their dimensionality is reduced. These local descriptors are then encoded by means of GMM supervectors. After a normalization step, they are used as input for an Exemplar-SVM. The scores of the Exemplar-SVMs are used for ranking the document.</figDesc><graphic coords="4,95.00,53.23,406.22,713.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: For each document of the test set an individual Exemplar-SVM is trained. The GMM supervector of this document is used as positive sample, while all the encodings of the training set are used as negatives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Example lines of the three datasets, from top to bottom: ICDAR13, CVL and KHATT.</figDesc><graphic coords="7,95.00,53.23,406.22,713.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Table 1 :</head><label>1</label><figDesc>-SIFT + PCA-64 + Wh. 84.0 Comparison of SIFT using different modalities. From top to bottom: R-SIFT computed at SIFT keypoints, R-SIFT evaluated densely over the image (Dense-R-SIFT), R-SIFT computed at the contour of the script (C-R-SIFT). C-R-SIFTs are evaluated with a PCA-dimensionality reduced version retaining 64 components (second last row) and additionally whitened (last row). The results are given in terms of mAP evaluated on the ICDAR13 training set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Evaluation of the relevance factor using the ICDAR13 training set.</figDesc><graphic coords="9,95.00,53.23,406.22,713.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Evaluation of the accuracy (left) and time (right) using different number of negatives for the Exemplar-SVM training, evaluated with the ICDAR13 test set.</figDesc><graphic coords="10,95.00,53.23,406.22,713.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Runtime of the different pipeline steps, evaluated using the ICDAR13 dataset.</figDesc><graphic coords="11,95.00,53.23,406.22,713.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison of different GMM supervector component combinations (a): only weights (SVw); means (SVm); covariances (SVc); means and covariances (SVmc); weights and means and covariances (SVwmc). (b) shows different normalization techniques:</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Comparison of different encoding methods evaluated on the ICDAR13 test set.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>SIFT + SV wmc,ssr<ref type="bibr" target="#b21">[22]</ref> 97.1 98.5 98.9 99.0 42.8 23.8 67.1</figDesc><table><row><cell>Method</cell><cell>S-1</cell><cell>S-2</cell><cell>S-5</cell><cell>S-10</cell><cell>H-2</cell><cell cols="2">H-3 mAP</cell></row><row><cell>SIFT + FV mc,ssr [7]</cell><cell cols="6">90.9 93.6 97.0 98.0 44.8 24.5</cell><cell>-</cell></row><row><cell>HIT-ICG</cell><cell cols="6">94.8 96.7 98.0 98.3 63.2 36.5</cell><cell>-</cell></row><row><cell>CS [9]</cell><cell cols="5">95.1 97.7 98.6 99.1 19.6</cell><cell>7.1</cell><cell>-</cell></row><row><cell>R-Proposed</cell><cell cols="6">98.2 98.6 98.7 98.9 71.2 47.7</cell><cell>81.4</cell></row><row><cell>Proposed + E-SVM</cell><cell cols="7">99.7 99.7 99.8 99.8 84.8 63.5 89.4</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">A) Using solely the CVL training set for creating the</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">background model, PCA-transformation matrix, and</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">the computed GMM supervectors as negatives for the</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Exemplar-SVM.</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">B) As training set we merged two additional datasets:</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">i) the complete IAM dataset [53] consisting of 1539</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">pages, and ii) the ICDAR 2011 benchmark dataset [54]</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">containing 209 documents. The UBM and the PCA-</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">transformation matrix were computed using the IC-</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">DAR13 training set.</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">Thus, A) gives a fair comparison to other methods, since</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">only information from the dataset itself is used. For B) we</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">show what is possible with additional training data, even</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">when this data comes from different datasets. Similarly,</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">Table 6 shows a large improvement using Exemplar-SVMs</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">in the case of scenario B) where we enriched the training</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">set. However, using solely the CVL training set for the</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">training of the Exemplar-SVMs worsens the results. This</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">is in contradiction to our Exemplar-SVM analysis, where</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">even 25 negatives for the Exemplar-SVM training bring a</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">small improvement for the ICDAR13 test set. We believe</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">that the small number of different scribes in the training</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">set prevents the creation of strong Exemplar-SVMs. Also</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">the lack of a suitable validation set makes a calibration of</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">the balancing factor C impossible. Note that our proposed</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Comparison of our method with the state of the art evaluated on the ICDAR13 test set. Values of HIT-ICG,<ref type="bibr" target="#b6">[7]</ref>,<ref type="bibr" target="#b8">[9]</ref> are taken from<ref type="bibr" target="#b10">[11]</ref>.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Greek</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>English</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>S-1</cell><cell>S-2</cell><cell cols="3">S-5 S-10 mAP</cell><cell>S-1</cell><cell>S-2</cell><cell>S-5</cell><cell cols="2">S-10 mAP</cell></row><row><cell>SIFT + FV [7]</cell><cell cols="4">88.4 92.0 96.8 97.8</cell><cell>-</cell><cell cols="4">91.4 94.2 95.8 97.2</cell><cell>-</cell></row><row><cell>HIT-ICG</cell><cell cols="4">93.8 96.4 97.2 97.8</cell><cell>-</cell><cell cols="4">92.2 94.6 96.4 96.8</cell><cell>-</cell></row><row><cell>CS [9]</cell><cell cols="4">95.6 98.2 98.6 99.2</cell><cell>-</cell><cell cols="4">94.6 97.0 98.4 98.8</cell><cell>-</cell></row><row><cell>SV [22]</cell><cell cols="5">97.4 98.6 99.0 99.4 98.2</cell><cell cols="5">96.4 97.4 98.0 98.8 97.2</cell></row><row><cell>∆-n H. [6]</cell><cell>96.0</cell><cell>-</cell><cell>-</cell><cell>98.4</cell><cell>-</cell><cell>93.4</cell><cell>-</cell><cell>-</cell><cell>97.8</cell><cell>-</cell></row><row><cell>Comb. [10]</cell><cell cols="5">99.2 99.6 99.8 99.8 99.5</cell><cell cols="5">97.4 97.8 98.6 98.8 97.9</cell></row><row><cell>Proposed</cell><cell cols="5">98.2 98.6 99.2 99.4 98.6</cell><cell cols="5">95.8 96.6 97.0 97.6 96.5</cell></row><row><cell cols="5">Proposed + E-SVM 100 100 100 100</cell><cell cols="6">100 99.0 99.2 99.8 100 99.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Comparison with the state of the art on the ICDAR13 test set: Greek only (left) and English only (right). Values of HIT-ICG,</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>S-10 H-2 H-3 H-4 mAP SIFT + FV mc,ssr<ref type="bibr" target="#b6">[7]</ref> 97.8 98.6 99.1 99.6 95.6 89.4 75.8 -R-SIFT + SV wmc,ssr [22] 99.2 99.2 99.5 99.6 98.1 95.8 88.7 97.1 Comb. [10] 99.4 99.5 99.6 99.7 98.3 94.8 82.9 96.9 Comparison with the state of the art on the CVL test set. We experimented using different negative sets for the E-SVM training: A) the CVL training set; B) the IAM datasets plus the ICDAR 2011 benchmark dataset.</figDesc><table><row><cell>3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Comparison with the state of the art on the KHATT test set.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>The authors have not provided results for the complete ICDAR13 dataset</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>Note that the evaluation protocol of<ref type="bibr" target="#b4">[5]</ref> is different from ours, since the authors chose to use not the official dataset splitting: They use two documents from each author to train a multi-class SVM (resulting in 2000 documents). The system is then tested by using one document as probe and the other as query, i. e., 1000 evaluations. In contrast, we evaluate the algorithm on the official testing subset in a leave-one-document-out manner.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been supported by the German Federal Ministry of Education and Research (BMBF), grant-nr. 01UG1236a. The contents of this publication are the sole responsibility of the authors.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Writer Identification Using Directional Ink-Trace Width Measurements</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Smit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bulacu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schomaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="162" to="171" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scribe Identification in Medieval English Manuscripts</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gilliam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition (ICPR), 2010 20th International Conference on</title>
		<meeting><address><addrLine>Istanbul</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1880" to="1883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Writer Identification for Historical Arabic Documents</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Asit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Märgner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>El-Sana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fingscheidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition (ICPR), 2014 22nd International Conference on</title>
		<meeting><address><addrLine>Stockholm</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3050" to="3055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Text-Independent Writer Identification and Verification Using Textural and Allographic Features, Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bulacu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schomaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="701" to="717" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evaluation of Texture Features for Offline Arabic Writer Identification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Djeddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-S</forename><surname>Meslati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Siddiqi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ennaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Abed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gattal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Analysis Systems (DAS), 2014 11th IAPR International Workshop on</title>
		<meeting><address><addrLine>Tours</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="8" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schomaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Delta-N</forename><surname>Hinge</surname></persName>
		</author>
		<title level="m">Pattern Recognition (ICPR), 2014 22nd International Conference on</title>
		<meeting><address><addrLine>Stockholm</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2023" to="2028" />
		</imprint>
	</monogr>
	<note>Rotation-Invariant Features for Writer Identification</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Writer Identification and Writer Retrieval using the Fisher Vector on Visual Vocabularies</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sablatnig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Analysis and Recognition (ICDAR), 2013 12th International Conference on</title>
		<meeting><address><addrLine>Washington DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="545" to="549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Junction Detection in Handwritten Documents and its Application to Writer Identification</title>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wiering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schomaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4036" to="4048" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Writer Identification Using an Alphabet of Contour Gradient Descriptors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Analysis and Recognition (ICDAR), International Conference on</title>
		<meeting><address><addrLine>Buffalo</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="550" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Combining Local Features for Offline Writer Identification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Frontiers in Handwriting Recognition (ICFHR), 2014 14th International Conference on</title>
		<meeting><address><addrLine>Heraklion</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="583" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">IC-DAR 2013 Competition on Writer Identification</title>
		<author>
			<persName><forename type="first">G</forename><surname>Louloudis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gatos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Stamatopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Papandreou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Analysis and Recognition (ICDAR), 2013 12th International Conference on</title>
		<meeting><address><addrLine>Washington DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1397" to="1401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D L</forename><surname>Griffin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Writer Identification Using Oriented Basic Image Features and the Delta Encoding</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="2255" to="2265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic Writer Identification Using Connected-Component Contours and Edge-Based Features of Uppercase Western Script, Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">L</forename><surname>Schomaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bulacu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="787" to="798" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Offline Text-Independent Writer Identification Based on Scale Invariant Feature Transform, Information Forensics and Security</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="526" to="536" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Speaker Verification Using Adapted Gaussian Mixture Models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Quatieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Dunn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Signal Processing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="19" to="41" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Support Vector Machines Using GMM Supervectors for Speaker Verification</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Sturim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Reynolds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing Letters, IEEE</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="308" to="311" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Age and Gender Recognition for Telephone Applications Based on GMM Supervectors and Support Vector Machines</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bocklet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nöth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<meeting><address><addrLine>Las Vegas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008. 2008. 2008</date>
			<biblScope unit="page" from="1605" to="1608" />
		</imprint>
	</monogr>
	<note>IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Three Things Everyone Should Know to Improve Object Retrieval</title>
		<author>
			<persName><forename type="first">R</forename><surname>Arandjelovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2911" to="2918" />
		</imprint>
	</monogr>
	<note type="report_type">Providence</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distinctive Image Features from Scale-Invariant Keypoints</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ensemble of Exemplar-SVMs for Object Detection and Beyond</title>
		<author>
			<persName><forename type="first">T</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), IEEE International Conference on</title>
		<meeting><address><addrLine>Barcelona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Blocks that shout: Distinctive parts for scene classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Juneja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Jawahar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="923" to="930" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<author>
			<persName><forename type="first">V</forename><surname>Christlein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bernecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hönig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Angelopoulou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Writer Identification and Verification Using GMM Supervectors</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="998" to="1005" />
		</imprint>
	</monogr>
	<note>Applications of Computer Vision (WACV)</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Novel Gaussianized Vector Representation for Improved Natural Scene Categorization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hasegawa-Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="702" to="708" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">KHATT: An Open Arabic Offline Handwritten Text Database</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mahmoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Al-Khatib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alshayeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tanvir Parvez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Märgner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Fink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1096" to="1112" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">ICFHR2014 Competition on Arabic Writer Identification Using AHTID/MW and KHATT Databases</title>
		<author>
			<persName><forename type="first">F</forename><surname>Slimane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Awaida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Frontiers in Handwriting Recognition (ICFHR), 14th International Conference on</title>
		<meeting><address><addrLine>Heraklion</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="797" to="802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Image Classification with the Fisher Vector: Theory and Practice</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="222" to="245" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A New Text-Independent GMM Writer Identification System Applied to Arabic Handwriting</title>
		<author>
			<persName><forename type="first">F</forename><surname>Slimane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Märgner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Frontiers in Handwriting Recognition (ICFHR), 2014 14th International Conference on</title>
		<meeting><address><addrLine>Heraklion</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Off-line Writer Identification and Verification Using Gaussian Mixture Models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schlapbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning in Document Analysis and Recognition</title>
		<title level="s">Studies in Computational Intelligence</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Marinai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Fujisawa</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="409" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Aggregating Local Image Descriptors into Compact Codes, Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1704" to="1716" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Texture-based Descriptors for Writer Identification and Verification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bertolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Justino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sabourin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2069" to="2080" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A Writer Identification System for On-line Whiteboard Data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schlapbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2381" to="2397" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Texture for Script Identification, Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Busch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Boles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sridharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1720" to="1732" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A Comparison of Fisher Vectors and Gaussian Supervectors for Document Versus Non-document Image Classification</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Kornelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE 8856, Applications of Digital Image Processing XXXVI</title>
		<meeting><address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">8856</biblScope>
			<biblScope unit="page" from="88560N" to="88560N" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">All About VLAD</title>
		<author>
			<persName><forename type="first">R</forename><surname>Arandjelovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<meeting><address><addrLine>Portland, OR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1578" to="1585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">An Evaluation of Popular Copy-Move Forgery Detection Approaches, Information Forensics and Security</title>
		<author>
			<persName><forename type="first">V</forename><surname>Christlein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Riess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Riess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Angelopoulou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1841" to="1854" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Revisiting the Fisher Vector for Fine-grained Classification</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Gosselin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="92" to="98" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Kobayashi</surname></persName>
		</author>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on</title>
		<meeting><address><addrLine>Columbus</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3278" to="3285" />
		</imprint>
	</monogr>
	<note>Dirichlet-based Histogram Feature Transform for Image Classification</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Munoz</surname></persName>
		</author>
		<title level="m">Computer Vision (ICCV), IEEE 11th International Conference on</title>
		<imprint>
			<publisher>Rio de Janeiro</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>Image Classification Using Random Forests and Ferns</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.4506</idno>
		<title level="m">Bag of Visual Words and Fusion Methods for Action Recognition: Comprehensive Study and Good Practice</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Maximum Likelihood from Incomplete Data via the EM Algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Extended Hierarchical Gaussianization for Scene Classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Processing (ICIP), 2010 17th IEEE International Conference on, Hong Kong</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1837" to="1840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The Devil is in the Details: an Evaluation of Recent Feature Encoding Methods</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Hoey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Mckenna</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Trucco</surname></persName>
		</editor>
		<meeting><address><addrLine>Dundee</addrLine></address></meeting>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="76" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Revisiting the VLAD Image Representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Delhumeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-H</forename><surname>Gosselin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multimedia (MM), 21st ACM international conference on</title>
		<meeting><address><addrLine>Barcelona</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="653" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Kobayashi</surname></persName>
		</author>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2765" to="2773" />
		</imprint>
	</monogr>
	<note>Three Viewpoints Toward Exemplar SVM</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<title level="m">Computer Vision -ECCV 2012: 12th European Conference on Computer Vision</title>
		<meeting><address><addrLine>Florence, Italy; Berlin Heidelberg, Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">October 7-13, 2012. 2012</date>
			<biblScope unit="page" from="459" to="472" />
		</imprint>
	</monogr>
	<note>Discriminative Decorrelation for Clustering and Classification</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Gharbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<idno>MIT-CSAIL-TR-2012-032</idno>
		<title level="m">A Gaussian Approximation of Feature Space for Fast Image Similarity</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Zepeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3052" to="3060" />
		</imprint>
	</monogr>
	<note>Exemplar SVMs as Visual Feature Encoders</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">LIBLINEAR: A Library for Large Linear Classification</title>
		<author>
			<persName><forename type="first">R.-E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Competition on Writer Identification Challenge 1: Latin/Greek Documents</title>
		<author>
			<persName><forename type="first">G</forename><surname>Louloudis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gatos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Stamatopoulos</surname></persName>
		</author>
		<author>
			<persName><surname>Icfhr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Frontiers in Handwriting Recognition (ICFHR), 2012 International Conference on</title>
		<meeting><address><addrLine>Bari</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="829" to="834" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">CVL-DataBase: An Off-Line Database for Writer Retrieval, Writer Identification and Word Spotting</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kleber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sablatnig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Analysis and Recognition (ICDAR), 2013 12th International Conference on</title>
		<meeting><address><addrLine>Washington DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="560" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A Threshold Selection Method from Gray-Level Histograms, Systems, Man, and Cybernetics</title>
		<author>
			<persName><forename type="first">N</forename><surname>Otsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="62" to="66" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">VLFeat -An Open and Portable Library of Computer Vision Algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fulkerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multimedia, International Conference on, ACM, Firenze</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1469" to="1472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The IAM-database: An English Sentence Database for Offline Handwriting Recognition</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Marti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Document Analysis and Recognition</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="46" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Louloudis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Stamatopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gatos</surname></persName>
		</author>
		<title level="m">Document Analysis and Recognition (ICDAR), 2011 International Conference on</title>
		<meeting><address><addrLine>Beijing</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1475" to="1479" />
		</imprint>
	</monogr>
	<note>ICDAR 2011 Writer Identification Contest</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Boosting VLAD with Supervised Dictionary Learning and High-Order Statistics</title>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2014</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Fleet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</editor>
		<meeting><address><addrLine>Zurich</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8691</biblScope>
			<biblScope unit="page" from="660" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Triangulation Embedding and Democratic Aggregation for Image Search</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, Columbus</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3310" to="3317" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
