<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Facing Scalability Issues in Requirements Prioritization with Machine Learning Techniques</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Paolo</forename><surname>Avesani</surname></persName>
							<email>avesani@irst.itc.it</email>
							<affiliation key="aff0">
								<orgName type="department">ITC-IRST</orgName>
								<address>
									<addrLine>Via Sommarive 18</addrLine>
									<postCode>I-38050</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cinzia</forename><surname>Bazzanella</surname></persName>
							<email>bazzanella@irst.itc.it</email>
							<affiliation key="aff0">
								<orgName type="department">ITC-IRST</orgName>
								<address>
									<addrLine>Via Sommarive 18</addrLine>
									<postCode>I-38050</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anna</forename><surname>Perini</surname></persName>
							<email>perini@irst.itc.it</email>
							<affiliation key="aff0">
								<orgName type="department">ITC-IRST</orgName>
								<address>
									<addrLine>Via Sommarive 18</addrLine>
									<postCode>I-38050</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Angelo</forename><surname>Susi</surname></persName>
							<email>susi@irst.itc.it</email>
							<affiliation key="aff0">
								<orgName type="department">ITC-IRST</orgName>
								<address>
									<addrLine>Via Sommarive 18</addrLine>
									<postCode>I-38050</postCode>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Facing Scalability Issues in Requirements Prioritization with Machine Learning Techniques</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">38D4118A7B18798853ABDA9CA2618D7A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Case-based driven approaches to requirements prioritization proved to be much more effective than first-principle methods in being tailored to a specific problem, that is they take advantage of the implicit knowledge that is available, given a problem representation. In these approaches, firstprinciple prioritization criteria are replaced by a pairwise preference elicitation process. Nevertheless case-based approaches, using the Analytic Hierarchy Process (AHP) technique, become impractical when the size of the collection of requirements is greater than about twenty since the elicitation effort grows as the square of the number of requirements.</p><p>We adopt a case-based framework for requirements prioritization, called Case-Based Ranking, which exploits machine learning techniques to overcome the scalability problem. This method reduces the acquisition effort by combining human preference elicitation and automatic preference approximation.</p><p>Our goal in this paper is to describe the framework in details and to present empirical evaluations which aim at showing its effectiveness in overcoming the scalability problem. The results prove that on average our approach outperforms AHP with respect to the trade-off between expert elicitation effort and the requirement prioritization accuracy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Requirements prioritization plays a key role in software development when we need to plan for system releases and to decide which requirements to implement in each release, according to budget and time constraints as well as to customer expectations <ref type="bibr" target="#b1">[2]</ref>. Different factors influence the definition of priority criteria such as business aspects (e.g. market competition or regulations), customer satisfaction, or technical aspects (e.g. the development cost).</p><p>Requirements prioritization can be conceived as an order relation on a given set of requirements, on the basis of which it is possible to derive a partition into many subsets, one for each release. Usually, it is not crucial to get the relative order of core requirements, because all of them will be part of the first release, but the accuracy of the rank becomes more and more important when deciding which of the pending requirements can be removed from the subsequent releases.</p><p>Recent approaches <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b25">26]</ref> to requirements prioritization seem to share a common model for the requirements prioritization process, consisting of the following steps: (i) selection of one or more prioritization criteria among business goals and technical features (e.g. customer value, revenue or development cost); (ii) acquisition of a requirements ordering according to a specific criterion from one or more stakeholders (e.g. customers, users, project manager); (iii) composition of the acquired orderings into a final one based upon an appropriate composition schema. These steps are part of a process that can be iterated many times during the entire life-cycle of a software system.</p><p>First principle or ex-ante methods for requirements prioritization, define a-priory the ranking criteria (that is the requirements attributes -or priority indexes -and the relative ranges of values), independently of the current set of requirements that are to be evaluated. Partial orders are a possible outcome of ex-ante methods and can be the source of less effective decision making support.</p><p>Our work follows an alternative approach based on expost methods. Differently from first principle strategy, the elicitation of prioritization criteria is performed in parallel with the requirements analysis. A process of pairwise comparison allows to define at the same time which requirement and why it has to be preferred between two alternatives. That is, the prioritization criteria are not explicitly encoded but acquired by examples. This approach is known as casebased ranking and it is inspired by case-based reasoning <ref type="bibr" target="#b0">[1]</ref>, a problem solving paradigm where the solution is built by looking at examples rather than by using a first-principle knowledge representation.</p><p>The Analytical Hierarchy Process (AHP) <ref type="bibr" target="#b24">[25]</ref> can be considered the reference method among those which adopt a case-based driven strategy. In this technique the ranking criteria are defined through an assessment of the relative priority between a couple of requirements considered all the possible pairs of requirements. This becomes impractical as soon as the number of requirements increases and scalability problems limit severely the applicability of this technique.</p><p>A straightforward remedy may consist in reducing the amount of elicited pairs. Current solutions to scalability issues tend to define heuristics for supporting the choice of when the pairwise elicitation process can be stopped.</p><p>We propose an alternative strategy that aims at learning the prioritization criteria making a ranking hypothesis for the unknown pairs. We show that machine learning techniques can be effective in dealing with the scalability problem by providing an accurate approximation of the final ranking within a limited elicitation effort. Approximation does not necessarily mean poor quality results. A qualitative description of this framework and a first experimental evidence of its effectiveness has been presented in <ref type="bibr" target="#b3">[4]</ref>.</p><p>Our goal in this paper is twofold. First, we give a formal description of the framework and point out its main differences with case-based approaches using the AHP technique. Second, we describe a set of experimental evaluations which intend to characterize the effectiveness of our approach with respect to AHP based approaches when considering large set of requirements. In this analysis we take into account also state-of-the-art solutions to the AHP scalability problem.</p><p>The experimental results prove that in average our approach outperforms AHP with respect to the trade-off between expert elicitation effort and the requirement prioritization accuracy.</p><p>The paper is structured as follows. In Section 2, we describe in details our case-based prioritization framework and the referred machine learning techniques. In Section 3, we recall briefly how an AHP-based process looks like and recall the stopping rule technique that has been proposed as a solution to the scalability problem in AHP. In Sections 4 and 5, we describe the experimental evaluations and discuss their results. Related work are presented in Section 6 and conclusion are given in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Prioritization Methodology</head><p>We recently proposed a novel framework for prioritizing requirements <ref type="bibr" target="#b3">[4]</ref>. It adapts the Case-Based Ranking (CBRanking) methodology described in <ref type="bibr" target="#b5">[6]</ref> which exploits machine learning techniques to reduce the elicitation effort in the prioritization process. The framework rests on an iterative process that can handle single and multiple decision makers (stakeholders) and different criteria (both business goals and technical parameters).</p><p>Figure <ref type="figure" target="#fig_0">1</ref> sketches the basic steps of the prioritization process, where manual elicitation interleaves with machine supported steps.</p><p>The main input to the process is the finite collection of requirements Req = {r 1 , r 2 , . . . , r n } that have to be ranked. The final output of the process is an approximation of the target ranking formulated as a function H : Req → R where r i ≺ r j when H(r i ) &lt; H(r j ).</p><p>The basic process iteration rests on the following three main steps: Pair sampling. It is an automatic procedure which selects a pair (or a sample of pairs) of requirements, (r i , r j ), on the basis of a predefined selection policy which may take into account, information on the currently available rankings.</p><p>Preference elicitation. This step is in charge of the stakeholder. It takes in input a collection of pairs of requirements and it produces in output their ranks. More formally: at a certain iteration τ of the process, a function Φ τ , simply Φ from now on, describes the preferences elicited from the user in terms of pair relations. In particular Φ : Req × Req → {-1, 0, 1} where Φ(r i , r j ) = 1 means that r j be ranked above r i , Φ(r i , r j ) = -1 means that r i be ranked above r j , and Φ(r i , r j ) = 0 indicates that no preference has been given between r i and r j (we assume Φ(r i , r j ) = 0 and Φ(r i , r j ) = -Φ(r j , r i ) for all r i , r j ∈ Req).</p><p>Ranking learning. It takes in input the stakeholder preference Φ, and it computes an approximation of the ranking function H(r) that, while preserving the elicited preferences, tries to make a ranking hypothesis of the unknown pairs. The learning procedures may exploit also available knowledge on the requirements rankings induced by other prioritization criteria (e.g. the cost for the realization of the requirements, the estimated utility) defined on the initial set of requirements. We call this knowledge ranking criteria and denote it as a finite set of m functions F = (f 1 , . . . , f l , . . . , f m ), where f l : Req → R (R = R ∪ {⊥}) and the inequality f l (r i ) &gt; f l (r j ) means that r i is preferred to r j according to the l th criterion, while f l (r) = ⊥ if r is unranked with respect to the l th criterion. The Ranking learning procedure exploits machine learning techniques, as detailed below.</p><p>The final ranking, that is the output of the process represents an approximation of the exact ranking and may become the input to a further iteration of the process. We denote the target ranking with the function K : Req → R where r j is ranked higher than r i by K if K(r j ) &gt; K(r i ).</p><p>Notice that the step of Preference elicitation is usually a manual task; in the off-line simulation this task Prioritization Process Input: the set of requirements Req, previous iteration rankings H(r) Output: the final Ranking H(r) Iteration steps:</p><p>1. Pair sampling (Req, H(Req)); 2. Preference Elicitation ((r i , r j )); 3. Ranking learning (Φ(r i , r j ), F ); is performed by the machine through a sampling of the target ranking function K that is assumed to be given.</p><p>If the result of the learning step is considered enough accurate or the end user has been overloaded, the iteration halts and the latest approximated rank is given as output; otherwise another cycle of the loop is carried on. Notice that the first and the third steps are automated while the second step is in charge of the stakeholder. In the following, for simplicity, we will assume that the preference elicitation is monotonic (i.e. the user does not see the same pair twice).</p><p>To summarize we can conceive the prioritization process as an approximation problem where, given a set of requirements Req = {r i } and a subset of pairwise priority relations Φ τ ⊆ Φ, the challenge is to learn a function H(r) such that ∀r i , r j we have</p><formula xml:id="formula_0">H(r i ) &gt; H(r j ) if K(r i ) &gt; K(r j )</formula><p>where K(r) is the unknown target prioritization criteria. Of course the objective is twofold: to minimize the elicitation effort, while reducing the disagreement between the target (K) and the approximate rank (H).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">The learning algorithm</head><p>The Ranking learning step produces an approximation of a preference structure, exploiting the boosting approach described in <ref type="bibr" target="#b9">[10]</ref>. In the following we give a brief description of the problem that we handle with the boosting approach and of the algorithm.</p><p>The basic concepts, we introduced so far, are the set of requirements, the ranking features, the exact (or target) ranking and the elicitated pairwise preferences. The input to the algorithm are described below.</p><p>• A finite set of requirements Req = {r 1 , . . . , r n }.</p><p>• The ranking criteria F = (f 1 , . . . , f m ).</p><p>• The initial user preferences represented by the function Φ 0 (r i , r j )</p><p>• Related to the Φ we also define a density function D :</p><formula xml:id="formula_1">Req × Req → R such that D(r i , r j ) = γ • max({0, Φ(r i , r j )})</formula><p>setting to 0 all negative entries of Φ; γ is a positive constant chosen in such a way that D is a distribution, satisfying the following normalization property:</p><formula xml:id="formula_2">ri,rj D(r i , r j ) = 1</formula><p>The goal of the learning step is to produce a ranking of all requirements in Req. This ranking is represented in the form of a function H : Req → R. The function H represents the approximated ordering of Req induced by the user preference function Φ using the information from the set of features F ; the objective is to minimize a measure of error called ranking loss rloss, which is defined in the following. Given a pair r i , r j , the pair is said to be crucial if Φ(r i , r j ) &gt; 0, so that the pair receives non-zero weight under D. The algorithm we use has been designed to find an order function H with a small weighted number of crucialpair misorderings, in other words with a small ranking loss rloss D (H) defined as:</p><formula xml:id="formula_3">rloss D (H) = ri,rj D(r i , r j )[[H(r j ) ≤ H(r i )]] = P r (ri,rj )∼D [H(r j ) ≤ H(r i )]</formula><p>where</p><formula xml:id="formula_4">[[H(req j ) ≤ H(req i )]] = 1 if H(req j ) ≤ H(req i ) is true, 0 otherwise.</formula><p>In our framework, the function H is computed by an adaptation of the boosting method that is able to produce highly accurate prediction rules by combining many weak rules which may be moderately accurate; here we refer to the boosting algorithm introduced in <ref type="bibr" target="#b8">[9]</ref>, which is sketched, in pseudocode, in Figure <ref type="figure" target="#fig_1">2</ref>.</p><p>The algorithm RankBoost performs T iterations; it takes as input the initial distribution D and the set of functions F and gives as output the final hypothesis H in the form of a linear combination of partial order functions h t : Req → R with a set of coefficients α = {α 1 , . . . , α t , . . . } (where t is the iteration index).</p><p>Algorithm RankBoost Input: the set of requirements Req = {r 1 , . . . , r i , r j , . . . , r n }, the set of ranking criteria F , the function Φ τ , the initial distribution D Output: the final Hypothesis H(r) begin D 1 = D; For t = 1, . . . , T :</p><formula xml:id="formula_5">h t = W eakLearner(Req; Φ τ , F, D t ) where h t : Req → R; Choose α t , where α t ∈ R; D t+1 (r i , r j ) = Dt(ri,rj ) Zt e αt(ht(ri)-ht(rj))</formula><p>, where The basic iteration t performs the three steps described below.</p><formula xml:id="formula_6">D t+1 : Req × Req → R return H(r) = T t=1 α t h t (r); end.</formula><p>• Compute a partial order h t : Req → R via the function h t = W eakLearner(Req; Φ τ , F, D) of the elements in Req tacking into account the function Φ τ , the ranks induced by the functions in F , and the distribution D t .</p><p>In our experiments we referred to the W eakLearner function described in <ref type="bibr" target="#b8">[9]</ref>; it is a binary classifier that in every iteration t produces a dichotomy on the sets of requirements and defines a precedence relationship among the resulting subsets.</p><p>• Compute a value for the parameter α t . This value is a measure of the accuracy of the partial order h t respect to the final order H.</p><p>• Compute a new distribution D over the set of pairs whose value has been given by the users, which is passed, on the next iteration, to the procedure that computes the partial order h t . The algorithm, in fact, uses the distribution D to emphasize some pairs in Req Φ × Req Φ ; D is computed as in the equation:</p><formula xml:id="formula_7">D t+1 (r i , r j ) = Dt(ri,rj</formula><p>) Zt e αt(ht(ri)-ht(rj )) . In particular at the iteration t a high value for D t+1 assigned to a pair of requirements indicates a great importance that the function h t+1 (so the W eakLearner) orders that pair as indicated by the user.</p><p>The total number of iterations, T , can be fixed a-priori or the algorithm stops when a stable ordering configuration has been found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The AHP prioritization process</head><p>The Analytic Hierarchy Process (AHP) <ref type="bibr" target="#b24">[25]</ref> is a multiple criteria decision making techniques based on a pairwise comparison approach. It has been largely applied in software engineering, for instance in software package and component selection <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>, in COTS evaluation <ref type="bibr" target="#b19">[20]</ref> and in requirements prioritization <ref type="bibr" target="#b13">[14]</ref> .</p><p>From a practical point of view, when using AHP for prioritizing requirements, the first step is the representation of the set of requirements under investigation in a matrix whose rows and columns represent the candidate requirements. Given a prioritization criterion, the second step implements a pairwise comparison process where each element of the matrix<ref type="foot" target="#foot_1">1</ref> are assigned an integer belonging to the interval [1 . . . 9] which represents a qualitative measure of the preference relation between the corresponding requirements (e.g. if the requirement A is "equally important" than requirement B respect to the given criterion, the value 1 is given, if the requirement A is "essentially more important" than requirement B the value 5 is given). When this step has been completed, a total order is synthesized through the computation of a vector of weights that specifies the rank of each requirement.</p><p>In case of multiple criteria, the whole process is repeated for each criterion and a further step is required, that is the synthesis of a global rank based on a weighted composition of the different criteria orderings is computed. The weights are derived using an analogous preference elicitation process performed on a matrix where rows and columns represent the different criteria.</p><p>Among the main, well known, limits of AHP, the growth of the number of comparisons needed as long as the number of candidate requirements increases. Notice that even with a small set of requirements, say 10, it is necessary to elicit 45 pairwise preferences, for each criterion 2 .</p><p>In Saaty <ref type="bibr" target="#b24">[25]</ref> is proposed a technique to handle this scalability problem by introducing the so called "dominance hierarchy" whose top levels elements refer to criteria and the lowest level correspond to the requirements. Intuitively, following the dominance hierarchy, the general prioritization problem is decomposed into sub-problems allowing for a reduction of the elicitation effort, but, at the same time introducing a strong bias. In fact the dominance hierarchy reflects the a-priori knowledge on the relative importance of the criteria, independently from the current candidate requirements.</p><p>A recent approach to handle the AHP scalability problem in prioritizing requirements has been proposed in <ref type="bibr" target="#b13">[14]</ref>. This approach rests on the exploitation of the local stopping rule technique proposed in <ref type="bibr" target="#b10">[11]</ref>. This technique allows to determine when new pairwise comparisons are no longer needed.</p><p>More precisely, adopting the notation introduced in the previous section, we can define the function K AHP that represents the correct ranking and the function H AHP (req) θ that represents the ranking computed by the AHP algorithm at a certain stage θ of the pairwise elicitation step (i.e. the second step of the AHP process described above). The stopping-rule can be represented by the expression (1)</p><formula xml:id="formula_8">(|H(r i ) θ-1 -H(r j ) θ | &lt; a) (<label>1</label></formula><formula xml:id="formula_9">)</formula><p>where a is a positive real number.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Empirical Evaluation</head><p>In this section we present two types of experimental evaluation aiming at characterizing the effectiveness of our approach for a large set of requirements: the first consists in comparing the CBRanking approach to AHP when prioritizing requirements sets of increasing cardinality; the second aims at verifying the applicability and the effectiveness of the stopping rule technique, briefly recalled in Section 3, a state of the art solution to overcoming the AHP scalability problem.</p><p>Both experimental evaluations rest on a simulation of the prioritization process for a given target ranking, in other words we assume that a simulated decision maker knows the preference function K for a predefined set of requirements, or, equivalently the correct prioritization criterion. More precisely, a simulation of the prioritization process can be accomplished as follows. First a subset of pairs (req i , req j ) is selected from the cartesian product 2 The number of comparison required goes as n(n -1)/2, where n is the number of candidates Req×Req with the restriction that i = j and (req i , req j ) = (req j , req i ). In particular, in the CBRanking experiments, the initial subset of pairs has cardinality n/2 and it is chosen in order to guarantee that each requirement is a member of at least one pair in the subset, while for AHP a spanning tree (composed by n -1 pairs) is chosen, as described in <ref type="bibr" target="#b14">[15]</ref>. The following step, related to preference elicitation, simulates the user behavior retrieving the Φ(req i , req j ) value by sampling directly the given preference function K. For simplicity we restrict the simulation to a monotonic behavior and we assume that a decision maker acts without giving inconsistent answers during the process. The third step, invokes the RankBoost algorithm to produce an estimate of the proper prioritization, H(req), fully defined over the set Req resulting in an approximated priority rank.</p><p>We call this experimental approach off-line empirical evaluation, in contrast to the on-line approach which involve human decision-makers. The usefulness of the off-line experimentation when setting up a set of on-line experiments have been presented in <ref type="bibr" target="#b3">[4]</ref> where also a set of on-line tests aiming at measuring the accuracy of the final ranking corresponding to a given elicitation effort, have been discussed.</p><p>Notice that the complexity of a prioritization process it is not directly dependent on the choice of a specific preference function K but to the relationship that holds between a given preference function K and the set of ranking features F . As illustrated in <ref type="bibr" target="#b4">[5]</ref> it is possible to recognize four different types of relationships that correspond respectively to an increasing prioritization complexity: isotonic, anti-tonic, non-monotonic, non-projective. According to this considerations, we generated a set of prioritization problems of different degrees of difficulty.</p><p>The first experimental evaluation has been conducted on sets of requirements with cardinality n equal to 10, 25, 50, 100 respectively. On a given set of requirements, we run two prioritization processes, one based on our approach, the other on AHP. In both processes we computed the the disagreement corresponding to a given number of elicitated pair preferences. That is, given a pair (r i , r j ) we introduce the measure dp(r i , r j ) which assumes the value 1 if the functions H, K gives different ordering relationships for that pair, and 0 otherwise, namely:</p><formula xml:id="formula_10">dp(r i , r j ) =    1 if (H(r i ) &lt; H(r j ) ∧ K(r i ) &gt; K(r j )) ∨(H(r i ) &gt; H(r j ) ∧ K(r i ) &lt; K(r j )) 0 otherwise</formula><p>(2) The total disagreement(H, K) of the ordering function H respect to the target ranking K is then defined in the formula <ref type="bibr" target="#b2">(3)</ref>.  The values plotted in Figure <ref type="figure" target="#fig_2">3</ref>, have been obtained as the average of the disagreement values measured on ten runs. On the x axis is shown the percentage of requirements pair preferences that have been elicited (which is a measure of the elicitation effort). Notice that 5% of requirements pairs corresponds to the cardinality of the set of requirements. This corresponds to the amount of evaluations that are usually requested by methods that are linearly related to the number of requirements (within the hypothesis of monotonicity).</p><formula xml:id="formula_11">disagreement(H, K) = 1 n(n -1) i,j,i =j</formula><p>In The second set of experiments focuses on the application of the local stopping rule briefly described in Section 2, that have been used both with AHP and with our approach.</p><p>A critical problem when using this technique is how to choose a-priori, the right value for the parameter a, having in mind the precise value for the maximum elicitation effort at which the process should be stopped.</p><p>The input to this second type of experiments is a set of requirements, a value for K and a value for a. The output is a measure of the disagreement computed for the elicited pairs number at which the process stop.</p><p>In Figure <ref type="figure">6</ref> are shown some results. In particular the diagram represents the results over twenty AHP runs, on the same set of 25 requirements and for a = 0.001. Every point in the diagram represents the final value of one of these twenty runs.</p><p>The stopping rule technique has been adapted for our methodology and values for the parameter a CBR for our approach which may be compared to those for a AHP has been found experimentally.</p><p>The results obtained running our approach with the stopping rule, on the same set of requirements, and with a comparable value for the stopping parameter a are depicted in the same plot.</p><p>Note that other values for parameter a have been tested giving analogous results. The choice of showing the results for a AHP = 0.001 and respectively for a CBR = 0.5 is because they cover a region of the elicitation effort from 10% to 30%, which is a region of interest with respect to the previously discussed experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>The first set of experiments allows a deep analysis of the trade-off between the elicitation effort and the ranking accuracy, in the two approaches, namely CBRanking and AHP, and provides an empirical evidence that the first uniformly outperforms the second.</p><p>First, the CBRanking framework results more effective especially for lower values of elicited pairs, as shown in the plots depicted in Figure <ref type="figure" target="#fig_2">3,</ref><ref type="figure" target="#fig_3">4,</ref><ref type="figure">5</ref>, where, for instance the improvement in the approximation accuracy obtained with the CBRanking framework with respect to that obtained with AHP, at 5% of the elicited pairs is greater then the relative improvement measured at 10% of the elicited pairs. This is particularly remarkable when we are considering large numbers of requirements since, in practice, only a small portion of pairs can be manually elicited. For example, the 10% pairwise analysis of 200 requirements requires to perform around 2000 comparisons.</p><p>Moreover, if we focus our attention to the behaviour of the two techniques for low elicitation effort (the most interesting case for practical approaches, as claimed above) we can see that the improvement of CBRanking with respect to AHP increases when considering larger and larger sets of requirements. Considering the approximated ranking obtained with an elicitation effort of 5% of pairs, it is characterized by a 20% of disagreement in the case of 25 requirements, by a 15% of disagreement in the case of 50 requirements and by a a 10% of disagreement in the case of 100 requirements (see Figure <ref type="figure" target="#fig_2">3</ref>, Figure <ref type="figure" target="#fig_3">4</ref> and Figure <ref type="figure">5</ref> respectively). This can be considered a relevant empirical evidence of the effectiveness of the CBRanking framework in dealing with the scalability issue. During the experiments the effectiveness of the spanning tree initialization strategy used in AHP have been tested also in our framework. The results show that the adoption of this strategy does not produce a faster convergence of the RankBoost algorithm.</p><p>The results discussed so far concern with the average behaviour analysis. Since the % disagreement measured with the CBRanking technique has a greater variance with respect to that measured with AHP, the results of CBRanking can be much more better. The analysis of complexity of a requirement prioritization process is out of the scope of this paper and is discussed in details in <ref type="bibr" target="#b4">[5]</ref>; here it is important to notice that one of the source of complexity in the CBRanking method, other than the complexity related to number of requirements, is the relationship between the target ranking K and the domain knowledge represented by the ranking criteria in F ; they can give effective support to the ranking process in the case they specify a ranking close to the target ranking. Nevertheless it is important to remark, even though not depicted in the plots, that the worst behaviour of CBRanking performs at least as AHP.</p><p>The successful results of CBRanking can be extended to the analysis of stopping-rule. The achievement is twofold: better average accuracy and lower effort variance. The first result is of course a straightforward consequence of the previous achievement. Since CBRanking outperforms AHP, if we apply a policy to reduce the elicitation effort the final results will be related to the general behaviour of the two techniques.</p><p>A meaningful additional result is concerned with the variance of elicitation effort. The behaviour of stoppingrule, as technique to reduce the elicitation effort, is strongly context sensitive. The final outcome is an high variance of the numbers of pairs that have to be elicited. For example, in our experiment with 25 requirements depicted in Figure <ref type="figure">6</ref>, the percentage of elicitation effort spans from 10% to 30% for 10 iterations of the same problem. For the same experiment the variance of CBRanking is half with respect to AHP: the values are in the range between 10% and 20%. It is important to notice that for both the methods the results show a high variance with respect to the disagreement obtained when the process is stopped by the rule, so, especially for AHP, the low effort in the elicitation process is not balanced with the accuracy of the final ranking.</p><p>The behaviour of CBRanking seems to get much more effective the use of stopping-rule. Not only CBRanking halves the variance of elicitation effort but at the same time it lower the upper bound of the number of pairs that have to be elicited. In our experiment illustrated in Figure <ref type="figure">6</ref>, the worst case of 30% is reduce to 20%. As mentioned in advance, reducing the elicitation effort is dual problem of scaling with respect to the number of requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Related work</head><p>In this paper we focused on how to deal with the scalability problems that arise in managing the prioritization of a large number of requirements. Among the relevant approaches that face these issues, we already mentioned <ref type="bibr" target="#b14">[15]</ref> which proposes the concept of stopping-rule to reduce the pairwise elicitation effort. This rule allows to define a threshold on the variation of the estimated requirements ordering under which new comparisons are no longer needed. In Section 5 we pointed out critical aspects related to the fact that the value of the threshold has to be chosen a-priori, and showed how our approach can limit them.</p><p>Considering the requirements prioritization in a more general perspective, in <ref type="bibr" target="#b7">[8]</ref> we can find a discussion of the possible purpose and benefits, challenges and risks that arises during the process of requirement prioritization as well as a classification of currently used techniques. Among them, of particular interest for our work are the following. The Cost-Value approach, described in <ref type="bibr" target="#b13">[14]</ref>, exploits the AHP technique for the evaluation of requirements against two main criteria: business value, that is the ability of a requirement to contribute to the customer satisfaction, and cost of implementation. The result is then plotted in a costvalue diagram that shows in a visual way the relative position of the requirements. This composition of the two requirements rankings offers a rather effective method for classifying the requirements, nevertheless the method suffers from all the limits of the AHP technique and in particular those related to the scalability.</p><p>In <ref type="bibr" target="#b20">[21]</ref> is proposed another AHP-based methodology named Soft Requirements Negotiator (SRN). The SRN method aims at addressing the incompleteness and uncertainty of the initial set of requirements to be prioritized and for this reason integrates AHP, multi-criteria approaches and simulation techniques for the estimation of quantitative ranking features. Multi-criteria techniques are exploited with the attempt to deal with incomplete information, and in particular to support the selection of balancing "for" and "against" arguments for a given requirement.</p><p>Other studies on basic multi-criteria decision making methods to be used during requirements prioritization are <ref type="bibr" target="#b22">[23]</ref>, SMART <ref type="bibr" target="#b6">[7]</ref>, Quality Function Deployment (QFD) <ref type="bibr" target="#b2">[3]</ref>, the Multi-criteria Preference Analysis Requirements Negotiation (MPARN) <ref type="bibr" target="#b11">[12]</ref>, and Quantitative WinWin <ref type="bibr" target="#b23">[24]</ref>.</p><p>Main limits of the above mentioned approaches are related to the strong assumptions which are inherent to the decision making techniques they adopt, such as, the completeness and certainty of the set of requirements to be evaluated and the plausibility of a rating scale based on discrete categories. Moreover most of them typically do not scale unless the requirements are previously grouped in some manner. This considerations <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b25">26]</ref> motivated the development of methodologies which are less accurate, but more easy-to use and less time consuming that can be preferred in industrial practice. For instance, in <ref type="bibr" target="#b21">[22]</ref> is described an experimental study where an AHP based approach is compared to an approach based on Planning Game, a technique used in Extreme Programming <ref type="bibr" target="#b15">[16]</ref>, showing that the second approach was preferred.</p><p>Other works propose the integration of different decision making techniques as well as methods for the identification of relevant criteria for requirements prioritization derived from other disciplines, (e.g. portfolio-based reasoning) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b25">26]</ref>.</p><p>Concerning the specific techniques that has been exploited in our CBRanking framework, in <ref type="bibr" target="#b12">[13]</ref> are proposed interesting modifications to the boosting algorithms, and in particular to the Ada Boost algorithm <ref type="bibr" target="#b9">[10]</ref>. A new algorithm has been defined in order to cope with the problem of overfitting and with the problem of improving the selection of the most promising patterns that are able to approximate the final target ranking; this may result in a better behavior of the algorithm in finding a good approximated solution with reducing the elicitation effort for the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>In this paper we presented in details a novel framework for requirements prioritization, called Case-Based Ranking. Similarly to the AHP process, our framework adopts an elicitation process based on the acquisition of pairwise preferences, differently from AHP it enables a prioritization process even over a large set of requirements, thanks to the exploitation of machine learning techniques that induce requirements ranking approximations from the acquired data.</p><p>The Case-Based Ranking framework has been evaluated with respect to AHP on simulated data. We described this set of tests and discussed the results which shows that our framework is effective in dealing with large sets of requirements. Basically, they prove that in average, our approach outperforms AHP with respect to the trade-off between expert elicitation effort and the requirement prioritization accuracy and that in the worst case, it works as well as AHP technique.</p><p>Current results seems to be promising and we are going to further investigate the framework addressing other issues of requirements prioritization such as the negotiation among the points of view of different stakeholders, the handling of requirements dependencies and of "anytime" prioritization, a relevant issue when new unexpected requirements have to be added. Moreover, in <ref type="bibr" target="#b3">[4]</ref> we addressed the problem of evaluating the effectiveness of the CBRanking method in a real setting. Here an interesting emerging problem is repre-sented by the need of setting up methods for the validation of the experimental results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Basic steps of the prioritization process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. A sketch of the RankBoost algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The plot of disagreement (y-axis) for a set of 25 requirements in AHP and the CBRanking frameworks for an increasing number of elicitated pairs (x-axis).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The plot of disagreement (y-axis) for a set of 50 requirements in AHP and the CBRanking frameworks for an increasing number of elicitated pairs (x-axis).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 ,Figure 5 .Figure 6 .</head><label>356</label><figDesc>Figure 5. The plot of disagreement (y-axis) for a set of 100 requirements in AHP and the CBRanking frameworks for an increasing number of elicitated pairs (x-axis).</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Proceedings of the 2005 13th IEEE International Conference on Requirements Engineering (RE'05)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>More precisely, half of the matrix values is elicited while the other half is computed by symmetry.Proceedings of the</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2005" xml:id="foot_2"><p>13th IEEE International Conference on Requirements Engineering (RE'05)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>Proceedings of the 2005 13th IEEE International Conference on Requirements Engineering (RE'05) 0-7695-2425-7/05 $20.00 © 2005 IEEE</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Case-based reasoning: Foundational issues, methodological variations, adn system approaches</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aamodt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Communications</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="59" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SWEBOK -Guide to the Software Engineering Body of Knowledge</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dupuis</surname></persName>
		</author>
		<ptr target="http://www.swebok.org" />
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Quality Function Deployment: Integrating Customer Requirements into Product Design</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Akao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Productivity Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Supporting the Requirements Prioritization Process. A Machine Learning approach</title>
		<author>
			<persName><forename type="first">P</forename><surname>Avesani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bazzanella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Susi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 16th International Conference on Software Engineering and Knowledge engineering (SEKE 2004)</title>
		<meeting>16th International Conference on Software Engineering and Knowledge engineering (SEKE 2004)<address><addrLine>Banff, Alberta, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>KSI press</publisher>
			<date type="published" when="2004-06">June 2004</date>
			<biblScope unit="page" from="306" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Exploiting Domain Knowledge in Requirements Prioritization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Avesani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bazzanella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Susi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 17th International Conference on Software Engineering and Knowledge Engineering (SEKE 2005)</title>
		<meeting>of the 17th International Conference on Software Engineering and Knowledge Engineering (SEKE 2005)<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>KSI press</publisher>
			<date type="published" when="2005-07">July 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Case-Based Ranking for Decision Support Systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Avesani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Susi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCBR 2003, number 2689 in LNCS</title>
		<meeting>ICCBR 2003, number 2689 in LNCS</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="35" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Smarts and smarter: Improved simple methods for multiattribute utility measurement</title>
		<author>
			<persName><forename type="first">W</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Baron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="306" to="325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Prioritizing Requirements</title>
		<author>
			<persName><forename type="first">D</forename><surname>Firesmith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Object Technology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="36" to="47" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An Efficient Boosting Algorithm for Combining Preferences</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 15th International Conference on Machine Learning</title>
		<meeting>15th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Short Introduction to Boosting</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Japan. Soc. for Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="771" to="780" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Incomplete Pairwise Comparisons in the Analitic Hierarchy Process</title>
		<author>
			<persName><forename type="first">P</forename><surname>Harker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Modeling</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="837" to="848" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-Criteria Preference Analysis for Systematic Requirements Negotiation</title>
		<author>
			<persName><forename type="first">H</forename><surname>In</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rodgers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">26th Annual International Computer Software and Applications Conference</title>
		<meeting><address><addrLine>Oxford, England</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-08">August 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A New Boosting Algorithm Using Input-Dependent Regularizer</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Machine Learning (ICML 2003)</title>
		<meeting>the 20th International Conference on Machine Learning (ICML 2003)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2003-08">August 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Software requirements prioritizing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Karlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRE&apos;96</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improved Practical Support for Large Scale Requirements Prioritizing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ryan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Requirements Engineering</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="51" to="67" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Extreme Programming Explained</title>
		<author>
			<persName><forename type="first">K</forename><surname>Beck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Otso: A systematic process for reusable software component selection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kontio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Integrating Decision-Making Techniques into Requirements Engineering</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A M</forename><surname>Maiden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gizikis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K O</forename><surname>Clause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of REFSQ&apos;02 workshop in RE&apos;02 Conference</title>
		<meeting>REFSQ&apos;02 workshop in RE&apos;02 Conference<address><addrLine>Essen, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The fundamentals of prioritising requirements</title>
		<author>
			<persName><forename type="first">F</forename><surname>Moisiadis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">System Engineering, Test and Evaluation Conference</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">COTS Evaluation Using Desmet Methodology &amp; Analytic Hierarchy Process (AHP)</title>
		<author>
			<persName><forename type="first">D</forename><surname>Morera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the PROFES 2002 conference</title>
		<meeting>the PROFES 2002 conference<address><addrLine>Rovaniemi, Finland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002-12">December 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Requirements Negotiation under Incompleteness and Uncertainty</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ngo-The</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ruhe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Engineering Knowledge Engineering 2003 (SEKE 2003)</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-07">July 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An industrial case study on distributed prioritisation in market-driven requirements engineering for packaged software</title>
		<author>
			<persName><forename type="first">B</forename><surname>Regnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Host</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Dag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Beremark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hjelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Requirements Engineering</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">B</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bouyssou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aide Multicritère à la Decision: Methods et Cas. Economica</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<pubPlace>Paris</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Quantitative winwin -a quantitative method for decisione support in requirements negotiation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ruhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eberlein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pfahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 14th International Conference on Software Engineering and Knowledge Engineering (SEKE&apos;02)</title>
		<meeting>14th International Conference on Software Engineering and Knowledge Engineering (SEKE&apos;02)<address><addrLine>Ischia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-07">July 2002</date>
			<biblScope unit="page" from="159" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fundamentals of the analytic network process</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Saaty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Symposium on Analytical Hierarchy Process</title>
		<meeting>International Symposium on Analytical Hierarchy Process</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Linking the selection of requirements to market value: A portfolio-based approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sivzattian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nuseibeh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
