<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ESimCSE: Enhanced Sample Building Method for Contrastive Learning of Unsupervised Sentence Embedding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-09-12">12 Sep 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xing</forename><surname>Wu</surname></persName>
							<email>wuxing@kuaishou.com</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Kuaishou Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chaochen</forename><surname>Gao</surname></persName>
							<email>gaochaochen@iie.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liangjun</forename><surname>Zang</surname></persName>
							<email>zangliangjun@iie.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jizhong</forename><surname>Han</surname></persName>
							<email>hanjizhong@iie.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhongyuan</forename><surname>Wang</surname></persName>
							<email>wangzhongyuan@kuaishou.com</email>
							<affiliation key="aff2">
								<orgName type="department">Kuaishou Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Songlin</forename><surname>Hu</surname></persName>
							<email>husonglin@iie.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ESimCSE: Enhanced Sample Building Method for Contrastive Learning of Unsupervised Sentence Embedding</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-09-12">12 Sep 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2109.04380v2[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>SimCSE 1 adopts dropout as data augmentation and encodes an input sentence twice into two corresponding embeddings to build a positive pair. Since SimCSE is a Transformerbased encoder that directly encodes the length information of sentences through positional embeddings, the two embeddings in a positive pair contain the same length information. Thus, a model trained with these positive pairs is biased, tending to consider that sentences of the same or similar length are more similar in semantics. To alleviate it, we apply a simple but effective repetition operation to modify the input sentence. Then we pass the input sentence and its modified counterpart to the pretrained Transformer encoder, respectively, to get the positive pair. Additionally, we draw inspiration from the computer vision community and introduce momentum contrast to enlarge the number of negative pairs without additional calculations. The proposed modifications are applied to positive and negative pairs separately, and build a new sentence embedding method, termed Enhanced SimCSE (ES-imCSE). We evaluate the proposed ESimCSE on several benchmark datasets w.r.t the semantic text similarity (STS) task. Experimental results show that ESimCSE outperforms Sim-CSE by an average Spearman correlation of 2.02% on BERT-base. Our code are available at https://github.com/caskcsg/ESimCSE.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, researchers have proposed using contrastive learning to learn better unsupervised sentence embeddings <ref type="bibr" target="#b34">(Wu et al., 2020;</ref><ref type="bibr" target="#b36">Zhang et al., 2020;</ref><ref type="bibr" target="#b22">Liu et al., 2021;</ref><ref type="bibr" target="#b15">Gao et al., 2021;</ref><ref type="bibr" target="#b35">Yan et al., 2021)</ref>. Contrastive learning aims to learn effective sentence embeddings based on the assumption Length Diff Avg. Similarity Diff &gt; 3 16.34 ≤ 3</p><p>18.18 (+1.84) that effective sentence embeddings should bring similar sentences closer while pushing away dissimilar ones. It generally uses various data augmentation methods <ref type="bibr" target="#b28">(Shleifer, 2019;</ref><ref type="bibr">Wei and Zou, 2019;</ref><ref type="bibr" target="#b33">Wu et al., 2019)</ref> to generate different views for each sentence randomly, and assumes a sentence is semantically more similar to its augmented counterpart than any other sentence. Among these methods, the most representative one is SimCSE <ref type="bibr" target="#b15">(Gao et al., 2021)</ref>, which performs on par with previously supervised counterparts. SimCSE implicitly hypothesizes dropout acts as a minimal data augmentation method. Specifically, SimCSE composes N sentences in a batch and feeds each sentence to the pre-trained BERT twice with two independently sampled dropout masks. Then the embeddings derived from the same sentence constitute a "positive pair", while those derived from two different sentences constitute a "negative pair".</p><p>Using dropout as a minimal data augmentation method is simple and effective, but there is a weak point. SimCSE models are built on Transformer blocks, which will encode a sentence's length information through positional embeddings. In a positive pair, two embeddings are derived from the same sentence to contain the same length information. In contrast, in a negative pair, two embeddings in a negative pair are derived from two different sentences and generally contain different length information. Therefore, positive and negative pairs are different in their length information, acting as a feature to distinguish them. The semantic simi-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text</head><p>Similarity original sentence I like this apple because it looks so fresh and it should be delicious.</p><p>1.0 random insertion I don't like this apple because but it looks so not fresh and it should be dog delicious.</p><p>0.69 random deletion I like this apple because it looks so fresh and it should be delicious. 0.32 word repetition I like like this apple because it looks so so fresh and and it should be delicious.</p><p>0.99 word repetition I I like this apple apple because it looks looks so fresh fresh and it should be delicious delicious. larity model trained with these pairs can be biased, which probably considers that two sentences of the same or similar lengths are more similar in semantics. To confirm it, we evaluate on seven standard semantic textual similarity datasets with the SimCSE-BERT base model published by <ref type="bibr" target="#b15">(Gao et al., 2021)</ref>. We partition each STS test set into two groups based on whether the sentence pairs' length difference is ≤ 3. We calculate the similarity differences between the model predictions and the normalized ground truths for each group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0.98</head><p>As shown in Table <ref type="table" target="#tab_0">1</ref>, the average similarity difference of seven datasets is higher when the length difference is ≤ 3, which verifies our assumption.</p><p>Comparison details on each dataset can refer to Table <ref type="table" target="#tab_6">7</ref>.</p><p>To alleviate this problem, we propose a simple but effective enhancement method to SimCSE. For each positive pair, we expect to change the length of a sentence without changing its semantic meaning. Existing methods to change the length of a sentence generally use random insertion and random deletion. However, inserting randomly selected words into a sentence may introduce extra noise, which will probably distort the meaning of the sentence; deleting keywords from a sentence will also change its semantics substantially. Such operations are detrimental to SimCSE learning, which is also discussed in a contemporaneous work <ref type="bibr" target="#b12">(Chuang et al., 2022)</ref>. Therefore, we propose a safer method, termed "word repetition", which randomly duplicates some words in a sentence. For example, as shown in Table <ref type="table" target="#tab_1">2</ref>, either random insertion or random deletion may generate a sentence that deviates far from the meaning of the original sentence. On the contrary, the method of "word repetition" maintains the meaning of the original sentence quite well.</p><p>Apart from the optimization above for positive pairs construction, we further explore how to optimize the construction of negative pairs. Since contrastive learning is carried out between positive pairs and negative pairs, theoretically, more negative pairs can lead to a better comparison between the pairs <ref type="bibr" target="#b11">(Chen et al., 2020)</ref>. And thus, a potential optimization direction is to leverage more negative pairs, encouraging the model towards more refined learning. However, according to <ref type="bibr" target="#b15">(Gao et al., 2021)</ref>, larger batch size is not always a better choice. For example, for the SimCSE-BERT base model, the optimal batch size is 64, and other settings of the batch size will lower the performance. Therefore, we tend to figure out how to expand the negative pairs more effectively. In the community of computer vision, to alleviate the GPU memory limitation when expanding the batch size, a feasible way is to introduce the momentum contrast <ref type="bibr" target="#b16">(He et al., 2020)</ref>, which is also applied to natural language understanding <ref type="bibr" target="#b14">(Fang et al., 2020)</ref>. Momentum contrast allows us to reuse the encoded embeddings from the immediate preceding mini-batches to expand the negative pairs by maintaining a queue. It always enqueues the sentence embeddings of the current mini-batches and meanwhile dequeues the "oldest" ones. As the enqueued sentence embeddings come from the preceding mini-batches, we keep a momentum updated encoder by taking the moving average of its parameters and use the momentum encoder to generate enqueued sentence embeddings. Note that, we turn off dropout when using the momentum encoder, which can narrow the gap between training and prediction.</p><p>The above two optimizations are proposed separately for building positive and negative pairs. We finally combine both with SimCSE, termed Enhanced SimCSE (ESimCSE). We illustrate the schematic diagram of ESimCSE in Figure <ref type="figure" target="#fig_0">1</ref>. The proposed ESimCSE is evaluated on the semantic Our contributions can be summarized as follows:</p><p>• We observe that SimCSE constructs each positive pair with two sentences of the same length, which can bias the learning process.</p><p>We propose a simple but effective "word repetition" method to alleviate the problem.</p><p>• We propose to use the momentum contrast method to increase the number of negative pairs involved in the loss calculation, which encourages the model towards more refined learning.</p><p>• We conduct extensive experiments on several benchmark datasets w.r.t semantic text similarity task. The experimental results well demonstrate that both proposed optimizations bring improvements to SimCSE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background: SimCSE</head><p>Given a set of paired sentences</p><formula xml:id="formula_0">x i , x + i m i=1</formula><p>, where</p><p>x i and x + i are semantically related and will be referred to positive pairs. The core idea of SimCSE is to use identical sentences to build the positive pairs, i.e., x + i = x i . Note that in Transformer, there is a dropout mask placed on fully-connected layers and attention probabilities. And thus, the key ingredient is to feed the same input x i to the encoder twice by applying different dropout masks z i and z + i and output two separate sentence embeddings to build a positive pair as follows:</p><formula xml:id="formula_1">h i = f θ (x i , z i ) , h + i = f θ x i , z + i (1)</formula><p>With h i and h + i for each sentence in a mini-batch with batch size N , the contrastive learning objective w.r.t x i is formulated as follows,</p><formula xml:id="formula_2">i = − log e sim(h i ,h + i )/τ N j=1 e sim(h i ,h + j )/τ (2)</formula><p>where τ is a temperature hyperparameter and sim (h i , h i ) is the similarity metric, which is typically the cosine similarity function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Enhanced SimCSE</head><p>In this section, we first introduce the word repetition method to construct better positive pairs. Then we introduce the momentum contrast method to expand negative pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Word Repetition</head><p>The word repetition mechanism randomly duplicates some words/sub-words in a sentence. Here we take sub-word repetition as an example. Given a sentence s, after processing by a sub-word tokenizer, we get a sub-word sequence x = {x 1 , x 2 , ..., x N }, N being the length of sequence.</p><p>We define the number of repeated tokens as</p><formula xml:id="formula_3">dup_len ∈ [0, max(2, int(dup_rate * N ))] (3)</formula><p>where dup_rate is the maximal repetition rate, which is a hyperparameter. Then dup_len is a randomly sampled number in the set defined above, which will introduce more diversity when extending the sequence length. After dup_len is determined, we use uniform distribution to randomly select dup_len sub-words that need to be repeated from the sequence, which composes the dup_set as follows,</p><formula xml:id="formula_4">dup_set = unif orm([1, N ], num = dup_len) (4) For example, if the 1st sub-word is in dup_set, then sequence x becomes x + = {x 1 , x 1 , x 2 , ..., x N }.</formula><p>And different from SimCSE which passes x to the pre-trained BERT twice, E-SimCSE passes x and x + independently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Momentum Contrast</head><p>The momentum contrast allows us to reuse the encoded sentence embeddings from the immediate preceding mini-batches by maintaining a queue of a fixed size. Specifically, the embeddings in the queue are progressively replaced. When the output sentence embeddings of the current mini-batch is enqueued, the "oldest" ones in the queue are removed if the queue is full. Note that we use a momentum-updated encoder to encode the enqueued sentence embeddings. Formally, denoting the parameters of the encoder as θ e and those of the momentum-updated encoder as θ m , we update θ m in the following way,</p><formula xml:id="formula_5">θ m ← λθ m + (1 − λ)θ e (5)</formula><p>where λ ∈ [0, 1) is a momentum coefficient parameter. Note that only the parameters θ e are updated by back-propagation. And here we introduce θ m to generate sentence embeddings for the queue, because the momentum update can make θ m evolve more smoothly than θ e . As a result, though the embeddings in the queue are encoded by different encoders (in different "steps" during training), the difference among these encoders can be made small.</p><p>With sentence embeddings in the queue, the loss function of ESimCSE is further modifed as follows,</p><formula xml:id="formula_6">i = − log e sim(h i ,h + i )/τ N j=1 e sim(h i ,h + j )/τ + M m=1 e sim(h i ,h + m) /τ</formula><p>(6) where h + m is denotes a sentence embedding in the momentum-updated queue, and M is the size of the queue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Setup</head><p>Our experimental language is English. For a fair comparison, our experimental setup mainly follows SimCSE. We use 1-million sentences randomly drawn from English Wikipedia for training<ref type="foot" target="#foot_0">2</ref> . The semantic textual similarity task measures the capability of sentence embeddings, and we conduct our experiments on seven standard semantic textual similarity (STS) datasets. STS12-STS16 datasets <ref type="bibr" target="#b7">(Agirre et al., 2012</ref><ref type="bibr" target="#b8">(Agirre et al., , 2013</ref><ref type="bibr" target="#b4">(Agirre et al., , 2014</ref><ref type="bibr" target="#b3">(Agirre et al., , 2015</ref><ref type="bibr" target="#b5">(Agirre et al., , 2016) )</ref> do not have train or development sets, and thus we evaluate the models on the development set of STS-B <ref type="bibr" target="#b10">(Cer et al., 2017)</ref> to search for better settings of the hyper-parameters. The SentEval toolkit<ref type="foot" target="#foot_1">3</ref> is used for evaluation, and Spearman correlation coefficient<ref type="foot" target="#foot_2">4</ref> is used to report the model performance. All the experiments are conducted on Nvidia 3090 GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training Details</head><p>We start from pre-trained checkpoints of BERT(uncased) or RoBERTa(cased) using both the base and the large versions, and we add an MLP layer on top of the [CLS] representation to get the sentence embedding. We implement ESimCSE based on Huggingface's transformers package<ref type="foot" target="#foot_3">5</ref> . We train our models for one epoch using the Adam optimizer with the batch size = 64 and the temperature τ = 0.05 in Eq. ( <ref type="formula">3</ref>). The learning rate is set as 3e-5 for ESimCSE-BERT base model and 1e-5 for other models. The dropout rate is p = 0.1 for base models, p = 0.15 for large models. For the momentum contrast, we empirically choose a relatively large momentum λ Table <ref type="table">3</ref>: Sentence embedding performance on 7 semantic textual similarity (STS) test sets. ♣ : results from official published model by <ref type="bibr" target="#b15">(Gao et al., 2021)</ref>.♥ : results from <ref type="bibr" target="#b35">(Yan et al., 2021)</ref>. ♠ : results from <ref type="bibr" target="#b19">(Kim et al., 2021)</ref>. ♦ : results from <ref type="bibr" target="#b21">(Li et al., 2020)</ref>. : results are reproduced and reevaluated by <ref type="bibr" target="#b15">(Gao et al., 2021)</ref>. : results from <ref type="bibr" target="#b22">(Liu et al., 2021)</ref> . = 0.995. In addition, following SimCSE's code, we evaluate the model every 125 training steps on the development set of STS-B and keep the best checkpoint for the final evaluation on test sets. We use sub-word repetition instead of word repetition, further discussed in the ablation study section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Main Results</head><p>Table <ref type="table">3</ref> shows the models' performance on seven semantic textual similarity (STS) test sets. We mainly select SimCSE for comparison, since it is the current state-of-the-art and shares the same setting as our approach. In addition, we also use IS-BERT <ref type="bibr" target="#b36">(Zhang et al., 2020)</ref>, CT-BERT <ref type="bibr" target="#b9">(Carlsson et al., 2021)</ref>, ConSERT <ref type="bibr" target="#b35">(Yan et al., 2021)</ref>, SG-OPT <ref type="bibr" target="#b19">(Kim et al., 2021)</ref>, BERT-flow <ref type="bibr" target="#b21">(Li et al., 2020)</ref>, Mirror-BERT <ref type="bibr" target="#b22">(Liu et al., 2021)</ref>    <ref type="bibr" target="#b15">(Gao et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Ablation Study</head><p>This section investigates how different settings affect ESimCSE's performance. All results are compared on BERT base scale models and are evaluated on the development set of STS-B unless otherwise specified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">The Importance of Word Repetition and Momentum Contrast</head><p>We explore how much improvement it can bring to SimCSE when only using word repetition or momentum contrast. As shown in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Effect of Sentence-Length-Extension Method</head><p>In addition to sub-word repetition, we also explore three other methods to increase sentence length:</p><p>• Word Repetition is similar to sub-word repetition, except that the repetition operation occurs before tokenization. For example, given a word "microbiology", word repetition will produce "microbiology microbiology", while sub-word repetition will produce "micro micro ##biology" or "micro ##biology ##biology".</p><p>• Inserting Stop-words inserts a random stopword after the selected word instead of repeating the selected word.</p><p>• Inserting [MASK] inserts a [MASK] token after the selected word. We can regard [MASK] as a dynamic context-compatible word placeholder.</p><p>• Inserting Masked Prediction inserts a [MASK] token after the selected word and uses the masked language model to predict the top-1 substitution. The substitution is used to replace the inserted [MASK] token.</p><p>As shown in Table <ref type="table">5</ref>, sub-word repetition achieves the best performance, and word repetition can also bring a good improvement, which shows that more fine-grained repetition can better alleviate the bias brought by the length difference of positive pairs. Inserting [MASK] can also improve slightly, but inserting stop words will decrease the effect.</p><p>Inserting masked prediction also brings a good improvement, but this method requires a pre-trained masked language model to predict replacements, bringing high additional computational overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Batching Sentences of Similar Length in Training</head><p>Apart from sentence-length-extension methods, we explore whether batching sentences of similar length in training will alleviate the bias towards identical sequence length in inference. We divide training sentences into buckets by length and batch them within each bucket. We explore two different settings:</p><p>• We divide the training set into two coarsegrained buckets based on whether the sentence length is greater than buc_len, where buc_len ∈ [3, 8];</p><p>• We divide the training set by sentence length into 6 fine-grained buckets: {≤ 3, 4, 5, 6, 7, ≥ 8}, which we use buc_len = 3 ∼ 8 for short.</p><p>We list the experimental results in Table <ref type="table" target="#tab_5">6</ref>. Dividing the training set into buckets does not bring significant improvements and even decreases in some settings. We believe that after being divided into buckets, shuffle can only be performed within a bucket, leading to an insufficient comparison in contrastive learning. In contrast, the effect of word repetition is much better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">The Relationship between The Similarity and Length Difference</head><p>We further explore the relationship between the similarity and length difference of sentence pairs on <ref type="bibr">ESimcSE, compared</ref>   on whether the sentence pairs' length difference is ≤ 3. Then we calculate the similarity differences between the model predictions and the normalized ground truths for each group. As listed in Table <ref type="table">ESimCSE</ref> significantly reduces the average similarity difference gap between &gt;3 and ≤ 3, from 1.84 to 0.71, alleviating the learning bias we mentioned in the Introduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Will Word Repetition Bring New Bias ?</head><p>We further explore whether word repetition will mislead the model to be more inclined to consider sentences with repeated overlaps are more similar.</p><p>We conduct a detection experiment on wiki data with the following settings:</p><p>1. We randomly select a sentence as a query, such as q = "I like this apple because it looks very fresh" 2. We use the query to randomly recall a candidate sentence with 13%-17% overlap tokens, such as s1 = "This is a very tall tree and it looks like a giant" 3. We apply the word-repetition operation on the overlap tokens in the candidate sentence and produce a word-repeated sentence, such as s2 = "This this is a very very tall tree and it looks looks like a giant."</p><p>4. We calculate the similarity of &lt;q, s1 &gt;and &lt;q, s2 &gt;and compare them.</p><p>We experiment on 100 different query sentences and calculate their average similarity. in Table <ref type="table" target="#tab_7">8</ref>, compared to the 0.68 increase of the SimCSE, ESimCSE-BERT only increased by 0.05. Therefore, word repetition does not bring a new bias to the learning process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Effect of Hyperparameters</head><p>Repetition Rate To quantitatively study the effect of repetition rate on the model performance, we slowly increase the repetition rate parameter dup_rate from 0.08 to 0.36, with each increase by 0.04. As shown in Table <ref type="table" target="#tab_8">9</ref>, when dup_rate = 0.32, ESimCSE achieves the best performance, a larger or smaller dup_rate will cause performance degradation, which is consistent with our intuition.</p><p>Momentum Queue Size The size of the momentum contrast queue determines the number of negative pairs involved in the loss calculation. We experiment with the queue size equals to different multiples of the batch size. The experimental results are listed in Table <ref type="table" target="#tab_9">10</ref>. The optimal result is reached when the queue size was 2.5 times the batch size. A smaller queue size will reduce the effect. This is intuitive because more negative pairs participate in the loss calculation to compare positive pairs more fully. But a too large queue size also reduces the effect. We guess that is because the negative pairs in the momentum contrast are generated by the past "steps" during training, and a larger queue will use the outputs of more outdated encoder models which are quite different from the current one. And thus that will reduce the reliability of the loss calculation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Unsupervised sentence representation learning has been widely studied. <ref type="bibr" target="#b29">(Socher et al., 2011;</ref><ref type="bibr" target="#b17">Hill et al., 2016;</ref><ref type="bibr">Le and Mikolov, 2014)</ref> propose to learn sentence representation according to the internal structure of each sentence. <ref type="bibr" target="#b20">(Kiros et al., 2015;</ref><ref type="bibr" target="#b23">Logeswaran and Lee, 2018)</ref> predict the surrounding sentences of a given sentence based on the distribution hypothesis. <ref type="bibr" target="#b25">(Pagliardini et al., 2017)</ref> propose Sent2Vec, a simple unsupervised model allowing to compose sentence embeddings using word vectors along with n-gram embeddings. Recently, contrastive learning has been explored in unsupervised sentence representation learning and has become a promising trend <ref type="bibr" target="#b36">(Zhang et al., 2020;</ref><ref type="bibr" target="#b34">Wu et al., 2020;</ref><ref type="bibr" target="#b24">Meng et al., 2021;</ref><ref type="bibr" target="#b22">Liu et al., 2021;</ref><ref type="bibr" target="#b15">Gao et al., 2021;</ref><ref type="bibr" target="#b35">Yan et al., 2021;</ref><ref type="bibr" target="#b12">Chuang et al., 2022)</ref>. Those contrastive learning based methods for sentence embeddings are generally based on the assumption that a good semantic representation should be able to bring similar sentences closer while pushing away dissimilar ones. Therefore, those methods use various data augmentation methods to randomly generate two different views for each sentence and design an effective loss function to make them closer in the semantic representation space. Among these contrastive methods, the most related ones to our work are unsup-ConSERT <ref type="bibr" target="#b35">(Yan et al., 2021)</ref> and unsup-SimSCE <ref type="bibr" target="#b15">(Gao et al., 2021)</ref>. ConSERT explores various effective data augmentation strategies(e.g., adversarial attack, token shuffling, Cutoff, dropout) to generate different views for contrastive learning and analyze their effects on unsupervised sentence representation transfer. Unsup-SimSCE, the current state-of-the-art unsupervised method uses only standard dropout as minimal data augmentation, and feed an identical sentence to a pretrained model twice with independently sampled dropout masks to generate two distinct sentence embeddings as a positive pair. Unsup-SimSCE is very simple but works surprisingly well, performing on par with previously supervised counterparts. However, we find that SimCSE constructs each positive pair with two sentences of the same length, which can mislead the learning of sentence embeddings. So we propose a simple but effective method temed "word repetition" to alleviate it. We also propose to use the momentum contrast method to increase the number of negative pairs involved in the loss calculation, which encourages the model towards more refined learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>In this paper, we propose optimizations to construct positive and negative pairs for SimCSE and combine them with SimCSE, which is termed ESim-CSE. Through extensive experiments, the proposed ESimCSE achieves considerable improvements on standard semantic text similarity tasks over Sim-CSE.</p><p>In the future, we will focus on designing a more refined objective function to improve the discrimination between different negative pairs. Also we will make attempt to optimize the performance on both semantic textual similarity tasks and transfer tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The schematic diagram of the ESimCSE method.</figDesc><graphic url="image-1.png" coords="3,127.56,70.87,340.16,213.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The average similarity difference between the model (SimCSE-BERT) predictions and the normalized ground truths.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>An example of semantic similarity after different methods change a sentence's length.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>as baselines. It can be seen that ESimCSE improves the measurement of semantic textual similarity in different settings over SimCSE. Specifically, ESimCSE outperforms SimCSE by +2.02% on BERT base , +0.90% on BERT large , +0.87% on RoBERTa base , +0.55% on RoBERTa large , respectively.</figDesc><table><row><cell>Model</cell><cell>STS-B</cell></row><row><cell>SimCSE ♣</cell><cell>82.45</cell></row><row><cell>+ word repetition</cell><cell>84.09 (+1.64)</cell></row><row><cell cols="2">+ momentum contrast 83.98 (+1.53)</cell></row><row><cell>ESimCSE</cell><cell>84.85 (+2.40)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Improvement on STS-B development sets that word repetition or momentum contrast brings to Sim-CSE. ♣ : results from official published model by</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>, either word</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>with that of SimCSE in the Introduction. As STS12-STS16 datasets do not have train or development sets, and thus we evaluate the models on the test set of each dataset. We partition each STS test set into two groups based Effects of different bucket lengths buc_len.</figDesc><table><row><cell>buc_len</cell><cell>wr</cell><cell>3</cell><cell>4</cell><cell>5</cell></row><row><cell>STS-B</cell><cell cols="4">84.09 81.92 82.00 82.66</cell></row><row><cell>buc_len</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>3 ∼ 8</cell></row><row><cell>STS-B</cell><cell cols="4">82.00 82.13 83.00 82.18</cell></row></table><note>"wr" means using word repetition method instead of bucketing sentences. "3 ∼ 8" means fine-grained buckets setting: {≤ 3, 4, 5, 6, 7, ≥ 8}.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>The difference between the model predicted cosine similarity and the true label on each dataset's test set. "LD" is short for length difference.</figDesc><table><row><cell>Model</cell><cell cols="2">Sim &lt;q,s1 &gt; Sim &lt;q,s2 &gt;</cell></row><row><cell>SimCSE</cell><cell>26.39</cell><cell>27.07(+0.68)</cell></row><row><cell>ESimCSE</cell><cell>36.82</cell><cell>36.87(+0.05)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 :</head><label>8</label><figDesc>Effect of repeated words on the average similarity of two sets</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9 :</head><label>9</label><figDesc>Effects of repetition rate dup_rate.</figDesc><table><row><cell>As shown</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 10 :</head><label>10</label><figDesc>Effects of queue size of momentum contrast.</figDesc><table><row><cell>Queue Size</cell><cell>STS-B</cell></row><row><cell>1 × batch_size</cell><cell>83.83</cell></row><row><cell cols="2">1.5 × batch_size 83.81</cell></row><row><cell>2 × batch_size</cell><cell>83.03</cell></row><row><cell cols="2">2.5 × batch_size 84.85</cell></row><row><cell>3 × batch_size</cell><cell>82.66</cell></row><row><cell cols="2">5.7 Performance on Transfer Tasks</cell></row><row><cell cols="2">Following (Gao et al., 2021), we further evaluate</cell></row><row><cell cols="2">ESimCSE on transfer tasks, to see the transferabil-</cell></row><row><cell cols="2">ity of the sentence embeddings from ESimCSE.</cell></row><row><cell cols="2">The transfer tasks include: MR (movie review)</cell></row><row><cell cols="2">(Pang and Lee, 2005), CR (product review) (Hu</cell></row><row><cell cols="2">and Liu, 2004), SUBJ (subjectivity status) (Pang</cell></row><row><cell cols="2">and Lee, 2004) , MPQA (opinion-polarity) (Wiebe</cell></row><row><cell cols="2">et al., 2005), SST-2 (binary sentiment analysis)</cell></row><row><cell cols="2">(Socher et al., 2013), TREC (question-type clas-</cell></row><row><cell cols="2">sification) (Voorhees and Tice, 2000) and MRPC</cell></row><row><cell cols="2">(paraphrase detection) (Dolan and Brockett, 2005).</cell></row><row><cell cols="2">For more details, one can refer to SentEval 6 . As</cell></row><row><cell cols="2">shown in Table 11, compared with the performance</cell></row><row><cell cols="2">of SimCSE, ESimCSE slightly increases the trans-</cell></row><row><cell cols="2">ferability of embedding. As our optimizations are</cell></row><row><cell cols="2">focused on semantic textual similarity tasks, the</cell></row><row><cell cols="2">ability of ESimcse on transfer tasks remains stable</cell></row><row><cell>relative to SimCSE.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 11 :</head><label>11</label><figDesc>MR CR SUBJ MPQA SST TREC MRPC Avg. SimCSE ♣ 81.18 86.46 94.45 88.88 85.50 89.80 74.43 85.81 ESimCSE 81.32 86.22 94.74 88.74 85.50 91.00 74.90 86.06 Results on transfer tasks of different sentence embedding models, in terms of accuracy. ♣ : results from (Gao et al., 2021).</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">https://huggingface.co/datasets/princeton-nlp/datasetsfor-simcse/resolve/main/wiki1m_for_simcse.txt</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">3 https://github.com/facebookresearch/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2">SentEval 4 https://en.wikipedia.org/wiki/ Spearman%27s_rank_correlation_</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3">coefficient 5 https://github.com/huggingface/transformers,version 4.2.1.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4">https://github.com/facebookresearch/ SentEval</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Sts12 Sts13 Sts14 Sick15 Sts16 Sts-B</forename><surname>Model</surname></persName>
		</author>
		<author>
			<persName><surname>Sick-R Avg</surname></persName>
		</author>
		<idno>IS-BERT base 56.77 69.24 61.21 75.23 70.16 69.21 64.25 66.58</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><surname>Simcse-Roberta</surname></persName>
		</author>
		<idno>base ♣ 70.16 81.77 73.24 81.36 80.65 80.22 68.56 76.57 ESimCSE-RoBERTa base 69.90 82.50 74.68 83.19 80.30 80.99 70.54 77.44</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><surname>Simcse-Roberta</surname></persName>
		</author>
		<idno>large ♣ 72.86 83.99 75.62 84.77 81.80 81.98 71.26 78.90</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">References Eneko Agirre</title>
		<author>
			<persName><forename type="first">Esimcse-Roberta ; Carmen</forename><surname>Banea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inigo</forename><surname>Lopez-Gazpio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Montse</forename><surname>Maritxalar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<idno>large 73.20 84.93 76.88 84.86 81.21 82.79 72.27 79.45</idno>
	</analytic>
	<monogr>
		<title level="m">Semeval-2015 task 2: Semantic textual similarity, english, spanish and pilot on interpretability</title>
				<imprint>
			<date type="published" when="2015">2015. SemEval 2015</date>
			<biblScope unit="page" from="252" to="263" />
		</imprint>
	</monogr>
	<note>Proceedings of the 9th international workshop on semantic evaluation</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semeval-2014 task 10: Multilingual semantic textual similarity</title>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carmen</forename><surname>Banea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><forename type="middle">T</forename><surname>Daniel M Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rada</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">German</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janyce</forename><surname>Rigau</surname></persName>
		</author>
		<author>
			<persName><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval@ COLING</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="81" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semeval-2016 task 1: Semantic textual similarity, monolingual and cross-lingual evaluation</title>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carmen</forename><surname>Banea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Gonzalez Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">German</forename><surname>Rigau Claramunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval-2016. 10th International Workshop on Semantic Evaluation</title>
				<imprint>
			<date type="published" when="2016-06-16">2016. 2016 Jun 16-17</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>San Diego</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>ACL (Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="497" to="511" />
			<pubPlace>Stroudsburg (PA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Semeval-2012 task 6: A pilot on semantic textual similarity</title>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">* SEM 2012: The First Joint Conference on Lexical and Computational Semantics</title>
				<imprint>
			<date type="published" when="2012">2012. SemEval 2012</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="385" to="393" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">* sem 2013 shared task: Semantic textual similarity</title>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second joint conference on lexical and computational semantics (* SEM), volume 1: proceedings of the Main conference and the shared task: semantic textual similarity</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="32" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semantic re-tuning with contrastive tension</title>
		<author>
			<persName><forename type="first">Fredrik</forename><surname>Carlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amaru</forename><surname>Cuba Gyllensten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangelia</forename><surname>Gogoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">Ylipää</forename><surname>Hellqvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magnus</forename><surname>Sahlgren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inigo</forename><surname>Lopez-Gazpio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.00055</idno>
		<title level="m">Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Yung-Sung</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rumen</forename><surname>Dangovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marin</forename><surname>Soljačić</surname></persName>
		</author>
		<author>
			<persName><surname>Shang-Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><surname>Glass</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.10298</idno>
		<title level="m">Diffcse: Difference-based contrastive learning for sentence embeddings</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automatically constructing a corpus of sentential paraphrases</title>
		<author>
			<persName><forename type="first">B</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Workshop on Paraphrasing (IWP2005)</title>
				<meeting>the Third International Workshop on Paraphrasing (IWP2005)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Cert: Contrastive self-supervised learning for language understanding</title>
		<author>
			<persName><forename type="first">Hongchao</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sicheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayuan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengtao</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.12766</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingcheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08821</idno>
		<title level="m">Simcse: Simple contrastive learning of sentence embeddings</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
				<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.03483</idno>
		<title level="m">Learning distributed representations of sentences from unlabelled data</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Taeuk</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sang-Goo</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.07345</idno>
		<title level="m">Self-guided contrastive learning for bert sentence representations</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Advances in neural information processing systems, 28. Quoc Le and Tomas Mikolov</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Russ R Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2014">2015. 2014</date>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
	<note>Distributed representations of sentences and documents</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">On the sentence embeddings from pre-trained language models</title>
		<author>
			<persName><forename type="first">Bohan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junxian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.05864</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Fast, effective, and self-supervised: Transforming masked language models into universal lexical and sentence encoders</title>
		<author>
			<persName><forename type="first">Fangyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Vulić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nigel</forename><surname>Collier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08027</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">An efficient framework for learning sentence representations</title>
		<author>
			<persName><forename type="first">Lajanugen</forename><surname>Logeswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02893</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Coco-lm: Correcting and contrasting text sequences for language model pretraining</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Payal</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="23102" to="23114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Unsupervised learning of sentence embeddings using compositional n-gram features</title>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Pagliardini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prakhar</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Jaggi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.02507</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<idno>arXiv preprint cs/0409058</idno>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<idno>arXiv preprint cs/0506075</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.09244</idno>
		<title level="m">Low resource text classification with ulmfit and backtranslation</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dynamic pooling and unfolding recursive autoencoders for paraphrase detection</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 conference on empirical methods in natural language processing</title>
				<meeting>the 2013 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Building a question answering test collection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ellen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><surname>Tice</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.11196</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</title>
				<editor>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kai</forename><surname>Zou</surname></persName>
		</editor>
		<meeting>the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2000">2000. 2019</date>
			<biblScope unit="page" from="200" to="207" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Eda: Easy data augmentation techniques for boosting performance on text classification tasks</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Annotating expressions of opinions and emotions in language. Language resources and evaluation</title>
		<author>
			<persName><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="165" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Conditional bert contextual augmentation</title>
		<author>
			<persName><forename type="first">Xing</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shangwen</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liangjun</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jizhong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songlin</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on computational science</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="84" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Clear: Contrastive learning for sentence representation</title>
		<author>
			<persName><forename type="first">Zhuofeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sinong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madian</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15466</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Consert: A contrastive framework for self-supervised sentence representation transfer</title>
		<author>
			<persName><forename type="first">Yuanmeng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rumei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sirui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiran</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.11741</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">An unsupervised sentence embedding method by mutual information maximization</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruidan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zuozhu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kwan</forename><surname>Hui Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.12061</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
