<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TOAD-GAN: Coherent Style Level Generation from a Single Example</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-08-04">4 Aug 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Maren</forename><surname>Awiszus</surname></persName>
							<email>awiszus@tnt.uni-hannover.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institut für Informationsverarbeitung</orgName>
								<orgName type="institution">Leibniz University</orgName>
								<address>
									<settlement>Hanover</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Frederik</forename><surname>Schubert</surname></persName>
							<email>schubert@tnt.uni-hannover.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institut für Informationsverarbeitung</orgName>
								<orgName type="institution">Leibniz University</orgName>
								<address>
									<settlement>Hanover</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
							<email>rosenhahn@tnt.uni-hannover.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institut für Informationsverarbeitung</orgName>
								<orgName type="institution">Leibniz University</orgName>
								<address>
									<settlement>Hanover</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">TOAD-GAN: Coherent Style Level Generation from a Single Example</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-08-04">4 Aug 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2008.01531v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work, we present TOAD-GAN (Token-based Oneshot Arbitrary Dimension Generative Adversarial Network), a novel Procedural Content Generation (PCG) algorithm that generates token-based video game levels. TOAD-GAN follows the SinGAN architecture and can be trained using only one example. We demonstrate its application for Super Mario Bros. levels and are able to generate new levels of similar style in arbitrary sizes. We achieve state-of-the-art results in modeling the patterns of the training level and provide a comparison with different baselines under several metrics. Additionally, we present an extension of the method that allows the user to control the generation process of certain token structures to ensure a coherent global level layout. We provide this tool to the community to spur further research by publishing our source code.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Level design is a key component of the game creation process. The designer has to consider aspects like physics, playability and difficulty during the creation process. This task can require a lot of time for even a single level.</p><p>Procedural Content Generation (PCG) has the potential to assist the designer by automating parts of the process. Early works in PCG used the co-occurrence of tokens (e.g. a single enemy or ground block) in existing game levels to identify patterns <ref type="bibr" target="#b3">(Dahlskog and Togelius 2012</ref>) and combined them using simple statistical models <ref type="bibr" target="#b17">(Snodgrass and Ontanón 2013)</ref>. The quality of these algorithms critically depends on the extracted patterns and co-occurrence relations, which have to be defined manually. Recent approaches used PCG via Machine Learning (PCGML) <ref type="bibr" target="#b17">(Summerville et al. 2018)</ref> to learn the patterns and relations from the data automatically <ref type="bibr" target="#b17">(Summerville and Mateas 2016;</ref><ref type="bibr" target="#b22">Volz et al. 2020</ref>). However, simply applying them to the level generation task comes with several drawbacks. The Machine Learning algorithms need many examples to extract the patterns. As manual level design is a costly process, there is usually a very limited number available for training. Even if the amount is sufficient, the generated levels are mixtures of all example levels and do not have a coherent style. Finally, Figure <ref type="figure">1</ref>: Generated levels based on Super Mario Bros. level 1-2. The new levels can be generated in any size and preserve the token distribution of the original level, while also containing new, previously unseen patterns.</p><p>most recent PCGML algorithms are black boxes and do not allow for high-level control of their generated content.</p><p>In this paper, we introduce TOAD-GAN as a solution to these problems. Our work is inspired by SinGAN <ref type="bibr" target="#b15">(Shaham, Dekel, and Michaeli 2019)</ref>, a recent Generative Adversarial Network (GAN) <ref type="bibr">(Goodfellow et al. 2014)</ref> architecture that learns a generative model given only one example image. This is achieved by learning patch-based features on different spatial scales. Since SinGAN was developed for natural RGB images, it is unable to generate convincing video game levels that are based on 2D token maps. Our method, on the other hand, was developed exactly with this purpose in mind. As shown in Fig. <ref type="figure">1</ref>, TOAD-GAN is able to generate new levels in the style of one given example level.</p><p>In summary, our contributions are: • With TOAD-GAN, we present a novel generative model that allows for level generation following the one-shot training approach of SinGAN. • We introduce a downsampling algorithm for token-based levels specifically designed to preserve important tokens. • An extension of our method enables authoring of the global level structure. We show this for example levels generated for Super Mario Kart. • We visualise our generated content in a latent space to compare it with the original levels.</p><p>• We enable further research by publishing our source code.<ref type="foot" target="#foot_0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Generating Super Mario Bros. (SMB) levels was one of the first challenges proposed to the PCG community <ref type="bibr" target="#b16">(Shaker et al. 2011)</ref>. Since its introduction, many approaches were presented that tried to capture the patterns from the original levels and combine them in novel ways. This section only covers a selection, due to the vast amount of PCG approaches.</p><p>For a review of pattern-based level generators for SMB see <ref type="bibr" target="#b11">Khalifa et al. (2019)</ref>.</p><p>Super Mario Bros. Level Generation <ref type="bibr" target="#b3">Dahlskog and Togelius (2012)</ref> identified and analyzed patterns with different themes, such as enemies, gaps or stairs.</p><p>They assessed the difficulty of the patterns to human players and outlined how those patterns could be combined and varied to create new levels. In their continued work <ref type="bibr" target="#b3">(Dahlskog and Togelius 2014)</ref>, they additionally defined micro-(vertical slices) and macro-patterns (sequences of patterns). Using an Evolutionary Algorithm (EA), they generated levels by selecting micro-patterns, with a fitness function based on the occurrence of patterns and macro-patterns.</p><p>Search-based PCG <ref type="bibr">(Togelius et al. 2011</ref>) was applied to SMB by <ref type="bibr" target="#b18">Summerville, Philip, and Mateas (2015)</ref>. The authors used Monte Carlo Tree Search (MCTS) <ref type="bibr" target="#b2">(Coulom 2006)</ref> to guide the sampling process from a Markov Chain model of tokens. The reward of the MCTS was computed based on the solvability, number of gaps, number of enemies and rewards (coins or power-ups).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural Networks for PCG</head><p>Recent PCGML approaches that use Neural Networks have also been applied extensively to the SMB level generation problem. <ref type="bibr" target="#b10">Hoover, Togelius, and Yannakis (2015)</ref> trained a neural network with an EA to generate new levels. The network predicts the height of a token in a level slice, given the heights of all tokens in the previous slices. <ref type="bibr" target="#b17">Summerville and Mateas (2016)</ref> trained their model on levels by predicting the tokens sequentially. They used a neural network architecture based on Long Short-Term Memory (LSTM) cells <ref type="bibr" target="#b9">(Hochreiter and Schmidhuber 1997)</ref> to predict the next token, given a context of previous tokens in the unrolled level.</p><p>Recently, GANs were used to create SMB levels. In <ref type="bibr" target="#b21">(Volz et al. 2018)</ref> the authors train a GAN on slices of the original levels and use an EA to search the space of generated levels by scoring the fraction of enemy and ground tokens.</p><p>A similar approach was taken by Torrado et al. ( <ref type="formula">2019</ref>) who used the Self-Attention GAN (SAGAN) <ref type="bibr" target="#b23">(Zhang et al. 2019</ref>) architecture and conditioned their generation process on a feature vector that contained the targeted token distributions of the generated levels. This conditioning increased the variability of their generated content.</p><p>Figure <ref type="figure">2</ref>: Example of the mode collapse of a WGAN-GP trained solely on 16 × 16 slices from SMB level 1-1. This slice size is chosen because square images are preferable for GANs and 16 is the default height of all SMB levels. The generator stops creating anything but the ground and sky.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Limited training data is one of the key problems of PCGML algorithms <ref type="bibr" target="#b20">(Torrado et al. 2019;</ref><ref type="bibr" target="#b1">Bontrager and Togelius 2020)</ref>. Therefore, the goal of our work is the generation of new levels for SMB from very little training data. With TOAD-GAN, we take this problem to the extreme regime of learning from only one single training level. Similar to other recent publications <ref type="bibr" target="#b21">(Volz et al. 2018;</ref><ref type="bibr" target="#b20">Torrado et al. 2019;</ref><ref type="bibr" target="#b22">Volz et al. 2020)</ref>, TOAD-GAN is based on the GAN architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generative Adversarial Networks</head><p>GANs are able to generate samples from a given training distribution <ref type="bibr">(Goodfellow et al. 2014)</ref>. They consist of two adversaries: The generator G maps random noise vectors z to samples x, which the discriminator D is trying to distinguish from real samples x. In the end, G produces x that are indistinguishable from real x. However, this process can become unstable. In the low-data regime, the discriminator might be able to memorize the distribution of real samples and stops providing useful gradients for the generator. Many different extensions to the basic architecture were proposed to stabilize the training process, for example minimizing the Wasserstein distance <ref type="bibr" target="#b0">(Arjovsky, Chintala, and Bottou 2017)</ref> and penalizing the norm of the gradients of the discriminator <ref type="bibr" target="#b7">(Gulrajani et al. 2017)</ref>. The resulting Wasserstein GAN with Gradient Penalty (WGAN-GP) is able to model a variety of distributions, but it is still prone to failures like mode collapse. This is the case when the generator produces samples that contain only a few features (or modes) of the data which the discriminator cannot classify correctly. Then, the generator will never learn to produce the missed modes. See Fig. <ref type="figure">2</ref> for an example.</p><p>Even though GANs have shown promising results, their success depends on the availability of a lot of samples from the real distribution. Additionally, long range correlations in an image can only be modeled by convolutional GANs with many layers. For longer levels, this increases the number of parameters that have to be optimized, which further complicates the training process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SinGAN</head><p>SinGAN <ref type="bibr" target="#b15">(Shaham, Dekel, and Michaeli 2019</ref>) is a novel GAN architecture that enables learning a generative model from a single image. This is achieved by using a cascade of generators and discriminators that act on patches from differently scaled versions of the image. The weights of (1)</p><p>The discriminators receive either a scaled real image or the output of their respective generator. Generator and discriminator only act on patches and are fully-convolutional. This means that the size of the output is determined by the size of the initial noise map at the lowest scale. For a more in-depth explanation please refer to the original SinGAN paper by <ref type="bibr" target="#b15">Shaham, Dekel, and Michaeli (2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TOAD-GAN</head><p>Fig. <ref type="figure" target="#fig_0">3</ref> shows the pipeline of TOAD-GAN for the generation of SMB levels. There are 15 original SMB levels provided by the Video Game Level Corpus <ref type="bibr" target="#b17">(Summerville et al. 2016)</ref>, each with different characteristics. The levels are placed in three worlds (overworld, underground, floating platforms) with different global structure and token patterns. For training, one level is sampled down to N different scales. We choose N such that the receptive field of the convolutional filters in our generators and discriminators is able to cover at minimum half of the height of the levels at the lowest scale. This ensures that larger structures are modeled correctly, but allows for variation in their global position.</p><p>Interpreting each token as one pixel of an image and then downsampling naively results in lost information, as aliasing would make important tokens disappear at lower scales.</p><p>To keep most of the information from the original level, we propose a downsampling method which preserves important tokens. This method is inspired by TF-IDF weighting (Manning, Raghavan, and Schütze 2008) in Natural Language Processing where the importance of a term is defined by its term frequency multiplied by its inverse document frequency. In our case, terms are tokens and documents are levels. Tokens that occur often and in multiple levels, like the sky and ground blocks, are of lower importance than rare tokens, such as the hidden and special blocks. The complete token hierarchy can be found in Tab. 1. The steps of this process are as follows. First, bilinear downsampling is used on the one-hot encoded training level to create the base levels of the chosen scales. For each pixel in each scale, the tokens with a value greater than zero are selected. From that list, the tokens with the highest rank in our hierarchy are kept and the remaining tokens are set to zero. Finally, a Softmax is applied over all channels per pixel. In Fig. <ref type="figure" target="#fig_0">3</ref> on the right, two downsampled versions of level 1-2 can be seen. Later, we also need to sample the outputs on lower scales up. For this we use bilinear up-sampling.</p><p>On natural images, SinGAN uses zero-centered gaussian spatial noise that is constant over all color channels for a given pixel, i.e. it only changes the brightness of that pixel. This places a prior on the hue of the up-sampled pixels and increases the similarity of the generated samples between the different scales. In our case, the channels represent the tile types. Because these are independent from each other, we apply the noise to all channels individually.</p><p>TOAD-GAN can be extended to perform level authoring by injecting a predefined input into the generator cascade.   The generators fill in the details and produce a sample which follows the structure of the injected input but has a similar style as the training sample. This application is particularly interesting for PCG as the designer can describe a desired level or layout for a given token and the generators create variants of it. In our experiments, we inject a new, differently structured map for a specific token after the very first generation step. This basic structure is preserved and expanded upon by the following generator steps, which results in a level with the desired structure that consists of the patterns learned by the generators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Our experiments are split into two parts. First, we perform a qualitative evaluation of the generated levels by presenting a number of samples to highlight capabilities of our approach. Then, our generated levels are assessed with regards to their Tile Pattern KL-Divergence (TPKL-Div) (Lu-cas and Volz 2019) and visualised using an embedding of the level slices that is inspired by the Fréchet Inception Distance (FID) <ref type="bibr" target="#b8">(Heusel et al. 2017</ref>). In the second part, we show the generality of TOAD-GAN by applying it to Super Mario Kart and present an example of level authoring. We use the same hyperparameters for all experiments. The samples were generated at scales 0.5, 0.75, 0.88 and 1.0 of the original training sample size. The remaining hyperparameters and specific architectures will be published with our source code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Level Generation Evaluation</head><p>Qualitative Examples In this experiment, TOAD-GAN is trained on each of the levels provided by the SMB benchmark. Fig. <ref type="figure" target="#fig_3">4</ref> shows randomly generated samples for levels of different types. To increase comparability, all levels were cut (others), or generated (ours) to the same length. The style of our generated samples matches that of the level they were trained on. For example, the hidden 1-Up block in (b) is placed very similarly in (d). However, the patterns in our samples are combined differently than in their training level (e.g. the three small platforms with coins from (j) are transformed to different heights in (l)). All this while the general structure of the generated levels is similar to a SMB level. We tested the validity of our generated content using the A* agent by Baumgarten <ref type="bibr" target="#b19">(Togelius, Karakovskiy, and Baumgarten 2010)</ref>, who was able to win 65% of randomly sampled levels compared to the 52% of the original levels <ref type="bibr" target="#b6">(Green et al. 2020</ref>).</p><p>While we focus on learning one generator for one level, other methods create one for all training levels. The levels (m-p) are some example results of such generators. In them, different kinds of levels are mixed (e.g. pyramids are created on floating platforms) and the level style is not captured. The levels (o) and (p) depict recognizable overworld levels, however the sample cut from (o) was trained on 4-2 and should therefore be more similar to an underground level. The closest to a convincing overworld level is (p) which was also created using a GAN-based approach <ref type="bibr" target="#b21">(Volz et al. 2018)</ref>. However, this method relies on small samples that are stitched together and can result in repeating patterns.</p><p>Tile Pattern KL-Divergence We use the TPKL-Div by <ref type="bibr" target="#b13">Lucas and Volz (2019)</ref> to evaluate the similarity of our generated patterns to the originals. Fig. <ref type="figure" target="#fig_4">5</ref> shows the results for all original SMB levels. As expected, the values on the main diagonal, where the generated samples are compared to the level they were trained with, are very small. This indicates that TOAD-GAN is able to model the original pattern distributions for any type of level. Also noticeable are spots in the matrix where a very low value occurs for a different level than the one trained on. This happens because these levels are of a similar style. For example, levels 1-3, 3-3, 5-3, and 6-3 are all levels with floating platforms, as shown in Fig. <ref type="figure" target="#fig_3">4(i)-(l)</ref>.</p><p>Tab. 2 shows our resulting divergences compared to those reported by <ref type="bibr" target="#b13">Lucas and Volz (2019)</ref> and <ref type="bibr" target="#b6">Green et al. (2020)</ref>. For our results, we computed the mean 2 × 2, 3 × 3, and 4 × 4 pattern divergences with w = 1.0. As we train 15 1.70 TOAD-GAN (ours) 0.33</p><formula xml:id="formula_0">1-1 1-2 1-3 2-1 3-1 3-3 4-1 4-2 5-1 5-3 6-1 6-2 6-3 7-1 8-1 Original Level 1-1 1-2 1-3 2-1 3-1 3-3 4-1 4-2 5-1 5-3 6-1 6-2 6-3 7-1 8-1</formula><p>GAN Level 0.224.3 5.9 3 2.7 6.6 2.4 5.7 1.5 5.9 2 4.6 5.4 3.2 2.1 1.70.615.6 1.6 2 6.1 1 2 1.5 5.7 1.7 1.9 4.6 2.7 1.2 2.4 5 0.284.2 3.30.912.2 6.3 2.50.33 2 5 0.513.6 2.6 1.4 4 5.90.331.2 6.40.994.90.79 6 1.6 1 5.3 1.90.91 1.2 3.4 5.90.950.326.5 1 3.90.82 6 1.4 1.2 5.3 1.7 1 3.5 5.3 1.3 4.9 4.50.492.9 6.4 3.2 1.3 3.6 5.50.494.7 3.2 2.3 6.3 5.2 2.4 2.2 6.10.13 7 1.9 5.2 1.5 2 4.8 2.5 1.7 2.4 2.1 5.4 2 2.3 5.9 1.30.682.1 5.4 1.8 1.4 4.6 2.7 1.3 1.8 5.8 6.5 2 2.1 6.9 1.9 6.70.216.5 2.4 1.7 5.7 1.5 1.1 2.3 5.20.364.1 3.3 1 2.2 6.6 2.40.291.9 5 0.613.6 2.6 2.1 4.4 5.3 2.1 1.7 6 0.494.8 1.9 5.40.211.6 4.4 2.2 1.7 1.9 4.2 5.7 2.1 2.2 6.4 1.9 4 1.6 5.7 2 0.285.3 2.1 1.3 4.2 5.6 2.1 5.4 5.2 1.5 3.1 6.5 3.7 2.1 4.4 5.90.295.1 3.6 2.1 4.5 6.5 1.9 1.7 6.8 1.2 4.6 1.5 6.5 1.8 1.5 5.40.281.6 1.5 4.2 5 1.8 1.9 5.8 1.3 5.20.78 5 1.6 1.3 4.6 2.40.27 separate generators, we average their values to get the result in Tab. 2. We generated 1000 sample levels with a size of 200 × 16 tokens for each generator. On average, levels generated by TOAD-GAN produce a lower and therefore better TPKL-Div. However, as the TPKL-Div measures only the differences for patterns already present in the original level, newly generated patterns are not taken into account. Visual inspection of the generated levels (compare Figs. <ref type="figure" target="#fig_3">1 and 4</ref>) indicates that existing patterns are not only reproduced, but combined in novel ways and new patterns are generated. Fig. <ref type="figure">2</ref> indicates that GANs tend to produce very similar or even the same output. We tested the variability of our generated content by computing the uniqueness of structures in our generated samples. For that, we randomly picked 100000 square 16 × 16 slices evenly from our previously generated samples and found that an average of 90.62% of them were unique.</p><p>2 Results by <ref type="bibr" target="#b13">Lucas and Volz (2019)</ref>, on level 1-1 averaged over 2 × 2, 3 × 3, and 4 × 4 patterns with w = 1.0</p><p>3 Results by <ref type="bibr" target="#b6">Green et al. (2020)</ref>, averaged over level 1-1, 4-2 and 6-1, only 3 × 3 patterns Level Embeddings Even though the TPKL-Div captures some aspects of the similarities between SMB levels, it is limited to patterns of fixed sizes. We propose a new method that additionally results in an easily interpretable visualization. Unlike the TPKL-Div, our distance metric is independent of the size of the patterns. Similar to FID, we train a convolutional classifier c on slices s of the original levels to predict the level they are from. level ∈ arg max c(s) = arg max W φ(s) + b</p><p>(2)</p><p>The slice representation in the penultimate layer φ(s) of the classifier is a vector of non-linear features that is mapped linearly to the predicted level. In Fig. <ref type="figure">6</ref>(a), we visualize the distribution of these representations by projecting them to two dimensions with the Universal Manifold Approximation and Projection (UMAP) <ref type="bibr" target="#b14">(McInnes, Healy, and Melville 2018)</ref> method. This reveals the three level types which SMB levels fall into: Overworld to the top right, underground to the left and floating platforms at the bottom. <ref type="bibr">Fig. 6(b)</ref> shows the distribution of level slices generated by our 15 generators by mapping them with the same transformation learned in (a). Our generators are indeed generating slices very close but not limited to the manifold of their original level. In some cases, our generators even learn to create slices that are not in their training distribution, but still within the level manifold. Examples are G 1-3, G 5-3, and G 6-3 that generate slices in the same space as 3-3. This experiment highlights the variability of the produced slices of a generator while still being within the intended constraints of being a SMB level of the same style.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Level Authoring</head><p>TOAD-GAN enables us to perform authoring of the global level structure. This is made possible by editing the token maps in any of the scales, which results in the edit being represented in the generated level. Fig. <ref type="figure" target="#fig_6">7</ref> shows examples of this application for seeding a track layout in Super Mario Kart. TOAD-GAN is only trained on the original sample track and will generate track layouts similar to that. Because our method does not yet take playability into account, dead ends and unconnected track pieces can be generated. Seeding a layout can not only ensure a connected and working racing track, it also allows the track to have a significantly different structure than the original sample. Each seed can, depending on the noise in the other token maps and the other scales, generate an infinite amount of levels with the given structure. As the Super Mario Kart levels are much larger than the SMB levels, we used 5 convolutional layers instead of 3 and chose 9 scales (0.2, 0.3, . . . , 1.0). The token hierarchy is (from low to high) ground, wall, road and special (coins etc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>With this paper, we propose TOAD-GAN, a Procedural Content Generation algorithm that is able to generate tokenbased levels (as shown for Super Mario Bros. and Super Mario Kart) while being trained on a single example. We  expand on the novel SinGAN architecture to generate tokenbased levels instead of natural images. The generated levels are evaluated qualitatively by computing their Tile Pattern KL-Divergence. Their visualization as slice embeddings ofof them with the original levels without specifying the pattern dimensions. By seeding a predefined basic level layout, it is possible to generate new levels while still keeping the style that TOAD-GAN was trained on. An example of this is shown by using hand drawn tracks for generating Super Mario Kart levels. Our experiments demonstrate how TOAD-GAN is able to capture the patterns of its training input and generate consistent variations of it.</p><formula xml:id="formula_1">1-1 1-2 1-3 2-1 3-1 3-3 4-1 4-2 5-1 5-3 6-1 6-2 6-3 7-1 8-1<label>(</label></formula><p>We intend to improve our approach in the future by also taking gameplay mechanics into account during the generation process. Samples generated with TOAD-GAN are visually convincing Super Mario Bros. levels, but a proper study with human participants will help to assess the output quality in more depth. Another future direction will be the application of TOAD-GAN to voxel-based games (e.g. Minecraft) or to maze games with a non-linear level structure.</p><p>TOAD-GAN is a step towards using PCG via Machine Learning during the game design process due to its low requirements for the amount of data necessary and its extension to Level Authoring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgment</head><p>This work has been supported by the Federal Ministry for Economic Affairs and Energy under the Wipano programme "NaturalAI" 03THW05K06.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Generation process of TOAD-GAN on Super Mario Bros. level 1-2. The architecture is adapted from SinGAN (cf. Fig. 4 of<ref type="bibr" target="#b15">(Shaham, Dekel, and Michaeli 2019)</ref>). We use a downsampling method on a one-hot encoded version of the level that preserves small but important structures which would be lost when performing simple spatial downsampling. The upwards arrow between the scales represents bilinear upsampling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Overworld</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Example levels generated by TOAD-GAN for the three different level types found in Super Mario Bros. in comparison to other generators. TOAD-GAN is able to capture the style of the level it was trained on.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Mean Tile-Pattern-KL-Divergence between 100 generated levels and the original levels. Values are averaged over 2 × 2, 3 × 3 and 4 × 4 patterns. Each row represents a TOAD-GAN that was trained on the labelled SMB level.</figDesc><graphic url="image-76.png" coords="5,77.47,169.76,182.13,182.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Figure6: Level slice representations of a level classifier projected to two dimensions. Each point represents a 16 × 16 slice of a Super Mario Bros. level. The marked points are the ones closest to the mean of their respective level. For visualization purposes, a small amount of noise was added to the points, as some would otherwise overlap. The generated slices are close to the original slices of their respective level, with some slices being similar to other levels of the same style.</figDesc><graphic url="image-112.png" coords="6,54.74,372.35,66.72,66.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: TOAD-GAN can be applied to levels of arbitrary token-based games, e.g. Super Mario Kart. We can enforce a predetermined track layout by conditioning the generation process in the lowest scale. The examples shown are two different hand-drawn digits from the MNIST dataset (LeCun et al. 1998) and an additional layout made for this example.</figDesc><graphic url="image-113.png" coords="6,54.86,542.78,66.72,66.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Token Hierarchy</figDesc><table><row><cell>Group</cell><cell>Tokens</cell><cell></cell><cell></cell></row><row><cell>0 Sky</cell><cell></cell><cell></cell><cell></cell></row><row><cell>1 Ground</cell><cell></cell><cell></cell><cell></cell></row><row><cell>2 Pyramid</cell><cell></cell><cell></cell><cell></cell></row><row><cell>3 Platforms</cell><cell cols="2">, , , ,</cell><cell></cell></row><row><cell>4 Pipes</cell><cell>,</cell><cell>+</cell><cell></cell></row><row><cell>5 Enemies</cell><cell>, , ,</cell><cell></cell><cell></cell></row><row><cell>6 Special Enemies</cell><cell>,</cell><cell>,</cell><cell>, ,</cell></row><row><cell>7 Special Blocks</cell><cell cols="3">, + , + , +</cell></row><row><cell>8 Hidden Blocks</cell><cell cols="3">+ , + , + , +</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Average Tile Pattern KL-Divergence</figDesc><table><row><cell>Algorithm</cell><cell>TPKL-Div.</cell></row><row><cell>ELSGAN 2</cell><cell>1.58</cell></row><row><cell>GAN 2</cell><cell>1.70</cell></row><row><cell>ETPKLDiv 3x3 2</cell><cell>0.88</cell></row><row><cell>Evolution World 3</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://github.com/Mawiszus/TOAD-GAN</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Wasserstein generative adversarial networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Bontrager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05259</idno>
		<title level="m">Fully Differentiable Procedural Content Generation through Generative Playing Networks</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search</title>
		<author>
			<persName><forename type="first">R</forename><surname>Coulom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on computers and games</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="72" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Patterns and procedural content generation: Revisiting Mario in world 1 level 1</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dahlskog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dahlskog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Design Patterns in Games -DPG &apos;12</title>
				<meeting>the First Workshop on Design Patterns in Games -DPG &apos;12<address><addrLine>Raleigh, North Carolina; Dortmund, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012. 2014</date>
		</imprint>
	</monogr>
	<note>2014 IEEE Conference on Computational Intelligence and Games</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mugrai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khalifa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.02992</idno>
		<title level="m">Mario Level Generation From Mechanics Using Scene Stitching</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improved Training of Wasserstein GANs</title>
		<author>
			<persName><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5767" to="5777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gans trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName><forename type="first">M</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
				<meeting>the 31st International Conference on Neural Information Processing Systems<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="6629" to="6640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Composing Video Game Levels with Music Metaphors through Functional Scaffolding</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Hoover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Yannakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Computational Creativity and Games Workshop</title>
				<imprint>
			<publisher>ACC</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Intentional computational level design</title>
		<author>
			<persName><forename type="first">A</forename><surname>Khalifa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Barros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Genetic and Evolutionary Computation Conference</title>
				<meeting>The Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="796" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tile Pattern KL-Divergence for Analysing and Evolving Game Levels</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Volz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference. Manning</title>
				<meeting>the Genetic and Evolutionary Computation Conference. Manning</meeting>
		<imprint>
			<publisher>Cambridge university press</publisher>
			<date type="published" when="2008">2019. 2008</date>
		</imprint>
	</monogr>
	<note>troduction to information retrieval</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Melville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03426</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Singan: Learning a generative model from a single natural image</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Shaham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Michaeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
				<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4570" to="4580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Shaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Yannakakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hashiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sorenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pasquier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mawhorter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Baumgarten</surname></persName>
		</author>
		<title level="m">The 2010 Mario AI Championship: Level Generation Track. IEEE Transactions on Computational Intelligence and AI in Games</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Super Mario as a String: Platformer Level Generation Via LSTMs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Snodgrass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ontanón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Summerville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mateas</surname></persName>
		</author>
		<author>
			<persName><surname>Fdg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Summerville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Snodgrass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mateas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ontañón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Snodgrass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guzdial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Holmgård</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Hoover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Isaksen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nealen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth Artificial Intelligence and Interactive Digital Entertainment Conference</title>
				<meeting><address><addrLine>Summerville, A</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013. 2016. 2016. 2018</date>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
	<note>Procedural Content Generation via Machine Learning (PCGML)</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">MCM-CTS PCG 4 SMB: Monte Carlo Tree Search to Guide Platformer Level Generation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Summerville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mateas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dahlskog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yannakakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eleventh Artificial Intelligence and Interactive Digital Entertainment Conference</title>
				<imprint>
			<date type="published" when="2011">2015. 2013. 2011</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>ACM. Togelius,</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The 2009 Mario AI Competition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karakovskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Baumgarten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Congress on Evolutionary Computation</title>
				<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Torrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khalifa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Justesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Risi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01603</idno>
		<title level="m">Bootstrapping Conditional GANs for Video Game Level Generation</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Evolving mario levels in the latent space of a deep convolutional generative adversarial network</title>
		<author>
			<persName><forename type="first">V</forename><surname>Volz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schrum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Risi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference</title>
				<meeting>the Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="221" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Volz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Justesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Snodgrass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Asadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Purmonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Holmgå Rd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Risi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.12579</idno>
		<title level="m">Capturing Local and Global Patterns in Procedural Content Generation via Machine Learning</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08318</idno>
		<title level="m">Self-Attention Generative Adversarial Networks</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
