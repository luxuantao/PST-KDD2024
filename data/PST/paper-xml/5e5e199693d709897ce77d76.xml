<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Toward Improving ECG Biometric Identification Using Cascaded Convolutional Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Deng</forename><surname>Cai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yazhao</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Electrical and Information Engineering</orgName>
								<orgName type="institution">Tianjin University</orgName>
								<address>
									<postCode>300072</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yanwei</forename><surname>Pang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Electrical and Information Engineering</orgName>
								<orgName type="institution">Tianjin University</orgName>
								<address>
									<postCode>300072</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kongqiao</forename><surname>Wang</surname></persName>
							<email>kongqiao.wang@huami.com</email>
							<affiliation key="aff3">
								<orgName type="institution">Huami Corporation</orgName>
								<address>
									<postCode>230088</postCode>
									<settlement>Hefei</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xuelong</forename><surname>Li</surname></persName>
							<email>xuelong_li@opt.ac.cn</email>
							<affiliation key="aff4">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<postCode>710119</postCode>
									<settlement>Xi&apos;an, Shaanxi</settlement>
									<country key="CN">P. R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Toward Improving ECG Biometric Identification Using Cascaded Convolutional Neural Networks</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Toward Improving ECG Biometric Identification Using Cascaded Convolutional Neural Networks Yazhao Li</orgName>
								<address>
									<settlement>Yanwei Pang, Kongqiao Wang, Xuelong Li</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Toward Improving ECG Biometric Identification Using Cascaded Convolutional Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1016/j.neucom.2020.01.019</idno>
					<note type="submission">Received date: 27 April 2019 Revised date: 7 January 2020 Accepted date: 10 January 2020 Preprint submitted to Neurocomputing January 13, 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Human identification</term>
					<term>biometric identification</term>
					<term>convolutional neural networks (CNN)</term>
					<term>cascaded CNN</term>
					<term>electrocardiogram (ECG)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is a PDF file of an article that has undergone enhancements after acceptance, such as the addition of a cover page and metadata, and formatting for readability, but it is not yet the definitive version of record. This version will undergo additional copyediting, typesetting and review before it is published in its final form, but we are providing this version to give early visibility of the article. Please note that, during the production process, errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Human identification by the uniqueness of every individual is an indispensable part of human life nowadays <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. However, because of the lack of liveness check, traditional biometric recognition techniques via fingerprint, palm print, face <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>, iris, or speech recognition are facing severe challenges caused by data replication and malicious forgery.</p><p>In the last decades, a new human identification technique by biometric recognition via electrocardiogram (ECG), which records the electrical depolarizationrepolarization patterns of the heart, has been proposed and studied <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b7">8]</ref>. Different from other biometrics, ECG signals can only be captured with the activity of hearts. Thus, liveness check is the premise of ECG capturing and ECG identification to avoid the forging of ECG signals. Bile et al. <ref type="bibr" target="#b16">[17]</ref> have demonstrated the feasibility of human identification based on ECG signals. Furthermore, Kyoso et al. <ref type="bibr" target="#b21">[22]</ref> and Page et al. <ref type="bibr" target="#b22">[23]</ref> have shown the availability of human identification by one-lead ECG signals. Although the less information via one-lead ECG signals than <ref type="bibr" target="#b11">12</ref>-lead signals makes it somewhat challenging for human identification, using one-lead ECG signals is more reasonable and promising in practice <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>. Therefore, we focus on one-lead based ECG biometrics in this paper.</p><p>For a human identification system via ECG signals, it should be generic for groups with variable members. Taking the attendance system with ECG biometrics as an instance, in the identification phase, the system should work even though there are some changes about the group members such as someone out or others in. That is, once the model is trained well, it should work stably for a long period without re-training. However, the previous neural network based methods suffer from the less generalization problem. Besides, traditional ECG identification methods extract manual features from ECG signals, which is inferior to the learning based methods. Thus, the effectiveness and robustness of the traditional identification methods cannot be guaranteed.</p><p>To overcome the aforementioned problems in biometric identification and meet the practical demands, we propose a CNN based method called Cascaded CNN for human identification via ECG biometrics, which can improve the effectiveness and efficiency of identification significantly. Overall, this approach consists of four steps before identification phase. First, ECG signals are acquired and preprocessed by filtering and segmentation to generate the templates of different individuals for registration. Then a CNN for feature extraction called F-CNN is trained by the means of multi-classification. After that, the second CNN called M-CNN is trained for matching based on the features extracted by F-CNN. Finally, these two networks are cascaded and embedded into devices for human identification fundamentally. The novelty, contribution, and characteristic of the proposed method are as follows.</p><p>? A deep F-CNN architecture for feature extraction of ECG biometrics is designed and implemented. Some modifications are conducted to make CNN suitable for one dimensional ECG signals. Consequently, the learned features by F-CNN are more superior to manual features.</p><p>? The M-CNN is designed for feature fusion and predicting the comparison results by learning the similarity between the template and input heartbeats. By using the M-CNN, the human identification task is simplified to binary classification instead of multi-classification.</p><p>? We propose to combine the F-CNN and M-CNN as the Cascaded CNN for ECG biometric identification. As a result, the generalization ability and portability can be guaranteed when using the trained Cascaded CNN models for variable groups. This meets the practical demands greatly as aforementioned.</p><p>? Because of the superiority of features and the superior generalization ability, the proposed Cascaded CNN is capable of achieving the state-of-theart performance for human identification via ECG biometrics on various groups with different members.</p><p>The rest of this paper is organized as follows. We review some related methods mainly about the feature extraction and identification methods for biometric identification in Sec. 2. Differences between our method and other neural networks based methods are also discussed. We present the details of the proposed method in Sec. 3. Subsequently, experimental results on several public ECG datasets in Physionet <ref type="bibr" target="#b33">[34]</ref> for human identification are presented in Sec. 4. We discuss and conclude this study in Sec. 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>For ECG biometric identification based systems, three tasks are always worked on: (1) ECG data pre-processing, <ref type="bibr" target="#b1">(2)</ref> feature extraction, and (3) identification.</p><p>To improve the efficiency of recognition, most studies of ECG biometrics require the segmentation of an ECG recording into consecutive heartbeats signals <ref type="bibr" target="#b9">[10]</ref>. As the groundwork of extracting reliable information from ECG signal, data pre-processing algorithms, such as filtering and R-peak detection for segmentation, have been widely explored and achieved almost the optimal performance <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>In this study, we focus on the challenging works for human identification via ECG, that is, feature extraction and identification algorithms. In prior arts, methods for feature extraction can be summarized into two groups: (1) manual features based methods and (2) learned features based methods. We first review these feature extraction methods. Then we discuss the identification methods. Finally, differences between some most related works and ours are presented.</p><p>(1) Manual features based methods. For manual features, two main categories can be found in prior arts: fiducial features and nonfiducial fea-tures. For fiducial features, specific anchor points on the ECG recordings are detected accurately. Among that, temporal features such as heartbeat waves duration and time intervals between anchor points <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b25">26]</ref>, amplitude features of various peaks <ref type="bibr" target="#b23">[24]</ref> and morphological features <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40]</ref>are favored in the literatures. Based on the fiducial points, Safie et al. <ref type="bibr" target="#b12">[13]</ref> adopted pulse active ratio as the features for one-to-one verification. Louis et al. <ref type="bibr" target="#b6">[7]</ref> proposed to use one-dimensional multi-resolution local binary patterns to extract features for continuous authentication system. However, these features may not be always easily obtained due to variations of ECG waveform from different people <ref type="bibr" target="#b40">[41]</ref>.</p><p>Clearly, the fiducial features are strictly influenced by the accuracy of the detection, especially for one-lead ECG signals with poor quality. For nonfiducial features, they are subdivided into auto-correction based <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b32">33]</ref>, phase space based <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref>, and frequency based <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46]</ref> features. However, although these methods help extract common features in some degree, it is difficult to select the reliable features. Different individuals present different characteristics by ECG. Designing a kind of real common and representative feature manually is somewhat difficult. Thus, these features extracted by statistics and domain transformation are somewhat coarse and sub-optimal.</p><p>(2) Learned features based methods. Different from traditional manual features based methods, learned features based methods tend to learn the structural and hierarchical characteristics and mine deep information from the ECG signals directly. Generally, training the learners iteratively to an optimal state can make them obtain a strong capability to extract representative features and improve the generalization ability of learners. However, there are few literatures for ECG biometrics using the learned features. Page et al. <ref type="bibr" target="#b22">[23]</ref> proposed to utilize neural networks (NN) for embedded ECG-based biometric authentication system. Neural networks were used for QRS detection and user identification.</p><p>However, the shallow networks used in <ref type="bibr" target="#b22">[23]</ref> cannot provide abundant features. Convolutional neural networks (CNN) have drawn much attention on various visual tasks such as image classification <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b4">5]</ref>, semantic segmentation <ref type="bibr" target="#b28">[29]</ref>, object detection <ref type="bibr" target="#b29">[30]</ref>, and so on. To extract abundant and multi-hierarchical features, stacked convolution operations with millions of parameters in different convolutional layers are executed. Recent works on skin cancer diagnosis <ref type="bibr" target="#b30">[31]</ref> and detection of diabetic retinopathy in retinal fundus photographs <ref type="bibr" target="#b31">[32]</ref> by CNN have gained huge success. Generally, there are some structural features in ECG signals <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, which promotes the combination of ECG and CNN. Kiranyaz et al. <ref type="bibr" target="#b46">[47]</ref> proposed to extract learned features from the ECG signals by 1-D CNN and demonstrated the performance of CNN for ECG classification <ref type="bibr" target="#b18">[19]</ref>. The strong capability of CNN for feature extraction of ECG signals has drawn extensive attention recently. In this study, we focus on developing a deep CNN method to extract learned features for ECG biometrics.</p><p>We then discuss the identification algorithms in ECG biometrics. The main identification methods can be categorized into (1) distance based methods and</p><p>(2) NN based methods.</p><p>(1) Distance based methods for identification. For distance based methods <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b24">25]</ref>, assigning the unknown sample to the class of the closest sample according the features distance in the features space is the most common approach for identification. The classifiers based on distance such as KNN classifiers, LDA classifiers, and SVM classifiers have been widely explored <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b48">49]</ref>.</p><p>(2) NN based methods for identification. Different from distance based methods, NN based methods tend to learn the complex non-linear relations between different input samples. The most commonly used NN for ECG biometrics is the multilayer perceptron (MLP) neural networks <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51]</ref> following the review of <ref type="bibr" target="#b9">[10]</ref>. NN based on radial basis function (RBF) have also been studied <ref type="bibr" target="#b51">[52]</ref>.</p><p>Due to the mechanism of neural network, directly learning non-linear relations from the training samples, we argue it is more effective than traditional distance based methods. As the evolution of conventional neural network, convolutional neural networks (CNN) help extract more abundant and hierarchical features by deep convolutional layers, and better fit the non-linear function. Besides the superiority of CNN itself, we analyze some drawbacks and differences of some related methods as follows.</p><p>PCA algorithm was used for feature extraction and dimension reduction. Then a Back Propagation Neural Network (BPNN) was used as a classifier. Although the method was built based on NN, the features to the NN classifiers were coarse which limited the final identification performance. Besides, the NN was designed for a special community. That could not be generalized to others, which is the main weakness as <ref type="bibr" target="#b50">[51]</ref>.</p><p>Differently, Wan et al. <ref type="bibr" target="#b52">[53]</ref> proposed to use a BPNN to predict the comparison result of wavelet coefficients from two ECG heartbeats. As the comparison classifier, the trained NN model could be used for any groups, which demonstrated the generalization ability of NN. However, as aforementioned, the features were manual based and coarse features, which limited the performance.</p><p>Zhang et al. <ref type="bibr" target="#b32">[33]</ref> proposed to use a multi-resolution CNN for identification.</p><p>However, wavelet and autocorrelation were conducted before input to the CNN for identification. In addition, the CNN was designed as a group dedicated CNN.</p><p>That is, once there were some changes about the members in the group, the CNN must be re-trained. Therefore, this kind of methods is of less practicality. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Method</head><p>As aforementioned, we argue that more attention should be paid to improve the generalization ability of the identification model by CNN. We propose to construct the Cascaded CNN towards improving ECG biometric identification.  First of all, we present the overview of the entire mechanism of the proposed 175 Cascaded CNN method for biometric identification via ECG. Following that, the data pre-processing operations for models training and testing in this study are presented. Subsequently, we show the details of F-CNN for feature extraction and M-CNN for template comparison respectively. Finally, we discuss other two CNN based mechanisms for biometric identification via ECG. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Data pre-processing</head><p>Before the detailed introduction of the Cascaded CNN, the pre-processing operations for ECG signals are discussed in this part. The ECG signals captured by sensors are easily disturbed by noise like baseline noise and powerline interference. Therefore, we perform noise filtering to improve the quality of ECG signals. Filtering and segmentation have been widely explored <ref type="bibr" target="#b53">[54]</ref>. Complex pre-processing operations are beyond of the scope of this study. Instead, filtering operation as <ref type="bibr" target="#b32">[33]</ref> is conducted for getting smoothed records. Only R peaks instead of much more fiducial points are detected as <ref type="bibr" target="#b36">[37]</ref>.</p><p>Because the human identification via ECG biometrics is based on heartbeats instead of sequential ECG recordings, segmentation of the ECG recordings based on R peaks is needed. To eliminate the effect of heart rate variations and keep the complete information containing key points such as P wave, QRS complex, and T wave, 40% and 60% durations of RR intervals are truncated as a heartbeat. To be suitable for CNN, the segmented heartbeats are resized to a fixed length M ? 1 .</p><p>The proposed method is based on template comparison. Templates of users are needed be generated and stored. To obtain a more representative template for one user as analysed in <ref type="bibr" target="#b8">[9]</ref>, several processing operations are performed. Denote x n as a heartbeat segmented from the registered recording and x as the calculated template by N heartbeats. We generate x as To eliminate the disturbance of some sudden change of amplitudes or stubborn noise, we calculate the Euclidean distances d n of x and x n as</p><formula xml:id="formula_0">x = 1 N N n=1 x n , n = 1, 2, . . . , N.<label>(1)</label></formula><formula xml:id="formula_1">d n = x -x n 2 , n = 1, 2, . . . , N.<label>(2)</label></formula><p>The first half of heartbeats with smallest d n are used to refine the x to x as Eq.</p><p>1. Finally, x is registered as the template.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Design of F-CNN</head><p>Conventionally, deep CNN is used for tasks about images and has achieved significant performance. However, for ECG, the data are in one dimensional structure. Thus, to motivate the superior power of CNN on ECG recognition, some modifications should be made to suit the one-dimensional ECG signals.</p><p>Several works <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b18">19]</ref> have been studied and demonstrated the availability of modified 1-D CNN for one dimensional ECG heartbeats classification. Despite the differences in the targets, it is no doubt that CNN can be used to learn representative and abundant features from ECG signals. represents the length (also known as spatial size) of the input, and D l represents the channel size of the input. Specifically, X 0 ? R M ?1?1 . Then, the output of the Convolution unit is calculated as</p><formula xml:id="formula_2">X l+1 = ReLU(BN(X l ? W l )) ? R H l+1 ?1?D l+1 ,<label>(3)</label></formula><p>where ? represents the convolution operation between input X l and convolutional kernel W l ? R h l ?1?D l ?D l+1 as descript in <ref type="bibr" target="#b46">[47]</ref>. h l ? 1 represents the convolution widow in Convolution units and D l+1 represents the channel size of output. Considering the characteristic of ECG signals, we do not adopt zero padding for convolutional layers in F-CNN. Typically,</p><formula xml:id="formula_3">H l+1 = (H l -h l )/s l + 1,<label>(4)</label></formula><p>where s l represents the convolution sliding stride, and z rounds down z if it is a fraction. BN(?) represents the Batch Normalization operation <ref type="bibr" target="#b55">[56]</ref>, and the nonlinear activation operation is performed by</p><formula xml:id="formula_4">ReLU(x)= ? ? ? x, x ? 0 0, otherwise .<label>(5)</label></formula><p>The output X l+1 of the current Convolution unit is input to the subsequent layer for further calculation.</p><p>(2) Pooling layer for subsampling. Pooling layer is widely used for feature dimension reduction. Max Pooling can provide translation invariant in some degree. Thus, for F-CNN, max Pooling is used for subsampling the feature.</p><p>Thus, for a Pooling window with a size of w l ? 1, the element with maximum value is kept as the output of that window. That is, for the k th subsampling window, the output value is calculated as</p><formula xml:id="formula_5">x l+1,k = max(x l,k,1 , x l,k,2 , x l,k,3 , ..., x l,k,w l ).<label>(6)</label></formula><p>A stride s l is adopted for sliding the subsampling window, the spatial size of the input of Pooling layer is reduced by s times approximately. Suppose the input is</p><formula xml:id="formula_6">X l ? R H l ?1?D l , then the output of the Pooling layer is X l+1 ? R H l+1 ?1?D l+1 ,</formula><p>where D l+1 is equal to D l and H l+1 can be inferenced by</p><formula xml:id="formula_7">H l+1 = (H l -w l )/s l + 1.<label>(7)</label></formula><p>For F-CNN, overlapped Pooling (w l &gt; s l ) without zero padding is adopted for keeping more information.</p><p>(3) Dropout layer for regularization. Dropout layer <ref type="bibr" target="#b54">[55]</ref> is proposed to regularize F-CNN for avoiding overfitting. Denote the input of Dropout layer as</p><formula xml:id="formula_8">X l ? R H l ?1?D l ,</formula><p>then the output is calculated as</p><formula xml:id="formula_9">X l+1 =m ? X l ? R H l+1 ?1?D l+1 ,<label>(8)</label></formula><p>where m ? Bernolli(p) is the randomly generated binary mask according to the Dropout rate p. Suppose p is equal to 0.5, then about 50% elements of the input features are set to zero while others keep same. For this layer, D l+1 is equal to D l . After the training of F-CNN, the Dropout layer will be removed to eliminate the uncertainty and randomness.</p><p>(4) Fully connected layer for encoding the global information. At the head of F-CNN, Fully connected layers are used for encoding global information. Denote the input vectored feature as</p><formula xml:id="formula_10">X v l ? R (H l ?1?D l )?1</formula><p>, then the Fully connected filters have the same spatial size as the input, that is,</p><formula xml:id="formula_11">W l ? R (H l ?1?D l )?D l+1 .</formula><p>The output X l+1 ? R 1?1?D l+1 of Fully connected layer is calculated as</p><formula xml:id="formula_12">x l+1,i = W l,i T X v l ? R 1 , i = 1, 2, ..., D l+1 .<label>(9)</label></formula><p>For the last classification with a fully connected layer, D l+1 is equal to N which is corresponding to the number of individuals in the F-CNN training dataset.</p><p>(5) Softmax layer for class prediction. Softmax layer converts the input values to probabilities which represent the classification confidences. Suppose there are N classes for F-CNN, for each class, the corresponding probability p j is calculated as p j =log( e x l,j j e x l,j ),</p><formula xml:id="formula_13">N j=1 p j =1, 0 ? p j ? 1, j = 1, 2, ..., N.<label>(10)</label></formula><p>When training F-CNN, the preprocessed heartbeats and corresponding classes (individuals) are supplied for supervised learning. Forward propagation (FP) is performed for predicting classification and calculating the prediction loss. For F-CNN, Softmaxloss as follows</p><formula xml:id="formula_14">L = - N j=1 y j log p j<label>(11)</label></formula><p>is adopted for calculating the loss, where y j = 1 if the current heartbeat is belong to the j th person. Otherwise, y j = 0. Backward propagation (BP) is performed for calculating the gradients of the filter weights and updating the weights with Stochastic Gradient Descent (SGD) algorithm and BP algorithm. FP and BP are performed iteratively to train F-CNN until the loss is convergent. The for match and non-match will be output as the final results. An illustration of M-CNN is presented as Fig. <ref type="figure" target="#fig_12">3</ref>. Notably, the proposed M-CNN share the similar motivation with the 2-channel networks in <ref type="bibr" target="#b5">[6]</ref>. Different from that in <ref type="bibr" target="#b5">[6]</ref>, our M-CNN is an 1-D CNN used for identification based on the features extracted by F-CNN. We also evaluate the performance of M-CNN without F-CNN in Table <ref type="table" target="#tab_2">4</ref> and prove that the proposed Cascaded CNN can achieve better performance than single M-CNN based method.</p><p>Due that one sample for M-CNN is composed of features from one heartbeat and one template by F-CNN, the size of one sample can be reshaped to L?2?1, that is, X 0 ? R L?2?1 , which is different from that of F-CNN. Therefore, for the convolutional layer in the first Convolution units, the filters should be in a spatial size of h ? 2 rather than h ? 1. Thus,</p><formula xml:id="formula_15">X 1 = ReLU(BN(X 0 ? W 0 )) ? R H1?1?D1<label>(12)</label></formula><p>where W 0 ? R h0?2?1?D1 . For other Convolution units, the similar operation as Eq. To use the Cascaded CNN for human identification, some post-processing operations are needed. To improve the security and reduce the false acceptance for one verified heartbeat, the match probabilities are compared and the comparison result with maximum matching probability is output by the system as the final identification result. To improve the identification rate in practice, vote by n consecutive heartbeats is adopted. That is, if there are more than half of the heartbeats matching with the same one template, then the user is identified to the individual who have registered the template. Otherwise, the identification is failure and more heartbeats are required for further identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Different mechanisms based on CNN for ECG biometrics</head><p>Although there are more advantages by using our Cascaded CNN as analyzed, it is still applicable for using one CNN for ECG biometric identification.</p><p>In this part, we discuss three kinds of mechanisms for ECG biometrics based on CNN.</p><p>(1) F-CNN based method. As aforementioned, the F-CNN is trained as a multi-classification CNN. So, it is apparent that the trained F-CNN can be used for identification directly as <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b32">33]</ref>. For a specific group with fixed members, the dedicated F-CNN is trained based on the ECG signals captured from each member. It can be used to identify the input heartbeats to corresponding individuals. F-CNN based methods can directly export the categories (corresponding individuals) of heartbeats at the top prediction layer of the network.</p><p>However, the network trained on one specific dataset (a group of individuals) in F-CNN based methods can only be used to test on the same dataset. Once the individuals are changed, the trained networks cannot work any longer. Thus, even when there are small changes about members in the current group such as someone in or out, the trained F-CNN fails to work.</p><p>(2) M-CNN based method. For the second kind of CNN mechanism, ECG biometric identification can be realized only based on M-CNN by replacing the input features to raw heartbeat signals. That is, all the amplitudes of raw ECG signals can be seen as manual features. Therefore, the architecture of M-CNN should be adjusted to suit for the new input. Although it is feasible, using manual features makes it difficult for M-CNN based method to achieve good performance.</p><p>(3) Cascaded CNN method. The Cascaded CNN mechanism for ECG biometrics can be seen as the third but most useful mechanism. Because the features input to M-CNN are learned by F-CNN, they are more general and representative than traditional manual features. Due to the learned features, nonlinear mapping function can be easily fitted by M-CNN. Thus, this method is more robust than the previous methods. Experimental results demonstrate the superiority of the proposed Cascaded CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head><p>In this section, five public datasets in Physionet <ref type="bibr" target="#b33">[34]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">ECG datasets</head><p>To the best of our knowledge, although the human identification via ECG biometrics has been explored for decade years, there is not a standard criterion for comparing different methods. The datasets for evaluating different methods are various and inconsistent. To make it convenient for others to implement and compare with the proposed method, five public datasets FANTASIA <ref type="bibr" target="#b56">[57]</ref>,</p><p>CEBSDB <ref type="bibr" target="#b57">[58]</ref>, NSRDB <ref type="bibr" target="#b58">[59]</ref>, STDB <ref type="bibr" target="#b59">[60]</ref>, and AFDB <ref type="bibr" target="#b60">[61]</ref> are used for conducting experiments. These datasets are collected in different conditions such as different members, different sample rates, different health states, etc. We present the configurations of these datasets in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Considering that most wearable devices digitalize the ECG signals at 250Hz, we resample all the ECG recordings to 250Hz firstly. For pre-processing, the ECG signals are filtered and the R-peaks are detected as mentioned in Sec. 3.2.</p><p>Then the long-term ECG recordings are segmented into heartbeats. According to the statistic, 196 is a suitable length for most ECG heartbeats to contain the entire P wave, QRS wave, and T wave. So we normalize each heartbeat into the fixed length 196 to meet the demand of CNN and fix the R-peak on the point 79 for simple alignment. We show some instances in Fig. <ref type="figure" target="#fig_8">4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Configuration of cascaded CNN</head><p>The network configuration of F-CNN for training stage is shown in Table <ref type="table">2</ref> and that of M-CNN is shown in Table <ref type="table" target="#tab_1">3</ref>. Multi-scale convolutional kernels help extract hierarchical and abundant features. Small size of convolutional filters are beneficial for the computational efficiency and extracting more sharp features.</p><p>Therefore, for the first three Convolution units of F-CNN, convolution filters with spatial sizes of 5?1, 5?1 and 3?1 are applied with 32, 64, and 128 filters, As shown in Table <ref type="table" target="#tab_1">3</ref>, for M-CNN, the convolutional filter in the first layer   After the training of F-CNN and M-CNN, the Cascaded CNN is constructed by the trained F-CNN and M-CNN. When using the Cascaded CNN for identification, one heartbeat and one template compose an input sample to the network. Therefore, the input size of our Cascaded CNN can be represented as 196 ? 2. Our method can be used for identification for various groups. For the identification phase of Cascaded CNN, one heartbeat is combined with one registered template as a test sample with a size of 196?2 and input to the Cascaded CNN for calculating the match probability.</p><formula xml:id="formula_16">F-CNN Layers Input Size Parameters Output Size C1 196 ? 1 ? 1 5 ? 1 ? 1 ? 32, s = 2 96 ? 1 ? 32 C2 96 ? 1 ? 32 5 ? 1 ? 32 ? 64, s = 2 46 ? 1 ? 64 P1 46 ? 1 ? 64 3 ? 1, s = 2 22 ? 1 ? 64 C3 22 ? 1 ? 64 3 ? 1 ? 64 ? 128, s = 20 ? 1 ? 128 P2 20 ? 1 ? 128 3 ? 1, s = 2 9 ? 1 ? 128 F1 9 ? 1 ? 128 9 ? 1 ? 128 ? 64 1 ? 1 ? 64 F2 1 ? 1 ? 64 1 ? 1 ? 64 ? 256 1 ? 1 ? 256 F3 1 ? 1 ? 256 1 ? 1 ? 256 ? 40 1 ? 1 ? 40 Table 2: Configurations of F-CNN M-CNN Layers Input Size Parameters Output Size C1 64 ? 2 ? 1 5 ? 2 ? 1 ? 32, s = 1 60 ? 1 ? 32 P1 60 ? 1 ? 32 5 ? 1, s = 2 28 ? 1 ? 32 C2 28 ? 1 ? 32 3 ? 1 ? 32 ? 64, s = 26 ? 1 ? 64 P2 26 ? 1 ? 64 5 ? 1, s = 2 11 ? 1 ? 64 C3 11 ? 1 ? 64 5 ? 1 ? 64 ? 64, s = 7 ? 1 ? 64 F1 7 ? 1 ? 64 7 ? 1 ? 64 ? 64 1 ? 1 ? 64 F2 1 ? 1 ? 64 1 ? 1 ? 64 ? 2 1 ? 1 ? 2</formula><p>For F-CNN based method, the network trained on Dataset F can be directly used for identification on the current FANTASIA dataset. The trained F-CNN cannot be used for identification on other datasets directly unless retrained.   The identification performance of F-CNN based method, M-CNN based method and Cascaded CNN are presented in Table <ref type="table" target="#tab_2">4</ref>. 97.8%, 98.1% and 99.3% identification rates are obtained by F-CNN based method, M-CNN based method, and Cascaded CNN, respectively. Apparently, with the F-CNN for feature extraction, 1.2% outperformance against M-CNN based method is achieved by the proposed Cascaded CNN, which demonstrates our motivation that extracting deeper and finer features is beneficial for better identification performance.</p><p>In addition, the proposed Cascaded CNN outperforms F-CNN based method by 1.5%. M-CNN based method slightly outperforms F-CNN based method by 0.3%. Besides, the inherent drawback, less generalization ability, of F-CNN based method limits its practical application. Consequently, matching mechanism is more superior.</p><p>Due that the proposed Cascaded CNN and M-CNN based method realize identification by template comparison mechanism, the trained Cascaded CNN and the network for M-CNN based method on FANTASIA dataset can be directly used for identification on other datasets without retraining and finetuning. To further demonstrate the superior of Cascaded CNN to M-CNN based method, we evaluate these two methods on CEBSDB, NSRDB, STDB, and AFDB datasets. For each of these datasets, the first 100 heartbeats of each individual are used for calculating the template and other 200 heartbeats are randomly selected to compose the test dataset.</p><p>The evaluation result is shown in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Test performance of Cascaded CNN</head><p>In this part, we evaluate the proposed Cascaded CNN by votes of heartbeats and also discuss the influence of scalability to the identification performance.</p><p>(1) The performance by voting of heartbeats.</p><p>In practice, to improve the identification performance and security, identification based on sequential heartbeats is preferred sometimes. So we explore the contribution of votes by different number of heartbeats to identification performance. Experiments by votes of 3, 5, 8, 10, 15, and 20 heartbeats are conducted respectively. The identification results on these datasets are shown in Table <ref type="table" target="#tab_5">6</ref>.  It is apparent that with the increasing of the voting heartbeats, the identification performance is improved. Although using more heartbeats for vote benefits the identification accuracy, considering the time cost for ECG signals collection</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>As shown in</head><p>for identification in practice, in this study, we advocate to use 3 heartbeats for the final identification. Therefore, we take the identification rates by votes of 3 heartbeats as the final identification performance for other experiments.</p><p>(  The generalization of the identification methods also influence the final performance in practice. So in this study, the proposed method is simply compared with some methods, as shown in  and much better than those of <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b63">64]</ref> by a large margin. However, the dedicated methods presented in Table <ref type="table" target="#tab_10">9</ref> do not satisfy the practical demands for convenience and generalization.</p><p>We have also evaluated the trained Cascaded CNN on other four datasets, which is more convictive than other methods for practicality. Comparing with generic methods <ref type="bibr" target="#b24">[25]</ref> and <ref type="bibr" target="#b45">[46]</ref>, the proposed Cascaded CNN achieves better performance. In <ref type="bibr" target="#b45">[46]</ref>, if 5s ECG signals are used for once identification, only 82.2% identification rate which is far less than 94.3% by 3 heartbeats obtained by the proposed Cascaded CNN. If 10 heartbeats are used for vote in our method, 97.1% identification rate outperforming that of <ref type="bibr" target="#b45">[46]</ref> by 1.5% is gained. Notably, when evaluating on new datasets, method in <ref type="bibr" target="#b45">[46]</ref> needs to compute more new parameters whereas the trained Cascaded CNN is directly used without updating any parameters.</p><p>Besides, we also compare the proposed method with HeartID <ref type="bibr" target="#b32">[33]</ref> on the same five datasets. As a dedicated method, HeartID trained different models for different datasets. We show the performance comparison in Table <ref type="table" target="#tab_12">10</ref>. Although our Cascaded CNN is only trained on FANTASIA dataset, it still outperforms the dedicated HeartID method on NSRDB and STDB. Overall, the proposed Cascaded CNN owns more advantages and can achieve high performance for identification in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Computational complexity of cascaded CNN</head><p>In this part, we analyze the computational complexity of our Cascaded CNN.</p><p>The proposed method is implemented based on MatConvNet <ref type="bibr" target="#b64">[65]</ref> with some modifications to make it suitable for ECG biometric identification. All these experiments are performed on a computer device with I7-4790 CPU at 3.60GHz.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Different from the aforementioned methods, we propose to train a deep CNN (F-CNN) for feature extraction and another deep CNN (M-CNN) for identification matching progressively. The Cascaded CNN by combining the F-CNN and M-CNN is used to implement the human identification via ECG. The features learned by F-CNN, from deep convolutional layers, which are abstract, representative and fine, are superior to manual based features. Besides, M-CNN, based on comparison mechanism, makes the Cascaded CNN general and suitable for various communities with variable number of members. We analyze the details of the proposed Cascaded CNN in Sec. 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) Training phase of the Cascaded CNN. Output F CNN (b) Identification phase of the Cascaded CNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An overview of the proposed Cascaded CNN for human identification via ECG biometrics. (a) Training phase of the Cascaded CNN; (b) Identification phase of the Cascaded CNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>180 3 . 1 .</head><label>31</label><figDesc>Overview of our methodAn illustration of our method with training phase and identification phase is shown in Fig.1. Due to the practical demands for real-time identification, this study focuses on the identification via ECG heartbeats instead of long-term ECG recordings. That is, ECG records are pre-processed by noise filtering and heartbeats segmentation to meet the demands.As shown in Fig.1(a), two steps, training of the F-CNN and training of the M-CNN, are contained in the training phase of the Cascaded CNN. First, we train the F-CNN by the manner of multi-classification. The heartbeats with the annotations indicating the belonging individuals are collected and input to the F-CNN for training iteratively. For the M-CNN training, templates for different individuals are generated firstly. Training samples are generated by combining different heartbeats with different templates. The corresponding match or nonmatch annotations are labeled. These samples are input to the trained backbone network of F-CNN for feature extraction. Then the features of heartbeat and the template are input to M-CNN for predicting the comparison result. Thus, M-CNN is trained by the manner of binary-classification. Subsequently, M-CNN is trained iteratively based on the extracted features until convergence. After training the F-CNN and M-CNN, the backbone network of F-CNN and the M-CNN are cascaded to compose the Cascaded CNN. For the identification phase of the proposed method, as shown in Fig. 1(b), when inputting one heartbeat and one registered template, the backbone network of F-CNN is used to extract learned features firstly. Then, the features are input to M-CNN for predicting the comparison results. If the match probability is larger than that of non-match, match decision is output. In practice, there are more than one person in the registered system. Thus, the match probabilities with different templates are ulteriorly compared to identify the current heartbeat to the one with largest probability. Due to the comparison mechanism which the Cascaded CNN is built based on, the trained Cascaded CNN can be used for human identification without the limitation of the members in the communities. Even if there are some changes about the members like someone out or others in, the trained Cascaded CNN can still work for human identification without retraining. Besides, no extra manual features but original ECG heartbeats are used for biometric identification in this study. Complex non-linear mapping function between heartbeats and match results is directly learned by the Cascaded CNN. Details of F-CNN and M-CNN are presented subsequently.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Architecture of F-CNN in training phase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>For</head><label></label><figDesc>ECG signals, all the convolutional kernels (filters) and Pooling windows are in the form of h ? 1 instead of h ? h which is always used for image tasks. To learn general and discriminated features directly from the ECG signals, Convolution units, Dropout layers [55], Pooling layers, Fully connected layers, and Softmax layer are stacked to compose the F-CNN. The architecture of F-CNN for training phase is shown in Fig. 2. From Fig. 2, suppose the size of one input heartbeat is M ? 1 as we analyzed in Section 3.2. At the training phase of F-CNN, the size of output is 1?N where N refers to the number of individuals in the training database. The output results correspond to the probabilities of the current heartbeat belonging to each individual.As shown in Fig.2, F-CNN is constructed by stacking three Convolution units (C1, C2, C3), two Pooling layers (P1, P2), and three Fully connected layers (F1, F2, F3). Considering the instability of low-level features in the bottom layers, only one Dropout layer is added to the end of P2 layer to regularize F-CNN. Softmax layer is appended to the top of F-CNN for calculating the classification probabilities. Denote X l as the input of (l+1)th layer and X l+1 as the output of (l+1) th layer. Then we discuss the typical operations of F-CNN as follows.(1)Convolution unit for feature extraction. In F-CNN, Convolution unit is composed of convolutional operation, Batch Normalization (BN) operation [56], and ReLU activation. BN is widely used to promote the convergence of deep network. ReLU non-linear activation function can alleviate the gradient vanishment problem of deep CNN. For one specific Convolution unit in F-CNN, denote the input (one ECG heartbeat or ECG feature vectors calculated by the previous layer) of the current Convolution unit as X l ? R H l ?1?D l , where H l ? 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>h 2 Figure 3 :</head><label>23</label><figDesc>Figure 3: Architecture of M-CNN in training phase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>3 is performed for M-CNN. The operations in Pooling layer, Dropout layer, Fully connected layer, and Softmax layer of M-CNN are executed as Eq.3 -Eq. 10 of F-CNN. Because there are only two classes for M-CNN, match and non-match, N in Softmax layer is equal to 2. Besides, Softmaxloss as shown in Eq. 11 is also adopted for training M-CNN. The specific configurations of M-CNN for the evaluation experiments in this paper is shown in Table3and discussed in Sec. 4.2.3.5. Cascaded CNN for identificationAfter the training of F-CNN and M-CNN, the Cascaded CNN is generated by cascading these two networks with some modification. For CNN, the features extracted by shallow layers are somewhat coarse features whereas deeper layers are responsible for more hierarchical features. So extracting features from the deep layer is more robust. In F-CNN, the last two fully connected layers are used for generating the features for classification. So the features extracted for the last two fully connected layers are task-specific. To obtain more general ECG features, the last two fully connected layers of F-CNN are removed. The rest layers of F-CNN are connected with M-CNN to compose the Cascaded CNN for ECG biometric identification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Some instances from the ECG datasets. (a)The raw ECG signals from FANTASIA dataset without pre-processing; (b)-(f) present the segmented heartbeats from the corresponding datasets shown in Table 1 with all the R peaks are fixed in the point 79 of the length 196.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>respectively. The fully connection window of the first fully connected layers is of size 9?1 with 64 filters, and the last two are of size 1?1 with 256 filters and 40 (using FANFASIA for training) filters, respectively. The Pooling layers used in F-CNN configured with pooling window 3?1 and stride 2. So the input size of M-CNN is 64?2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>475</head><label></label><figDesc>For training phase, F-CNN is trained based on single heartbeat with size 196?1 on FANTASIA dataset. Each heartbeat with its label (corresponding individual) is input to F-CNN as a sample. Because there are 40 individuals in FANTASIA dataset, the output of F-CNN is in a size of 1?1?40. That is, there are 40 nodes in the output layer. Each node represents the probability of iden-480 tification to current individual. To evaluate the Cascaded CNN on FANTASIA dataset, for each member, 1000 heartbeats are randomly selected. We split the Training curves of M-CNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Training curves of the proposed cascaded CNN. (a) Training curves of F-CNN; (b) Training curves of M-CNN. samples by 3: 1: 1 to compose the training, validation, and test dataset, respectively. Totally, there are 24000 samples in training dataset and 8000 samples in validation dataset for F-CNN. These samples compose the Dataset F. The other 8000 samples compose the test dataset. F-CNN is trained by batch SGD algorithm with a mini-batch size of 30 at a fixed constant momentum value of 0.9. For M-CNN training, the templates of 40 members in FANTASIA dataset are generated firstly. 800 heartbeats of each individual in the training and validation dataset of F-CNN are used for generating training and validation datasets of M-CNN. The rest 200 heartbeats of each individual as those in F-CNN are used for testing. In order to generating a more representative template for one individual, the first 100 heartbeats are selected and calculated as Eq. 1 and Eq. 2. The rest 700 heartbeats of each person are used to generate the training dataset for M-CNN when combining with templates. There are 28000 positive samples and much more negative samples. To keep the balance of M-CNN, 28000 negative samples are randomly sampled. 80% of them for training and others for validation. These samples composed the Dataset M. Inputting the samples into F-CNN, features are extracted for generating the training samples of M-CNN. Subsequently, M-CNN is trained by batch SGD algorithm with a mini-batch size as 200 at a fixed constant momentum value of 0.9. The dropout layers in F-CNN and M-CNN are configured with dropout rate 0.5. All the filters in F-CNN and M-CNN are initialized by Gaussian method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>4. 3 .</head><label>3</label><figDesc>Comparison of CNN based methods on FANTASIA CNN based methods with different mechanisms as discussed in Sec. 3.6 are compared and analyzed in this part. To evaluate the performance, FANTASIA dataset is used for conducting experiments. As aforementioned, there are 200 heartbeats for each member in test dataset for evaluating the performance of identification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>For M-CNN</head><label></label><figDesc>based method, the architecture need be designed before used for identification due to the input size 196?2 instead of 64?2. We modified the filters of the first Convolution unit in F-CNN to 5?2. The output nodes are set as 2 instead of 40. The modified network are used for M-CNN based method and trained on Dataset M.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>Notably, there is no any acceleration technique such as parallel computation by GPUs to be used for faster speed. Actually, all the training and test stages can be executed fast enough. Only 13 minutes are needed for training F-CNN. Because of the larger number of training samples for M-CNN, 27 minutes are needed for training M-CNN. If more training data are used, the time cost will be increased for training the Cascaded CNN. However, once Cascaded CNN is trained well, it can be used for any groups without retraining steps. Therefore, the training time for the Cascaded CNN can be neglected in practice, which is quite different from the dedicated methods. For practical use, the human identification should not consume a significant amount of time and should be in real-time even. We count the time for once comparison operation in our experiments without deep code optimization, which is from inputting one heartbeat and one template to Cascaded CNN to outputting the comparison result. From experiments, only 2 milliseconds are needed. That is, for a group with 5 members, only 0.01 second is needed for once human identification by one ECG heartbeat. With 100 individuals, only 0.2 second is needed for once identification. For 3 heartbeats, 0.6 second is needed for identification. Considering the time for heartbeat acquisition and pre-processing, for identification by one heartbeat, 2 seconds are enough. As for identification by votes of 3 heartbeats, 2-3 seconds are needed to get better identification performance. All these show the efficiency of the proposed Cascaded CNN and the feasibility for practical use.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>5 .</head><label>5</label><figDesc>Conclusion and Future WorkIn this paper, we have proposed to apply a Cascaded CNN for biometric identification via ECG. The Cascaded CNN consists of two CNN, one CNN called F-CNN for feature extraction and the other called M-CNN for identification.Due to the superiority of the proposed method, it is of stronger generalization ability to be used for various groups with variable individuals and is capable to achieve significant performance. Once the Cascaded CNN is trained well, it can be directly used for various groups for identification without any re-training or fine-tuning. Experimental results demonstrate the effectiveness and efficiency of the proposed method. Due to the low computational complexity and high speed for ECG biometric identification, it promotes the application of ECG biometrics for human identification in practice.Despite of the success achieved by the proposed method, there are still some problems which need be overcame in the subsequent exploration. For instance, the ECG states of one individual are always changeable in different conditions such as before and after exercise. For one individual, there are always large variations for ECG waveforms during a long span, which causes interference to the ECG signals and makes it somewhat difficult for ECG biometric identification. How to eliminate the effect of different states and capture more robust characteristics are worthy of further researches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Configurations of ECG Datasets</figDesc><table><row><cell>are used for evaluating</cell></row></table><note><p>tional complexity of the proposed method is analyzed. From the experimental results, the proposed Cascaded CNN is effective and efficient to realize human identification via ECG biometrics.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>Configurations of M-CNN</figDesc><table /><note><p>is in a spatial size of 5?2 with 32 filters for feature fusion. Others are in 5?1 and 3?1 with 64 filters respectively. All the convolutional layers are with the stride 1. The Pooling window size of the Pooling layers is 5?1 with stride 2 for fusing more features.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 :</head><label>4</label><figDesc>Performance Comparison by Identification Rate on FANTASIA Dataset for Different</figDesc><table><row><cell>CNN Based Methods</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell cols="3">Identification Accuracy Rates (%) by CNN Methods M-CNN Based Cascaded CNN ?(%)</cell></row><row><cell>CEBSDB</cell><cell>90.9</cell><cell>93.1</cell><cell>2.2</cell></row><row><cell>NSRDB</cell><cell>87.9</cell><cell>91.4</cell><cell>3.5</cell></row><row><cell>STDB</cell><cell>87.4</cell><cell>92.7</cell><cell>5.3</cell></row><row><cell>AFDB</cell><cell>88.5</cell><cell>89.7</cell><cell>1.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 :</head><label>5</label><figDesc>Performance Comparison by Identification Rates for Different CNN Based Methods on Different Datasets</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>On the test dataset of CEBSDB,</figDesc><table><row><cell>NSRDB, STDB, and AFDB datasets, 93.1%, 91.4%, 92.7%, 89.7% identifica-</cell></row><row><cell>tion rates can be obtained by the proposed Cascaded CNN, which outperforms</cell></row><row><cell>those of M-CNN based method by 2.2%, 3.5%, 5.3%, and 1.2%, respectively.</cell></row><row><cell>From the experimental results, more representative features are beneficial to the</cell></row><row><cell>final identification. The effectiveness of F-CNN for feature extraction of Cas-</cell></row><row><cell>caded CNN is demonstrated. With strong generalization ability, the proposed</cell></row><row><cell>Cascaded CNN achieves better performance than other CNN based methods.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell>, if only one heartbeat is used for identification, 99.3%,</cell></row><row><cell>93.1%, 91.4%, 92.7%, and 89.7% identification rates are gained for FANTA-</cell></row><row><cell>SIA, CEBSDB, NSRDB, STDB, and AFDB, respectively. The identification</cell></row><row><cell>performance demonstrates the superior generalization ability of the proposed</cell></row><row><cell>Cascaded CNN. Fig. 6 presents the confusion matrix for human identification</cell></row><row><cell>on the test datasets. Some heartbeats which are not presented on the diag-</cell></row><row><cell>onal are false matched. Consequently, only slight false match samples occur</cell></row><row><cell>occasionally which accords with the characteristics of the proposed method.</cell></row><row><cell>When 3 heartbeats are used for identification, 99.9%, 95.0%, 96.1%, 95.2%,</cell></row><row><cell>and 90.9% performance are gained for FANTASIA, CEBSDB, NSRDB, STDB,</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Identification Performance of the Proposed Cascaded CNN on Different DatasetsFigure 6: Confusion Matrix for identification performance on the test datasets.and AFDB, respectively. By average, by voting of 3 heartbeats, regardless of the FANTASIA dataset, 94.3% average identification rate, outperforming that of with one heartbeat by 2.6%, is achieved on the other four datasets. By average on CEBSDB, NSRDB, STDB, and AFDB datasets, 95.6%, 97.0%, 97.1%, 97.1%,</figDesc><table><row><cell>and 97.7% identification rates can be achieved by votes of 5, 8, 10, 15, and 20</cell></row><row><cell>heartbeats, respectively.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>)</head><label></label><figDesc>Test performance for different training dataset scales.</figDesc><table><row><cell>Datasets</cell><cell cols="3">Identification Rates (%) with Different Scales 20 30 40</cell></row><row><cell>CEBSDB</cell><cell>64.4</cell><cell>84.0</cell><cell>95.0</cell></row><row><cell>NSRDB</cell><cell>94.3</cell><cell>94.4</cell><cell>96.1</cell></row><row><cell>STDB</cell><cell>91.7</cell><cell>92.8</cell><cell>95.2</cell></row><row><cell>AFDB</cell><cell>87.2</cell><cell>88.1</cell><cell>90.9</cell></row><row><cell>Average</cell><cell>84.4</cell><cell>89.8</cell><cell>94.3</cell></row><row><cell cols="4">Further, to evaluate the influence of training dataset scales, we train sev-</cell></row><row><cell cols="4">eral models on different training datasets with different numbers of individuals</cell></row><row><cell cols="4">from FANTASIA, and evaluate them on CEBSDB, NSRDB, STDB, and AFDB,</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Identification Performance of the Proposed Cascaded CNN on Different Datasets by Training on Different Datasets with Different Scales of Individuals</figDesc><table><row><cell>CNN Methods</cell><cell>5</cell><cell>10</cell><cell>20</cell><cell>40</cell><cell>60</cell><cell>129</cell></row><row><cell>Identification Accuracy (%)</cell><cell>99.8</cell><cell>99.1</cell><cell>97.6</cell><cell>96.4</cell><cell>96.0</cell><cell>95.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Identification Performance of the Proposed Cascaded CNN on Test Datasets with Different Scales of Individuals.respectively. The performance of Cascaded CNN is shown in Table7. When us-</figDesc><table><row><cell>ing 20, 30, and 40 individuals' data from FANTASIA dataset to train Cascaded</cell></row><row><cell>CNN, 84.4%, 89.8%, and 94.3% average identification rates can be obtained,</cell></row><row><cell>respectively. Thus, more training datasets from more individuals are beneficial</cell></row><row><cell>to improve the identification performance.</cell></row><row><cell>(3) Test performance for different test dataset scales.</cell></row><row><cell>To evaluate the influence of test dataset scales, experiments are conducted</cell></row><row><cell>for testing on different datasets with different individual scales. To increase the</cell></row><row><cell>number of individuals, we integrate all the members from FANTASIA, CEB-</cell></row><row><cell>SDB, NSRDB, STDB, and AFDB datasets to one dataset. There are totally</cell></row><row><cell>129 individuals in the mixed dataset. Then the mixed dataset is divided into</cell></row><row><cell>6 scales which contain 5, 10, 20, 40, 60, and 129 individuals, respectively. For</cell></row><row><cell>scale with 5 individuals, the mixed dataset is split into 25 groups stochastically.</cell></row><row><cell>The test identification rate is averaged on all the groups with the same scale. So</cell></row><row><cell>do for the other datasets. The test performance of Cascaded CNN on different</cell></row><row><cell>test scales is shown in Table 8.</cell></row><row><cell>When evaluating the Cascaded CNN on test datasets with scales 5, 10, 20,</cell></row></table><note><p>To verify the performance of our method for imposter rejection, for once evaluation, we delete one specific individuals template from the template reference set and input the probe of that individual to the Cascaded CNN for identification. If the matching probabilities of one heartbeat with all the templates are all smaller than the threshold (0.5), the individual is thought as the one who hasn't registered before (i.e., imposter) and the identification is correct. Oth-</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Performance Comparison with Other Methods</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 ,</head><label>9</label><figDesc>in terms of what types of features are extracted for identification, what kinds of identification algorithms are adopted, whether the models in the methods are general for different datasets or ded-</figDesc><table><row><cell>650</cell><cell></cell></row><row><cell></cell><cell>icated for the training dataset, what kinds of datasets are used for test, how</cell></row><row><cell></cell><cell>long the duration of ECG signals for once identification is needed, and what the</cell></row><row><cell></cell><cell>average identification rate can be achieved.</cell></row><row><cell></cell><cell>In Table 9, only the proposed Cascaded CNN owns the characteristics of</cell></row><row><cell>655</cell><cell>learned features and superior generalization ability simultaneously. Only meth-</cell></row><row><cell></cell><cell>ods in [25] and [46] are generic methods as ours which can be used for various</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 10 :</head><label>10</label><figDesc>Performance Comparison Between Our Method and HeartID on the Same Datasets groups. The other methods are dedicated methods which can only be used for specific groups. From Table9, if we directly apply the Cascaded CNN trained on FANTASIA dataset as a dedicated CNN for FANTASIA dataset with 40 subjects, 99.9% identification rate can be achieved. The identification performance is better than that of the best dedicated method in<ref type="bibr" target="#b49">[50]</ref> which achieved 99.6%</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Human identification using finger vein and ECG signals</title>
		<author>
			<persName><forename type="first">K</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">332</biblScope>
			<biblScope unit="page" from="111" to="118" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fingerprint indexing schemes-A survey</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Arora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">335</biblScope>
			<biblScope unit="page" from="352" to="365" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Arrhythmia classification using mahalanobis distance based improved fuzzy c-means clustering for mobile health monitoring systems</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A H</forename><surname>Haldar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Abbas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="page" from="221" to="235" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ECG beat classification via deterministic learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">240</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Randomly translational activation inspired by the input distributions of ReLU</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">275</biblScope>
			<biblScope unit="page" from="859" to="868" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to compare image patches via convolutional neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="4353" to="4361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Continuous authentication using one-dimensional multi-resolution local binary patterns (1DMRLBP) in ECG biometrics</title>
		<author>
			<persName><forename type="first">W</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Komeili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hatzinakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2818" to="2832" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cardiovascu-lar biometrics: Combining mechanical and electrical signals</title>
		<author>
			<persName><forename type="first">I</forename><surname>Odinaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>O'sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Sirevaag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Rohrbaugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="16" to="27" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On evaluating ECG biometric systems: Session-dependence and body posture</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wahabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pouryayevali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hatzinakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2002" to="2013" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ECG biometric recognition: A comparative analysis</title>
		<author>
			<persName><forename type="first">I</forename><surname>Odinaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Osullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Sirevaag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Rohrbaugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">18121824</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A discriminative feature learning approach for deep face recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="499" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Electrocardiogram (ECG) biometric authentication using pulse active ratio (PAR)</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Safie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Soraghan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Petropoulakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1315" to="1322" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Individual identification via electrocardiogram analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fratini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sansone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bifulco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cesareli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioMedical Engineering OnLine</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">78</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ECG authentication for mobile devices</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Arteaga-Falconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Osman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>El-Saddik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Instrumentation and Measurement</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">591600</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Biometric authentication using noisy electrocardiograms acquired by mobile sensors</title>
		<author>
			<persName><forename type="first">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">12661273</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">ECG analysis: a new approach in human identification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Biel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Pettersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Philipson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Instrumentation and Measurement</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">808812</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">One-lead ECG for identity verification</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Tompkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second Joint Engineering in Medicine and Biology and the Fall Meeting of the Biomedical Engineering Society</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="62" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Patient-specific ECG classification by deeper CNN from generic to dedicated</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">314</biblScope>
			<biblScope unit="page" from="336" to="346" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">ECG authentication system design based on signal analysis in mobile and wearable devices</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">I</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="805" to="808" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Toward improving electrocardiogram (ECG) biometric verification using mobile sensors: A two-stage classifier approach</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">410</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Development of an ECG identification system</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kyoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Uchiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Conference on Engineering in Medicine and Biology Society</title>
		<imprint>
			<biblScope unit="page" from="3721" to="3723" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Utilizing deep neural nets for an embedded ECG-based biometric authentication system</title>
		<author>
			<persName><forename type="first">A</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mohsenin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Biomedical Circuits and Systems Conference(BioCAS)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Wiederhold, ECG to identify individuals</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Israel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Wiederhold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="133" to="142" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Wavelet distance measure for person identification using electrocardiograms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Hamdy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Badre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Badee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Instrumentation and Measurement</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="248" to="253" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Implementation of a onelead ECG human identification system on a normal population</title>
		<author>
			<persName><forename type="first">T.-W</forename><forename type="middle">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Tompkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Engineering and Computer Innovations</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="12" to="21" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Convolution in convolution for network in network</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1587" to="1597" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cascaded subpatch networks for effective CNNs</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2684" to="2694" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Region-based convolutional networks for accurate object detection and segmentation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="142" to="158" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dermatologist-level classification of skin cancer with deep neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Esteva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kuprel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Novoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Swetter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Blau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">542</biblScope>
			<biblScope unit="issue">7639</biblScope>
			<biblScope unit="page" from="115" to="118" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs</title>
		<author>
			<persName><forename type="first">V</forename><surname>Gulshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Coram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Stumpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Widner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Madams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cuadros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Webster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Association</title>
		<imprint>
			<biblScope unit="volume">316</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="2402" to="2410" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">HeartID: A multiresolution convolutional neural network for ECG-based biometric human identification in smart health applications</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="11805" to="11816" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A N</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hausdorff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Mietus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="215" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Detection of ECG characteristic points using wavelet transforms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="28" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A wavelet-based ECG delineator: evaluation on standard databases</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Laguna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="570" to="581" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Accurate ECG R-peak detection for telemedicine</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">X</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rayside</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Canada International Humanitarian Technology Conference (IHTC)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Fusing face and ECG for personal identification</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Israel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Scruggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Worek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Irvine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">nd Applied Imagery Pattern Recognition Workshop</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="226" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A wavelet method for biometric identification using wearable ECG sensors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th International Summer School and Symposium on Medical Devices and Biosensors</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="297" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">One-lead ECG-based personal identification using Ziv-Merhav cross parsing</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Fred</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">20th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="3858" to="3861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Body surface ECG signal shape dispersion</title>
		<author>
			<persName><forename type="first">B</forename><surname>Khaddoumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Meste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fereniec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Maniewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="2491" to="2500" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">ECG biometric recognition without fiducial detection</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Plataniotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hatzinakos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biometric Consortium Conference</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A measure of relative entropy between individual sequences with application to universal classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ziv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Merhav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1270" to="1279" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">QRS detection-free electrocardiogram biometrics in the reconstructed phase space</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="595" to="602" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">ECG-based personal identification using empirical mode decomposition and Hilbert transform</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kouchaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Omranian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boostani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">16th CSI International Symposium on Artificial Intelligence and Signal Processing</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="569" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A human ECG identification system based on ensemble empirical mode decomposition</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="6832" to="6864" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Real-time patient-specific ECG classification by 1-D convolutional neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kiranyaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ince</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="664" to="675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Human identification by quantifying similarity and dissimilarity in electrocardiogram phase space</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1824" to="1831" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Robust ECG biometrics by fusing temporal and cepstral information</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">20th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1326" to="1329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">ECG identification based on neural networks, in: International Computer Conference on Wavelet Active Media Technology and Information Processing</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="92" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">ECG biometric using multilayer perceptron and radial basis function neural networks, in 2011 Annual International Conference of the</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Khalil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Engineering in Medicine and Biology Society (EMBC)</title>
		<imprint>
			<biblScope unit="page" from="2745" to="2748" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">ECG personal identification in subspaces using radial basis neural networks</title>
		<author>
			<persName><forename type="first">O</forename><surname>Boumbarov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Velchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sokolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Workshop on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="446" to="451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A neural network to identify human subjects with electrocardiogram signals</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Congress on Engineering and Computer Science</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">ECGbased heartbeat classification for arrhythmia detection: A survey</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Luz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Camara-Chavez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Menotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Methods and Programs in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page" from="144" to="164" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Christian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Age-related alterations in the fractal scaling of cardiac interbeat interval dynamics</title>
		<author>
			<persName><forename type="first">N</forename><surname>Iyengar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Morin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Lipsitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Physiology-Regulatory, Integrative and Comparative Physiology</title>
		<imprint>
			<biblScope unit="volume">271</biblScope>
			<biblScope unit="page" from="1078" to="1084" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Garcia-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Argelags</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fernndez-Chimeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ramos-Castro</surname></persName>
		</author>
		<title level="m">Mediterranean Conference on Medical and Biological Engineering and Computing</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="962" to="964" />
		</imprint>
	</monogr>
	<note>Differences in QRS locations due to ECG lead: relationship with breathing</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A comparison of heartbeat detectors for the seismocardiogram</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Garcia-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Argelags</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fernndez-Chimeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ramos-Castro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computing in Cardiology Conference (CinC)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="461" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">ST segment characterization for long term automated ECG analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Albrecht</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A new method for detecting atrial fibrillation using RR intervals</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Cardiology</title>
		<imprint>
			<biblScope unit="page" from="227" to="230" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Classification of electrocardiogram signals with RS and quantum neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Multimedia and Ubiquitous Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="363" to="372" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">ECG based personal identification using extended Kalman filter</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Salleh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Conference on Information Science, Signal Processing and their Applications</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="774" to="777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Investigation of human identification using two-lead electrocardiogram (ECG) signals</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Coimbra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth IEEE International Conference on Biometrics: Theory Applications and Systems 930 (BTAS)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">MatConvNet: Convolutional neural networks for matlab</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lenc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Multimedia Conference</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="689" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">He is currently a Ph.D. degree candidate in the Tianjin University and his supervisor is Prof. Yanwei Pang. His research interests include deep learning and its application in biometric recognition and computer vision</title>
		<author>
			<orgName type="collaboration">Yazhao Li received the B.S</orgName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<pubPlace>Tianjin, China</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Tianjin University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">His current research interests include object detection, image recognition, image processing, and their applications in self-driving cars, visual surveillance, human-machine interaction, and biometrics, in which he has published more than 120 scientific papers including 35 IEEE Transactions papers. Kongqiao Wang received the Ph.D. degree in signal and information processing from the University of Science and Technology of China</title>
	</analytic>
	<monogr>
		<title level="m">Currently, he has been with the Nokia Research Center</title>
		<meeting><address><addrLine>China; Beijing, China; Hefei, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">2004. 1999</date>
		</imprint>
		<respStmt>
			<orgName>University of Science and Technology of China</orgName>
		</respStmt>
	</monogr>
	<note>Currently, he is a professor of the Tianjin University. He is currently the director of the Artificial Intelligence Laboratory of the Huami Corporation</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
