<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Creating an Explainable Intrusion Detection System Using Self Organizing Maps</title>
				<funder ref="#_epeQuUc">
					<orgName type="full">US Army Engineering Research and Develop Center</orgName>
					<orgName type="abbreviated">ERDC</orgName>
				</funder>
				<funder ref="#_3Nzp9SN #_29fEuzk">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">U.S. Department of Defense (DoD) High Performance Computing Modernization Program</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-07-15">15 Jul 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jesse</forename><surname>Ables</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">Mississippi State University</orgName>
								<address>
									<settlement>Mississippi</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Kirby</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">Mississippi State University</orgName>
								<address>
									<settlement>Mississippi</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">William</forename><surname>Anderson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">Mississippi State University</orgName>
								<address>
									<settlement>Mississippi</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sudip</forename><surname>Mittal</surname></persName>
							<email>mittal@cse.msstate.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">Mississippi State University</orgName>
								<address>
									<settlement>Mississippi</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shahram</forename><surname>Rahimi</surname></persName>
							<email>rahimi@cse.msstate.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">Mississippi State University</orgName>
								<address>
									<settlement>Mississippi</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ioana</forename><surname>Banicescu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">Mississippi State University</orgName>
								<address>
									<settlement>Mississippi</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maria</forename><surname>Seale</surname></persName>
							<email>maria.a.seale@erdc.dren.mil</email>
							<affiliation key="aff1">
								<orgName type="department">Development Center Vicksburg</orgName>
								<orgName type="institution">U.S Army Engineer Research</orgName>
								<address>
									<region>Mississippi</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Creating an Explainable Intrusion Detection System Using Self Organizing Maps</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-07-15">15 Jul 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2207.07465v1[cs.CR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Modern Artificial Intelligence (AI) enabled Intrusion Detection Systems (IDS) are complex black boxes. This means that a security analyst will have little to no explanation or clarification on why an IDS model made a particular prediction. A potential solution to this problem is to research and develop Explainable Intrusion Detection Systems (X-IDS) based on current capabilities in Explainable Artificial Intelligence (XAI). In this paper, we create a Self Organizing Maps (SOMs) based X-IDS system that is capable of producing explanatory visualizations. We leverage SOM's explainability to create both global and local explanations. An analyst can use global explanations to get a general idea of how a particular IDS model computes predictions. Local explanations are generated for individual datapoints to explain why a certain prediction value was computed. Furthermore, our SOM based X-IDS was evaluated on both explanation generation and traditional accuracy tests using the NSL-KDD and the CIC-IDS-2017 datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The use of Artificial Intelligence (AI) in cyber-defense solutions, particularly Intrusion Detection Systems (IDS), has been gaining traction to protect against a wide range of cyber attacks. While these AI models have high detection rates, high false positive and false negative rates can dissuade a security analyst from using an AI enabled IDS <ref type="bibr" target="#b0">[1]</ref>. These IDS built using AI and deep learning methods are black boxes, meaning a security analyst will have little to no explanations and clarifications on why a model made a particular prediction. With the rise in cyber attacks on critical infrastructure, government organizations, and business networks, there is a pressing need for an explainable, automated detection system that can provide real-time aid to an analyst.</p><p>Intrusion Detection Systems are generally utilized as part of a larger cybersecurity defense effort at an organization generally located in a Cyber-Security Operations Center (CSoC). These systems monitor networks and automate attack detection by comparing network activity to the signature of known attacks or by detecting behavior that is anomalous to benign network patterns <ref type="bibr" target="#b1">[2]</ref>. Through these methods, a security analyst can use an IDS to detect improper use, unauthorized access, or the abuse of a network. Analysts can then create mitigating strategies to minimize damages and costs of the malicious behavior. The usefulness and cost effectiveness of IDS have therefore been the subject of much research <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>.</p><p>Previous work in AI enabled IDS has generally focused on improving detection rates while limiting false positives and false negatives. These techniques have been effective at achieving high detection rate, but have failed to provide explanations for their computed predictions. Without the ability to understand how a model reached a decision and which features were relevant to the decision computation, a security analyst will give less credence to these AI enabled IDS. Opaque Deep Learning methods in particular, can be considered as black boxes providing no explanations and feature relevance information, severely limiting adoption in real world cyberdefense scenarios <ref type="bibr" target="#b4">[5]</ref>.</p><p>A potential solution to this problem is to research and develop Explainable Intrusion Detection Systems (X-IDS) based on current capabilities in Explainable Artificial Intelligence (XAI) <ref type="bibr" target="#b5">[6]</ref>. The guidelines proposed by the Defense Advanced Research Projects Agency (DARPA) indicate that to be explainable, an AI should explain the reasoning for its decisions, characterize its strengths and weaknesses, and convey a sense of its future behavior <ref type="bibr" target="#b6">[7]</ref>. An X-IDS that is transparent in its behavior and decision making process, will empower a security analyst to make better informed actions, understand the feature composition of a prediction, help CSoCs defend from known attacks, and quickly understand zero-day attacks. To address this need, we create an X-IDS using Self Organizing Maps (SOMs).</p><p>Data collected from modern networks contain potentially hundreds of different features about the traffic flow, operating systems, network protocols, and other metadata. SOMs work by representing this high dimensional data on a 2-dimensional plane. This also includes maintaining the topographical relationship of the data by grouping similar data <ref type="bibr" target="#b7">[8]</ref>. Through this dimensional reduction and various other SOM visualization techniques, a security analyst can view both global and local explanations about a potential attack rather than an opaque prediction generated by a black box model.</p><p>As the need for explainable cyber-defense systems increases and to address the lack of XAI research in the field of IDS, the main objective of this paper is to demonstrate the explainability of the SOM based X-IDS rather than creating the most accurate system. Higher accuracy systems can be developed by using complex derivative architectures. However, further research is necessary to make them explainable. Our goal in this paper is to increase trust in IDS and help CSoCs defend from attack through the use of explainable insights. As a secondary focus, we also provide the accuracy scores of our SOM based X-IDS system trained on the NSL-KDD and CIC-IDS-2017 datasets.</p><p>Major contributions presented in this paper are -</p><p>? A SOM based X-IDS, built using DARPA's proposed guidelines for an explainable system. This system is able to produce robust, explanatory visualizations of the SOM model and create accurate IDS predictions. ? A Local and Global explainability analysis using the SOM explainable architecture. The explanation module creates a collection of explainable visualizations that can be used by a security analyst to understand predictions. ? A performative analysis using NSL-KDD and CIC-IDS-2017. The SOM based model is able to achieve accuracies as high as 91% on NSL-KDD and 80% on CIC-IDS-2017 datasets. The rest of the paper is outlined as follows -In Section II, we discuss some related work on IDS, XAI, and X-IDS. Section III briefly describes the SOM algorithm and how it can be used to achieve explainability. Section IV, outlines our SOM based X-IDS with its architecture presented in Figure <ref type="figure">1</ref>. Section V lists our experimental results. Finally, the conclusion and future work has been presented in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In this section, we present some related work on Intrusion Detection Systems (IDS), Explainable Artificial Intelligence (XAI), and Explainable Intrusion Detection Systems (X-IDS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Intrusion Detection Systems (IDS)</head><p>An intrusion refers to an action that obtains unauthorized access to a network or system <ref type="bibr" target="#b8">[9]</ref>. Intrusions can be characterized by a violation of Confidentiality, Integrity, or Availability (CIA). An IDS consists of tools, methods, and resources that help a CSoC protect an organization <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>.</p><p>IDS can be classified as either a host-based IDS or networkbased IDS. Host-based IDS are placed on a host system and monitor host activity, incoming and outgoing network traffic <ref type="bibr" target="#b11">[12]</ref>. Network-based IDS are built to survey and protect a network of hosts from intrusion <ref type="bibr" target="#b12">[13]</ref>. In addition, IDS can also be categorized into operation-based classes, such as signature, anomaly, and hybrid. Signature-based IDS operate by preventing known attacks from accessing a network. The IDS compares incoming network traffic to a database of known attack signatures. Notably, this method has difficulty in preventing zero-day attacks <ref type="bibr" target="#b13">[14]</ref>. Anomaly-based IDS look for patterns in incoming traffic to recognize potential threats and leverage complex AI models <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>. A significant drawback of this approach is the the tendency for such systems to categorize legitimate, unseen behavior as anomalous. Hybridbased IDS incorporate the design philosophy of both signature-based and intrusion-based IDS to improve the detection rate while minimizing false positives <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>.</p><p>Current AI enabled anomaly-based IDS can be further divided into black box and white box models. White box models are considered easy to understand by an expert. This allows the expert to analyze the decision process and understand how the model renders its decision. This "semi-transparent" property allows white box models to be deployed in decision sensitive domains, where auditing the decision process is a requirement. White box models may use regression-based approaches <ref type="bibr" target="#b18">[19]</ref>, decision trees <ref type="bibr" target="#b19">[20]</ref>, and SOMs <ref type="bibr" target="#b20">[21]</ref>. Black box models, on the other hand, have an opaque decision process. This opaqueness property makes establishing the relationship between inputs and the decision difficult, if not outright impossible. Black box models comprise nearly all the AI enabled state-of-theart approaches for IDS, as the focus is traditionally on model performance, not explainability. Examples of black box models are Isolation Forest <ref type="bibr" target="#b21">[22]</ref>, One-Class SVM <ref type="bibr" target="#b22">[23]</ref>, and Neural Networks <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Explainable Artificial Intelligence (XAI)</head><p>As previously stated, state-of-the-art approaches for IDS, as well as machine learning as a whole, focus on model performance through the lens of model accuracy. This focus on model accuracy has driven the development further away from modeling approaches that are transparent or have methods of explainability. In turn, this creates a separation between model inference and understanding model inference, which gives the inability to confirm model fairness, privacy, reliability, causality, and ultimately trust.</p><p>The notion of XAI dates back to the 1970s. Moore et al. <ref type="bibr" target="#b24">[25]</ref> surveyed works from the 1970s to the 1980s, detailing early methods of explanations. Some early explanations consisted of canned text and code translations, such as the 1974 explainer MYCIN <ref type="bibr" target="#b25">[26]</ref>. We can find a more current definition of XAI by DARPA <ref type="bibr" target="#b6">[7]</ref>. They define XAI as systems that are able to explain their reasoning to a human user, characterize their strengths and weaknesses, and convey a sense of their future behavior. In turn, the system offers some form of justification for its action, leading to more trust and understanding of the system. The explanations from an XAI system help the user not only in using and maintaining the AI model, but also helping users complete tasks in parallel with the AI system. Tasks can include doctors making medical decisions <ref type="bibr" target="#b25">[26]</ref>- <ref type="bibr" target="#b27">[28]</ref>, credit score decisions <ref type="bibr" target="#b28">[29]</ref>, detecting counterfeit banknotes <ref type="bibr" target="#b29">[30]</ref> or CSoC operators defending a network <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b30">[31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Explainable Intrusion Detection Systems (X-IDS)</head><p>Explainable Intrusion Detection Systems (X-IDS) are still an emerging sub-genre in the field. The need for explainability in IDS is becoming increasingly necessary both to warrant further application in decision sensitive domains, as well as to supplement and empower existing knowledge techniques (e.g. data mining, rule-based development) that black boxes obfuscate. The users need to be confident in the predictions or recommendations computed by an IDS. Understandable explanations allow users to perform their tasks correctly. The stakeholders of an IDS (e.g. CSoC operators, developers, and investors) are individuals who will be dependent on the performance of the system. CSoC operators will be performing defensive actions based on prediction and explanation results. Developers can use explanations to fortify the model in areas where it is weak. Investors may need explanations to help them in making budgeting decisions for their company.</p><p>The current literature consists of many different black box and white box models being used alongside explanation techniques. Common explainer modules for black box models are Local Interpretable Model-agnostic Explanations (LIME) <ref type="bibr" target="#b31">[32]</ref>, SHapley Additive exPlanations (SHAP) <ref type="bibr" target="#b32">[33]</ref>, and Layerwise Relevance Propagation (LRP) <ref type="bibr" target="#b33">[34]</ref>. Modern techniques for explaining black box models consist of creating surrogate models that generate explanations either locally or globally. Other methods involve propagating predictions backwards in a Neural Network or decomposing a gradient. More novel approaches have also experimented with making datasets explainable <ref type="bibr" target="#b34">[35]</ref> or making GUIs for explainable systems <ref type="bibr" target="#b35">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPLAINABLE SELF ORGANIZING MAPS</head><p>In this section, we briefly describe the theoretical and the practical aspects of SOMs and how they can be utilized to detect intrusions and generate explanations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Self Organizing Maps (SOMs)</head><p>Self Organizing Maps (SOMs), sometimes referred to as Kohonen Maps <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b36">[37]</ref>, Kohonen Self Organizing Maps <ref type="bibr" target="#b37">[38]</ref>, or Kohonen Networks <ref type="bibr" target="#b38">[39]</ref>, are a class of unsupervised machine learning algorithms. SOMs are comprised of a network of individual units, each of which has a feature vector of the same size as the dimension of training data. Some implementations also include an (x,y) coordinate to allow unit movement in a two-dimensional (2D) space. This 2D space is typically represented as a square or a hexagonal grid, to more easily visualize the represented space.</p><p>Training a SOM model, outlined in Algorithm 1, utilizes the following steps: First, a random training sample is picked. Then, the Best Matching Unit (BMU) is calculated by finding the smallest euclidean distance from the training sample to a SOM unit. After the BMU is found, it and its neighbors are updated using the formula w i = w i -? * (w i -i i ), where w is the set of BMU weights and i is the set of feature values. ? is the learning rate function that considers the current training iteration and distance from the BMU. Lastly, the learning rate, neighborhood radius, and current iteration numbers are updated. The function ? works in a way that it decreases during the course of the training process.</p><p>SOMs have some unique advantages that come with their application. The first is algorithmic simplicity. As shown in Algorithm 1, the brevity of the algorithm helps to maintain the desired properties of algorithmic decomposability and tractability. Additionally, due to its unsupervised nature, SOMs can work on a variety of datasets and applications (e.g. data mining and discovery), not just prediction <ref type="bibr" target="#b39">[40]</ref>. <ref type="bibr">By</ref>  </p><formula xml:id="formula_0">w i = w i -? * (w i -i i ) 9:</formula><p>Update BMU Neighbors t+ = 1 12: end while 13: return W SOMs convert high-dimensional data into a lower dimensional representation. This representation can be topologically clustered and explained through visualizations <ref type="bibr" target="#b40">[41]</ref>. One challenge that comes with the application of SOMs is the selection of the size parameter, as the size does not dynamically adjust and there is no best size heuristic <ref type="bibr" target="#b41">[42]</ref>. Finally, another challenge with SOMs is their scalability, both in their time complexity, O(N 2 ), and space complexity. More methods, such as those in <ref type="bibr" target="#b42">[43]</ref>, are needed to address these challenges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. SOMs and Intrusion Detection</head><p>In the past, SOMs have been used to create many IDS. These studies focused on building accurate IDS and did not discuss explainability. Among these approaches, SOMs were used to create both host-based <ref type="bibr" target="#b43">[44]</ref> and network-based <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref> IDS. The majority of these methods simply trained a SOM based IDS and illustrated mappings between datapoints and the associated BMU. The approaches in <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b46">[47]</ref> use multiple SOMs in conjunction with one another to create a more effective IDS. Only one approach <ref type="bibr" target="#b44">[45]</ref> discussed the false positive rate and accuracy of a SOM-based IDS. Their method for prediction involved assigning a label to BMUs based on the training dataset. Using this approach meant that not all SOM units were assigned a label. The authors utilized Gaussian Mixture Modeling (GMM) to make predictions when a testing sample was similar to an unlabeled unit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. SOMs and Explainability</head><p>Once trained, SOMs are able to illustrate mappings between datapoints and the associated BMU. As this is generally a 2D representation of the feature space, it can be visually understood by the user. This advantageous SOM property makes them explainable. SOM's explainablity can be divided into Global and Local explanations.</p><p>Global explanations are used to give a general idea of how a particular model computes predictions. The U-Matrix (See Section IV-C), is a commonly used technique <ref type="bibr" target="#b47">[48]</ref>. This additive metric works by summing the distance to each of a </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SOM Unit Visualization</head><p>Local/Global Feature Significance Fig. <ref type="figure">1</ref>: Architecture for an Explainable Intrusion Detection System (X-IDS) utilizing Self Organizing Maps (SOMs), based on DARPA's recommended architecture for Explainable Artificial Intelligence (XAI) systems <ref type="bibr" target="#b6">[7]</ref>.</p><p>unit's neighbors. A group of low scores represents clusters in the map, while a group of high scores signifies sparseness. The Starburst U-Matrix is an updated variation of the U-Matrix. This updated version helps visualize cluster sizes and locations on the map. Other clustering representations, like Kmeans clustering, can also aid in visualization. For more finegrained data, feature heat-maps can be created to visualize SOM feature values and their importance. These techniques provide global explanations.</p><p>Local interpretations of data are a more recent development for explaining SOMs. These explanations are generated for individual sample datapoints and are used to explain why a certain prediction value was computed. This allows the user to understand the decision process of the SOM model. The primary use of this method is to explain and visualize feature importance. When making a prediction, a datapoint's features are scored based on how impactful they are to the computed prediction. Wickramasinghe et al. <ref type="bibr" target="#b48">[49]</ref> developed an explainable SOM for Cyber-Physical Systems. Their system created both local and global explanations by data-mining a SOM model. The mined information was used to create visualizations including histograms, T-distributed Stochastic Neighbor Embedding (t-SNE), heat maps, U-Matrix, component planes, and U-Map. This variety of visualizations allow the SOM to be explainable not only to domain experts, but also non-domain experts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. X-IDS ARCHITECTURE</head><p>An X-IDS's main goal is to help stakeholders protect their networks and understand various relevant events. The system should act as both a guard and adviser for network security. When an IDS discovers an intrusion, the user should be notified to prevent a possible attack. Explanations generated by the X-IDS should assist CSoC operators in their mission to protect their organization. To help achieve this goal, we propose the proof of concept SOM based X-IDS architecture in Figure IV. The proposed architecture is based on DARPA's recommended architecture for XAI systems <ref type="bibr" target="#b6">[7]</ref>. Components of the framework can be changed to suit users' needs. The architecture is abstract enough that methods other than SOMs can be interchanged to create different X-IDS. The architecture consists of three stages: pre modeling, modeling, and post modeling explainability. In the first phase, the model preprocesses raw network data captured into high quality datasets, and selects parameters for the SOM model. Next, the model is trained during the modeling phase. Metrics are recorded to determine the newly trained model's quality. Lastly, in the post modelling phase, the SOM is data-mined to generate explanatory visualizations that allow users to understand how predictions are generated. In the next subsections, we describe each of these phases in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets and Pre Modeling Phase</head><p>In this work, NSL-KDD <ref type="bibr" target="#b49">[50]</ref> and CIC-IDS-2017 <ref type="bibr" target="#b50">[51]</ref> were used to test the explainability and effectiveness of our architecture. NSL-KDD was chosen because of its wide use in the literature. It allows our method to be compared to other existing IDS. CIC-IDS-2017 includes more modern attacks and is useful for testing an unbalanced dataset. The datasets are passed through a preprocessing module that normalizes the data. Additionally, the architecture uses Bayesian Probability of Significance <ref type="bibr" target="#b51">[52]</ref> to select features. Any feature significance value over a designer selected threshold is included in the preprocessed dataset. The resulting high quality dataset is used during the modelling phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Modeling Phase</head><p>The modeling phase begins by training the SOM model using the high quality dataset generated during the pre modeling phase. For this paper, we use the POPSOM implementation <ref type="bibr" target="#b52">[53]</ref>. Training parameters include total training iterations, learning rate, and SOM size. At the end of the training session, the model will be tested to produce topographical error, quantization error, F1-score, precision, recall, and a confusion matrix. The confusion matrix can be used to determine both the false positive and false negative rate for the model. The quality metrics are used to determine if a model has been sufficiently trained to generate explanations.</p><p>Quality Metrics: There have been various metrics and measures proposed to evaluate the quality of a trained SOM. These include quantization error, topographic accuracy, embedding accuracy, and convergence index. Quantization error was used by Kohenen <ref type="bibr" target="#b53">[54]</ref>, and measures the average distance between nodes and the data points. To measure how much the features of the input space have been preserved in low dimensional output space, a topographic error is used. The topographic error is measured by evaluating how often the BMU and second BMU are next to each other <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b54">[55]</ref>. Map embedding accuracy is similar to quantization error and it measures how similar the distribution of the input data is with respect to that of the SOM units <ref type="bibr" target="#b55">[56]</ref>. In order to measure both topographic preservation and distribution similarity between the input and SOM units, the convergence index was proposed to be a measure that linearly combines map embedding accuracy and topographic accuracy <ref type="bibr" target="#b56">[57]</ref>. Prediction accuracy metrics are also important to include in an IDS architecture. These metrics include F1-score, false positive rate, and false negative rate. These measurements allow the architecture to be compared to other existing IDS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Post Modeling Explainability</head><p>Once the modeling phase has been completed and quality metrics have ensured that the model is a good representation of the data, the model can be used to perform a variety of explainability and visualization tasks. The model itself is a list of SOM units and the weights associated with these units. Visualization tasks include creating local and global explanations, a U-Matrix, and feature heatmaps.</p><p>1) Local and Global Explanations: Global and local interpretability can be achieved by examining important features of the trained SOM, and utilizing this information to generate an explanation for a specific data instance classification or cluster classification <ref type="bibr" target="#b57">[58]</ref>. Global significance for NSL-KDD is shown in Figure <ref type="figure" target="#fig_0">2b</ref> with higher values denoting that a feature has a higher probability of being important. Higher variance features increase the probability that a model will capture the dataset's structure <ref type="bibr" target="#b51">[52]</ref>. Through this graph, an analyst can understand which features are important to the overall SOM structure, allowing them to examine predictions at a local level based on globally important features.</p><p>Figure <ref type="figure" target="#fig_0">2a</ref> shows the local explanations for a prediction, where each feature on the y-axis has a value representing distance from its respective BMU value (See Section III). In this example, we can see the features with the largest impact on a prediction: duration, dst bytes, and src bytes. These features were the closest to the BMU, and they played a large role in computing the predicted value. Seeing the specific features that influence predictions provides insight about samples labeled as malicious or benign and can further help operators determine the reason of incorrect predictions. These features can also be further investigated with feature value heat maps.</p><p>2) Unified Distance Matrix (U-Matrix): The U-Matrix is a visualization of the distances between neighboring SOM units. With distances shown as a color gradient, units far apart will create dark boundaries while areas with similar units will be lighter. This can visually represent the natural clusters of input data. To enhance the standard U-Matrix, the starburst model uses connected component lines of nodes overlaid on the matrix to better represent clusters <ref type="bibr" target="#b58">[59]</ref>. For a labeled data set, the user is able to visualize each BMU along with the associated label. Figure <ref type="figure" target="#fig_2">3a</ref> shows clear clusters with boundaries separating malicious (1) and benign (0) behavior. Using this information a security analyst can investigate more visualizations and feature importance values to gain an understanding about why certain malicious network activities are being grouped together.</p><p>3) Feature Value Heat Map: Heat maps show general trends that a feature has on the entire SOM model. SOM feature values are represented from 0 to 1, and the heat maps denote this with darker and lighter values, respectively. An example feature value heat map can be found in Figure <ref type="figure" target="#fig_2">3c</ref>. In this example, the 'dst bytes' features has a cluster of higher values in the bottom-left corner, while the rest of the SOM consists of lower values. Users can use this information to form conclusions about the model. Feature value maps are more powerful when multiple are viewed at a time. In addition, the U-Matrix or K-means clustering charts can then be referenced to make general decisions about the model. The heat maps work well as a fine-grained global explanation that helps users to understand the overall model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL RESULTS AND EVALUATION</head><p>Our SOM based X-IDS was evaluated on both explanation generation and traditional accuracy tests. Experiments were run using the aforementioned datasets (See Section IV-A), which was used to train two 18x18 SOMs. The training process was completed in 1000 iterations over the dataset. After 1000 iterations, there was no significant improvement in evaluation metrics. In fact, while training on the CIC-IDS-2017 dataset, the SOM model performance began to degrade as a result of over-fitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Model Explainability</head><p>The results for the NSL-KDD dataset can be found in Figures <ref type="figure" target="#fig_0">2a</ref> and<ref type="figure" target="#fig_0">2b</ref>. The local explanation example shows that the most important features for its prediction were 'Duration', 'Destination (dst) bytes', and 'Source (src) bytes'. The remaining features, 'Service (srv) count', 'Count', and 'Destination (dst) host count' are considered less significant because of their distance from the BMU. Two of the important features coincide with the Global Feature Significance graph. This trend continues when testing on many different test samples. The most important global features are frequently at the forefront for local significance. Similarly to NSL-KDD, CIC-IDS-2017 follows this trend. Many of the top, globally selected features also play a more important role in the local predictions.</p><p>The next set of explainability techniques has been datamined from the trained SOM. Figures <ref type="figure" target="#fig_2">3a</ref> and<ref type="figure" target="#fig_2">3d</ref> show the generated Starburst U-Matrix for NSL-KDD and CIC-IDS-2017, respectively. The SOM algorithm was able to separate benign clusters from malicious clusters in the map created from NSL-KDD dataset. The bottom-left corner is primarily malicious samples, while the top-right corner contains mostly benign samples. Additionally, the clusters marked by the starbursts' origins mostly represent one label. On the other hand, the CIC-IDS-2017 map has not separated the labels sufficiently. Most of the labels present in the figure are benign (0) with very few malicious labels <ref type="bibr" target="#b0">(1)</ref>. CIC-IDS-2017 is an unbalanced dataset, with about 70% of samples being benign and 30% of samples as malicious. This class imbalance causes the SOM to be trained on more benign samples than malicious.</p><p>For a simplified label separation, users can visualize a K-means clustering interpretation in Figure <ref type="figure" target="#fig_2">3b</ref>. This figure helps to explain which clusters the benign and malicious traffic are grouped in. The NSL-KDD K-means graph is similar to the computed U-matrix. However, the CIC-IDS-2017 Kmeans cluster graph was unable to form accurate clusters. As mentioned above, there were few units that were labeled malicious (1), and the K-means clustering algorithm chosen was unable to create a meaningful separation.</p><p>Lastly, the feature value heatmaps are generated for each feature of the dataset. The examples chosen were the most significant features for each dataset: 'destination (dst) bytes' and 'flow bytes/s'. On their own, they can be used to see general training trends for each feature. In Figures <ref type="figure" target="#fig_2">3c</ref> and<ref type="figure" target="#fig_2">3e</ref>, we can see that each of these features have higher values in the bottom-left units and lower values elsewhere. Users will be able to build a mental model of the SOM when visualized in conjunction with the features maps. For example, 'destination (dst) byte', 'duration', and 'source (src) byte' all have higher values in the malicious section of the map. One may conclude  that when these values are all close to one, the sample is more than likely malicious.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Accuracy</head><p>When creating an IDS, accuracy is an important metric to consider. Table <ref type="table" target="#tab_4">I</ref> shows the accuracy metrics obtained for both the NSL-KDD and CIC-IDS-2017 datasets. The accuracy of the NSL-KDD evaluation can be attributed to the separation of benign and malicious traffic, as mentioned above. The accuracy of CIC-IDS-2017, however, is much lower. The Umatrix shows that not many units are labeled as malicious.</p><p>Interestingly, only 14% of the units are labeled as malicious, which means that 77.4% of malicious samples are similar to that small subset of units.</p><p>The results from the explainability and accuracy experiments show that it is possible to create explainable and relatively accurate SOM based X-IDS. The visualization techniques used can give users an understanding of the model and can empower security analysts to make their own predictions, similar to the model. A 91% F1-score can be attributed to the clear separation the model makes between malicious and benign samples. We believe that this can be further improved with more complex SOM algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION AND FUTURE WORK</head><p>In this paper, we created a proof of concept SOM based X-IDS implementation. The implementation was able to produce robust, explainable figures describing the SOM model. Explainability was demonstrated using various forms of vi-</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: These figures show the local and global feature explanations for both the NSL-KDD and CIC-IDS datasets. (a) The local explainability of a prediction is defined by the distance between feature value and BMU. More important features have a lower score than less important features. This figure shows the feature importance for an anomalous sample from the NSL-KDD testing set. (b) Global feature significance is calculated using Bayesian Probability of Significance [52]. Higher values are considered more important than lower values.</figDesc><graphic url="image-3.png" coords="6,50.71,192.48,248.33,191.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) NSL-KDD Starburst U-Matrix (b) NSL-KDD K-means Clustering Map (c) Dst byte Feature Map (d) CIC-IDS-2017 Starburst U-Matrix (e) Flow bytes/s Feature Map</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: (a)(d)The Starburst U-Matrix shows both the most common label for each node and the clusters the SOM has learned. Darker areas represent units that are close Euclidean Distance-wise. Notably, we can see a clear divide between classes on the NSL-KDD dataset as represented in the figure. (b)(e) K-means clustering can be used as a simplified view of where labels appear on the SOM. In this model's iteration, anomalous traffic is mostly grouped on the bottom of the SOM.(c) The feature value heatmap displays the value of a specific feature on each unit in the SOM. Lighter values represent units with values closer to 1, while darker values show values closer to 0. The 'dst byte' example shows that the bottom 'anomalous' cluster values higher values.</figDesc><graphic url="image-9.png" coords="7,331.54,220.69,154.21,154.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>design,</figDesc><table><row><cell cols="2">Algorithm 1 SOM Algorithm</cell></row><row><cell cols="2">Input: n, m, T</cell></row><row><cell cols="2">Output: W</cell></row><row><cell cols="2">1: Allocate n * m element array W</cell></row><row><cell cols="2">2: for each node in W do</cell></row><row><cell>3:</cell><cell>Allocate N element array with random values [0,1]</cell></row><row><cell cols="2">4: end for</cell></row><row><cell cols="2">5: while t &lt; T do</cell></row><row><cell>6:</cell><cell>Pick a training sample</cell></row><row><cell>7:</cell><cell>Find Best Matching Unit using Euclidean Distance</cell></row><row><cell>8:</cell><cell>Update BMU elements:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE I :</head><label>I</label><figDesc>Accuracy Metrics for NSL-KDD and CIC-IDS-2017</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>sualization including feature significance, U-matrices, and feature heatmaps. Through these, users are able to create their own conclusions about how the model works and makes predictions. Additionally, accuracy was tested using the NSL-KDD and CIC-IDS-2017 datasets. The SOM implementation was able to achieve accuracies of <rs type="grantNumber">91%</rs> and <rs type="grantNumber">80%</rs>, respectively. Potential future works will include analysing the explainability and accuracy of Growing SOMs or Growing Hierarchical SOMs. These studies will aim to increase the accuracy of SOMs while simultaneously decreasing false positives and false negatives. In addition, explanations can be improved by surveying security analysts to discover the most useful visualizations and feedback. We will continue to use and improve our architecture to create the state-of-the art in X-IDS.</p></div>
<div><head>VII. ACKNOWLEDGMENT</head><p>This work by <rs type="institution">Mississippi State University</rs> was financially supported by the <rs type="funder">U.S. Department of Defense (DoD) High Performance Computing Modernization Program</rs>, through the <rs type="funder">US Army Engineering Research and Develop Center (ERDC)</rs> (#<rs type="grantNumber">W912HZ-21-C0058</rs>). The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the <rs type="institution">U.S. Army ERDC</rs> or the <rs type="institution">U.S. DoD</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_3Nzp9SN">
					<idno type="grant-number">91%</idno>
				</org>
				<org type="funding" xml:id="_29fEuzk">
					<idno type="grant-number">80%</idno>
				</org>
				<org type="funding" xml:id="_epeQuUc">
					<idno type="grant-number">W912HZ-21-C0058</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Artificial intelligence: Explainability, ethical issues and bias</title>
		<author>
			<persName><forename type="first">Alaa</forename><surname>Marshan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Robotics and Automation</title>
		<imprint>
			<biblScope unit="volume">08</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Cyber security operations center</title>
		<author>
			<persName><surname>Raytheon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Performance evaluation of intrusion detection based on machine learning using apache spark</title>
		<author>
			<persName><forename type="first">Mustapha</forename><surname>Belouch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salah</forename><forename type="middle">El</forename><surname>Hadaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Idhammad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The use of computational intelligence in intrusion detection systems: A review</title>
		<author>
			<persName><forename type="first">Xiaonan</forename><surname>Shelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><surname>Banzhaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied soft computing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery</title>
		<author>
			<persName><surname>Zachary C Lipton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Queue</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="31" to="57" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Explainable intrusion detection systems (x-ids): A survey of current methods, challenges, and opportunities</title>
		<author>
			<persName><forename type="first">Subash</forename><surname>Neupane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Ables</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sudip</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahram</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Banicescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Seale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Darpa&apos;s explainable artificial intelligence (xai) program</title>
		<author>
			<persName><forename type="first">David</forename><surname>Gunning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Aha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="44" to="58" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Self-organized formation of topologically correct feature maps</title>
		<author>
			<persName><forename type="first">Teuvo</forename><surname>Kohonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological cybernetics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="69" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An intrusion-detection model</title>
		<author>
			<persName><forename type="first">Dorothy</forename><forename type="middle">E</forename><surname>Denning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on software engineering</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="222" to="232" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Intrusion detection systems</title>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Gurley Bace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Mell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep learning techniques for behavioural malware analysis in cloud iaas</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mcdole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maanak</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmoud</forename><surname>Abdelsalam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sudip</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mamoun</forename><surname>Alazab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Malware Analysis using Artificial Intelligence and Deep Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Host-based intrusion detection and prevention system (hidps)</title>
		<author>
			<persName><forename type="first">Kopelo</forename><surname>Letou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruwajita</forename><surname>Devi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yumnam</forename><surname>Jayanta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Applications</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="28" to="33" />
			<date type="published" when="2013-05">05 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Network intrusion detection</title>
		<author>
			<persName><forename type="first">Biswanath</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">L</forename><surname>Heberlein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><forename type="middle">N</forename><surname>Levitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="26" to="41" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Evolution and detection of polymorphic and metamorphic malwares: A survey</title>
		<author>
			<persName><forename type="first">Ashu</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sahay</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1406.7061</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Anomaly detection: A survey</title>
		<author>
			<persName><forename type="first">Varun</forename><surname>Chandola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arindam</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vipin</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page">58</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Analyzing cnn based behavioural malware detection techniques on cloud iaas</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mcdole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmoud</forename><surname>Abdelsalam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maanak</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sudip</forename><surname>Mittal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Cloud Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="64" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Achieving explainability of intrusion detection system by hybrid oracleexplainer approach</title>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Szczepa?ski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Micha?</forename><surname>Chora?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marek</forename><surname>Pawlicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafa?</forename><surname>Kozik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Explainable deep few-shot anomaly detection with deviation networks</title>
		<author>
			<persName><forename type="first">Guansong</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Choubo</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><surname>Hengel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.00462</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Intrusion detection systems using linear discriminant analysis and logistic regression</title>
		<author>
			<persName><forename type="first">Basant</forename><surname>Subba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santosh</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sushanta</forename><surname>Karmakar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 Annual IEEE India Conference (INDICON)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Explainable artificial intelligence (xai) to enhance trust management in intrusion detection systems using decision tree model</title>
		<author>
			<persName><forename type="first">Basim</forename><surname>Mahbooba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohan</forename><surname>Timilsina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radhya</forename><surname>Sahal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Serrano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complexity</title>
		<imprint>
			<date type="published" when="2021">2021, 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Annabell island: a 3d color hexagonal som for visual intrusion detection</title>
		<author>
			<persName><forename type="first">Chet</forename><surname>Langin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Wainer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahram</forename><surname>Rahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internation Journal of Computer Science and Information Security</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Tony</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</author>
		<title level="m">Eighth IEEE International Conference on Data Mining</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="413" to="422" />
		</imprint>
	</monogr>
	<note>Isolation forest</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Support vector method for novelty detection</title>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neural networks for classification: a survey</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="451" to="462" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Explanation in expert systemss: A survey</title>
		<author>
			<persName><forename type="first">D</forename><surname>Johanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">R</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><surname>Swartout</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
		<respStmt>
			<orgName>University of Southern California Marina Del Rey Information Sciences Inst</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Mycin: a rule-based computer program for advising physicians regarding antimicrobial therapy selection</title>
		<author>
			<persName><forename type="first">Edward</forename><surname>Hance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shortliffe</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1974">1974</date>
		</imprint>
		<respStmt>
			<orgName>Stanford Univ Calif Dept of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">What do we need to build explainable ai systems for the medical domain</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Holzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Constantinos</forename><forename type="middle">S</forename><surname>Pattichis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><forename type="middle">B</forename><surname>Kell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.09923</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Explainable artificial intelligence for falls prediction</title>
		<author>
			<persName><forename type="first">Leeanne</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sonya</forename><surname>Coleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dermot</forename><surname>Kerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne</forename><surname>Moorhead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Advances in Computing and Data Sciences</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="76" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Study on credit rating model using explainable ai</title>
		<author>
			<persName><forename type="first">Se Bin</forename><surname>Ye Eun Chun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ja</forename><forename type="middle">Yun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><forename type="middle">Hwan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Woo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Korean Data &amp; Information Science Society</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="283" to="295" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Joint banknote recognition and counterfeit detection using explainable artificial intelligence</title>
		<author>
			<persName><forename type="first">Miseon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeongtae</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page">3607</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Broad agency announcement explainable artificial intelligence (xai)</title>
		<author>
			<persName><surname>Darpa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="7" to="8" />
		</imprint>
	</monogr>
	<note>DARPA-BAA-16-53</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">explaining the predictions of any classifier</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1135" to="1144" />
		</imprint>
	</monogr>
	<note>Why should i trust you?</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A unified approach to interpreting model predictions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su-In</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Layer-wise relevance propagation for neural networks with local renormalization layers</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gr?goire</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus-Robert</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="63" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Domain knowledge aided explainable artificial intelligence for intrusion detection and response</title>
		<author>
			<persName><forename type="first">Rabiul</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><surname>Eberle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ambareen</forename><surname>Sheikh K Ghafoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Siraj</surname></persName>
		</author>
		<author>
			<persName><surname>Rogers</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09853</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Featureoriented design of visual analytics system for interpretable deep learning based intrusion detection</title>
		<author>
			<persName><forename type="first">Chunyuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aijuan</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoju</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanling</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 International Symposium on Theoretical Aspects of Software Engineering (TASE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Kohonen maps</title>
		<author>
			<persName><forename type="first">Erkki</forename><surname>Oja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Kaski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Kohonen self-organizing maps</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><surname>Guthikonda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">98</biblScope>
		</imprint>
		<respStmt>
			<orgName>Wittenberg University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Teuvo</forename><surname>Kohonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Honkela</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Kohonen network. Scholarpedia</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">1568</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Data mining using selforganizing kohonen maps: A technique for effective data clustering &amp; visualization</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Syed</forename><surname>Muhammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raza</forename><surname>Abidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IC-AI</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Intrusion detection system using self organizing maps</title>
		<author>
			<persName><forename type="first">Parag</forename><surname>Vk Pachghare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deven</forename><forename type="middle">M</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><surname>Nikam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 International Conference on Intelligent Agent &amp; Multi-Agent Systems</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Evaluating self-organizing map quality measures as convergence criteria</title>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Breard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A scalable heterogeneous parallel som based on mpi/cuda</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="264" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Host-based intrusion detection using self-organizing maps</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Lichodzijewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nur Zincir-Heywood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malcolm</forename><forename type="middle">I</forename><surname>Heywood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 International Joint Conference on Neural Networks. IJCNN&apos;02</title>
		<meeting>the 2002 International Joint Conference on Neural Networks. IJCNN&apos;02</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1714" to="1719" />
		</imprint>
	</monogr>
	<note>Cat. No. 02CH37290</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Implementation of an intrusion detection system based on self organizing map</title>
		<author>
			<persName><forename type="first">Emiro</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">La</forename><surname>Hoz</surname></persName>
		</author>
		<editor>Miguel De La Hoz Correa, and Fabio Enrique Mendoza Palechor</editor>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Andr?s Ortiz Garc?a</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multiple self-organizing maps for intrusion detection</title>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Craig Rhodes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">A</forename><surname>Mahaffey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">D</forename><surname>Cannady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd national information systems security conference</title>
		<meeting>the 23rd national information systems security conference</meeting>
		<imprint>
			<publisher>MD Press Baltimore</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="16" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Combining self-organizing map algorithms for robust and scalable intrusion detection</title>
		<author>
			<persName><forename type="first">Sahin</forename><surname>Albayrak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Scheel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragan</forename><surname>Milosevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Achim</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC&apos;06)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="123" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Kohonen&apos;s self organizing feature maps for exploratory data analysis</title>
		<author>
			<persName><forename type="first">Alfred</forename><surname>Ultsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peter Siemon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Neural Network Conference (INNC-90)</title>
		<meeting>the International Neural Network Conference (INNC-90)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Academic Press</publisher>
			<date type="published" when="1990">July 9-13, 1990. 1990</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="305" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Explainable unsupervised machine learning for cyber-physical systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chathurika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kasun</forename><surname>Wickramasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">L</forename><surname>Amarasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Craig</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milos</forename><surname>Rieger</surname></persName>
		</author>
		<author>
			<persName><surname>Manic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="131824" to="131843" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">A detailed analysis of the kdd cup 99 data set</title>
		<author>
			<persName><forename type="first">Mahbod</forename><surname>Tavallaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ebrahim</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><forename type="middle">A</forename><surname>Ghorbani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A detailed analysis of cicids2017 dataset for designing intrusion detection systems</title>
		<author>
			<persName><forename type="first">Ranjit</forename><surname>Panigrahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samarjeet</forename><surname>Borah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Engineering &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="479" to="482" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Bayesian probability approach to feature significance for infrared spectra of bacteria</title>
		<author>
			<persName><forename type="first">Lutz</forename><surname>Hamel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Spectroscopy</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="48" to="59" />
			<date type="published" when="2012">1 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Implementation of self-organizing maps with Python</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Yuan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
		<respStmt>
			<orgName>University of Rhode Island</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">The self-organizing map</title>
		<author>
			<persName><forename type="first">Teuvo</forename><surname>Kohonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Clustering properties of hierarchical self-organizing maps</title>
		<author>
			<persName><forename type="first">Jouko</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erkki</forename><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="261" to="272" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Som quality measures: An efficient statistical approach</title>
		<author>
			<persName><forename type="first">Lutz</forename><surname>Hamel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Springer Verlag</publisher>
			<biblScope unit="volume">428</biblScope>
			<biblScope unit="page" from="49" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Self-organizing map convergence</title>
	</analytic>
	<monogr>
		<title level="j">Int. J. Serv. Sci. Manag. Eng. Technol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="61" to="84" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Explainable unsupervised machine learning for cyber-physical systems</title>
		<author>
			<persName><forename type="first">Kasun</forename><surname>Chathurika S Wickramasinghe</surname></persName>
		</author>
		<author>
			<persName><surname>Amarasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Craig</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milos</forename><surname>Rieger</surname></persName>
		</author>
		<author>
			<persName><surname>Manic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="131824" to="131843" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Improved interpretability of the unified distance matrix with connected components. 7th International Conference on Data Mining (DMIN&apos;11</title>
		<author>
			<persName><forename type="first">Lutz</forename><surname>Hamel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brown</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">2012</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
