<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Partial Face Recognition: An Alignment Free Approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shengcai</forename><surname>Liao</surname></persName>
							<email>scliao@cse.msu.edu</email>
						</author>
						<author>
							<persName><forename type="first">Anil</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
							<email>jain@cse.msu.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<postCode>48824</postCode>
									<settlement>East Lansing</settlement>
									<region>MI</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Brain and Cognitive Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
								<address>
									<addrLine>Anam-dong, Seongbuk-gu</addrLine>
									<postCode>136-713</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Partial Face Recognition: An Alignment Free Approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8310B1D9378227ECD608ABE3E5D87A5B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many approaches have been developed for holistic face recognition with impressive performance. However, few s tudies have addressed the question of how to recognize an arbitrary image patch of a holistic face. In this paper we ad dress this problem of partial face recognition. Partial faces frequently appear in unconstrained image capture environ ments, particularly when faces are captured by surveillance cameras or handheld devices (e.g. mobile phones). The pro posed approach adopts a variable-size description which represents each face with a set of keypoint descriptors. In this way, we argue that a probe face image, holistic or par tial, can be sparsely represented by a large dictionary of gallery descriptors. The proposed method is alignment free and we address large-scale face recognition problems by a fast filtering strategy. Experimental results on three pub lic domain face databases (FRGCv2.0, AR, and LFW) show that the proposed method achieves promising results in rec ognizing both holistic and partial faces.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Face recognition deals with verifying or identifying a face from its image. It has received substantial attention and its performance has advanced significantly over the last three decades due to its value both in understanding how the face recognition process works in humans as well as in addressing many applications, including access control and video surveillance. While face recognition in controlled conditions (frontal face and uniform illumination) has al ready achieved satisfactory performance, there still exist many challenges in uncontrolled scenarios, such as non frontal pose, facial occlusion, and illumination variations.</p><p>Typical applications of face recognition in uncontrolled environments include recognition of individuals in video surveillance frames and images captured by handheld de vices (e.g. a mobile phone), where a face may be captured  Sensor saturation underexposure or overexposure in arbitrary pose without user cooperation. In such scenar ios, it is quite likely that the captured face image is not a holistic face. These scenarios raise the following important questions: (i) is it possible to recognize a person from a par tial image of his face? and (ii) which portion of the face and what size of the partial face are critical for accurate recogni tion? We call the resulting problem as Partial Face Recog nition (PFR), so as to differentiate it from the holistic face recognition problem. State-of-the-art face recognition sys tems <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> have difficulties with the general PFR problem.</p><p>Partial face images result due to many factors, which are categorized in Table <ref type="table" target="#tab_0">1</ref>. <ref type="bibr">Fig. l(a)</ref> shows some examples of partial faces which include a non-frontal face, a face oc cluded by another face, and a face that is not completely visible in the image frame. Images or videos captured in unconstrained environments often contain partial faces that are difficult to recognize by state-of-the-art face recognition systems. Therefore, research on partial face recognition is important to advance the state of the art. As an example, a PFR system will enable law enforcement agencies to iden tify a suspect in a crowd from his partial face captured by a mobile phone and match it to a watch list through a wire less link. Figs. l(b) and (c) show two scenarios in uncon trolled environments, where (b) many occluded faces exist in a crowd; and (c) two persons are trying to hide their iden tities by wearing hooded sweatshirt and sunglasses.</p><p>To our knowledge, almost all of the current face recog nition systems require face alignment. To align a face, the most popular approach is to first detect the two eyes and then normalize the face image geometrically. However, this approach will fail as long as one eye is invisible in a par tial face image. Other face alignment methods include Ac tive Shape Model (ASM) <ref type="bibr" target="#b8">[9]</ref> and Active Appearance Model (AAM) <ref type="bibr" target="#b7">[8]</ref>. They depend on localization of a certain fixed number of landmarks in the holistic face image.</p><p>Among various types of partial faces, in practice the oc cluded and non-frontal ones are the most frequently en countered. While several papers have dealt with occlusion <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16]</ref>, they still require well aligned face images to compensate for the occlusion effect. Ekenel and Stiefel hagen showed that face alignment plays a key role in recog nition performance in case of occlusion <ref type="bibr" target="#b9">[10]</ref>.</p><p>Wright et al. introduced sparse representation classifi cation (SRC) scheme for face recognition <ref type="bibr" target="#b33">[34]</ref>, which was further improved in <ref type="bibr" target="#b31">[32]</ref> to compensate for some possible registration errors. Good performance under small amounts of pose and occlusion variations was reported. However, S RC is not applicable to partial face images with large pose variations or limited field of view (see Fig. <ref type="figure">l(a)</ref>).</p><p>Non-frontal face recognition has also attracted signifi cant attention, including multi-view <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b25">26]</ref> and cross-view face recognition [30, J J, <ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b32">33]</ref>. A critical step in these ap proaches is to localize a certain fixed number of represen tative facial landmarks and establish landmark correspon dences between the input image and the target image in dif ferent views. As a result, both images are required to have visible anchor points. This requirement would not be satis fied in case of external occlusion or limited field of view. <ref type="bibr" target="#b34">[35]</ref> for frontal, near infrared images with limited field of view. While this method achieved promising matching accuracy, it requires high resolution images with good skin texture, and it has difficulty with pose variations. Some research on partial face recognition that only re quire face sub-images as input has been reported. Sato et al. <ref type="bibr" target="#b28">[29]</ref> showed that certain facial sub-images (such as eye, nose, and ear) could be used for recognition. Gutta et al. <ref type="bibr" target="#b11">[12]</ref> showed that a half (left or right) of the face is sufficient for the recognition task. Park et al. showed that the peri ocular region is useful for identification <ref type="bibr" target="#b24">[25]</ref>. Nevertheless, these approaches require the presence of expected and pre defined facial components in the face image for recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yi et al. developed a recognition method</head><p>Instead of holistic representation, some face recognition approaches adopted part-based fusion to deal with occlu sion and pose variation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b21">22]</ref>. These approach es either manually divide the face image into several sub regions, or automatically detect several predefined compo nents (e.g. eye, nose, and mouth), and fuse results from in dividual parts for recognition. However, their performance deteriorates when some of the facial portions are invisible and cannot be localized.</p><p>For images that are difficult to align (e.g. flowers), bag of-words (BoW) representation is frequently used for vi sual object categorization, which applies clustering tech niques to build "visual words". However, histogram of vi sual words of a partial face may be quite different from that of the whole face. In <ref type="bibr" target="#b19">[20]</ref>, the BoW representation was ap plied for face recognition, but it required pre-alignment so that face images could be divided into regular blocks.</p><p>In this paper, we present a general formulation of the partial face recognition problem. We do not know a prior i whether the input face is holistic or partial. Further, we do not assume the presence of the eyes or any other facial component in the image, and we do not assume any pri or information about face alignment. We provide a general matching solution to all types of partial faces listed in Table <ref type="table" target="#tab_0">1</ref>. Our goal is to recognize an arbitrary partial face with out alignment. This is achieved by first deriving a multi keypoint descriptor based representation and constructing a gallery dictionary accordingly. Then multi-task sparse rep resentation is learned from features of each probe face, and recognition is done by the returned sparse coefficients. We call the proposed method as multi keypoint descriptor based sparse representation classification (MKD-SRC).</p><p>The various approaches we have reviewed along with the proposed one are summarized in Table <ref type="table" target="#tab_1">2</ref>. The novelties of the proposed approach are: (i) it addresses the general par tial face recognition problem without an alignment stage; (ii) by applying multi keypoint descriptors in SRC, it is a u nified face recognition framework for both holistic and par tial faces; (iii) a fast filtering strategy is proposed to address large-scale face recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Proposed Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Gallery Dictionary Construction</head><p>To allow for general partial face recognition capability, we construct a large gallery dictionary of multi keypoint descriptors (MKD) as follows. First, we detect multiple SIFT keypoints <ref type="bibr" target="#b20">[21]</ref> in each image, and compute the cor responding descriptors. For each class (subject) c in the gallery, suppose kc keypoints, say, PCl' PC2' ... ,PCk e ' are detected. Note that if class c has multiple images, we sim- Part-based fusion <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b21">22]</ref> Single component <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b24">25]</ref> Pose Multi-view <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b25">26]</ref> Alignment via landmarks ::; 250 Cross-view <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b32">33]</ref> Limited FOV Skin texture <ref type="bibr" target="#b34">[35]</ref> Frontal, partial face alignment 114</p><p>Occlusion, pose, limited FOV MKD-SRC (proposed) Alignment free &gt; 10,000</p><p>ply pool the keypoints extracted from all the images from class c. The corresponding kc SIFT descriptors are denot ed as dcl, dC2 , ... , dckc' where each descriptor is an 11,11dimensional vector (in our case, M = 128). Let</p><formula xml:id="formula_0">0.7 ,----�-�-�-� -�_ __ __ _,<label>(1)</label></formula><p>Then the descriptors from the same class form a sub dictionary of size M x kc representing class c. A gallery dictionary for all the C classes is built as</p><formula xml:id="formula_1">(2)</formula><p>Note that D has a total number of K = L� =l kc descrip tors. Hence the dictionary size is M x K.</p><p>Inspired by <ref type="bibr" target="#b33">[34]</ref>, we adopt a sparse representation scheme for recognition, and express any descriptor from a probe image in terms of a sparse linear combination of the gallery dictionary D .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Multi-Task Sparse Representation</head><p>Let us consider a probe face image with k descriptors We aim to solve a multi-task h -minimization problem k (3)</p><formula xml:id="formula_2">X = argm 1n L Il xi lll' s.t. Y = DX,<label>(4)</label></formula><p>i=l where X = (X l , X2,'" ,X k ) E R Kxk is the sparse coeffi cient matrix, and II . III denotes the 11 norm of a vector. This is equivalent to solving the following k h -minimization problems for each probe descriptor Yi Xi = arg min Il xill l ' s.t. Yi = DX i , i = 1,2" " ,k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Xi</head><p>(5) We adopt the following multi-task sparse representation based classification to determine the identity of the probe image, which is inspired from <ref type="bibr" target="#b33">[34]</ref> k min rc(Y ) = � L II Yi -Dc bc( x i) II� , (6)     where b cU is a function which selects only the coefficients corresponding to class c. We call the resulting algorithm as multi keypoint descriptor based SRC (MKD-SRC). Note that MKD-SRC does not need an alignment stage.</p><p>Fig. <ref type="figure" target="#fig_2">2(c</ref>) illustrates the MKD-SRC approach, where the solution is indeed sparse with zero or near zero coefficients at many keypoints, and the probe partial face is correctly recognized. In contrast, the direct SIFT matching approach <ref type="bibr" target="#b20">[21]</ref> misclassifies the same probe image (Figs. <ref type="figure" target="#fig_2">2(a)</ref> &amp; (b)). This example shows that MKD-SRC successfully exploits the gallery class information and suppresses matches be tween impostor pairs by seeking the sparsest representation among all the gallery images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Fast Filtering</head><p>Taking into account the very large value of K (in prac tice, K can be of the order of millions) in the dictionary D, solving Eq. ( <ref type="formula">5</ref>) will be computationally challenging in practice. Therefore, we adopt a fast approximate solution.</p><p>For each probe descriptor Yi, we first compute the follow ing linear correlation coefficients between Yi and all the de scriptors in the dictionary D Ci = DT Yi , i = 1,2,•• . , k.</p><p>Then for each Yi, we filter out only L (L « K) descriptors according to the top L largest values in Ci, resulting in a small sub-dictionary D� XL . Next, D is replaced by D( i )</p><p>in Eq. ( <ref type="formula">5</ref>), and Eq. ( <ref type="formula">6</ref>) is adjusted accordingly. As we will see later, this approximate solution is much faster, with no significant degradation in performance.</p><p>From Eq. ( <ref type="formula" target="#formula_3">7</ref>) and the selection of top L elements (note that this can be done in O( K [Og2L) by the partial quick sort algorithm) we know that the computation time of the filter ing step scales linearly with respect to K (the number of gallery keypoints) and k (the number of probe keypoints), and hence scales almost linearly with respect to the gallery size for each probe image (considering an average number of keypoints per image).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Differences with Related Methods</head><p>The differences between the proposed method and three related methods for face recognition are listed in Table <ref type="table">3</ref>. Both SIFT <ref type="bibr" target="#b1">[2]</ref>] and MKD-SRC use variable-size descrip tion; they are alignment free and can be used for both holis tic and partial face recognition. In contrast, both SRC <ref type="bibr" target="#b33">[34]</ref> and LBP-SRC <ref type="bibr" target="#b6">[7]</ref> (which uses LBP histograms instead of pixel values in SRC) use a fixed-length description; they require face alignment and can not be applied to general partial face recognition problem. All SRC based method s exploit gallery class information for face recognition, but SIFT matches each pair of images separately.</p><p>The difference among SRC, LBP-SRC and MKD-SRC lies in the feature representation. Since both SRC and LBP SRC require face alignment and use a single fixed-size fea ture vector to represent an image, each column of their corresponding dictionaries is related to one gallery image. However, in such a scheme a partial face might have d ifficulty in alignment and representation due to some un known missing facial regions. In contrast, MKD-SRC uses a variable-size description; each image is represented by a set of descriptors. The MKD dictionary is composed of a large number of gallery descriptors, making it possible to sparsely represent descriptors from a probe face, regardless of being holistic or partial. Note that although LBP-SRC al so extracts local features (LBP histograms) from the image, they are extracted at a certain fixed number of predefined locations after alignment. Some other existing face recognition approaches based on SIFT include <ref type="bibr">[5, 18,20,</ref> ] 9], however, all of them depend on pre-aligned face images. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>In this section, we provide experimental results on three public domain databases: FRGCv2.0, AR, and LFW, which are summarized in Table <ref type="table" target="#tab_2">4</ref>. With these three databases we focus on three scenarios of partial face recognition: arbi trary patch of holistic face, occluded face, and face images with arbitrary occlusion and pose variations, respectively. Since in surveillance scenarios, identification is a more rea sonable mode than verification, we performed identification experiments on these three databases and used the Cumula tive Matching Characteristic (CMC) curve for performance evaluation. We compared the proposed MKD-SRC method to the SIFT matching approach <ref type="bibr" target="#b1">[2]</ref>], as well as a conuner cial face recognition software FaceVACS <ref type="bibr" target="#b0">[1]</ref> and the origi nal SRC algorithm <ref type="bibr" target="#b33">[34]</ref> if they are applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Partial Face Recognition with Arbitrary Patch</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Database</head><p>To evaluate the proposed method, we synthetically gener ated a large database of partial faces. We used 16,028 frontal face images of 466 subjects from the Face Recog nition Grand Challenge Ve r2.0 (FRGCv2.0) database <ref type="bibr" target="#b27">[28]</ref>. The selected images were randomly divided into gallery and probe subset. The gallery set consisted of 1,398 images of 466 subjects, with 3 images per subject. The remaining 14,630 images composed the probe set. To make the iden tification problem more challenging, we included an addi tional 10,OOO frontal face images (1 image per subject) from a private database to enlarge the gallery set. Therefore, the gallery set contained 11,398 images in total.</p><p>All gallery face images were cropped to 128 x 128 pix els according to the two eye coordinates provided. Fig. <ref type="figure" target="#fig_4">3(a)</ref> shows some examples of cropped face images. The probe images were first cropped in the same manner as the gallery images. Next, for each cropped probe image, a patch at random position of a random size h x w was cropped to represent a partial face, where both hand w were uniform ly distributed in [50,100] . Fig. <ref type="figure" target="#fig_4">3(b)</ref> shows some instances of such randomly cropped face patches. Our objective is to recognize these arbitrary patches (we assume they have been manually cropped, as commonly made in forensic ap plications), which can be viewed as partial faces with exter nal occlusions or limited FOY. Note that the position infor mation of how these patches were cropped was not known Table <ref type="table">3</ref>. Differences between the proposed and three related face recognition algorithms SIFT <ref type="bibr" target="#b20">[21]</ref> SRC <ref type="bibr" target="#b33">[34]</ref> LBP-SRC <ref type="bibr" target="#b6">[7]</ref> MKD    to any of the recognition algorithm used in our evaluation.</p><p>Next we built an MKD based dictionary from the gallery images, and also extracted multi keypoint descriptors for each probe image. The MKD dictionary was of size 128 x 1,181,514, while the number of descriptors for all probe images was 280,838. To solve Eq. ( <ref type="formula">5</ref>), we utilized the L1 Homotopy MATLAB toolbox <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Parameter Selection and Computation Time</head><p>Our MATLAB implementation of MKD-SRC runs on a PC server with Intel Core i7 2.93GHz CPU and 16GB memo ry. There is one parameter L in the proposed algorithm, as described in Section 2.3. We tried different values of Land evaluated the resulting performance in both speed and ac curacy, as shown in Fig. <ref type="figure" target="#fig_5">4</ref>. We used a subset of the selected data, including 1,398 gallery images and 466 probe images of the 466 subjects. This resulted in K =111,643 for the dic tionary. Using all the K gallery descriptors (Eq. ( <ref type="formula" target="#formula_3">7</ref>) was not computed), the rank-l recognition rate is 83.05%, with an average recognition time of 5004 seconds per probe. From Fig. <ref type="figure" target="#fig_5">4</ref> we can see that L=100 and L=1000 have a good bal ance between computation time and accuracy. We decided to set L=100 for all the following experiments.</p><p>Next we evaluated MKD-SRC on the large-scale dataset  (11,398 gallery images and 14,630 probe images). The av erage number of keypoints per gallery image and per probe image were 104 and 19, respectively. A complete solution of the MKD-SRC framework consists of three steps: key point detection, gallery keypoint filtering (by Eq. (7», and multi-task sparse representation and classification. For a probe image, the average computation times for the first and the last steps are 0.07 and 0.61 seconds, respectively, which are independent of the gallery size. For the second step, it takes 0.80 seconds per probe, on average. As analyzed in Section 2.3, the computation time of the second step scales approximately linearly with respect to the gallery size. In smmnary, the whole matching process takes 1048 seconds per probe for a gallery of 11,398 images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Performance and Comparison</head><p>The proposed MKD-SRC algorithm was compared to the SIFT matching approach with the same keypoints and de scriptors <ref type="bibr" target="#b20">[21]</ref>. The SRC algorithm was not compared be cause it is not applicable to partial face recognition without prior alignment. Fig. <ref type="figure" target="#fig_7">5</ref> shows the performance of the cu mulative matching characteristic (CMC) curves of the two algorithms. It can be seen that the proposed MKD-SRC al gorithm significantly improves partial face recognition per formance compared to that of the SIFT matching. The rank-1 recognition rate of MKD-SRC is 81.31 %, while that of SIFT matching is 58.70%.</p><p>Figs. <ref type="figure" target="#fig_8">6</ref> and<ref type="figure" target="#fig_9">7</ref> show examples of some correctly and in correctly recognized partial faces, respectively, from the FRGCv2.0 database. It appears that the periocular region contains rich information for recognition, while face patch-   es with closed eyes, or partial mouth/cheek are not easy to recognize (note that only three images per subject were randomly selected in the gallery set). For a partial mouth patch or a cheek patch, very few keypoints could be detect ed. Fig. <ref type="figure" target="#fig_10">8</ref> shows some probe images where no keypoints could be detected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Holistic Face Recognition with occlusion</head><p>For a more convincing experimental evaluation and com parison, we performed two additional experiments on holis tic faces with staged occlusions and real occlusions. The first experiment was done on the AR database <ref type="bibr" target="#b22">[23]</ref> with staged occlusions. The AR database contains 135 subject s with 76 males and 59 females. We selected one image (neutral expression) per class as the gallery set, and 1,530 images, all with sunglasses or scarf, as the probe set. Each probe image may have left-side or right-side illumination. We added 1,196 frontal images from the FERET database <ref type="bibr" target="#b26">[27]</ref> to increase the gallery size. All images were cropped to 128 x 128 pixels after face detection. No alignment was done between the probe and gallery sets. Fig. <ref type="figure">9</ref> shows some cropped face images from the AR database. It can be seen that they are not aligned very well.</p><p>We compared the proposed method to SIFT matching <ref type="bibr" target="#b20">[21]</ref>, SRC <ref type="bibr" target="#b33">[34]</ref>, and FaceVACS <ref type="bibr" target="#b0">[1]</ref>. The alignment stage was used only in FaceVACS. Fig. <ref type="figure" target="#fig_0">10</ref> shows the CMC curves of these methods on the AR database. These re sults indicate that MKD-SRC outperforms other algorithms with a notable margin, achieving rank-l recognition rate of 76.01 %. As expected, FaceVACS does not perform very well (49.41 % rank-l accuracy) on these occluded probe im ages. The rank-l recognition rate for SIFT and SRC are 36.86% and 8.30%, respectively. Note that this experimen t is really challenging because all the probe images have faces with sunglasses or scarf and also contain illumina tion variations; meanwhile, only one sample per class with neutral expression is available in the gallery set. While Wright et al. demonstrated that their SRC algorithm showed promising performance on well aligned AR faces with sun glasses and scarf, and with sufficient number of training samples <ref type="bibr" target="#b33">[34]</ref>, our experiments show that the performance of SRC is not good on unaligned faces with only one train ing sample per class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Face Recognition on LFW</head><p>While the above experiments were done on synthesized or studio-controlled databases, we performed another ex periment on more realistic face images captured in uncon trolled environments: Labeled Faces in the Wild (LFW) <ref type="bibr" target="#b14">[15]</ref>. The LFW database was created in an effort to chal lenge face recognition algorithms in real scenarios. All im ages in this database were downloaded from the internet. The only condition for including an image in this database was that the face can be detected by the Viola-Jones face de tector <ref type="bibr" target="#b30">[31]</ref> . The LFW database includes 13,233 images of 5,749 subjects. Face images from LFW contain large varia tions in pose and illumination, and they might be arbitrarily occluded. Fig. <ref type="figure" target="#fig_12">11</ref> shows some examples from this database.</p><p>For our experiments on the LFW database, we select-  ed all the 5,749 subjects with up to lO images per subject to compose the gallery set, which included lO,489 images. The remaining 2,744 images were selected as the probe set. We also added an additional lO,OOO background im ages to enlarge the gallery set. Note that the original LFW bench mark protocol is for 1-vs-1 verification mode. Here, we conducted an identification experiment to simulate the surveillance scenario. Further, we used unaligned versions of LFW images in our experiments. These images contain extended windows (a ratio of 2.2) output by the Viola-Jones face detector, and re-scaled to 250 x 250 pixels. We used the face detector output (the center part of 114 x 114 pixels) directly for our experiments.</p><p>The CMC curves of three face recognition algorithms are depicted in Fig. <ref type="figure" target="#fig_13">12</ref>. One can observe that the perfor mance of the proposed MKD-SRC algorithm is similar to that of the state-of-the-art algorithm FaceVACS, and both of them achieve higher recognition rates than SIFT. The rank-1 recognition rates for MKD-SRC, Face VA CS, and SIFT are 56.23%, 54.96%, and 13.99%, respectively. No tice that although the recognition rates of both MKD-SRC and FaceVACS are not very satisfactory for this challenging database, it is promising that MKD-SRC could also deal with non-frontal faces. A sum score fusion of MKD-SRC and FaceVACS, also depicted in Fig. <ref type="figure" target="#fig_13">12</ref>, shows an improved rank-l accuracy of 62.79%. Fig. <ref type="figure" target="#fig_4">13</ref> shows examples of probe images that are correctly and incorrectly recognized by MKD-SRC. While MKD-SRC is able to recognize some non-frontal, occluded, or incorrectly localized faces, there still exist many challenging examples that are hard to rec ognize. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Summary and Future Work</head><p>We have addressed the problem of recognizing a face from its partial image. We have proposed a novel alignment free approach, called MKD-SRC to deal with this problem in general. MKD-SRC represents each face image with a set of keypoint descriptors, and constructs a large dictio nary from all the gallery descriptors. In this way descriptors of a probe image can be sparsely represented by the dictio nary and the identity of the probe face image can be inferred accordingly. We have shown promising results on synthe sized partial faces (from the FRGCv2.0 database), occluded holistic faces (in the AR database), and arbitrarily occlud ed or non-frontal faces (in the LFW database). Compari son with state-of-the-art approaches shows that the MKD SRC is well suited for the general partial face recognition problem. Our future work would address to improve the description step for a better handling of illumination varia tions. Furthermore, due to the general framework of MKD SRC, it may be interesting to also apply MKD-SRC to other image classification areas, such as recognition of biometric modalities other than face, and object categorization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Examples of partial faces. (a) Partial faces from the LFW database [15]. (b) Many occluded faces in a crowd I. (c) Two persons who are trying to hide their identities by wearing hooded sweatshirt and sunglasses 2.</figDesc><graphic coords="1,313.93,227.51,226.56,51.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>i=l</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Matching examples with a partial face image as probe. (a) SIFT matching: 3 keypoints are matched for a genuine pair. (b) SIFT matching: 5 keypoints are matched for an impostor pair. (c) MKD-SRC coefficient distribution and the corresponding match es. Horizontal axis: keypoints correspond to columns of D; ver tical axis: coefficient strength, as computed by �7=1 IXijl, i=l, 2, ... , K, where k=15 in this example. The maximum coefficien t strength corresponds to a genuine match (right subplot), where 8 correspondences are drawn because 8 probe descriptors get the maximum coefficients at gallery keypoints of this user. In contrast, the left subplot corresponds to an impostor match.</figDesc><graphic coords="3,402.24,229.43,146.88,109.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Example face images: (a) gallery images from the FRGCv2.0 database (upper row) and the extended gallery set (bot tom row); (b) partial face images cropped from FRGCv2.0.</figDesc><graphic coords="5,50.89,174.71,235.20,54.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Performance in both speed (average computation time per probe for a gallery of 1,398 images) and rank-l accuracy, with respect to the parameter L, on the FRGCv2.0 database.</figDesc><graphic coords="5,174.73,287.03,118.08,73.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. CMC curves on face patches extracted from the FRGCv2.0 database.</figDesc><graphic coords="5,358.08,176.64,128.64,98.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Correctly recognized partial faces (first row) synthesized from the FRGCv2.0 database and the corresponding gallery im ages (second row).</figDesc><graphic coords="6,55.69,71.03,230.40,69.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Misclassified partial faces (top row) cropped from the FRGCv2.0 database, and the corresponding true gallery images (bottom row) and the false matches at rank-l (middle row).</figDesc><graphic coords="6,200.65,191.99,85.44,98.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Partial face images with no keypoints detected.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 .Figure 10 .</head><label>910</label><figDesc>Figure 9. Typical face images from the AR database. Top row: gallery images. Bottom row: probe images.</figDesc><graphic coords="6,319.68,71.03,214.08,56.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. Sample images from the LFW database.</figDesc><graphic coords="7,95.04,71.04,145.92,72.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. CMC curves on the LFW database.</figDesc><graphic coords="7,102.72,187.20,125.76,99.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure l3 .</head><label>l3</label><figDesc>Figure l3. Correctly (top row) and incorrectly (bottom row) rec ognized face images from the LFW database using the proposed method.</figDesc><graphic coords="7,315.85,71.03,222.72,56.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Categories of partial faces</figDesc><table /><note><p><p>Category Example</p>External occlusion occlusion by other objects Self occlusion non-frontal pose Facial accessories hat, sunglasses, scarf, mask Limited field of view not completely in camera's FOV Extreme illumination gloomy or highlighted facial area</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>A comparison of partial face recognition approaches along with the proposed one</figDesc><table><row><cell>Problem addressed</cell><cell>Approach</cell><cell>Face image requirement</cell><cell>Gallery size</cell></row></table><note><p><p><p><p><p>Subspace</p><ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b23">24]</ref> </p>SRC</p><ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b31">32]</ref> </p>Occlusion SVM [14, ]6] Frontal, aligned and cropped ::;1,196</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4</head><label>4</label><figDesc>Databases used in our experiments</figDesc><table><row><cell>Database</cell><cell>FRGCv2.0</cell><cell>AR</cell><cell>LFW</cell></row><row><cell>Scenario</cell><cell>partial patch</cell><cell>occlusion</cell><cell>pose &amp; occlusion</cell></row><row><cell>#Gallery</cell><cell>11,398</cell><cell>1,331</cell><cell>20,489</cell></row><row><cell>#Probe</cell><cell>14,630</cell><cell>1,530</cell><cell>2,744</cell></row><row><cell>#Subjects</cell><cell>10,466</cell><cell>1,331</cell><cell>15,749</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://www.textually.org/picturephoning/archives/2008/09/021247.htm</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://www.howtovanish.coml20 1 010 1 lavoi d-nosy -surveillance camerasl</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>The authors would like to thank Brendan Klare and Un sang Park for their valuable feedback. Anil K. Jain's re search was partially supported by the WCU (World Class University) program funded by the Ministry of Education, Science and Technology through the National Research Foundation of Korea (R31-1 0008).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://www.cognitec-systems.de.1" />
		<title level="m">FaceVACS Software Developer Kit, Cognitec Systems Gmb H</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">PittPatt Face Recognition Web Demo</title>
		<ptr target="http://demo.pittpatt.comlrecognition_demo/.1" />
		<imprint>
			<publisher>Pittsburgh Pattern Recognition, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Ll homotopy: A MATLAB toolbox for ho motopy algorithms in Ll norm minimization problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Asif</surname></persName>
		</author>
		<ptr target="http://users.ece.gatech.edursasiflhomotopy/.5" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Face recognition under varying pose</title>
		<author>
			<persName><forename type="first">D</forename><surname>Beymer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pat tern Recognition</title>
		<imprint>
			<date type="published" when="1994-06">June 1994</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the use of SIFT features for face authentication</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bicego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lagorio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grosso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tistarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPRW &apos;06: Proceedings of the 2006 Conference on Computer Vi sion and Pattern Recognition Workshop</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Face recognition: Features ver sus templates</title>
		<author>
			<persName><forename type="first">R</forename><surname>Brunelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sparse representation of (Multi scale) histograms for face recognition robust to registration and il lumination problems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Active appearance models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="681" to="685" />
			<date type="published" when="2001-06">June 2001. 2</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ac tive shape models -their training and application</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="38" to="59" />
			<date type="published" when="1995-01">Jan 1995. 2</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Why is facial occlusion a challenging problem?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ekenel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Biometrics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fisher light-fields for face recognition across pose and illumination</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An investigation into the use of partial-faces for face recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Philomin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Trajkovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pro ceedings of International Conference on Automatic Face and Gesture Recognition</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Face recognition: component-based versus global approaches</title>
		<author>
			<persName><forename type="first">B</forename><surname>Heisele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vi sion and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Robust face recognition under partial occlusion based on support vector machine with local gaussian sum mation kernel</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hotta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Labeled faces in the wild: A database for studying face recognition in unconstrained environments</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
		<idno>port 07-49</idno>
		<imprint>
			<date type="published" when="2007-10">October 2007</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<pubPlace>Amherst</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Re</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Support vector machines in face recognition with occlusions</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Martinez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Com puter Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Com puter Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2009-06">June 2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Effective representa tion using ICA for face recognition robust to local distortion and partial occlusion</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Turk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="1977">1977-1981, 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Face iden tification by SIFT-based complete graph topology</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kisku</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rattani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grosso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tistarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshop on Automatic Identification Advanced Te chnolo gies</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="63" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Matching forensic sketches to mug shot photos. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">B</forename><surname>Klare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="639" to="646" />
			<date type="published" when="2004">march 2011. 4</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Robust face recognition using block-based bag of words</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Imai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kaneko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 20th International Confer ence on Pattern Recognition</title>
		<imprint>
			<date type="published" when="2004-02">Aug. 2010. 2, 4</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004. 2, 3, 4, 5, 6</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Recognizing imprecisely localized, partially occluded, and expression variant faces from a single sample per class</title>
		<author>
			<persName><forename type="first">A</forename><surname>Martinez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Ma chine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2002-06">June 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The AR face database</title>
		<author>
			<persName><forename type="first">A</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Benavente</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>CV C</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Occlusion invariant face recognition using selective local non-negative matrix factorization basis images</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Periocular biometrics in the visible spectrum: A feasibility study</title>
		<author>
			<persName><forename type="first">U</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 3rd Interna tional Conference on Biometrics: Theory, Applications, and Systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">View-based and modular eigenspaces for face recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Moghaddam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Starner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceed ings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>eed ings of the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The FERET database and evaluation procedure for face-recognition algo rithms</title>
		<author>
			<persName><forename type="first">P</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wechsler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="295" to="306" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Overview of the face recognition grand challenge</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Scruggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Worek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Partial face recognition using radial basis function networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third IEEE International Conference on Automatic Face and Gesture Recognition</title>
		<meeting>the Third IEEE International Conference on Automatic Face and Gesture Recognition</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Linear object classes and image synthesis from a single example image</title>
		<author>
			<persName><forename type="first">T</forename><surname>Vetter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Robust real time object detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICCV Workshop on Statistical and Computational Theories of Vision</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-07-13">July 13 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">To wards a practical face recognition system: Robust registra tion and illumination by sparse representation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Com puter Society Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Face recognition by elastic bunch graph matching</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wiskott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Fellous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intel ligence</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note>von der Mals burg</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Robust face recognition via sparse representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2006">2009. 2, 3, 4, 5, 6</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Partial face match ing between near infrared and visual images in MBGC portal challenge</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Biometrics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="733" to="742" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
