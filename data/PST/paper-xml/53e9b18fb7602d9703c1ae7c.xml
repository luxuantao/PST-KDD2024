<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Spider Monkey Optimization algorithm for numerical optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Memetic</forename><surname>Comp</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jagdish</forename><surname>Chand Bansal</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Harish</forename><surname>Sharma</surname></persName>
							<email>harish.sharma0107@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Shimpi</forename><surname>Singh</surname></persName>
							<email>shimpisingh2k6@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Maurice</forename><surname>Clerc</surname></persName>
							<email>maurice.clerc@writeme.com</email>
						</author>
						<author>
							<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bansal</surname></persName>
							<email>jcbansal@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Jadon</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">ABV-Indian Institute of Information Technology and Management</orgName>
								<address>
									<settlement>Gwalior</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">South Asian</orgName>
								<address>
									<settlement>University, New Delhi</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Independent Consultant in Optimization</orgName>
								<address>
									<settlement>Groisy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Spider Monkey Optimization algorithm for numerical optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9D953EDBE8BC7310A6C8CF5692F301A1</idno>
					<idno type="DOI">10.1007/s12293-013-0128-0</idno>
					<note type="submission">Received: 21 June 2012 / Accepted: 7 December 2013</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Swarm intelligence is one of the most promising area for the researchers in the field of numerical optimization. Researchers have developed many algorithms by simulating the swarming behavior of various creatures like ants, honey bees, fish, birds and the findings are very motivating. In this paper, a new approach for numerical optimization is proposed by modeling the foraging behavior of spider monkeys. Spider monkeys have been categorized as fission-fusion social structure based animals. The animals which follow fissionfusion social systems, split themselves from large to smaller groups and vice-versa based on the scarcity or availability of food. The proposed swarm intelligence approach is named as Spider Monkey Optimization (SMO) algorithm and can broadly be classified as an algorithm inspired by intelligent foraging behavior of fission-fusion social structure based animals.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The name swarm is used for an accumulation of creatures such as ants, fish, birds, termites and honey bees which behave collectively. The definition given by Bonabeau for the swarm intelligence is "any attempt to design algorithms or distributed problem-solving devices inspired by the collective behaviour of social insect colonies and other animal societies" <ref type="bibr" target="#b2">[3]</ref>.</p><p>Swarm Intelligence is a meta-heuristic approach in the field of nature inspired techniques that is used to solve optimization problems. It is based on the collective behavior of social creatures. Social creatures utilize their ability of social learning and adaptation to solve complex tasks. Researchers have analyzed such behaviors and designed algorithms that can be used to solve nonlinear, non-convex or combinatorial optimization problems in many science and engineering domains. Previous research <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b38">39]</ref> have shown that algorithms based on Swarm Intelligence have great potential to find a near optimal solution of real world optimization problem. The algorithms that have been emerged in recent years are Ant Colony Optimization (ACO) <ref type="bibr" target="#b6">[7]</ref>, Particle Swarm Optimization (PSO) <ref type="bibr" target="#b16">[17]</ref>, Bacterial Foraging Optimization (BFO) <ref type="bibr" target="#b25">[26]</ref>, Artificial Bee Colony Optimization (ABC) <ref type="bibr" target="#b13">[14]</ref> etc.</p><p>In order to design a new swarm intelligence based algorithm, it is necessary to understand whether a behavior is swarm intelligent behavior or not. Karaboga et al. mentioned that Division of Labor and Self-Organization are the necessary and sufficient conditions for obtaining intelligent swarming behaviors. 1. Self-organization: is an important feature of a swarm structure which results in global level response by means of interactions among its low-level components without a central authority or external element enforcing it through planning. Therefore, the globally coherent pattern appears from the local interaction of the components that build up the structure, thus the organization is achieved in parallel as all the elements act at the same time and distributed as no element is a central coordinator. <ref type="bibr">Bonabeau et al.</ref> have defined the following four important characteristics on which self-organization is based <ref type="bibr" target="#b2">[3]</ref>:</p><p>(i) Positive feedback: is an information extracted from the output of a system and reapplied to the input to promotes the creations of convenient structures. In the field of swarm intelligence positive feedback provides diversity and accelerate the system to new stable state. (ii) Negative feedback: compensates the effect of positive feedback and helps to stabilize the collective pattern. (iii) Fluctuations: are the rate or magnitude of random changes in the system. Randomness is often crucial for efflorescent structures since it allows the findings of new solutions. In foraging process, it helps to getride of stagnation. (iv) Multiple interactions: provide the way of learning from the individuals within a society and thus enhance the combined intelligence of the swarm.</p><p>2. Division of labour: is a cooperative labour in specific, circumscribed tasks and like roles. In a group, there are various tasks, which are performed simultaneously by specialized individuals. Simultaneous task performance by cooperating specialized individuals is believed to be more efficient than the sequential task performance by unspecialized individuals <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b23">24]</ref>.</p><p>This paper proposes a new swarm intelligence algorithm based on the foraging behavior of spider monkeys. The foraging behavior of spider monkeys shows that these monkeys fall in the category of fission-fusion social structure (FFSS) based animals. Thus the proposed optimization algorithm which is based on foraging behavior of spider monkeys is explained better in terms of FFSS. Further, the proposed strategy is tested on various benchmark and engineering optimization test problems. The rest of the paper is organized as follows: Sect. 2 describes the foraging behavior and social structure of spider monkeys. In Sect. 3, first, the foraging behavior is critically evaluated to be a swarm intelligent behavior over the necessary and sufficient conditions of swarm intelligence and then Spider Monkey Optimization algorithm is proposed. A detail discussion about the proposed strategy is presented in Sect. 4. In Sect. 5, performance of the proposed strategy is analyzed and compared with four state-of-the-art algorithms, namely DE, PSO, ABC and CMA-ES. Finally, in Sect. 6, paper is concluded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Foraging and social behavior of spider monkeys</head><p>Fission-fusion swarm is a social grouping pattern in which individuals form temporary small parties (also called subgroups) whose members belong to a larger community (or unit-group) of stable membership, there can be fluid movement between subgroups and unit-groups such that group composition and size changes frequently <ref type="bibr" target="#b36">[37]</ref>.</p><p>The fission-fusion social system of swarm can minimize direct foraging competition among group members, so they divide themselves into sub-groups in order to search food. The members of these subgroups then communicate (through barking and other physical activities) within and outside the subgroup depending upon the availability of food. In this society, social group sleep in one habitat together but forage in small sub-groups going off in different directions during the day. This form of social formation occurs in several species of primates like hamadryas, bonobo, chimpanzees, gelada baboons and spider monkeys. These societies change frequently in their size and composition, making up a strong social group called the 'parent group'. All the individual members of a faunal community comprise of permanent social networks and their capability to track changes in the environment varies according to their individual animal dynamics. In a fission-fusion society, the main parent group can fission into smaller subgroups or individuals to adapt to the environmental or social circumstances. For example, members of a group are separated from the main group in order to hunt or forage for food during the day, but at night they return to join (fusion) the primary group to share food and to take part in other activities <ref type="bibr" target="#b36">[37]</ref>.</p><p>The society of spider monkeys is one of the example of fission-fusion social structure. In subsequent subsections, a brief overview on swarming of spider monkeys is presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Social organization and behavior</head><p>The social organization of spider monkeys is related to fission-fusion social system. Figure <ref type="figure" target="#fig_0">1</ref> provide some pictures of spider monkeys <ref type="bibr" target="#b30">[31]</ref>. They are social animals and live in group of up to 50 individuals <ref type="bibr" target="#b33">[34]</ref>. Spider monkeys break up into small foraging groups that travel together and forage throughout the day within a core area of the larger group's home range <ref type="bibr" target="#b33">[34]</ref>. Spider monkeys find their foods in a very different way: a female leads the group and is responsible for finding food sources. In case if she doesn't find sufficient food for the group, she divides the group into smaller subgroups that forage separately <ref type="bibr" target="#b22">[23]</ref>. The subgroups within the band are temporary and may vary in formation frequently throughout the day, but on average 3 members can be found in any group at any time <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b37">38]</ref>. When two different bands of spider monkeys come closer, the males in each band display aggressiveness and territorial behavior such as calling  <ref type="bibr" target="#b30">[31]</ref> and barking. These communications occur with much distance between the two subgroups and do not involve any physical contacts, showing that groups respect distinct territory boundaries <ref type="bibr" target="#b37">[38]</ref>. Members of a society might not ever be noticed closer at one place, but their mutual tolerance of each other when they come into contact reflects that they are component of the larger group <ref type="bibr" target="#b37">[38]</ref>. The main reason behind emerging of fission-fusion social system is the competition for food among the group members when there is a shortage in food availability due to seasonal reasons <ref type="bibr" target="#b22">[23]</ref>. When a big group gets food at particular location, there is likely to be less food per group member compared to a small group. After some time, when food scarcity is at its peak, average subgroup size is the smallest and during period of highest food availability, subgroup size is the largest, indicating that competition for scarce resources necessitates breaking into smaller foraging groups <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b37">38]</ref>. One reason spider monkeys break into smaller foraging groups but still remain part of a larger social unit is the advantage to individual group members in terms of increased mating chances and security from predators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Communication</head><p>Spider monkeys share their intentions and observations using postures and positions, such as postures of sexual receptivity and of attack. During traveling, they interact with each other over long distances using a particular call which sounds like a horse's whinny. Each individual has its own discernible sound so that other members of the group can easily identify who is calling. This long-distance communication permits spider monkeys to get-together, stay away from enemies, share food and gossip. In order to interact to other group members, they generally use visual and vocal communication <ref type="bibr" target="#b29">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Spider Monkey Optimization algorithm</head><p>Social behavior of spider monkeys inspires authors to develop an stochastic optimization technique that mimics fission-fusion social structure (FFSS) based foraging behav-ior of spider monkeys. Following are the key features of the FFSS.</p><p>1. The fission-fusion social structure based animals are social and live in groups of 40-50 individuals. The FFSS of swarm may reduce the foraging competition among group members by dividing them into sub-groups in order to search food. 2. A female (global Leader) generally leads the group and is responsible for searching food sources. If she is not able to get enough food for the group, she divides the group into smaller subgroups (size varies from 3 to 8 members) that forage independently. 3. Sub-groups are also supposed to be lead by a female (local leader) who becomes decision-maker for planning an efficient foraging route each day. 4. The members of these subgroups then communicate within and outside the subgroup depending upon the availability of food and to maintain territorial boundaries.</p><p>In the developed strategy, the foraging behavior of FFSS based animals (e.g. spider monkeys) is divided into four steps. First, the group starts food foraging and evaluates their distance from the food. In the second step, based on the distance from the foods, group members update their positions and again evaluate distance from the food sources. Furthermore, in the third step, the local leader updates its best position within the group and if the position is not updated for a specified number of times then all members of that group start searching of the food in different directions. Next, in the fourth step, the global leader, updates its ever best position and in case of stagnation, it splits the group into smaller size subgroups. All the four steps mentioned before, are continuously executed until the desired output is achieved. There are two important control parameters necessary to introduce in the proposed strategy, one is 'GlobalLeaderLimit' and another is 'LocalLeaderLimit' which helps local and global leaders to take appropriate decisions.</p><p>The control parameter LocalLeaderLimit is used to avoid stagnation i.e., if a local group leader does not update herself in a specified number of times then that group is re-directed to a different direction for foraging. Here, the term 'specified number of times' is referred as LocalLeaderLimit. Another control parameter, GlobalLeaderLimit is used for the same purpose for global leader. The global leader breaks the group into smaller sub-groups if she does not update in a specified number of times.</p><p>The proposed strategy follows self-organization and division of labour properties for obtaining intelligent swarming behaviors of animals. As animals updating their positions by learning from local leader, global leader and self experience in the first and second steps of algorithm, it shows positive feedback mechanisms of self-organization. The third step, in which the stagnated group members are re-directed to different directions for food searching, is responsible for fluctuations in the food foraging process. In the fourth step, when the global leader is get stuck, it divides the groups into smaller subgroups for foraging of foods. This phenomena presents division of labour property. 'Local leader limit' and 'Global leader limit' provides negative feedback to help local and global leader's for their decisions.</p><p>However, the proposed strategy is inspired from the foraging behavior of spider monkeys, it is different from the natural foraging behavior of spider monkeys. In In the proposed strategy, the post of leader (local or global) is not permanent but depends upon the ability of leader to search of food. Further, the spider monkeys use different type of communication tactics which are not simulated by the proposed strategy. In this way, the proposed strategy is different from the real foraging behavior of spider monkeys.  <ref type="bibr" target="#b41">[42]</ref> and modified version of ABC <ref type="bibr" target="#b15">[16]</ref>. The details of each step of SM O implementation are explained below:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Initialization of the population</head><p>Initially, SM O generates a uniformly distributed initial population of N spider monkeys where each monkey</p><formula xml:id="formula_0">SM i (i = 1, 2, ..., N ) is a D-dimensional vector.</formula><p>Here D is the number of variables in the optimization problem and SM i represent the i th Spider Monkey (SM) in the population. Each spider monkey SM corresponds to the potential solution of the problem under consideration. Each SM i is initialized as follows:</p><formula xml:id="formula_1">SM i j = SM min j + U (0, 1) × (SM max j -SM min j ) (1)</formula><p>where SM min j and SM max j are bounds of SM i in j th direction and U (0, 1) is a uniformly distributed random number in the range [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Local Leader Phase (LLP)</head><p>In the Local Leader phase, each Spider Monkey SM modifies its current position based on the information of the local leader experience as well as local group members experience.</p><p>The fitness value of so obtained new position is calculated.</p><p>If the fitness value of the new position is higher than that of the old position, then the SM updates his position with the new one. The position update equation for ith SM (which is a member of kth local group) in this phase is</p><formula xml:id="formula_2">SMnew i j = SM i j + U (0, 1) × (L L k j -SM i j ) + U (-1, 1) × (SM r j -SM i j ) (2)</formula><p>where SM i j is the jth dimension of the ith SM, L L k j represents the jth dimension of the kth local group leader position. SM r j is the jth dimension of the r th SM which is chosen randomly within kth group such that r = i, U (0, 1) is a uniformly distributed random number between 0 and 1. Algorithm 1 shows position update process in the Local Leader phase. In Algorithm 1, MG is the maximum number of groups in the swarm and pr is the perturbation rate which controls the amount of perturbation in the current position. The range of pr is [0.1, 0.9] (explained in Sect. 5.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Position update process in Local Leader Phase:</head><p>for each k ∈ {1, ..., MG} do for each member SM i ∈ k th group do for each j ∈ {1, ..., D} do if U (0, 1) ≥ pr then</p><formula xml:id="formula_3">SMnew i j = SM i j +U (0, 1)×(L L k j -SM i j )+U (-1, 1)×(SM r j -SM i j ) else SMnew i j = SM i j end if</formula><p>end for end for end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Global Leader Phase (GLP)</head><p>After completion of the Local Leader phase, the Global Leader phase (GLP) starts. In GLP phase, all the SM's update their position using experience of Global Leader and local group member's experience. The position update equation for this phase is as follows:</p><formula xml:id="formula_4">SMnew i j = SM i j + U (0, 1) × (G L j -SM i j ) + U (-1, 1) × (SM r j -SM i j )<label>(3)</label></formula><p>where G L j represents the jth dimension of the global leader position and j ∈ {1, 2, ..., D} is the randomly chosen index.</p><p>In this phase, the positions of spider monkeys (SM i ) are updated based on a probabilities pr ob i which are calculated using their fitness. In this way a better candidate will have a higher chance to make itself better. The probability pr ob i may be calculated using following expression (there may be some other but it must be a function of fitness):</p><formula xml:id="formula_5">pr ob i = 0.9 × f itness i max_ f itness + 0.1,<label>(4)</label></formula><p>here f itness i is the fitness value of the ith SM and max_ f itness is the maximum fitness in the group. Further, the fitness of the newly generated position of the SM's is calculated and compared with the old one and adopted the better position.</p><p>Algorithm 2 Position update process in Global Leader Phase (GLP) :</p><formula xml:id="formula_6">for k = 1 to MG do count = 1; GS = k th group size; while count &lt; GS do for i = 1 to GS do if U (0, 1) &lt; prob i then count = count + 1.</formula><p>Randomly select j ∈ {1...D}.</p><p>Randomly select SM r from k th group s.t. r = i.</p><formula xml:id="formula_7">SMnew i j = SM i j +U (0, 1)×(G L j -SM i j )+U (-1, 1)×(SM r j -SM i j ). end if end for if i is equal to GS then i = 1;</formula><p>end if end while end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Global Leader Learning (GLL) phase</head><p>In this phase, the position of the global leader is updated by applying the greedy selection in the population i.e., the position of the SM having best fitness in the population is selected as the updated position of the global leader. Further, it is checked that the position of global leader is updating or not and if not then the Global LimitCount is incremented by 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.5">Local Leader Learning (LLL) phase</head><p>In this phase, the position of the local leader is updated by applying the greedy selection in that group i.e., the position of the SM having best fitness in that group is selected as the updated position of the local leader. Next, the updated position of the local leader is compared with the old one and if the local leader is not updated then the Local LimitCount is incremented by 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.6">Local Leader Decision (LLD) phase</head><p>If any Local Leader position is not updated up to a predetermined threshold called Local Leader Limit, then all the members of that group update their positions either by random initialization or by using combined information from Global Leader and Local Leader through Eq. ( <ref type="formula" target="#formula_8">5</ref>), based on the pr .</p><formula xml:id="formula_8">SMnew i j = SM i j + U (0, 1) × (G L j -SM i j ) + U (0, 1) × (SM i j -L L k j );<label>(5)</label></formula><p>It is clear from the Eq. ( <ref type="formula" target="#formula_8">5</ref>) that the updated dimension of this SM is attracted towards global leader and repel from the local leader. The pseudo code of LLD phase for kth group is shown in Algorithm 3. In this algorithm Local LimitCount k is the trial counter for the local best solution of kth group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 Local Leader Decision Phase:</head><formula xml:id="formula_9">for k = {1...MG} do if Local LimitCount k &gt; Local Leader Limit then Local LimitCount k = 0.</formula><p>GS = k th group size;</p><p>for i ∈ {1...GS} do for each j ∈ {1...D} do if U (0, 1) ≥ pr then SMnew i j = SM min j + U (0, 1) × (SM max j -SM min j )</p><p>else</p><formula xml:id="formula_10">SMnew i j = SM i j +U (0, 1) × (G L j -SM i j ) +U (0, 1) × (SM i j -L L k j ) end if</formula><p>end for end for end if end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.7">Global Leader Decision (GLD) phase</head><p>In this phase, the position of global leader is monitored and if it is not updated up to a predetermined number of iterations called Global Leader Limit, then the global leader divides the population into smaller groups. Firstly, the population is divided into two groups and then three groups and so on till the maximum number of groups (MG) are formed as shown in the Figs.  -MG = N /10, i.e., it is chosen such that minimum number of SM's in a group should be 10 </p><formula xml:id="formula_11">-Global Leader Limit ∈ [N /2, 2 × N ],</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>Exploration and exploitation are the two important characteristics of the population (or swarm) based optimization algorithms <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b24">25]</ref>. In optimization algorithms, the explo-Fig. <ref type="figure">4</ref> SMO topology: swarm is divided into three group Fig. <ref type="figure">5</ref> SMO topology: minimum size group ration represents the ability to discover the global optimum by investigating the various unknown regions in the solution search space. While, the exploitation represents the ability to find better solutions by implementing the knowledge of the previous good solutions. In behavior, the exploration and exploitation contradict with each other, however both abilities should be well balanced to achieve better optimization performance <ref type="bibr" target="#b39">[40]</ref>. It is expected from a good search process that it should explore the new solutions, while main-taining satisfactory performance by exploiting existing solutions <ref type="bibr" target="#b11">[12]</ref>.</p><p>The inherent drawback with most of the population based stochastic algorithms is premature convergence. ABC, DE and PSO are not exceptions <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20]</ref>. Dervis Karaboga and Bahriye Akay <ref type="bibr" target="#b14">[15]</ref> compared the different variants of ABC and found that ABC shows poor performance and remains inefficient in exploring the search space. The solution search equation of ABC is significantly influenced by a random quantity which helps in exploration at the cost of exploitation of the search space <ref type="bibr" target="#b41">[42]</ref>. Further, Mezura-Montes et al. <ref type="bibr" target="#b19">[20]</ref> analyzed DE and its variants for global optimization and found that DE has deficiency of premature convergence and stagnation. Also some studies proved that DE sometimes stops proceeding toward the global optima even though the population has not converged to local optima or any other point <ref type="bibr" target="#b17">[18]</ref>. Price et al. <ref type="bibr" target="#b27">[28]</ref> also drawn the same conclusions regarding DE. However the standard PSO has the capability to get a good solution at a significantly faster rate but, when it is compared to other optimization techniques, it is weak to refine the optimum solution, mainly due to less diversity in later search <ref type="bibr" target="#b1">[2]</ref>. On the different side, problem-based tuning of parameters is required in PSO, to get an optimum solution accurately and efficiently <ref type="bibr" target="#b32">[33]</ref>. Therefore, it is clear that if a population based algorithm is capable of balancing between exploration and exploitation of the search space, then the algorithm is regarded as an efficient algorithm. From this point of view ABC, PSO and DE are not efficient algorithms. The problems of premature convergence and stagnation is a matter of serious consideration for designing a comparatively efficient nature inspired algorithms (NIAs). By keeping in mind the existing drawbacks of NIAs, SMO is designed in this paper.</p><p>In the proposed algorithm, the first phase named 'Local Leader phase' is used to explore the search region as in this phase all the members of the groups update their positions with high perturbation in the dimensions. The perturbation is high for initial iterations and gradually reducing in later iterations. The second phase 'Global Leader phase' promotes the exploitation as in this phase, better candidates get more chance to update and in position update process, only single randomly selected dimension is updated. The third and fourth phase namely 'Local Leader Learning phase' and 'Global Leader Learning phase', are used to check that the search process is not stagnated. In these two phases, it is checked that the local best and global best solutions are updating or not in a predefined number of trials. If not then the solution is considered stagnated. The fifth phase 'Local Leader Decision phase' is used to avoid the stagnation or premature convergence of local solutions. In this phase, if the local best solution is not updated in a predefined number of trials (LocalLeaderLimit) then all the members of that group are re-initialized. In this phase, all the dimensions of the individ-uals are initialized either randomly or by using global best solution and best solution. Further, the Global Leader Decision phase is used to avoid stagnation of the global best solution. In this phase if the global best solution is not updated within a predefined number of trials (GlobalLeaderLimit) then the group is divided into smaller subgroups. The benefit of this structured group strategy is that initially there is a single group so every newly generated food source is attracted towards the best food source (in this case the global best will be the local best also), thereby converging faster to the solution. But as a results of such exploitative tendency, in many cases, the population may skip the global minima and can get stuck into local minima. Therefore, to avoid this situation, if global minima is not updating itself for a predefined number of times then the group is divided into subgroups. Now every new solution will be attracted towards the respective subgroup's local best food source, hence contributes in the exploration of the search space. When the maximum number of subgroups have been formed and even though the global optima is not updating its position then all the subgroups are combined to form a single group and process repeats itself. Therefore, this phase helps to balance the exploration and exploitation capability of the algorithm while maintaining the convergence speed. From above discussion, it is clear that SMO tries to balance the diversity in the population/swarm and hence can be considered as a new candidate in the field of population based algorithms like ABC <ref type="bibr" target="#b14">[15]</ref>, PSO <ref type="bibr" target="#b16">[17]</ref>, DE <ref type="bibr" target="#b34">[35]</ref> etc. In ABC, DE and PSO, the position update equation is based on the difference vector and so is the case with SMO. Therefore, it may be considered in the category of ABC, PSO and DE algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental results</head><p>In order to analyze the performance of SMO algorithm, 26 different global optimization problems ( f 1 to f 26 ) are selected (listed in Table <ref type="table" target="#tab_2">1</ref>). These are continuous, un-biased optimization problems and have different degrees of complexity and multimodality. Test problems f 1f 19 and f 24f 26 are taken from <ref type="bibr" target="#b0">[1]</ref> and test problems f 20f 23 are taken from <ref type="bibr" target="#b35">[36]</ref> with the associated offset values. This set is large enough to include different kinds of problems such as unimodal, multimodal, separable and non separable. A unimodal function f (x) has a single extremum (minimum or maximum in the range specified for x. On the other hand if a function has more than one peaks in the search space i.e., local extremum, this function is called multimodal. Multimodal functions are used to test the ability of algorithms getting rid of local minima. If the exploration process of an algorithm is poor then it will not be able to search the whole search space efficiently and will stuck to some local optima. Functions having flat surfaces are also difficult for algorithms since, the flatness of the function does not give any informa-tion to the algorithm to direct the search process towards the minima.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental setting</head><p>Swarm size, perturbation rate ( pr ), L L L, G L L and maximum number of groups (MG) are the parameters that affect the performance of the SM O, significantly. To fine tune (finding most suitable values) these parameters, sensitivity analyses with different values of these parameters have been carried out. Swarm size is varied from 40 to 160 with step size 20, pr is varied from 0.1 to 0.9 with step size 0.1, MG is varied from 1 to 6 with step size 1, L L L is varied from 100 to 2500 with step size 200 and G L L is varied from 10 to 220 with step size 30. At a time only one parameter is varied while all other parameters are kept fixed. This fine tuning is done with the following assumptions:</p><p>-pr is varied from 0.1 to 0.9 while MG, L L L, G L L and Swarm size are fixed to be 5, 1500, 50, and 50, respectively. -MG is varied from 1 to 6 while L L L, G L L and Swarm size are fixed to be 1500, 50, and 50, respectively. pr is linearly increasing from 0.1 to 0.4 through iterations. -G L L is varied from 10 to 220 while L L L, MG and Swarm size are fixed to be 1500, 5, and 50, respectively. pr is linearly increasing from 0.1 to 0.4 through iterations. -L L L is varied from 100 to 2500 while MG, G L L and Swarm size are fixed to be 5, 50, and 50, respectively. pr is linearly increasing from 0.1 to 0.4 through iterations. -Swarm size is varied from 40 to 160 while L L L, G L L and MG are fixed to be 1500, 50, and 5, respectively. pr is linearly increasing from 0.1 to 0.4 through iterations.</p><p>For the purpose of sensitivity analysis, 6 test problems are considered and each problem is simulated 30 times. Effects of these parameters are shown in Fig. <ref type="figure">6a</ref>-f respectively. It is clear from Fig. <ref type="figure">6a</ref> that SMO is very sensitive towards pr . SMO performs better on some problems with small values of pr while on some, it performs better with large values of pr . Therefore, the value of pr is adopted linearly increasing over iterations to consider the dynamic nature of parameter pr . It should be noted that this setting of pr is not general. For a particular problem a different setting of pr may provide better results. Further, by analyzing Fig. <ref type="figure">6b</ref>, it can be stated that the value of MG = 5 gives comparatively better results for the given set of test problems. Sensitivity of Global Leader Limit (G L L) and Local Leader Limit (L L L) can be analyzed by Fig. <ref type="figure">6c,</ref><ref type="figure">d</ref>. It is observed that the value of G L L = 50 and L L L = 1500 gives better results on the considered benchmark optimization problems. Further, swarm size is analyzed in Fig. <ref type="figure">6e,</ref><ref type="figure">f</ref>. It is clear from Fig. <ref type="figure">6e</ref> that SMO is quite sensitive with respect </p><formula xml:id="formula_12">f 1 (x) = D i=1 ( i j=1 x j ) 2 [-100, 100] 0 30 UN 1.0E -03</formula><p>Step function</p><formula xml:id="formula_13">f 2 (x) = D i=1 ( x i + 0.5 ) 2 [-100, 100] 0 30 US 1.0E -03</formula><p>Schwefel function</p><formula xml:id="formula_14">f 3 (x) = -D i=1 (x i sin √ |x i |) [-500, 500] -418.9829×D 30 MS 1.0E -03 Rastrigin f 4 (x) = 10D + D i=1 [x 2 i -10 cos(2π x i )]</formula><p>[-5.12, 5.12] 0 30 MS</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1.0E -03</head><p>Levy function 1 <ref type="bibr" target="#b9">10,</ref><ref type="bibr">100,</ref><ref type="bibr" target="#b3">4)</ref>, where</p><formula xml:id="formula_15">f 5 (x) = π D [10 sin 2 (π y 1 ) + D-1 i=1 (y i -1) 2 (1 + 10 sin 2 (π y i+1 )) + (y D -1) 2 ] + D i=1 u(x i ,</formula><formula xml:id="formula_16">y i = 1 + 1 4 (x i + 1) and u(x i , a, k, m) = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ k(x i -a) m , x i &gt; a; 0, -a ≤ x i ≤ a; k(-x i -a) m , x i &lt; a. [-50, 50] 0 30 MN 1.0E -03 Levy function 2 f 6 (x) = 0.1(sin 2 (3π x 1 ) + D-1 i=1 [(x i -1) 2 (1 + sin 2 (3π x i+1 ))] + (x -1) 2 (1 + sin 2 (2π x D )) + D i=1 u(x i , 5, 100, 4) [-50, 50] 0 30 MN 1.0E -03</formula><p>Shekel Foxholes Function </p><formula xml:id="formula_17">f 7 (x) = [ 1 500 + 25 j=1 1 j+ 2 i=1 (x i -A i j ) 6 ] -1</formula><formula xml:id="formula_18">f 8 (x) = 11 i=1 a i - x1(b 2 i +b i x2) b 2 i +b i x3+x4 2 [-5, 5] 0.0003075 4 MN 1.0E -03</formula><p>Six-hump camel back</p><formula xml:id="formula_19">f 9 (x) = (4 -2.1x 2 1 + x 4 1 /3)x 2 1 + x 1 x 2 + (-4 + 4x 2 2 )x 2 2 [-5, 5] -1.0316 2 MN 1.0E -03</formula><p>Branin RCOS function</p><formula xml:id="formula_20">f 10 (x) = (x 2 -5.1 4π 2 x 2 1 + 5 π x 1 -6) 2 + 10(1 -1 8π ) cos x 1 + 10 x 1 ∈ [-5, 10], x 2 ∈ [0, 15] 0.397887 2 MN 1.0E -03</formula><p>Goldstien &amp; Price function</p><formula xml:id="formula_21">f 11 (x) = [1 + (x 1 + x 2 + 1) 2 (19 -14x 1 + 13x 2 1 -14x 2 + 6x 1 x 2 + 3x 2 2 )] * [30 + (2x 1 -3x 2 ) 2 (18 -32x 1 + 12x 2 1 -48x 2 -36x 1 x 2 + 27x 2 2 )] [-2, 2] 3 2 MN 1.0E -03</formula><p>Hartmann function 3</p><formula xml:id="formula_22">f 12 (x) = -4 i=1 α i ex p[-3 j=1 A i j (x j -P i j ) 2 ] [0, 1] -3.86278 3 MN 1.0E -03</formula><p>Hartmann function 6  </p><formula xml:id="formula_23">f 13 (x) = -4 i=1 α i ex p[-6 j=1 B i j (x j -Q i j ) 2 ] [0, 1] -3.32237 6 MN 1.0E -03 Shekel function 5 f 14 (x) = -5 j=1 [ 4 i=1 (x i -C i j ) 2 + β j ] -1 [0, 10] -10.1532 4 MN 1.0E -03 Shekel function 7 f 15 (x) = -7 j=1 [ 4 i=1 (x i -C i j ) 2 + β j ] -1 [0, 10] -10.4029 4 MN 1.0E -03 Shekel function 10 f 16 (x) = -10 j=1 [ 4 i=1 (x i -C i j ) 2 + β j ] -1 [0, 10]</formula><formula xml:id="formula_24">f 19 (x) = [1.5 -x 1 (1 -x 2 )] 2 + [2.25 -x 1 (1 -x 2 2 )] 2 + [2.625 -x 1 (1 -x 3 2 )] 2 [-4.5, 4.5] 0 2 UN 1.0E -05 Shifted Sphere f 20 (x) = D i=1 z 2 i + f bias , z = x -o, x = [x 1 , x 2 , ....x D ], o = [o 1 , o 2 , ...o D ] [-100, 100] -450 10 US 1.0E -05 Shifted Schwefel f 21 (x) = D i=1 ( i j=1 z j ) 2 + f bias , z = x -o, x = [x 1 , x 2 , ....x D ], o = [o 1 ,</formula><formula xml:id="formula_25">f 22 (x) = D i=1 z 2 i 4000 -D i=1 cos( z i √ i ) + 1 + f bias , z = (x -o), x = [x 1 , x 2 , ....x D ], o = [o 1 , o 2 , ...o D ]</formula><p>[-600, 600] -180</p><formula xml:id="formula_26">10 MN 1.0E -05 Shifted Ackley f 23 (x) = -20 exp(-0.2 1 D D i=1 z 2 i ) - exp( 1 D D i=1 cos(2π z i )) + 20 + e + f bias , z = (x - o), x = (x 1 , x 2 , ........x D ), o = [o 1 , o 2 , ........o D ] [-32, 32] -140 10 MS 1.0E -05</formula><p>Easom's function</p><formula xml:id="formula_27">f 24 (x) = -cos x 1 cos x 2 e ((-(x1-π) 2 -(x2-π) 2</formula><p>))</p><p>[-10, 10]</p><formula xml:id="formula_28">-1 2 U N 1 .0E -13</formula><p>Dekkers and Aarts</p><formula xml:id="formula_29">f 25 (x) = 10 5 x 2 1 + x 2 2 -(x 2 1 + x 2 2 ) 2 + 10 -5 (x 2 1 + x 2 2 ) 4 [<label>-20, 20]</label></formula><p>-24777</p><formula xml:id="formula_30">2 MN 5.0E -01 Shubert f 26 (x) = -5 i=1 i cos((i + 1)x 1 + 1) 5 i=1 i cos((i + 1)x 2<label>+ 1) [-10, 10]</label></formula><p>-186.7309</p><formula xml:id="formula_31">2 MN 1.0E -05 D Dimensions, C Characteristic, U Unimodal, M Multimodal, S Separable, N Non-Separable, AE Acceptable Error</formula><p>to the swarm size. The optimum value of swarm size around 40 can be observed from the Fig. <ref type="figure">6e</ref>, f. To prove the efficiency of SMO algorithm, it is compared with four state-of-art algorithms, namely PSO <ref type="bibr" target="#b3">[4]</ref> (based on Standard PSO 2006 but with linearly decreasing inertia weight, modified velocity update equation and a different parameters setting), ABC <ref type="bibr" target="#b13">[14]</ref>, DE (DE/rand/bin/1) <ref type="bibr" target="#b34">[35]</ref> and Covariance Matrix Adaptation Evolution Strategies (CMA-ES) <ref type="bibr" target="#b10">[11]</ref>. For the comparison, same stopping criteria, number of simulations and maximum number of function evaluations are used for all the considered algorithms. The values of parameters for the considered algorithms are as follows:</p><p>SMO parameters setting:</p><p>-The Swarm size N = 50, -MG = 5, -Global Leader Limit = 50, -Local Leader Limit = 1500, -pr ∈ [0.1, 0.4], linearly increasing over iterations,</p><formula xml:id="formula_32">pr G+1 = pr G + (0.4 -0.1)/M I R; pr 1 = 0.1. (6)</formula><p>where, G is the iteration counter, M I R is the maximum number of iterations. -The stopping criteria is either maximum number of function evaluations (which is set to be 2.0×10 5 ) is reached or the corresponding acceptable error (mentioned in Table <ref type="table" target="#tab_2">1</ref>) have been achieved, -The number of simulations (or run) =100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABC parameters setting:</head><p>-Colony size S N = 100, -Number of food sources S N/2, -limit = 1500 <ref type="bibr" target="#b13">[14]</ref>,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DE parameters setting:</head><p>-The crossover probability C R = 0.9 <ref type="bibr" target="#b7">[8]</ref>, -The scale factor which controls the implication of the differential variation F = 0.5 <ref type="bibr" target="#b26">[27]</ref>, -Population size N P = 50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PSO parameters setting:</head><p>-Inertia Weight (w), decreases linearly from 1 to 0.1, -Acceleration coefficients (c 1 = 2, c 2 = 2), -Swarm size S = 50. <ref type="bibr" target="#b9">[10]</ref>: All parameter settings for CMA-ES is kept same as in <ref type="bibr" target="#b9">[10]</ref>. The results of CMA-ES are obtained by the source code provided at its developer's webpage, http://www.bionik.tuberlin.de/user/niko/index.html.  Table <ref type="table" target="#tab_5">2</ref> shows that most of the time SMO outperforms in terms of reliability, efficiency and accuracy. Some more intensive statistical analyses based on boxplots, the Mann-Whitney U rank sum test, performance indices <ref type="bibr" target="#b5">[6]</ref>, and acceleration rate (AR) <ref type="bibr" target="#b28">[29]</ref>  Table <ref type="table" target="#tab_8">3</ref> shows the results of the Mann-Whitney U rank sum test for the average function evaluations of 100 simulations. First we observe the significant difference by Mann-Whitney U rank sum test i.e., whether the two data sets are significantly different or not. If significant difference is not seen (i.e., the null hypothesis is accepted) then sign '=' appears and when significant difference is observed i.e., the null hypothesis is rejected then compare the average number of function evaluations. And we use signs '+' and '-' for the case where SMO takes less or more average number of function evaluations than the other algorithms, respectively. Therefore in Table <ref type="table" target="#tab_8">3</ref>, '+' shows that SMO is significantly better and '-' shows that SMO is worse. As Table <ref type="table" target="#tab_8">3</ref> includes 79 '+' signs out of 104 comparisons. Therefore, it can be concluded that the results of SMO is significantly cost effec-tive than DE, PSO, ABC and CMA-ES over considered test problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CMA-ES parameters setting</head><p>Further, to compare the considered algorithms, by giving weighted importance to SR, AFE and SD, performance indices (P I s) are calculated <ref type="bibr" target="#b5">[6]</ref>. The values of P I for the DE, PSO, ABC and CMA-ES are calculated by using following equations:</p><formula xml:id="formula_34">P I = 1 N p N p i=1 (k 1 α i 1 + k 2 α i 2 + k 3 α i 3 )</formula><p>Where    -Ao i = Standard deviation obtained by an algorithm for the ith problem. -N p = Total number of optimization problems evaluated.</p><formula xml:id="formula_35">α i 1 = Sr i T r i ; α i 2 = M f i A f i , if Sr i &gt; 0. 0, if Sr i = 0. ; and α i 3 = Mo i Ao i i = 1,<label>2</label></formula><p>The weights assigned to SR, AFE and SD are represented by k 1 , k 2 and k 3 respectively, where k 1 + k 2 + k 3 = 1 and 0 ≤ k 1 , k 2 , k 3 ≤ 1. To calculate the P I s, equal weights are assigned to two variables while weight of the remaining variable vary from 0 to 1 as given in <ref type="bibr" target="#b5">[6]</ref>. Following are the resultant cases:</p><formula xml:id="formula_37">1. k 1 = W, k 2 = k 3 = 1-W 2 , 0 ≤ W ≤ 1; 2. k 2 = W, k 1 = k 3 = 1-W 2 , 0 ≤ W ≤ 1; 3. k 3 = W, k 1 = k 2 = 1-W 2 , 0 ≤ W ≤ 1</formula><p>The graphs corresponding to each of the cases (1), ( <ref type="formula" target="#formula_35">2</ref>) and (3) for the considered algorithms are shown in Fig. <ref type="figure" target="#fig_6">8a-c</ref> respectively. In these figures the weights k 1 , k 2 and k 3 are represented by horizontal axis while the P I is represented by the vertical axis.</p><p>In case <ref type="bibr" target="#b0">(1)</ref>, AFE and SD are given equal weights. P I s of the considered algorithms are superimposed in Fig. <ref type="figure" target="#fig_6">8a</ref> for comparison of the performance. It is observed that P I of SMO is higher than the considered algorithms. In case (2), equal weights are assigned to SR and AFE and in case (3), equal weights are assigned to SR and AFE. It is clear from Fig. <ref type="figure" target="#fig_6">8b</ref>, c that the algorithms perform same as in case <ref type="bibr" target="#b0">(1)</ref>.</p><p>Further, we compare the convergence speed of the considered algorithms by measuring the AFEs. A smaller AFEs means higher convergence speed. In order to minimize the effect of the stochastic nature of the algorithms, the reported function evaluations for each test problem is averaged over 100 runs. In order to compare convergence speeds, we use the acceleration rate (AR) which is defined as follows, based on the AFEs for the two algorithms ALGO and SMO:</p><formula xml:id="formula_38">AR = AFE ALGO AFE SMO ,<label>(7)</label></formula><p>where, ALGO∈ {DE, PSO, ABC, CMA-ES} and AR &gt; 1 means SMO is faster. In order to investigate the AR of the proposed algorithm as compared to the considered algorithms, results of Table <ref type="table" target="#tab_5">2</ref> are analyzed and the value of AR is calculated using equation <ref type="bibr" target="#b6">(7)</ref>. Table <ref type="table" target="#tab_9">4</ref> shows a comparison between SMO and DE, SMO and PSO, SMO and ABC, and SMO and CMA-ES in terms of AR. It is clear from the Table <ref type="table" target="#tab_9">4</ref> that convergence speed of SMO is better than considered algorithms for most of the functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, a new swarm intelligence algorithm for optimization is proposed. The inspiration is from the social behavior of spider monkeys. The proposed algorithm is proved to be very flexible in the category of swarm intelligence based algorithms. With the help of numerical experiments over test problems, it has been shown that, for most of the problems the reliability (due to success rate), efficiency (due to average number of function evaluations) and accuracy (due to mean objective function value) of SMO is competitive or similar to those of DE, PSO, ABC and CMA-ES. Hence, it may be concluded that SMO is going to be a competing candidate in the field of swarm intelligence based optimization algorithms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Social Organization and Behavior a Spider-Monkey, b Spider Monkey Group, c Spider Monkey sub-group, d foods foraging<ref type="bibr" target="#b30">[31]</ref> </figDesc><graphic coords="3,53.65,56.33,487.69,83.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>3. Select global leader and local leaders by applying greedy selection (see section 3.1.4, 3.1.5). while (Termination criteria is not satisfied) do (i) For finding the objective (Food Source), generate the new positions for all the group members by using self experience, local leader experience and group members experience.[Refer Algorithm 1]. (ii) Apply the greedy selection process between existing position and newly generated position, based on fitness and select the better one; (iii) Calculate the probability prob i for all the group members using equation (4). (iv) Produce new positions for the all the group members, selected by prob i , by using self experience, global leader experience and group members experiences. [Refer Algorithm 2]. (v) Update the position of local and global leaders, by applying the greedy selection process on all the groups (see section 3.1.4, 3.1.5).(vi) If any Local group leader is not updating her position after a specified number of times (LocalLeaderLimit) then re-direct all members of that particular group for foraging by algorithm (3) (vii) If Global Leader is not updating her position for a specified number of times (GlobalLeaderLimit) then she divides the group into smaller groups by algorithm (4). end while3.2 Control parameters in SM OIt is clear from the above discussion that there are four control parameters in SM O algorithm: the value of Local Leader Limit, Global Leader Limit, the maximum group MG and perturbation rate pr . Some settings of control parameters are suggested as follows:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 Fig. 3</head><label>23</label><figDesc>Fig. 2 SMO topology: single group</figDesc><graphic coords="6,325.69,71.54,198.76,198.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>-</head><label></label><figDesc>, ..., N p Sr i = Successful simulations/runs of ith problem. -T r i = Total simulations of ith problem. -M f i = Minimum of average number of function evaluations used for obtaining the required solution of ith problem. -A f i = Average number of function evaluations used for obtaining the required solution of ith problem. -Mo i = Minimum of standard deviation obtained for the ith problem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8</head><label>8</label><figDesc>Fig.<ref type="bibr" target="#b7">8</ref> Performance index for test problems; a for case<ref type="bibr" target="#b0">(1)</ref>, b for case<ref type="bibr" target="#b1">(2)</ref> and c for case<ref type="bibr" target="#b2">(3)</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="7,70.57,56.60,198.28,258.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Benchmark functions used in Test Problem</figDesc><table><row><cell>Objective function</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 .</head><label>2</label><figDesc>Effect of parameters on success rate for functions f 9 , f 12 , f 14 , f 18 , f 25 and f 26 a when pr is varied, b when MG is varied, c when Global Leader Limit is varied, d when Local Leader Limit is varied, In Table 2, standard deviation (SD), mean error (ME), average number of function evaluations (AFE), and success rate (SR) are reported for test problems f 1 to f 26 .</figDesc><table><row><cell>e Swarm Size v/s Successful Runs, f Swarm Size v/s Average number</cell></row><row><cell>of function evaluations</cell></row></table><note><p>Fig. 6 AF E = 100 i=1 # of function evaluations to meet the termination criteria for run i 100</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2</head><label>2</label><figDesc>Experimental results</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Table 2 continued</cell><cell></cell><cell></cell></row><row><cell>Test</cell><cell cols="2">Algorithm SD</cell><cell>ME</cell><cell>AF E</cell><cell>SR</cell><cell>Test</cell><cell cols="2">Algorithm SD</cell><cell>ME</cell><cell>AF E</cell><cell>SR</cell></row><row><cell>Function</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Function</cell><cell></cell><cell></cell><cell></cell></row><row><cell>f 1</cell><cell>DE</cell><cell cols="3">1.42E-04 8.68E-04 27378</cell><cell>100</cell><cell></cell><cell>ABC</cell><cell cols="2">2.79E-04 4.77E-04</cell><cell>1480</cell><cell>100</cell></row><row><cell></cell><cell>PSO</cell><cell cols="4">6.72E-05 9.34E-04 45914.5 100</cell><cell></cell><cell cols="3">CMA-ES 1.40E-07 3.98E-04</cell><cell>594</cell><cell>100</cell></row><row><cell></cell><cell>ABC</cell><cell cols="3">2.02E-04 7.57E-04 35901</cell><cell>100</cell><cell></cell><cell>SMO</cell><cell cols="2">2.91E-04 4.25E-04</cell><cell>673.2 100</cell></row><row><cell></cell><cell cols="4">CMA-ES 2.90E-04 7.10E-04 21248</cell><cell>100</cell><cell>f 11</cell><cell>DE</cell><cell cols="2">1.20E-04 4.78E-04</cell><cell>1608</cell><cell>100</cell></row><row><cell></cell><cell>SMO</cell><cell cols="4">8.38E-05 8.88E-04 15128.19 100</cell><cell></cell><cell>PSO</cell><cell cols="2">2.70E-04 4.83E-04</cell><cell>1900.5 100</cell></row><row><cell>f 2</cell><cell>DE</cell><cell cols="3">3.54E-01 1.00E-01 25858</cell><cell>95</cell><cell></cell><cell>ABC</cell><cell cols="2">3.08E-04 4.88E-04</cell><cell>2925.11 100</cell></row><row><cell></cell><cell>PSO</cell><cell cols="4">2.36E-04 2.53E-04 38273.5 100</cell><cell></cell><cell cols="3">CMA-ES 2.51E-01 1.43E-02</cell><cell>2052</cell><cell>78</cell></row><row><cell></cell><cell>ABC</cell><cell cols="3">5.92E-04 6.35E-04 20244</cell><cell>100</cell><cell></cell><cell>SMO</cell><cell cols="2">2.96E-04 4.85E-04</cell><cell>866.25 100</cell></row><row><cell></cell><cell cols="3">CMA-ES 1.77E+00 1.44E+00</cell><cell>72184</cell><cell>36</cell><cell>f 12</cell><cell>DE</cell><cell cols="2">1.04E-04 5.01E-04</cell><cell>1334</cell><cell>100</cell></row><row><cell></cell><cell>SMO</cell><cell cols="4">1.20E-05 2.34E-04 12018.41 100</cell><cell></cell><cell>PSO</cell><cell cols="2">2.46E-04 5.77E-04</cell><cell>1080.5 100</cell></row><row><cell>f 3</cell><cell>DE</cell><cell cols="3">6.12E+02 2.24E+03 200000</cell><cell>0</cell><cell></cell><cell>ABC</cell><cell cols="2">2.64E-04 5.48E-04</cell><cell>1415</cell><cell>100</cell></row><row><cell></cell><cell>PSO</cell><cell cols="3">6.70E+02 2.80E+03 200000</cell><cell>0</cell><cell></cell><cell cols="3">CMA-ES 4.80E-08 9.25E-04</cell><cell>996</cell><cell>100</cell></row><row><cell></cell><cell>ABC</cell><cell cols="3">1.18E+01 1.19E+00 170335</cell><cell>76</cell><cell></cell><cell>SMO</cell><cell cols="2">2.66E-04 5.15E-04</cell><cell>598.95 100</cell></row><row><cell></cell><cell cols="4">CMA-ES 8.96E+02 7.64E+03 200000</cell><cell>0</cell><cell>f 13</cell><cell>DE</cell><cell cols="3">5.22E-02 8.84E-02 149112</cell><cell>26</cell></row><row><cell></cell><cell>SMO</cell><cell cols="4">1.11E+02 7.67E+01 180525.04 65</cell><cell></cell><cell>PSO</cell><cell cols="3">5.63E-02 4.29E-02 76074</cell><cell>64</cell></row><row><cell>f 4</cell><cell>DE</cell><cell cols="3">4.93E+00 1.54E+01 200000</cell><cell>0</cell><cell></cell><cell>ABC</cell><cell cols="2">2.33E-04 6.81E-04</cell><cell>4652</cell><cell>100</cell></row><row><cell></cell><cell>PSO</cell><cell cols="3">1.35E+01 3.80E+01 200000</cell><cell>0</cell><cell></cell><cell cols="4">CMA-ES 5.80E-02 3.80E-03 22330</cell><cell>48</cell></row><row><cell></cell><cell>ABC</cell><cell cols="3">3.14E-04 4.72E-04 87039</cell><cell>100</cell><cell></cell><cell>SMO</cell><cell cols="3">1.18E-02 1.86E-03 27278.86 99</cell></row><row><cell></cell><cell cols="4">CMA-ES 1.36E+01 5.18E+01 200000</cell><cell>0</cell><cell>f 14</cell><cell>DE</cell><cell cols="2">1.05E+00 1.50E-01</cell><cell>7962</cell><cell>98</cell></row><row><cell></cell><cell>SMO</cell><cell cols="4">2.33E-04 3.39E-04 83158.66 100</cell><cell></cell><cell>PSO</cell><cell cols="3">1.36E+00 2.75E-01 16708.5</cell><cell>96</cell></row><row><cell>f 5</cell><cell>DE</cell><cell cols="3">1.45E-02 2.90E-03 24490.5</cell><cell>98</cell><cell></cell><cell>ABC</cell><cell cols="2">2.56E-04 5.74E-04</cell><cell>6656</cell><cell>100</cell></row><row><cell></cell><cell>PSO</cell><cell cols="3">1.44E-02 2.98E-03 52777.5</cell><cell>98</cell><cell></cell><cell cols="4">CMA-ES 2.58E-02 3.18E-02 42561</cell><cell>40</cell></row><row><cell></cell><cell>ABC</cell><cell cols="3">2.19E-04 7.48E-04 29301</cell><cell>100</cell><cell></cell><cell>SMO</cell><cell cols="3">2.58E-04 6.40E-04 17592.18 100</cell></row><row><cell></cell><cell cols="4">CMA-ES 3.40E-02 7.20E-04 23254</cell><cell>88</cell><cell>f 15</cell><cell>DE</cell><cell cols="2">1.65E-04 5.63E-04</cell><cell>3659.5 100</cell></row><row><cell></cell><cell>SMO</cell><cell cols="3">1.61E-04 6.52E-04 16176</cell><cell>100</cell><cell></cell><cell>PSO</cell><cell cols="2">2.35E-04 6.89E-04</cell><cell>5435</cell><cell>100</cell></row><row><cell>f 6</cell><cell>DE</cell><cell cols="3">1.78E-03 1.15E-03 26753</cell><cell>97</cell><cell></cell><cell>ABC</cell><cell cols="2">2.93E-04 5.90E-04</cell><cell>8222.32 100</cell></row><row><cell></cell><cell>PSO</cell><cell cols="3">2.58E-03 1.62E-03 51446</cell><cell>93</cell><cell></cell><cell cols="4">CMA-ES 1.74E-01 1.25E-02 35632</cell><cell>48</cell></row><row><cell></cell><cell>ABC</cell><cell cols="3">1.96E-04 7.89E-04 32604</cell><cell>100</cell><cell></cell><cell>SMO</cell><cell cols="2">2.57E-04 6.62E-04</cell><cell>9519.46 100</cell></row><row><cell></cell><cell cols="4">CMA-ES 4.50E-03 1.70E-03 13756</cell><cell>86</cell><cell>f 16</cell><cell>DE</cell><cell cols="2">6.67E-01 6.76E-02</cell><cell>5620</cell><cell>99</cell></row><row><cell></cell><cell>SMO</cell><cell cols="4">1.43E-04 1.07E-04 23728.83 100</cell><cell></cell><cell>PSO</cell><cell cols="2">2.56E-04 6.57E-04</cell><cell>5463.5 100</cell></row><row><cell>f 7</cell><cell>DE</cell><cell cols="2">7.15E -05 2.39E-04</cell><cell cols="2">2632.5 100</cell><cell></cell><cell>ABC</cell><cell cols="2">2.82E-04 5.75E-04</cell><cell>9584.35 100</cell></row><row><cell></cell><cell>PSO</cell><cell cols="2">3.09E-04 3.06E-04</cell><cell>3778</cell><cell>100</cell><cell></cell><cell cols="4">CMA-ES 2.54E-02 2.15E-03 11234</cell><cell>52</cell></row><row><cell></cell><cell>ABC</cell><cell cols="2">2.79E-04 1.93E-04</cell><cell>1306</cell><cell>100</cell><cell></cell><cell>SMO</cell><cell cols="2">2.48E-04 6.53E-04</cell><cell>7605.82 100</cell></row><row><cell></cell><cell cols="4">CMA-ES 6.87E+00 1.04E+01 200000</cell><cell>0</cell><cell>f 17</cell><cell>DE</cell><cell cols="3">1.34E-06 8.63E-06 40678</cell><cell>100</cell></row><row><cell></cell><cell>SMO</cell><cell cols="2">2.68E-04 2.02E-04</cell><cell cols="2">919.71 100</cell><cell></cell><cell>PSO</cell><cell cols="3">5.46E-07 9.38E-06 69416.5 100</cell></row><row><cell>f 8</cell><cell>DE</cell><cell cols="2">2.14E-04 8.32E-04</cell><cell>8170</cell><cell>97</cell><cell></cell><cell>ABC</cell><cell cols="3">1.82E-06 8.25E-06 63993</cell><cell>100</cell></row><row><cell></cell><cell>PSO</cell><cell cols="2">1.33E-04 8.39E-04</cell><cell>1957</cell><cell>100</cell><cell></cell><cell cols="4">CMA-ES 6.61E-06 2.51E-05 10318</cell><cell>100</cell></row><row><cell></cell><cell>ABC</cell><cell cols="2">1.34E-04 8.43E-04</cell><cell cols="2">7525.37 100</cell><cell></cell><cell>SMO</cell><cell cols="3">9.45E-07 8.94E-06 22477.95 100</cell></row><row><cell></cell><cell cols="4">CMA-ES 4.20E-03 1.50E-03 13434</cell><cell>88</cell><cell>f 18</cell><cell>DE</cell><cell cols="3">1.31E-06 8.60E-06 26463.5 100</cell></row><row><cell></cell><cell>SMO</cell><cell cols="2">1.38E-04 8.51E-04</cell><cell cols="2">2214.37 100</cell><cell></cell><cell>PSO</cell><cell cols="3">6.13E-07 9.37E-06 44129.5 100</cell></row><row><cell>f 9</cell><cell>DE</cell><cell cols="2">1.01E-04 4.44E-04</cell><cell cols="2">1686.5 100</cell><cell></cell><cell>ABC</cell><cell cols="3">2.00E-06 8.18E-06 41861</cell><cell>100</cell></row><row><cell></cell><cell>PSO</cell><cell cols="2">3.05E-04 4.80E-04</cell><cell>1318</cell><cell>100</cell><cell></cell><cell cols="4">CMA-ES 1.06E-06 7.03E-06 16463</cell><cell>100</cell></row><row><cell></cell><cell>ABC</cell><cell cols="2">3.11E-04 5.08E-04</cell><cell>899</cell><cell>100</cell><cell></cell><cell>SMO</cell><cell cols="3">7.62E-07 8.96E-06 14679.72 100</cell></row><row><cell></cell><cell cols="3">CMA-ES 5.20E-11 6.03E-04</cell><cell>619</cell><cell>100</cell><cell>f 19</cell><cell>DE</cell><cell cols="2">1.13E-06 4.72E-06</cell><cell>1849</cell><cell>100</cell></row><row><cell></cell><cell>SMO</cell><cell cols="2">2.99E-04 4.02E-04</cell><cell cols="2">529.65 100</cell><cell></cell><cell>PSO</cell><cell cols="2">2.67E-06 4.22E-06</cell><cell>2762</cell><cell>100</cell></row><row><cell>f 10</cell><cell>DE</cell><cell cols="2">1.32E-04 4.89E-04</cell><cell>2081</cell><cell>100</cell><cell></cell><cell>ABC</cell><cell cols="3">2.42E-06 7.81E-06 31948.76 100</cell></row><row><cell></cell><cell>PSO</cell><cell cols="2">2.82E-04 4.81E-04</cell><cell cols="2">1445.5 100</cell><cell></cell><cell cols="3">CMA-ES 1.01E-06 1.17E-06</cell><cell>1247.16 100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>have been carried out for the results of DE, PSO, ABC, CMA-ES and SMO.5.3 Statistical analysisDE, PSO, ABC, CMA-ES and SMO are compared based on SR, AFE, and ME. First SR of all these algorithms is com-pared and if it is not possible to distinguish the performance of algorithms based on SR then comparison is made on the basis of AFE. ME is used for comparison if the comparison is not possible on the basis of SR and AFE both. From the results shown in Table2, it is clear that SMO costs less on 14 function( f 1 , f 2 , f 4 , f 5 , f 6 , f 7 , f 9 , f 11 , f 12 , f 18 , f 20 , f 23 , f 25 , f 26 )among all the considered algorithms. As these functions include unimodel, multimodel, separable, non separable, lower and higher dimension functions, it can be stated that SMO balances the exploration and exploitation capabilities efficiently. ABC outperforms SMO over five test functions ( f 3 , f 13 , f 14 , f 15 , f 21 , f 22 ) and four are multimodel functions. It shows that ABC perform better on multimodel functions as the solution search equation of ABC is significantly influenced by a random quantity which helps in exploration at the cost of exploitation of the search space<ref type="bibr" target="#b31">[32]</ref>. CMA-ES outperforms over SMO on six test functions ( f 10 , f 17 , f 19 , f 21 , f 22 , f 24 ) among these four test functions are unimodel functions. Generally speaking, the cost of CMA-ES is lower than those of SMO, ABC, DE and PSO for the unimodal functions. This is because CMA-ES is a local method devised for optimal exploitation of local information<ref type="bibr" target="#b20">[21]</ref>. DE outperform over only two test functions</figDesc><table><row><cell>(a)</cell><cell>(b)</cell></row><row><cell>(c)</cell><cell></cell></row><row><cell>average number of function evaluations used by the con-</cell><cell></cell></row><row><cell>sidered algorithms to solve the different problems are not</cell><cell></cell></row><row><cell>normally distributed, so a non-parametric statistical test is</cell><cell></cell></row><row><cell>required to compare the performance of the algorithms. The</cell><cell></cell></row><row><cell>Mann-Whitney U rank sum [19], a non-parametric test, is</cell><cell></cell></row><row><cell>well established test for comparison among non-Gaussian</cell><cell></cell></row><row><cell>data. In this paper, this test is performed at 5% level of sig-</cell><cell></cell></row><row><cell>nificance (α = 0.05) between SMO-DE, SMO-PSO, SMO-</cell><cell></cell></row><row><cell>ABC, and SMO-CMA-ES.</cell><cell></cell></row></table><note><p>Fig. 7 Boxplots graph for a average number of function evaluation, b standard deviation, and c success rate</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3</head><label>3</label><figDesc>Comparison based on mean function evaluations and the Mann-Whitney U rank sum test at a α = 0.05 significance level ('+' indicates SMO is significantly better, '-' indicates SMO is significantly worst and '=' indicates that there is no significant difference), TP: Test Problem</figDesc><table><row><cell>TP</cell><cell cols="3">Mann-Whitney U rank sum test with SMO</cell><cell></cell><cell>TP</cell><cell cols="3">Mann-Whitney U rank sum test with SMO</cell><cell></cell></row><row><cell></cell><cell>DE</cell><cell>PSO</cell><cell>ABC</cell><cell>CMA-ES</cell><cell></cell><cell>DE</cell><cell>PSO</cell><cell>ABC</cell><cell>CMA-ES</cell></row><row><cell>f 1</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>f 14</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>+</cell></row><row><cell>f 2</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>f 15</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>+</cell></row><row><cell>f 3</cell><cell>+</cell><cell>+</cell><cell>-</cell><cell>+</cell><cell>f 16</cell><cell>-</cell><cell>-</cell><cell>+</cell><cell>+</cell></row><row><cell>f 4</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>f 17</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>-</cell></row><row><cell>f 5</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>f 18</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell></row><row><cell>f 6</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>-</cell><cell>f 19</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>-</cell></row><row><cell>f 7</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>f 20</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell></row><row><cell>f 8</cell><cell>+</cell><cell>-</cell><cell>+</cell><cell>+</cell><cell>f 21</cell><cell>=</cell><cell>=</cell><cell>=</cell><cell>=</cell></row><row><cell>f 9</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>f 22</cell><cell>+</cell><cell>+</cell><cell>-</cell><cell>-</cell></row><row><cell>f 10</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>-</cell><cell>f 23</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell></row><row><cell>f 11</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>f 24</cell><cell>-</cell><cell>-</cell><cell>+</cell><cell>-</cell></row><row><cell>f 12</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>f 25</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell></row><row><cell>f 13</cell><cell>+</cell><cell>+</cell><cell>-</cell><cell>-</cell><cell>f 26</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4</head><label>4</label><figDesc>Acceleration rate (AR) of SMO as compared to the DE, PSO, ABC and CMA-ES</figDesc><table><row><cell>TP</cell><cell>DE</cell><cell>PSO</cell><cell>ABC</cell><cell>CMA-ES</cell></row><row><cell>f 1</cell><cell cols="4">1.809734013 3.035029306 2.373119322 1.404530218</cell></row><row><cell>f 2</cell><cell cols="4">2.151532524 3.184572668 1.684415825 6.006118946</cell></row><row><cell>f 3</cell><cell>1.10787955</cell><cell>1.10787955</cell><cell cols="2">0.943553315 1.10787955</cell></row><row><cell>f 4</cell><cell cols="4">2.405041159 2.405041159 1.046661887 2.405041159</cell></row><row><cell>f 5</cell><cell cols="3">1.514002226 3.262704006 1.81138724</cell><cell>1.43756182</cell></row><row><cell>f 6</cell><cell cols="4">1.127447076 2.168079926 1.374024762 0.579716741</cell></row><row><cell>f 7</cell><cell cols="3">2.862315295 4.107816594 1.42001283</cell><cell>217.4598515</cell></row><row><cell>f 8</cell><cell cols="4">3.689536979 0.883772811 3.398424834 6.066736815</cell></row><row><cell>f 9</cell><cell cols="4">3.184178231 2.488435759 1.697347305 1.168696309</cell></row><row><cell>f 10</cell><cell cols="3">3.091206179 2.147207368 2.19845514</cell><cell>0.882352941</cell></row><row><cell>f 11</cell><cell cols="4">1.856277056 2.193939394 3.376750361 2.368831169</cell></row><row><cell>f 12</cell><cell cols="4">2.227230988 1.803990316 2.362467652 1.662910093</cell></row><row><cell>f 13</cell><cell cols="4">5.466210831 2.788752902 0.170534986 0.818582595</cell></row><row><cell>f 14</cell><cell cols="2">0.452587456 0.94976859</cell><cell cols="2">0.378349926 2.419313581</cell></row><row><cell>f 15</cell><cell cols="4">0.384423066 0.570935746 0.863738069 3.74306946</cell></row><row><cell>f 16</cell><cell cols="4">0.738907836 0.718331488 1.260133687 1.477026803</cell></row><row><cell>f 17</cell><cell cols="4">1.809684602 3.088204218 2.846923318 0.459027625</cell></row><row><cell>f 18</cell><cell>1.80272512</cell><cell cols="3">3.006154068 2.851621148 1.121479156</cell></row><row><cell>f 19</cell><cell cols="4">1.178344964 1.760188637 20.36055189 0.794799732</cell></row><row><cell>f 20</cell><cell cols="4">1.831931263 2.687923207 2.901115892 2.340542043</cell></row><row><cell>f 21</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>f 22</cell><cell cols="4">1.265507786 1.518209872 0.776847816 0.731019331</cell></row><row><cell>f 23</cell><cell>1.75965528</cell><cell cols="3">2.722068408 3.574110276 1.914682244</cell></row><row><cell>f 24</cell><cell cols="4">0.441903288 0.829353235 10.93521325 0.815273399</cell></row><row><cell>f 25</cell><cell cols="4">2.166034857 3.956957458 2.040070254 1.371305502</cell></row><row><cell>f 26</cell><cell cols="4">2.206285276 16.49690851 1.883336073 3.256342813</cell></row><row><cell cols="2">TP test problems</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>( f 15 , f 24 ) in which f 15 is unimodel and f 24 is multimodel. Further, PSO performs better than SMO over five test function ( f 8 , f 15 , f 16 , f 21 , f 24 ) which all are non separable functions as well as four are multimodel functions. Overall, SMO is better than DE over 24 test functions, PSO over 21 test functions, ABC over 20 test functions, and CMA-ES over 20 test functions of mixed characteristics, when compared separately. It means that when the results of all functions are evaluated together, the SMO algorithm is the cost effective algorithm for most of the functions.For the purpose of comparison in terms of consolidated performance, boxplot analyses have been carried out for all the considered algorithms. The empirical distribution of data is efficiently represented graphically by the boxplot analysis tool<ref type="bibr" target="#b40">[41]</ref>. The boxplots of average number of function evaluations for DE, PSO, ABC, CMA-ES and SMO are shown in Fig.7. It is clear from Fig.7athat SMO is cost effective in terms of function evaluations as interquartile range and median of average number of function evaluations are low for SMO. When the considered algorithms are compared on the basis of standard deviation and success rate, it can be observed from Fig.7b, cthat ABC and SMO have equal performance, while they perform better than DE, PSO and CMA-ES.Though, it is clear from box plots that SMO is cost effective than DE, PSO, ABC, and CMA-ES i.e., SMO's result differs from the other, now to check, whether there exists any significant difference between algorithm's output or this difference is due to some randomness, we require another statistical test. It can be observed from boxplots Fig.7a that</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors acknowledge the anonymous reviewers for their valuable comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A numerical evaluation of several stochastic algorithms on selected continuous global optimization test problems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Khompatraporn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Zabinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="635" to="672" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Evolutionary optimization versus particle swarm optimization: philosophy and performance differences</title>
		<author>
			<persName><forename type="first">P</forename><surname>Angeline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary programming VII</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Swarm intelligence: from natural to artificial systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bonabeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Theraulaz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A method to improve standard PSO</title>
		<author>
			<persName><forename type="first">M</forename><surname>Clerc</surname></persName>
		</author>
		<ptr target="http://clerc.maurice.free.fr/pso/Design_efficient_PSO.pdf" />
		<imprint>
			<date type="published" when="2012-01">2012. Jan 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Artificial immune systems: Part I-basic theory and applications</title>
		<author>
			<persName><forename type="first">De</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Von Zuben FJ</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>Universidade Estadual de Campinas, Dezembro de</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A new crossover operator for real coded genetic algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deep</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl Math Comput</title>
		<imprint>
			<biblScope unit="volume">188</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">895911</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Ant colony optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stützle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A parameter study for differential evolution</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gamperle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Koumoutsakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv Intell Syst Fuzzy Syst Evol Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="293" to="298" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Genetic algorithms in search, optimization, and machine learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison-Wesley Professional</publisher>
			<pubPlace>Upper Saddle River</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The cma evolution strategy: a comparing review</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Towards a new evolutionary computation</title>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="75" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Adapting arbitrary normal mutation distributions in evolution strategies: the covariance matrix adaptation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ostermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE international conference on evolutionary computation</title>
		<meeting>IEEE international conference on evolutionary computation</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="312" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Balancing exploration and exploitation in learning to rank online</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Whiteson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv Inform Retr</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="251" to="263" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The evolution of the organization of work in social insects</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Jeanne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Monitore Zoologico Italiano</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="133" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">An idea based on honey bee swarm for numerical optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Erciyes University Press</publisher>
			<pubPlace>Erciyes</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Techn. Rep. TR06</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A comparative study of artificial bee colony algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Akay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl Math Comput</title>
		<imprint>
			<biblScope unit="volume">214</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="132" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A modified artificial bee colony (ABC) algorithm for constrained optimization problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Akay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl Soft Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="3021" to="3031" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on neural networks</title>
		<meeting>the IEEE international conference on neural networks</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995">1995. 1995</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On stagnation of the differential evolution algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Zelinka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MENDEL, Citeseer</title>
		<meeting>MENDEL, Citeseer</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="76" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On a test of whether one of two random variables is stochastically larger than the other</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Whitney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals Math Stat</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="60" />
			<date type="published" when="1947">1947</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A comparative study of differential evolution variants for global optimization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mezura-Montes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Velázquez-Reyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th annual conference on Genetic and evolutionary computation</title>
		<meeting>the 8th annual conference on Genetic and evolutionary computation<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="485" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Self-organizing nets for optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Milano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koumoutsakos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Netw</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="758" to="765" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Diet and social organization of a free-ranging spider monkey population: the development of species-typical behavior in the absence of adults</title>
		<author>
			<persName><forename type="first">K</forename><surname>Milton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Juvenile primates: life history, development, and behavior</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="173" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Challenge of neotropical frugivory: travel patterns of spider monkeys and bearded sakis</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Norconk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Kinzey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am J Primatol</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="171" to="183" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Caste and ecology in the social insects</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Oster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">O</forename><surname>Wilson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>Princeton Univ ersity Press</publisher>
			<pubPlace>Princeton</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Biomimicry of bacterial foraging for distributed optimization and control</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Passino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Control Syst Mag</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="52" to="67" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Bacterial foraging optimization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Passino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Swarm Intell Res (IJSIR)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Differential evolution: a fast and simple numerical optimizer</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fuzzy information processing society, 1996. NAFIPS. 1996 Biennial conference of the North American</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="524" to="527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Differential evolution: a practical approach to global optimization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Lampinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Oppositionbased differential evolution</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rahnamayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Tizhoosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mma</forename><surname>Salama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Evol Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="79" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Patterns of association, feeding competition and vocal communication in spider monkeys</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ramos-Fernandez</surname></persName>
		</author>
		<ptr target="http://repository.upenn.edu/dissertations/AAI3003685" />
	</analytic>
	<monogr>
		<title level="m">Ateles geoffroyi. Dissertations, University of Pennsylvania</title>
		<imprint>
			<date type="published" when="2001-01-01">2001. 1 Jan 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Sartore</surname></persName>
		</author>
		<ptr target="http://animals.nationalgeographic.com/animals/mammals/spider-monkey" />
		<title level="m">Spider monkey images</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
	<note>Retrived on 21 Decmber</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Opposition based lévy flight artificial bee colony</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Arya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memet Comput</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="213" to="227" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Parameter selection in particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary programming VII</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="591" to="600" />
		</imprint>
	</monogr>
	<note>Heidelberg</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Diets of some french guianan primates: food composition and food choices</title>
		<author>
			<persName><forename type="first">B</forename><surname>Simmen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sabatier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Primatol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="661" to="693" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Differential evolution-a simple and efficient adaptive scheme for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Global Optim</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Problem definitions and evaluation criteria for the CEC 2005 special session on real-parameter optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deb</forename><forename type="middle">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">P</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">Kan-GAL Report</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fission-fusion social organization inateles andpan</title>
		<author>
			<persName><forename type="first">Mmf</forename><surname>Symington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Primatol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="61" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Instituto Nacional de Pesquisas da Amazônia. Habitat preferences, diet, feeding strategy and social organization of the black spider monkey (ateles paniscus paniscus linnaeus 1758) in surinam</title>
		<author>
			<persName><forename type="first">Mgm</forename><surname>Van Roosmalen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Roosmalen</publisher>
			<pubPlace>Wageningen</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A comparative study of differential evolution, particle swarm optimization, and evolutionary algorithms on numerical benchmark problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vesterstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Thomsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Congress on evolutionary computation</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004. 2004. 2004</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1980" to="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Evolutionary optimization: pitfalls and booby traps</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comput Sci Technol</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="907" to="936" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The box plot: a simple visual method to interpret data</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Kendrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals Intern Med</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">916</biblScope>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Gbest-guided artificial bee colony algorithm for numerical function optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl Math Computat</title>
		<imprint>
			<biblScope unit="volume">217</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3166" to="3173" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
