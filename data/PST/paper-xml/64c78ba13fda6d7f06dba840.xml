<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MELF: Multivariant Executables for a Heterogeneous World</title>
				<funder ref="#_tcweQXk">
					<orgName type="full">Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) -468988364</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dominik</forename><surname>T?llner</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Illia</forename><surname>Ostapyshyn</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Florian</forename><surname>Rommel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Lohmann</surname></persName>
						</author>
						<author>
							<persName><forename type="first">C</forename><surname>Melf</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Linker</forename><surname>Script</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Leibniz Universit?t Hannover Christian Dietrich Hamburg University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Leibniz Universit?t Hannover</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Leibniz Universit?t Hannover</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Leibniz Universit?t Hannover</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MELF: Multivariant Executables for a Heterogeneous World</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Compilers today provide a plethora of options to optimize and instrument the code for specific processor extensions, safety features and compatibility settings. Application programmers often provide further instrumented variants of their code for similar purposes, controlled again at compiletime by means of preprocessor macros and dead-code elimination. However, the global once-for-all character of compile-time decisions regarding performance-, debugging-, and safety/security-critical features limits their usefulness in heterogeneous execution settings, where available processor features or security requirements may evolve over time or even differ on a per-client level.</p><p>Our Multivariant ELF (MELF) approach makes it possible to provide multiple per-function compile-time variants within the same binary and flexibly switch between them at run-time, optionally on a per-thread granularity. As MELFs are implemented on binary level (linker, loader), they do not depend on specific language features or compilers and can be easily applied to existing projects. In our case studies with SQLite, memcached, MariaDB and a benchmark for heterogeneous architectures with overlapping ISAs, we show how MELFs can be employed to provide per-client performance isolation of expensive compile-time security or debugging features and adapt to extended instruction sets, when they are actually available. shared mapping decoupled mapping shared mapping 1. Multi-Variant Compilation main.c foo.c f, g, h main.o foo-A.o foo-B.o CC CC A</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Modern compilers provide a plethora of options to statically optimize and instrument the code. Natural examples for such at-compile-time tailoring include support for hardwarespecific processor extensions, but also compiler-specific debugging, program instrumentation, and sanitizing aid. These options commonly do not alter the semantics of the code, but influence its nonfunctional properties with respect to performance, safety, security, and compatibility. They are put under the control of the developer, because they reflect important tradeoffs: Exploiting special instruction-set extensions can greatly improve performance <ref type="bibr" target="#b0">[1]</ref>, but at the cost of losing compatibility to smaller or older processors. Letting the compiler instrument the code with extra sanity checks increases safety and security <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b5">[6]</ref>, but comes at a significant performance cost. This also holds for many higher-level instrumentations that are inserted manually by the developers, often by means of the preprocessor: Typical examples are executable asserts <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, tracing, and logging support, which have been shown to actively increase safety <ref type="bibr" target="#b8">[9]</ref> and security <ref type="bibr" target="#b9">[10]</ref>, but are commonly disabled at compile time in production builds due to their performance overhead.</p><p>However, in a world of increasing dynamic hardware and use-case heterogeneity, the global once-for-all character of compile-time decisions regarding performance-, debugging-, and safety/security-critical features limits their usefulness: In heterogeneous cloud environments or on machines with heterogeneous ISAs, the availability of processor features may change over time, even for individual threads. The performance costs of the extra sanity checks might be acceptable while processing input from external users, but not in general. In a DevOps setting, it would be useful to temporarily enable tracing and logging, but only for that specific client who is having troubles.</p><p>In short: It would be useful to decide at run time, depending on the dynamic context, on features that are technically bound at the compile time of the code. We call this flexibility semi-dynamic variability, which conceptually lays between static and dynamic variability in that the code of all variants is still generated at the compile-time of the project (thus, facilitating whole-program optimization), but the actually used variants can be decided on at run time.</p><p>While there are special-purpose solutions for semidynamic variability in some domains (e.g, math libraries <ref type="bibr" target="#b10">[11]</ref> or the Linux kernel <ref type="bibr" target="#b11">[12]</ref>) that adapt at load or initialization time to the actually available hardware features, these solutions are limited in scope, require manual intervention, and typically involve costly extra indirections via proxies <ref type="bibr" target="#b12">[13]</ref> or inherently fragile means of fine-grained run-time code patching <ref type="bibr" target="#b11">[12]</ref>; often they have to prevent inlining. In the linker, the matched input sections are aligned <ref type="bibr" target="#b2">(3)</ref> and the resulting output sections (4) are placed in the virtual-and load-address space. At run time <ref type="bibr" target="#b4">(5)</ref>, the variants are loaded into different MMViews, which share everything but the decoupled regions; common symbols and pointers are stable across views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>About this Paper</head><p>We present multivariant ELF (MELF) as an easy-to-apply approach for the inclusion of multiple compile-time variants within the same binary and flexible switching between them at run time on function/section granularity. MELFs are implemented solely on binary level, hence mostly independent of the employed languages and compilers (as long as they produce ELF-compatible objects), which also makes them easy to apply to existing software projects. Function variants are aligned by the MELF linker to the same virtual address, so that existing pointers or relocations remain valid even in case of a variant switch at run time. They can optionally be loaded by the MELF loader into additional in-process address spaces (with the MMViews kernel extension, taken from <ref type="bibr" target="#b13">[14]</ref>), where multiple variants can coexist at the same time to be applied on a per-thread level.</p><p>In particular, we claim the following contributions:</p><p>? We provide the MELF concept, as an end-to-end solution for semi-dynamic variability.</p><p>? We describe our MELF linker (an extension to LLVM's LLD linker) and the MELF loader.</p><p>? We demonstrate the MELF benefits and costs in four case studies from different domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The MELF Approach</head><p>The MELF approach (see Fig. <ref type="figure" target="#fig_0">1</ref>) provides semi-dynamic variability on function granularity for compiled functions by aligning functions (and data) with a modified LLD at link time. At run time, either one of variants is loaded into the process's address space or, with the help of the MMViews, multiple variants can coexist simultaneously. We describe our approach for executable and linking file format (ELF) and Linux processes, but are confident that our approach is generalizable to other binary formats (e.g., COFF, Mach-O) and process models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">System Model</head><p>We target programs written in compiled languages (e.g., C, C++, Rust, . . . ) that organize their binary code in regular, hierarchically-called functions (e.g., unlike Haskell, Forth). For a subset of all functions (i.e., not main()), it is intended to include multiple function variants in the final binary. For these functions, the signature (including the mangled symbol name) must be equal and their side effects on the program's object space must be compatible. The compiler must be able to put functions into their individual binary section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Compile-Time: Static Variant Generation</head><p>First (Fig. <ref type="figure" target="#fig_0">1</ref>, step 1), we have to statically generate multiple variants of our functions at compile time. These static variants can, for example, originate from translating the same translation unit multiple times with different compiler flags or CPP configurations. But also, manual variant encoding (e.g., directly in assembler) or programmatically in the compiler via guided-function specialization <ref type="bibr" target="#b14">[15]</ref> is possible. In Lst. 1, we show that this variant generation is simple with modern build systems, like CMake <ref type="bibr" target="#b15">[16]</ref>. In the example, which is taken from our SQLite3 case study (Sec. 3.1), we compile the SQLite source files twice into two static libraries. <ref type="foot" target="#foot_0">1</ref> Both libraries are compiled with different predefined CPP macros and linked into the main executable. Besides the multi-variant compilation, the ELF <ref type="bibr" target="#b16">[17]</ref> standard forces us to put each function and each data object into their own section. In order to understand this requirement, we now take a quick detour into the ELF standard, which is also necessary to understand the MELF linker.</p><p>Excursus: ELF Sections vs. Functions The executable and linking file format (ELF) is a format that is used for linking and for loading programs. An ELF contains multiple byte streams (code, data, debug info, . . . ) that are arranged in two views: In the link view, those byte streams are called sections, while they are called program headers (or segments) in the load view. Additionally, the link view makes use of symbols as named offsets into a section. Further, relocations specify how to edit a byte stream while linking it to a virtual address. In a nutshell, the linker arranges the link-time sections into load-time segments while resolving (most) relocations.</p><p>The basic unit of linking is the section and not a (languagelevel) function or (global) data object. In fact, the linker has no idea about those, and it cannot (due to compile-time resolved relocations) break up a section back into smaller pieces. Therefore, as we want to align the function's start address, we have to instruct the compiler<ref type="foot" target="#foot_1">2</ref> to put each function (and data-object) into its own section, named like the (mangled) function name. For example, the C++ function void foo(int) will end up in the section .text._Z3fooi.</p><p>For data objects (i.e., global variables and read-only data), we require that all variants share the same (data-) object space. For this, the linker has to throw away all but one instance, which requires each variable to be located in its own section <ref type="foot" target="#foot_2">3</ref> . Furthermore, we restrict the program's interpretation of the shared data objects: As objects can be accessed from different variants, we require that the interpretation of objects, statically and heap allocated, must be compatible across all variants. This means that matching struct fields have to be aligned, that language-level types have to be of equal size, and that variants must have a common understanding of the object state. Nevertheless, this restriction holds for many automatically-applied program transformations as they are nonfunctional by design. In Sec. 4, we will discuss this topic further.</p><p>After the multi-variant compilation, we end up with a set of ELF object files whose sections s can be categorized as follows: A variant v = {s v,1 . . . s v,n } is a collection of sections that should be visible together; all sections of one variant have to have the same section type (e.g., code, read-only data, . . . ), which becomes the variant type. A variant overlay (overlay, o) is a collection of |o| equally-typed variants and a variant-overlay group (group) is a set of overlays that are semantically connected. For a program, multiple independent overlays and groups can exist. For example, besides a math-code overlay (non-AVX vs. AVX2), there can another overlay group (code and read-only data) for the SQLite library that allows to en/disable executable assertions. We call all sections that are not covered by a variant the remaining sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Link-Time: Virtual-Address Alignment</head><p>After the compile-time preparation, the linker generates the multi-variant ELF (Fig. <ref type="figure" target="#fig_0">1</ref>, steps 2-4), for which it must match and align sections from the different variants within an overlay such that they end up with the same virtual address. For our implementation, we modified LLD <ref type="bibr" target="#b17">[18]</ref>, the linker of the LLVM project that is a drop-in replacement for the GNU ld and gold. We will describe the required linker modifications on base of this implementation. However, they should be easily generalizable to other linkers as well.</p><p>First (Fig. <ref type="figure" target="#fig_0">1</ref>, step 2), the developer must be able to express the relationship between sections, variants, and overlays. For this, we add a VARIANT_OVERLAY statement to the linker-script language, which is the command language of ld (and gold/lld). The statement contains multiple variant statements, which define, similar to other commands, patterns that are matched against the input sections, which the linker extracts from the object files. The lexically first variant of an overlay is its primary variant. In the overview example, we see a linker-script fragment that defines an overlay foo with two variants (A, B), which collect the code (text) sections from the respective foo_{A,B}.o.</p><p>Thereafter (Fig. <ref type="figure" target="#fig_0">1</ref>, step 3), we align the input sections within an overlay: For this, we first match sections from the different variants and identify those sections that occur only in one variant: Starting with all sections captured by the overlay, we group the sections by the key (variant, section name) and select a single section as representative for that key. While there is usually only one candidate section, ELF v \n</p><formula xml:id="formula_0">f g h X J A s A,f s A,g s A,X s A,J B s B,f s B,g s A,h s B,X s B,J C s C ,f s C ,g s C ,J</formula><p>Figure <ref type="figure">2</ref>: Input-Section Table (extended running example) section groups <ref type="foot" target="#foot_3">4</ref> and weakly-defined functions<ref type="foot" target="#foot_4">5</ref> can result in multiple candidates. In the former case, we can choose any section as the group representative, in the latter case we apply the usual override semantic for weakly-defined functions, but only within the group. With the representatives, we end up with one section s v,n per (variant, name)-pair and form the overlay's input-section table, which tabularizes the results.</p><p>In the table (Fig. <ref type="figure">2</ref>) for the (extended) running example, we see that f and g are present in all variants and h is private to variant B. For partially-filled columns (e.g., X) that contain more than one entry, we report an error. With the table in place, we validate and manipulate the symbol table. With multivariant compilation, the linker will encounter the same symbol, which is a named pointer into a section, multiple times. Instead of reporting an error, we collect duplicate symbols and delete all but the symbol that points to the primary variant. In this process, we verify that each variant's symbol points to the same column and has the same offset.</p><p>While we usually report an error if this check fails, some compiler optimizations (e.g., function-body deduplication) can result in two aliased symbols pointing to the same section in one variant but not in the other. However, as we cannot align this section to two different sections in the other variant, we have to solve this rare situation differently: We equip each variant with a jump table (e.g., s A,J in Fig. <ref type="figure">2</ref>) and insert a jmp instruction for one of the aliased symbols. In each variant's jump table, the instruction jumps to the correct section and offset, while we globally redirect the original symbol to the jump-table entry in the primary variant.</p><p>With all symbols being aligned within their column, we align the columns by padding each s v,n to max v i ?o s v i ,n . As this can induce large padding gaps, we use variant-local sections as gap-filler sections. Currently, we perform the filling greedy as we did not encounter a situation where a (more) optimal algorithm would be required. In the example (Fig. <ref type="figure" target="#fig_0">1</ref>, step 3), the gray areas are padding and s B,h is used for filling the gap in B that s A,g provokes.</p><p>After column alignment, we place the variants in the ELF's virtual address space (Fig. <ref type="figure" target="#fig_0">1</ref>, step 4). For this, we utilize the fact that the load address (where the loader will copy the section to) and the virtual address (where the section "thinks" it is) can disagree. We combine all sections for a variant (table row) in an output section; an established linker-internal concept that acts as an intermediate step between input sections and segments. Each output section is linked (i.e., relocated) to the virtual address of the primary variant, while we load them, by default, sequentially. Thereby, load and virtual address only match for the primary variant. All remaining sections can be linked as usual.</p><p>The result of MELF is a regular ELF binary, which is only special with regard for the non-primary output sections, whose load and virtual addresses do not match.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Run-Time: Multivariant Loading</head><p>With the MELF binary constructed, it is time to bring our multi-variant program to execution. As this depends on the indented usage scenario, this section will only provide the necessary primitives from which different use cases can be constructed (see Sec. 3).</p><p>First, we have to decide which variant(s) will execute and initialize the program state. As primary variants are loaded to their virtual address, the program automatically starts executing in those variants, and it also loads their data-segment contents. This also requires us to only run the constructors for global variables of the primary variant, which is done by discarding the initialization-array entries of the other variants.</p><p>For the usage of MELF's, we provide two operation modes by the MELF run-time loader library: With the base mode, only one variant per overlay is active at the same time, which the developer can replace with an explicit call into the runtime library. For this, we use the mprotect() system call to make the respective overlay region writable and copy the contents of the desired variant to the primary virtual address. To make overlay and variant regions known to the MELF loader, the linker places symbols with virtual and the load addresses before and after each output section; with these, the program can reference all variants in the program. Usually, the developer will only replace text and other read-only sections, as switching data variants would reinitialize the global variables. Also, for this mode to work, we demand that no thread currently executes or has a call frame for a function from the replaced overlay. This program state is called global quiescence <ref type="bibr" target="#b13">[14]</ref>.</p><p>As the base mode is of limited use for multithreaded programs, we also provide the MMView mode, based on MMViews <ref type="bibr" target="#b13">[14]</ref>. Thereby, multiple variants can be active simultaneously and threads can switch their variants for which they only have to be locally quiescent (i.e., they do not execute a replaced function). As this mode requires the MMView kernel extension, we give a brief overview of its semantic.</p><p>Excursus: MMViews With MMViews, a process can have multiple, closely-synchronized, concurrently-active address spaces, which have the same structure: all mappings are equally placed and address-space modifications work si-multaneously on all MMViews. Also, the contents of most mappings are synchronized by sharing the physical page frames. Only for mappings that the user explicitly marked as decoupled, the kernel will establish a copy-on-write mapping, whereby those mappings contain MMView-local memory. Also, threads can switch between MMViews and can create a new MMView by cloning their current view.</p><p>The existing <ref type="bibr" target="#b13">[14]</ref> MMView Linux extension implements MMViews as separate page-table trees. So, since an MMView is technically a separate address space, they induce higher memory overhead (for the page tables) and increase the TLB pressure if two MMViews are active on the same core. Also, page-table modifications, although the extension synchronizes them lazily, have a higher run-time overhead. However, switching views is rather cheap as the kernel only exchanges a single CPU register.</p><p>Coming back to MELF, we use the described extension to execute multiple variants in one process concurrently: We decouple all primary-variant regions, allowing the user to create one MMView for each desired variant combination. With the described base-mode primitives, the user can load different variants into the MMViews. Thereby, an MMView can combine these variants from the variant-overlay groups.</p><p>In Fig. <ref type="figure" target="#fig_0">1</ref>, step 5, we see two MMViews ? and ?, which currently have loaded variant A resp. B. We see that the nonmultivariant text and data remain shared and only in the overlay region (0x2000-0x3000) is decoupled. Since MMViews have a synchronized structure and the MELF linker aligned the start address of the multivariant functions, all common symbols (e.g., call f) and function pointers (e.g., gptr) are globally valid and threads in different views can easily co-operate.</p><p>With MMViews in place, a thread can switch variants on function-call granularity, for which call and return edges have to perform inverse MMView switches. For this, the run-time library provides a trampoline function (Lst. 2) that switches to the desired MMView, forwards arguments, restores the previous MMView and returns the return value. As the trampoline is not part of an overlay, it can also transfer the control flow between two multi-variant functions. The call protocol for MELFs defines the following call-chain: Listing 2: Trampoline function call_with_helper ensures to call call_return at the end of the call chain to switch back to the caller's original application variant.</p><p>Since the protocol always requires jumping back to the original application variant, we only demand local quiescence per thread.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Case Studies</head><p>As the MELF approach is a general semi-dynamicvariability method for compiled languages, we now provide multiple case studies to demonstrate the potential of our approach. We will justify, for each case study, its relevance, describe the usage of MELF, and show its benefits with a quantitative evaluation. Thereby, we will only focus on the MMView mode as we consider it the more interesting application mode for MELF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmark Setup</head><p>We cover the server-centric scenarios with a dual-socket system (Intel Xeon Gold 6252, 2.10GHz, 2?24 physical cores, 2 NUMA nodes, 384 GiB DRAM, hyperthreading disabled). Additionally, we use a smaller machine with more restricted hardware (Intel i5-6400, 4 cores, 32 GiB DRAM, no hyperthreading). On the software side, we used Debian </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Case-Study: SQLite Asserts</head><p>With this case study, we demonstrate that MELF is able to overlay multiple handwritten code variants and that we can performance-isolate both variants for thread-contextualized execution (with MMViews). More concretely, we build a MELF binary that contains two variants of the SQLite library: (1) the debug view, where assert() statements and additional sanity checks are enabled, and (2) the performance view, where these are disabled. Within the same process, multiple threads execute read-only SQL queries, either with the debug view or the performance view. We vary the total number of threads and the number of threads in the debug view, as well as the benchmark machine.</p><p>Scenario Justification Unlike compiler-based security measures, executable asserts <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref> are inserted manually by the developers to test high-level invariants at run time. They are an intrinsic part of debug builds, which often include extended data structures and code paths to check application behavior. Thereby, assertions not only assist the development of safer programs <ref type="bibr" target="#b8">[9]</ref>, but they are also an active security measure <ref type="bibr" target="#b9">[10]</ref>. However, due to their complexity, size and performance impact, they are usually disabled in production in favor of a performance/release build. With MELF, we can provide a more restricted debug view with enabled assertions, for example, for SQL queries that handle user input. Technically, this case-study is of interest as it shows how to manage multiple variants that interpret data differently.</p><p>Workload We use a geospatial proximity search, since handling two-dimensional data requires complex algorithms and data structures. On the list of 2856 UK postcodes, we issue SQL queries that find the geographically closest code that is not further away than 25 km for randomly chosen coordinates in the UK. For handling coordinates, we use SQLite's R-Tree plugin. </p><formula xml:id="formula_1">-0 -2 -2 -1 0 -1 0 -2 -1 1 0 -0 -2 -3 -4 -2 -5 0 1 2 2 2 1 -1 -4 0 -1 -0 2 -3 -0 1 -1 -2 0 0 -1 -2 -3 -3 -5 -2 -3 -2 0 3 3 3 1 0 1 -1 2 1 1 0 -0 3 0 2 -0 -0 1 2 2 1 -0 0 -0 -0 -0 -0 -0 -2 -1 -1 -1 -3 -1 -1 0 -1 0 -0 -1 1 -3 -2 0 0 -0 -1 -3 2 0 0 -4 0 -1 -2 -2 -2 -2 -0 -1 -3 -3 -3 -2 0 1 1 -1 -1 1 2 -2 0 0 -1 -0 1 -1 -1 0 1.0 2.0 2.9</formula><p>3.9</p><p>3.9 Benchmark In Tab. 1, we provide a comprehensive overview about the used benchmark binary. Since SQLite's default configuration did not scale beyond a single core, we had to disable some statistic features to limit contention. While running both views concurrently worked out-of-the-box for most parts, we had to unify the struct sqlite_mutex as the debug view requires additional fields to track mutex ownership. Without a unified data type, the address calculation for array elements differed and provoked a crash. In total, we had to change 30 lines of code.</p><p>For a seamless interoperability, MELF aligns 1 310 functions by inserting a total of 372.3 KiB of padding, which is 13.48 percent of the combined size in the virtual address space. MELF already optimized the required padding by using 109/202 view-private functions in the performance/debug view as gap fillers. For the mutable global data in (.data, .bss), we align both variants but only use the debug view's data.</p><p>Performance Isolation In order show that the MELF approach is able to isolate the impact of the debug view on threads in the performance view, we run the benchmark with 1 to 16 threads, whereby 0 to 16 threads execute permanently in the debug view, while the others execute in the performance view. We also execute the benchmarks on our 4-core and on our 48-core machine in order to determine if core contention has a significant impact. We execute each benchmark for 60 seconds, record the number of completed SQL queries In Fig. <ref type="figure" target="#fig_1">3</ref>, we show the per-thread SQL-query rate and normalize it to the results where all threads execute in the performance view (y-axis = 0), which we consider the baseline for this experiment. For the baseline case, we also show the speedup to confirm that contention within SQLite itself is not the cause of performance degradation but only the usage of MMViews and MELF. As expected, we see near perfect speedup on the 48-core machine, while the speedup caps around 4 on the 4-core machine. Please note the highly asymmetric color scale in this figure.</p><p>In the debug view, we see a significant impact of the additional assertions and sanity checks on the query rate. As the slowdown on the 48-core machine (-39 % to -72 %) is significantly worse for more threads in the debug view than on the 4-core machine (-38 % to -43 %), we conclude that the additional sanity checks provoke more contention due to additional state locking.</p><p>In the performance view, we see that the number of threads in the debug view has no consistent impact on the other threads, and some results even indicate better indicate a higher performance with using MMViews. Therefore, we take a look at the relative standard deviations for the baseline case to determine if these results stem from SQLite itself. While we cannot derive any conclusions from the relative standard deviation for the 4-core machine (0.3 %-12.4 %), the 48-core machine (rel. stdev.: 0.3 %-1.7 %) suggests that the MELF approach also has a small impact on the performance view. If compared to the observed relative query rates (-4 % to 3.4 %), we conclude that MELF has a negative performance impact of around 1 percent and adds around 2 percent of jitter. Nevertheless, in relation to the impact of globally-enabled assertions, the MELF approach isolates the impact of additional sanity checks in SQLite successfully.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Case-Study: Thread Pools on Heterogeneous Instruction-Set Machines</head><p>With this case study, we show that MELF eases the programming of non-homogeneous multicore machines where cores share a common subset instruction-set architecture (ISA) but have additional heterogeneous ISA extensions. More concretely, we provide a thread-pool abstraction (see Fig. <ref type="figure" target="#fig_4">4</ref>) that accepts jobs together with a hint on which core type the job will run best. Depending on the current load, the pool schedules the job (preferably) on a hinted core where it uses a MELF-prepared code view that exploits the core-specific ISA extensions or on another core with a different code view that is optimized for that core. Thereby, the thread-pool user fully utilizes her heterogeneous architecture without the need for adapting her code paths for the specific architecture. Scenario Justification While the first non-uniform multicores (e.g., , ARM big.LITTLE <ref type="bibr" target="#b18">[19]</ref>) came with a unified ISA, recent work <ref type="bibr" target="#b19">[20]</ref>- <ref type="bibr" target="#b21">[22]</ref> investigates on the performance and energy benefits of heterogeneous ISAs. However, ISA diversity poses a programmability challenge as programmer are not keen to distribute their program/data   <ref type="bibr" target="#b22">[23]</ref>, cross-core invocation <ref type="bibr" target="#b23">[24]</ref>, and multi-kernel <ref type="bibr" target="#b24">[25]</ref> methods to manage this variability. With MELF, we take a step towards the seamless integration of heterogeneous ISAs into our programs. Technically, this case-study is of interest as we make use of different crosscutting compiler options on instruction level, something that is not easily expressible on a language or ifdef level.</p><p>System Model As we have no heterogeneous-ISA machine at hand, we simulate one by virtually dividing one NUMA node of our 48-core machine into two partitions (see Fig. <ref type="figure" target="#fig_4">4</ref>): On the 12 AVX2 cores, modern AVX/AVX2 vector instructions are available, while the other 12 cores lack this ISA extension.</p><p>Work Load For our benchmark, we choose two job types that benefit differently from the AVX2 instructions: While jobs with a recursive Fibonacci (n=36, Base/AVX: 57.9 ms) do not benefit at all, the duration of a Matrixmultiplication (565 ? 565) job drops from 58.3 ms to 38 ms on the AVX2 core. For the matrix multiplication, we use the Eigen C++ library (v3.4), which uses explicit ISA specialization according to the given compiler flags. Please note, that we have chosen the parameters such that the base-core execution time match. As work load, we submit 1000 jobs with 0 to 100 percent of the jobs being matrix multiplications (see Fig. <ref type="figure" target="#fig_5">5</ref>) and record the end-to-end latency of those 1000 jobs as well as the accumulated job execution time.</p><p>Thread-Pool Variants Based on Eigen's non-blocking thread pool, which already implements thread-local queues and work stealing, we build three thread-pool abstractions that all take a function pointer and a scheduling hint as a job description: The 1 Pool, Base only variant executes all jobs on a single 24-worker thread pool and only uses code without AVX2 instructions; the scheduling hint is ignored. The 2 Pool variant uses two 12-worker thread pools, one for the base cores and one for the AVX2 cores; each core executes code specialized for its ISA and workers are pinned to its core; no stealing happens between the pools; and the scheduling hint selects the thread pool. The 1 Pool, MELF variant uses a single 24-worker pool that utilizes MELF: Each worker thread is pinned to its core and executes in a MELF code view that is specialized for its ISA. If a worker queue runs empty, the worker first tries to steal from workers with the same ISA (see Fig. <ref type="figure" target="#fig_4">4</ref>, 1. local steal) before stealing from other ISAs (2. global steal). Please note that stealing from a foreign ISA queue works seamlessly as the local MMView exposes the same functions but implemented with different instructions. Results In Fig. <ref type="figure" target="#fig_5">5</ref>, we show the evaluation results on one NUMA node of our 48-core machine, where we compare the three pool variants with respect to required processing time. Please note, that we divided the accumulated processing time by 24 to match its scale to the end-to-end latency. The remaining difference between latency and processing time stems from pool overheads and execution phases where not all workers execute jobs.</p><p>For the Base only variant, processing time is, as expected, only spent in the base code view (less bright colors). The slight increase in both curves stems from the increased cache pressure if 24 cores execute matrix multiplications in parallel compared to executing recursive Fibonacci calls on the (cached) stack. Although the 2 Pool variant spends the least amount of processing time, its end-to-end latency for 1000 jobs is significant at both ends as it only utilizes 12 cores at 0 and 100 percent matrix-multiplication jobs. Also, it achieves its best latency at 60 percent multiplications, which is expected from the ratio between a Fibonacci job (57.9 ms) and an AVX2-Matrix multiplication (38 ms).</p><p>Finally, the MELF-enhanced 1 Pool variant, performs better in both dimensions: Compared to Base only, it uses less processing time as it actually utilizes the AVX2 instructions, whereby also its latency is better. Compared to the 2 Pool variant, it always utilizes all cores resulting in a consistently low latency and only when more than 60 percent of the sub-mitted jobs are Matrix-multiplications requires more processing time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Case-Study: Profiling in memcached</head><p>In this case study, we dynamically en-/disable compilerintroduced function-level profiling on a per-thread basis with MELF and MMViews in memcached (v1.6.10). Similar to the SQLite study, we combine two memcached variants in one binary: <ref type="bibr" target="#b0">(1)</ref> In the profiling view, the compiler (with the -pg flag) introduced mcount() calls into function prologues that record the invocation, while (2) the performance view contains the same functions but without profiling code. On a per-connection basis, worker threads either select the profiling or the performance view. For our benchmark, we gradually change the number of profiled connections and measure the request handling time within memcached.</p><p>Scenario Justification As developers cannot emulate complex production environments, it is often up to the De-vOps team to detect and explain performance anomalies after deployment. For this function-level profiling, as provided by gprof <ref type="bibr" target="#b25">[26]</ref>, would provide precise insights about call frequencies and caller-callee relationships, but its cost prohibits us to have it permanently enabled. Also, in a multi-tiered environment, where only some clients incur a certain anomaly, it is desirable to enable profiling only selectively for certain threads and requests. Because gprof consists of both, a compiler instrumentation to modify function translation and a statically-linked profiling library, developers are unable to define exclusive code paths they want to profile. They can either profile the whole application or nothing at all. Thanks to MELF, the DevOps team can enable gprof-profiling dynamically and selectively, thus limiting the impact to a minimum.</p><p>Technically, this case-study is of interest as we reduce contention on cross-cutting features.</p><p>Work Load As a work load for our multi-variant memcached server, we use the memtier benchmark, which is a specialized benchmark for key-value databases <ref type="bibr" target="#b26">[27]</ref>. On the client side, we use its default SET-GET ratio of 1:10 and start 16 threads with 50 clients each, resulting in 800 clients with 800 active connections to memcached. We execute the benchmark on the same machine, but pin memcached to one NUMA node, while pinning memtier onto the other. We record data request latencies until each view has serviced 100 million requests.</p><p>Benchmark Unlike other servers, memcached has an event-based design and the worker threads execute a state machine for each connection. Thereby, connections can be easily rebalanced between workers and one worker routinely handles many connections. To match the 16 memtier threads, we start memcached with 16 worker threads that, together, service all client requests.</p><p>For new connections, we decide whether it will execute in the performance or the profiling view, mimicking scenar- As long as the profiling percentage threshold is not met, each connection will be profiled. Because memcached distributes connections round-robin across workers, each worker thread will serve both, profiling and performance connections. Consequently, every worker thread switches between performance and profiling view continuously across the whole benchmark, which increases TLB pressure since they live in distinct address spaces. Nevertheless, as we will show, this penalty is still better than to enable profiling globally and could even be improved by a profiling-aware connection scheduling.</p><p>For our measurement, we record the execution time of the drive_machine() function, which is responsible for executing the per-connection state machine, making the function crucial for the request latency. For each benchmark run, we record request latencies until we reach 100M data points for each view. Therefore, for the mixed-mode benchmarks (25 %-75%), we will end up with 200M data points.</p><p>Results In Fig. <ref type="figure">6</ref>, we show violin plots for the drive_machine() execution times separated by requests serviced that were serviced in the profiling or the performance view. Please note, that the 25% performance violin on the left matches the 25% profiling violin on the right as both stem from the same benchmark run. Also, we include the base variants, which show the results for a memcached server with statically enabled or disabled profiling without MELF or MMViews. For preparing the violin plots, we limit each data set (100M data points) to the [0.01%, 99.99%]interval to remove outliers and randomly sample 1 million representative data points.</p><p>By comparing the base variants, we see that profiling has a significant impact on memcached's most important function and increases its execution time by 175 percent. Further, for both views, the violin with the maximum number per-formance/profiling connections match the results of the base variant (i.e., performance base ? 0% performance). From this, we can conclude that MELF enables us to enable and disable profiling dynamically at run-time without having a continued run-time impact.</p><p>For the profiling view, we see that the impact of profiling per request increases if more connections use the profiling path. This behavior can be explained by looking at the gprof-induced into the code: For each function, gprof allocates a counter variable that the compiler-introduced mcount() function uses to keep track of the number of invocations. As the activated memcached logic is rather small and executed by 16 threads in parallel, all workers in a profiling view access the same small set of per-function counters. Together with the fact that gprof does not even cache-align these counters, profiling results in many cross-core cache invalidations. Further, this effect scales with the percentage of threads working in the profiling view as more cache conflicts happen.</p><p>For the performance view, we see a slight increase in the median and tail latencies if more connections are shifted to the profiling view. Since workers need to switch views if the currently active MMView does not match the next processes connection, MELF increases the TLB pressure, impacting also workers in the performance view. Also, the frequent cache invalidations in the neighboring profiling view increases the cache-coherence traffic and puts a burden on the memory bandwidth. Nevertheless, even with 75 percent of all connections being profiled, the median over the base variant only increases by 7.61 percent for performance connections, which is far less than activating profiling globally. Inspired by these results, one could restrict profiling to a single worker thread or a small set of connections to get a statistic picture of the whole memcached process without inflicting the described cache conflicts from invocation counters.</p><p>In total, the MELF approach was able to make the static gprof method dynamically and selectively applicable without requiring a restart of the process and without touching the compiler.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Case-Study: ASAN in MariaDB</head><p>With this case study, we demonstrate that MELF is able to handle multiple variants in complex C++ projects. We compile MariaDB (&gt; 20000 functions) once with (-fsanitize-address) and once without address sanitizer <ref type="bibr" target="#b4">[5]</ref> and use the MELF linker to overlay both variants in the same binary. At run-time, we decide on a per-user basis whether a client's SQL queries are executed with sanitized or unsanitized MMView.</p><p>Scenario Justification Sanitizers <ref type="bibr" target="#b27">[28]</ref>, like Address-Sanitizer <ref type="bibr" target="#b4">[5]</ref> and UBSan <ref type="bibr" target="#b28">[29]</ref>, are often implemented as compiler transformations and they are usually used at development time to find bugs. However, due to their high  overheads, they are then disabled in production, although they could provide an additional level of sanity checking for code that handles user input. With MELF, we enable AddressSanitizer, which was found to be the most common sanitizer <ref type="bibr" target="#b27">[28]</ref>, for individual database users in MariaDB, whereby we mimic a trusted-untrusted customer model. Technically, this case-study is of interest as MariaDB is a multi-threaded, large server application. With ASAN being strongly invasive on the code and data path, it helps to understand how MELF scales for large code bases. Work Load As a work load, we use the sysbench [30] oltp_point_select benchmark. On our 48-core machine, we execute and pin MariaDB to NUMA node 1, while sysbench runs on NUMA node 2. We start MariaDB in the one-thread-per-connection mode, and always have 24 concurrent sysbench connections. To satisfy the mentioned trusted-untrusted customer model, we execute two sysbench instances, each of which connects as different database user. To vary the load between the ASAN/no-ASAN view, we vary the distribution of the 24 connections between both instances. We use the output of sysbench, which records the end-to-end latencies per transaction, as our result data.</p><p>Results In Tab. 2, we see an overview of the MariaDB binary produced by the MELF linker. First, we see that the application of ASAN increases the number of functions, as the compiler cannot inline and eradicate some of the smaller functions. We also see that the ASAN variant's text section is 2.6 times larger than the normal text section. Together with the fact that 98 percent of the normal view's functions had to be aligned and, therefore, could not be used for gap filling, explains the larger percentage of padding bytes (33.87 %).</p><p>In Tab. 3, we show the end-to-end latency results for the oltp_point_select benchmark. First of all, we see that AddressSanitizer has a significant impact on the performance of MariaDB as it increases the median latency by 89 percent. This latency penalty is also inflicted on clients whose queries are processed in the ASAN view. However, also clients in the normal view have a 36 percent increased query latency. This increase can be explained by the fact that the ASAN run-time library still has to intercept and wrap heap allocations, which are known to have a major impact on query performance <ref type="bibr" target="#b30">[31]</ref>, in order to keep its shadow-memory map up to date. However, in the normal view, MELF only removes the additional checks from the query processing and the additional overhead from the run-time library remains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>In the following, we discuss limitations and benefits of the MELF approach.</p><p>Multi-Variant Data As we have discussed in Sec. 2.3, the MELF approach is currently limited to a strict data-object sharing semantic, where all variants share the data sections of the primary variant. For this, the data and its interpretation have to be compatible in all variants, which can, as we have seen with SQLite (Sec. 3.1), require some manual program modifications.</p><p>The following program demonstrates this limitation as it is incompatible in three different dimensions: (1) If a lock is allocated in A, the object would be too small to usage in B, (2) the field L has different offsets, and (3) both variants have a different idea about the lock state (1 vs. -1).</p><formula xml:id="formula_2">// Variant A struct lock { int L; } #define LOCKED 1 // Variant B struct lock {int O; int L ;} #define LOCKED ( -1)</formula><p>Supporting these cases in general is impossible, as it would require complete program understanding on the language level. However, for many cases, one could use semiautomated transformer functions <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>, known from dynamic software updates, to synchronize two copies of the data.</p><p>For data initialization, we use the variant that is active at the initialization time. Therefore, we use the global data segment and invoke all global constructors in the primary variant. Function-local static variables are, in line with C/C++ semantics, initialized at the first call of the respective function and, thus, in the context of the then active variant.</p><p>Besides strict data sharing, the MELF linker also supports a strict data-object partitioning. For this, the linker has to keep all data sections, let each variant only reference its own data sections, and we would run the constructor of all vari-ants at program start. In this use case, the developer has to ensure that objects do not flow (i.e., across the univariant parts of the program) across variant boundaries. This mode could be useful for using multiple incompatible versions of libraries that make heavy use of global state.</p><p>MMView Dependency We acknowledge that MELF plays out its benefits particularly in combination with MMViews, which we use to back the same virtual-address range with different contents depending on the active thread of a process. The MMView approach has disadvantages, such as memory overhead and increased TLB pressure <ref type="bibr" target="#b13">[14]</ref>. Because the exact runtime overhead of MMViews highly depends on the size of virtual memory and its physical data (plain data in RAM, file-backed mappings), a general overhead cannot be quantified. Furthermore, the measurable effect on the TLB directly correlates to a thread's view switch frequency and memory access patterns, which is individual to every application. For view creation and switching, a mean runtime penalty of 7?s with a standard deviation of 6?s has been measured on earlier benchmarks for memcached and MariaDB <ref type="bibr" target="#b13">[14]</ref>. In another recent study of memcached, the cost of MMViews were only measurable for context-switches between different views. In general, however, a transition from one view to another is comparable to a context-switch between two threads of two different processes. As an alternative, multithreaded MELFs could be facilitated through CPU-assisted segmentation <ref type="bibr" target="#b33">[34]</ref>, such as supported by the IA-32 architecture <ref type="bibr" target="#b34">[35]</ref>. With segmentation, we would load every variant into its own segment and each thread could select its variant by setting its code-segment selector register accordingly. On the IA-32 platform, where call and jump instructions implicitly use the code segment, this would be equivalent to MMViews. Without the separate address-space clones, the memory and TLB overheads would be replaced by a minor offset calculation overhead that segmentation entails.</p><p>Although segmentation contradicts Linux's flat memory model, MELF binaries could easily be supported if (a) the kernel provides means to initialize and switch hardware segments and (b) if the code-segment register is preserved between thread switches. Unfortunately, segmentation as a virtual memory primitive is currently not in fashion on modern platforms. Particularly, it has been removed from AMD64 <ref type="bibr" target="#b34">[35]</ref> and was never available on RISC architectures. Given that segmentation has other advantages, such as safety benefits, we would applaud a renaissance of this virtual memory primitive. However, even without segmentation, we could theoretically implement text variants, using position-independent code coupled with the segmentation remnants in AMD64 (FS/GS register) to facilitate variantadherence for indirect jumps. However, this would require intrusive linker and compiler modifications.</p><p>Switching For both modes (base and MMView), we demand that switching the variant takes only place at func-tion boundaries. This limitation stems from the fact that MELF only aligns function start addresses, but all other intra-function addresses could be unaligned. For example, saved return addresses may not be valid in the other variant. However, with additional compiler support, this quiescence requirement could be weakened: For example, if the compiler would also align call sites and would make the call frames at those call sites compatible across variants, we could switch variants flexibly at every call and return edge. Such an extension could be beneficial for supporting workloads on heterogeneous ISA as it would, for example, ease thread migration between different ISAs without stack rewriting <ref type="bibr" target="#b35">[36]</ref>.</p><p>Applicability and Benefits With our case studies, we have shown that the MELF approach is applicable to a wide range of programs. By covering not only C but also C++ projects, which result in more complex object files (e.g., C++templates are a main user for COMDAT), we have demonstrated that MELF works on multiple programming languages. Further, as our approach only requires a compiler to produce "sectioned" object files, we are in principle language agnostic and widely applicable.</p><p>Also, MELF is agnostic to the source of the code modification.</p><p>As shown, we support automaticallyintroduced compiler transformations (e.g., profiling) as well as manually-encoded variants (e.g., SQLite). Thereby, MELF covers more scenarios than pure language-based methods, like aspect-oriented programming (AOP) <ref type="bibr" target="#b36">[37]</ref>. Further, as MELF prepares everything at link time, static binary validation could make MELF safer than dynamicbinary instrumentation (e.g., Intel Pin <ref type="bibr" target="#b37">[38]</ref>), which was criticized to ease an exploiter's life <ref type="bibr" target="#b38">[39]</ref>.</p><p>Further, we have shown that MELF's semi-dynamic approach to variability is able to cover a wide range of use cases that are security-related (assertions, ASAN), provide DevOps with deeper insights (profiling), and ease the support of coming hardware generations (heterogeneous ISAs). We believe that especially the DevOps and the heterogeneous-ISA scenario will require semi-dynamic variability, since: (1) We need more dynamically-observed metrics to understand our complex systems down to the individual hot path.</p><p>(2) Extensible architectures, such as RISC-V platform <ref type="bibr" target="#b39">[40]</ref>, with its many ISA compatibility levels, will boost the spreading of heterogeneous-ISA machines. (3) In many settings, we simply have not the choice to drop existing applications in favor of from-scratch developed software.</p><p>Although three of our four case-studies do not dynamically switch views during runtime, we were able to gain reasonable performance isolation in each application scenario: For profiling in memcached we achieved performance isolation of profiling connections and do dynamically switch a thread's view based on the connection currently being served. In the other case-studies, we were able to obtain: (a) Performance isoliation and improved robustness for dy-namic assertions in SQLite. (b) Performance maximization via ISA-specialized function variants with thread-pools. (c) Performance isolation and improved security for ASAN in MariaDB. Additionally, function pointers work "out-of-thebox" for MELF, which eases a programmer's life.</p><p>We also imagine that MELF can be used in an embedded setting, where no MMU is available to implement MMViews: For these machines, MELF can prepare variant overlays of in-flash text segments, which then can be exchanged at run-time by partially rewriting the flash memory. Thereby, multiple software variants can be supported in one device without inducing indirection overhead.</p><p>Also, we have seen that MELF's function alignment only induces moderate memory overheads (see Tab. 1), while the run-time overhead in combination with MMViews depends on the concrete case study. Nevertheless, even in the memcached case study, where threads switch on a regular basis between views, the run-time overhead was limited to less than 8 percent. Furthermore, Fig. <ref type="figure">6</ref> shows that the median runtime latency in the performance view is equal for the base and 0% variant.</p><p>Summarized, MELF is a cheap, language-agnostic method to lift static code variability to the semi-dynamic level. MELF is widely applicable and provides us with a framework for further explorations of semi-dynamic variability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Technically, text overlays <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref> are a closely related topic: They were used to reduce a program's primary-storage requirement by loading only the currently used subset of functions into the memory. While overlays have a renaissance <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref> for managing complex memory hierarchies, they are fundamentally different as they partition one program to fit it into a smaller memory. In contrast, MELF overlays multiple but similar programs in one binary and, with MMViews, execute those variants concurrently.</p><p>On the language level, aspect-oriented programming <ref type="bibr" target="#b44">[45]</ref> if applied dynamically <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b46">[47]</ref> is similar to MELF. However, as aspects only add code before, after, or around function (calls), it does not support variants that stem from generic and cross-cutting code transformations.</p><p>Function Multiversioning <ref type="bibr" target="#b47">[48]</ref> is a GCC extension to generate multiple versions per function, each of which specialized for the availability of different instruction-set extensions. The loader selects one variant on function granularity, which, unlike with MELFs, cannot be changed later on.</p><p>Fat binaries support multiple processor architectures by embedding program versions for the different processor types into one executable or library <ref type="bibr" target="#b48">[49]</ref>- <ref type="bibr" target="#b53">[54]</ref>. The variant to execute can be either selected directly by the operating system <ref type="bibr" target="#b53">[54]</ref> or through a polyglot opcode string that is interpretable by both architectures <ref type="bibr" target="#b51">[52]</ref>. Nextstep's Mach-O format, which was later adopted by Mac OS X, even supports "multifat" binaries that allow more than two different architectures (68K, x86, HP PA-RISC, SPARC) <ref type="bibr" target="#b49">[50]</ref>, <ref type="bibr" target="#b52">[53]</ref>, <ref type="bibr" target="#b53">[54]</ref>. Going one step further, Cha et al. propose a system for generating multi-architecture binaries that, in contrast to fat binaries, use the same program string which is transformed in a way to be correctly interpretable by multiple processor types <ref type="bibr" target="#b54">[55]</ref>. Similarly to the architecture heterogeneity of fat binaries, the Windows Portable Executable format has support for multiple platforms as it contains a DOS and Windows program in parallel <ref type="bibr" target="#b55">[56]</ref>. Whereas the DOS part is usually just a small stub nowadays, it has been used to ship binaries that work under DOS and Windows in the past. In contrast to MELF, in all these approaches the variant selection covers the whole program, that means it is determined at process start, and cannot be changed later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Multivariant ELF (MELF) is as a binary-level approach for the inclusion of multiple compile-time variants within the same binary and flexible switching between them at run time on function/section granularity. This facilitates the implementation of semi-dynamic variability, that is, dynamic switching between feature-variants at run time that are nevertheless generated and known at compile time, whereby even highly cross-cutting compiler features become configurable at run time. In combination with a kernel extension for inprocess address spaces, this even works on the level of individual threads.</p><p>MELFs are implemented solely on binary level and mostly independent of the employed languages and compilers. Function variants are aligned by the MELF linker to the same virtual address, so that existing pointers or relocations remain valid even in case of a variant switch at run time. Thereby, MELFs are relatively easy to apply to existing projects. We demonstrated this on the example of four case studies, ranging over a wide range of multithreaded C and C++ projects. In all cases, MELF was able to isolate the costs and benefits of the compiler/developer-induced code variants to those threads, that use it at run time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Artifact Appendix Abstract</head><p>This artifact includes all tools and a documentation to run the evaluation for multivariant ELFs, a binary-level, language-agnostic approach to semi-dynamic variability. It details how to run and modify four case studies using the provided artifact package, which includes benchmark scripts, a virtual disk file and the MMView kernel and its initrd. Users run the virtual machine via QEMU and execute scripts, which allow to generate and display benchmark data for each case-study. The four case studies are: (a) MariaDB ASan, (b) SQLite assertions, (c) Heterogeneous-ISA thread-pool, and (d) memcached profiling to prove the wide applicability of MELFs. Each case study includes instructions on running, exporting results, and modifying the benchmark. Next to the case-studies, users can also modify the provided MELF linker, the crucial component in creating MELFs, to examine the generation and placement of variant generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scope</head><p>Users investigating the MELF benchmarks are able to verify that the only dependencies and changes to-be-made to make use of MELFs in applications are:</p><p>(1) Express the existence of multiple application variants inside an applicationspecific linker script file (2) Extend existing application code to declare and load variants. (3) Use the llvm-based MELF linker to link application modules (object files) to the final MELF executable.</p><p>For each individual case-study, users can reconstruct the claimed benefits of MELFs described within the paper, which is mainly performance isolation and increased binary size depending on the workload. All evaluators, however, need to keep in mind that running those benchmarks in a virtualized environment will not provide the same results we were able to get for our paper. Your final result highly depends on the hardware your host machines use. But the main concept of performance isolation shall be visible in each benchmark executed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contents</head><p>This archive provides the user with every evaluation resource needed to run our evaluation setup. Namely, this archive consists of:</p><p>? run.sh. A script that starts a virtual machine via QEMU.</p><p>? hda.qcow2. The virtual disk file of the virtual machine which includes the whole artifact evaluation, based on debian 11.7.</p><p>? linux-mmview-vmlinuz-5.15. A Linux kernel fork of version 5.15 which includes the operating system abstractions for MMViews.</p><p>? initrd-linux-mmview-vmlinuz-5.15. The corresponding initrd of the MMView kernel fork.</p><p>? README.txt. A documentation file giving a detailed explanation of every benchmark setup and how to build, modify and draw benchmark data.</p><p>To start artifact evaluation, the user has to have QEMU installed onto their execution environment and to start run.sh. After the VM booted, the user can get access to the system by logging in either as the user "user" or as "root". The user has a Makefile inside his home directory which contains a target for each benchmark to generate the data and export that data into different formats.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hosting</head><p>The artifact evaluation archive is hosted on the domain of our institution and can be downloaded from there: https://sra.uni-hannover.de/Publications/ 2023/melf-usenix-atc23/</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Requirements</head><p>Most of our artifacts do not require specialized hardware. For the heterogeneous-ISA artifact, we execute code making use of AVX512 instructions. In order to run this artifact your host machine has to support AVX512, but most of modern hardware does that by default. Otherwise, the list of requirements is:</p><p>? Modern CPU with at least 16 cores. If you have less you have to adjust the run.sh script and the benchmarks inside the VM.</p><p>? At least 8GB RAM, the more the better.</p><p>For software requirements, you need to have installed:</p><p>? KVM module installed and loaded on your host machine.</p><p>? QEMU virtualization software stack.</p><p>Users can deviate from the given requirements, but doing so requires manual modification of run.sh and the benchmark inside the virtual machine.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview about the MELF approach. At compile time (1), parts of the program are compiled into multiple variants (A and B), which are captured and organized in the linker script in the variant overlay foo (2). In the linker, the matched input sections are aligned (3) and the resulting output sections (4) are placed in the virtual-and load-address space. At run time (5), the variants are loaded into different MMViews, which share everything but the decoupled regions; common symbols and pointers are stable across views.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head># Collect SQLite 3</head><label>3</label><figDesc>Source files file(GLOB SRCS sqlite3 /*. c) # The Non-Debug Version add_library(sql -ndebug STATIC ${ SRC }) target_compile_options(sql -ndebug -DNDEBUG =1) # The Debug Version add_library(sql -debug STATIC ${ SRC }) target_compile_options(sql -debug -DSQLITE_DEBUG =1) # Case-Study Executable: main add_executable( main main . cc melf_loader .c) target_link_libraries( main sql -ndebug sql -debug ..) Listing 1: Multi-Variant compilation with CMake</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: SQLite Performance Measurements</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Heterogeneous-ISA Thread Pool</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Latency and accumulated processing time for a mixed work load on a 24-core heterogeneous-ISA machine with different thread-pool configurations. To scale latency and processing time, the processing time was divided by 24.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Overview over the SQLite case-study binary GNU/Linux 11 with an MMView-enabled Linux 5.15 kernel with Spectre and Meltdown mitigations enabled.</figDesc><table><row><cell cols="2">SQLite 3.39.4 (a29f994989)</cell><cell>(both views)</cell><cell></cell></row><row><cell>-O3</cell><cell></cell><cell cols="2">Required for scalability</cell></row><row><cell cols="2">DEFAULT_MEMSTATUS=0</cell><cell cols="2">Required for scalability</cell></row><row><cell cols="4">PAGE_CACHE_OVERFLOW_STATS=0 Required for scalability</cell></row><row><cell>ENABLE_RTREE=1</cell><cell></cell><cell cols="2">Required for workload</cell></row><row><cell cols="2">Unify struct sqlite3_mutex</cell><cell cols="2">Required for MELF compatibility</cell></row><row><cell>Perf. View</cell><cell>NDEBUG=1</cell><cell cols="2">Debug View SQLITE_DEBUG=1</cell></row><row><cell>Functions: 1 432</cell><cell></cell><cell>Functions: 1 726</cell><cell></cell></row><row><cell>.text=1 008.5 K</cell><cell>.rodata=27.4 K</cell><cell>.text=1 294 K</cell><cell>.rodata=51.6 K</cell></row><row><cell>.data=2.6 K</cell><cell>.bss=1.2 K</cell><cell>.data=2.6 K</cell><cell>.bss=2.3 K</cell></row><row><cell>MELF Overlay</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Aligned Functions: 1 310</cell><cell cols="2">Padding: 372.3 K (13.48 %)</cell></row><row><cell cols="4">VM Size: .text=1 314.3 K .rodata=61.8 K .data=2.7 K .bss=2.5 K</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Overview of the MariaDB case-study binary</figDesc><table><row><cell>MariaDB (10.11)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ASAN View</cell><cell></cell><cell cols="2">Normal View</cell></row><row><cell>Functions: 21 448</cell><cell></cell><cell cols="2">Functions: 20 986</cell></row><row><cell>.text=16 777.4 K</cell><cell></cell><cell cols="2">.text=4 661.6 K</cell></row><row><cell>.rodata=1 082.2 K</cell><cell></cell><cell cols="2">.rodata=1 079.2 K</cell></row><row><cell>.data=173.9 K</cell><cell></cell><cell cols="2">.data=173.9 K</cell></row><row><cell>.bss=218.3 K</cell><cell></cell><cell>.bss=218 K</cell><cell></cell></row><row><cell>MELF Overlay</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aligned Functions: 20 615</cell><cell></cell><cell cols="3">Padding: 12 487 K (33.87 %)</cell></row><row><cell cols="5">VM Size: .text=16 934 K .rodata=1 099 K .data=180 K .bss=224 K</cell></row><row><cell>Clients</cell><cell cols="2">Normal View</cell><cell cols="2">ASAN View</cell></row><row><cell cols="2">Normal / ASAN Median</cell><cell cols="2">99% Median</cell><cell>99%</cell></row><row><cell>24 / 0</cell><cell cols="2">63 us 73 us</cell><cell>-</cell><cell>-</cell></row><row><cell>18 / 6</cell><cell cols="2">63 us 74 us</cell><cell cols="2">90 us 104 us</cell></row><row><cell>12 / 12</cell><cell cols="2">63 us 74 us</cell><cell cols="2">89 us 102 us</cell></row><row><cell>6 / 18</cell><cell cols="2">64 us 74 us</cell><cell cols="2">90 us 102 us</cell></row><row><cell>0 / 24</cell><cell>-</cell><cell>-</cell><cell cols="2">89 us 102 us</cell></row><row><cell>Base w/o MELF</cell><cell cols="2">47 us 55 us</cell><cell cols="2">89 us 100 us</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Query Latency for Sysbench oltp_point_select benchmark on MariaDB with and without AddressSanitizer (ASAN).</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Static libraries are fundamentally different from dynamic libraries. They are only collections of object files, (nearly) transparent for the linking process, and induce no run-time overhead.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>2 GCC/Clang: -ffunction-sections, MSVC: /</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Gy 3 GCC/Clang: -fdata-sections, MSVC: /Gw</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>e.g., used for deduplicating functions from C++ template expansions.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>Weak functions are only used if no non-weak counterpart is defined</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank our anonymous reviewers and our shepherd <rs type="person">Kenji Kono</rs> for their constructive feedback and the efforts they made to improve this paper. This work was funded by the <rs type="funder">Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) -468988364</rs>, <rs type="grantNumber">501887536</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_tcweQXk">
					<idno type="grant-number">501887536</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Use of simd vector operations to accelerate application code performance on low-powered arm and intel platforms</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Rendell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mccreath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1109/IPDPSW.2013.207</idno>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Symposium on Parallel &amp; Distributed Processing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1107" to="1116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stackguard: Automatic adaptive detection and prevention of bufferoverflow attacks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Conference on USENIX Security Symposium</title>
		<meeting>the 7th Conference on USENIX Security Symposium<address><addrLine>San Antonio, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note>SSYM &apos;98)</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pointguardtm: Protecting pointers from buffer overflow vulnerabilities</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Beattie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wagle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference on USENIX Security Symposium</title>
		<meeting>the 12th Conference on USENIX Security Symposium<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note>SSYM &apos;03)</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Valgrind: A framework for heavyweight dynamic binary instrumentation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nethercote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Seward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="89" to="100" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">AddressSanitizer: A fast address sanity checker</title>
		<author>
			<persName><forename type="first">K</forename><surname>Serebryany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bruening</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Potapenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vyukov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 USENIX Annual Technical Conference (USENIX ATC 12)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="309" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">NSan: A floating-point numerical sanitizer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Courbet</surname></persName>
		</author>
		<idno type="DOI">10.1145/3446804.3446848</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM SIGPLAN International Conference on Compiler Construction (CC &apos;21), Virtual, Republic of Korea: Association for Computing Machinery</title>
		<meeting>the 30th ACM SIGPLAN International Conference on Compiler Construction (CC &apos;21), Virtual, Republic of Korea: Association for Computing Machinery</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">9781450383257</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Executable assertions -an aid to reliable software</title>
		<author>
			<persName><forename type="first">S</forename><surname>Saib</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACSSC.1977.748932</idno>
	</analytic>
	<monogr>
		<title level="m">1977 11th Asilomar Conference on Circuits, Systems and Computers</title>
		<imprint>
			<date type="published" when="1977">1977. 1977</date>
			<biblScope unit="page" from="277" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Applying &apos;design by contract&apos;</title>
		<author>
			<persName><forename type="first">B</forename><surname>Meyer</surname></persName>
		</author>
		<idno type="DOI">10.1109/2.161279</idno>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="40" to="51" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Assert use in github projects</title>
		<author>
			<persName><forename type="first">C</forename><surname>Casalnuovo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Devanbu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Filkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ray</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICSE.2015.88</idno>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE/ACM 37th IEEE International Conference on Software Engineering</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="755" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">High system-code security with low overhead</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kuznetsov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Candea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kinder</surname></persName>
		</author>
		<idno type="DOI">10.1109/SP.2015.58</idno>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Symposium on Security and Privacy</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="866" to="879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<ptr target="https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html" />
		<title level="m">Intel? oneapi math kernel library</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>visited on 12/23/2022</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Corbet</surname></persName>
		</author>
		<ptr target="https://lwn.net/Articles/164121/" />
		<title level="m">Smp alternatives</title>
		<imprint>
			<date type="published" when="2005-12">Dec. 2005</date>
		</imprint>
	</monogr>
	<note>visited on 12/22/2022</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Practical dynamic software updating for c</title>
		<author>
			<persName><forename type="first">I</forename><surname>Neamtiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stoyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Oriol</surname></persName>
		</author>
		<idno type="DOI">10.1145/1133981.1133991</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM SIGPLAN Conference on Programming Language Design and Implementation, ser. PLDI &apos;06</title>
		<meeting>the 27th ACM SIGPLAN Conference on Programming Language Design and Implementation, ser. PLDI &apos;06<address><addrLine>Ottawa, Ontario, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="72" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">From global to local quiescence: Wait-free code patching of multi-threaded processes</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rommel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dietrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Friesel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>K?ppen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Borchert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Spinczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lohmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th Symposium on Operating System Design and Implementation (OSDI &apos;20)</title>
		<imprint>
			<date type="published" when="2020-11">Nov. 2020</date>
			<biblScope unit="page" from="651" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multiverse: Compiler-assisted management of dynamic variability in low-level system software</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rommel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dietrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rodin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lohmann</surname></persName>
		</author>
		<idno type="DOI">10.1145/3302424.3303959</idno>
	</analytic>
	<monogr>
		<title level="m">Fourteenth EuroSys Conference 2019 (EuroSys &apos;19)</title>
		<meeting><address><addrLine>Dresden, Germany; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<idno>2023-01-03</idno>
		<ptr target="http://www.cmake.org/" />
		<title level="m">CMake -Cross platform make</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Elf(5) -format of exectuable and linking format (ELF) files, Linux Progammer&apos;s Manual</title>
		<ptr target="https://man7.org/linux/man-pages/man5/elf.5.html" />
		<imprint>
			<date type="published" when="2021-03">Mar. 2021</date>
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Lld -The Llvm</forename><surname>Linker</surname></persName>
		</author>
		<ptr target="https://lld.llvm.org/" />
		<imprint/>
	</monogr>
	<note>visited on 01/03/2023</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Big. little processing with arm cortexa15 &amp; cortex-a7: Improving energy efficiency in highperformance mobile platforms</title>
		<author>
			<persName><forename type="first">P</forename><surname>Greenhalgh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>white paper, ARM Ltd</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Harnessing energy efficiency of heterogeneous-isa platforms</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barbalace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ravindran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="65" to="69" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">HECTOR-V: A heterogeneous CPU architecture for a secure RISC-V execution environment</title>
		<author>
			<persName><forename type="first">P</forename><surname>Nasahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schilling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Werner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mangard</surname></persName>
		</author>
		<idno type="DOI">10.1145/3433210.3453112</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security, ser. ASIA CCS &apos;21, Virtual Event</title>
		<meeting>the 2021 ACM Asia Conference on Computer and Communications Security, ser. ASIA CCS &apos;21, Virtual Event<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">9781450382878</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Exploring heterogeneous-isa core architectures for high-performance and energy-efficient mobile socs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sunwoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Emmons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gerstlauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>John</surname></persName>
		</author>
		<idno type="DOI">10.1145/3060403.3060408</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the on Great Lakes Symposium on VLSI 2017, ser. GLSVLSI &apos;17</title>
		<meeting>the on Great Lakes Symposium on VLSI 2017, ser. GLSVLSI &apos;17<address><addrLine>Banff, Alberta, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="419" to="422" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Operating system support for overlapping-isa heterogeneous multi-core architectures</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Knauerhase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koufaty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hahn</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2010.5416660</idno>
	</analytic>
	<monogr>
		<title level="m">HPCA -16 2010 The Sixteenth International Symposium on High-Performance Computer Architecture</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Flick: Fast and lightweight isa-crossing call for heterogeneous-isa environments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madaminov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milder</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISCA45697.2020.00026</idno>
	</analytic>
	<monogr>
		<title level="m">2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="187" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Popcorn: Bridging the programmability gap in heterogeneous-isa platforms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Barbalace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sadini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ansary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jelesnianski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kendir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ravindran</surname></persName>
		</author>
		<idno type="DOI">10.1145/2741948.2741962</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth European Conference on Computer Systems, ser. EuroSys &apos;15</title>
		<meeting>the Tenth European Conference on Computer Systems, ser. EuroSys &apos;15<address><addrLine>Bordeaux, France</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Gprof: A call graph execution profiler</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Kessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Mckusick</surname></persName>
		</author>
		<idno type="DOI">10.1145/872726.806987</idno>
	</analytic>
	<monogr>
		<title level="j">SIGPLAN Not</title>
		<idno type="ISSN">0362-1340</idno>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="120" to="126" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><surname>Redislabs</surname></persName>
		</author>
		<ptr target="https://github.com/RedisLabs/memtier_benchmark" />
		<title level="m">Memtier benchmark on github</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sok: Sanitizing for security</title>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lettner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rajasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Volckaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Franz</surname></persName>
		</author>
		<idno type="DOI">10.1109/SP.2019.00010</idno>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1275" to="1295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Taming undefined behavior in llvm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Hur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Majnemer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Regehr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Lopes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="633" to="647" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Sysbench -scriptable database and system performance benchmark</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kopytov</surname></persName>
		</author>
		<ptr target="https://github.com/akopytov/sysbench" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Experimental study of memory allocation for high-performance query processing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Durner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Leis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Very Large Databases (VLDB)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Dymos: A dynamic modification system</title>
		<author>
			<persName><forename type="first">I</forename><surname>Lee</surname></persName>
		</author>
		<ptr target="www.cis.upenn.edu/~lee/mydissertation.doc" />
		<imprint>
			<date type="published" when="1983">1983</date>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin-Madison</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Dynamic software updating</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nettles</surname></persName>
		</author>
		<idno type="DOI">10.1145/381694.378798</idno>
	</analytic>
	<monogr>
		<title level="j">SIGPLAN Not</title>
		<idno type="ISSN">0362-1340</idno>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="13" to="23" />
			<date type="published" when="2001-05">May 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Segmentation and the design of multiprogrammed computer systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Dennis</surname></persName>
		</author>
		<idno type="DOI">10.1145/321296.321310</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<idno type="ISSN">0004-5411</idno>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="589" to="602" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<ptr target="https://cdrdv2.intel.com/v1/dl/getContent/671200" />
		<title level="m">Intel? 64 and ia-32 architectures software developer&apos;s manual, combined volumes: 1</title>
		<imprint>
			<date type="published" when="2022">2a, 2b, 2c, 2d, 3a, 3b, 3c, 3d and 4. 2022</date>
		</imprint>
		<respStmt>
			<orgName>Intel Corporation</orgName>
		</respStmt>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Immediate multithreaded dynamic software updates using stack reconstruction</title>
		<author>
			<persName><forename type="first">K</forename><surname>Makris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Bazzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on USENIX Annual Technical Conference, ser. USENIX &apos;09</title>
		<meeting>the 2009 Conference on USENIX Annual Technical Conference, ser. USENIX &apos;09<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="31" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Getting started with As-pectJ</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kiczales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hilsdale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hugunin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kersten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Palm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Griswold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="page" from="59" to="65" />
			<date type="published" when="2001-10">Oct. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Pin -a dynamic binary instrumentation tool</title>
		<ptr target="https://software.intel.com/sites/landingpage/pintool/docs/98650/Pin/doc/html/index.html" />
		<imprint>
			<date type="published" when="2022">2022</date>
			<pubPlace>Santa Clara, California, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>tel Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Pwin -pwning intel pin: Why dbi is unsuitable for security applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhechev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bierbaumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kittel</surname></persName>
		</author>
		<editor>Computer Security, J. Lopez, J. Zhou, and M. Soriano</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="volume">ISBN</biblScope>
			<biblScope unit="page" from="978" to="981" />
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">The risc-v instruction set manual, volume i: Unpriviledged isadocument version</title>
		<editor>A. Waterman and K. Asanovi?</editor>
		<imprint>
			<date type="published" when="2019">20191213. Dec. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An automatic overlay generator</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cytron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Loewner</surname></persName>
		</author>
		<idno type="DOI">10.1147/rd.306.0603</idno>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="603" to="608" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Operating systems: Program overlay techniques</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Pankhurst</surname></persName>
		</author>
		<idno type="DOI">10.1145/362896.362923</idno>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<idno type="ISSN">0001-0782</idno>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="125" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A performance model and code overlay generator for scratchpad enhanced embedded processors</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ghadge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kadne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Chatha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighth IEEE/ACM/IFIP international conference on Hardware/software codesign and system synthesis</title>
		<meeting>the eighth IEEE/ACM/IFIP international conference on Hardware/software codesign and system synthesis</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Automatic code overlay generation and partially redundant code fetch elimination</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Egger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ryu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Architecture and Code Optimization (TACO)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Aspectoriented programming</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kiczales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lamping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mendhekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Loingtier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Irwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th European Conference on Object-Oriented Programming (ECOOP &apos;97)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Aksit</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Matsuoka</surname></persName>
		</editor>
		<meeting>the 11th European Conference on Object-Oriented Programming (ECOOP &apos;97)</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1997-06">Jun. 1997</date>
			<biblScope unit="volume">1241</biblScope>
			<biblScope unit="page" from="220" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Dynamic weaving for aspect-oriented programming</title>
		<author>
			<persName><forename type="first">A</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Alonso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Conference on Aspect-Oriented Software Development (AOSD &apos;02)</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Kiczales</surname></persName>
		</editor>
		<meeting>the 1st International Conference on Aspect-Oriented Software Development (AOSD &apos;02)<address><addrLine>Enschede, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002-04">Apr. 2002</date>
			<biblScope unit="page" from="141" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Dynamic aspectc++: Generic advice at any time</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tartler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lohmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Schr?der-Preikschat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Spinczyk</surname></persName>
		</author>
		<idno type="DOI">10.3233/978-1-60750-049-0-165</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on New Trends in Software Methodologies, Tools and Techniques (SoMeT &apos;09)</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Fujita</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Mar?k</surname></persName>
		</editor>
		<meeting>the 2009 Conference on New Trends in Software Methodologies, Tools and Techniques (SoMeT &apos;09)<address><addrLine>Prague, Czech Republic; Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="165" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Function multi-versioning in gcc 6</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Duenas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Stupachenko</surname></persName>
		</author>
		<ptr target="https://lwn.net/Articles/691932/" />
		<imprint>
			<date type="published" when="2016-06">Jun. 2016</date>
		</imprint>
	</monogr>
	<note>visited on 01/10/2023</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Creating fat binary programs</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Inc</surname></persName>
		</author>
		<ptr target="https://developer.apple.com/library/archive/documentation/mac/runtimehtml/RTArch-87.html" />
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note>Online. visited on 01/11/2023</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Mac OS X Internals: A Systems Approach: A Systems Approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Addison Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Universal binaries for linux</title>
		<author>
			<persName><surname>Fatelf</surname></persName>
		</author>
		<ptr target="https://icculus.org/fatelf/" />
		<imprint/>
	</monogr>
	<note>Available. visited on 01/11/2023</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Something common about ms-dos and cp/m</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wilkinson</surname></persName>
		</author>
		<ptr target="https://www.heco.wxwilki.com/commscpm.html" />
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>visited on 01/11/2023</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Method and apparatus for architecture independent executable files</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tevanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Demoney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Enderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Snyder</surname></persName>
		</author>
		<ptr target="https://patents.google.com/patent/US5432937A/en" />
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Method and apparatus for architecture independent executable files</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tevanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Demoney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Enderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Snyder</surname></persName>
		</author>
		<ptr target="https://patents.google.com/patent/US5604905/en" />
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Platform-independent programs</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brumley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Lipton</surname></persName>
		</author>
		<idno type="DOI">10.1145/1866307.1866369</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM Conference on Computer and Communications Security, ser. CCS &apos;10</title>
		<meeting>the 17th ACM Conference on Computer and Communications Security, ser. CCS &apos;10<address><addrLine>Chicago, Illinois, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="547" to="558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Pe format -win32 apps, en-us</title>
		<author>
			<persName><forename type="first">B</forename></persName>
		</author>
		<ptr target="https://learn.microsoft.com/en-us/windows/win32/debug/pe-format" />
		<imprint/>
	</monogr>
	<note>visited on 01/11/2023</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
