<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PUnifiedNER: a Prompting-based Unified NER System for Diverse Datasets</title>
				<funder ref="#_7sRAUbM">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">SenseTime Research</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-11-27">27 Nov 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jinghui</forename><surname>Lu</surname></persName>
							<email>lujinghui1@sensetime.com</email>
							<affiliation key="aff0">
								<orgName type="department">SenseTime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rui</forename><surname>Zhao</surname></persName>
							<email>zhaorui@sensetime.com</email>
							<affiliation key="aff0">
								<orgName type="department">SenseTime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Brian</forename><forename type="middle">Mac</forename><surname>Namee</surname></persName>
							<email>brian.macnamee@ucd.ie</email>
							<affiliation key="aff1">
								<orgName type="department">The Insight Centre for Data Analytics</orgName>
								<orgName type="institution">University College Dublin</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University College Dublin</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fei</forename><surname>Tan</surname></persName>
							<email>tanfei@sensetime.com</email>
							<affiliation key="aff0">
								<orgName type="department">SenseTime Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PUnifiedNER: a Prompting-based Unified NER System for Diverse Datasets</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-11-27">27 Nov 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2211.14838v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Much of named entity recognition (NER) research focuses on developing dataset-specific models based on data from the domain of interest, and a limited set of related entity types. This is frustrating as each new dataset requires a new model to be trained and stored. In this work, we present a "versatile" model-the Prompting-based Unified NER system (PUnifiedNER)-that works with data from different domains and can recognise up to 37 entity types simultaneously, and theoretically it could be as many as possible. By using prompt learning, PUnifiedNER is a novel approach that is able to jointly train across multiple corpora, implementing intelligent on-demand entity recognition. Experimental results show that PUnifiedNER leads to significant prediction benefits compared to dataset-specific models with impressively reduced model deployment costs. Furthermore, the performance of PUnifiedNER can achieve competitive or even better performance than state-of-the-art domain-specific methods for some datasets. We also perform comprehensive pilot and ablation studies to support in-depth analysis of each component in PUnifiedNER.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The Named Entity Recognition (NER) task involves the automatic recognition of entities in text with specific meaning, and so includes both entity extraction and entity classification. The recent rise of transformer-based, pre-trained language models <ref type="bibr" target="#b1">(Devlin et al. 2019;</ref><ref type="bibr" target="#b28">Raffel et al. 2020;</ref><ref type="bibr" target="#b31">Tan et al. 2020</ref><ref type="bibr" target="#b32">Tan et al. , 2021;;</ref><ref type="bibr">Lu et al. 2022a;</ref><ref type="bibr" target="#b25">Mao et al. 2022</ref>) has led to significant performance improvements in NER for various scenarios <ref type="bibr">(Fries et al. 2022;</ref><ref type="bibr" target="#b26">Parmar et al. 2022)</ref>.</p><p>Modern NER models perform self-supervised learning on large unlabelled text datasets to learn generic linguistic representations, and then are fine-tuned for a specific NER task on domain-specific datasets. The output of these approaches, however, is still a single dataset-specific model capable of recognising a few entity types, rather than a "versatile" model that can handle multiple domains and a large number of entity types simultaneously. This is unsatisfactory in practice: for example, an NER model trained on an e-commerce dataset can only extract entity types related to the e-commerce domain such as "company" and "commodity" but not named entities from other domains such as "lo-cation", "organisation", etc. As a result, such NER methods can not scale up well as each new dataset demands a new model to be trained and stored.</p><p>We believe that it is more appealing to have a versatile model handle all scenarios. Besides, a unified model can achieve better performance than dataset-specific models if the unified model can be trained jointly, incorporating label information from different datasets. To be specific, although most NER datasets focus on corpora from various domains with different entity types, the underlying semantics or entity recognition are shared across corpora and exploiting this shared semantic information can enhance model robustness.</p><p>We hypothesise that this enhancement is derived from two aspects: commonality and diversity of label information. The enhancement from commonality refers to the fact that the model can see more relevant phrases from the same entity type. For example, several datasets with the "location" entity can capture most of the keywords belonging to the "location" entity in the real world. The enhancement from diversity means that the model can perceive more polysemous words. For example, "apple" could be a "company" entity (Apple Inc.) in a financial NER dataset, but may be a "commodity" entity (fruit apple) in an e-commerce dataset. Access to both senses during training will potentially strengthen the robustness of a model with regard to the polysemy problem. Moreover, when applying an NER model to specific text, users are not always interested in all of the entity types embedded in the text. Existing NER models typically always output all entity types that they can recognise, which is not an ideal delivery mode. One on-demand model that flexibly recognises requested entity types should be attractive to many users.</p><p>In this work, we develop a versatile model that can handle multiple NER datasets simultaneously, addressing all of the challenges mentioned above -the Prompting-based Unified NER system (PUnifiedNER). Empowered by prompt learning, PUnifiedNER is built upon the recently proposed T5 language model <ref type="bibr" target="#b28">(Raffel et al. 2020)</ref>, and an overview of the model is shown in Figure <ref type="figure" target="#fig_0">1</ref>. We jointly train the model on eight different datasets, supporting a total of 37 entity types. An obvious benefit of a prompting-based design is that the prompts can be served as instructions to guide the model to provide different outputs depending on the entity types of interest to the user, examples of which are shown in the red prompt text on the left panels of Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>In addition to the ability to deal with various entity types and domains, our experimental results show that PUnified-NER can achieve better performance than models of the same architecture trained using single datasets. This is a promising result, as different NER datasets vary greatly in corpus domain, entity annotation, and scale, and it is a difficult challenge to have a single versatile model capable of handling multiple scenarios simultaneously. In other words, joint training on multiple datasets mutually benefits each other rather than degrades each other, which has been viewed as a notorious challenge <ref type="bibr" target="#b21">(Lu et al. 2020;</ref><ref type="bibr" target="#b6">Kamath et al. 2021;</ref><ref type="bibr">Li et al. 2022c</ref>). Furthermore, PUnified-NER is on par with state-of-the-art methods on OntoNotes 4.0 dataset <ref type="bibr" target="#b27">(Pradhan et al. 2013</ref>) and achieves a new state-ofthe-art result on the Resume dataset <ref type="bibr" target="#b41">(Zhang and Yang 2018)</ref>. To conclude, our contributions are as follows:</p><p>? We propose PUnifiedNER a new method that supports the extraction and recognition of up to 37 entity types.</p><p>We also show that given different prompts, the model is able to generate entity types of interest to the user, enabling on-demand entity recognition (Figure <ref type="figure" target="#fig_0">1</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Prompting-based Approaches for NLP: The essence of prompt learning is making better use of pre-trained language model by adding additional "hints" <ref type="bibr">(Liu et al. 2021a;</ref><ref type="bibr" target="#b34">Wang et al. 2022</ref>). Inspired by this, a large number of prompting methods are proposed in the literature to reformulate downstream tasks into pre-training ones to further leverage pretrained language models. These prompting approaches can be categorised according to their model architectures and associated pre-training tasks, including methods based on bidirectional encoder-only models like BERT <ref type="bibr" target="#b30">(Sun et al. 2021;</ref><ref type="bibr">Lu et al. 2022b)</ref>, causal language decoder-only models like GPT-3 <ref type="bibr" target="#b0">(Brown et al. 2020;</ref><ref type="bibr" target="#b35">Xie et al. 2021)</ref>, and encoderdecoder models like T5 <ref type="bibr" target="#b8">(Khashabi et al. 2020;</ref><ref type="bibr" target="#b10">Lester, Al-Rfou, and Constant 2021)</ref>.</p><p>There are also some studies exploring using prompting to unify various tasks, which is inline with our usage of prompting. However, they focus on various classification <ref type="bibr" target="#b10">(Lester, Al-Rfou, and Constant 2021)</ref> or QA tasks <ref type="bibr" target="#b8">(Khashabi et al. 2020</ref>) instead of NER problems.</p><p>Deep Learning Approaches for NER: Most work considers NER as a sequence labelling task, where each token is assigned a pre-defined tag (e.g., BIO scheme). In this line of work, usually deep neural networks such as bidirectional LSTM <ref type="bibr" target="#b41">(Zhang and Yang 2018;</ref><ref type="bibr" target="#b19">Liu et al. 2019)</ref> or pre-trained transformer-based language models <ref type="bibr" target="#b24">(Ma et al. 2020;</ref><ref type="bibr">Liu et al. 2021b</ref>) is combined with Conditional Random Fields (CRF) <ref type="bibr" target="#b9">(Lafferty, McCallum, and Pereira 2001)</ref> and has been widely used in solving flat NER, where neither overlapped entities nor non-adjacent entities will appear in the text.</p><p>Inspired by the success of using deep learning model in flat NER task, many work in the literature attempts to solve nested NER (i.e., entities have overlaps with each other) or discontinuous NER (i.e., entities consist of non-consecutive text sequence) by reformulating the token-level sequence labelling methods used in flat NER to span-level sequence labelling methods <ref type="bibr" target="#b7">(Katiyar and Cardie 2018;</ref><ref type="bibr" target="#b39">Yu, Bohnet, and Poesio 2020;</ref><ref type="bibr" target="#b29">Shen et al. 2021;</ref><ref type="bibr" target="#b12">Li et al. 2021)</ref>, where text spans instead of tokens are enumerated and classified. Seq2Seq model is alsoapplicable for NER, which takes as input a sentence and generates a sequence of entity offsets, span lengths as well as labels <ref type="bibr" target="#b3">(Fei et al. 2021)</ref>.</p><p>There is an important research thread attempting to unify three sub-tasks in NER into one framework. <ref type="bibr">Li et al. (2022a)</ref> propose W 2 NER framework that reframes NER as a wordword relation classification problem and reach the state-ofthe-art performance in 14 NER datasets. <ref type="bibr" target="#b38">Yan et al. (2021)</ref> apply seq2seq model to generate a sequence of entity startend indexes and types. More recently, <ref type="bibr">Lu et al. (2022c)</ref> propose a text-to-structure framework based on seq2seq model to unify not only NER tasks but other information extraction tasks (i.e., event, relation and sentiment extraction).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Differences between PUnifiedNER and Other Unified</head><p>Approaches: Though unifying various sub-tasks, most of existing work essentially tries to build up a dedicated model for every single dataset. The most significant difference is that, we focus on training a versatile model that handles a large scale of entity types as well as datasets simultaneously, which is more compelling.</p><p>Other differences are (1) PUnifiedNER vs. W 2 NER: we reframe NER as seq2seq while W 2 NER recasts NER as word-word relation classification, which is totally different, and PUnifiedNER outperforms W 2 NER in dataset Resume.</p><p>(2) PUnifiedNER vs. other seq2seq-based NER approaches: most seq2seq methods still consider identifying more accurate entity boundaries, thus, the output is entity offsets and span lengths, or entity start-end indexes. PUnifiedNER elegantly generates entity types and corresponding text spans using natural language, which also indicates the potential of tackling nested and discontinuous NER. We leave these explorations for future work. Besides, enhanced by promptlearning, our model implements the on-demand named entity recognition which has not been fully explored in existing studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PUnifiedNER</head><p>Our unified NER system is based on the recent seq2seq frameworks, i.e., T5 <ref type="bibr" target="#b28">(Raffel et al. 2020</ref>). <ref type="foot" target="#foot_0">1</ref> We first present the model architecture and describe how we reframe the NER task on different datasets into a unified seq2seq format with prompts. We then present the datasets used in our experiments. Finally, we detail the way PUnifiedNER is trained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Architecture</head><p>Our model is mainly implemented by reusing the pre-trained T5 model. T5 follows the vanilla transformer encoderdecoder architecture <ref type="bibr" target="#b33">(Vaswani et al. 2017</ref>) with some minor modifications, described in <ref type="bibr" target="#b28">Raffel et al. (2020)</ref>. The encoder, consisting of multiple transformer encoder blocks, uses the bidirectional multi-head self-attention mechanism to encode the input text sequence. The decoder, consisting of multiple transformer decoder blocks, receives the output hidden state from the encoder and uses the unidirectional attention mechanism to autoregressively generate the output text sequence. The predicted token generated at each step is compared to the ground truth token, supervised using a cross entropy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Reframing</head><p>As shown in Figure <ref type="figure" target="#fig_0">1</ref>, we reframe NER as a promptingbased seq2seq problem. Formally, given an original text sequence x, we transform x to a source sequence x input by prefixing it with a series of prompts as follows:</p><p>x input = [s e , s p1 , ..., s e , s pn , s t , x]</p><p>(1)</p><p>where x input is the model input; s e is the special token "&lt;entity&gt;" indicating that the following token is the entity type that we are interested in; s pi is the entity type, e.g., "city"; and s t is the special token "&lt;text&gt;" indicating that the following text sequence is the sentence from which entities should be extracted. Then the target sequence y output is as follows:</p><formula xml:id="formula_0">y output = ((s p1 ) : (ent 1 ), ..., (s pn ) : (ent n )) (2)</formula><p>where y output is the model output; s pi are entity types that are identical to those in Equation <ref type="formula">1</ref>; and ent i is the ground truth texts extracted from the input sequence.</p><p>For example, suppose we have an input x "Tom will go to the zoo tomorrow." and we are interested in entities "time" and "location". Then x input will be "&lt;entity&gt;&lt;time&gt;&lt;entity&gt;&lt;location&gt;&lt;text&gt;Tom will go to the zoo tomorrow." and y output will be "((time):(tomorrow),(location):(zoo))". Alternatively, if we intend to parse entities "name", then x input will be "&lt;en-tity&gt;&lt;name&gt;&lt;text&gt;Tom will go to the zoo tomorrow." and y output will be "((name):(Tom))". In this case, we hope prompts can function well as indicators that suggest which entities users are interested in to steer model produce different entities, even given the same input x (also see example A and B in Figure <ref type="figure" target="#fig_0">1</ref>). Note that if users assign an entity absent in input x, the ent i in y output will be a special token "NULL" (see example C in Figure <ref type="figure" target="#fig_0">1</ref>).</p><p>We argue that this design has several advantages: (1) prompts serve as indicators of target entities as discussed above; (2) unifying entities from different datasets into a single model reduces the cost of model deployment compared to using a dedicated model for each dataset; and</p><p>(3) reusing labelled information of different datasets. Many NER datasets share similar entity types such as "name", "location" and "organisation". Training a model solely on a single dataset can only learn knowledge of the given dataset. PUnifiedNER can exploit the shared knowledge crossing diverse datasets by using prefixed prompting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets</head><p>We train and evaluate PUnifiedNER on eight existing public NER datasets that target various entity types from different domains including social media, e-commerce, datasets. After preprocessing, these datasets provide 37 unique entities. Figure <ref type="figure" target="#fig_1">2</ref> summarises the properties of these entities. They are categorised into four big groups-name, location, organisation, and other-based on their semantic information and three granularities-coarse-grained, fine-grained, and ultra fine-grained. Note that all texts are originally in Chinese, so we provide translations in this paper to facilitate understanding. Additional details of the datasets and entities are provided in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language Model Adaptation</head><p>T5 is pre-trained with "reconstructing" masked spans in the source sequence, which are marked with unique sentinel tokens. The target output sequence consists of several sentinels that are followed by the corresponding masked content. Concretely, given a text "The capital of China is Beijing.", the source sequence of the pre-trained example might be constructed as "The &lt;extra0&gt; of &lt;ex-tra1&gt; is Beijing." and the target sequence will be "&lt;ex-tra0&gt;capital&lt;extra1&gt;China&lt;extra2&gt;" where "&lt;extra i &gt;" are sentinels and the last sentinel ("&lt;extra2&gt;" in this case) 2 People Daily 2014 and Boson datasets are available at https://github.com/hspuppy/hugbert/tree/master/ner_dataset.</p><p>3 https://tianchi.aliyun.com/competition/entrance/531900/information is the end of sequence token.</p><p>Although this pre-training objective works effectively in <ref type="bibr" target="#b28">Raffel et al. (2020)</ref>, we believe that this setup is not good enough to shift the pre-trained model to our downstream prompting-based seq2seq NER task. One main obstacle is the objective gap where the pre-trained T5 has never seen a natural and complete input sequence (i.e., text sequence without sentinels) that is crucial for NER tasks. The NER model needs to extract text spans correctly from the original input given the completed context. Therefore, inspired by the idea of continuously pre-training language models <ref type="bibr" target="#b8">(Khashabi et al. 2020;</ref><ref type="bibr" target="#b21">Lu et al. 2020;</ref><ref type="bibr" target="#b10">Lester, Al-Rfou, and Constant 2021;</ref><ref type="bibr">Lu et al. 2022c)</ref>, we adopt the prefix language modelling objective discussed by <ref type="bibr" target="#b28">Raffel et al. (2020)</ref>; <ref type="bibr" target="#b10">Lester, Al-Rfou, and Constant (2021)</ref> to further adapt the pre-trained language model: we randomly split a given natural text into two substrings and the model must produce the latter substring conditioned on the former substring. For example, given a original sentence "The capital of China is Beijing.", the source input of a pre-trained example might be constructed as "The capital of China" and the target output will be "is Beijing.", respectively.</p><p>We conduct prefix language modelling training based on T5-v1.1-base-chinese over all NER datasets, encouraging the model to close both the objective gap and the domain gap simultaneously. We have found that training using this self-supervised objective can largely close the objective and domain gaps as well as boosting model performance. This is presented in the pilot study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Dataset Joint Learning</head><p>After language model adaptation we adopt a simple, yet effective, multi-dataset learning strategy to train the model: for each batch, we randomly select examples from different datasets until the number of examples is identical to the batch size.</p><p>Note that during multi-dataset training, it is unfeasible to use all entities as prefixed prompts-prefixing all entity prompts results in around 296 extra tokens (avg. 8 for each entity in Chinese) to the input sequence as well as multiple "NULL" tokens in the target output sequence. Therefore, we propose three prefixed prompt setups:</p><p>? Random Prompt: During training, we randomly sample up to all 37 entities as prefixed prompts.</p><p>While during inference, we use all entities of the specific testing dataset as prefixed prompts. For example, the MSRA dataset contains three entitieslocation, organisation, and name-so during inference the prefixed prompts are always "&lt;entity&gt;-&lt;location&gt;&lt;entity&gt;&lt;organisation&gt;&lt;entity&gt;&lt;name&gt;&lt;te-xt&gt;". The effectiveness of these three prefixed prompt settings is explored in the ablation study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pilot Study: The Benefits of Language Model Adaptation</head><p>We first ask a question: Is it necessary to apply language model adaptation before multi-dataset learning? To answer this question, we first train a T5-v1.1-base-chinese checkpoint on the CLUENER dataset using the Dataset-Dependent Prompt approach discussed in previous section.</p><p>The best validation f-score achieved is 48.67 which is far from ideal.</p><p>Then we continuously pre-train T5 model with the prefix language modelling objective over eight public datasets. The training/validation split is the same as the original setting. We also use the sampling strategy discussed in the previous section to construct training batches and continuously pre-train T5 up to 50K steps, evaluating every 1K steps (other training details are provided in the Appendix). Figure <ref type="figure">3</ref> shows the prefix language modelling validation loss for the eight datasets. We find that for most datasets, the model achieves the lowest validation loss with at least 5K steps.</p><p>Finally, we select the model after 6K steps, which has on average a lower validation loss across all eight datasets, and retrain it with the CLUENER dataset. The best validation f-score is 74.78, outperforming the previous f-score of 48.67 by a large margin. This demonstrates the necessity and effectiveness of applying language model adaptation to close the gap between T5 pre-training and downstream prompting-based seq2seq NER tasks. Given the benefit brought by language model adaptation, we will use the model at prefix language modelling step 6K as our backbone model unless otherwise stated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments Comparison to Single Dataset Performance</head><p>Our intention is to answer the question: Can a jointly trained PUnifiedNER model learn shared information among datasets and hence outperform seq2seq NER models trained on single datasets?</p><p>As with the pilot study, we first establish baseline performance of single-dataset training by fine-tuning the T5 backbone on each NER dataset independently. The finetuning procedure is the same as discussed in the pilot study. Then we jointly train another T5 backbone on multiple NER datasets using Dataset-Dependent Prompt settings and the same sampling strategy to construct batches described in the pilot study. For single-dataset training, we select the best performing model on a validation set and report its test f-score. For multi-dataset training, we select the model with best mean f-score on all eight NER datasets and report its test f-scores on each dataset separately. Other hyperparameters settings are detailed in the Appendix.</p><p>Experimental results are shown in Table <ref type="table" target="#tab_2">1</ref>. It shows a clear pattern that the jointly trained PUnifiedNER model can learn shared information between datasets, surpassing single-dataset trained models by an average improvement of 1.33 points. To be specific, in six out of eight datasets, PUni-fiedNER exceeds its single-dataset trained counterparts by a large margin especially in OntoNotes 4.0 (82.56 vs. 78.44), <ref type="bibr">Resume (97.18 vs. 93.91)</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison to State-of-the-art Approaches</head><p>In Table <ref type="table" target="#tab_3">2</ref> we compare the performance of PUnifiedNER with recent state-of-the-art approaches, as well as other flat NER approaches including Lattice LSTM <ref type="bibr" target="#b41">(Zhang and Yang 2018)</ref>, TENER <ref type="bibr" target="#b37">(Yan et al. 2019)</ref>, LGN <ref type="bibr" target="#b5">(Gui et al. 2019)</ref>, FLAT <ref type="bibr" target="#b16">(Li et al. 2020)</ref>, SoftLexicon <ref type="bibr" target="#b24">(Ma et al. 2020)</ref>, and</p><p>LEBERT <ref type="bibr">(Liu et al. 2021b)</ref>. We draw special comparison with the recent W 2 NER approach <ref type="bibr">(Li et al. 2022b)</ref> as it demonstrates very strong performance on several Chinese NER datasets. We also compare PUnifiedNER with DML-NEZHA-Large<ref type="foot" target="#foot_1">4</ref> and NEZHA-BC <ref type="bibr" target="#b40">(Zhang et al. 2022</ref>) since they achieve state-of-the-art results for the CLUENER and Ecommerce datasets, respectively. Our single multi-dataset jointly trained model achieves competitive performance with these state-of-the-art dataset-specific models in two out of five datasets. In particular, on the Resume dataset, PUni-fiedNER surpasses the state-of-the-art (96.65 -&gt; 97.18). Though the performance of PUnifiedNER is less satisfactory for some datasets e.g., MSRA, we should keep in mind that PUnifiedNER is a single model for diverse datasets while the other methods train dedicated models for each dataset, which means more resources are required when deploying models in realistic situations. To be specific, W 2 NER and DML-NEZHA-Large are based on BERT-Base (110 million parameters) or BERT-Large (340 million parameters) and include additional layers (e.g., Convolution Layer and Co-Predictor Layer in <ref type="bibr">Li et al. (2022b)</ref>). Specifically, if we need to deploy an NER model for N datasets, the number of model parameters is at least N * 340 million. However, if we use PUnifiedNER, the number of model parameters is equal to the number of T5-base parameters, i.e., 220 million, which is N * 1.55 times smaller than in W 2 NER (BERT-Large version) or DML-NEZHA-Large. Also, as reported in previous work <ref type="bibr" target="#b28">(Raffel et al. 2020;</ref><ref type="bibr" target="#b10">Lester, Al-Rfou, and Constant 2021;</ref><ref type="bibr">Lu et al. 2022c</ref>), increasing the model size of T5 architecture can further improve performance. Thus, we believe that PUnifiedNER is able to compensate the performance if we change the backbone to T5-Large/XL/XXL without significant increase in the number of parameters needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Study</head><p>Ablations on Prefixed Prompts Setups: To verify our prefixed prompt design choices, we perform ablations for different prefixed prompt settings as discussed in the pilot study and report results on five datasets: MSRA, OntoNotes 4.0, Resume, CLUENER and CCKS2021.</p><p>The results are shown in Table <ref type="table" target="#tab_4">3</ref>. We also report overall average performance in the rightmost column. Our default setting is Dataset-Dependent Prompt. We compare this with two ablations: Random Prompt and Random Prompt+Exact Match. We observe that Dataset-Dependent Prompt leads to much better performance compared to Random Prompt (avg. 85.83 vs. 73.24) and Random Prompt+Exact <ref type="bibr">Match (avg. 85.83 vs. 72.31)</ref>. This makes sense since Exact Match suffers from information leakage in training, thus the performance degrades during inference. While Random Prompt results in too many "NULL" examples with few or even zero positive examples where the model learns nothing about ground truth. Dataset-Dependent Prompt is more useful in balancing positive and "NULL" examples, reducing the risk of information leakage and improving data efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablations on Language Model Adaptation Steps:</head><p>The pilot study has shown that language model adaptation can largely close the objective gap and boost downstream task performance on the prompting-based seq2seq NER task. In this subsection, we go a step further to verify whether selecting the model with lowest validation loss on language model adaptation can benefit the downstream multi-dataset joint learning. We perform another multi-dataset joint training with all eight NER datasets based on model after 10k steps and after 50K steps (full training). All training settings are the same as described in the pilot study. Other hyper-parameters settings are presented in the Appendix.</p><p>Table <ref type="table" target="#tab_5">4</ref> shows the results where our default setting of 6K steps surpasses the other two settings: after 10K steps <ref type="bibr">(avg. 84.82 vs. 84.25) and after 50K steps (avg. 84.82 vs. 84.51)</ref>. This demonstrates that selecting the model with the lowest validation loss is a useful approach. However, other settings outperform the default for some datasets. For example, the model after 50K steps achieves an f-score of 97.24, which is a new state-of-the-art for the Resume dataset. We notice from Figure <ref type="figure">3</ref> that the model after 50K steps has a high validation loss as compared to the model after 6K steps for the Resume dataset , which suggests that validation loss might not be the only model selection criterion that should be used. We leave this exploration for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>On-demand Named Entity Recognition</head><p>Our code and a demo interface for PUnifiedNER have been made available,<ref type="foot" target="#foot_2">5</ref> which demonstrates the capability of ondemand named entity recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this work, we present a novel Prompting-based Unified NER system (PUnifiedNER) that can recognise a large set of entity types in data from various domains and support on-demand entity recognition. To achieve this, we first recast the NER task to a seq2seq task where a prefix language modelling objective is introduced to reduce the gap between pre-training and fine-tuning. A pilot study shows that prefix language modelling is very effective in adapting pre-trained language models. Dataset-Dependent Prompt is designed to unify data from all datasets into a united format that enables joint training crossing multiple datasets for PUnified-NER. Besides on-demand named entity recognition, experimental results show that the multi-dataset training empowered by prompting can also lead to significant performance gains over single-dataset training, while dramatically reducing model deployment cost. Further, the jointly trained PUnifiedNER model sets a new state-of-the-art performance level for the Resume dataset, and is comparable to other state-of-the-art dataset-specific NER methods in some cases. Lastly, extensive ablation studies are performed to clarify the design choices of PUnifiedNER.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An overview of PUnifiedNER which reframes NER as a seq2seq task where red texts are prompts to suggest which entities users are interested in. For the same text input, PUnifiedNER returns different results conditioned on prefixed prompts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Properties of 37 entities provided by eight public NER datasets. All entities are manually categorised into four groups, i.e., name, location, organisation, and others. Entities in the same quadrant fall into the same group. Entities in different colors indicate different entity granularity, i.e., blue (coarse-grained), green (fine-grained) and yellow (ultra fine-grained). Note that the manually crafted granularity/category information in this figure is for a better visualisation and is not leveraged in model training.</figDesc><graphic url="image-1.png" coords="4,72.45,54.00,201.60,190.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Figure3: Prefix language modelling validation loss on eight datasets. Loss is log scaled to make trends more noticeable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>information leakage where ground truth entities can help the model narrow down the entity space to reduce difficulty during training, we do not use Exact Match during inference. Thus it is still a fair comparison. Also, we hope the use of Random Prompt can partially alleviate the information leakage problem.? Dataset-Dependent Prompt: Training and inference both use all entities from the specific dataset as prefixed prompts.</figDesc><table><row><cell>? Random Prompt + Exact Match: During training, each</cell></row><row><cell>original example is prefixed in two styles (therefore two</cell></row><row><cell>training examples are generated), one using Random</cell></row></table><note><p>Prompt as discussed above, and the other using the exact entities from the ground truth as prefixed prompts (i.e., Exact Match). During inference, we use all entities of the specific testing dataset as prefixed prompts. Though this setting suffers from</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>and CLUENER (77.00 vs. 74.57), and with a reasonable improvement in Ecommerce (71.32 Comparison of PUnifiedNER to single-dataset training. "*" indicates that this dataset does not contain the test set, thus we report the results of validation set.</figDesc><table><row><cell>Methods</cell><cell cols="9">MSRA* OntoNotes Resume CLUENER Ecommerce People Daily Boson CCKS2021* Avg.</cell><cell># models</cell></row><row><cell cols="2">Single-Dataset Training 87.78</cell><cell>78.44</cell><cell>93.91</cell><cell>74.57</cell><cell>69.38</cell><cell>96.99</cell><cell>82.60</cell><cell>84.26</cell><cell cols="2">83.49 8</cell></row><row><cell>PUnifiedNER</cell><cell>87.07</cell><cell>82.56</cell><cell>97.18</cell><cell>77.00</cell><cell>71.32</cell><cell>94.49</cell><cell>83.58</cell><cell>85.34</cell><cell cols="2">84.82 1</cell></row><row><cell cols="2">Flat NER Methods</cell><cell></cell><cell cols="8">MSRA OntoNotes Resume CLUENER Ecommerce # Params</cell></row><row><cell cols="4">Lattice LSTM (Zhang and Yang 2018) 93.18</cell><cell>73.88</cell><cell>94.46</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell></row><row><cell cols="2">TENER (Yan et al. 2019)</cell><cell></cell><cell>92.74</cell><cell>72.43</cell><cell>95.00</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell></row><row><cell cols="2">LGN (Gui et al. 2019)</cell><cell></cell><cell>93.71</cell><cell>74.45</cell><cell>95.11</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell></row><row><cell cols="2">FLAT (Li et al. 2020)</cell><cell></cell><cell>96.09</cell><cell>81.82</cell><cell>95.86</cell><cell>-</cell><cell>-</cell><cell></cell><cell>N*110M</cell></row><row><cell cols="3">SoftLexicon (Ma et al. 2020)</cell><cell>95.42</cell><cell>82.81</cell><cell>96.11</cell><cell>-</cell><cell>-</cell><cell></cell><cell>N*110M</cell></row><row><cell cols="3">LEBERT (Liu et al. 2021b)</cell><cell>95.70</cell><cell>82.08</cell><cell>96.08</cell><cell>-</cell><cell>-</cell><cell></cell><cell>N*110M</cell></row><row><cell cols="3">State-of-the-art Methods</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">W 2 NER (Li et al. 2022b)</cell><cell></cell><cell>96.40</cell><cell>83.08</cell><cell>96.65</cell><cell>-</cell><cell>-</cell><cell></cell><cell>N*110M</cell></row><row><cell cols="3">NEZHA-BC (Zhang et al. 2022)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">78.69</cell><cell>N*110M</cell></row><row><cell cols="2">DML-NEZHA-Large</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>83.30</cell><cell>-</cell><cell></cell><cell>N*340M</cell></row><row><cell>Our Method</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>PUnifiedNER</cell><cell></cell><cell></cell><cell>87.07</cell><cell>82.56</cell><cell>97.18</cell><cell>77.00</cell><cell cols="2">71.32</cell><cell>1*220M</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Comparison of the performance of PUnifiedNER to recent state-of-the-art methods. All state-of-the-art methods are dataset-specific models. Estimated number of parameters used for model deployment in realistic scenarios are shown in the rightmost column, where N is the number of datasets. The number of parameters for some methods are estimated from the corresponding paper.</figDesc><table><row><cell>Prompt</cell><cell cols="6">MSRA OntoNotes Resume CLUENER CCKS2021 Avg. Score</cell></row><row><cell>Random Prompt</cell><cell>69.93</cell><cell>46.88</cell><cell>95.48</cell><cell>69.62</cell><cell>84.30</cell><cell>73.24</cell></row><row><cell cols="2">Random Prompt + Exact Match 69.21</cell><cell>55.47</cell><cell>90.20</cell><cell>66.30</cell><cell>80.37</cell><cell>72.31</cell></row><row><cell>Dataset-Dependent Prompt</cell><cell>87.07</cell><cell>82.56</cell><cell>97.18</cell><cell>77.00</cell><cell>85.34</cell><cell>85.83</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Ablations on our Prefixed Prompts design choices.</figDesc><table><row><cell>Step</cell><cell cols="9">MSRA OntoNotes Resume CLUENER CCKS2021 Ecommerce People Daily Boson Avg. Score</cell></row><row><cell>Step 6K</cell><cell>87.07</cell><cell>82.56</cell><cell>97.18</cell><cell>77.00</cell><cell>85.34</cell><cell>71.32</cell><cell>94.49</cell><cell>83.58</cell><cell>84.82</cell></row><row><cell cols="2">Step 10K 86.94</cell><cell>82.09</cell><cell>96.62</cell><cell>76.16</cell><cell>86.01</cell><cell>71.23</cell><cell>95.27</cell><cell>79.69</cell><cell>84.25</cell></row><row><cell cols="2">Step 50K 86.64</cell><cell>81.86</cell><cell>97.24</cell><cell>75.21</cell><cell>84.83</cell><cell>70.52</cell><cell>96.95</cell><cell>82.84</cell><cell>84.51</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Ablations on language model adaptation steps.</figDesc><table><row><cell>vs. 69.38), Boson (83.58 vs 82.60) and CCKS2021 (85.34</cell><cell>Fine-grained Analysis: We further report fine-grained</cell></row><row><cell>vs. 84.26). In MSRA, the performance of PUnifiedNER is</cell><cell>named entity f-scores for the Boson and Resume datasets in</cell></row><row><cell>also comparable. The only exception is the People Daily</cell><cell>Figure 4. First, for the Boson dataset the f-score achieved by</cell></row><row><cell>2014 dataset where the single-dataset trained model exceeds</cell><cell>PUnifiedNER for almost all entity types is improved com-</cell></row><row><cell>PUnifiedNER by 2.5 points. Given the fact that the People</cell><cell>pared to the corresponding single-training counterpart. This</cell></row><row><cell>Daily 2014 dataset includes more than 400K instances, we</cell><cell>is consistent to our expectation because all entity types in</cell></row><row><cell>believe that PUnifiedNER suffers from insufficient training</cell><cell>Boson have appeared in other datasets and joint training can</cell></row><row><cell>regarding the People Daily 2014 dataset. This is probably</cell><cell>take advantage of "seeing" more data. It is surprising to find</cell></row><row><cell>because we select the checkpoint that is generally useful</cell><cell>out that the prompting-based joint training can also bring ad-</cell></row><row><cell>for all datasets according to performance on validation sets,</cell><cell>ditional discriminative ability for entity types that only ap-</cell></row><row><cell>where models are converged in all datasets other than People</cell><cell>pear in one dataset, which is evidenced by the f-scores for</cell></row><row><cell>Daily 2014. In our follow-up observations, we found that the</cell><cell>the Education and Profession entities in the Resume dataset</cell></row><row><cell>validation set performance of the PUnifiedNER model was</cell><cell>as shown in Figure 4(b).</cell></row><row><cell>still improving after the "best" checkpoint, and more details</cell><cell></cell></row><row><cell>can be seen in the Appendix. We suspect that this can be</cell><cell></cell></row><row><cell>alleviated by some multi-training strategies such as Curricu-</cell><cell></cell></row><row><cell>lum Learning and Dynamic Stop-and-Go (Lu et al. 2020),</cell><cell></cell></row><row><cell>which we will address in future work.</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We use the T5-v1.1-base-chinese checkpoint pretrained by UER: https://huggingface.co/uer/t5-base-chinesecluecorpussmall.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>State-of-the-art performance is reported at https://www. cluebenchmarks.com/ner.html as of July 1st, 2022.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>All resources are available at: https://github.com/ GeorgeLuImmortal/PUnifiedNER.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="person">Hongyu Lin</rs> from <rs type="affiliation">Chinese Academy of Sciences</rs> for his thoughtful discussion, as well as the many others who have helped. We would also like to thank anonymous reviewers for their insightful comments to help improve the paper. This publication has emanated from research conducted with the support of <rs type="funder">SenseTime Research</rs>.</p></div>
			</div>
			<div type="funding">
<div><p>C.&lt;entity&gt;company&lt;entity&gt;name&lt;text&gt;The G-League 2011 Season 1 offline finals hosted by XX Games came to a shocking end at <rs type="affiliation">Century Square on Nanjing Road Pedestrian Street in Shanghai's Huangpu District</rs>. B.&lt;entity&gt;city&lt;entity&gt;poi&lt;text&gt;The G-League 2011 Season 1 offline finals hosted by XX Games came to a shocking end at <rs type="affiliation">Century Square on Nanjing Road Pedestrian Street in Shanghai's Huangpu District</rs>. A.&lt;entity&gt;location&lt;text&gt;The G-League 2011 Season 1 offline finals hosted by XX Games came to a shocking end at <rs type="affiliation">Century Square on Nanjing Road Pedestrian Street in Shanghai's Huangpu District</rs>.</p><p>PUnifiedNER A.((location):(<rs type="projectName">Century Square on Nanjing Road Pedestrian Street in Shanghai's Huangpu District</rs>)) C.((company):(XX Games),(name):(NULL))</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_7sRAUbM">
					<orgName type="project" subtype="full">Century Square on Nanjing Road Pedestrian Street in Shanghai&apos;s Huangpu District</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For some tags that are hard to understand, we provide their meaning in brackets. "#" denotes the amount of entity types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices A Evaluation Metrics</head><p>Regarding evaluation metrics, we follow prior work <ref type="bibr" target="#b38">(Yan et al. 2021;</ref><ref type="bibr">Li et al. 2022b;</ref><ref type="bibr">Lu et al. 2022c</ref>) and employ macro F1-score. A predicted entity is counted as true positive only if its text span and entity types match those of a gold entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Dataset Statistics</head><p>We evaluate our framework on 8 Chinese flat NER datasets. In Table <ref type="table">5</ref>, we present the detailed statistics. The details of entity type of each dataset is presented in Table <ref type="table">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Implementation Details</head><p>In this section, we provide more details of our experiments. Hyper-parameter settings are listed in Table <ref type="table">7</ref>. We adopt AdamW <ref type="bibr" target="#b20">(Loshchilov and Hutter 2018)</ref> optimizer. Our model is implemented with PyTorch, language model adaptation is trained with 24 NVIDIA 1080Ti GPUs, multi-dataset training is trained with 8 Tesla V100 GPUs. Note that we use beam width equals to 5 in evaluation but 10 in testing. Single-dataset training is trained with one Tesla V100 GPU and we use beam width equals to 10 for both evaluation and testing. Hyper-parameter tuning is based on validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Multi-dataset Joint Training Performance on Validation Set</head><p>The validation macro f-score of each checkpoint is presented in Figure <ref type="figure">5</ref>. We select checkpoint on step 30K since it is generally ideal for all datasets. However, we can observe that after the chosen checkpoint, the validation performance on People Daily 2014 (the red line) consistently increases and reaches the best f-score at step 100K. This explains the suboptimal performance of PUnifiedNER on dataset People Daily 2014.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Language Models are Few-Shot Learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><surname>Balcan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter<address><addrLine>Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Minneapolis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A neural multi-digraph model for Chinese NER with gazetteers</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2019</title>
		<meeting>the ACL 2019</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1462" to="1467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Rethinking boundaries: End-to-end recognition of discontinuous mentions with pointer networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="12785" to="12793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Seelam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Altay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kusa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cahyawijaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Barth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Samwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>S?nger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Callahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Peri??n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gigant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Posada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Sivaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>P?mies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nezhurina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cullan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Freidank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dahlberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Broad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Labrak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Deshmukh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kiblawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Neeraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Golde</surname></persName>
		</author>
		<imprint>
			<publisher>del Moral</publisher>
		</imprint>
	</monogr>
	<note>and Beilharz, B. 2022. BigBIO: A Framework for Data-Centric Biomedical Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Lexicon-Based Graph Neural Network for Chinese NER</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1040" to="1050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">MDETR-modulated detection for endto-end multi-modal understanding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Carion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1780" to="1790" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Nested Named Entity Recognition Revisited</title>
		<author>
			<persName><forename type="first">A</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long Papers</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="861" to="871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">UNIFIEDQA: Crossing Format Boundaries with a Single QA System</title>
		<author>
			<persName><forename type="first">D</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1896" to="1907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning, ICML &apos;01</title>
		<meeting>the Eighteenth International Conference on Machine Learning, ICML &apos;01<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Power of Scale for Parameter-Efficient Prompt Tuning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Online and Punta Cana</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3045" to="3059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Third International Chinese Language Processing Bakeoff: Word Segmentation and Named Entity Recognition</title>
		<author>
			<persName><forename type="first">G.-A</forename><surname>Levow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Fifth SIGHAN Workshop on Chinese Language Processing<address><addrLine>Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="108" to="117" />
		</imprint>
	</monogr>
	<note>Sydney</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Span-Based Model for Joint Overlapped and Discontinuous Named Entity Recognition</title>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2021 and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the ACL 2021 and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4814" to="4828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unified named entity recognition as wordword relation classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="10965" to="10973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unified named entity recognition as wordword relation classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">2022c. Grounded language-image pre-training</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-N</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<biblScope unit="page" from="10965" to="10975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">FLAT: Chinese NER Using Flat-Lattice Transformer</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2020</title>
		<meeting>the ACL 2020</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6836" to="6842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">2021a. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.13586</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Lexicon Enhanced Chinese Sequence Labeling Using BERT Adapter</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2021 and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the ACL 2021 and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5847" to="5858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An Encoding Strategy Based Word-Character LSTM for Chinese NER</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2379" to="2389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Decoupled Weight Decay Regularization</title>
		<author>
			<persName><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">12-in-1: Multi-task vision and language representation learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="10437" to="10446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">2022a. A Rationale-Centric Framework for Human-in-the-loop Machine Learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Namee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6986" to="6996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">What Makes Pre-trained Language Models Better Zero/Few-shot Learners?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mac Namee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2022</title>
		<meeting>the ACL 2022<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5755" to="5772" />
		</imprint>
	</monogr>
	<note>Unified Structure Generation for Universal Information Extraction</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Simplify the Usage of Lexicon in Chinese NER</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2020</title>
		<meeting>the ACL 2020</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5951" to="5960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.03963</idno>
		<title level="m">SDA: Simple Discrete Augmentation for Contrastive Sentence Representation Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">In-BoXBART: Get Instructions into Biomedical Multi-Task Learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Purohit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Baral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: NAACL 2022</title>
		<meeting><address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="112" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Towards Robust Linguistic Analysis using OntoNotes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bj?rkelund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Conference on Computational Natural Language Learning</title>
		<meeting>the Seventeenth Conference on Computational Natural Language Learning<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="143" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Locate and Label: A Two-stage Identifier for Nested Named Entity Recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2021 and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the ACL 2021 and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2782" to="2794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">NSP-BERT: A Prompt-based Zero-Shot Learner Through an Original Pre-training Task-Next Sentence Prediction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qiu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.03564</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">TNT: Text Normalization based Pre-training of Transformers for Content Moderation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4735" to="4741" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">BERT-Beta: A Proactive Probabilistic Approach to Text Moderation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Online and Punta Cana</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8667" to="8675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Super-NaturalInstructions:Generalization via Declarative Instructions on 1600+ Tasks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Alipoormolabashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mirzaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arunkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ashok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Dhanasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">An explanation of in-context learning as implicit bayesian inference</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.02080</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.04351</idno>
		<title level="m">CLUENER2020: finegrained named entity recognition dataset and benchmark for chinese</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">TENER: adapting transformer encoder for named entity recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.04474</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A Unified Generative Framework for Various NER Subtasks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2021 and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the ACL 2021 and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5808" to="5822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Named Entity Recognition as Dependency Parsing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2020</title>
		<meeting>the ACL 2020</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6470" to="6476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Domain-Specific NER via Retrieving Correlated Samples</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Computational Linguistics</title>
		<meeting>the 29th International Conference on Computational Linguistics<address><addrLine>Gyeongju, Republic of Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2398" to="2404" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Chinese NER Using Lattice LSTM</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2018</title>
		<meeting>the ACL 2018<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1554" to="1564" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
