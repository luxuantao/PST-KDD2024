<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HEAX: An Architecture for Computing on Encrypted Data</title>
				<funder ref="#_8NWZdhC #_XyX2acD">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">M</forename><surname>Sadegh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kim</forename><surname>Laine</surname></persName>
							<email>kim.laine@microsoft.com</email>
						</author>
						<author>
							<persName><forename type="first">Blake</forename><surname>Pelton</surname></persName>
							<email>blakep@microsoft.com</email>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Dai</surname></persName>
							<email>wei.dai@microsoft.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">UC San Diego</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">HEAX: An Architecture for Computing on Encrypted Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3373376.3378523</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Fully Homomorphic Encryption; FPGAs</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With the rapid increase in cloud computing, concerns surrounding data privacy, security, and confidentiality also have been increased significantly. Not only cloud providers are susceptible to internal and external hacks, but also in some scenarios, data owners cannot outsource the computation due to privacy laws such as GDPR, HIPAA, or CCPA. Fully Homomorphic Encryption (FHE) is a groundbreaking invention in cryptography that, unlike traditional cryptosystems, enables computation on encrypted data without ever decrypting it. However, the most critical obstacle in deploying FHE at large-scale is the enormous computation overhead.</p><p>In this paper, we present HEAX, a novel hardware architecture for FHE that achieves unprecedented performance improvements. HEAX leverages multiple levels of parallelism, ranging from ciphertext-level to fine-grained modular arithmetic level. Our first contribution is a new highlyparallelizable architecture for number-theoretic transform (NTT) which can be of independent interest as NTT is frequently used in many lattice-based cryptography systems. Building on top of NTT engine, we design a novel architecture for computation on homomorphically encrypted data. Our implementation on reconfigurable hardware demonstrates 164-268? performance improvement for a wide range of FHE parameters. CCS Concepts. ? Security and privacy; ? Hardware;</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Cloud computing has, in a short time, fundamentally changed the economics of computing. It allows businesses to quickly and efficiently scale to almost arbitrary-sized workloads; small organizations no longer need to own, secure, and maintain their own servers. However, cloud computing comes with significant risks that have been analyzed in the literature over the last decade (see <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b39">38,</ref><ref type="bibr" target="#b57">57]</ref>). Specifically, many of these risks revolve around data security and privacy. For example, data in cloud storage might be exposed to both outsider and insider threats, and be prone to both intentional and unintentional misuse by the cloud provider. Recently, the European Union and the State of California have passed strong data privacy regulations. In this light, companies and organizations that possess highly private data are hesitant to migrate to the cloud, and cloud providers are facing increasing liability concerns.</p><p>To mitigate security and privacy concerns, cloud providers should keep customers' data encrypted at all times. Symmetrickey encryption schemes, such as Advanced Encryption Standard (AES) <ref type="bibr" target="#b21">[22]</ref>, allow private data to be stored securely in a public cloud indefinitely. However, unless the customers share their secret keys with the cloud, the cloud becomes merely a storage provider.</p><p>In 2009, a new class of cryptosystems, called Fully Homomorphic Encryption (FHE) <ref type="bibr" target="#b34">[33]</ref>, was introduced that allows arbitrary computation on encrypted data. This groundbreaking invention enables clients to encrypt data and send ciphertexts to a cloud that can evaluate functions on ciphertexts. Final and intermediate results are encrypted, and only the data owner who possesses the secret key can decrypt data, providing end-to-end encryption for the client.</p><p>FHE provides provable security guarantees without any trust assumptions on the cloud provider, and it can be used to enable several secure and privacy-preserving cloud-based solutions. For instance, in the context of Machine Learning as a Service (MLaaS), FHE can be used to perform oblivious neural network inference <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b36">35]</ref>: clients send the encrypted version of their data, the cloud server runs ML models on the encrypted queries, and returns the result to the clients. All intermediate and final results are encrypted and can only be decrypted by the clients. Perhaps, the most critical obstacle today to deploy FHE at large-scale is the enormous computation overhead compared to a plaintext counterpart in which data is not kept confidential.</p><p>Session 14A: Security with little performance loss -Fast and furious! ASPLOS <ref type="bibr">'20, March 16-20, 2020</ref>, Lausanne, Switzerland Most FHE schemes, i.e., BGV <ref type="bibr" target="#b11">[11]</ref>, BFV <ref type="bibr" target="#b31">[31]</ref>, and TFHE <ref type="bibr" target="#b18">[18]</ref> schemes, perform exact computation on encrypted data. A recently proposed FHE scheme called CKKS <ref type="bibr" target="#b17">[17]</ref> performs approximate computation of real numbers and supports efficient truncation of encrypted values. Several works <ref type="bibr" target="#b41">[40,</ref><ref type="bibr" target="#b44">43]</ref> have shown the benefits of choosing the CKKS scheme over other schemes when an approximate computation is required, e.g., in Machine Learning applications. Therefore, we focus on the CKKS scheme in this paper, even though our core modules are applicable to most of the FHE schemes.</p><p>In this paper, we introduce HEAX (stands for Homomorphic Encryption Acceleration): a novel high-performance architecture for computing on (homomorphically) encrypted data. We design several optimized core computation blocks for fast modular arithmetic and introduce a new architecture for high-throughput Number-Theoretic Transform (NTT). Building on top of the NTT module we design modules to perform high-level operations supported by FHE, thus accelerating any FHE-based privacy-preserving system.</p><p>Prior Art and Challenges. One of the main challenges of designing an architecture for FHE is that homomorphic operations on ciphertexts involve computationally intensive modular arithmetic on big integers (with several hundred bits). These operations have convoluted data dependency among different parts of the computation, making it challenging to design a high-throughput architecture. Moreover, the degree of the underlying polynomials is enormous (in the order of several thousand). Storing the entire intermediate results on FPGA chip is prohibitive.</p><p>Prior work that propose customized hardware for non-CKKS schemes have taken one of these approaches: (i) Designing co-processors that only accelerate certain low-level ring operations <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b40">39,</ref><ref type="bibr" target="#b61">61]</ref>; high-level operations are performed on the CPU-side, which makes the coprocessors of limited practical use. (ii) Storing intermediate results on off-chip memory, which significantly degrades the performance <ref type="bibr" target="#b52">[51]</ref> to the extent that it can be worse than naive software execution <ref type="bibr" target="#b54">[53]</ref>. (iii) Designing a hardware for a fixed modest-sized parameter, e.g., n = 2 12  <ref type="bibr" target="#b55">[54]</ref>. However, encryption parameters determine the security-level and the maximum number of consecutive multiplications that one can perform on ciphertext, both of which are applicationdependent. One of our primary design goals in HEAX is to have an architecture that can be readily used for a wide range of encryption parameters.</p><p>Client-Side and Server-Side Computation. Figure <ref type="figure" target="#fig_0">1</ref> illustrates the data flow and the operations involved in a typical application based on FHE. The client encrypts her data and sends the resulting ciphertext to the cloud. The cloud server performs the computation on encrypted data and sends the result back to the client. In order to perform SIMD-style operations, an encoding step is performed by the client to embed many numbers in a single ciphertext. Note that encoding/decoding and encryption/decryption are performed on the client-side. These operations are not computationally expensive; thus, we do not implement customized hardware for these operations. The operations that are performed by the server for evaluating a function on ciphertexts are computationally intensive and are the focus of this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions.</head><p>In what follows, we elaborate on our major contributions in more detail:</p><p>? We design a novel architecture for number-theoretic transform which is a fundamental building block -and usually the computation bottleneck -for many lattice-based cryptosystems including all FHE schemes. Our design can process arbitrary-sized polynomials with an adjustable throughput. We develop several techniques to overcome the challenges due to the complex data-dependency and convoluted access patterns within NTT. ? We introduce the first architecture for CKKS homomorphic encryption. We leverage multi-layer parallelism design starting from ciphertext-level to fine-grained optimized modular arithmetic engines. In contrast to the prior art for other FHE schemes, our architecture can be scaled for different FPGA chips due to its modularity. Moreover, HEAX is not custom-designed for specific FHE parameter set and can be used for a broad range of parameters.  In what follows, we provide more background on CKKS.</p><p>Notation. Throughout the paper, integers and real numbers are written in normal case, e.g. q. Polynomials and vectors are written in bold, e.g. a. Vectors of polynomials and matrices are written in upper-case bold, e.g. A. We use subscripts to denote the indices, e.g. a i is the i-th polynomial or row of A.</p><p>We assume that n is a power-of-two integer and define a polynomial ring R = Z[X ]/(X n + 1) whose elements have degrees at most n-1 since X n = -1 ? R. We write R q = R/qR for the residue ring of R modulo an integer q whose elements have coefficients in [-?(q -1)/2? , ?q/2?] ? Z. In the actual computation, we represent coefficients in [0, q -1] ? Z. We denote by u ? v the multiplication of two polynomials where the product is reduced modulo X n +1 in R and further reduced modulo q in R q . We denote by ?u, v? the dot product of two vectors, which gives</p><formula xml:id="formula_0">i u i ? v i . We denote by u ? v the coefficient-wise multiplication (u 0 ? v 0 , u 1 ? v 1 , . . .).</formula><p>For a real number r , ?r ? denotes the nearest integer to r , and ?r ? is the largest integer smaller than or equal to r . For an integer a, [a] p denotes the reduction of a modulo an integer p to [0, p -1] ? Z. We use a ? ? to denote sampling a according to distribution ? . For a finite set S, U (S) denotes the uniform distribution on S.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Residue Number System (RNS).</head><p>There is a well-known technique to achieve asymptotic/practical improvements in polynomial arithmetic over R q with an RNS by choosing q = L i=0 p i where p i 's are pair-wise coprime integers, based on the ring isomorphism R q ? L i=0 R p i . </p><formula xml:id="formula_1">A = a i = [a] p i 0?i ?L ? L i=0 R p i .</formula><p>The inverse mapping is defined based on the formula a = L i=0 a i ? i ? -1 i p i (mod q), where ? i = q p i . Multiplications or additions in R q , denoted by c = Func(a, b), can be performed on their RNS representation:</p><formula xml:id="formula_2">c i = Func(a i , b i ) in R p i (in parallel), i = 0, 1, . . . , L.</formula><p>Gadget Decomposition. Let g ? Z d be a gadget vector and q an integer. The gadget decomposition, denoted by g -1 , is a function from R q to R d which transforms an element a ? R q into A ? R d , a vector of small polynomials such that a = ?g, A? (mod q). We integrate the RNS-friendly gadget decomposition from <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b37">36]</ref>.</p><p>CKKS Subroutines. We briefly review relevant subroutines: ? CKKS.Setup(?): For a security parameter ?, set a ring size n, a ciphertext modulus q, a special modulus p coprime to q, and a key distribution ? and an error distribution ? over R.</p><p>? CKKS.SymEnc(m, sk): Let m ? R be a given plaintext and sk = s ? R qp be a secret key. Sample a ? U (R qp ) and e ? ?, compute b = -a ? s + e ? R qp , and return the ciphertext ct = (c 0 , c 1 ) = (b, a).</p><p>? CKKS.KeyGen(): Sample s ? ? . Return a secret key sk = s and a public key pk = SymEnc(0, sk).</p><p>? CKKS.KskGen(sk ? , sk): Let sk = s ? R qp be the generated secret key, sk ? = s ? ? R qp be a different key, and a gadget vector g ? Z d . Return a key switching key ksk =</p><formula xml:id="formula_3">(D 0 | D 1 ) ? R (L+2)?2 q ? p , where (d 0,i , d 1,i ) ? SymEnc(? i ? s ? , s) for i = 0, 1, . . . , d -1. ? CKKS.Add(ct 0 , ct 1 ): Given ciphertexts ct 0 , ct 1 ? R 2 q ? en- crypting pt 0 , pt 1 ? R, generate ct ? = ct 0 +ct 1 ? R 2 q ? which is equivalent to the encryption of pt 0 + pt 1 ? R.</formula><p>Two frequently used operations in homomorphic evaluation are modular reduction and modular multiplication: ? Mod(x, p): Used to perform modular reduction of a singleword or double-word integer <ref type="bibr" target="#b9">[9]</ref>. For a modulus p with at most w bits, given an integer x ? 0, (p -1) 2 , precompute u = 2 2w /p , and compute z = x (mod p). Mod(a, p) performs Mod(a i , p) for all i = 0, 1, . . . , n -1.</p><p>? MulRed(x, y, y ? , p): For w-bit words and a modulus p &lt; 2 w -2 , given x, y ? Z p and precomputed y ? = ?y ? 2 w /p?, compute x ? y (mod p) according to Algorithm 1.</p><p>Session 14A: Security with little performance loss -Fast and furious! ASPLOS <ref type="bibr">'20, March 16-20, 2020</ref>, Lausanne, Switzerland</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MULT MODULE</head><p>In this section, we describe our proposed architectures for homomorphic multiplication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Homomorphic Multiplication Algorithm</head><p>This operation is performed in RNS and NTT form. Although in general ciphertexts can have more than two polynomial components, in practice, ciphertexts are usually relinearized and the multiplication is carried out on two components as discussed next. Nevertheless, our proposed architecture is generic and supports any number of components.</p><p>? CKKS.Mul(ct 0 , ct 1 ): Given ciphertexts ct 0 , ct 1 ? R 2 q ? encrypting pt 0 , pt 0 ? R, generate ct ? ? R 3 q ? according to Algorithm 2 which encrypts pt 0 ? pt 1 ? R.</p><p>Algorithm 2 Homomorphic Mult. | CKKS.Mul(ct 0 , ct 1 )</p><formula xml:id="formula_4">Input: ct 0 = ( ?0 , ?1 ), ct 1 = ( B0 , B1 ) ? ( ? i=0 R p i ) 2 Output: ct = ( C0 , C1 , C2 ) ? ( ? i=0 R p i ) 3 1: for (i = 0; i ? ?; i = i + 1) do 2: c0,i ? Mod(? 0,i ? b0,i , p i ) ? Dyadic Core 3: c1,i ? Mod(? 0,i ? b1,i + ?1,i ? b0,i , p i ) 4:</formula><p>c2,i ? Mod(? 1,i ? b1,i , p i ) 5: end for 3.2 HEAX Word Size and Native Operations Microsoft SEAL library <ref type="bibr" target="#b56">[56]</ref> is developed for x86 architectures with 64-bit native operations. However, on FPGAs, the bit-width of Digital Signal Processing (DSP) units that perform multiplication may vary, hence, it is more efficient to have a flexible bit-width for native operations. For example, the two FPGA chips that we have implemented our architecture on have 27-bit DSP units. Choosing 27-bit or 54-bit words enables us to use fewer DSPs to do the same computation. Naive construction of a 64-bit multiplier requires nine 27-bit DSPs. Whereas, a 54-bit multiplier requires only four. However, by reducing the bit-width of the RNS bases, one may need to increase the number of RNS bases; roughly speaking, by a factor of 64 54 ? 1.2. In practice, small ciphertext moduli are usually less than 54 bits and thus, we do not need to increase the number of moduli.</p><p>It is worth-mentioning that leveraging more sophisticated multi-word multiplication algorithms such as Toom-Cook, one can implement 64-bit multiplication using five 27-bit multipliers together with more bit-level and Addition operations. Overall, by switching from 64-bit native operations to 54-bit, we observe between 1.4-2.25? reduction in the number of DSP units needed (depending on the HE parameters). However, to support 54-bit word size, we need to make sure that all of the ciphertext moduli (p i ) are (i) less than 52-bit to ensure the correctness of Algorithm 1 and (ii) congruent to 1 mod 2n to support NTT as described in Section 4. We have modified the SEAL library accordingly and precomputed all of such moduli for different parameter sets. The MULT module, as depicted in Figure <ref type="figure" target="#fig_1">2</ref>, encompasses nc DYD -many Dyadic Cores; thus, it can compute nc DYD dyadic multiplication at each clock cycle (nc stands for number of cores). Each Dyadic core takes as input two polynomial coefficients (Op 1 and Op 2 ), two precomputed constant values (R 1 and R 2 ), and one-word prime p and outputs the result.</p><p>Let us denote the number of components in ct 0 and ct 1 by ? and ?, respectively. The outcome of homomorphic multiplication is a ciphertext with ? + ? -1 components. Each ciphertext component is represented in a RNS form. Recall that in homomorphic multiplication (Algorithm 2), the computation can be carried out independently on each RNS basis. We leverage this property to reduce BRAM utilization. Minimum BRAM utilization is achieved by storing only one residue of one ciphertext component on FPGA chip. However, this approach significantly increases data transfer from CPU to FPGA from (? + ?) ? n words to (? ? ? + min(?, ?)) ? n words because we need to compute all pairwise combinations of ct 0 and ct 1 components. Thus, we allocate ?-many memories of size n for ct 0 and ?-many memories for ct 1 to hold one residue of all ciphertext components. As a result, we achieve O (? + ?) ? n data transfer and BRAM consumption.</p><p>In order to fully utilize all nc DYD Dyadic cores -regardless of the values of ? and ? -we read nc DYD coefficients from one of the polynomials of ct 0 and ct 1 at every clock cycle. However, each unit of on-chip memory, i.e., Block RAMs (BRAM), only supports one read and one write at each clock cycle. In order to read many coefficients from one polynomial at each cycle, we store each polynomial across nc DYD -many parallel memory blocks that share common read/write address signals as depicted in Figure <ref type="figure" target="#fig_1">2</ref>. Let us call the aggregation of one row among different BRAMs as a memory element (ME). Therefore, at every cycle, one memory element (ME1/ME2) is read from ct 0 /ct 1 memory banks and the result (ME3) is written to a separate output memory. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">NTT MODULE</head><p>NTT calculation as well as its inverse (INTT) are the most computationally intensive low-level operations. Polynomial multiplication is more efficiently performed by transforming polynomials and using the convolution theorem. In what follows, we provide an overview on NTT algorithm followed by our proposed architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Algorithms</head><formula xml:id="formula_5">Computing c = a ? b ? R p is equivalent to computing the negacyclic convolution of their coefficient vectors in Z n p : c j = j i=0 a i b j-i -n-1 i-j+1 a i b j-i+n (mod p), j = 0, 1, . . . , n -1.</formula><p>For a large n it is asymptotically better to use the convolution theorem and perform a specific form of fast Fourier transform, i.e., NTT, over a finite field. Polynomials are kept in NTT form to reduce the number of NTT/INTT conversions. Fast NTT algorithms are well studied in lattice-based cryptography. We adapt the algorithms in <ref type="bibr" target="#b45">[44]</ref> which analyzes fast NTT algorithms and introduces specific optimizations for negacyclic convolution. For a ring degree n, we choose a prime number p = 1 mod 2n such that there exists a 2n-th primitive root of unity ? , i.e.,</p><formula xml:id="formula_6">? n = -1 mod p. ? NTT p (a): Given a ? Z n p , compute ? ? Z n p such that ?j = n-1 i=0 a i ? (2i+1)j , according to Algorithm 3.</formula><p>An important operation that is used during key switching and rescaling is called flooring which can be formalized as:</p><p>? Floor( C, p): Given C, the RNS and NTT form of c ? R q ? p , generate C? , the RNS and NTT form of c ? = p -1 ? c ? R q ? according to Algorithm 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">NTT Architecture</head><p>In what follows, we use the term NTT to refer to both NTT and INTT operations/modules for simplicity. At the end of this section, we discuss the differences between these two modules. As can be seen from Algorithm 5, in KeySwitch, NTT is frequently used in different parts of this algorithm. However, the number of required transformations is not consistent in different parts of the Algorithm. In order to have a fully-pipelined architecture, we allocate one NTT module per each NTT operation in Algorithm 5. However, the relative throughput-rate among different NTT instances depends on the chosen FHE parameters, which is applicationdependent. As a result, we need to have a generic architecture such that the throughput can be adjusted as needed. This, in turn, is translated to the number of NTT cores that is dedicated to a given NTT module.</p><p>NTT Core. Figure <ref type="figure" target="#fig_3">3</ref> shows the internal architecture of an NTT core. Each core accepts two coefficients (c in.a and c in.b ), one twiddle factor (w), one precomputed value (wp), and a prime number (p) as inputs and computes two transformed coefficients as the outputs (c out.a and c out.b ). The modular arithmetic operations within NTT core are all pipelined to maximize the throughput of the overall NTT module. for (i = 0; i &lt; m; i + +) do 3:</p><formula xml:id="formula_7">for (j = i ?n m ; j &lt; (2i+1)n 2m ; j + +) do 4: v = MulRed(a j+ n m , y m+i , y ? m+i , p) 5:</formula><p>a j+ n m = a j -v (mod p)</p><p>6:</p><formula xml:id="formula_8">a j = a j + v (mod p) ? NTT Core 7:</formula><p>end for 8:</p><p>end for 9: end for 10: ? ? a Algorithm 4 RNS Flooring | Floor( C, p)</p><formula xml:id="formula_9">Input: C = (c 0 , . . . , c?+1 ) ? Z n p 0 ? ? ? ? ? Z n p ? ? Z n p . Output: C? = (c ? 0 , . . . , c? ? ) ? Z n p 0 ? ? ? ? ? Z n p ? . 1: a ? INTT p (c ?+1 ) ? INTT Module 2: for (i = 0; i ? ?; i = i + 1) do 3: r ? Mod(a, p i ) 4: r ? NTT p i (r) ? NTT Module 5: c? i ? ci -r (mod p i ) 6: c? i ? Mod p -1 p i ? c? i , p i ? MS Module 7:</formula><p>end for Figure <ref type="figure" target="#fig_3">3</ref> illustrates the full architecture of NTT module. From the functionality perspective, the architecture follows Algorithm 3. At a high-level, the NTT module computes NTT of a polynomial of size n in log n stages. In each stage, the module computes the transformed result of 2 nc NTT coefficients, thus, requiring n 2 nc NTT steps to finish one stage. On the three corners of the NTT architecture exist data memory, twiddle factor memories, and the output memory. At every cycle, one ME is fetched from data memory and is stored in ME e and ME o registers every other cycles, respectively. For each input coefficient of NTT cores, i.e., c ? in.a or c ? in.b , a set of multiplexers select the correct coefficient from ME e and ME o (depicted as light blue boxes in Figure <ref type="figure" target="#fig_3">3</ref>). The throughput is proportional to the number of NTT cores. We denote the number of NTT cores as nc NTT . Ideally at each clock cycle, and given full utilization of NTT cores, 2 nc NTT coefficients are transformed. In order to read and write 2 nc NTT coefficients at each clock cycle, we store each polynomial across many parallel BRAMs that share common read/write address signals as depicted in Figure <ref type="figure" target="#fig_3">3</ref> (similar to the MULT module). This is possible thanks to the aligned access pattern in NTT: while access pattern changes during NTT, the number of consecutive accesses to the polynomial is always a power of two. Next, we discuss the details of the access patterns in NTT followed by our proposed solution to select each coefficient efficiently.   </p><formula xml:id="formula_10">(j = 0, 1, ... , n 2 1+i -1) is passed along with x[j + m + n 2 1+i ] where m ? { h ?n 2 i | h = 0, 1, ..., i}.</formula><p>The address of the ME that is fetched in Type 1 stages is computed in Address Logic. As soon as n 2 i = 2 nc NTT , the inter-ME data dependency no longer exists, and pairs of coefficients are selected from within each ME independently, i.e., Type 2 stages.</p><p>In Type 1 stages, coefficients within two fetched MEs are always accessed in the same order. For example, the second coefficient in each ME is always passed to the second NTT core. However, in Type 2 stages, a coefficient at specific location of ME is passed to a different NTT core or even different inputs of an NTT core. Therefore, coefficients have to be reordered to be passed to NTT cores. Later in this section, we discuss an efficient method for this task.</p><p>The access pattern for twiddle factors, i.e., Y and Y ? in Algorithm 3, is different. At stage i, only 2 i unique values of twiddle factors, starting at index 2 i of twiddle polynomial, are used. Since in the worst-case scenario, nc NTT unique twiddle factors are used in a single step of NTT, we store twiddle factors in batches of size nc NTT in parallel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Reordering Coefficients and Optimal MUXs</head><p>During Type 1 stages, once the ME is fetched, passing each coefficient within ME to the right NTT core (and right input wire) is straightforward and it can be summarized as follows: In Type 2 stages, first one of the ME e or ME o is selected using 2 nc NTT -many two-to-one multiplexers (MUX1) and is stored in ME s registers. Next, c ? in.a (or c ? in.b ) receive data from one of the coefficients in ME s depending on the value of ? and i. The naive approach is to use one multiplexer per each coefficient input of every NTT core that selects one number from 2 nc NTT fetched numbers. We denote such multiplexer as MUX 2 nc NTT . As a result, we need 2 nc NTT -many MUX 2 nc NTT to pass coefficients to NTT cores and the same number of MUXs to reorder them to be written back to the memory.</p><formula xml:id="formula_11">? ? ? ? ? ? ? c ? in.a = ME e [? + (j mod 2) ? nc NTT ] c ? in.b = ME o [? + (j<label>mod</label></formula><p>These MUXs not only make the placement and route process more challenging but also consume enormous number of registers and logic blocks. Moreover, scaling the NTT module to higher number of cores (&gt; 32) is inefficient due to super-linear resource consumption with respect to nc NTT . In our case, synthesis tools failed to place and route the required resources to realize these MUXs. In contrast, we take advantage of the observation that NTT cores' inputs have a different number of possibilities from which they select the correct coefficient at a given stage. For example, during Type  In the worst-case scenario, there are log nc NTT different indices from which a coefficient should be accessed from ME s for a particular NTT core input. Therefore, instead of using (4 ? nc NTT )-many MUX 2 nc NTT , we instantiate (4 ? nc NTT )many MUXs of size at most MUX log 2 nc NTT . These optimal multiplexers are shows as MUX2 in Figure <ref type="figure" target="#fig_3">3</ref>. The selection signal of these MUXs is set to s = log n -1 -i (i being the stage number). The corresponding inputs (MUX{c ? in.a }(?) and MUX{c ? in.b }(?)) from which a coefficient should be selected are assigned based on the following formula:</p><formula xml:id="formula_12">= ? ? ? ? ? ? ? ME s [(? &amp; (2 s -1)) + ((i &gt;&gt; s) &lt;&lt; (s + ?))] ME s [(? &amp; (2 s -1)) + ((i &gt;&gt; s) &lt;&lt; (s + ?)) + 2 s ]</formula><p>where MUX{c ? in.a }(?) is the ?-th input wire of the MUX that selects the corresponding input coefficient from ME s for the ?-th core, thus, 0 ? ? &lt; log nc NTT . Finally, depending on the stage type, MUX4 selects the output of MUX2 or MUX3.</p><p>A similar set of MUXs (MUX6 and MUX7) are used to reorder the data back before storage. Final results (ME4 and ME5) will be stored in the data memory during two consecutive clock cycles; except for the the last stage where they will be stored in output memory. The optimized multiplexers for twiddle factors is designed in a similar manner. The optimal multiplexers are an integral part of the design of NTT module. For instance, this optimization reduces the number of registers used for a 8-core NTT module from 224,000 to 97,000. Note that to synthesize the NTT module, register is the most limited resource (see <ref type="bibr">Section 7)</ref>, thus, without the proposed optimal multiplexers, one cannot scale the design properly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">NTT High-Level Pipeline</head><p>Storing polynomial coefficients across parallel memory blocks enables simultaneous access to multiple coefficients. However, the NTT cores cannot be fully utilized due to the following reason. During Type 1 stages, coefficients that should be passed to each NTT core are not located in the same ME. Therefore, two different MEs should be read before the computation can start which introduces 50% bubble in the NTT core pipeline. More precisely, first log nlog nc NTT -1 stages face this problem. Given that NTT modules consume most of the FPGA resources, this issue reduces the throughput of the entire design to (log nlog nc NTT -1)/log n.</p><p>To address this problem, we propose to double the size of MEs and store 2 nc NTT consecutive coefficients in each memory element. Meanwhile, we reduce the depth of the memories that store the polynomial by half. Even though it is still necessary to read two MEs before starting the computation, we can now transform two MEs in the next two cycles and store them back in the memory. This modification results in the full utilization of NTT core. In order to have minimal BRAM usage, all of the reads and writes during different NTT stages are inplace, and no additional BRAM is used to store intermediate values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Memory Utilization and Word-Packing</head><p>Storing multiple polynomial coefficients in multiple parallel memory units (M20K) causes memory block underutilization both depth-size and width-size. Consider a general scenario where ?-many numbers are stored in parallel: Depth-wise: Each M20K memory unit holds 512-many 40-bit wide words and at any cycle, one word can be read from or written into the memory. When fewer than 512 words are stored in the memory, the rest of the memory rows cannot be used to store a secondary polynomial since at any point in time we are reading/writing one word associated with the first polynomial. As long as n ? ? 512, M20K is fully utilized. This inequality generally holds in our architecture except when n = 2 12 (smallest polynomial size) and nc NTT = 16 which makes M20K half utilized. However, this is not an issue since our design is not BRAM-constrained when n = 2 12 . Width-wise: As the polynomial-size (n) grows, our design becomes more and more BRAM-constrained to the extent that at n = 2 14 , there is not enough BRAM on the chip; thus, we have to use DRAM as well (we will discuss this in more detail in Section 6). Therefore, it is essential that the polynomials are efficiently stored in memory. By storing each coefficient in a separate physical BRAM, we will only reach 54  2?40 = 68% utilization. In contrast, we pack multiple coefficients and store them in fewer M20K units as shown in Figure <ref type="figure" target="#fig_3">3</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">KEYSWITCH MODULE</head><p>In this section, we discuss the KeySwitch algorithm followed by our proposed architecture and the design details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Algorithm</head><p>Key switching is a technique to make a ciphertext decryptable with a different secret key homomorphically. Various gadget decomposition methods can be adopted to balance noise growth and execution time. Given q d-1 , the product of coprime integers p 0 , . . . , p d-1 , and q ? divides q d-1 , define gadget decomposition R q ? ? R d as g -1 (a) = [a] p i 0?i ?d-1 , and gadget vector as g = ? i ? -1</p><formula xml:id="formula_13">i p i 0?i ?d-1</formula><p>where</p><formula xml:id="formula_14">? i = q d -1</formula><p>p i . This choice of gadget decomposition contributes to a fast key switching and high noise growth. With the special modulus p and a rescaling at the end of key switching, explained in <ref type="bibr" target="#b15">[15]</ref>, key switching is almost noise-free.</p><p>? KeySwitch(ct, ksk): Given a ciphertext ct = (c 0 , c 1 ) ? R 2 q ? decryptable with secret key s and a key switching key</p><formula xml:id="formula_15">ksk = (D 0 | D 1 ) ? R (L+2)?2 q ? p</formula><p>, where | appends one column vector to another, generate a new ciphertext ct ? = (c ? 0 , c ? 1 ) ? R 2 q ? decryptable with secret key s ? . (see Algorithm 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">KeySwitch Architecture</head><p>KeySwitch is the most computationally intensive high-level operation in CKKS. It has several important roles, including relinearization and ciphertext rotation. Figure <ref type="figure" target="#fig_13">5</ref> illustrates the KeySwitch architecture, which from the functionality perspective corresponds to Algorithm 5. To reduce onchip memory usage, our design takes one polynomial (one RNS component) at a time and outputs two polynomials.</p><p>Recall that in CKKS, all polynomials are in NTT form by default. Thus, once the input polynomial is written into the input memory, it has to be converted back to the original domain. This process is performed using the first INTT module (INTT0). Next, the polynomial is transformed to the NTT form for all other primes (including the special modulus). Since per each INTT computation, we have to perform k NTT, the throughput of the NTT module(s) has to be ktimes the throughput of INTT0. Here, k is the number of RNS components of ciphertext modulus, i.e., L + 1. This requirement can be realized in two different ways: (i) having one NTT module with k-many more cores than INTT0 or (ii) having multiple NTT module with fewer cores per each module. We denote this NTT module (or a set of them) as NTT0. We will discuss the trade-offs later in this section. In Figure <ref type="figure" target="#fig_13">5</ref>, the second approach (using more than one NTT module) is chosen for n = 2 13 and k = 4 parameter set.</p><p>Once the NTT computations are finished, the DyadMult module computes the dyadic product between the output of NTT modules and the relinearization/Galois keys according to Algorithm 5. Recall that a dyadic product on the original input polynomial is also needed in KeySwitch; thus, a Algorithm 5 Key Switching | KeySwitch(ct, ksk)</p><formula xml:id="formula_16">Input: ct = ( C0 , C1 ) ? ( ? i=0 R p i ) 2 , and ksk = Di,0 0?i ?L+1 Di,1 0?i ?L+1 ? (p L i=0 R p i ) (L+2)?2 Output: ct ? = ( C? 0 , C? 1 ) ? ( ? i=0 R p i ) 2 1: for (i = 0; i ? ?; i = i + 1) do 2: a ? INTT p i (c 1,i ) ? INTT Module 3:</formula><p>for (j = 0; j ? ?; j = j + 1) do 4:</p><p>if i j then end if</p><formula xml:id="formula_17">10: c?? 0,j ? c?? 0,j + b ? di,0,j (mod p j ) 11: c?? 1,j ? c?? 1,j + b ? di,1,j (mod p j ) ? Dyadic Mod.</formula><p>12:</p><p>end for 13:</p><p>b ? Mod(a, p)</p><formula xml:id="formula_18">14: b ? NTT p (b) ? NTT Module 15: c?? 0,?+1 ? c?? 0,?+1 + b ? d0,i,L+1 (mod p j ) 16: c?? 1,?+1 ? c?? 1,?+1 + b ? d1,i,L+1 (mod p j ) ? Dyd. M. 17: end for 18: ct ? ? (Floor( C?? 0 , p), Floor( C?? 1 , p)) ? INTT/NTT/MS 19: ct ? ? CKKS.Add(ct, ct ? )</formula><p>separate Dyadic module is used. After dyadic product computation, the result is stored in the corresponding memory banks. There are two sets of BRAM banks, each bank containing the RNS components of one polynomial.</p><p>The computation flow described above repeats for k-many times (one per each RNS component). The result is accumulated in the BRAM banks. After k iterations, the second part of the computation -usually referred to as Modulus Switching (developed in <ref type="bibr" target="#b12">[12]</ref>) -is performed. In Modulus Switching which executes Floor, the polynomial corresponding to the special modulus has to be transformed back to the time domain (by INTT1) and then be transformed using every other k primes (by NTT1). The aforementioned process is independently performed for both sets of banks. Next, the polynomial is multiplied by the inverse value of the associated prime and subtracted from the result of the first half of KeySwitch computation. The MS module embeds multiplication and subtraction operations. The output of KeySwitch is stored as two sets of k polynomials referred to as "Output Poly 0/1".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Balancing Throughput</head><p>Our primary goal in designing KeySwitch architecture is to have a fully end-to-end pipelined module that can process many key switching operations simultaneously without excessive FIFOs between different components. Thus, we have to tune the throughput of each component carefully. As we discussed in Section 4, this is one of the reasons to design a flexible architecture for NTT, the throughput of which can be adjusted. According to Algorithm 5, per each initial INTT, Session 14A: Security with little performance loss -Fast and furious! ASPLOS <ref type="bibr">'20, March 16-20, 2020</ref>, Lausanne, Switzerland we have to compute k NTTs. In general, let's denote the number of NTT0 as m 0 (assuming a power of two number). Thus, we have:</p><formula xml:id="formula_19">nc NTT 0 = k ? nc INTT 0 /m 0 .</formula><p>Next, we compute the number of cores needed for DyadMult. Recall that it takes (n log n)/(2 nc NTT 0 ) cycles for NTT module to finish the computation. The DyadMult module has to compute the product of NTT output with two different sets of keys (ksk = D 0 | D 1 ). It takes (2 n)/nc DYD cycles to perform dyadic multiplication on the output of the NTT module. Since in general, log n is not a power of two, the throughputs do not perfectly match. We make sure that the throughput of Dyadic module is greater than that of (or equal to) the NTT module by satisfying the following inequality: )/log n . For two FPGA chips that we have implemented HEAX on, the optimal architecture parameters are computed and summarized in Table <ref type="table" target="#tab_7">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">KeySwitch Ops. and Synchronization</head><p>Figure <ref type="figure" target="#fig_15">6</ref> shows the high-level pipeline of KeySwitch module for n = 2 13 (third row of Table <ref type="table" target="#tab_7">5</ref>). All of the modules -and their internal components -are pipelined, and the throughput is balanced. As can be seen, multiple key switching operations are computed simultaneously in different pipeline stages (in lighter colors). The fifth Dyadic module that operates on input polynomial BRAM is synchronized with the rest of the Dyadic modules even though the computation can be started as soon as the input poly is available. The reason is that during each of the k iterations of Dyadic product, each module computes and accumulates the results by reading/writing from/to a separate BRAM bank. This enables us to avoid any memory replication considering that these memory banks are prohibitively large. However, this delayed computation introduces a dependency problem in the pipeline referred to as "Data Dependency 1". By the time the k-th Dyadic module starts the computation, the content of input poly is overridden by the next key switching operation. As a result, we allocate enough BRAM to hold f 1 -many polynomials where</p><formula xml:id="formula_20">f 1 = 3 + nc INTT 0 nc NTT 0</formula><p>. Similarly, MS module receives inputs from DyadMult modules. This is marked as "Data Dependency 2" in Figure <ref type="figure" target="#fig_15">6</ref>. Thus, we need to allocate more memory to store the output of the DyadMult modules in f 2 different buffers. The value of f 2 can be computed as: </p><formula xml:id="formula_21">f 2 = 1 + m 0 ? nc INTT 1 nc NTT 1 + nc INTT 1 ?log n nc MS .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">SYSTEM-VIEW and DATA FLOW</head><p>In this section, we discuss a higher-level view of the computation and elaborate on the data flow. Figure <ref type="figure">7</ref> shows a system-view comprising host CPU and FPGA Board which are connected via Peripheral Component Interconnect express (PCIe) bus. On FPGA board, exist the FPGA chip as well as off-chip DRAM memory connected via DDR interface.</p><p>Figure <ref type="figure">7</ref>. System-view of HEAX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">On-Chip vs. Off-Chip Memory Accesses</head><p>There are two main ways to store data on FPGA board: (i) off-chip DRAM with several Gigabytes of capacity but high response delay and (ii) on-chip BRAM with few megabits of capacity but very fast response time and high throughput.</p><p>As has been shown by prior art <ref type="bibr" target="#b54">[53,</ref><ref type="bibr" target="#b55">54]</ref>, leveraging off-chip memory to store intermediate results significantly reduces the overall performance due to high delays between subsequent reads and writes. One of our primary design goals is to avoid off-chip memory access as much as possible. We have introduced several techniques to use minimal on-chip memory, re-use many BRAM units, together with data compaction (see Section 4 and Section 5). As a result, no off-chip memory access is performed for n = 2 12 parameter set on both Arria 10 and Stratix 10 FPGAs; which is one of the main reasons for our unprecedented performance improvements.</p><p>For n = 2 13 parameter set, there is sufficient on-chip memory on Stratix 10 chip. Unfortunately, for n = 2 14 , there is not enough BRAM available for our design, and as a result, we have to move some part of the data to off-chip memory. In order to minimize the effect of off-chip memory accesses, we choose to put key switching keys (ksk) in DRAM because of two main reasons: (i) the size of these keys grow very rapidly with HE parameters. In general, the size of ksk grows as O n k 2 , and roughly speaking, k grows linearly with n which results in (almost) O n 3 . This is the highest growth rate compared to all other memory components, including twiddle factors which grow as O n k . (ii) ksk is only read once per each KeySwitch. Note that each unique element of twiddle factors is read k times during one KeySwitch operation; thus, twiddle factors are less suitable candidates.</p><p>We distribute the ksk among four different DRAM banks such that at any point in time, the full capacity of off-chip memory bandwidth is used. In order to further mask the effect of DRAM accesses, we leverage the burst mode in which a long sequence of data is read at the same time on each channel. The entire process of reading ksk from DRAM is pipelined to minimize the drop in throughput of KeySwitch. It is worth-mentioning that DRAM bandwidth is sufficient to match the throughput of KeySwitch. Per each KeySwitch, two sets of ksk have to be streamed to FPGA chip. Each of these sets, hold k ? (k + 1)-many vectors of size n. Substituting n = 2 14 , k = 8, and 64-bit per each word results in approximately 151 megabits. We have to stream this volume of data in 383 microseconds (please see Table <ref type="table" target="#tab_10">8</ref>). Therefore, DRAM bandwidth should be higher than 49.28 GBps, which is indeed lower than the measured bandwidth of all four channels combined.</p><p>In addition to storing ksk, we use DRAM for one more purpose. In some applications, it is more efficient to store the result of computation in DRAM instead of sending them back to CPU (in case these results are going to be used soon). The address at which the result is stored is held on the CPU side and is shown as "Memory Map". The memory map is used to point to the ciphertext(s) that are stored in DRAM to be used later on without involving PCIe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Data Transfer on PCIe</head><p>In order to maximize the utilization of computation blocks on FPGA, we need to interleave computation and data transfer between FPGA and CPU. We divide this design process into two parts: CPU-side and FPGA-side. On the CPU-side, we need to sequence and batch multiple operations in the program (that uses SEAL) and start the data transfer process on PCIe using multiple threads. On the FPGA-side, we need to allocate the necessary buffers to store the received data. In what follows, we explain these two parts in more detail.</p><p>Sequencing and Batching. Transferring data on PCIe involves three main steps: (i) a memcpy is issued to copy the content of the polynomial to pinned memory pages, (ii) CPU signals FPGA that the data is ready, and (iii) FPGA reads the data from PCIe. In order to reduce the data copy time, Direct Memory Access (DMA) is used. However, even by relying on DMA, the maximum throughput that PCIe can provide depends on the message size and the number of simultaneous data transfer requests. Therefore, we transfer (at least) a complete polynomial (2 15 -2 17 Bytes) in each request. Moreover, we implement a multi-threaded data transfer mechanism that uses eight threads to interleave eight separate polynomials at a time to maximize the PCIe throughput and avoid unnecessary bubbles in the computation pipeline. Double and Quadruple Buffering. For the MULT module, it suffices to double-buffer the input such that CPU writes to one of these buffers and FPGA reads from the other one. For KeySwitch module, however, we need to perform quadruple buffering due to the data dependency on input polynomial as discussed in Section 5. In order to make sure buffers are not overridden before they are read, we stop the writing process if the buffer has not been read yet.</p><p>Session 14A: Security with little performance loss -Fast and furious! ASPLOS <ref type="bibr">'20, March 16-20, 2020</ref>, Lausanne, Switzerland</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">IMPLEMENTATION and EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Experimental Setup</head><p>In this section, we discuss the resource consumption of HEAX components as well as the performance comparison with CPUs and GPUs. To illustrate the adaptability of HEAX, we implement HEAX on two FPGAs which represent two different classes of computational resources. Table <ref type="table" target="#tab_3">1</ref> summarizes the breakdown of resources of each FPGA chip. There are three major types of resources that are available: ? Digital Signal Processing (DSP) units that are able to perform one 27-bit or two 18-bit multiplications.</p><p>? Adaptive Logic Modules (ALM) are core logic units with two combinational adaptive look-up tables, a two-bit full adder, and four 1-bit Registers (REG).</p><p>? Block RAM (BRAM) units that are on-chip memories. Each M20K unit of BRAM holds 512-many 40-bit values. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">FHE Parameters and Security Guarantees</head><p>The security guarantees of HEAX directly derives from the CKKS scheme <ref type="bibr" target="#b17">[17]</ref> since the functionality of the scheme is not altered. The security parameters for which we have instantiated HEAX are borrowed from the HE security standards <ref type="bibr" target="#b2">[2]</ref> for 128-bit classical security. Changing the underlying word-size in HEAX reduces the number of DSPs used but does not affect the security since the total bitwidth of the ciphertext modulus is preserved <ref type="bibr" target="#b2">[2]</ref>. Similarly, we leveraged the RNS-level parallelism which is proven to be secure <ref type="bibr" target="#b16">[16]</ref>. We evaluate our design on a wide range of FHE parameters: from ciphertext polynomial size (n) of 2 12 and 109-bit ciphertext modulus (?log qp? + 1) to 2 14 with 438-bit ciphertext modulus. We refer to these parameter sets as Set-A, Set-B, and Set-C, respectively (summarized in Table <ref type="table" target="#tab_4">2</ref>). Recall that k is the number of small RNS components of ciphertext modulus. Parameters with 128-bit post-quantum security require slightly smaller ciphertext moduli. We select as few prime moduli for RNS as possible for superior performance <ref type="bibr" target="#b37">[36]</ref>. Note that parameter sets corresponding to 2 11 (or lower) are almost never used in practice due to the multiplication depth of 1 (or zero). Choosing 2 15 (or higher) results in enormous computation blow-up and are also rarely used in practice.  <ref type="table" target="#tab_8">6</ref> provides a breakdown of FPGA resource consumption for different HE parameter sets. The complete design encompasses the KeySwitch module along with the MULT module. For standalone NTT requests from CPU, the NTT modules within KeySwitch is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Performance</head><p>Critical Paths and Maximum Clock Frequency. We have analyzed the critical paths of our design and have eliminated such paths during many design iterations reaching the maximum clock frequency of 275 MHz and 300 MHz for Arria 10 and Stratix 10 FPGA chips, respectively.</p><p>Scalability. One of design principles of HEAX is that it can automatically be instantiated at different scales with no manual tuning, enabling cloud providers to seamlessly use HEAX based on the underlying hardware resource. To illustrate this, we have instantiated HEAX for the same HE parameters (Set-A) but at two different scales (see Table <ref type="table" target="#tab_7">5</ref>). The up-scaled version on Stratix 10 consumes (close to) twice the resources (Table <ref type="table" target="#tab_8">6</ref>) and provides twice the throughput compared to Arria 10 instantiation (see Table <ref type="table" target="#tab_10">8</ref>).   Performance Comparison with CPUs. We compare the performance of HEAX with Microsoft SEAL V3.3 <ref type="bibr" target="#b56">[56]</ref>, which is an FHE library for BFV and CKKS schemes that has undergone several years of performance optimizations. We measure the performance of SEAL on a single-threaded Intel Xeon(R) Silver 4108 running at 1.80 GHz; which is a similar CPU used in prior art <ref type="bibr" target="#b55">[54]</ref>. The single-thread baseline is used by prior art for measuring the performance (non-CKKS schemes) <ref type="bibr" target="#b55">[54]</ref>. In addition, SEAL is thread-safe but not multithreaded due to the complex data dependencies, hence, we cannot compare to a multi-threaded execution. In general, CKKS evaluation functions do not have a balanced parallelizable computation flow and many parts are not parallelizable at all. For instance, the "Modulus Switching" is not parallelizable leading to the Data-Dependency 2 (Figure <ref type="figure" target="#fig_15">6</ref>). This is the reason why we cannot allocate a single NTT/INTT module in KeySwitch and use it over time for different steps. Instead, we design an end-to-end pipelined design and use the chip-area proportional to the computation overhead. Table <ref type="table" target="#tab_9">7</ref> shows the performance results (number of operations per second) of HEAX for low-level operations and its comparison with SEAL. Results are reported for processing a single polynomial (in case of NTT/INTT) or pair of polynomials (MULT). On Stratix 10, 16-core modules are instantiated. On Arria 10, a 16-core MULT and 8-core NTT/INTT modules are used (see Table <ref type="table" target="#tab_7">5</ref>). Note that we report the performance results for low-level operation merely for completeness. These operations are rarely used in isolation and are instead used as part of high-level operations. For high-level operations, i.e., Rotation and Relinearization (using KeySwitch) and a complete ciphertext multiplication (using MULT and KeySwitch), the performance improvements are more pronounced as shown in Table <ref type="table" target="#tab_10">8</ref>. As can be seen, HEAX achieves close to two orders of magnitude performance improvement using Arria 10 compared to CPU (first row of Table <ref type="table" target="#tab_10">8</ref>). On a more powerful FPGA, i.e., Intel Stratix 10 (Board-B), HEAX achieves 164-268? performance improvements among various HE parameter sets (second to fourth rows of Table <ref type="table" target="#tab_10">8</ref>). </p><formula xml:id="formula_22">n = 2 12 (Set-A) 1 ? INTT (8) ? 2 ? NTT (8) ? 3 ? Dyad (4) ? 2 ? INTT (4) ? 2 ? NTT (8) ? 2 ? MS (2) Stratix10 n = 2 12 (Set-A) 1 ? INTT (16) ? 2 ? NTT (16) ? 3 ? Dyad (8) ? 2 ? INTT (8) ? 2 ? NTT (16) ? 2 ? MS (4) n = 2 13 (Set-B) 1 ? INTT (16) ? 4 ? NTT (16) ? 5 ? Dyad (8) ? 2 ? INTT (4) ? 2 ? NTT (16) ? 2 ? MS (4) n = 2 14 (Set-C) 1 ? INTT (8) ? 4 ? NTT (16) ? 5 ? Dyad (8) ? 2 ? INTT (1) ? 2 ? NTT (8) ? 2 ? MS (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">RELATED WORK</head><p>The CKKS scheme is one of the most recently proposed FHE schemes that allows homomorphic operations on fixed-point numbers; making it the prime candidate for machine learning applications. To the best of our knowledge, no hardware architecture has been proposed for the CKKS scheme, and in this paper, we propose the first of its kind. As a result, it is not fair to compare the performance of HEAX with previous designs that focus on non-CKKS schemes. In what follows, we briefly review the research effort related to FPGA, ASIC, and GPU-based acceleration for non-CKKS schemes.</p><p>Hardware Acceleration for non-CKKS Schemes. In <ref type="bibr" target="#b54">[53]</ref>, a system based on FPGA is proposed for BFV scheme to process ciphertext polynomial sizes of 2 15 . However, due to the massive off-chip data transfer, their design does not yield superior performance compared to CPU execution.</p><p>Perhaps, the closest work to ours is by Roy et al. <ref type="bibr" target="#b55">[54]</ref> in which authors propose an architecture for BFV scheme and implement their design on Xilinx Zynq UltraScale+ MPSoC ZCU102. In order to avoid off-chip memory accesses, authors focus on n = 2 12 ciphertext sizes and report 13? speed-up (using two instances of their proposed processors) compared to the FV-NFLlib <ref type="bibr" target="#b32">[32]</ref> executing on an Intel i5 processor running at 1.8 GHz. However, compared to a more optimized Microsoft SEAL library [55], FV-NFLlib is 1.2? slower <ref type="bibr" target="#b7">[7]</ref>. In addition, our design is significantly more modular and scalable. We have instantiated HEAX for three different set of HE parameters with no manual tuning (polynomial sizes of 2 12 , 2 13 , and 2 14 ). Moreover, HEAX has a multi-layer pipelined design and is drastically more efficient, offering more than two orders of magnitude performance improvement compared to Microsoft SEAL running on Intel Xeon Silver 4108 at 1.8 GHz (note that similar processor is used compared with <ref type="bibr" target="#b55">[54]</ref> running at identical frequency).</p><p>FPGA-based Co-Processors. Designing co-processors has also been studied in the literature. These co-processors work in conjunction with CPUs and accelerate one or more of the homomorphic operations <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b38">37,</ref><ref type="bibr" target="#b40">39,</ref><ref type="bibr" target="#b42">41,</ref><ref type="bibr" target="#b47">46,</ref><ref type="bibr" target="#b48">47]</ref>. In <ref type="bibr" target="#b47">[46]</ref> and <ref type="bibr" target="#b38">[37,</ref><ref type="bibr" target="#b48">47]</ref>, authors focus on designing hardware architecture for the encryption operation only, by leveraging Karatsuba and Comba multiplication algorithms, respectively. In <ref type="bibr" target="#b20">[20]</ref>, a Homomorphic Encryption Processing Unit (HEPU) is proposed for LTV scheme <ref type="bibr" target="#b46">[45]</ref>. Authors focus on accelerating the Chinese Remainder Transform (CRT) for power-of-2 cyclotomic rings and report 3.2-4.4? performance improvements for homomorphic multiplication using Xilinx Virtex-7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Large-Integer Multiplication Hardware Acceleration.</head><p>A line of research focuses on designing very large integer multipliers (768K-bit to 1.18M-bit multiplications) -based on FPGAs or ASICs -that can be used to accelerate homomorphic operations <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b61">61,</ref><ref type="bibr" target="#b62">62]</ref>. In <ref type="bibr" target="#b14">[14]</ref>, a large-integer multiplier and a Barrett modular reduction are proposed that can accelerate HE operations by 11?.</p><p>GPU-based Acceleration. GPU is an alternative computing platform to accelerate evaluation functions <ref type="bibr" target="#b6">[6,</ref><ref type="bibr">21,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b43">42,</ref><ref type="bibr" target="#b49">48,</ref><ref type="bibr" target="#b59">59</ref>]. Wang et al. <ref type="bibr" target="#b59">[59]</ref> have proposed the first GPU acceleration of FHE that targets Gentry-Halevi <ref type="bibr" target="#b35">[34]</ref> scheme. Subsequent improvements are reported in <ref type="bibr" target="#b60">[60]</ref>. In <ref type="bibr" target="#b58">[58]</ref>, a GPU-based implementation of BGV scheme <ref type="bibr" target="#b11">[11]</ref> is introduced. In <ref type="bibr" target="#b6">[6]</ref>, a comprehensive study is reported for multithreaded CPU execution as well as GPU for the BFV scheme. To the best of our knowledge, there is no GPU-accelerated implementation of the CKKS scheme. GPUs normally offer less performance per watt of power than FPGAs by design. Therefore, FPGAs are more suitable candidates for highperformance and low-power secure computation.</p><p>Acceleration of YASHE and LTV Schemes. Several works <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b50">49,</ref><ref type="bibr" target="#b51">50]</ref> focus on improving the performance of YASHE <ref type="bibr" target="#b10">[10]</ref> and LTV <ref type="bibr" target="#b46">[45]</ref> schemes or their variants. These constructions -based on an overstretched NTRU assumption -are subject to a subfield lattice attack <ref type="bibr" target="#b3">[3]</ref> and are no longer secure. In <ref type="bibr" target="#b53">[52]</ref>, an architecture for YASHE scheme is proposed that provides 25? performance improvement over CPU. However, authors assume unlimited memory bandwidth which renders off-chip memory accesses free of cost and is not a realistic assumption. P?ppelmann et al. <ref type="bibr" target="#b52">[51]</ref> have also proposed an architecture for YASHE scheme. Since ciphertexts are prohibitively large to be stored on on-chip memory, authors propose to leverage the idea of Cached-NTT <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b5">5]</ref> to reduce off-chip memory accesses. In contrast, HEAX relies on the ring isomorphism property and perform independent computation on RNS components. This, in turn, allows us to avoid off-chip memory accesses for small HE parameters and minimize such accesses for large parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION</head><p>In this paper, we introduced a novel set of architectures for Fully Homomorphic Encryption (FHE). To the best of our knowledge, HEAX is the first architecture and fullyimplemented hardware acceleration for the CKKS FHE scheme. CKKS is the prime candidate for machine learning on encrypted data due to floating-point support of this scheme. The components designed in HEAX can also be used for other lattice-based cryptosystems and other FHE/HE schemes. The proposed architecture provides a unique degree of flexibility that can be readily adjusted for various FPGA chips. As a proof-of-concept, we have implemented HEAX on two different FPGAs with contrasting hardware resources. Moreover, unlike prior FPGA-based acceleration for BFV scheme, our design is not tied to a specific FHE parameter set. We evaluate HEAX on a wide range of FHE parameters demonstrating more than two orders of magnitude performance improvements. We hope that HEAX paves the way for large-scale deployment of privacy-preserving computation in clouds.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The data flow of an end-to-end encrypted computation based on homomorphic encryption.</figDesc><graphic url="image-1.png" coords="2,103.15,72.00,403.20,91.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Architecture of MULT module. 3.3 MULT Architecture The MULT module can process both ciphertext-ciphertext (C-C) as well as ciphertext-plaintext (C-P) homomorphic multiplications. We describe the architecture for C-C multiplication as C-P is a special case of C-C. Since ciphertexts are in NTT form by default, homomorphic multiplication is simply a series of dyadic products on different components.The MULT module, as depicted in Figure2, encompasses nc DYD -many Dyadic Cores; thus, it can compute nc DYD dyadic multiplication at each clock cycle (nc stands for number of cores). Each Dyadic core takes as input two polynomial coefficients (Op 1 and Op 2 ), two precomputed constant values (R 1 and R 2 ), and one-word prime p and outputs the result.Let us denote the number of components in ct 0 and ct 1 by ? and ?, respectively. The outcome of homomorphic multiplication is a ciphertext with ? + ? -1 components. Each ciphertext component is represented in a RNS form. Recall that in homomorphic multiplication (Algorithm 2), the computation can be carried out independently on each RNS basis. We leverage this property to reduce BRAM utilization. Minimum BRAM utilization is achieved by storing only one residue of one ciphertext component on FPGA chip. However, this approach significantly increases data transfer from CPU to FPGA from (? + ?) ? n words to (? ? ? + min(?, ?)) ? n words because we need to compute all pairwise combinations of ct 0 and ct 1 components. Thus, we allocate ?-many memories of size n for ct 0 and ?-many memories for ct 1 to hold one residue of all ciphertext components. As a result, we achieve O (? + ?) ? n data transfer and BRAM consumption.In order to fully utilize all nc DYD Dyadic cores -regardless of the values of ? and ? -we read nc DYD coefficients from one of the polynomials of ct 0 and ct 1 at every clock cycle. However, each unit of on-chip memory, i.e., Block RAMs (BRAM), only supports one read and one write at each clock cycle. In order to read many coefficients from one polynomial at each cycle, we store each polynomial across nc DYD -many parallel memory blocks that share common read/write address signals as depicted in Figure2. Let us call the aggregation of one row among different BRAMs as a memory element (ME). Therefore, at every cycle, one memory element (ME1/ME2) is read from ct 0 /ct 1 memory banks and the result (ME3) is written to a separate output memory.</figDesc><graphic url="image-2.png" coords="4,317.96,72.00,240.05,110.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Session 14A: Security with little performance loss -Fast and furious! ASPLOS'20, March 16-20, 2020, Lausanne, Switzerland   </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 3</head><label>3</label><figDesc>Number-Theoretic Transform (NTT) | NTT p (a) Input: a ? Z n p , p ? 1 mod 2n, Y ? Z n p storing powers of ? in bit-reverse order, and Y ? = ?Y ? 2 w /p?. Output: : ? ? NTT p (a) in bit-reverse ordering. 1: for (m = 1; m &lt; n; m = 2m) do 2:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Session 14A: Security with little performance loss -Fast and furious! ASPLOS'20, March 16-20, 2020, Lausanne, Switzerland   </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Architecture of NTT module.</figDesc><graphic url="image-3.png" coords="6,54.00,72.00,503.98,201.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>4. 3</head><label>3</label><figDesc>Access PatternOne of the main challenges in realizing the proposed NTT architecture is that the access pattern of the coefficients changes from one stage to another. We categorize the access patterns into two groups as illustrated in Figure 4. During the first (log n -log nc NTT -1) stages, each pair of coefficients for each NTT core are stored in different MEs. Let us call these Type 1 stages. For instance, consider n = 4096 and nc NTT = 8, during the first step of the first stage of NTT, x[0] (in ME 0 ) and x[2048] (in ME 256 ) should be passed to the first NTT core. More precisely, polynomial coefficient x[j] (j = 0, 1, ... , n 2 -1) is passed together with x[j + n 2 ] to a given NTT core. In general, during i t h stage, x[j + m]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>2 )</head><label>2</label><figDesc>? nc NTT ] where c ? in.a (respectively c ? in.b ) is the input coefficient a (respectively b) of ? t h NTT core, ME e (resp. ME o ) is the memory element at "even" ("odd") read cycles, i.e., j mod 2 = 0 (j mod 2 = 1) where j is the step number. In other words, c ? in.a (resp. c ? in.b ) is selected from one of the two positions from ME e (resp. ME o ) using multiplexer #3 (MUX3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Session 14A: Security with little performance loss -Fast and furious! ASPLOS'20, March 16-20, 2020, Lausanne, Switzerland   </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Access pattern of Type 1 and Type 2 stages in NTT. 2 stages, c 0 in.a only receives coefficients from the first word of the fetched ME, regardless of the stage or step number.In the worst-case scenario, there are log nc NTT different indices from which a coefficient should be accessed from ME s for a particular NTT core input. Therefore, instead of using (4 ? nc NTT )-many MUX 2 nc NTT , we instantiate (4 ? nc NTT )many MUXs of size at most MUX log 2 nc NTT . These optimal multiplexers are shows as MUX2 in Figure3. The selection signal of these MUXs is set to s = log n -1 -i (i being the stage number). The corresponding inputs (MUX{c ? in.a }(?) and MUX{c ? in.b }(?)) from which a coefficient should be selected are assigned based on the following formula:</figDesc><graphic url="image-4.png" coords="7,68.36,72.00,208.84,185.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>reaching memory utilization of ? ? 54/(?? ? 54/40? ? 40). For ? = 8, BRAM utilization will reach more than 98%. Performance. Computing the NTT of a polynomial requires log n stages and each stage takes n 2 nc NTT cycles. Hence, it takes n log n 2 nc NTT cycles to compute one NTT. INTT Module. This module is identical to the NTT module except: (i) the NTT core is replaced by the INTT core, (ii) the control unit operates in the reverse order of stage numbers, and (iii) twiddle factors correspond to the INTT calculations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Session 14A: Security with little performance loss -Fast and furious! ASPLOS'20, March 16-20, 2020, Lausanne, Switzerland   </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Architecture of KeySwitch module.</figDesc><graphic url="image-5.png" coords="9,77.96,72.00,453.61,202.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>2 n nc DYD ? n log n 2</head><label>2</label><figDesc>nc NTT 0 ? nc DYD = 4 nc NTT 0 log n The throughput of INTT1 modules can be adjusted by assigning nc INTT 1 = nc INTT 0 /k . One can also determine nc NTT 1 = nc INTT 0 and nc MS = (2 nc NTT 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. High-level pipeline of KeySwitch module.</figDesc><graphic url="image-6.png" coords="9,328.71,472.07,216.04,224.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Session 14A :</head><label>14A</label><figDesc>Security with little performance loss -Fast and furious! ASPLOS'20, March 16-20, 2020, Lausanne, Switzerland FPGA Device HE Param. Set KeySwitch Architecture Parameter Set Arria10</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Session 14A :</head><label>14A</label><figDesc>Security with little performance loss -Fast and furious! ASPLOS'20, March 16-20, 2020, Lausanne, Switzerland   </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>In FHE schemes, the ciphertext is a set (usually a pair) of polynomials with degree n -1 modulo a big integer. The homomorphic property of FHE schemes enables computation on encrypted data without the access to the decryption key. For example, adding two ciphertexts results in a ciphertext that encrypts "summation of the corresponding plaintext values". Multiplication, however, is significantly more complicated. It increases the number of polynomials in the resulting ciphertext; requiring an operation, called relinearization, to transform the ciphertext back to a pair of polynomials. In order to avoid the underlying plaintext values in the ciphertext to blow-up, an operation called rescaling is performed which divides the plaintext value by a constant number. CKKS scheme supports rotation in which the numbers encoded in a ciphertext can be rotated circularly.Relinearization, rescaling, and rotation operations can be expressed as a unified operation called Key Switching (plus certain pre-and/or post-processing steps). Modular arithmetic operations can be computed more efficiently if ciphertext coefficients are represented in a Residue Number System (RNS). The full-RNS variant of the CKKS scheme was introduced in<ref type="bibr" target="#b16">[16]</ref>. Another orthogonal optimization based on NTT provides a more efficient polynomial multiplication.</figDesc><table><row><cell>2 PRELIMINARIES</cell></row><row><cell>CKKS Scheme.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Algorithm 1 Optimized Modular Mult. | MulRed(x, y, y ? , p) Input: x, y ? Z p , p &lt; 2 w -2 , and y ? = ?y ? 2 w /p? Output: z ? x ? y (mod p)1: z ? x ? y (mod 2 w ) ? the lower word of the product 2: t ? ?x ? y ? /2 w ? ? the upper word of the product 3: z ? ? t ? p (mod 2 w ) ? the lower word of the product</figDesc><table><row><cell cols="2">4: z ? z -z ?</cell><cell>? single-word subtraction</cell></row><row><cell cols="2">5: if z ? p then</cell></row><row><cell>6:</cell><cell>z ? z -p</cell></row><row><cell cols="2">7: end if</cell></row><row><cell cols="3">We denote the RNS representation of an element a ? R q by</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>Summary of FPGA boards' specifications.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Chip Resources</cell><cell></cell><cell cols="2">DRAM</cell></row><row><cell>Board</cell><cell>Chip</cell><cell>DSP</cell><cell>REG ALM</cell><cell cols="2">BRAM bits #M20K</cell><cell>#chnl.</cell><cell>BW (GBps)</cell></row><row><cell cols="5">Board-A Arria 10 GX 1150 1518 1.71M 427K 53Mb</cell><cell>2.7K</cell><cell>2</cell><cell>34</cell></row><row><cell cols="5">Board-B Stratix 10 GX 2800 5760 3.73M 933K 229Mb</cell><cell>11.7K</cell><cell>4</cell><cell>64</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .</head><label>2</label><figDesc>HE Param. Set n ?log qp? + 1 k The HE parameter sets used in this paper. n is the ciphertext polynomial size, qp is the ciphertext modulus, and k is the number of RNS components of q. Table3provides a detailed resource consumption of Dyadic, NTT, and INTT computation cores as well as the number of pipeline stages (delay) for each core.</figDesc><table><row><cell>Set-A</cell><cell>2 12</cell><cell>109</cell><cell>2</cell></row><row><cell>Set-B</cell><cell>2 13</cell><cell>218</cell><cell>4</cell></row><row><cell>Set-C</cell><cell>2 14</cell><cell>438</cell><cell>8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>Resource consumption of each computation core. Basic Modules. Table4provides a detailed resource consumption of different modules (with various number of cores). The BRAM utilization is reported for Set-B parameters (n = 213 ). The BRAM bits usage in each module does not depend on the number of cores but the number of M20K units does. The reason is that more coefficients are stored in parallel M20K units. In the last column, the number of cycles that takes for each module to process a polynomial (or pair of polynomials in case of MULT module) is reported.</figDesc><table><row><cell cols="3">Module #Cores DSP</cell><cell>REG</cell><cell>ALM</cell><cell cols="2">BRAM #bits #M20K</cell><cell>Cycles</cell></row><row><cell>A10 Shell</cell><cell>-</cell><cell cols="4">1 79203 39222 886496</cell><cell>144</cell><cell>-</cell></row><row><cell>S10 Shell</cell><cell>-</cell><cell cols="4">2 86984 45612 1201096</cell><cell>173</cell><cell>-</cell></row><row><cell>MULT</cell><cell>4 8 16</cell><cell cols="3">88 42817 15795 176 61878 22160 352 93594 35257</cell><cell>1 1 0 4 3 8 4</cell><cell>65 65 164</cell><cell>1024 512 128</cell></row><row><cell></cell><cell>32</cell><cell cols="3">704 181503 62157</cell><cell></cell><cell>293</cell><cell>64</cell></row><row><cell>NTT</cell><cell>4 8 16</cell><cell cols="3">40 61670 22316 80 96919 36336 160 196205 67865</cell><cell>1 5 1 4 4 9 6</cell><cell>86 185 380</cell><cell>6144 3072 1536</cell></row><row><cell></cell><cell>32</cell><cell cols="3">320 387357 142300</cell><cell></cell><cell>725</cell><cell>768</cell></row><row><cell>INTT</cell><cell>4 8 16</cell><cell cols="3">40 63917 22700 80 104575 37331 160 182478 68645</cell><cell>1 5 1 4 4 9 6</cell><cell>86 185 380</cell><cell>6144 3072 1536</cell></row><row><cell></cell><cell>32</cell><cell cols="3">320 384267 144957</cell><cell></cell><cell>724</cell><cell>768</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 .</head><label>4</label><figDesc>Resource consumption of basic modules. Complete Design. Table</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 .</head><label>5</label><figDesc>KeySwitch architecture for different HE parameter sets.</figDesc><table><row><cell>FPGA Device HE Param. Set DSP (%)</cell><cell>REG (%)</cell><cell>ALM (%) BRAM bits (%) BRAM #M20K (%) Freq. (MHz)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 .</head><label>6</label><figDesc>Resource consumption of HEAX for different HE parameter sets.</figDesc><table><row><cell cols="2">FPGA Device HE Param. Set</cell><cell cols="4">NTT CPU HEAX Speed-up CPU HEAX Speed-up CPU INTT</cell><cell>Dyadic MULT HEAX Speed-up</cell></row><row><cell>Arria10</cell><cell>Set-A</cell><cell>7222 89518</cell><cell>12.4 7568 89518</cell><cell cols="3">11.8 36931 1074219</cell><cell>29.1</cell></row><row><cell></cell><cell>Set-A</cell><cell>7222 195313</cell><cell>27.0 7568 195313</cell><cell cols="3">25.8 36931 1171875</cell><cell>31.7</cell></row><row><cell>Stratix10</cell><cell>Set-B</cell><cell>3437 90144</cell><cell>26.2 3539 90144</cell><cell cols="3">25.5 18362 585938</cell><cell>31.9</cell></row><row><cell></cell><cell>Set-C</cell><cell>1631 41853</cell><cell>25.7 1659 41853</cell><cell>25.2</cell><cell cols="2">9117 292969</cell><cell>32.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 .</head><label>7</label><figDesc>Performance comparison of HEAX with CPU. Number of operations per second for CKKS low-level operations.</figDesc><table><row><cell cols="2">FPGA Device HE Param. Set</cell><cell cols="6">KeySwitch CPU HEAX Speed-up CPU HEAX Speed-up MULT+ReLin</cell></row><row><cell>Arria10</cell><cell>Set-A</cell><cell cols="2">488 44759</cell><cell>91.7</cell><cell cols="2">420 44759</cell><cell>106.6</cell></row><row><cell></cell><cell>Set-A</cell><cell cols="2">488 97656</cell><cell>200.5</cell><cell cols="2">420 97656</cell><cell>232.5</cell></row><row><cell>Stratix10</cell><cell>Set-B</cell><cell cols="2">97 22536</cell><cell>232.3</cell><cell cols="2">84 22536</cell><cell>268.3</cell></row><row><cell></cell><cell>Set-C</cell><cell>16</cell><cell>2616</cell><cell>163.5</cell><cell>15</cell><cell>2616</cell><cell>174.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 .</head><label>8</label><figDesc>Performance comparison of HEAX with CPU. Number of operations per second for CKKS high-level operations.</figDesc><table><row><cell cols="5">Performance Comparison with GPUs. To the best of our</cell></row><row><cell cols="5">knowledge, there does not exist any work based on FPGAs</cell></row><row><cell cols="5">or GPUs for CKKS scheme. In Table 9, we compare the per-</cell></row><row><cell cols="5">formance of our "NTT architecture" on Stratix10 (which</cell></row><row><cell cols="5">holds ten 16-core NTT modules) with two NVIDIA GPUs [1].</cell></row><row><cell cols="5">Not only HEAX consumes significanlty less power but it is</cell></row><row><cell cols="4">36-81? faster compared to data-center GPUs.</cell><cell></cell></row><row><cell>Polynomial</cell><cell>HEAX</cell><cell>Tesla-K80</cell><cell>Tesla-P100</cell><cell>Performance</cell></row><row><cell>Size</cell><cell>(10?16-cores)</cell><cell>(2496-cores)</cell><cell>(3584-cores)</cell><cell>Comparison</cell></row><row><cell>2 12</cell><cell>1953130</cell><cell>25641</cell><cell>27777</cell><cell>70-76?</cell></row><row><cell>2 13</cell><cell>901440</cell><cell>20833</cell><cell>25000</cell><cell>36-43?</cell></row><row><cell>2 14</cell><cell>418530</cell><cell>5181</cell><cell>11494</cell><cell>36-81?</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 .</head><label>9</label><figDesc>Performance comparison (operations per second) of HEAX with NVIDIA GPUs for NTT computation.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would like to thank our shepherd <rs type="person">Dr. Timothy Sherwood</rs> and our reviewers for their valuable suggestions.</p><p>Session 14A: Security with little performance loss -Fast and furious! ASPLOS '20, March <rs type="grantNumber">16-20</rs>, <rs type="grantNumber">2020</rs>, Lausanne, Switzerland</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_8NWZdhC">
					<idno type="grant-number">16-20</idno>
				</org>
				<org type="funding" xml:id="_XyX2acD">
					<idno type="grant-number">2020</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Session 14A: Security with little performance loss -Fast and furious! ASPLOS <ref type="bibr">'20, March 16-20, 2020, Lausanne, Switzerland</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">-A</forename><surname>Set</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">3986</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">High-performance FV somewhat homomorphic encryption on GPUs: An implementation using CUDA</title>
		<author>
			<persName><forename type="first">Ahmad</forename><surname>Al Badawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bharadwaj</forename><surname>Veeravalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chan</forename><surname>Fook Mun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khin</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mi</forename><surname>Aung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IACR Transactions on Cryptographic Hardware and Embedded Systems</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="70" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Martin</forename><surname>Albrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melissa</forename><surname>Chase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jintai</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shafi</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Gorbunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shai</forename><surname>Halevi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Hoffstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristin</forename><surname>Lauter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satya</forename><surname>Lokam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniele</forename><surname>Micciancio</surname></persName>
		</author>
		<title level="m">Homomorphic Encryption Security Standard</title>
		<editor>
			<persName><forename type="first">Amit</forename><surname>Sahai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vinod</forename><surname>Vaikuntanathan</surname></persName>
		</editor>
		<meeting><address><addrLine>Dustin Moody, Travis Morrison; Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>HomomorphicEncryption.org</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Subfield Lattice Attack on Overstretched NTRU Assumptions -Cryptanalysis of Some FHE and Graded Encoding Schemes</title>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">R</forename><surname>Albrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shi</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L?o</forename><surname>Ducas</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-662-53018-4_6</idno>
		<ptr target="https://doi.org/10.1007/978-3-662-53018-4_6" />
	</analytic>
	<monogr>
		<title level="m">Advances in Cryptology -CRYPTO 2016, Part I</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Matthew</forename><surname>Robshaw</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jonathan</forename><surname>Katz</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg; Santa Barbara, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Germany</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9814</biblScope>
			<biblScope unit="page" from="153" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">An approach to low-power, high-performance, fast Fourier transform processor design</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bevan</surname></persName>
		</author>
		<author>
			<persName><surname>Baas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>Ph.D. Dissertation. Citeseer</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A generalized cached-FFT algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bevan</surname></persName>
		</author>
		<author>
			<persName><surname>Baas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">89</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings.(ICASSP&apos;05</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Implementation and Performance Evaluation of RNS Variants of the BFV Homomorphic Encryption Scheme</title>
		<author>
			<persName><forename type="first">Ahmad</forename><surname>Al Badawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuriy</forename><surname>Polyakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mi</forename><forename type="middle">Mi</forename><surname>Aung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bharadwaj</forename><surname>Veeravalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Rohloff</surname></persName>
		</author>
		<idno type="DOI">10.1109/TETC.2019.2902799</idno>
		<ptr target="https://doi.org/10.1109/TETC.2019.2902799" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Emerging Topics in Computing</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">High-Performance FV Somewhat Homomorphic Encryption on GPUs: An Implementation using CUDA</title>
		<author>
			<persName><forename type="first">Ahmad</forename><surname>Al Badawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bharadwaj</forename><surname>Veeravalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chan</forename><surname>Fook Mun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khin</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mi</forename><surname>Aung</surname></persName>
		</author>
		<idno type="DOI">10.13154/tches.v2018.i2.70-95</idno>
		<ptr target="https://doi.org/10.13154/tches.v2018.i2.70-95https://tches.iacr.org/index.php/TCHES/article/view/875" />
	</analytic>
	<monogr>
		<title level="m">IACR Transactions on Cryptographic Hardware and Embedded Systems</title>
		<imprint>
			<date type="published" when="2018">2018. 2018. 2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="70" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Full RNS Variant of FV Like Somewhat Homomorphic Encryption Schemes</title>
		<author>
			<persName><forename type="first">Jean-Claude</forename><surname>Bajard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Eynard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Anwar</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Zucca</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-69453-5_23</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-69453-5_23" />
	</analytic>
	<monogr>
		<title level="m">SAC 2016: 23rd Annual International Workshop on Selected Areas in Cryptography</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Roberto</forename><surname>Avanzi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Howard</forename><forename type="middle">M</forename><surname>Heys</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg, Germany, St. John&apos;s, NL, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">10532</biblScope>
			<biblScope unit="page" from="423" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Implementing the Rivest Shamir and Adleman Public Key Encryption Algorithm on a Standard Digital Signal Processor</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barrett</surname></persName>
		</author>
		<idno type="DOI">10.1007/3-540-47721-7_24</idno>
		<ptr target="https://doi.org/10.1007/3-540-47721-7_24" />
	</analytic>
	<monogr>
		<title level="m">Advances in Cryptology -CRYPTO&apos;86</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Odlyzko</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg; Santa Barbara, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Germany</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">263</biblScope>
			<biblScope unit="page" from="311" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improved Security for a Ring-Based Fully Homomorphic Encryption Scheme</title>
		<author>
			<persName><forename type="first">Joppe</forename><forename type="middle">W</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristin</forename><surname>Lauter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><surname>Loftus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Naehrig</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-45239-0_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-45239-0_4" />
	</analytic>
	<monogr>
		<title level="m">14th IMA International Conference on Cryptography and Coding</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Martijn</forename><surname>Stam</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg, Germany, Oxford, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">8308</biblScope>
			<biblScope unit="page" from="45" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Leveled) fully homomorphic encryption without bootstrapping</title>
		<author>
			<persName><forename type="first">Zvika</forename><surname>Brakerski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Craig</forename><surname>Gentry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinod</forename><surname>Vaikuntanathan</surname></persName>
		</author>
		<idno type="DOI">10.1145/2090236.2090262</idno>
		<ptr target="https://doi.org/10.1145/2090236.2090262" />
	</analytic>
	<monogr>
		<title level="m">ITCS 2012: 3rd Innovations in Theoretical Computer Science, Shafi Goldwasser</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="309" to="325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient Fully Homomorphic Encryption from (Standard) LWE</title>
		<author>
			<persName><forename type="first">Zvika</forename><surname>Brakerski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinod</forename><surname>Vaikuntanathan</surname></persName>
		</author>
		<idno type="DOI">10.1109/FOCS.2011.12</idno>
		<ptr target="https://doi.org/10.1109/FOCS.2011.12" />
	</analytic>
	<monogr>
		<title level="m">52nd Annual Symposium on Foundations of Computer Science, Rafail Ostrovsky</title>
		<meeting><address><addrLine>Palm Springs, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="97" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Accelerating Fully Homomorphic Encryption over the Integers with Super-size Hardware Multiplier and Modular Reduction</title>
		<author>
			<persName><forename type="first">Xiaolin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ciara</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>M?ire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><forename type="middle">O</forename><surname>Neill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>'sullivan</surname></persName>
		</author>
		<author>
			<persName><surname>Hanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IACR Cryptology ePrint Archive</title>
		<imprint>
			<biblScope unit="page">616</biblScope>
			<date type="published" when="2013">2013. 2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">High-speed fully homomorphic encryption over the integers</title>
		<author>
			<persName><forename type="first">Xiaolin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ciara</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>M?ire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Neill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth O'</forename><surname>Hanley</surname></persName>
		</author>
		<author>
			<persName><surname>Sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Financial Cryptography and Data Security</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="169" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient Multi-Key Homomorphic Encryption with Packed Ciphertexts with Application to Oblivious Neural Network Inference</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hao Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miran</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongsoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><surname>Song</surname></persName>
		</author>
		<ptr target="https://eprint.iacr.org/2019/524" />
	</analytic>
	<monogr>
		<title level="j">Cryptology ePrint Archive</title>
		<imprint>
			<date type="published" when="2019">2019. 2019/524</date>
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Full RNS Variant of Approximate Homomorphic Encryption</title>
		<author>
			<persName><forename type="first">Jung</forename><surname>Hee Cheon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyoohyung</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrey</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miran</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongsoo</forename><surname>Song</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-10970-7_16</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-10970-7_16" />
	</analytic>
	<monogr>
		<title level="m">SAC 2018: 25th Annual International Workshop on Selected Areas in Cryptography</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carlos</forename><surname>Cid</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Jacobson</surname><genName>Jr</genName></persName>
		</editor>
		<editor>
			<persName><forename type="first">:</forename></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg, Germany, Calgary, AB, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11349</biblScope>
			<biblScope unit="page" from="347" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Homomorphic Encryption for Arithmetic of Approximate Numbers</title>
		<author>
			<persName><forename type="first">Jung</forename><surname>Hee Cheon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrey</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miran</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Soo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-70694-8_15</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-70694-8_15" />
	</analytic>
	<monogr>
		<title level="m">Advances in Cryptology -ASIACRYPT 2017, Part I</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Tsuyoshi</forename><surname>Takagi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Peyrin</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg, Germany, Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10624</biblScope>
			<biblScope unit="page" from="409" to="437" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Faster Fully Homomorphic Encryption: Bootstrapping in Less Than 0.1 Seconds</title>
		<author>
			<persName><forename type="first">Ilaria</forename><surname>Chillotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Gama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariya</forename><surname>Georgieva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malika</forename><surname>Izabach?ne</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-662-53887-6_1</idno>
		<ptr target="https://doi.org/10.1007/978-3-662-53887-6_1" />
	</analytic>
	<monogr>
		<title level="m">Advances in Cryptology -ASIACRYPT 2016, Part I</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Jung</forename><surname>Hee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Cheon</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tsuyoshi</forename><surname>Takagi</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg, Germany, Hanoi, Vietnam</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">10031</biblScope>
			<biblScope unit="page" from="3" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An FPGA co-processor implementation of homomorphic encryption</title>
		<author>
			<persName><forename type="first">David</forename><surname>Bruce Cousins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Golusky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Rohloff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sumorok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE High Performance Extreme Computing Conference (HPEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Designing an FPGA-accelerated homomorphic encryption co-processor</title>
		<author>
			<persName><forename type="first">David</forename><surname>Bruce Cousins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Rohloff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sumorok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Emerging Topics in Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="193" to="206" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">The design of Rijndael: AES-the advanced encryption standard</title>
		<author>
			<persName><forename type="first">Joan</forename><surname>Daemen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Rijmen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Accelerating NTRU based homomorphic encryption using GPUs</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yark?n</forename><surname>Dor?z</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berk</forename><surname>Sunar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE High Performance Extreme Computing Conference (HPEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">cuHE: A Homomorphic Encryption Accelerator Library</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berk</forename><surname>Sunar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cryptography and Information Security in the Balkans, Enes Pasalic and</title>
		<editor>
			<persName><forename type="first">Lars</forename><forename type="middle">R</forename><surname>Knudsen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="169" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Chet: Compiler and runtime for homomorphic evaluation of tensor programs</title>
		<author>
			<persName><forename type="first">Roshan</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olli</forename><surname>Saarikivi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristin</forename><surname>Lauter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saeed</forename><surname>Maleki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madanlal</forename><surname>Musuvathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Mytkowicz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.00845</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cloud computing: issues and challenges</title>
		<author>
			<persName><forename type="first">Tharam</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 24th IEEE international conference on advanced information networking and applications</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="27" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Accelerating LTV based homomorphic encryption in reconfigurable hardware</title>
		<author>
			<persName><forename type="first">Yark?n</forename><surname>Dor?z</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erdin?</forename><surname>?zt?rk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erkay</forename><surname>Sava?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berk</forename><surname>Sunar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Cryptographic Hardware and Embedded Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="185" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evaluating the hardware performance of a million-bit multiplier</title>
		<author>
			<persName><forename type="first">Yarkin</forename><surname>Dor?z</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erdin?</forename><surname>?zt?rk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berk</forename><surname>Sunar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 Euromicro Conference on Digital System Design</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="955" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m">Session 14A: Security with little performance loss -Fast and furious! ASPLOS&apos;20</title>
		<meeting><address><addrLine>Lausanne, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">March 16-20, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Accelerating fully homomorphic encryption in hardware</title>
		<author>
			<persName><forename type="first">Yark?n</forename><surname>Dor?z</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erdin?</forename><surname>?zt?rk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berk</forename><surname>Sunar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="1509" to="1521" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A million-bit multiplier architecture for fully homomorphic encryption</title>
		<author>
			<persName><forename type="first">Yark?n</forename><surname>Dor?z</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erdin?</forename><surname>?zt?rk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berk</forename><surname>Sunar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Microprocessors and Microsystems</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="766" to="775" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Somewhat Practical Fully Homomorphic Encryption</title>
		<author>
			<persName><forename type="first">Junfeng</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederik</forename><surname>Vercauteren</surname></persName>
		</author>
		<ptr target="http://eprint.iacr.org/2012/144" />
	</analytic>
	<monogr>
		<title level="j">Cryptology ePrint Archive</title>
		<imprint>
			<date type="published" when="2012">2012. 2012/144</date>
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName><surname>Fv-Nfllib</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>n.d.</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName><surname>Fv-Nfllib</surname></persName>
		</author>
		<ptr target="https://github.com/CryptoExperts/FV-NFLlib.CryptoExperts" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Fully homomorphic encryption using ideal lattices</title>
		<author>
			<persName><forename type="first">Craig</forename><surname>Gentry</surname></persName>
		</author>
		<idno type="DOI">10.1145/1536414.1536440</idno>
		<ptr target="https://doi.org/10.1145/1536414.1536440" />
	</analytic>
	<monogr>
		<title level="m">41st Annual ACM Symposium on Theory of Computing</title>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Mitzenmacher</surname></persName>
		</editor>
		<meeting><address><addrLine>Bethesda, MD, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="169" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Implementing gentry&apos;s fullyhomomorphic encryption scheme</title>
		<author>
			<persName><forename type="first">Craig</forename><surname>Gentry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shai</forename><surname>Halevi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual international conference on the theory and applications of cryptographic techniques</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="129" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">CryptoNets: Applying neural networks to encrypted data with high throughput and accuracy</title>
		<author>
			<persName><forename type="first">Ran</forename><surname>Gilad-Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Dowlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristin</forename><surname>Lauter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Naehrig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Wernsing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="201" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An Improved RNS Variant of the BFV Homomorphic Encryption Scheme</title>
		<author>
			<persName><forename type="first">Shai</forename><surname>Halevi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuriy</forename><surname>Polyakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Shoup</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-12612-4_5</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-12612-4_5" />
	</analytic>
	<monogr>
		<title level="m">Topics in Cryptology -CT-RSA 2019</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Mitsuru</forename><surname>Matsui</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg, Germany, San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11405</biblScope>
			<biblScope unit="page" from="83" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Accelerating Integer Based Fully Homomorphic Encryption Using Frequency Domain Multiplication</title>
		<author>
			<persName><forename type="first">Shakirah</forename><surname>Hashim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Benaissa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information and Communications Security</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="161" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Assessing the security risks of cloud computing</title>
		<author>
			<persName><forename type="first">Jay</forename><surname>Heiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Nicolett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Gartner report</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="29" to="52" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Polynomial multipliers for fully homomorphic encryption on FPGA</title>
		<author>
			<persName><forename type="first">Cedric</forename><surname>Jayet-Griffon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M-A</forename><surname>Cornelie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Maistri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R?gis</forename><surname>Ph Elbaz-Vincent</surname></persName>
		</author>
		<author>
			<persName><surname>Leveugle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 International Conference on ReConFigurable Computing and FPGAs (ReConFig)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Secure Outsourced Matrix Computation and Application to Neural Networks</title>
		<author>
			<persName><forename type="first">Xiaoqian</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miran</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristin</forename><forename type="middle">E</forename><surname>Lauter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongsoo</forename><surname>Song</surname></persName>
		</author>
		<idno type="DOI">10.1145/3243734.3243837</idno>
		<ptr target="https://doi.org/10.1145/3243734.3243837" />
	</analytic>
	<monogr>
		<title level="m">ACM CCS 2018: 25th Conference on Computer and Communications Security</title>
		<editor>
			<persName><forename type="first">David</forename><surname>Lie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mohammad</forename><surname>Mannan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Backes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xiaofeng</forename><surname>Wang</surname></persName>
		</editor>
		<meeting><address><addrLine>Toronto, ON, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1209" to="1222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Homomorphic processing unit (HPU) for accelerating secure computations under homomorphic encryption</title>
		<author>
			<persName><forename type="first">Khedr</forename><surname>Alhassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glenn</forename><surname>Gulak</surname></persName>
		</author>
		<idno>App. 10/298</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">385</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">US Patent</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">SHIELD: Scalable Homomorphic Implementation of Encrypted Data-Classifiers</title>
		<author>
			<persName><forename type="first">Alhassan</forename><surname>Khedr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glenn</forename><surname>Gulak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinod</forename><surname>Vaikuntanathan</surname></persName>
		</author>
		<idno type="DOI">10.1109/TC.2015.2500576</idno>
		<ptr target="https://doi.org/10.1109/TC.2015.2500576" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="2848" to="2858" />
			<date type="published" when="2016-09">2016. Sep. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Logistic regression model training based on the approximate homomorphic encryption</title>
		<author>
			<persName><forename type="first">Andrey</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongsoo</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miran</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keewoo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung</forename><surname>Hee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheon</forename></persName>
		</author>
		<idno type="DOI">10.1186/s12920-018-0401-7</idno>
		<ptr target="https://doi.org/10.1186/s12920-018-0401-7" />
	</analytic>
	<monogr>
		<title level="j">BMC Medical Genomics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">83</biblScope>
			<date type="published" when="2018-10-11">2018. 11 Oct 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Speeding up the Number Theoretic Transform for Faster Ideal Lattice-Based Cryptography</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Longa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Naehrig</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-48965-0_8</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-48965-0_8" />
	</analytic>
	<monogr>
		<title level="m">CANS 16: 15th International Conference on Cryptology and Network Security</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Sara</forename><surname>Foresti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Giuseppe</forename><surname>Persiano</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg, Germany, Milan, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">10052</biblScope>
			<biblScope unit="page" from="124" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">On-the-fly multiparty computation on the cloud via multikey fully homomorphic encryption</title>
		<author>
			<persName><forename type="first">Adriana</forename><surname>L?pez-Alt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eran</forename><surname>Tromer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinod</forename><surname>Vaikuntanathan</surname></persName>
		</author>
		<idno type="DOI">10.1145/2213977.2214086</idno>
		<ptr target="https://doi.org/10.1145/2213977.2214086" />
	</analytic>
	<monogr>
		<title level="m">44th Annual ACM Symposium on Theory of Computing</title>
		<editor>
			<persName><forename type="first">Howard</forename><forename type="middle">J</forename><surname>Karloff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Toniann</forename><surname>Pitassi</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1219" to="1234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A high-speed accelerator for homomorphic encryption using the karatsuba algorithm</title>
		<author>
			<persName><forename type="first">C?dric</forename><surname>Vincent Migliore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><forename type="middle">M?ndez</forename><surname>Seguin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vianney</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Lapotre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Tisserand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Fontaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><surname>Gogniat</surname></persName>
		</author>
		<author>
			<persName><surname>Tessier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Embedded Computing Systems (TECS)</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">138</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Accelerating integer-based fully homomorphic encryption using Comba multiplication</title>
		<author>
			<persName><forename type="first">Ciara</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>M?ire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Neill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth O'</forename><surname>Hanley</surname></persName>
		</author>
		<author>
			<persName><surname>Sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Workshop on Signal Processing Systems (SiPS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title/>
		<author>
			<persName><surname>Nufhe Nucypher</surname></persName>
		</author>
		<ptr target="https://github.com/nucypher/nufhe" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A custom accelerator for homomorphic encryption applications</title>
		<author>
			<persName><forename type="first">Erdin?</forename><surname>?zt?rk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yark?n</forename><surname>Dor?z</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erkay</forename><surname>Sava?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berk</forename><surname>Sunar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="3" to="16" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Accelerating Somewhat Homomorphic Evaluation using FPGAs</title>
		<author>
			<persName><forename type="first">Erdin?</forename><surname>?zt?rk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yarkin</forename><surname>Dor?z</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berk</forename><surname>Sunar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erkay</forename><surname>Savas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IACR Cryptology ePrint Archive</title>
		<imprint>
			<biblScope unit="page">294</biblScope>
			<date type="published" when="2015">2015. 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Accelerating homomorphic evaluation on reconfigurable hardware</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>P?ppelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Naehrig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Putnam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Macias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Cryptographic Hardware and Embedded Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="143" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Modular hardware architecture for somewhat homomorphic function evaluation</title>
		<author>
			<persName><forename type="first">Sujoy</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Kimmo</forename><surname>J?rvinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederik</forename><surname>Vercauteren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Cryptographic Hardware and Embedded Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="164" to="184" />
		</imprint>
	</monogr>
	<note>Vassil Dimitrov, and Ingrid Verbauwhede</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">HEPCloud: An FPGA-based multicore processor for FV somewhat homomorphic function evaluation</title>
		<author>
			<persName><forename type="first">Sujoy</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Kimmo</forename><surname>J?rvinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jo</forename><surname>Vliegen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederik</forename><surname>Vercauteren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingrid</forename><surname>Verbauwhede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="1637" to="1650" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">FPGA-Based High-Performance Parallel Architecture for Homomorphic Computing on Encrypted Data</title>
		<author>
			<persName><forename type="first">Sujoy</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Furkan</forename><surname>Turan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kimmo</forename><surname>Jarvinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederik</forename><surname>Vercauteren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingrid</forename><surname>Verbauwhede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="387" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<author>
			<persName><surname>Seal</surname></persName>
		</author>
		<ptr target="https://github.com/Microsoft/SEAL" />
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Microsoft Research</publisher>
			<pubPlace>Redmond, WA</pubPlace>
		</imprint>
	</monogr>
	<note>Microsoft SEAL (release 3.3</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A survey on security issues in service delivery models of cloud computing</title>
		<author>
			<persName><forename type="first">Subashini</forename><surname>Subashini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veeraruna</forename><surname>Kavitha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of network and computer applications</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Accelerating leveled fully homomorphic encryption using GPU</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinming</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE International Symposium on Circuits and Systems (ISCAS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2800" to="2803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Accelerating fully homomorphic encryption using GPU</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lianmu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinming</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berk</forename><surname>Sunar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Exploring the feasibility of fully homomorphic encryption</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lianmu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinming</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berk</forename><surname>Sunar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="698" to="706" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">FPGA implementation of a large-number multiplier for fully homomorphic encryption</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinming</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Symposium on Circuits and Systems (ISCAS2013)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2589" to="2592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">VLSI design of a large-number multiplier for fully homomorphic encryption</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinming</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niall</forename><surname>Emmart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Weems</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Very Large Scale Integration (VLSI) Systems</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1879" to="1887" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
