<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Open constraint programming</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Boi</forename><surname>Faltings</surname></persName>
							<email>boi.faltings@epfl.ch</email>
							<affiliation key="aff0">
								<orgName type="department">IN-Ecublens</orgName>
								<orgName type="laboratory">Artificial Intelligence Laboratory (LIA)</orgName>
								<orgName type="institution">Swiss Federal Institute of Technology (EPFL)</orgName>
								<address>
									<postCode>CH-1015</postCode>
									<settlement>Ecublens</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Santiago</forename><surname>Macho-Gonzalez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">IN-Ecublens</orgName>
								<orgName type="laboratory">Artificial Intelligence Laboratory (LIA)</orgName>
								<orgName type="institution">Swiss Federal Institute of Technology (EPFL)</orgName>
								<address>
									<postCode>CH-1015</postCode>
									<settlement>Ecublens</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Open constraint programming</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">84FCCD2726D96A9184F7A6DDD275A6EC</idno>
					<idno type="DOI">10.1016/j.artint.2004.10.005</idno>
					<note type="submission">Received 6 March 2003; accepted 1 October 2004</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Constraint satisfaction</term>
					<term>Multi-agent systems</term>
					<term>Distributed AI</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Traditionally, constraint satisfaction problems (CSP) have assumed closed-world scenarios where all domains and constraints are fixed from the beginning. With the Internet, many of the traditional CSP applications in resource allocation, scheduling and planning pose themselves in open-world settings, where domains and constraints must be discovered from different sources in a network. To model this scenario, we define open constraint satisfaction problems (OCSP) as CSP where domains and constraints are incrementally discovered through a network. We then extend the concept to open constraint optimization (OCOP).</p><p>OCSP can be solved without complete knowledge of the variable domains, and we give sound and complete algorithms. We show that OCOP require the additional assumption that variable domains and relations are revealed in non-decreasing order of preference. We present a variety of algorithms for solving OCOP in the possibilistic and weighted model.</p><p>We compare the algorithms through experiments on randomly generated problems. We show that in certain cases, open constraint programming can require significantly less information than traditional methods where gathering information and solving the CSP are separated. This leads to a reduction in network traffic and server load, and improves privacy in distributed problem solving.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Constraint satisfaction in distributed information systems</head><p>Constraint satisfaction has been applied with great success to resource allocation, scheduling, planning and configuration. Traditionally, these problems are solved in a closed-world setting: first all variables, domains, constraints and relations are defined, then the CSP is solved by a search algorithm.</p><p>With the increasing use of the Internet, many of the problems that CSP techniques are good at now pose themselves in a distributed setting. For example, in personnel allocation, it is possible to obtain additional staff on short notice. In configuration, it is possible to locate additional suppliers of parts through the Internet. In an auction, it may be possible to look for additional bidders.</p><p>This change in setting makes a fundamental difference to the underlying constraint satisfaction problem. Most successful CSP methods, in particular constraint propagation, are based on the closed-world assumption that the domains of variables are completely known and fixed. In an open world, this assumption no longer holds.</p><p>Furthermore, each information gathering step is orders of magnitude more expensive than constraint checks while searching for a consistent solution. Consequently, the main criterion for performance in a distributed setting is the number of queries made in information gathering.</p><p>In this paper, we define Open Constraint Satisfaction Problems (OCSP) to model such scenarios, and show algorithms that solve them while querying only a fraction of the available values. We then extend the framework to Open Constraint Optimization Problems (OCOP) where not only choices, but also preferences are gathered incrementally from the network. Optimization becomes feasible by introducing the assumption that information sources always report their most preferred values first, thus ruling out the possibility that better choices could remain undiscovered after the algorithm finishes. We then present algorithms for solving OCSP and two variants of OCOP: possibilistic and weighted optimization. We compare the performance of these algorithms to other methods by systematic tests on randomly generated problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Open constraint satisfaction problems</head><p>Constraint satisfaction problems (CSP) are commonly defined as a tuple X, D, C, R where • X = {x 1 , . . . , x n } is a set of variables, • D = {d 1 , . . . , d n } is a set of corresponding domains, • C = {c 1 , . . . , c m } is a set of constraints, given as sets of variables, • R = {r 1 , . . . , r m } is a set of relations.</p><p>We consider CSP with discrete, but possibly unbounded domains (allowing integers but not real numbers). Relations can be intensional such as =, , = and specified independently of the variable domains, or extensional and specified by a list of allowed value tuples. We consider the setting shown in Fig. <ref type="figure" target="#fig_0">1</ref>. We assume that the set of variables, constraints and intensional relations is fixed and unchanging during the solving process. However, for variable domains and extensional relations, the CSP solver can access an unbounded set of information sources through a mediator. The mediator is a directory that indexes the information that can be found on the information servers. Such directories already exist in unstructured form (Yahoo), and industry is working towards formal models based for example on the UDDI standard.</p><p>The mediator model could provide separate queries for variables and extensional constraints. This, however, greatly complicates the algorithms. An elegant notation for unifying both types of queries is to encode OCSP using the hidden variable encoding <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref>. In this encoding, each extensional constraint is represented as an additional variable with a tuple-valued domain representing the corresponding relation. To ensure a consistent assignment, they are connected to the variables of the constraint using binary intensional relations <ref type="bibr" target="#b1">[2]</ref>. Specifically, if x c is a new tuple-valued variable replacing an extensional constraint between variables (x i1 , x i2 , . . . , x ik ), this variable will have an intensional relation r j with each x ij , j = 1, . . . , k, where r j is a binary constraint that enforces equality between the j th element of the value of x c and the value of x ij . The hidden variable encoding applies to any discrete CSP and represents an equivalent problem. Without loss of generality, we therefore assume that CSP are encoded using this notation, and consider that only variables can have their domains extended through additional queries.</p><p>We assume that the mediator implements the following functionality:</p><p>• a more(xi) message requests the mediator to gather one additional value for a variable domain, • the mediator will then contact the relevant information sources, and either return a value, or indicate that no further values can be found using a nomore(xi) message.</p><p>Many distributed information systems <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7]</ref>, would first gather all values and then apply standard CSP techniques to solve the problem. However, this solution is very inefficient, and even infeasible when the number of information sources is unbounded. We therefore define the following new model:</p><formula xml:id="formula_0">Definition 1.</formula><p>An open constraint satisfaction problem (OCSP) is a possibly unbounded, partially ordered set {CSP(0), CSP(1), . . .} of constraint satisfaction problems, where CSP(i) is defined by a tuple X, C, D(i), R(i) where</p><formula xml:id="formula_1">• X = {x 1 , x 2 , . . . , x n } is a set of n variables, • C = {(x i , x j ), (x k , x l ), .</formula><p>. .} is a set of m binary constraints, given by the pairs of variables they involve,</p><formula xml:id="formula_2">• D(i) = {d 1 (i), d 2 (i), . . . , d n (i)} is the set of domains for CSP(i), with d k (0) = {} for all k, • R = {r 1 , r 2 , . . . , r m } is the set of intensional relations corresponding to the constraints.</formula><p>The set is ordered by the relation ≺ where</p><formula xml:id="formula_3">CSP(i) ≺ CSP(j ) if and only if (∀k ∈ [1, . . ., n])d k (i) ⊆ d k (j ) and (∃k ∈ [1, . . . , n])d k (i) ⊂ d k (j ).</formula><p>An assignment to an OCSP is a combination of value assignments from the corresponding domains to all variables. An assignment is consistent in instance CSP(i) if and only if all intensional constraints are satisfied. A solution of an OCSP is an assignment that is consistent for some instance CSP(i) and any instance CSP(j ) CSP(i).</p><p>The following property shows that OCSP can be solved without knowledge of the complete problem: Lemma 1. Let A be a consistent assignment to an instance CSP(i) of an OCSP. Then A is also a consistent assignment to all instances CSP(j ), CSP(i) ≺ CSP(j ) of the same OCSP.</p><p>Proof. As the domains of CSP(i) are contained in those of CSP(j ), A is also an assignment in CSP(j ). As the constraints remain the same, it remains consistent. 2 Thus, if we find a consistent assignment to an instance CSP(i), we have found a solution to the OCSP, and do not need to examine any further values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Example</head><p>As an example, consider the scenario illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>. A company has to decide on three design features x 1 , x 2 and x 3 of a new product. The space of options is x 1 ∈ {A, B, C}, x 2 ∈ {A, C} and x 3 ∈ {B, C}. The product requires three subassemblies S 1 , S 2 and S 3 , where S 1 influences features x 1 and x 2 , S 2 influences x 1 and x 3 , and S 3 all three features. These influences are modelled as constraints with associated extensional relations. Fig. <ref type="figure" target="#fig_1">2</ref> also shows the hidden variable encoding. The constraints of subassemblies S 1 through S 3 are now encoded as additional variables x 4 through x 6 . Fig. <ref type="figure" target="#fig_1">2</ref> shows the domains that would eventually be discovered in this problem.</p><p>The company discovers these relations by asking suppliers to make offers for the subassemblies, and would like to find a feasible solution with a minimum amount of effort, i.e., asking a minimum number of offers of the suppliers. The example in Fig. <ref type="figure" target="#fig_1">2</ref> has a solution x 1 = A, x 2 = A, x 3 = B that can be computed by asking only the first value for each variable, rather than discovering the entire constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Extension to optimization problems</head><p>In practice, it often required to not only find a solution that satisfies a set of constraints, but to find a solution that is optimal with respect to some criteria. The CSP framework can be extended to handle optimization problems by allowing some constraints to be soft. In soft CSP, every value or combination of values is associated with a cost and the goal is to optimize a combination of these costs. <ref type="bibr" target="#b7">[8]</ref> defines a semiring-based framework that unifies a wide variety of different formalisms that have been proposed for combining and comparing these costs. From an algorithmic point of view, however, it is often useful to distinguish two cases:</p><p>• possibilistic constraint satisfaction <ref type="bibr" target="#b8">[9]</ref>, also sometimes called MAX-VCSP and similar to Fuzzy CSP <ref type="bibr" target="#b9">[10]</ref>, where the optimization goal is to minimize the maximum cost of any constraint. For example, the company would like a combination of subassemblies that minimizes the maximum delivery delay; • weighted constraint satisfaction, where the optimization goal is to minimize the sum of the costs of the constraints. Weighted constraint satisfaction is a generalization of partial constraint satisfaction <ref type="bibr" target="#b10">[11]</ref>. For example, the company would like to minimize the total cost of the subassemblies.</p><p>In the semiring framework of <ref type="bibr" target="#b7">[8]</ref>, the possibilistic case corresponds to the × operator being max, and the weighted case to the × operator being addition. The soft constraint framework allows expressing a wide variety of optimization problems. Similar to the constraint satisfaction case, we assume that hidden-variable encoding is used to transform the problem into one where only variable domains are open and need to be dynamically modified. We thus define:</p><formula xml:id="formula_4">Definition 2.</formula><p>An open constraint optimization problem (OCOP) is an unbounded, partially ordered set {COP(0), COP(1), . . .} of constraint optimization problems, where COP(i) is defined by a tuple X, C, D(i), R, W (i) :</p><p>• X, C, D(i), R are instances of an OCSP; • W (i) = {w 1 (i), w 2 (i), . . . , w n (i)} is a set of cost (weight) functions on the domains in D, where w i : d i → R + gives the cost associated with each value in the domain d i .</p><p>The set is ordered as the instances of the corresponding OCSP. An assignment is optimal for an instance COP(i) if and only if it is consistent for the CSP(i) and there is no other consistent assignment of COP(i) such that the sum (for weighted COP) or the maximum (for possibilistic COP) of the weights of all values w j (v(x j )) is smaller.</p><p>An assignment is the solution to an instance COP(i) if and only if it is optimal and there is no other optimal assignment that is lexicographically smaller.</p><p>An assignment is a solution to an OCOP if it is the solution for an instance COP(i) and optimal for all instances COP(j ), COP(i) ≺ COP(j ).</p><p>To make the cost functions accessible, the mediator now returns option(vi,w(vi)) as a pair.</p><p>At first glance, it would seem impossible to compute optimal solutions in an open setting, since it could always be that additional values that have not been discovered yet would lead to a better solution than the one proposed. To avoid this, we make the following important assumption: Monotonicity Assumption. For each variable, the mediator provides values always in strictly non-decreasing order of cost.</p><p>This assumption is indeed realistic in many distributed problems: for example, in a negotiation situation participants would always propose their most preferred (lowest cost) options first, and when options are found using search engines they would also return the best matches first. We can show that this assumption is necessary for open optimization: Theorem 1. When the monotonicity assumption does not hold, there is no general algorithm for solving OCOP that is guaranteed to terminate with the optimal solution without querying the entire domain of all variables.</p><p>Proof. When the monotonicity assumption does not hold, it is possible for a problem to have one consistent assignment with cost 0 such that all of its values are only discovered as the very last ones, and have all other consistent assignments with cost &gt; 0. Since a general algorithm cannot know whether such a case is present, for any problem that does not have a solution with cost = 0 it will have to check all domains completely to rule out this case and guarantee optimality. 2</p><p>Later in the paper, we will see sufficient conditions for guaranteeing that the optimal solution to an instance COP(i) is indeed the solution to the OCOP, and algorithms that ensure these conditions.</p><p>The example given in Fig. <ref type="figure" target="#fig_1">2</ref> is extended to an optimization setting by associating a cost with every variable/value combination. Specifically, we assume that for x 1 and x 2 , A has a cost of 0, B has a cost of 1, and C has a cost of 2, while for x 3 , B has a cost of 0 and C has a cost of 2. For the three additional variables x 4 through x 6 , we assume the following costs:</p><formula xml:id="formula_5">S 1 ⇒ r 4 ⇒ x 4 : S 2 ⇒ r 5 ⇒ x 5 : S 3 ⇒ r 6 ⇒ x 6 : (x 1 , x 2 ) cost (B, C) 0 (A, C) 1 (B, A) 3 (A, A) 5 (x 1 , x 3 ) cost (A, C) 0 (A, B) 1 (B, C) 3 (B, B) 5 (x 1 , x 2 , x 3 ) cost (x 1 , x 2 , x 3 ) cost (A, A, B) 0 (B, C, C) 4 (B, A, B) 0 (C, A, C) 4 (A, A, C) 2 (C, C, C) 6 (A, C, B) 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related work</head><p>Within the CSP community, the work that is closest to ours is interactive constraint satisfaction (ICSP), introduced in <ref type="bibr" target="#b11">[12]</ref>. Similarly to our work, in ICSP domains are acquired incrementally from external agents. The forward checking algorithm is modified so that when domains become empty, it launches a specific request for additional values that would satisfy the constraints on that variable. In earlier work <ref type="bibr" target="#b12">[13]</ref>, the same authors also show how arc consistency algorithms can be provided with the right dependency structures so that consistency can be adapted to values that might be added later. However, ICSP has a strong focus on the efficiency of the CSP search algorithm rather than on minimizing information gathering; it typically gathers significantly more values than necessary. It also does not address the problems of an open environment, in particular it limits itself to finite domains and assumes that variable domains can be exhaustively retrieved from the information agents.</p><p>Mailharro <ref type="bibr" target="#b13">[14]</ref> proposes a framework for constraint satisfaction in configuration where variable domains include wildcards that stand for possible future values. However, his work does not include algorithms for solving such systems with a minimum number of value queries.</p><p>Open constraint satisfaction bears some resemblance to the dynamic constraint satisfaction problem (DCSP), where constraints are added and removed over time. Bessière <ref type="bibr" target="#b14">[15]</ref> has shown methods for dynamically adapting consistency computations to such changes. However, dynamic CSP methods require that the set of all possible domain values is known beforehand, and thus do not apply to the OCSP problem. Another major difference is that OCSPs are restricted to a monotonic ordering of domains and values, while DCSP allow adding and removing variables in any order.</p><p>Another related area are distributed search algorithms for CSP(DisCSP), investigated in particular by Yokoo <ref type="bibr" target="#b15">[16]</ref> and more recently also other researchers. DisCSP does not require agents to announce the complete variable domains beforehand, so by its formulation it would also allow them to be open. However, all known systematic search algorithms for solving DisCSP rely on closed-world assumptions over variable domains for initiating backtracks. Distributed local search algorithms require complete knowledge of variable domains at each local optimization step. Thus, both are not applicable to the context of open constraint programming.</p><p>There has been some research into using constraints as a formalism for representing and integrating information, in particular the KRAFT project <ref type="bibr" target="#b16">[17]</ref> and the FIPA CCL content language <ref type="bibr" target="#b17">[18]</ref>. These address in particular issues of how to represent constraints in languages such as XML so that it is easy to carry out composition. They will be important for practical implementations of OCSP.</p><p>Research in the database community has addressed issues of information gathering and information retrieval, starting with federated databases <ref type="bibr" target="#b18">[19]</ref>, then dynamic information integration <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b19">20]</ref>, and finally multi-agent information systems such as InfoSleuth <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. Significant work has gone into matchmaking between queries and information sources. In our research, we use an ontology-based classification similar to that of <ref type="bibr" target="#b20">[21]</ref>. There are significantly more complex matchmaking techniques such as the Information Manifold <ref type="bibr" target="#b6">[7]</ref>. Decker and Sycara <ref type="bibr" target="#b21">[22]</ref> investigate the efficiency of middle-agent systems, and Sycara <ref type="bibr" target="#b22">[23]</ref> elaborates on their use as information agents. Techniques such as LARKS <ref type="bibr" target="#b23">[24]</ref> show that much more complex classifications than simply ontologies are possible. Thus, there is a sufficient technology base for implementing the mediator functionality we assume in this paper.</p><p>Recently, researchers in information retrieval have paid more attention to driving information retrieval from the task that users are trying to solve. Systems such as Watson and I2I <ref type="bibr" target="#b24">[25]</ref> and just-in-time information retrieval <ref type="bibr" target="#b25">[26]</ref> automatically retrieve information from databases, mail archives and other information sources by matching it with keywords that occur in the current activity of the user-for example, a document being prepared.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Algorithms for OCSP</head><p>We first consider algorithms for solving open constraint satisfaction problems. The simplest algorithm is to first collect all values for all variables and then solve the CSP using a standard algorithm. We refer to this as classical CSP. Classical CSP can only be applied when domains are finite.</p><p>A better algorithm is to systematically query values for all variables only as long as no solution has been found. We call this algorithm, shown in Algorithm 1, o-search. In line 3, it calls a function solve that returns a solution to the current instance of the CSP if there is one. If there is none, the algorithm queries a new value for the domain of each variable x k whose domain is not exhaustively known, as indicated by the variable e k (lines 5-14), and restarts the process with the new domains. Algorithm 1 must be called initially with the array E = (e 1 . . . e n ) all set to OPEN. We can show: Theorem 2. o-search is sound and complete.</p><p>Proof. Any solution returned by o-search is a solution to some instance CSP(i). Thus, by Lemma 1, it is a solution to the OCSP, so the algorithm is sound. Furthermore, if there is an instance CSP(i) that has a solution, the algorithm will eventually explore this instance or an instance CSP(j ) CSP(i) and find this solution. Thus, the algorithm is complete.  if nv = nomore(x k ) then 12:</p><p>e k ← CLOSED 13: else 14: <ref type="figure">search(X,</ref><ref type="figure">D,</ref><ref type="figure">C,</ref><ref type="figure">R,</ref><ref type="figure">E</ref>) Algorithm 1. o-search: an incremental algorithm for solving OCSP.</p><formula xml:id="formula_6">d k ← d k ∪ {nv} 15: o-</formula><p>However, Algorithm 1 is not very efficient, since it blindly gathers values for every variable of the CSP without focussing on those parts that caused the failure.</p><p>To reduce the amount of unnecessary server accesses, information gathering must focus on finding additional options for the minimal unsolvable subproblems of the current instantiation of the CSP, defined as follows: Definition 3. An unsolvable subproblem of size k of an instance CSP(i) of an OCSP is a set of variables S = {x s1 , x s2 , . . . , x sk } such that there is no value assignment (x s1 ∈ d s1 , . . . , x sk ∈ d sk ) that satisfies all constraints between these variables.</p><p>The following lemma provides the basis for identifying variables that are part of minimal unsolvable subproblems. It was first discovered in a different context in <ref type="bibr" target="#b26">[27]</ref>: Lemma 2. Let a CSP be explored by a failed backtrack search algorithm with static variable ordering (x 1 , . . . , x n ), and let x k be the deepest node reached in the search with inconsistency detected at x k . Then x k , called the failed variable, is part of every unsolvable subproblem of the CSP involving variables in the set {x 1 , . . . , x k }.</p><p>Proof. In order to reach x k , the search algorithm has constructed at least one valid assignment to x 1 , . . . , x k-1 , so this set of variables does not contain any unsolvable subproblem. However, there is no consistent assignment to x 1 , . . . , x k , so this set does contain unsolvable subproblem(s). Since the only difference is x k , x k must be part of all of these unsolvable subproblems. 2 Algorithm 2, called fo-search (failure-driven open search) uses this lemma to identify the most promising variables for information gathering. It differs from Algorithm 1 in that the call to an external solver is replaced by the backtrack search in lines 2-12 that leaves k with the index of the deepest explored node. Steps 17-21 are identical to steps 10-14 of Algorithm 1. Note that no consistency techniques can be used in the search, although the chronological backtracking can be replaced with backjumping techniques to make it more efficient.</p><p>We are now going to show that fo-search is a complete algorithm for solving OCSP. We start with the following lemmas: Lemma 3. For any instances CSP(j ) and CSP(i) of an OCSP such that CSP(j ) CSP(i), if a subproblem S is unsolvable in CSP(j ) then it is also unsolvable in CSP(i).</p><p>Proof. Let S = {x t 1 , . . . , x tk }. By Definition 1, the domains d t 1 (i) ⊆ d t 1 (j ), . . . , d tk (i) ⊆ d tk (j ). If S was solvable in CSP(i), then the values used in its solution must also be part of the corresponding domains for CSP(j ). Thus, S could not be unsolvable in CSP(j ). 2 Lemma 4. Assume that the last k + 1 calls to Algorithm 2 have been with instances CSP(i 0 ), . . . , CSP(i k ), that the algorithm has last searched variables in the order x j 1 , . . . , x jk and identified the kth variable x jk as the failed variable, and that each of the instances CSP(i 0 ), . . . , CSP(i k ) has identical unsolvable subproblems. Then:</p><p>• in the last k calls, Algorithm 2 has called the mediator (function more) exactly once for each of the variables x j 1 , . . . , x jk ; • S = {x j 1 , . . . , x jk } is a minimal unsolvable subproblem of CSP(i k );</p><p>• the algorithm will continue to call more on each of the variables in S in turn until S becomes solvable.</p><p>Proof. As the algorithm always puts the variable for which it has called more values as the first in the search, the first claim follows directly from the function of the algorithm. Furthermore, S is unsolvable as no solution could be found by complete search. Suppose that it was not minimal, i.e., that there was a variable x jl such that S = S \ x jl was also unsolvable. x jl was the failed variable when fo-search was run on CSP(i l ), and that search must have included variable x jk . By Lemma 2, x jl was part of every unsolvable subproblem of CSP(i l ) that also involves x jk . But as x jk is the failed variable of subproblem S, by Lemma 2, it is part of every unsolvable subproblem involving variables in S. Consequently, every unsolvable subproblem within S must also involve x jl .</p><p>The third claim follows from the fact that as long as S is unsolvable, running fo-search on CSP(i k ) gives an identical result as running it on CSP(i 0 ). 2</p><p>We can now show completeness of Algorithm 2: Theorem 3. Suppose that an OCSP is solvable, i.e., by calling more on every variable a sufficient number of times we eventually reach an instance CSP(j ) such that for all CSP(m) CSP(j ), CSP(m) contains no unsolvable subproblems. Then Algorithm 2 will eventually terminate with a solution. Thus, the algorithm is complete.</p><p>Proof. CSP(1) has finitely many variables and thus finitely many unsolvable subproblems of size at most n. Assume that the algorithm never finds a solution; then since by Lemma 3, the set of unsolvable subproblems is monotonically non-increasing, there must exist an infinite sequence of calls to fo-search such that the unsolvable subproblems are always identical. By Lemma 4, in such a sequence the algorithm will eventually call for additional values for each variable of the same unsolvable subproblem S. Since the OCSP is solvable, these calls must eventually return values that will make S solvable. Thus, the sequence of calls where subproblems remain unsolvable cannot be infinite. 2</p><p>An interesting consequence of Theorem 3 is that if a problem is unsolvable and the set of available values is finite, the algorithm will stop while identifying a minimal unsolvable subproblem. This can be useful when it is possible to obtain information for several variables in parallel.</p><p>For efficiency reasons, it may be advantageous for the mediator to obtain values not only for single variables, but entire subproblems with a single query. Algorithm 2 can be modified for this case by not gathering additional values until a minimal unsolvable subproblem is completely identified. It can then call the mediator on that subproblem or subproblems that have a maximal overlap with that subproblem. However, it is important that every variable in the subproblem is eventually queried, for otherwise completeness is no longer guaranteed.</p><p>We compare the various algorithms experimentally on randomly generated coloring problems with 5-14 variables and 3-11 values per variable, and inequality constraints between randomly chosen variable pairs so that the graph is at least connected and at most complete. We start the algorithms with initially empty variable domains and measure performance on the number of accesses to information sources required to find a solution to the OCSP. We consider the following algorithms: classical CSP where all values are gathered initially, OS for o-search, systematically obtaining new values for all variables, FO for fo-search, where search for new values is driven by the failures of backtrack search, and interactive CSP <ref type="bibr" target="#b11">[12]</ref> which queries for values that are compatible with the previous assignments.</p><p>Fig. <ref type="figure" target="#fig_4">3</ref> plots the average number of values queried per variable against the average number of values in a variable domain. Note that while the number of values per variable varies between 3 and 11, in most cases their averages over a problem fall between 4 and 8 so we only have a meaningful number of runs for this range. The best methods are clearly o-search (Algorithm 1) and fo-search (Algorithm 2). They query only about 2-3 values per variable and this number rises only very slowly as the number of values increases. We can thus expect particularly significant savings on problems with large domains that often occur in distributed problem-solving. fo-search is not only the best algorithm overall in the number of queries, it also achieves this at only a modest increase in the number of constraint checks, whereas o-search suffers from a much larger search complexity. This is due to the fact that it does not reorder the problem to put the unsolvable subproblem at the beginning and thus often fails only much later in the search.</p><p>We can also observe a significant improvement over interactive constraint satisfaction as described in <ref type="bibr" target="#b11">[12]</ref>, which is expected as this algorithm does not have a heuristic for choosing which variables to query. However, ICSP requires slightly less constraint checks than fo-search.</p><p>Throughout the experiments, we have not observed any significant dependency of queries on constraint density, but it is possible to observe an increase in queries as the problem gets larger, particularly for the ICSP method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Algorithms for possibilistic open constraint optimization</head><p>In possibilistic constraint optimization, the goal is to minimize the maximum cost of any constraint. Any constraint satisfaction algorithm can be turned into an optimization algorithm for possibilistic CSP by introducing a threshold t for this maximum cost. Starting with the lowest possible threshold, it can be gradually increased until the problem becomes solvable.</p><p>In an open environment, we also have to consider the conditions for being able to guarantee that the optimal assignment to an instance of the problem is also optimal with respect to any later instance. In the satisfaction case, this was guaranteed by Lemma 1. For the possibilistic optimization case, we have as its equivalent: Lemma 5. An assignment to an instance COP(i) of a possibilistic OCOP with cost c * is optimal for all higher instances COP(j ), COP(i) ≺ COP(j ) if either:</p><p>• there is a subproblem whose optimal cost is c * , or • all domains have been generated completely or up to at least one value with cost c * , and there is no consistent assignment with lower possibilistic cost than c * .</p><p>Proof. The first case is straightforward as a COP cannot be solved unless every subproblem is solved. Since the cost of a complete solution is the maximum of the cost of all variables, and the best solution to the subproblem requires at least one variable to have cost c * , the maximum of the entire problem will also be at least c * . For the second case, the assume that there was an instance COP(j ) that admitted a solution with a lower cost c . Then this solution would have to use at least one value that is not part of COP(i). But since COP(i) ≺ COP(j ), such a value would have to have cost at least c * . Since the cost of a solution is the maximum of the cost of the constraints, the cost of the new solution cannot be less than c * . 2  <ref type="figure">search(X,</ref><ref type="figure">C,</ref><ref type="figure">D,</ref><ref type="figure">R,</ref><ref type="figure">W,</ref><ref type="figure">E,</ref><ref type="figure">M,</ref><ref type="figure">t</ref> For example, the optimal solution of the example given earlier under the possibilistic model is <ref type="figure">A,</ref><ref type="figure">C,</ref><ref type="figure">B</ref>) with a cost of 2. We can be sure that there is no solution with lower cost if this is the best solution when we have obtained all domains up to a cost of at least 2. What Lemma 5 shows is that it is sufficient to find a subproblem, for example (x 2 , x 4 ) whose best solution has cost 2 and generate the domains for its variables up to that cost; for all other variables, it is only necessary to search values as required to find a consistent solution.</p><formula xml:id="formula_7">x 1 = A, x 2 = C, x 3 = B, x 4 = (A, C), x 5 = (A, B), x 6 = (</formula><p>Algorithm 3 is an adaptation of Algorithm 2 that exploits this property to reduce the number of value queries required. Except for the condition in step 8, steps 2-16 are identical to those of Algorithm 2. The algorithm must be called initially with t = 0 and e k = OPEN, m k = UNMARKED for k = 1, . . ., n. Similarly to Algorithm 2, it is driven by failures of solution search. When new values can be queried with valuations lower than the current threshold t, they are queried immediately (steps <ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref>. When the valuation would exceed this threshold, the algorithm does not immediately query for new values once an unsolvable subproblem is found, but first ensures that it finds a minimal unsolvable subproblem. This is done by first only marking the variables until the same variable is encountered a second time (steps 24-26). Then, by Lemma 4, the algorithm has found a minimal unsolvable subproblem. After resetting the markings (step 27), it enters a loop where it systematically increases the domains with the lowest valuations for the variables in this subproblem until it becomes solvable (steps 28-36). When a solution to the subproblem is found through the call to the function optimize in step 35, the threshold t is increased to the valuation of this solution, and henceforth the algorithm allows any solution up to the threshold. Finally, as in fo-search, variables are reordered and the function called recursively. We can show that: Theorem 4. Algorithm 3 is sound, i.e., the solution it returns is optimal, and complete.</p><p>Proof. Let the cost of the final solution returned by Algorithm 3 be c * . Then the threshold t in the algorithm must reach at least c * , for otherwise it would not have passed the extension at step 8. The threshold can only be extended to c * if there is a subproblem whose optimal solution has valuation t and whose domains are all larger than t. But then this is a subproblem with optimal cost t = c * , and thus the solution with t = c * is optimal for the entire problem as well. The algorithm is complete because it is an adaptation of Algorithm 2 that queries values for complete unsolvable subproblems rather than individually. 2 Fig. <ref type="figure" target="#fig_6">4</ref> shows a comparison of the number of values queried by Algorithm 3 (possibilistic fo-search) and a classical COP algorithm that queries all values. The experiments were carried out on problems with 5-10 variables and 2-30 values per variable where both the constraint graph and the valuations of the tuples in each constraint were generated randomly. The results show a significant reduction in the number of values that need to be obtained when Algorithm 3 is used. At the same time, the increase in the number of constraint checks remains reasonable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Algorithms for weighted open constraint optimization</head><p>We now consider the problem of weighted OCOP, where the costs of each individual constraint are combined by adding them together like weights. This type of optimization occurs in practice for example when optimizing the price, and is therefore quite important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Optimality criteria for weighted OCOP</head><p>We first examine the question of how many domain values in an OCOP must be obtained in order to guarantee that a solution to an instance COP(i) is also optimal for all </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COP(j ), COP(i) ≺ COP(j ).</head><p>These considerations are valid for any optimization algorithm that may be used to solve the problem.</p><p>We denote by v * i x 1 ,...,x k (x j ) the value assigned to x j in the solution that is optimal for the subproblem x 1 , . . . , x k (of which x j is part) in the instance COP(i). v * is the corresponding notation for the values assigned in the optimal solution to the OCOP as a whole.</p><p>We first define:</p><p>Definition 4. The nuisance of a set A of variables with respect to a disjoint set B of variables, written n(A | B), is the difference between the cost of the assignments to variables in B in a solution to the problem of (A ∪ B) and the cost of the solution to B alone:</p><formula xml:id="formula_8">n(A | B) = x l ∈B c v * A∪B (x l ) -c v * B (x l ) .</formula><p>The nuisance calculated using the values in instance COP(i) is denoted n i .</p><p>In order to ensure that we find the optimal solution, we need to guarantee the following necessary condition: Definition 5. An instance COP(i) of an OCOP is subset domain-sufficient if the domains of its variables X are such that for any set of variables S ⊂ X, either:</p><p>• for all variables in S, there remain no further values to be queried, or • the nuisance of S with respect to X -S is not greater than the sum over all variables in S of the difference between the largest cost of any value obtained so far and cost of the value in the optimal solution for X:</p><formula xml:id="formula_9">n i (S | X -S) x l ∈S max v∈d l (i) w l (v) -w l v * i X (x l ) .</formula><p>We now state the following theorem:</p><p>Theorem 5. An optimal solution to an instance of an OCOP is guaranteed to be optimal with respect to all higher instances of the same OCOP if and only if the instance is subset domain-sufficient.</p><p>Proof. Suppose that the instance is subset domain-sufficient, and that a better assignment to the variables in X can be found using values not currently in the domains. Let S be the set of variables where such extra values are used. Each of the extra values v (x l ∈ S) will have a cost at least as great as all known values, i.e., we have:</p><formula xml:id="formula_10">w l v (x l ) max v∈d l (i) w l v(x l ) .</formula><p>The cost cost new of the new, better assignment is at least the cost of these new values plus the cost of a solution for the rest of the variables by themselves, i.e., cost new</p><formula xml:id="formula_11">x l ∈S w l v (x l ) + x l ∈X-S w l v * i X-S (x l ) x l ∈S max v∈d l w l v(x l ) + x l ∈X-S w l v * i X-S (x l ) .</formula><p>Now assume that the cost of the existing optimal solution cost old &gt; cost new :</p><formula xml:id="formula_12">cost old = x l ∈X-S w l v * i X (x l ) + x l ∈S w l v * i X (x l ) &gt; cost new x l ∈S max v∈d l (i) w l (v) + x l ∈X-S w l v * i X-S (x l )</formula><p>and by rearranging:</p><formula xml:id="formula_13">x l ∈X-S w l v * i X (x l ) -w l v * i X-S (x l ) = n(S | X -S) &gt; x l ∈S max v∈d l (i) w l (v) -w l v * i X (x l ) .</formula><p>But since the instance is domain-sufficient, no set S can satisfy this condition, so it cannot exist. Conversely, suppose that there is a set S that does not satisfy the condition of domainsufficiency. Then, by the same reasoning as above, there could a solution with cost new &lt; cost old using new values for the variables in S. 2 However, domain-sufficiency is not very useful in practice, as it does not specify conditions on the domains of individual variables. Furthermore, we can show: Theorem 6. There is no general algorithm for solving weighted OCOP that is guaranteed to solve any instance with a minimal number of queries.</p><p>Proof. Consider a problem with 3 variables x 1 , x 2 , x 3 with identical domains {a, b}, constraints that require all variables to have equal values, and the following costs:</p><formula xml:id="formula_14">Value x 1 x 2 x 3 a 0 2 0 b 3 0 1</formula><p>Note that by the symmetry of the problem, no algorithm can distinguish between x 1 and x 3 before it has queried the second value for both of them. Thus, if it generates the following instance:</p><formula xml:id="formula_15">x 1 x 2 x 3 a(0) b(0) a(0) b(3) a(2)</formula><p>which is subset domain-sufficient and proves the optimality of the solution x 1 = a, x 2 = a, x 3 = a, it may also generate the following instance:</p><formula xml:id="formula_16">x 1 x 2 x 3 a(0) b(0) a(0) a(2) b(1)</formula><p>which is not subset domain-sufficient because it still allows the possibility that x 1 admits value b at a cost of 0.5, which would make x 1 = b, x 2 = b, x 3 = b a better solution. Since an algorithm cannot distinguish the two cases, it cannot always query x 1 first, so it cannot always make a minimal number of queries. 2</p><p>We define therefore the following slightly stronger condition: Definition 6. An instance of an OCOP is singleton domain-sufficient if the domain of each variable either contains all values or contains all values up to a cost that at least equals the sum of its nuisance with respect to any other subproblem T and the cost of its assignment in the optimal solution to the subproblem T plus the variable:</p><formula xml:id="formula_17">max v∈d k (i) w k (v) n i {x k } | T + w k v * i T ∪{x k } (x k )</formula><p>which is useful because it can be tested on the domains of individual variables and can be the basis of a deterministic algorithm. Furthermore, it implies optimality, as we can show the following:</p><p>Theorem 7. An instance COP(i) of an OCOP which is singleton domain-sufficient is also subset domain-sufficient.</p><p>Proof. We prove this theorem by induction. First note that for singleton sets S = {x k }, the condition for singleton domain-sufficiency with T = X -S entails subset domainsufficiency. Now suppose that the theorem holds for set S, and consider the set S = S ∪ {x k }. By the induction hypothesis, we have on the one hand:</p><formula xml:id="formula_18">n i {x k } | X -S + n i (S | X -S) max v∈d k (i) w k (v) -w k v * i X-S (x k ) + x l ∈S max v∈d l (i) w l (v) -w l v * i X (x l ) -w k v * i X-S (x k ) + x l ∈S max v∈d l (i) w l (v) + max v∈d k (i) w k (v) = -w k v * i X-S (x k ) + x l ∈S max v∈d l (i) w l (v).</formula><p>By the definition of nuisance, we have on the other hand:</p><formula xml:id="formula_19">n i {x k } | X -S + n i (S | X -S) = x l ∈X-S w l v * i X-S (x l ) -w l v * i X-S (x l ) + x l ∈X-S w l v * i X (x l ) -w l v * i X-S (x l ) = w k v * i X (x k ) -w k v * i X-S (x k ) + x l ∈X-S w l v * i X (x l ) -w l v * i X-S (x l ) = w k v * i X (x k ) -w k v * i X-S (x k ) + n(S | X -S ) n i (S | X -S ) -w k v * i X-S (x k ) so that: n i (S | X -S ) -w k v * i X-S (x k ) -w k v * i X-S (x k ) + x l ∈S max v∈d l (i) w l (v), n i (S | X -S ) x l ∈S max v∈d l (i) w l (v)</formula><p>which completes the induction. 2</p><p>To clarify this concept, let us consider the example given earlier. The optimal solution under the weighted model is:</p><formula xml:id="formula_20">x 1 = A, x 2 = A, x 3 = B, x 4 = (A, A), x 5 = (A, B), x 6 = (A, A, B)</formula><p>with a total cost of 6. If we leave out variable x 5 , then the optimal solution is:</p><formula xml:id="formula_21">x 1 = B, x 2 = A, x 3 = B, x 4 = (B, A), x 6 = (B, A, B)</formula><p>with a total cost of 4. To be singleton domain-sufficient, the domain of x 5 has to include at least one element with a cost of at least 6 -4 = 2. Thus, the domain has to be known up to the first returned value with cost 2, in this case the values (A, C), (A, B) and (C, B). If it did not include the value (C, B), the optimization algorithm could not know that there was not another value (B, B) with cost 1 that would combine with the lowest cost solution without x 5 to produce an overall solution whose cost is 5 &lt; 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">An optimal algorithm for solving weighted OCOP</head><p>In the case of crisp CSP, the theoretical minimal number of queries is equal to one per variable: it occurs when the information sources happen to return just the value that is required for the solution as the first one. However, whether an algorithm achieves this bound depends not only on the algorithm itself, but also on the order in which information sources return these values. Thus, it is not possible to show that an algorithm is optimal.</p><p>In the corresponding optimization problem, the assumption of returning values in nondecreasing order of cost allows us to define a notion of minimality: the minimal number of values is what is required to satisfy singleton domain-sufficiency and thus guarantee optimality of the solution.</p><p>Algorithm 4 solves OCOP. It is a synthesis algorithm that incrementally generates optimal assignments for all connected subgraphs of size 1, . . ., n of the constraint graph. We use the notation SP(i) to denote these sets and COMPS(g) to denote the connected components of a subproblem g. The algorithm builds a table LB(g) that holds the cost of the optimal solutions for each connected subproblem g. For subproblems of size 1 containing only a single variable x i , the algorithm initializes the lower bound to the cost of the most preferred value in the domain of its variable x i (step 4). For every subproblem of size i (step 6), in step 8 the algorithm calls a closed-world optimization function c-opt that returns the cost and assignment of the optimal solution for the given subproblem with the given domains and weights. It can be implemented for example using a branch-and-bound optimization algorithm. It then determines the index k of the variable that comes closest to not being singleton domain-sufficient (steps 9-15). If this variable is indeed not singleton domain-sufficient, it queries an additional value (steps <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref>, and repeats the process until all variables are domain-sufficient. If there is a solution, this is the optimal solution to be filled in LB(g). The solution found in the final optimization is the one for the whole problem. Lemma 6. Consider a subproblem G in an instance COP(i) whose constraint graph consists of several maximal connected components g 1 , . . . , g k . Then COP(i) is singleton domain-sufficient for subproblem G if and only if it is singleton domain-sufficient for each of the subgraphs g 1 , . . . , g k . Proof. Let g 1 , . . . , g k be arbitrary subgraphs of the components g 1 , . . . , g k and let g l = k i=1 g i . Note that because the components have no constraints between them, we have for the cost of the optimal solutions:</p><formula xml:id="formula_22">c * (g l ) = c * (g 1 ∪ • • • ∪ g k ) = k j =1 c * (g j ).</formula><p>Now consider a variable x j ∈ g l , and its nuisance:</p><formula xml:id="formula_23">n(x j | g 1 ∪ • • • ∪ g k ) = k i=1 c * (g i ) -c * (g i \x j ) = c * (g l ) -c * (g l \x j ) = n(x j | g l ).</formula><p>Since singleton domain-sufficiency only depends on the nuisance of each variable, the domain of x j in COP(i) satisfies it if and only if it is satisfies it for subproblem g l . Thus, COP(i) is singleton domain-sufficient with respect to G if and only if this condition holds for all the component subproblems g 1 , . . . , g k . 2 Lemma 7. For each connected subproblem, Algorithm 4 makes exactly the queries necessary to ensure singleton domain-sufficiency and determines the optimal solution.</p><p>Proof. We prove this by induction on the size of the subproblems. It clearly holds for all subproblems of size 1, since these are the individual variables. Now consider a subproblem g involving i variables, i &gt; 1, and assume that the current instance of the COP is domain-sufficient with respect to all subproblems of size i -1 and that LB contains the cost of the optimal solutions for all subproblems of size i -1.</p><p>The algorithm considers each variable of g and determines the variable x k that would miss the condition of singleton domain-sufficiency by the largest margin, or equivalently, that has the lowest lower bound on a solution that could be found by extending its domain. If the domain of x k is indeed not singleton domain-sufficient, or if there is no solution to the subproblem in the current instance COP(i), the algorithm extends the domain of x k .</p><p>In the first case, even if another variable x l was also not domain-sufficient, the best cost of an optimal solution that could be achieved by obtaining another value for x l would be lb l lb k and x k would still not be domain-sufficient. Thus, the query is necessary to ensure domain-sufficiency.</p><p>In the second case, as no solution has been found yet, the optimal solution has a cost at least as high as lb k , so that x k could not be domain-sufficient. Thus, again the query is necessary to ensure domain-sufficiency.</p><p>The algorithm repeats this process until the domains of all variables are singleton domain-sufficient. Thus, when it terminates, the domains of all variables in g are singleton domain-sufficient with respect to g, and the optimizer has thus found the optimal solution. 2 Theorem 8. When Algorithm 4 terminates, the domains of the variables are singleton domain-sufficient, and the solution returned is the optimal solution.</p><p>Proof. By Lemma 7, the algorithm ensures singleton domain-sufficiency for all connected subproblems. By Lemma 6, this means that the condition also holds for all not connected subproblems. 2 Theorem 9. Algorithm 4 makes the minimal number of queries necessary to ensure singleton domain-sufficiency.</p><p>Proof. Follows from Lemma 7. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Best-first algorithms</head><p>Another approach is to use best-first algorithms based on A * that incrementally generate all possible assignments. Algorithm 5 is inspired by the preference elicitation algorithm of Conen and Sandholm <ref type="bibr" target="#b27">[28]</ref> for combinatorial auctions. It maintains a list OPEN of candidate assignments that is ordered according to their cost. It systematically adds all successors until it finds the first consistent assignment in step 8. This assignment is an optimal solution, since all assignments of lower weights have already been searched and found inconsistent in best-first manner (as in the A* algorithm). Whenever necessary, it queries additional values in step 14. We can show the following:  Proof. Soundness is guaranteed by the fact that the algorithm only returns consistent assignments and systematically explores all assignments in strictly non-decreasing order of cost, so that the one returned is also the one with the lowest cost. Completeness is guaranteed by the fact that the algorithm systematically enumerates all assignments. 2 Algorithm 6 significantly improves on this based on the observation that it is not necessary to generate all successors to an assignment a: Lemma 8. Let a = (a(1), . . ., a(n)) be an inconsistent assignment, let c(x i1 , . . . , x ij ) be a violated constraint, and consider the direct successor assignments b k = (a(1), . . ., succ(a(k), d k ), . . . , a(n). Provided that all successors b i1 , . . . , b il are considered, all other successors are redundant and can be pruned in Algorithm 5 without affecting its soundand completeness.</p><p>Proof. When k / ∈ {i1, . . ., ij} we have that:</p><p>1: Function i-o-opt(OCOP) . . . 13: nxj ← more(x j , a j , C, {a(l) | l &lt; j}) 14: if nxj = NIL then 15:</p><p>b ← (a(1), . . . , a(j -1), nxj, a(j + 1), . . . , a(n)) 16:</p><p>. . . . . . A potential problem with Algorithm 6 is that it keeps a complete list OPEN of all currently best nodes, so that memory consumption can become a problem. If necessary, the OPEN list can be incrementally regenerated by a depth-first search process such as IDA * <ref type="bibr" target="#b28">[29]</ref>, limiting memory consumption at the expense of additional computation time. It is straightforward to obtain the same behavior by querying additional values for the variables involved in the first conflict of the candidate tightest to the current cost limit.</p><p>For comparison, we also considered an interactive model similar to that given in <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> where the mediator itself could query for the best value that is compatible with a set of assignments and constraints. Thus, the function more takes as additional arguments a set of constraints and a set of assignments to other variables, and returns the best value with cost at least that of a j that could be compatible with these constraints and the value assignments.</p><p>Algorithm 7 implements this as a modification of Algorithm 6. The difference with Algorithm 6 is that all values that would be inconsistent with the previous instantiation are skipped. We can show: Theorem 12. Assume that the variables of an OCSP have a fixed ordering. Then, in Algorithm 6, for a variable x j all successors that are not consistent with earlier assignments are redundant. Consequently, Algorithm 7 is complete.</p><p>Proof. We prove the theorem inductively. Since x 1 has no predecessor, the algorithm here is the same as Algorithm 6 and thus complete. Assume that Algorithm 7 explores all consistent assignments for variables x 1 , . . . , x j -1 in increasing order of cost. Then any consistent successor to an assignment where x j is inconsistent either shares the same values for x 1 , . . . , x j -1 , and would also be found when only consistent successors are considered, or it has different values for x 1 , . . . , x j -1 . In the second case, it would also be a successor to another assignment that by the inductive hypothesis has already been generated. In both cases, the inconsistent assignment is redundant and thus the hypothesis also holds for x 1 , . . . , x j . By induction, Algorithm 7 is complete. 2 We can see that Algorithm 6 (FOOPT) is quite close to the optimum. For interactive optimization, we show two curves. I-O-OPT shows the number of queries the algorithm makes to the mediator, and corresponds to the amount of network traffic generated. This curve shows the main weakness of the interactive model: since the optimization procedure cannot know whether a value is has already seen is optimal for a given assignment, it has to make a query every time it examines a new assignment. The second curve, I-O-OPT-R, shows the number of different values revealed during the process. This curve shows the strength of the interactive model: it is best with respect to the number of values that have to actually be revealed. Note that this beats the optimal algorithm because it assumes a more powerful model of the mediator. Fig. <ref type="figure" target="#fig_9">5</ref> also shows a comparison of the same algorithms with respect to computation effort represented by the number of constraint checks. Here we see that Algorithms 6 and 7 are orders of magnitude more efficient than the optimal one, and will be the most applicable for practical applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Experimental evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>Many new and exciting applications in open information systems, in particular the WWW, address problems which CSP techniques are very good at solving. Such applications will appear increasingly with the emergence of web services and the semantic web. Our first contribution is to have defined Open Constraint Satisfaction Problems (OCSP) and their extension to optimization as a formulation that addresses this open setting.</p><p>The second contribution is to have shown an effective method for identifying minimal unsolvable subproblems and thus focussing information gathering. Based on this, we have given an algorithm that is provably complete even for unbounded variable domains, and demonstrated that on random coloring problems, it achieves a performance very close to the theoretical minimum as far as accesses to information servers is concerned.</p><p>In particular, the gains tend to increase with both the number of information servers and the number of values they provide. Thus, the technique is likely to be particularly useful to improve the scalability of intelligent information systems based on constraint satisfaction techniques.</p><p>The next contributions are based on the generalization to constraint optimization problems. This generalization is based on the assumption that agents always return their best options first. This assumption holds in many realistic settings, for example in supply chain optimization it will be normal for suppliers to present their best offers first.</p><p>The third contribution is an extension of the technique to open possibilistic constraint satisfaction, a class of constraint optimization problems. We have shown an algorithm that efficiently computes the optimal solution with a small number of value queries.</p><p>The fourth and final contribution is an algorithm for weighted constraint satisfaction that is provably optimal in the number of value queries, i.e., it does not query more values than necessary to ensure singleton domain-sufficiency and thus guarantee optimality of the final solution.</p><p>In general, we reduce the number of values that have to be queried by factors from 2 to 5, with significantly higher gains if there are many suboptimal values. If this gain does not seem to be very high for an individual process, note that in a multi-agent system, each value query launches another computational process so that the gains multiply. For example, in a supply chain of just 5 agents, a gain of 4 will translate to an overall efficiency gain by a factor of 4 5 = 1024. Note also that the constant factor gain for individual domains translates to a reduction in the size of the search space that is exponential in the number of variables, explaining the apparent discrepancy with some work in preference elicitation for combinatorial auction that observes exponential improvements.</p><p>We have made a first step towards extending constraint satisfaction and optimization towards open world scenarios. In particular, the problem of open constraint optimization turns out to be computationally very hard, and we need to discover the proper heuristics to make it tractable for large problems. While the traditional CSP tricks are unfortunately not sufficient for this, we expect that similarly powerful methods can be found in further research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Elements of an open constraint satisfaction problem: the CSP solver accesses an unbounded number of information sources through a mediator that performs the mapping from problem variables to relevant information sources.</figDesc><graphic coords="3,146.88,98.09,253.68,133.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Constraint satisfaction problem example (left) and its hidden variable encoding (right).</figDesc><graphic coords="5,128.16,98.08,290.88,92.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>2</head><label>2</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>1 :</head><label>1</label><figDesc>Function o-search(X,D,C,R,E) 2: s ← solve(X, D, C, R) 3: if s = {} then 4: return s as a solution 5: for k ∈ {1 . . . n} do 6: if e k = CLOSED then 7: if (∀i ∈ 1 . . . k -1)e k = CLOSED then 8: return failure 9: else 10: nv ← more(x k ) 11:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Average number of values queried vs. average number of values per variable, and average number of checks vs. number of variables, for various open constraint satisfaction algorithms.</figDesc><graphic coords="12,149.40,291.79,248.40,175.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>) {search again} Algorithm 3 .</head><label>3</label><figDesc>Function possibilistic-fo-search for solving possibilistic OCOP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Average number of values queried against average number of values per variable and average number of checks vs. number of variables for randomly generated problems in two different possibilistic OCOP algorithms.</figDesc><graphic coords="16,149.88,290.23,247.56,175.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Theorem 10 .</head><label>10</label><figDesc>Algorithm 5 is sound and complete.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Algorithm 7 . 2 Theorem 11 .</head><label>7211</label><figDesc>i-o-opt: modification of Algorithm 6 to implement interactive optimization.• b k is inconsistent, as it contains the same conflict with c as a,• for the same reason, all direct or indirect successors to b k that do not change the values for x i , i ∈ {i1, . . ., ij} are also inconsistent, • all direct (indirect) successors to b k that change the value for an x i , i ∈ {i1, . . ., ij} are also a direct (indirect) successor of b i , where we use the term indirect successor for sequences of direct successor relationships. Thus, all b k , k / ∈ {i1, . . ., il} cannot be themselves solutions or lead to solutions that would not be generated from {b i1 , . . . , b ij } already. Algorithm 6 is sound and complete.Proof. Follows from Theorem 10 and Lemma 8. 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 5</head><label>5</label><figDesc>Fig.5shows the experimental evaluation of the algorithms for open constraint optimization with the weighted model with respect to the number of values queried on randomly generated problems with 7-30 variables and 3-60 values per variable.We can see that Algorithm 6 (FOOPT) is quite close to the optimum. For interactive optimization, we show two curves. I-O-OPT shows the number of queries the algorithm makes to the mediator, and corresponds to the amount of network traffic generated. This curve shows the main weakness of the interactive model: since the optimization procedure cannot know whether a value is has already seen is optimal for a given assignment, it has to make a query every time it examines a new assignment. The second curve, I-O-OPT-R, shows the number of different values revealed during the process. This curve shows the strength of the interactive model: it is best with respect to the number of values that have to actually be revealed. Note that this beats the optimal algorithm because it assumes a more powerful model of the mediator. Fig.5also shows a comparison of the same algorithms with respect to computation effort represented by the number of constraint checks. Here we see that Algorithms 6 and 7 are orders of magnitude more efficient than the optimal one, and will be the most applicable for practical applications.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Average number of values queried vs. average number of values per variable (top) and number of constraint checks against number of variables (bottom) for four different weighted OCOP algorithms.</figDesc><graphic coords="26,149.52,289.27,248.28,175.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Algorithm 4. min-opt: an incremental algorithm for solving OCOP with a minimal number of queries.</figDesc><table><row><cell cols="2">1: Function min-opt(OCOP)</cell></row><row><cell cols="2">2: Forall x i , d i ← more(x i ) e i ← OPEN</cell></row><row><cell cols="2">3: for g ∈ SP(1) do</cell></row><row><cell>4:</cell><cell>LB(g) ← w i (first(d i )); (g = {x i })</cell></row><row><cell cols="2">5: for i ← 2 to n do</cell></row><row><cell cols="2">6: for g ∈ SP(i) do</cell></row><row><cell>7:</cell><cell>repeat</cell></row><row><cell>8:</cell><cell>(o, a) ← c-opt(g, D, W )</cell></row><row><cell>9:</cell><cell>lb k ← NIL; k ← NIL</cell></row><row><cell>10:</cell><cell>for x j ∈ g do</cell></row><row><cell>11:</cell><cell>if e j = OPEN then</cell></row><row><cell>12:</cell><cell>lb j ← c∈COMPS(g\x j ) LB(c) + max v∈d j w j (v)</cell></row><row><cell>13:</cell><cell>if (lb k = NIL) ∨ (lb j &lt; lb k ) then</cell></row><row><cell>14:</cell><cell>k ← j</cell></row><row><cell>15:</cell><cell>lb k ← lb j</cell></row><row><cell>16:</cell><cell>if (lb k = NIL) ∧ ((o = NIL) ∨ (lb k &lt; o)) then</cell></row><row><cell>17:</cell><cell>(nv, nw) ← more(x k )</cell></row><row><cell>18:</cell><cell>if nv = nomore(x k ) then</cell></row><row><cell>19:</cell><cell>e k ← CLOSED</cell></row><row><cell>20:</cell><cell>else</cell></row><row><cell>21:</cell><cell>d k ← d k ∪ nv; w k ← w k ∪ nw</cell></row><row><cell>22:</cell><cell>until (lb k = NIL) ∨ (lb k o)</cell></row><row><cell>23:</cell><cell>if o = NIL then</cell></row><row><cell>24:</cell><cell>return UNSOLVABLE</cell></row><row><cell>25:</cell><cell>else</cell></row><row><cell>26:</cell><cell>LB(g) ← o</cell></row><row><cell cols="2">27: return(o, a)</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the equivalence of constraint satisfaction problems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Petrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECAI-90</title>
		<meeting>ECAI-90</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="550" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Encodings of non-binary constraint satisfaction problems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Stergiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Walsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI-99</title>
		<meeting>AAAI-99<address><addrLine>Orlando, FL</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="163" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Solving non-binary CSPs using the hidden variable encoding</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mamoulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stergiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CP 2001</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>CP 2001<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">2239</biblScope>
			<biblScope unit="page" from="168" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Infomaster: an information integration system</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Genesereth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Duschka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1997 ACM SIGMOD Conference</title>
		<meeting>1997 ACM SIGMOD Conference</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Active information gathering in InfoSleuth</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nodine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ksiezyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Unruh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Cooperative Inform. Syst</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1/2</biblScope>
			<biblScope unit="page" from="3" to="28" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Agent-based semantic interoperability in InfoSleuth</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nodine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bargmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIG-MOD Record</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="60" to="67" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Querying heterogeneous information sources using source descriptions</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rajaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Ordille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd VLDB Conference</title>
		<meeting>the 22nd VLDB Conference<address><addrLine>Bombay, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Semiring-based constraint solving and optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bistarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Montanari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="201" to="236" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Possibilistic constraint satisfaction problems or &apos;How to handle soft constraints?</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schiex</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Uncertainty in AI</title>
		<meeting>the 8th International Conference on Uncertainty in AI<address><addrLine>Stanford</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fuzzy constraint satisfaction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ruttkay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd IEEE International Conference on Fuzzy Systems</title>
		<meeting>3rd IEEE International Conference on Fuzzy Systems</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="1263" to="1268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Partial constraint satisfaction</title>
		<author>
			<persName><forename type="first">E</forename><surname>Freuder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Constraint propagation and value acquisition: why we should do it interactively</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gavanelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lamma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Milano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Piccardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IJCAI-99</title>
		<meeting>IJCAI-99<address><addrLine>Stockholm, Sweden; San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="468" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Interactive constraint satisfaction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lamma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Milano</surname></persName>
		</author>
		<idno>DEIS- LIA-97-00</idno>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>University of Bologna</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A classification and constraint-based frame-work for configuration</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mailharro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI in Engineering, Design and Manucturing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="383" to="397" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Arc-consistency in dynamic constraint satisfaction problems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bessière</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI-91</title>
		<meeting>AAAI-91<address><addrLine>Anaheim, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="221" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Asynchronous weak-commitment search for solving large-scale distributed constraint satisfaction problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yokoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Conference on Multi-Agent Systems</title>
		<meeting>the First International Conference on Multi-Agent Systems<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page">467</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The evolving role of constraints in the functional data model</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M D</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Embury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Y</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J L</forename><surname>Kemp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Intelligent Inform. Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="113" to="137" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">CCL: expressions of choice in agent communication</title>
		<author>
			<persName><forename type="first">M</forename><surname>Calisti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Faltings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Macho-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Belakhdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Torrens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth International Conference on MultiAgent Systems (ICMAS-2000)</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Federated database systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sheth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The TSIMMIS project: integration of heterogeneous information sources</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chawathe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Garcia Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ireland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Papakostantinou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IPSJ Conference</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<pubPlace>Tokyo, Japan</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Flexible and scalable cost-based query planning in mediators: a transformational approach</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Ambite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Knoblock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="115" to="161" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Middle-agents for the internet</title>
		<author>
			<persName><forename type="first">K</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sycara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Joint Conference on Artificial Intelligence (IJCAI-97)</title>
		<meeting>the 15th International Joint Conference on Artificial Intelligence (IJCAI-97)<address><addrLine>Nagoya, Japan; San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="578" to="583" />
		</imprint>
	</monogr>
	<note>brokers/matchmakers</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Sycara</surname></persName>
		</author>
		<title level="m">Intelligent Information Agents: Cooperative, Rational and Adaptive Information Gathering on the Internet</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Klusch</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>-context information management through adaptive collaboration of intelligent agents</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">LARKS: dynamic matchmaking among heterogeneous software agents in cyberspace</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sycara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Widoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Klusch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Autonomous Agents and Multi-Agent Systems</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="173" to="203" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Supporting online resource discovery in the context of ongoing tasks with proactive assistants</title>
		<author>
			<persName><forename type="first">J</forename><surname>Budzik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bradshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hammond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Human-Computer Stud</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="74" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Just-in-time information retrieval agents</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Rhodes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Systems J</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="685" to="704" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Explanation-based generalisation of failures</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L N</forename><surname>De Siqueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Puget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th European Conference on Artificial Intelligence</title>
		<meeting>the 8th European Conference on Artificial Intelligence<address><addrLine>Munich</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="339" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Partial-revelation VCG mechanism for combinatorial auctions</title>
		<author>
			<persName><forename type="first">W</forename><surname>Conen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sandholm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI-02</title>
		<meeting>AAAI-02<address><addrLine>Edmonton, AB</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="367" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Korf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Depth-first iterative deepening: an optimal admissible tree search</title>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="97" to="109" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
