<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dynamic Hypergraph Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jianwen</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology(BNRist)</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">KLISS</orgName>
								<orgName type="department" key="dep2">School of Software</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuxuan</forename><surname>Wei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology(BNRist)</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">KLISS</orgName>
								<orgName type="department" key="dep2">School of Software</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yifan</forename><surname>Feng</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Information Science and Engineering</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<settlement>Xiamen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jingxuan</forename><surname>Cao</surname></persName>
							<email>jingxuac@alumni.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology(BNRist)</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">KLISS</orgName>
								<orgName type="department" key="dep2">School of Software</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yue</forename><surname>Gao</surname></persName>
							<email>gaoyue@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Beijing National Research Center for Information Science and Technology(BNRist)</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">KLISS</orgName>
								<orgName type="department" key="dep2">School of Software</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dynamic Hypergraph Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In recent years, graph/hypergraph-based deep learning methods have attracted much attention from researchers. These deep learning methods take graph/hypergraph structure as prior knowledge in the model. However, hidden and important relations are not directly represented in the inherent structure. To tackle this issue, we propose a dynamic hypergraph neural networks framework (DHGNN), which is composed of the stacked layers of two modules: dynamic hypergraph construction (DHG) and hypergrpah convolution (HGC). Considering initially constructed hypergraph is probably not a suitable representation for data, the DHG module dynamically updates hypergraph structure on each layer. Then hypergraph convolution is introduced to encode high-order data relations in a hypergraph structure. The HGC module includes two phases: vertex convolution and hyperedge convolution, which are designed to aggregate feature among vertices and hyperedges, respectively. We have evaluated our method on standard datasets, the Cora citation network and Microblog dataset. Our method outperforms state-ofthe-art methods. More experiments are conducted to demonstrate the effectiveness and robustness of our method to diverse data distributions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Graphs are widely used to model pair-wise relations including paper citations, personal contacts and protein-protein interactions. However, besides pair-wise relations, there exists a large number of non-pair-wise relations that simple graphs are unable to model, for example, the communities in social networks and the clusters in feature embeddings. Hypergraph is a generalized structure for relation modeling. A hypergraph is composed of a vertex set and a hyperedge set, where a hyperedge contains a flexible number of vertices. Therefore, hyperedges are able to model non-pair-wise relations mentioned above. The number of vertices a hyperedge contains is defined as the degree of the hyperedge. Especially, if the  degree of hyperedges is restricted to 2, a hypergraph is degenerated to a simple graph, indicating that simple graph is a subset of the hypergraph.</p><p>Recently graph/hypergraph-based deep learning methods have received more and more attention from researchers. Inspired by convolutional neural network (CNN) <ref type="bibr" target="#b5">[Krizhevsky et al., 2012]</ref> in computer vision, researchers have designed graph-based neural networks for semi-supervised learning, like GCN <ref type="bibr" target="#b4">[Kipf and Welling, 2017]</ref> and <ref type="bibr">GAT [Veličković et al., 2018]</ref>. Furthermore, <ref type="bibr">HGNN [Feng et al., 2018]</ref> is the first hypergraph neural network model. In a neural network model, feature embedding generated from deeper layer of the network carries higher-order relations that initial structure fails to capture. The major drawback of existing graph/hypergraph-based neural networks is that they only employ the initial graph/hypergraph structures while neglect the dynamic modifications of such structures from adjusted feature embedding.</p><p>Dynamic hypergraph structure learning (DHSL) <ref type="bibr" target="#b8">[Zhang et al., 2018]</ref> has been proposed to deal with this problem. DHSL uses raw input data to optimize hypergraph structure iteratively. Nonetheless, DHSL only updates the hypergraph structure on initial feature embedding, thus failing to exploit high-order relations among features. Also, the iterative optimization in DHSL suffers from expensive cost in time and space.</p><p>To tackle these issues, we propose a dynamic hypergraph neural networks (DHGNN) framework, which is stacked layers of dynamic hypergraph construction (DHG) module and For instance, two hyperedges are generated from two clusters (dashed ellipses). In the second frame, features of vertices contained in a hyperedge are aggregated to hyperedge feature through vertex convolution and features of adjacent hyperedges are aggregated to centroid vertex feature through hyperedge convolutoin. After performing such operations for all vertices on current layer feature embedding, we obtain the new feature embedding where new hypergraph structure will be constructed, as is shown in the third frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>New feature embedding</head><note type="other">Hypergraph Construction Hypergraph Convolution Vertex</note><p>hypergraph convolution (HGC) module. In DHG module, we utilize k-NN method and k-means clustering method to update hypergraph structure based on local and global features respectively during a single inference process. Furthermore, we propose a hypergraph convolution method in HGC module by a stack of vertex convolution and hyperedge convolution. For vertex convolution, we use a transform matrix to permute and weight vertices in a hyperedge; for hyperedge convolution, we utilize attention mechanism to aggregate adjacent hyperedge features to the centroid vertex. Compared with hypergraph-based deep learning method HGNN, our convolution module better fuses information from local and global features provided by our DHG module.</p><p>We have applied our model to data with and without inherent graph structure. For data with inherent graph structure, we conducted an experiment on a citation network benchmark, the Cora dataset <ref type="bibr" target="#b5">[Sen et al., 2008]</ref>, for the node classification task. In this experiment, we used DHGNN to jointly learn embeddings from given graph structure and a hypergraph structure from feature space. For data without inherent graph structure, an experiment was conducted on a social media dataset, the Microblog dataset <ref type="bibr" target="#b3">[Ji et al., 2019]</ref>, for the sentiment prediction task. In this experiment, a multi-hypergrpah was constructed to model the complex relations among multimodal data.</p><p>Our contributions are summarized as follows:</p><p>1. We propose a dynamic hypergraph construction method, which adopts k-NN method to generate basic hyperedge and extends adjacent hyperedge set by clustering algorithm, i.e., k-means clustering. By dynamic hypergraph construction method, local and global relations will be extracted.</p><p>2. We conducted experiments on network-based classification and social media sentiment prediction. On the network-based task, our method outperforms state-ofthe-art methods and shows higher robustness to different data distributions. On social media sentiment prediction, we observe performance improvement against state-ofthe-art methods. The rest of the paper is organized as follows. Section 2 introduces related work in graph-based deep learning and hypergraph learning. Section 3 explains the proposed dynamic hypergraph neural networks method. Applications and experimental results are presented in Section 4. Finally, we draw conclusions in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In this section, we give a brief review on graph-based deep learning and hypergraph learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Graph-based Deep Learning</head><p>Semi-supervised learning on graphs has long been an active research field in deep learning. <ref type="bibr">DeepWalk [Perozzi et al., 2014]</ref> and <ref type="bibr">Planetoid [Yang et al., 2016]</ref> view sampled paths in graphs as random sequences and learn vector embedding from these sequences.</p><p>After the great success of convolutional neural networks <ref type="bibr" target="#b5">[Krizhevsky et al., 2012]</ref> in image processing, researchers have been devoted to designing convolutional methods for graph-based data. Existing graph neural network methods can be divided in two main categories: spectral methods and spatial methods.</p><p>Based on spectral graph theory, spectral graph convolutional methods use graph Laplacian eigenvectors as graph Fourier basis. After transforming features to spectral domain, a spectral convolution operation is conducted on spectral features. To overcome the expensive computation cost in Laplacian factorization, ChebyshevNet introduces Chebyshev polynomials to approximate Laplacian eigenvectors <ref type="bibr" target="#b1">[Defferrard et al., 2016]</ref>. GCN further simplifies the process and uses one-order polynomial on each layer <ref type="bibr" target="#b4">[Kipf and Welling, 2017]</ref>.</p><p>Different from spectral methods, spatial graph convolution methods leverage spatial sampler and aggregator to generate neighborhood feature embedding. MoNet defines a generic spatial convolution framework for deep learning on non-Euclidean domains <ref type="bibr" target="#b5">[Monti et al., 2017]</ref>. GraphSAGE defines sampler and aggregator in graph neural network and tries LSTM as neighborhood aggregator <ref type="bibr">[Hamilton et al., 2017]</ref>. GAT introduces self-attention mechanism and computes the attention coefficients between node pairs <ref type="bibr" target="#b5">[Veličković et al., 2018]</ref>. In the field of computer vision, DGCNN, a 3D point cloud learning method, also leverages the concept of spatial graph convolution in its model <ref type="bibr" target="#b5">[Wang et al., 2018]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Hypergraph Learning</head><p>Hypergraph learning is first introduced by <ref type="bibr" target="#b8">[Zhou et al., 2007]</ref> as a label propagation method for semi-supervised learning. This method aims to minimize the differences in labels of vertices that share the same hyperedge. <ref type="bibr" target="#b2">[Huang et al., 2009]</ref> discusses the construction methods of hypergraph, including k-NN method and search radius method. More recent works concentrate on the learning of hyperedge weight, intending to assign larger weight to hyperedges or sub-hypergraphs with higher importance <ref type="bibr" target="#b1">[Gao et al., 2012]</ref>. Besides learning label propagation on hypergraph, dynamic hypergraph structure learning proposes learning of hypergraph structure by a dual optimization process <ref type="bibr" target="#b8">[Zhang et al., 2018]</ref>. Like graph neural network, hypergraph neural network (HGNN) has been proposed as the first deep learning method on hypergraph structure, employing hypergraph Laplacian to represent hypergraph from spectral perspective <ref type="bibr" target="#b1">[Feng et al., 2018]</ref>.</p><p>Hypergraph has many aspects of applications. In computer vision, hypergraph is used to describe relations among visual features for tasks like visual classification <ref type="bibr" target="#b5">[Wang et al., 2015]</ref>, image retrieval <ref type="bibr" target="#b2">[Huang et al., 2010]</ref> and video object segmentation <ref type="bibr" target="#b2">[Huang et al., 2009]</ref>. There are also works using hypergraph structure for label propagation on 3D model classification <ref type="bibr" target="#b8">[Zhang et al., 2018]</ref>. In social media, MHG <ref type="bibr" target="#b1">[Chen et al., 2015]</ref> and Bi-MHG <ref type="bibr" target="#b3">[Ji et al., 2019]</ref> are proposed to deal with multimodal data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dynamic Hypergraph Neural Networks</head><p>In this section, we introduce the dynamic hypergraph neural networks (DHGNN) proposed in detail. As is illustrated in Figure <ref type="figure" target="#fig_1">2</ref>, a DHGNN layer consists of two major part: dynamic hypergraph construction (DHG) and hypergraph convolution (HGC). We will first introduce these two parts in the following subsections and then discuss the implementation of dynamic hypergraph neural networks in the last subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dynamic Hypergraph Construction</head><p>Given feature embedding X = [x 1 ; x 2 ; ...; x n ] where x i (i = 1, 2, ..., n) denotes the feature of the i-th sample, we construct hypergraph G. In hypergraph, vertex u denotes a sample and hyperedge e denotes a sample collection containing a flexible number of samples. Therefore, a hypergraph can be formulated as G = {V, E}, where V denotes the vertex set and E denotes the hyperedge set. for i in ind do</p><formula xml:id="formula_0">9: G[u].insert(C[i]) 10:</formula><p>end for 11: end for We use symbol Con(e) to denote the vertex set a hyperedge e contains and use symbol Adj(u) to denote the hyperedge set composed of all hyperedge containing the vertex u, which is formulated as:</p><formula xml:id="formula_1">Con(e) = {u 1 , u 2 , ..., u ke } (1) Adj(u) = {e 1 , e 2 , ..., e ku } (2)</formula><p>where k e and k u is the number of vertices in hyperedge e and the number of hyperedges containing vertex u. Vertex u is defined as the centroid vertex of hyperedge set Adj(u).</p><p>We combine k-NN methods and k-means clustering methods for dynamic hypergraph construction to exploit local and global structure. On one hand, we have computed the k − 1 nearest neighbors for each vertex u. These neighborhood vertices, along with the vertex u, form a hyperedge in Adj(u). On the other hand, we have conducted k-means algorithm on the whole feature map of each layer according to Euclidean distance. For each vertex, the nearest S −1 clusters will be assigned as the adjacent hyperedges of this vertex. The detailed procedure is described in Algorithm 1.</p><p>We perform such procedure on the feature embedding of each layer. Especially, we initialize hypergraph structure with the input feature embedding. Therefore, the hyperedge set is dynamically adjusted as the feature embedding evolves with network going deeper. In this way, we are able to obtain better hypergraph struture for high-order data relation modeling with deep neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Hypergraph Convolution</head><p>Hypergraph convolution is composed of two submodules: vertex convolution submodule and hyperedge convolution submodule. Vertex convolution aggregates vertex features to hyperedge and then hyperedge convolution aggregates adjacent hyperedge features to centroid vertex by hyperedge convolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Vertex Convolution</head><p>Vertex convolution aggregates vertex features to the hyperedge containing these vertices. A simple solution is pooling  method like max pooling and average pooling. State-of-theart methods employ a fixed, pre-computed transform matrix generated from graph/hypergraph structure for vertex aggregation. However, such methods are unable to model discriminative information among vertices features well. To tackle this issue, we learn the transform matrix T from the vertex features for feature permutation and weighting, as is shown in Figure <ref type="figure" target="#fig_3">3</ref>. The transform matrix enables both inter-vertex and inter-channel information flow. In implementation, we use multi-layer perception (MLP) to generate transform matrix T and use 1-d convolution to compact the transformed features, as is described by equation 3.</p><formula xml:id="formula_2">T = M LP (X u ) (3a) x e = conv(T • M LP (X u )) (3b)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyperedge Convolution</head><p>Hyperedge convolution aggregates hyperedge features to centroid vertex feature, as is illustrated in Figure <ref type="figure" target="#fig_4">4</ref> </p><formula xml:id="formula_3">X v = V ertexSample(X, G) 4:</formula><p>x e = V ertexConv(X v ) 5:</p><p>xlist.insert(x e ) 6: end for 7: X e = stack(xlist) 8: x u = EdgeConv(X e ) 9: y u = σ(x u W + b) procedure can be formulated as follows:</p><formula xml:id="formula_4">w = sof tmax(x e W + b) (4a) x u = |Adj(u)| i=0 w i x i e (4b)</formula><p>|Adj(u)| denotes the size of adjacent hyperedge set, x e denotes adjacent hyperedge features and x u denotes centroid vertex feature. W and b are learnable parameters.  <ref type="figure" target="#fig_1">2</ref>, a hypergrpah convolutional layer updates vertex features for new feature embedding, based on which a new hypergraph structure will be constructed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Dynamic Hypergraph Neural Networks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Applications and Experiments</head><p>In this section, we applied our dynamic hypergraph neural network to two types of data: citation network with inherent graph structure and social media multimodal data without inherent data structure. Especially, for data with inherent graph structure, we sample k vertices in 1-order neighborhood of u and these k vertices also form a hyperedge in Adj(u).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiments on Citation Network</head><p>Citation network is a typical graph-structure dataset. Since graph is a special case of hypergraph, our model applies to graph-structure data as well. Furthermore, by constructing dynamic hypergraph, we are able to deploy information from both citation relation and feature embedding relation in a uniform manner. To evaluate the performance of our method, series of experiments were conducted on the public benchmark citation network dataset, Cora dataset. Cora dataset. Cora dataset is a benchmark dataset of citation network. In Cora dataset, there are 2,708 vertices denoting academic papers and 5,429 edges denoting citation relations between pairs of papers. Each vertex has a bag-of-word feature vector and a category label indicating the subject that the paper belongs to. There are 7 categories in total. Experimental setup. We have conducted experiments on different splits of the Cora dataset including standard split described in <ref type="bibr" target="#b6">[Yang et al., 2016]</ref>. Because the standard split uses fixed training samples with 5.2% of dataset, it is possible for a method to be influenced by the fixed data distribution. Therefore, for further comparison, we randomly sampled different proportion of data as training set to demonstrate the effectiveness of our method. The proportion for training set is selected as 2%, 5.2%, 10%, 20%, 30% and 44%, respectively. We compared our method with recent representative methods like GCN <ref type="bibr" target="#b4">[Kipf and Welling, 2017]</ref>, <ref type="bibr">HGNN [Feng et al., 2018]</ref> and <ref type="bibr">GAT [Veličković et al., 2018]</ref>. 10 times average accuracy was reported in Table <ref type="table" target="#tab_3">1</ref> for comparison.</p><p>We used 2 layer dynamic hypergraph neural network with a GCN-style input layer for feature dimension reduction. We used 400 cluster centers in k-means clustering method and chose 64 as the receptive field size. We added two dropout layers with the dropout rate of 0.5 before two convolutional layers. Semi-supervised node classification. We compared DHGNN with most recent graph/hypergraph-based neural network methods on different dataset splits. Experimental results are listed as Table <ref type="table" target="#tab_3">1</ref>, showing that our method outperformed state-of-the-art by 1.5%, 0.5%, 0.1%, 0.1%, 0.5%, 0.4% when 2%, 5.2%, 10%, 20%, 30%, 44% randomly sampled data was used as training set, respectively. Moreover, we observed that hypergraph structure was relatively more competitive when training set was smaller. The reason is that graph convolution only uses 1-order adjacent relation while hypergraph convolution utilizes high-order relation, which is helpful to the label propagation process on a sparsely labelled graph. Ablation experiments. To evaluate the effectiveness of proposed dynamic hypergraph construction (DHG) module and hypergraph convolution (HGC) module, we conducted two ablation experiments on the Cora dataset, where each module mentioned above was removed from the complete model. We compared the ablated models against the complete model and investigated the influence of hyperparameter k, which denotes the number of sampled vertices in a hyperedge. Results are shown in Figure <ref type="figure" target="#fig_5">5</ref>. From the results, we observe that DHG module and HGC module always improve the performance of baseline with different k. As k increases, the gain from both modules increases, indicating the effectiveness of our method. It is noted that even when k = 4 (is much smaller than the max degree in the Cora dataset, 169), our method still obtains similar performance with other  hypergraph-based learning method, i.e., HGNN and when k = 128, our method outperforms HGNN by 0.9%. This implies that our method is able to aggregate neighborhood features better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Microblog Sentiment Prediction</head><p>Apart from experiments on citation network, we also evaluated our model on a more complicated task, social media sentiment prediction. Multi-modality is an important feature of social media. We used hypergraph to model the highorder relations among different modalities. Specifically, vertices were used to denote a tweet. Hyperedge sets were constructed according to each modality feature and hyperedges from multi-modalities jointly represent the correlation between vertices. In our experiment, we used the Microblog dataset to evaluate our hypergraph model. Microblog dataset. The Microblog dataset contains 5,550 tweets crawled from Sina Microblog platform<ref type="foot" target="#foot_2">1</ref> during Feb. 2014 to Apr. 2014. Each tweet has three modalities: text, image and emoticon. We generated 2547-dimension bag-ofwords textual feature using Chinese auto-segmentation system ICTCLAS <ref type="bibr" target="#b7">[Zhang et al., 2003]</ref>. To generate visual feature, we used SentiBank <ref type="bibr" target="#b0">[Borth et al., 2013]</ref>, a kind of ANP detector library pre-trained on Twitter images to transform Microblog images to 1553-dimension feature vector. For emoticons, we built a emoticons dictionary with 49 frequently-used emoticons and computed bag-of-emoticons features. Each tweet has a label indicating its emotional polarity (postive or negative). The task is to predict tweet emotional polarity by multimodal features. There are 4196 positive tweets and 1354 negative tweets in the dataset.</p><p>Experimental setup. We followed the experimental setup in <ref type="bibr">[Ji et al.]</ref>, where 4,650, 400, 500 tweets were randomly selected as training, validation and test set, respectively. 10times average accuracy was reported for method evaluation. We used 2 layer dynamic hypergraph neural network with a multi-input fully-connected layer for feature dimension reduction. Dimensions of each modality feature were reduced to 32 before hypergraph convolution. We constructed three hyperedge sets for three modality respectively and merged these sets as one multimoal hyperedge set.  <ref type="table" target="#tab_5">2</ref>, which can be summarized as:</p><p>1. In terms of prediction accuracy, DHGNN achieved higher performance with 1.8% accuracy gains in multimodal sentiment prediction task compared with current state-of-the-art method.</p><p>2. In terms of time expense, DHGNN remarkably shortened training time compared with current state-of-theart methods (2300 times as fast as Bi-MHG and 1.4 times as fast as HGNN).</p><p>Experimental results indicate that our method outperformed the state-of-the-art method in both prediction accuracy and training speed. The experiments on Microblog dataset demonstrates the effectiveness of our method in modeling the high-order relations among multimodal data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we propose a dynamic hypergraph neural networks framework to update hypergraph structure on each layer. The method consists of two important modules: dynamic hypergraph construction method and hypergraph convolution, where hypergraph convolution includes vertex convolution and hyperedge convolution for hypergraph neighborhood feature aggregation. We apply our model to citation network data and multimodal social media data for evaluation.</p><p>Results demonstrate that our model achieves similar of better performance compared with state-of-the-art methods and is more robust to different data distributions. We also investigate the effectiveness of dynamic hypergraph construction module and hypergraph convolution module independently by ablation experiment. In our model, k-NN method and k-means clustering method are used in hypergraph dynamic construction. Future work can concentrate on better and more interpretable hypergraph construction methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: Dynamically constructed hyperedges. When embedding evolves from the l-th layer to the l + 1-th layer, hyperedge e l = {v0, v1, v2, v6} disappears while hyperedge e l+1 = {v2, v3, v4, v5} comes into existence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: DHGNN framework. The first frame describes the hypergraph construction process on centroid vertex (the star) and its neighbors. For instance, two hyperedges are generated from two clusters (dashed ellipses). In the second frame, features of vertices contained in a hyperedge are aggregated to hyperedge feature through vertex convolution and features of adjacent hyperedges are aggregated to centroid vertex feature through hyperedge convolutoin. After performing such operations for all vertices on current layer feature embedding, we obtain the new feature embedding where new hypergraph structure will be constructed, as is shown in the third frame.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1</head><label>1</label><figDesc>Hypergraph Construction Input: Input embedding X; hyperedge size k; adjacent hyperedge set size S Output: Hyperedge set G Function: k-Means clustering kM eans; k-nearest neighborhood selection knn; distance function dis; S − 1 smallest distance index selection topK 1: C = kM eans(X) 2: for u in range(len(X)) do 3: e b = knn(X[u], X, k)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: Vertex convolution module. For k vertices, a k × k transform matrix is computed by convolution. We multiply transform matrix and input vertex feature matrix to get permuted and weighted vertex feature matrix. Then a 1-dimension convolution is conducted for the 1-dimension hyperedge feature.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: Hyperedge convolution module. We use self-attention mechanism to aggregate hyperedge features. Self-attention weight w is computed through multi-layer perception (MLP) from hyperedge features. Then weighted average of hyperedge features is calculated as centroid vertex feature.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Ablation experiment on dynamic hypergraph(DHG) module and hypergraph convolution (HGC) module. For model without dynamic hypergraph, we used inherent graph structure on Cora for convolution operation. For model without hypergraph convolution, we used average pooling for substitution of vertex convolution and hyperedge convolution.</figDesc><graphic url="image-1.png" coords="5,323.11,244.54,226.76,96.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Performance comparisons on Cora with different splits. "lr" stands for label rate, "#train" stands for number of training samples and "std" stands for standard split. Standard split experiment and 5.2% split experiment share the same number of training samples. Different from the standard split setting, samples in 5.2% split is randomly selected. 44% is the largest possible size of training set with standard validation and test set.</figDesc><table><row><cell>lr</cell><cell cols="2">#train GCN</cell><cell cols="2">HGNN GAT</cell><cell>DHGNN</cell></row><row><cell>std</cell><cell>140</cell><cell cols="2">81.5% 81.6%</cell><cell>83.0% 82.5%</cell></row><row><cell>2%</cell><cell>54</cell><cell cols="2">69.6% 75.4%</cell><cell>74.8% 76.9%</cell></row><row><cell cols="2">5.2% 140</cell><cell cols="2">77.8% 79.7%</cell><cell>79.4% 80.2%</cell></row><row><cell cols="2">10% 270</cell><cell cols="2">79.9% 80.0%</cell><cell>81.5% 81.6%</cell></row><row><cell cols="2">20% 540</cell><cell cols="2">81.4% 80.1%</cell><cell>83.5% 83.6%</cell></row><row><cell cols="2">30% 812</cell><cell cols="2">81.9% 82.0%</cell><cell>84.5% 85.0%</cell></row><row><cell cols="2">44% 1200</cell><cell cols="2">82.0% 81.9%</cell><cell>85.2% 85.6%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>For each modality, we use 400 cluster centers in k-means clustering method and the number of vertices contained is 8 in each clusters. We select 2 nearest clusters from k-means clusters and one k-NN cluster as the adjacent hyperedge set of each vertex. We use identical activation and dropout setting with Section 4.1. We compare our model with recent approaches for multimodal sentiment prediction, such as Multi-kernel SVM<ref type="bibr" target="#b7">[Zhang et al., 2011]</ref>, Cross-media Bag-of-words Model<ref type="bibr" target="#b5">[Wang et al., 2014]</ref>,Bi-layer Multimodal Hypergraph Learning [Ji et al.,  2019], etc. Experiments were conducted on a Nvidia GeForce GTX 1080 Ti GPU with 11G memory and 10.6 T-flops computing capacity.</figDesc><table><row><cell>Microblog sentiment prediction. In this experiment, we</cell></row><row><cell>ran DHGNN to fuse features from mutliple modalities for</cell></row><row><cell>sentiment label prediction. Experimental results are shown</cell></row><row><cell>in Table</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Performance comparisons on the Microblog dataset convolution respectively. Despite of this, we also note that in the standard split of Cora dataset, GAT performs better than DHGNN. The main reason is that in standard split, training set contains fixed samples, thus suffering from larger randomness and bias. On the other settings, we have randomly sampled training set for 10 times and reported the average accuracy for comparison to suppress such randomness and bias.Discussion on time complexity. Traditional hypergraph learning models like Bi-MHG involve iterative optimization and matrix inversion, thus suffering from larger time cost than neural network model. When comparing HGNN and DHGNN, we find that parameter number of both models 0.133M, indicating that it takes roughly the same time to train a HGNN/DHGNN epoch. However, it takes 30 epochs on average for DHGNN to converge on Microblog sentiment dataset while it takes 200 epochs on average for HGNN to converge. Therefore, DHGNN runs faster on Microblog sentiment dataset.</figDesc><table><row><cell>Discussion on accuracy. Compared with statically initial-</cell></row><row><cell>ized hypergraph structure, dynamic hypergraph structure can</cell></row><row><cell>better represent data distribution in deeper layers. Compared</cell></row><row><cell>with pooling and multi-layer perception, hypergraph convolu-</cell></row><row><cell>tion uses fixed-size, weight-shared learnable convolution ker-</cell></row><row><cell>nel for feature extraction, thus being better for information</cell></row><row><cell>aggregation. Ablation experiments demonstrate the effective-</cell></row><row><cell>ness of the dynamic hypergraph construction and hypergraph</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1">Proceedings of the Twenty-Eighth International Joint Conference Artificial Intelligence</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_2">https://www.weibo.com Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence (IJCAI-19)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3">Proceedings of the International Joint Conference on Artificial Intelligence </note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by National Natural Science Funds of China (U1701262, U1801263, 61671267).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Large-scale visual sentiment ontology and detectors using adjective noun pairs</title>
		<author>
			<persName><surname>Borth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st ACM international conference on Multimedia</title>
				<meeting>the 21st ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="223" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName><forename type="first">Chen</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Multimedia and Expo (ICME)</title>
				<editor>
			<persName><forename type="first">Rongrong</forename><surname>Tao</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Qionghai</forename><surname>Ji</surname></persName>
		</editor>
		<editor>
			<persName><surname>Dai</surname></persName>
		</editor>
		<meeting><address><addrLine>Meng Wang</addrLine></address></meeting>
		<imprint>
			<publisher>Will Hamilton, Zhitao Ying, and Jure Leskovec</publisher>
			<date type="published" when="2012">2015. 2015. 2016. 2016. 2018. 2019. 2018. 2012. 2017. 2017</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Image retrieval via probabilistic hypergraph ranking</title>
		<author>
			<persName><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009. 2009. 2010. 2010</date>
			<biblScope unit="page" from="3376" to="3383" />
		</imprint>
	</monogr>
	<note>2009 IEEE Conference on Computer Vision and Pattern Recognition</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cross-modality microblog sentiment prediction via bi-layer multimodal hypergraph learning</title>
		<author>
			<persName><forename type="first">Ji</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="page" from="1062" to="1075" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">Welling</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Geometric deep learning on graphs and manifolds using mixture model cnns</title>
		<author>
			<persName><surname>Krizhevsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. Graph attention networks. International Conference on Learning Representations</title>
				<imprint>
			<publisher>Yongbin Sun</publisher>
			<date type="published" when="2008">2012. 2012. 2017. 2017. 2014. 2014. 2008. 2008. 2018. 2018. 2014. 2014. 2015. 2015. 2018. 2018</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2564" to="2574" />
		</imprint>
	</monogr>
	<note>AI magazine. Ziwei Liu, Sanjay E. Sarma, Michael M. Bronstein, and Justin M. Solomon. Dynamic graph cnn for learning on point clouds. CoRR, abs/1801.07829</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Revisiting semi-supervised learning with graph embeddings</title>
		<author>
			<persName><forename type="first">Yang</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Alzheimer&apos;s Disease Neuroimaging Initiative, et al. Multimodal classification of alzheimer&apos;s disease and mild cognitive impairment</title>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second SIGHAN workshop on Chinese language processing</title>
				<meeting>the second SIGHAN workshop on Chinese language processing</meeting>
		<imprint>
			<date type="published" when="2003">2003. 2003. 2011. 2011</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="856" to="867" />
		</imprint>
	</monogr>
	<note>Hhmm-based chinese lexical analyzer ictclas</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning with hypergraphs: Clustering, classification, and embedding</title>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2007">2018. 2018. 2007. 2007</date>
			<biblScope unit="page" from="1601" to="1608" />
		</imprint>
	</monogr>
	<note>IJCAI</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
