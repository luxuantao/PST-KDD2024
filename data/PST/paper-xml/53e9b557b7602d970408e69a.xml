<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Symmetric Sub-Pixel Stereo Matching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Richard</forename><surname>Szeliski</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<postCode>98052</postCode>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Scharstein</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Middlebury College</orgName>
								<address>
									<postCode>05753</postCode>
									<settlement>Middlebury</settlement>
									<region>VT</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Symmetric Sub-Pixel Stereo Matching</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4B7138F1BB7B2C6067B3559FCD9546B7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Two central issues in stereo algorithm design are the matching criterion and the underlying smoothness assumptions. In this paper we propose a new stereo algorithm with novel approaches to both issues. We start with a careful analysis of the properties of the continuous disparity space image (DSI), and derive a new matching cost based on the reconstructed image signals. We then use a symmetric matching process that employs visibility constraints to assign disparities to a large fraction of pixels with minimal smoothness assumptions. While the matching operates on integer disparities, sub-pixel information is maintained throughout the process. Global smoothness assumptions are delayed until a later stage in which disparities are assigned in textureless and occluded areas. We validate our approach with experimental results on stereo images with ground truth.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The last few years have seen a dramatic improvement in the quality of dense stereo matching algorithms <ref type="bibr" target="#b13">[14]</ref>. A lot of this improvement can be attributed to better optimization algorithms and better smoothness constraints <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b15">16]</ref>. However, a remarkable amount of the improvement has also come from better matching metrics at the input <ref type="bibr" target="#b2">[3]</ref>. In fact, Birchfield and Tomasi's sampling-insensitive dissimilarity measure is used by a number of today's best performing algorithms <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b3">4]</ref>.</p><p>Using something better than just pixel-sampled intensity differences is not a new idea. For example, Matthies et al. interpolated scanlines by a factor of 4 using a cubic interpolant before computing the SSD score <ref type="bibr" target="#b10">[11]</ref>. Tian and Huhns wrote an even earlier survey paper comparing various algorithms for sub-pixel registration <ref type="bibr" target="#b16">[17]</ref>. In fact, some stereo and motion algorithms have always evaluated displacements on a half-pixel grid, but never mentioned this fact explicitly (P. <ref type="bibr">Anandan, personal communication)</ref>.</p><p>The set of initial matching costs that are fed into a stereo matcher's optimization stage is often called the disparity space image (DSI) <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b4">5]</ref>. However, while the concept of stereo matching as finding an optimal surface through this space has been around for a while <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b4">5]</ref>, relatively little attention has been paid to the proper sampling and treatment of the DSI.</p><p>In this paper, we take a more careful look at the structure of the DSI, including its frequency characteristics and the effects of using different interpolators in sub-pixel registration. Among the questions we ask are: What does the DSI look like? How finely do we need to sample it? Does it matter what interpolator we use?</p><p>We also propose a number of novel modifications to the matching cost that produce a better set of initial high-quality matches, at least in textured, unoccluded areas. It is our contention that filling in textureless and occluded areas is best left to a later stage of processing <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b15">16]</ref>.</p><p>In the second half of the paper, we show how the local structure of the DSI can be used to select certain matches, i.e., matches that are correct with high probability. (Intille and Bobick <ref type="bibr" target="#b4">[5]</ref> call such points ground control points.) We also develop an iterative algorithm that adds more matches, using a combination of uniqueness enforcement (filling the DSI with high costs in already matched columns), and doing more aggregation for pixels with multiple possible matches. We present the final dense matching results of our approach, which are comparable in quality to recent stereo matching algorithms, but which do not require any global optimization algorithm.</p><p>The remainder of the paper is structured as follow. Section 2 presents our analysis of the DSI and discusses minimal sampling requirements. Section 3 develops some novel matching costs based on our analysis. The utility of these novel costs is validated experimentally in Section 4. Section 5 presents our algorithm for establishing certain matches and for iteratively adding more matches to this set. We conclude with some ideas for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Matching costs</head><p>In this section, we look at how matching costs are formulated. In particular, we analyze the structure of the DSI and its sampling properties and propose some improvements to commonly used matching costs.</p><p>Given two input images, I L (x, y) and I R (x, y), we wish to find a disparity map d L (x, y) such that the two images match as closely as possible</p><formula xml:id="formula_0">I L (x, y) ≈ I R (x -d L (x, y), y).</formula><p>(</p><p>(We assume that the images have been rectified to have a horizontal epipolar geometry <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b8">9]</ref>. We will also want to impose some smoothness or other prior constraints on the function d L (x, y).) Define the 3D signed difference image (SDI) as the intensity (or color) difference between the shifted left and right images,</p><formula xml:id="formula_2">SDI L (x, y, d) = I L (x, y) -I R (x -d, y).</formula><p>(</p><formula xml:id="formula_3">)<label>2</label></formula><p>Let the raw disparity space image (DSI) be the squared difference (summed over all the color bands),</p><formula xml:id="formula_4">DSI L (x, y, d) = SDI L (x, y, d) 2 . (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>Why do we use squared differences? The analysis for this case is simpler, and it also has some other advantages we will discuss shortly. In the ideal (continuous, noise-free) case with no occlusions, we expect DSI L (x, y, d L (x, y)) to be zero. Unfortunately, we do not actually have access to continuous, noise-free versions of I L (x, y) and I R (x, y). Instead, we have sampled noisy versions, ÎL (x i , y i ) and</p><formula xml:id="formula_6">ÎR (x i , y i ), ÎL (x i , y i ) = [I L * h](x i , y i ) + n L (x i , y i ) (4) ÎR (x i , y i ) = [I R * h](x i , y i ) + n R (x i , y i ),<label>(5)</label></formula><p>where h(x, y) is the combined point-spread-function of the optics and sampling sensor (e.g., it incorporates the CCD fill factor <ref type="bibr" target="#b17">[18]</ref>), and n L is the (integrated) imaging noise.</p><p>Given that we can only evaluate the DSI at the integral grid positions (x i , y i ), we have to ask whether this sampling of the DSI adequate, or whether there is severe aliasing in the resulting signal. We cannot, of course, reconstruct the true DSI since we have already band-limited, corrupted, and sampled the original images. However, we can (in principle) reconstruct continuous signals from the noisy samples, and then compute their continuous DSI. The reconstructed signal can be written as</p><formula xml:id="formula_7">I L (x, y) = i ÎL (x i , y i )g(x -x i , y -y i )<label>(6)</label></formula><p>= ĨL (x, y) + ñL (x, y), <ref type="bibr" target="#b6">(7)</ref> where g(x, y) is a reconstruction filter, ĨL (x, y) is the sampled and reconstructed version of the clean (original) signal, and ñL (x, y) is an interpolated version of the noise. This latter signal is a band-limited version of continuous Gaussian noise (assuming that the discrete noise is i.i.d. Gaussian). We can then write the interpolated SDI and DSI as</p><formula xml:id="formula_8">SDI L (x, y, d) = I L (x, y) -I R (x -d, y) and (8) DSI L (x, y, d) = SDI(x, y, d) 2 . (<label>9</label></formula><formula xml:id="formula_9">)</formula><p>What can we say about the structure of these signals?</p><p>The answer can be found by taking a Fourier transform of the SDI. Let us fix y for now and just look at a single scanline,</p><formula xml:id="formula_10">F{SDI} = H L (f x ) -H R (f x )e j2π(fx-f d ) , (<label>10</label></formula><formula xml:id="formula_11">)</formula><p>where H L and H R are the Fourier transforms of I L and I R .</p><p>Figure <ref type="figure" target="#fig_1">1</ref> shows the SDIs and DSIs for two scanlines taken from the 38th and 148th row of the image in Figure <ref type="figure" target="#fig_1">1a</ref>, along with their Fourier transforms. The first term in <ref type="bibr" target="#b9">(10)</ref> corresponds to the horizontal line in the SDI's Fourier transform (second column of Figure <ref type="figure" target="#fig_1">1</ref>), while the second term, which involves the disparity, is the slanted line.</p><p>Squaring the SDI to obtain the DSI (third column in Figure <ref type="figure" target="#fig_1">1</ref>) is equivalent to convolving the Fourier transform with itself (fourth column in Figure <ref type="figure" target="#fig_1">1</ref>). The resulting signal has twice the bandwidth in x and d as the original SDI (which has the same bandwidth as the interpolated signal). It is also interesting to look at the structure of the DSI itself. The thin diagonal stripes are spurious bad matches (dark-light transitions matching light-dark transitions), while the horizontal stripes are good matching regions (the straighter and darker the better).</p><p>What can we infer from this analysis? First, the continuous DSI has significant frequency content above the frequencies present in the original intensity signal. Second, the amount of additional content depends on the quality of the interpolator applied to the signal. Thus, when perfect band-limited reconstruction (a sinc filter) is used, the resulting DSI signal only has twice the frequency of the image. It is therefore adequate (in theory) to sample the DSI at 1/2 pixel intervals in x and d. When a poorer interpolant such as piecewise linear interpolation is used, the sampling may have to be much  higher. The same is true when a different non-linearity is used to go from the SDI to the DSI, e.g., when absolute differences or robust measures are used. This is one of the reasons we prefer to use squared difference measures. Other reasons include the statistical optimality of the DSI as the log likelihood measure under Gaussian noise, and the ability to fit quadratics to the locally linearized expansion of the DSI. We can summarize these observations in the following Lemma: Lemma 1: To properly reconstruct a Disparity Space Image (DSI), it must be sampled at at least twice the horizontal and disparity frequency as the original image (i.e., we must use at least 1/2 pixel samples and disparity steps).</p><formula xml:id="formula_12">(d) (e) (f) (g) (h) (i) (j) (k) (l) (m) (n) (o)</formula><p>It is interesting to note that if a piecewise linear interpolant is applied between image samples before differencing and squaring, the resulting DSI is piecewise quadratic. Therefore, it suffices in principle to simply compute one additional squared difference between pixels, and to then fit a piecewise quadratic model. While this does reconstruct a continuous DSI, there is no guarantee that this DSI will have the same behavior near true matches as a better reconstructed DSI. Also, the resulting minima will be sensitive to the original placement of samples, i.e., a significant bias towards integral disparities will exist <ref type="bibr" target="#b14">[15]</ref>.</p><p>For example, if the original signal is a fairly high-frequency chirp (Figure <ref type="figure" target="#fig_2">2a</ref>), then applying a piecewise linear interpolant will fail to correctly match the signal with a fractionally shifted version. Figure <ref type="figure" target="#fig_2">2b</ref> and<ref type="figure">c</ref> show the results of aggregating the original raw DSIs with a 7-pixel filter (see Section 3). Clearly, using the linear interpolant will result in the wrong disparity minimum being selected in the central portion (where the central horizontal line is weak). One might ask whether such high-frequency signals really exist in practice, but it should be clear from Figure <ref type="figure" target="#fig_1">1b</ref> and c that they do.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Improved matching costs</head><p>Given the above analysis, how can we design a better initial matching cost? Birchfield and Tomasi <ref type="bibr" target="#b2">[3]</ref> and Shimizu and Okutomi <ref type="bibr" target="#b14">[15]</ref> have both observed problems with integral DSI sampling, and have proposed different methods to overcome this problem.</p><p>Birchfield and Tomasi's sampling-insensitive dissimilarity measure compares each pixel in the reference image against the linearly interpolated signal in the matching image, and takes the minimum squared error as the matching cost. It then reverses the role of the reference and matching images, and takes the minimum of the resulting two cost measures. In terms of our continuous DSI analysis, this is equivalent to sampling the DSI at integral x locations, and computing the minimum value vertically and diagonally around each integral d value, based on a piecewise linear reconstruction of the DSI from integral samples. We generalize Birchfield and Tomasi's matching measure using the following two ideas: Symmetric matching of interpolated signals First of all, we interpolate both signals up by a factor s using an arbitrary interpolation filter. In this paper, we study linear (o = 1) and cubic (o = 3) interpolants. We then compute the squared differences between all of the interpolated and shifted samples, as opposed to just between the original left (reference) image pixels and the interpolated and shifted right (matching) image samples. This difference signal is then reduced back to the original horizontal image sampling using a symmetric filter of width s and then downsampling. A higherorder filter could potentially be used, but we wish to keep discontinuities in depth sharp in the DSI, so we prefer a simple box filter.</p><p>Interval matching If we wish to still apply the idea of a sampling-insensitive dissimilarity measure <ref type="bibr" target="#b2">[3]</ref>, we can still do this on the interpolated signals before downsampling. However, rather than treating the reference and matching images asymmetrically and then reversing the roles of reference and matching (as in <ref type="bibr" target="#b2">[3]</ref>), we have developed the following related variant that is based on interval analysis. images, and takes the minimum of the resulting two costs. Our version of the algorithm simply compares the two intervals, one from the left scanline, the other from the right, rather than comparing values against intervals. The unsigned difference between two intervals is trivial to compute: it is 0 if the intervals overlap (Figure <ref type="figure">3c</ref>), else it is the gap between the two intervals. A signed difference could also be obtained by keeping track of which interval is higher, but in our case this is unnecessary since we square the differences after computing them.</p><p>When working with color images, we currently apply this interval analysis to each color band separately. In principle, the same sub-pixel offset should be used for all three channels, but the problem then becomes a more complicated quadratic minimization problem instead of simple interval analysis.</p><p>Local minimum finding (quadratic fit) An alternative to doing such interval analysis is to directly compute the squared differences, and to then fit a parabola to the resulting sampled DSI. This is a classic approach to obtaining sub-pixel disparity estimates <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b10">11]</ref>, although applying it directly to integer-valued displacements (disparities) can lead to severe biases <ref type="bibr" target="#b14">[15]</ref>.</p><p>When the DSI has been adequately sampled, however, this is a very useful alternative for estimating the analytic minimum from the (fractionally) sampled DSI. In order to reduce the noise in the DSI before fitting, we apply spatial aggregation first. In this paper, we study both fixed and shiftable square windows, as these perform quite well <ref type="bibr" target="#b13">[14]</ref>, at least in textured areas. (We will deal with untextured areas in Section 5.)</p><p>Collapsing the DSI Finally, once the local minima in the DSI at all pixels have been adequately modeled, we can collapse the DSI back to an integral sampling of disparities. This step is often not necessary, as many stereo matchers do their optimization at subpixel disparities. It does, however, have several potential advantages:</p><p>-For optimization algorithms like graph cuts <ref type="bibr" target="#b5">[6]</ref> where the computation complexity is proportional to the square of the number of disparity level, this can lead to significant performance improvements. -Certain symmetric matching algorithm such as dynamic programming and the technique developed in Section 5 require an integral sampling of disparity to establish two-way optima.</p><p>To collapse the DSI, we find the lowest matching score within a 1 2 disparity from each integral disparity, using the results of the parabolic fitting, if it was used. We also store the relative offset of this minimum from the integral disparity for future processing and for outputting a final high-accuracy disparity map. Alternately, sub-pixel estimates could be recomputed at the end around each winning disparity using one of the techniques described in <ref type="bibr" target="#b16">[17]</ref>, e.g., using a Lucas-Kanade gradient-based fit <ref type="bibr" target="#b9">[10]</ref> to nearby pixels at the same disparity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental evaluation of matching costs</head><p>Since there are so many alternatives possible for computing the DSI, how do we choose among them? From theoretical arguments, we know that it is better to sample the DSI at fractional disparities and to interpolate the resulting surface when looking for local minima. However, real images have noise and other artifacts such as aliasing and depth discontinuities. So, how do we choose?</p><p>In order to answer this question, we apply the techniques introduced in this section to the four test sequences described in <ref type="bibr" target="#b13">[14]</ref>, which are also available on the Web (http://www.middlebury.edu/stereo/). Two of these sequences are shown in Figure <ref type="figure" target="#fig_4">4a</ref>. (The other two are omitted due to space limitations.) At this point, we are only interested in the accuracy of these techniques in unoccluded textured areas; techniques for estimating the disparities of the remaining pixels will be presented in the next section.</p><p>For the analysis in this section, we select textured pixels as follows: compute the squared horizontal gradient at each pixel (averaging the left and right values to remain symmetrical), and average these values in a 3×3 neighborhood. Then, threshold the averaged squared value to obtain the textureless masks shown in Figure <ref type="figure" target="#fig_4">4c</ref>. We currently use a threshold of 9 gray levels squared.</p><p>The parameters that we vary in our experiments are as follows:</p><p>s = 1, 2, 4 interpolation rate (inverse of fractional disparity) -o = 1, 3 interpolation order (linear or cubic) -i: symmetric matching of interpolated scanlines (on or off) -d: dissimilarity metric (squared differences SD or interval differences ID) -f : sub-pixel fit of disparities after aggregation (on or off)</p><p>The parameters that we hold fixed in the algorithm are the matching criterion (squared differences), the window size (7 × 7), and the fact that the windows are shiftable. We also collapse the DSI to an integer-valued sampling, so that the final winner-take-all is performed on integer disparities (with the stored sub-pixel minimum estimates used to compute the final sub-pixel disparity).</p><p>The statistics that we gather are the number of pixels that are "bad" matches, i.e., whose floating point disparity differs from the ground truth by more than 1.5 pixels. (We use 1.5 instead of 1 in order to tolerate small disparity deviations due to possible vertical misregistration.) Table <ref type="table" target="#tab_0">1</ref> shows the percentage of bad matches for each of the four data sets as a function of our variable parameters. We only show results using cubic interpolation (o = 3); linear interpolation gives comparable, but (on average) slightly inferior results. Image In Table <ref type="table" target="#tab_0">1</ref>, we have highlighted in boldface the lowest score for each of the four data sets. As one can see, there is no single setting that consistently outperforms the others, although sub-pixel fitting usually leads to slightly worse results, probably because it is sensitive to noise in the DSI. Figure <ref type="figure" target="#fig_4">4</ref> shows the results corresponding to the first (s = 1) and seventh (s = 4, f = 0, i = 1) columns. Note how the seventh column consistently outperforms both the original SD (squared difference) and ID (asymmetric interval difference) algorithms. Using interval analysis instead of sub-pixel fitting seems to usually result in lower errors, although it can lead to problems both during minfinding (this Section) and when establishing certain matches (Section 5) because many reasonable matches can yield a matching cost of 0.</p><formula xml:id="formula_13">d s = 1 s = 2 s = 4 f : 0 1 0 1 i : 0 1 0 1 0 1 0 1 Sawtooth SD 0.</formula><p>Carefully examining the error maps in Figure <ref type="figure" target="#fig_4">4</ref> shows that the main effects of using the fractional disparity matching scores seems to be getting better results at strong intensity discontinuities. The remaining errors seem to be a combination of the classic "fattening" effect seen near disparity discontinuities (which is characteristic of local analysis), and some errors in repeated textures such as the video tapes in the Tsukuba image, which could be ameliorated with more aggregation or global optimization.</p><p>In summary, while there are no clear winners among the different cost variants, it can be seen that symmetric interpolated matching (i = 1 and s =2 or s =4) usually outperforms traditional, integer-based matching. The benefit of interval matching depends on the winner selection strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Symmetric matching process</head><p>We now turn to the second part of our method: the symmetric matching process. Using an interpolated matching cost that is insensitive to aliasing, we can determine the quality of matches based on the cost distribution in the DSI after a small amount of initial aggregation. Throughout this section we use symmetric matching with 1  2 pixel interpolation (SD, s = 2, f = 0, i = 1). We are not using interval matching (ID) since this tends to "round down" good matching costs to 0, making it more difficult to draw conclusions from the cost value distributions.  Our algorithm starts by selecting a subset of high-confidence matches, and then aggregates the DSI with increasingly larger windows to disambiguate matches in untextured areas. (A related technique that starts with high-confidence corner matches has been proposed by Zhang and Yang <ref type="bibr" target="#b19">[20]</ref>.) For easier reasoning about visibility, we collapse the DSI to integer sampling, as discussed in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Selecting certain matches</head><p>There are two basic tests to determine whether a match is certain, i.e., correct with high probability. First, there should be a clear minimum among all candidate cost values. Second, the minima for both left-to-right and right-to-left matching should agree <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b4">5]</ref>, which can be checked by examining the vertical and diagonal columns in disparity space (Figure <ref type="figure" target="#fig_5">5b</ref>).</p><p>While the second test is easy to implement, the definition of a clear minimum is less straightforward. Using one of the improved matching costs developed in the previous section ensures that a correct match yields a low matching cost, even in high-frequency image regions. Thus, a minimum corresponding to a correct match should have a low cost value. Conversely, a large minimum value indicates an occluded pixel that has no correct match. At many pixels, however, there will be multiple low cost values that cannot always be disambiguated. Figure <ref type="figure" target="#fig_6">6</ref>  for a given winner margin m &lt; 1.</p><p>The winner margin m needs to be chosen low enough to avoid false positives (i.e., incorrect matches labeled certain). On the other hand, a higher margin results in a higher fraction of pixels being matched. Table <ref type="table" target="#tab_1">2a</ref> demonstrates this trade-off using the Tsukuba images from Figure <ref type="figure" target="#fig_4">4</ref>. It shows the error rate among the certain matches and the total fraction of pixels matched as a function of winner margin m. For lowest error rates, a small amount of aggregation is necessary. Here we aggregate the initial cost values with a 5×5 window. Note that unlike in Section 4, we do not need to explicitly label pixels as textureless, since this is subsumed by our test for match certainty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Reasoning about visibility and occlusions</head><p>Before discussing how we can propagate certain matches to ambiguous regions, we briefly address how visibility constraints enter the matching process. Since we eventually need to assign matches even where there is no clear minimum among the cost values, we need to ensure that the uniqueness constraint is enforced. We can achieve this by altering the cost values "shadowed" by certain matches. Every time a new certain match has been assigned, we set the cost values for other matches eliminated by the new match (i.e., the O's in Figure <ref type="figure" target="#fig_5">5b</ref>) to a large value C max . This prohibits the future assignment of low-cost matches in the diagonal DSI column. Altering the cost values can also help disambiguate multiple good matches, especially on the perimeter of textureless regions.</p><p>After the certain matches have been found and the costs have been altered as described, new certain matches may emerge where competing low cost values have been changed to C max . The process is thus repeated until no new certain matches can been found. Typically, this process yields an increase in certain matches of about 5-10%.</p><p>We have also experimented with enforcing the ordering constraint by assigning C max to all O's in Figure <ref type="figure" target="#fig_5">5c</ref>. We found, however, that this yields too few additional  <ref type="figure" target="#fig_8">7</ref>) using a constant margin m = 0.5. The last row shows the percentage of bad pixels in unoccluded regions after the remaining unmatched regions have been filled in.</p><p>certain matches to warrant the inability to deal with narrow occluding objects imposed by the ordering constraint.</p><p>The second advantage of eliminating matches by setting their costs to C max is that occluded pixels can be detected more easily. We currently label all pixels as occluded when their minimum cost value is more than 10 times the average cost value of all certain matches. This works very well in textured areas with many certain matches, whose C max values effectively rule out all disparities for pixels that must be occluded. The disparities of occluded areas can be estimated fairly reliably by filling them with the nearest background disparity on each scanline. This is the last stage in our matching algorithm. First, however, the disparities in ambiguous regions need to be recovered, which is discussed next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Propagating matches</head><p>To propagate certain matches into ambiguous matching regions, we propose an iterative algorithm similar in spirit to adaptive-windows techniques <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b19">20]</ref>. Our algorithm interleaves the selection of certain matches with further aggregation of the DSI, using successively larger windows. After each aggregation step, new certain matches are selected among the previously uncommitted pixels. The algorithm converges quickly because the large cost values C max are aggregated as well, which helps to rule out many ambiguous matches.</p><p>Figure <ref type="figure" target="#fig_8">7</ref> shows the results of our algorithm on the Tsukuba image pair. We start by aggregating with a 5 × 5 window, and then increase the window size by 4 after each iteration. We use a constant winner margin m = 0.5. After 5 iterations, disparities have been assigned to virtually all uncertain regions. The remaining occluded (highcost) regions are filled in as described in the previous section. Finally, we restore the sub-pixel estimates computed before collapsing the DSI to integer disparities. Table <ref type="table" target="#tab_1">2b</ref> lists the statistics for each of the five iterations. Note that the number of bad matched pixels increases only slightly, and the final numbers are quite good. The overall performance (4.9% bad unoccluded pixels) is comparable to most methods evaluated in <ref type="bibr" target="#b13">[14]</ref>, except for the graph-cut method <ref type="bibr" target="#b5">[6]</ref>. The overall running time for this experiment is 4.7 seconds on a 750 MHz Pentium III machine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we have presented both novel matching costs and a new symmetric matching algorithm. Our matching costs are based on interpolated image signals, and are motivated by a frequency analysis of the continuous disparity space image (DSI). We have explored several symmetric cost variants, including a generalized version of Birchfield and Tomasi's matching criterion <ref type="bibr" target="#b2">[3]</ref>. While there is no clear winner among the different variants, we have shown that our new costs result in improved matching performance, in particular in high-frequency image regions. An added benefit is that the sub-pixel information derived during the initial cost computation can be restored at the end for the winning disparities, even if the intermediate matching process operates on integer disparities.</p><p>Our second contribution, the symmetric matching algorithm, utilizes visibility constraints to find an initial set of high-confidence matches, and then propagates disparity estimates into ambiguous image regions using successive aggregation of the DSI. Our initial experiments show competitive performance for a method that does not perform global optimization.</p><p>There are several issues we plan to address in future work. Relating to matching costs, we have started to explore the effect of certain asymmetries that occur when collapsing the subsampled DSI to an integer grid. We also want to evaluate our matching costs with further experiments, and compare them with the method developed by Shimizu and Okutomi <ref type="bibr" target="#b14">[15]</ref>. Relating to disparity estimation, we plan to improve our current algorithm and to test its performance on image pairs with narrow occluding objects that violate the ordering constraint. In the longer term, we hope to achieve results competitive with the graph-cut algorithm <ref type="bibr" target="#b5">[6]</ref> by exploring new ways of imposing global smoothness constraints in textureless areas.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Sample SDIs and DSsI and their Fourier transforms. (a) Original color image with two selected scanlines; (b-c) profiles of second selected scanline (L148); notice how the sincinterpolated signals (red, solid) are more similar than the linearly interpolated ones (blue, dashed). (d-g) Signed Difference Image (SDI) and its transform, and Disparity Space Image (DSI) and its transform for L38, using perfect (sinc) interpolation; (h-k) same images using piecewise linear interpolation; (l-o) same images for L148 and perfect interpolation. (See the electronic version of this paper for color images.)</figDesc><graphic coords="4,217.17,461.54,86.40,86.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Chirp signal matching: (a) the continuous green signal is sampled discretely to obtain the red and blue signals; (b) Disparity Space Image (DSI) for linear interpolation; (c) horizontally aggregated DSI for sinc interpolation, showing correct minimum; (c) horizontally aggregated DSI for linear interpolation, with incorrect minima near the center.</figDesc><graphic coords="6,175.09,259.73,129.60,129.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 Fig. 3 .</head><label>33</label><figDesc>Fig. 3. Interval analysis: (a-b) two signals with their corresponding half-sample intervals; (c) three intervals being compared (differenced).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Test images and associated maps: (a) input images; (b) true disparity maps and occluded (black) and textureless (white) regions (the gray regions are the ones for which we collect statistics); (c) traditional shiftable SSD results (disparity map and error map); (d) interval difference (asymmetric Birchfield-Tomasi dissimilarity); (e) fractional disparities with symmetric matching; (f) fractional disparities with symmetric matching and interval difference.</figDesc><graphic coords="9,321.07,519.02,74.80,66.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Illustration of uniqueness and ordering constraints. The figures symbolize part of an xd slice through the DSI. (a) A proposed match M for x = 3 and d = 2. (b) Other matches O ruled out by the uniqueness constraint. The vertical line eliminates other matches for the reference (left) pixel; the diagonal line eliminates other matches for the matching (right) pixel. Many asymmetric algorithms only enforce the former. (c) Some algorithms (not ours) enforce the ordering constraint, and disallow all matches in the two triangular regions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Example cost value distributions (vertical DSI columns) for three locations in the Tsukuba images. We show both initial (raw) values and after aggregation with a 5×5 window. (a) Locally constant image region near the nose of the bust. Aggregation recovers the correct minimum. (b) Repetitive texture (video tapes on shelf), yielding two local minima. (c) Textureless region (shadow under the table), resulting in many low-cost values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>11 ) 2 .</head><label>112</label><figDesc>illustrates three different cost distributions, which help motivate the following definition: We define a match (x, y, d) with cost C = DSI(x, y, d) to be certain if 1. C is the minimum cost in both columns, i.e., C ≤ DSI(x, y, d ) ∀d = d, and C ≤ DSI(x-d+ d , y, d ) ∀d = d; (C is a strong minimum in at least one column, i.e., C ≤ m DSI(x, y, d ) ∀d = d, or C ≤ m DSI(x-d+ d , y, d ) ∀d = d (12)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Resolving unmatched areas using increasing amounts of aggregation. The figure shows a sequence of six (color) disparity maps as the matching process aggregates the DSI with windows of size 5, 9, 13, 17, and 21, and selects certain matches after each pass. Uncertain matches are shown in blue; high-cost (occluded) matches are shown in red. After the 5th pass, the remaining unmatched areas are filled in. Underneath each disparity map is the corresponding disparity error map (for certain matches only).Table 2b lists the statistics for each of the six disparity maps.</figDesc><graphic coords="14,138.58,458.52,108.00,81.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Percentage of bad matching pixels for various matching cost options. The numbers highlighted in boldface are the best matching variants for each dataset.</figDesc><table><row><cell></cell><cell></cell><cell>37 0.36 0.30 0.38 0.39 0.35 0.29 0.37 0.42</cell></row><row><cell></cell><cell>ID</cell><cell>0.22 0.20 0.12 0.18 0.16 0.22 0.20 0.25 0.26</cell></row><row><cell>Venus</cell><cell cols="2">SD 1.33 1.10 1.23 1.21 1.34 1.08 1.19 1.16 1.29</cell></row><row><cell></cell><cell>ID</cell><cell>4.04 1.33 4.68 1.43 4.82 1.26 1.52 1.38 1.65</cell></row><row><cell cols="3">Tsukuba SD 4.38 3.69 3.51 3.73 6.84 3.72 3.43 3.77 3.37</cell></row><row><cell></cell><cell>ID</cell><cell>6.54 3.25 3.15 3.62 3.22 3.67 3.17 3.65 3.26</cell></row><row><cell>Map</cell><cell cols="2">SD 4.72 3.85 3.25 3.84 3.24 3.66 3.20 3.64 3.22</cell></row><row><cell></cell><cell>ID</cell><cell>3.15 5.77 2.38 3.05 2.55 2.92 2.19 2.95 2.28</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>(a) Percent of bad certain matches (disparity error &gt; 1) and fraction of pixels matched as a function of winner margin m for the Tsukuba image pair. Lower margins result in fewer errors but leave more pixels unmatched. (b) Performance of our matching algorithm while aggregating with increasing window size w (see Section 5.3 and Figure</figDesc><table><row><cell>Margin m</cell><cell>Bad</cell><cell>Matched</cell><cell cols="2">Final w Pass</cell><cell>Bad</cell><cell>Matched</cell></row><row><cell>1.0</cell><cell>12.1%</cell><cell>96%</cell><cell>5</cell><cell>1</cell><cell>2.8%</cell><cell>59%</cell></row><row><cell>0.9</cell><cell>9.5%</cell><cell>90%</cell><cell>9</cell><cell>2</cell><cell>3.8%</cell><cell>83%</cell></row><row><cell>0.8</cell><cell>6.0%</cell><cell>81%</cell><cell>13</cell><cell>3</cell><cell>4.0%</cell><cell>90%</cell></row><row><cell>0.7</cell><cell>4.0%</cell><cell>73%</cell><cell>17</cell><cell>4</cell><cell>4.0%</cell><cell>91%</cell></row><row><cell>0.6</cell><cell>3.2%</cell><cell>66%</cell><cell>21</cell><cell>5</cell><cell>4.0%</cell><cell>91%</cell></row><row><cell>0.5</cell><cell>2.8%</cell><cell>59%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.4</cell><cell>2.4%</cell><cell>53%</cell><cell>21</cell><cell>5*</cell><cell>4.9%</cell><cell>100%</cell></row><row><cell>0.3</cell><cell>2.1%</cell><cell>45%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>(a)</cell><cell></cell><cell></cell><cell></cell><cell>(b)</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A computational framework and an algorithm for the measurement of visual motion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Anandan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="283" to="310" />
			<date type="published" when="1989-01">January 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Bayesian approach to binocular stereopsis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="237" to="260" />
			<date type="published" when="1996-08">August 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A pixel dissimilarity measure that is insensitive to image sampling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Birchfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="401" to="406" />
			<date type="published" when="1998-04">April 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiway cut for stereo and motion with slanted surfaces</title>
		<author>
			<persName><forename type="first">S</forename><surname>Birchfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh International Conference on Computer Vision (ICCV&apos;99)</title>
		<meeting><address><addrLine>Kerkyra, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="page" from="489" to="495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Large occlusion stereo</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Bobick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Intille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="200" />
			<date type="published" when="1999-09">September 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fast approximate energy minimization via graph cuts</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1222" to="1239" />
			<date type="published" when="2001-11">November 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A parallel stereo algorithm that produces dense depth maps and preserves image features</title>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Vision and Applications</title>
		<meeting><address><addrLine>Winter</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="35" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A stereo matching algorithm with an adaptive window: Theory and experiment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Okutomi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="920" to="932" />
			<date type="published" when="1994-09">September 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Computing rectifying homographies for stereo vision</title>
		<author>
			<persName><forename type="first">C</forename><surname>Loop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;99)</title>
		<imprint>
			<publisher>Fort Collins</publisher>
			<date type="published" when="1999-06">June 1999</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="125" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An iterative image registration technique with an application in stereo vision</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh International Joint Conference on Artificial Intelligence (IJCAI-81)</title>
		<meeting><address><addrLine>Vancouver</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="674" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Kalman filter-based algorithms for estimating depth from image sequences</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Matthies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="209" to="236" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A multiple baseline stereo</title>
		<author>
			<persName><forename type="first">M</forename><surname>Okutomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="353" to="363" />
			<date type="published" when="1993-04">April 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<title level="m">Stereo matching with nonlinear diffusion. International Journal of Computer Vision</title>
		<imprint>
			<date type="published" when="1998-07">July 1998</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="155" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A taxonomy and evaluation of dense two-frame stereo correspondence algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="42" />
			<date type="published" when="2002-05">May 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Precise sub-pixel estimation on area-based matching</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Okutomi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International Conference on Computer Vision (ICCV 2001)</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-07">July 2001</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="90" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A global matching framework for stereo computation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Sawhney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International Conference on Computer Vision (ICCV 2001)</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-07">July 2001</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="532" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Algorithms for subpixel registration</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Huhns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="220" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Statistical calibration of CCD imaging process</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International Conference on Computer Vision (ICCV 2001)</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-07">July 2001</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="480" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Local, global, and multilevel stereo matching</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;93)</title>
		<meeting><address><addrLine>New York, New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1993-06">June 1993</date>
			<biblScope unit="page" from="274" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A progressive scheme for stereo matching</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second European Workshop on 3D Structure from Multiple Images of Large-Scale Environments (SMILE 2000)</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</editor>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-07">July 2000</date>
			<biblScope unit="page" from="68" to="85" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
