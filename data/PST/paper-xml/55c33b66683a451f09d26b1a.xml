<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Multi-Operator Search Strategy based on Cheap Surrogate Models for Evolutionary Optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wenyin</forename><surname>Gong</surname></persName>
							<email>wygong@cug.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Aimin</forename><surname>Zhou</surname></persName>
							<email>amzhou@cs.ecnu.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Zhihua</forename><surname>Cai</surname></persName>
							<email>zh-cai@cug.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Hubei Key Laboratory of Intelligent Geo-Information Processing</orgName>
								<orgName type="institution">China University of Geosciences</orgName>
								<address>
									<postCode>430074</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">China University of Geosciences</orgName>
								<address>
									<postCode>430074</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">Shanghai Key Laboratory of Multidimensional Information Processing</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<postCode>200241</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<postCode>200241</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">China University of Geosciences</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">IEEE Computational Intel-ligence Magazine</orgName>
								<orgName type="department" key="dep2">ACM Transactions on Intelligent Systems and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department">Information Sciences</orgName>
								<orgName type="institution">European Journal of Operational Research</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution">degree from University of Essex</orgName>
								<address>
									<settlement>Colchester</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="department" key="dep1">Shanghai Key Laboratory of Multidimensional Information Processing</orgName>
								<orgName type="department" key="dep2">Department of Computer Sci-ence and Technology</orgName>
								<orgName type="institution">East China Normal Univer-sity</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="institution">China University of Geosciences</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Multi-Operator Search Strategy based on Cheap Surrogate Models for Evolutionary Optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">67DD5751A1CFF95D18DAA9F92C49601E</idno>
					<idno type="DOI">10.1109/TEVC.2015.2449293</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TEVC.2015.2449293, IEEE Transactions on Evolutionary Computation 1 This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TEVC.2015.2449293, IEEE Transactions on Evolutionary Computation This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TEVC.2015.2449293, IEEE Transactions on Evolutionary Computation 13</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Evolutionary algorithm</term>
					<term>global optimization</term>
					<term>multi-operator ensemble</term>
					<term>surrogate model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>It is well known that in evolutionary algorithms, different reproduction operators may be suitable for different problems or in different running stages. To improve the algorithm performance, the ensemble of multiple operators has become popular. Most ensemble techniques achieve this goal by choosing an operator according to a probability learned from the previous experience. In contrast to these ensemble techniques, in this paper we propose a cheap surrogate model based multi-operator search strategy for evolutionary optimization. In our approach, a set of candidate offspring solutions are generated by using the multiple offspring reproduction operators, and the best one according to the surrogate model is chosen as the offspring solution. Two major advantages of this approach are (a) each operator can generate a solution for competition compared to the probability based approaches, and (b) the surrogate model building is relatively cheap compared to that in the surrogateassisted evolutionary algorithms. The model is used to implement multi-operator ensemble in two popular evolutionary algorithms, that is, differential evolution and particle swarm optimization. Thirty benchmark functions and the functions presented in the CEC 2013 are chosen as the test suite to evaluate our approach. Experimental results indicate that the new approach can improve the performance of single operator based methods in the majority of the functions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>W ITHOUT loss of generality, in this work, the following numerical optimization problem is considered:</p><formula xml:id="formula_0">Minimize f (x), x ∈ S,<label>(1)</label></formula><p>where x = (x 1 , x 2 , • • • , x n ) T is an n-dimensional decision variable vector, and S ⊆ R n is a compact set which denotes the feasible region of the search space. Usually S = [x j , x j ] n where j = 1, 2, • • • , n, x j and x j are respectively the lower bound and upper bound of x j .</p><p>Evolutionary algorithms (EAs) are a kind of search techniques based on the simulated evolutionary process of natural selection, variation, and genetics <ref type="bibr" target="#b0">[1]</ref>. During the last few decades, a variety of EAs have been proposed, such as genetic algorithm (GA), evolution strategy (ES), evolutionary programming (EP) <ref type="bibr" target="#b0">[1]</ref>, differential evolution (DE) <ref type="bibr" target="#b1">[2]</ref>, particle swarm optimization (PSO) <ref type="bibr" target="#b2">[3]</ref>, etc. A major difference between these algorithms is in the choice of reproduction operator, that is, the way to generate new trial solutions. Meanwhile, new operators are being developed every day. On the one hand, these operators are more or less similar; on the other hand, different operators may be suitable for different problems or in different running stages.</p><p>In order to solve a wide range of problems, combining different search operators might be a way to improve current EAs. However, how to combine these operators more efficiently is still a challenging task. Most existing techniques firstly build a posterior probability model based on previous successful experience in each generation and then choose one for offspring reproduction according to the posterior probability model <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>. However, it is not trivial to build and update a proper posterior probability model; furthermore, an incorrect model may mislead the search. To alleviate this problem, in this paper we propose a cheap surrogate model (CSM) based multi-operator search strategy for evolutionary optimization. In contrast to the probability-based techniques, a CSM is built in each generation first; a set of candidate solutions are generated for each individual by using multiple search operators, and the best one is chosen as the corresponding offspring solution according to the CSM. In comparison with the probability based approach, each search operator can generate candidate offspring solutions.</p><p>It should be noted that the major target of this paper is not to propose some new EAs but to propose a new strategy, CSM, to improve the performance of existing EAs. To this end, the CSM is first integrated into three advanced EAs: JADE <ref type="bibr" target="#b7">[8]</ref>, OLPSO <ref type="bibr" target="#b8">[9]</ref>, and CoBiDE <ref type="bibr" target="#b9">[10]</ref>, to implement a multi-operator ensemble for each of them. Secondly, we try to implement a hybrid DE and PSO method by combining DE and PSO search operators based on the CSM. These CSM-based approaches are systematically compared to the original EAs and some existing multi-operator search algorithms on 30 benchmarks chosen from the literature <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref> and also on the CEC 2013 test suite <ref type="bibr" target="#b14">[15]</ref>. Experimental results indicate that the CSM-based algorithms can obtain better performance than the corresponding single operator based algorithms in the majority of the test functions. Moreover, they can also provide better results than the compared multi-operator approaches presented in <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b15">[16]</ref>.</p><p>The rest of the paper is organized as follows. Section II briefly reviews the related work, including the multi-operator search techniques and the surrogate-assisted optimization in EAs. In Section III, a novel multi-operator search strategy based on the computationally cheap surrogate models is proposed in detail, followed by the empirical study on the proposed CSM-based multi-operator EAs in Section IV. Finally, the paper is concluded in Section V with some suggestions for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In this section, we first briefly review the multi-operator search techniques proposed in the literature, followed by a brief introduction of surrogate-assisted optimization in EAs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multi-Operator Search</head><p>As mentioned above, a variety of search operators have been developed. Different operators might be suitable for different problems or in different running stages. Therefore, in order to solve a wide range of problems, the ensemble of different operators in one single algorithm represents one of the most promising areas of research in evolutionary computation.</p><p>The following are representative multi-operator search techniques.</p><p>• Adaptive Operator Selection: Adaptation or selfadaptation of the selection probabilities of different operators has been extensively studied recently <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>. The key issue is how to assign the reproduction operator selection probabilities adaptively. To achieve this goal, a variety of strategies, such as decision making scheme <ref type="bibr" target="#b18">[19]</ref>, probability matching <ref type="bibr" target="#b19">[20]</ref>, adaptive pursuit <ref type="bibr" target="#b20">[21]</ref>, game theory <ref type="bibr" target="#b21">[22]</ref>, previous experience <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b22">[23]</ref>, learning <ref type="bibr" target="#b6">[7]</ref>, and combinations of different strategies <ref type="bibr" target="#b5">[6]</ref>, have been proposed in the last few years. • Multi-Method based Search: Since no single algorithm is always efficient for a diverse set of optimization problems, recently, it has been natural to use multiple methods simultaneously. In <ref type="bibr" target="#b23">[24]</ref>, a multi-method was proposed for multi-objective optimization, where the concepts of global information sharing and genetically adaptive offspring creation were utilized to tune the number of offspring generated by each method in a generation. This idea was also extended to scalar-objective optimization <ref type="bibr" target="#b24">[25]</ref>.</p><p>In <ref type="bibr" target="#b25">[26]</ref>, another cooperation strategy was proposed, where each constituent algorithm was run with a given budget, and different algorithms were interacted with a migration strategy.</p><p>• Adaptive Memetic Algorithms: Adaptive memetic algorithms represent another kind of multi-operator search strategy, where different local search operators are adaptively selected for individual improving. In memetic algorithms, the hill-climbing <ref type="bibr" target="#b26">[27]</ref>, gradient-based methods <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>, and some other search methods <ref type="bibr" target="#b3">[4]</ref> are chosen as local search operators in the framework of EAs. A comprehensive survey and comparative study of memetic algorithms can be found in <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>. In addition to the above mentioned strategies, there are also some other search techniques <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>, which can be regarded as multi-operator search strategies. In all of these methods, how to choose a proper search operator while keeping the search efficiency plays a key role.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Surrogate-Assisted Optimization</head><p>In many cases when the fitness evaluation needs a computational simulation or an experiment, it is expensive to evaluate an individual. A key issue with these kinds of optimization problems is how to balance the number of fitness evaluations and the solution quality. The surrogate-assisted evolutionary algorithm (SAEA) is a technique that deals with expensive optimization problems <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>. The basic idea behind SAEA is that it builds an alternative function f (x), called surrogate model, based on some of the obtained individuals {(x, f (x))}, and estimates the fitness values of some new trial individuals through the surrogate model. Therefore, the number of function evaluations based on the original expensive function f (x) is reduced.</p><p>In practice, there are two issues that should be considered in designing a SAEA.</p><p>• Surrogate Model Definition: This issue is related to how to define a surrogate model. It is arguable that all regression models can be applied here. In practice, some widely used models include the linear models, polynomial models, support vector regression, Kriging or Gaussian process <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>, radial basis function network <ref type="bibr" target="#b39">[40]</ref>, and some other techniques <ref type="bibr" target="#b40">[41]</ref>. It should be noted that different models have their own properties and they should be used properly. For example, the linear models and polynomial models are cheap to build but not accurate, while the Gaussian process is accurate but expensive to build. In addition to these properties, there are some other issues to be considered when building  <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>. However, a challenge might be how to use both the surrogate model and the original function to obtain a satisfactory solution while using a minimum number of original function evaluations. When and which individuals are evaluated in the surrogate model are other key issues to be considered. However, this task is not trivial and the individual-based, generation-based, and population-based strategies have been well studied in the literature. All of these strategies lead to some additional control parameters, which are not easy to set in practice. No matter how the model is defined or how it is managed, it is arguable that it is highly related to the problem to be tackled. SAEA is extremely useful for practical problems <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref> and it has also been extended to multi-objective optimization <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b37">[38]</ref>. As far as we know, most current SAEAs focus on expensive problems and not much work has been done on applying surrogate models to general optimization problems. A major concern might be that compared to fitness evaluation and EA itself, the surrogate modeling process is expensive. In this work, we propose to use a CSM to guide the search process of EAs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED METHOD</head><p>As reviewed in Section II, most multi-operator search techniques actually choose one operator for offspring reproduction by maintaining a probability model. In addition, the surrogate models are mainly used for solving the expensive optimization problems in EAs. Recently, an estimation of distribution algorithm (EDA) based on nonparametric density estimation was proposed <ref type="bibr" target="#b45">[46]</ref>, where the nonparametric density estimation is used to estimate the quality of candidate offspring solutions sampled from the Gaussian distribution and thus to filter out low quality ones. Based on the above considerations and inspired by the work in <ref type="bibr" target="#b45">[46]</ref>, we propose a novel multi-operator search strategy, where firstly a set of candidate offspring solutions are generated by multiple reproduction operators for each solution and then a computationally CSM is built to filter these candidates and leave one as the offspring. Fig. <ref type="figure" target="#fig_0">1</ref> illustrates the basic idea of the proposed multi-operator search strategy, and more details are elucidated in the following sections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Candidate Generation</head><p>Suppose that we have λ different reproduction operators in the operator pool, that is, OP = {op 1 , • • • , op λ }. The population contains µ solutions. In the evolutionary cycle, for each parent x i (i = 1, • • • , µ), λ different candidate points y i,1 , • • • , y i,λ are generated by each of the operators in the pool <ref type="foot" target="#foot_0">1</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Cheap Surrogate Model Building</head><p>After offspring generation, we need to estimate the quality of the candidate solutions. This is usually achieved by surrogate models. However, in surrogate model building, it is time consuming to build an accurate model and it is required that the dimension of the variable vector should not be high. For a general optimization problem, the algorithm time complexity and the scalability of the problem are two major concerns. For this reason, we turn to the CSMs based on density estimation, by which the two concerns can be solved.</p><p>It is reasonable to assume that the objective function f (x) is continuous and not constant in the feasible region S. Let</p><formula xml:id="formula_1">f max = max x∈S f (x) and F (x) = f max -f (x) S (f max -f (x)) dx .</formula><p>It can be proven that</p><formula xml:id="formula_2">0 ≤ F (x) ≤ 1 and S F (x) dx = 1.</formula><p>Therefore, F (x) can be regarded as a probability density function, and</p><formula xml:id="formula_3">arg min x∈S f (x) = arg max x∈S F (x),</formula><p>that is, the minimization of f (x) is equal to finding the point with the highest probability density. In this section, we estimate the quality of a candidate offspring solution x by calculating the density F (x) instead of calculating its function value f (x).</p><p>In this work, the Parzen window method [47, Section 4.3] is employed to estimate the density probability of each candidate point. The Parzen window method (also known as kernel density estimation in pattern classification literature <ref type="bibr" target="#b46">[47,</ref><ref type="bibr">Section 4.3]</ref>) is the most popular density estimation method, which calculates the density probability as follows:</p><formula xml:id="formula_4">F (y) = 1 µ µ i=1 1 w ϕ ||y -x i || 2 w .<label>(2)</label></formula><p>Similar to <ref type="bibr" target="#b45">[46]</ref>, to make the better solutions contribute more to the density, the ranking of each solution is used. Then, the density estimation function in Equation ( <ref type="formula" target="#formula_4">2</ref>) is modified as</p><formula xml:id="formula_5">F (y) = 1 µ µ i=1 R i µ 1 w ϕ ||y -x i || 2 w<label>(3)</label></formula><p>where</p><formula xml:id="formula_6">• ||x|| 2 = n j=1</formula><p>x 2 j denotes the L 2 norm. • R i is the ranking of solution x i in the sorted population (from the best to the worst), and is calculated as <ref type="bibr" target="#b47">[48</ref>]</p><formula xml:id="formula_7">R i = µ -i + 1<label>(4)</label></formula><p>• ϕ(u) is the kernel. Different kernels can be used in Equation ( <ref type="formula" target="#formula_5">3</ref>), in this work, two kernels are used:</p><p>-The Epanechnikov kernel:</p><formula xml:id="formula_8">ϕ(u) = 3 4 (1 -u 2 )1 {|u|≤1}<label>(5)</label></formula><p>-The normal kernel:</p><formula xml:id="formula_9">ϕ(u) = 1 √ 2π exp - u 2 2<label>(6)</label></formula><p>The two kernels are selected because (a) the Epanechnikov kernel is optimal in a minimum variance sense <ref type="bibr" target="#b48">[49]</ref>, and (b) the normal kernel is often used in pattern recognition <ref type="bibr" target="#b46">[47]</ref>; • w is the window width and is calculated as <ref type="bibr" target="#b45">[46]</ref> </p><formula xml:id="formula_10">w = 1 n n j=1 a j -b j 2<label>(7)</label></formula><p>where</p><formula xml:id="formula_11">a j = arg max i=1,••• ,µ x i,j and b j = arg min i=1,••• ,µ x i,j .</formula><p>Note that to make sure |u| ≤ 1 in Equation ( <ref type="formula" target="#formula_8">5</ref>), when a new candidate point y is generated by the reproduction operator, if y j &lt; b j or y j &gt; a j , then b j or a j will be updated immediately. It should be noted that (a) the parameters R i and w in the density estimation model F (x) are directly calculated from the given data without much cost, and (b) the kernel functions are not highly related to the dimension of the variable vector. It is also to be expected that the density estimation might not be as accurate as a general surrogate model. However, our target is not to build accurate surrogate models but to guide the search of an EA with learned information from the population.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Offspring Filtering</head><p>Following the density probability estimation, one offspring y * i will be chosen as the offspring from the candidate points according to their estimated probabilities F (y i,1 ), • • • , F (y i,λ ) by Equation <ref type="bibr" target="#b2">(3)</ref>. Different techniques can be used as the filtering methods. In this work, two techniques are selected for illustration.</p><p>• Greedy selection: The point with the maximal density value is selected as the offspring, that is,</p><formula xml:id="formula_12">y * i = arg max k=1,••• ,λ F (y i,k )<label>(8)</label></formula><p>• Tournament selection: In this technique, two different points are randomly selected from λ candidate points, then the one with the higher density value will be selected as the offspring y * i . Finally, the offspring y * i will be evaluated and compared with its parent x i for the survival selection. Generate the candidate points yi,1, • • • , y i,λ by each operator in OP for the parent xi.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Estimate the density F (y i,k ) of each candidate point y i,k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>Choose the offspring y * i according to the density values of the candidate points. Calculate f (y * i ) for the offspring y * i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>Select the better one between xi and y * i to the next generation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Algorithm Framework</head><p>Combining the above-mentioned issues, the algorithm framework of the proposed CSM-based multi-operator search strategy is described in Algorithm 1. The candidate points are generated by different operators in OP for each parent in Line 5. Then, the density value of each point is estimated in Line 6, followed by the offspring filtering in Line 7. In Line 8, the offspring is evaluated and then compared with its parent solution in Line 9. According to Algorithm 1, since each operator in OP generates a candidate point in Line 5, no operator will be lost in the evolution process. By contrast in the selection probability based multi-operator search methods, if some operators have very small probabilities due to their poor performance in the previous stages, they may be lost when it comes to generate new candidate points in subsequent running stages, even though they would have been more suitable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Remarks</head><p>Note that our proposed CSM-based multi-operator search strategy is inspired by the work in <ref type="bibr" target="#b45">[46]</ref>. However, there are significant differences between them: (a) In <ref type="bibr" target="#b45">[46]</ref>, the nonparametric density estimation technique is used to filter offspring from different candidate points which are only sampled from the Gaussian distribution; whereas in this work different kinds of reproduction operators are used to generate candidate points. (b) To make the better solutions contribute more density, the ranking of each parent is used as shown in Equation (3). In <ref type="bibr" target="#b45">[46]</ref>, the objective function values is used, but this may cause the better solutions to provide significantly greater density values than the worse ones if their objective function values are several orders of magnitude larger. In this way, it may lead to the premature convergence for the multimodal functions. (c) In <ref type="bibr" target="#b45">[46]</ref> only the normal kernel is used in Equation (3), whereas in this work both the normal kernel and Epanechnikov kernel are used and their performance is empirically compared.</p><p>In the proposed CSM-based multi-operator search strategy, an additional computational cost is caused in lines 5, 6, and 7 of Algorithm 1. Suppose that the complexity of the generation operator (such as the operators in DE and PSO) is O(n), then the complexity in line 5 is O(λ • n), where n is the number of decision variables. In line 6, the complexity of density estimation is O(λ • µ • n), when the CSM is used. In line 7, the complexity of offspring filtering is O(λ). Therefore, the overall additional complexity of our method is O(λ</p><formula xml:id="formula_13">• µ • n). In summary, in Algorithm 1, the overall complexity is O(λ•µ 2 •n).</formula><p>It is clear that the framework shown in Algorithm 1 is generic, it can be used to implement the multi-operator ensemble for different EAs. To indicate the performance of our proposed CSM-based multi-operator search strategy, it is implemented as the multi-operator search for three advanced EAs: JADE <ref type="bibr" target="#b7">[8]</ref>, OLPSO <ref type="bibr" target="#b8">[9]</ref>, and CoBiDE <ref type="bibr" target="#b9">[10]</ref>. As an illustration, it is also used to implement the hybrid DE and PSO, in which different DE operators and PSO operators are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS AND ANALYSIS</head><p>In this section, the performance of the proposed CSMbased multi-operator search strategy is evaluated through the benchmark functions. Firstly, the influences of different kernels (see Section III-B) with different selection techniques (see Section III-C) are evaluated. Then, our approach is used to implement multi-operator search for JADE, OLPSO, CoBiDE, and hybrid DE and PSO. Finally,the performance of the CSMbased multi-operator search strategy is compared with other multi-operator search techniques proposed in the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Benchmark Functions</head><p>In this work, thirty benchmark functions, which are widely used in the literature <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref> <ref type="foot" target="#foot_1">2</ref> , are selected as the test suite. The test suite contains 9 unimodal functions (f 01 -f 09 ) and 21 multi-modal functions (f 10 -f 30 ). These functions are briefly described in Table <ref type="table">S</ref>-I in the supplementary file 3 . All functions are minimized with n = 30.</p><p>The maximal number of function evaluations (Max NFEs) for all benchmark problems are set to be 100, 000. To compare the results of different algorithms, each function is optimized over 50 independent runs. We use the same set of initial random populations to evaluate different algorithms, that is, all of the compared algorithms are started from the same initial population in each of the 50 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Contributions of Surrogate Model Components</head><p>This section studies the contributions of the surrogate model components, including the kernel, the selection technique, and the ranking strategy. As an example, we choose the reproduction operators from JADE <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b49">[50]</ref> as the multiple search operators: "DE/current-to-pbest/1" without archive, "DE/current-to-pbest/1" with archive, "DE/rand-to-pbest/1" without archive, and "DE/rand-to-pbest/1" with archive. In these strategies, the archive-based strategies can improve the diversity of the population; while the current-based strategies can perform the local search around the current vector, and hence, they can improve the convergence of the algorithm.  greedy selection. For these four methods, the parameter settings are set to be the same as used in JADE <ref type="bibr" target="#b7">[8]</ref>, that is, µ = 100, p = 0.1, and c = 0.1. Based on the average results obtained by these methods, their average rankings by the Friedman's test <ref type="foot" target="#foot_3">4</ref> are summarized in Table I for all functions. From the results, we can observe that:</p><p>• CSM-JADE4 provides the best ranking in the four variants.</p><p>• For the same kernel, the greedy selection gets better results than the tournament selection. The reason might be that the greedy selection can always pursue the maximal density of the candidate, while due to the randomness in the tournament selection it cannot always select the candidate with the maximal density. • The Epanechnikov kernel is able to obtain better results than the normal kernel under the same selection in CSM-JADE. The reason is that the Epanechnikov kernel can pay more concentration than the normal kernel when |u| ≤ 1 as shown in Fig. <ref type="figure" target="#fig_4">2</ref>. Based on these observations, in the following experiments, the Epanechnikov kernel with the greedy selection will be used in the CSM-based multi-operator search. 2) Influence of Ranking: Compared with Equation (2), the solution ranks are used to make the better solutions contribute more to the density in Equation (3). In this section, the influence of ranking in the CSM is empirically evaluated. CSM-JADE is compared with CSM-JADE-nonranking, in which only Equation ( <ref type="formula" target="#formula_4">2</ref>) is used to estimate the density. In terms of mean values, the results reveal that there are no significant differences in 27 out of 30 functions based on the Wilcoxon test at α = 0.05. Only in three functions f 01 , f 03 , f 24 , CSM-JADE significantly outperforms CSM-JADE-nonranking. However, with the ranking strategy, CSM-JADE converges slightly faster than CSM-JADE-nonranking as shown in Fig. <ref type="figure" target="#fig_5">3</ref>.</p><p>Therefore, we can conclude that in the CSM the kernel ϕ(u) plays the main role in density estimation. Additionally, the ranking strategy can slightly improve the performance of the CSM because of the selection pressure on better solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Study on CSM-based JADE</head><p>To verify the improved performance of CSM-JADE <ref type="foot" target="#foot_4">5</ref> , it is compared with four JADE variants (that is, JADE1: "DE/current-to-pbest/1" without archive; JADE2: "DE/current-to-pbest/1" with archive; JADE3: "DE/rand-topbest/1" without archive; and JADE4: "DE/rand-to-pbest/1" with archive) and JADE-r. In JADE-r, the four JADE mutation strategies are randomly selected for each target parent to generate the offspring. For all of the six algorithms, the parameter settings are kept unchanged as used in JADE <ref type="bibr" target="#b7">[8]</ref>.</p><p>The average and standard deviation values of the objective value of each function are described in Table <ref type="table">S</ref>-II in the supplementary file, where the overall best and the second best values are highlighted in gray boldface and boldface, respectively. Note that similar to the reported results in <ref type="bibr" target="#b7">[8]</ref>, when several algorithms obtain almost the same global optimum for a function, the intermediate results are also reported in Table <ref type="table">S</ref>-II with NFEs = 10, 000, such as for functions f 05 , f 09 , etc. For these functions, the averaged intermediate results are used for the statistical test. In Table S-II, "+", "=", and "-" indicate that CSM-JADE respectively performs significantly better than, almost the same as, and significantly worse than the compared algorithm by the Wilcoxon test at α = 0.05. In addition, the results of the multiple problem analysis <ref type="bibr" target="#b51">[52]</ref> by the Wilcoxon test are also shown in Table <ref type="table" target="#tab_2">II</ref>, where R + and R -mean the sum of ranks that CSM-JADE performs better than and worse than its competitor, respectively. According to the results in Table S-II, it is clearly observed that CSM-JADE significantly outperforms the compared algorithms in the majority of the functions. In 22 out of 30 functions, it is able to provide the best average results among the six algorithms. With respect to the multiple problem analysis, the results in Table II indicate that CSM-JADE performs on the whole significantly better than the other five JADE variants.   As suggested in <ref type="bibr" target="#b52">[53]</ref>, besides the Wilcoxon test, other nonparametric tests are also important to comprehensively understand the performance of the proposed method. In Table III, the average rankings by the Friedman's test for the six algorithms are shown. Obviously, the proposed CSM-JADE gets the best average ranking.</p><p>Meanwhile, the p-values of the Bonferroni-Dunn's, Holm's, and Hochberg's procedures between CSM-JADE and its competitors on the objective values of all functions are also reported in Table <ref type="table" target="#tab_5">IV</ref>. CSM-JADE obtains consistently better results compared with the other five JADE variants by the Holm's and Hochberg's procedures. In addition, it also outperforms JADE1, JADE3, and JADE-r by using the Bonferroni-Dunn's procedure. Additionally, the convergence curves of the six JADE algorithms are plotted in Fig. <ref type="figure">S</ref>-1 in the supplementary file. Note that the convergence curves show the median error performance of the best solution over the total runs. From Fig.</p><p>S-1, we clearly observe that in the majority of the functions CSM-JADE gets the fastest convergence speed among the six algorithms. To further investigate the run-time performance, the average function evaluations and number of successful runs to achieve f &lt; 1.0 × 10 -8 on the functions in Table <ref type="table">S</ref>  <ref type="table" target="#tab_2">III</ref>). From Table V, it can be clearly observed that the CSM-JADE consistently requires less average function evaluations to achieve f &lt; 1.0 × 10 -8 in the successful functions than JADE2. In addition, it can also provide higher successful runs in overall. Therefore, the results confirm that the CSM-based multi-operator search strategy is able to decrease the average function evaluations for a given acceptance criterion.</p><p>In this section, the capability of CSM-based JADE has been verified on benchmark functions at n = 30, it is also fruitful to demonstrate its performance on lower dimensional problems. To this aim, the functions shown in Table S-I at n = 1 and n = 2 are evaluated on JADE and CSM-JADE. At n = 1, functions f 10 , f 19 , and f 20 are not defined. The Max NFEs = 3, 000 and 6, 000 for functions at n = 1 and n = 2, respectively. According to the Wilcoxon test at α = 0.05<ref type="foot" target="#foot_5">6</ref> , CSM-JADE yields the results with w/t/l = 21/6/0 and w/t/l = 28/2/0 compared with JADE at n = 1 and n = 2, respectively. The results indicate that CSM-JADE obtains significant better results than JADE in the majority of functions. Therefore, CSM-JADE still works very well on lower dimensional problems.</p><p>To sum up, we can conclude that our proposed CSM-based multi-operator search strategy improves the performance of single mutation based JADE significantly. The cheap surrogate model is capable of estimating the density of different JADE mutation operators correctly and promoting the cooperation of these operators in the majority of the functions, and hence, it can select the most suitable mutation operator for a specific problem or in different running stages. It is the reason that CSM-JADE provides the best results in 22 test functions compared with other five JADE variants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. CSM with More Operators</head><p>In the above section, we have combined the CSM with JADE. It is to be expected that the CSM can also work with other EAs. This section studies the generality of the CSM by applying it to more operators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) CSM-based OLPSO:</head><p>In this section, CSM is integrated into an advanced PSO variant, that is, OLPSO <ref type="bibr" target="#b8">[9]</ref>. OLPSO is an orthogonal learning based PSO, where two variants are proposed, that is, OLPSO-G and OLPSO-L. In this section, CMS-OLPSO is presented, in which both OLPSO-G and OLPSO-L are used to generate the candidate points for each parent particle. The results of CSM-OLPSO are compared with those of OLPSO-G, OLPSO-L, and OLPSO-r. OLPSO-r is similar to JADE-r, where a randomly selected strategy between OLPSO-G and OLPSO-L is used to generate the offspring. All of the four OLPSO variants use the same parameter settings as presented in <ref type="bibr" target="#b8">[9]</ref>, such as µ = 40, c = 2.0, G = 5, etc.</p><p>The detailed results for all functions are tabulated in Table S-III in the supplementary file. Note that when several algorithms obtain the near global optimum for a function, the intermediate results at NFEs = 20, 000 are also reported. In Table <ref type="table">S</ref>-III, "p-value1", "p-value2", and "p-value3" indicate the p-values calculated by the Wilcoxon test in CSM-OLPSO vs OLPSO-G, CSM-OLPSO vs OLPSO-L, and CSM-OLPSO vs OLPSO-r, respectively. The summarized results of the multiple problem analysis by the Wilcoxon test, the average rankings by the Friedman's test, and the p-values of different statistical procedures are reported in Tables VI, VII, and VIII, respectively. In Table S-III, "w", "t", and "l" mean CSM-OLPSO wins in w functions, ties in t functions, and loses in l functions, compared with its competitors.</p><p>Table <ref type="table">S</ref>-III clearly shows that in the majority of the functions CSM-OLPSO significantly outperforms OLPSO-G, OLPSO-L, and OLPSO-r by the Wilcoxon test at α = 0.05. In 22 out of 30 test functions, CSM-OLPSO gets the best mean fitness values among these four algorithms.   From Table <ref type="table" target="#tab_7">VI</ref>, we can see that CSM-OLPSO provides significantly better results than OLPSO-G, OLPSO-L, and OLPSO-r by the Wilcoxon test at α = 0.05 based on the multiple problem analysis.</p><p>The results in Table <ref type="table" target="#tab_7">VII</ref> indicate that CSM-OLPSO obtains the first ranking, followed by OLPSO-L, OLPSO-G, and OLPSO-r. According to the results in Table VIII, it is clearly observed that CSM-OLPSO gets significantly better results compared with OLPSO-G, OLPSO-L, and OLPSO-r in all of the three statistical procedures.</p><p>Therefore, the above results indicate that the CMS-based multi-operator search strategy is also able to significantly improve the performance of OLPSO. In addition, the performance of OLPSO-r is the worst one among the four OLPSO variants, which means that the inappropriate integration of different operators may cause the algorithm to perform worse than the single operator based methods.</p><p>2) CSM-based CoBiDE: In this section, we evaluate the capability of our proposal for the multi-crossover search in EAs. Based on this consideration, the CoBiDE method proposed in <ref type="bibr" target="#b9">[10]</ref> is used. In CoBiDE, to establish an appropriate coordinate system, covariance matrix learning is presented for the crossover operator. To achieve a good tradeoff between diversity and convergence, the original DE binomial crossover and the crossover based on covariance matrix learning are combined and controlled by a parameter pb in CoBiDE <ref type="bibr" target="#b9">[10]</ref>. Based on our proposed method, the CSM-CoBiDE method is presented, where the two kinds of crossover operators are all used to generate the candidate points, then one of them is selected based on its density. In this way, in CSM-CoBiDE the parameter pb is not needed. In addition, two variants of CoBiDE only with one crossover are also used for comparison purpose, that is, CoBiDE1 with covariance matrix learning, and CoBiDE2 with DE binomial crossover. To make a fair comparison, the parameter settings of the four algorithms are set as used in the original CoBiDE method, that is, µ = 60, ps = 0.5, pb = 0.4 <ref type="bibr" target="#b9">[10]</ref>. The summarized results are presented in Table <ref type="table" target="#tab_10">IX</ref>, X, and XI.   The results in Table <ref type="table" target="#tab_10">IX</ref> reveal that CSM-CoBiDE can provide significantly better results than CoBiDE, CoBiDE1, and CoBiDE2 in the majority of the functions. Moreover, according to the multiple problem analysis by the Wilcoxon test, it is clear that CSM-CoBiDE is significantly better than the three competitors. For the average rankings reported in Table <ref type="table">X</ref>, the results exhibit that CSM-CoBiDE gets the first ranking, followed by CoBiDE2, CoBiDE, and CoBiDE1. According to the p-values for the Bonferroni-Dunn's, Holm's, and Hochberg's procedures in Table <ref type="table" target="#tab_12">XI</ref>, CSM-CoBiDE obtains significantly better results than CoBiDE, CoBiDE1, and CoBiDE2.</p><p>Based on the above observations, we can conclude that the CSM-based multi-operator search strategy is also capable of selecting a more suitable crossover operator for the multicrossover search techniques when solving different problems.</p><p>3) CSM-based Hybrid DE and PSO: This section addresses the ensemble of different types of reproduction operators. For this purpose, we develop a hybrid DE and PSO method (CSM-DE-PSO), where two DE operators ("DE/rand/1/bin" and "DE/rand/2/bin") and one PSO operator (OLPSO-L) are used to generate different candidates. According to the classification on hybrid DE and PSO <ref type="bibr" target="#b53">[54]</ref>, CSM-DE-PSO is the collaboration-based DE-PSO, where DE operators act on the personal best positions, but PSO operators act on the current positions. CSM-DE-PSO is compared with two DEs (that is, DE/rand/1/bin and DE/rand/2/bin), OLPSO-L, and DE-PSO-r. In DE-PSO-r, one of the three operators is randomly chosen to generate the offspring for each parent. For the five algorithms, the population size µ = 40. A self-adaptive parameter setting proposed in <ref type="bibr" target="#b54">[55]</ref> for CR and F is used in the DE variants. For the PSO variants, the parameters are set to be the same as presented in OLPSO <ref type="bibr" target="#b8">[9]</ref>. The results are summarized in Tables XII, XIII, and XIV.   From the results in Table <ref type="table" target="#tab_15">XIV</ref>, we can observe that CSM-DE-PSO consistently performs significantly better than OLPSO-L and DE-PSO-r in the Bonferroni-Dunn's, Holm's, and Hochberg's procedures. It is also better than DE/rand/2/bin in the Holm's and Hochberg's procedures. There are no significant differences between CSM-DE-PSO and DE/rand/1/bin based on the p-values of the Bonferroni-Dunn's, Holm's, and Hochberg's procedures.</p><p>In general, when different types of reproduction operators are combined, the CSM-based multi-operator search strategy is still able to obtain very promising results. It can promote the collaboration of different operators, and hence, CSM-DE-PSO can get the best overall performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Comparison with Other Multi-operator Search Techniques</head><p>In the previous sections, it has been shown that the proposed search strategy is beneficial to improve the performance of the single operator based algorithms, and can obtain better results than the algorithms with a randomly selected operator. In this section, the performance of CSM-JADE is compared with other multi-operator selection techniques: PM-JADE <ref type="bibr" target="#b5">[6]</ref> and AP-JADE <ref type="bibr" target="#b5">[6]</ref>. PM-JADE is a multi-operator based JADE with probability matching technique, while AP-JADE uses the adaptive pursuit technique to assign the selection probabilities for different operators. In addition, since CoDE <ref type="bibr" target="#b15">[16]</ref> is a prominent and simple DE variant with multiple mutation operators, our approach is also integrated into CoDE (the resulting algorithm is referred to as CSM-CoDE) to evaluate the enhanced performance when comparing with CoDE.</p><p>1) Results on JADE variants: For CSM-JADE and JADE-r, the parameter settings are the same as presented in <ref type="bibr" target="#b7">[8]</ref>. For PM-JADE and AP-JADE, the parameters presented in <ref type="bibr" target="#b5">[6]</ref> are used. Note that for these four JADE variants, the population size µ = 100. The results are reported in Tables XV, XVI, and XVII.   2) Results on CoDE variants: For CoDE and CSM-CoDE, the parameter settings are kept unchanged as used in the original CoDE literature <ref type="bibr" target="#b15">[16]</ref>. There are three mutation operators in CoDE, that is, "DE/rand/1/bin", "DE/rand/2/bin", and "DE/current-to-rand/1". In CSM-CoDE, each of them will generate a candidate point for each parent, and then one of the three points is sampled by the CSM technique as the offspring. In summary, our proposed CSM-based multi-operator search strategy is able to obtain better performance than the compared multi-operator search techniques. Thus, we can expect that it may be an effective alternative to implement the ensemble of different operators for other EAs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Performance on CEC 2013 Test Suite</head><p>Above, the experiments are conducted on the functions presented in Table S-I. To better understand the performance of our proposal, the problems presented in CEC 2013 <ref type="bibr" target="#b14">[15]</ref> are chosen as the test suite. In this test suite, there are 28 functions, where c 01 -c 05 are unimodal functions, c 06 -c 20 are basic multimodal functions, and c 21 -c 28 are composition functions. In this section, all functions are tested at n = 30, and the Max NFEs = 300, 000. Since many highly-rotated functions are contained in the test suite, we evaluate the performance of CSM-CoDE and CSM-CoBiDE. The reason for choosing the two methods is that there are rotation-invariant operations in CoDE and CoBiDE, such as "DE/current-to-rand/1" mutation in CoDE <ref type="bibr" target="#b15">[16]</ref> and covariance matrix learning in CoBiDE <ref type="bibr" target="#b9">[10]</ref>. In addition, the proposed search strategy is still implemented into SHADE <ref type="bibr" target="#b55">[56]</ref>, which obtained very promising results in the CEC 2013 test suite <ref type="bibr" target="#b56">[57]</ref>. In SAHDE <ref type="bibr" target="#b55">[56]</ref>, the "DE/currentto-pbest/1" with archive is used to generate the mutant. In CSM-SHADE, another mutation strategy, that is, "DE/randto-pbest/1" with archive, is also used. The results are reported in Table <ref type="table">S</ref>  In terms of the average rankings by the Friedman test, besides the above six algorithms, another recently presented DE variant with individual-dependent mechanism (IDE <ref type="bibr" target="#b57">[58]</ref>) is also included for comparison in the CEC 2013 test suite. The results are reported in Table <ref type="table" target="#tab_21">XVIII</ref>. Table XVIII reveals that each CSM-based method obtains better average ranking than its corresponding non-CSM-based method. Additionally, it is clear that CSM-SHADE gets the first ranking, followed by IDE and SHADE. Therefore, the results confirm that the proposed CSM-based multi-operator search strategy is beneficial to the performance enhancement of EAs.</p><p>According to the results, we also see that the shifted problems do not increase in difficulty in our proposal; however, the highly-rotated conditions may lead to difficulty when solving these problems. In addition, although the CSM-based multi-operator search strategy is still able to improve the performance of CoDE and CoBiDE in the CEC 2013 test suite, the improvements of CSM-CoDE and CSM-CoBiDE are not so significant when comparing the improvements in the functions presented in Table S-I. The reasons might be two-fold: (a) In this work, we only employ the simple and cheap surrogate model, which may not estimate the density exactly, especially for complex problems with a highly-rotated landscape. (b) In CoDE and CoBiDE, the rotation-invariant operators may not track the rotated landscape properly (such as the selected top solutions for covariance matrix learning in CoBiDE), in this way, the CSM-based multi-operator search strategy cannot pursue the right search direction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. On the Algorithm Complexity</head><p>In this section, as an example, the algorithm complexity of CoBiDE and CSM-CoBiDE is calculated for function c 14 in the CEC 2014 test suite <ref type="bibr" target="#b14">[15]</ref> according to the detailed instructions in <ref type="bibr" target="#b14">[15]</ref>. Table <ref type="table" target="#tab_22">XIX</ref> gives the computed algorithm complexity on n = 10, 30, and 50. In Table XIX, T 0 is calculated by running the test program below:</p><p>for i = 1:1000000 x = 0.55+(double)i; x = x+x; x = x./2; x = x * x; x = sqrt(x); x = log(x); x = exp(x); y = x/x; end T 1 is the computation time to evaluate 200, 000 evaluations just for c 14 of a certain dimension n, and T 2 is the computation time for an algorithm with 200, 000 evaluations of the same n dimension for function c 14 . T 2 is the mean T 2 values of 5 independent runs.</p><p>According to the results shown in Table <ref type="table" target="#tab_22">XIX</ref>, for both CoBiDE and CSM-CoBiDE, T 1 and T 2 scale linearly with the number of dimensions, since ( T 2-T 1)/T 0 grows linearly. In addition, the additional computation time of CSM-CoBiDE also increases linearly when compared with CoBiDE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS AND FUTURE WORK</head><p>In the family of evolutionary computation, different reproduction operators have been proposed during the last few decades. Generally, different operators are suitable for different problems or in different running stages. In order to solve a wide range of problems, in this paper, we proposed a novel multi-operator search technique based on the CSMs. In contrast to previous multi-operator search techniques, in our approach, each operator generates its own candidate point. In this way, no operator will be lost when it comes to generating new candidate points in subsequent running stages. Another advantage of our approach is that it is generic, it can implement an ensemble of different operators for different EAs.</p><p>To evaluate the performance of our approach, comprehensive experiments (including validation of different kernels and selection techniques, CSM-based JADE, CSM-based OLPSO, CSM-based CoBiDE, CSM-based DE-PSO, and comparison with other multi-operator search techniques) were conducted through benchmark functions. The results indicate that in the majority of the functions, CSM-based algorithms obtain significantly better results than their corresponding single operator based algorithms. The reason might be that in many cases our approach will estimate the density accurately, and hence it can promote the collaboration among different operators.</p><p>By carefully looking at the results shown in Table <ref type="table">S</ref>-II, CSM-JADE provides the worst results in functions f 10 and f 21 among the six algorithms. It might be that the CSM used in this work is not able to estimate the density of these functions accurately. In our future work, we will try to use other CSMs, such as the approximated multivariate kernel density estimation <ref type="bibr" target="#b58">[59]</ref>, to develop more sophisticated CSM-based multi-operator search strategy. Applying CSM to multiobjective optimization <ref type="bibr" target="#b59">[60]</ref> is another work worth future investigation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An illustration of the proposed multi-operator search strategy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 4 :</head><label>14</label><figDesc>Framework of CSM-based multi-operator search 1: Initialize the population with µ solutions x1, • • • , xµ. 2: Evaluate the fitness for each solution. 3: while termination criterion is not satisfied do for i = 1 to µ do 5:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Comparison of the Epanechnikov kernel and the normal kernel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Convergence curves of CSM-JADE and CSM-JADE-nonranking for the selected functions. (a): f 01 ; (b): f 23 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I AVERAGE</head><label>I</label><figDesc>RANKINGS OF CSM-JADE VARIANTS (FRIEDMAN)</figDesc><table><row><cell></cell><cell></cell><cell>Algorithm</cell><cell></cell><cell>Ranking</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>CSM-JADE1</cell><cell></cell><cell>3.2000</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>CSM-JADE2</cell><cell></cell><cell>3.0667</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>CSM-JADE3</cell><cell></cell><cell>1.9500</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>CSM-JADE4</cell><cell></cell><cell>1.7833</cell><cell></cell><cell></cell></row><row><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Normal kernel</cell><cell></cell></row><row><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Epanechnikov kernel</cell><cell></cell></row><row><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-1.5 0</cell><cell>-1</cell><cell>-0.5</cell><cell>0</cell><cell>0.5</cell><cell>1</cell><cell>1.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II MULTIPLE</head><label>II</label><figDesc>PROBLEM ANALYSIS BY THE WILCOXON TEST BETWEEN CSM-JADE AND ITS COMPETITORS.</figDesc><table><row><cell></cell><cell>R +</cell><cell>R -</cell><cell>p-value</cell></row><row><cell>JADE1</cell><cell>358.0</cell><cell>77.0</cell><cell>0.0017</cell></row><row><cell>JADE2</cell><cell>354.0</cell><cell>81.0</cell><cell>0.0023</cell></row><row><cell>JADE3</cell><cell>359.0</cell><cell>76.0</cell><cell>0.0015</cell></row><row><cell>JADE4</cell><cell>390.5</cell><cell>74.5</cell><cell>0.0026</cell></row><row><cell>JADE-r</cell><cell>366.0</cell><cell>69.0</cell><cell>8.09E-4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V THE</head><label>V</label><figDesc>AVERAGE FUNCTION EVALUATIONS AND NUMBER OF SUCCESSFUL RUNS TO ACHIEVE f &lt; 1.0 × 10 -8 ON THE FUNCTIONS FOR JADE2, CMS-JADE: THE FIRST VALUE IS THE AVERAGE FUNCTION VALUES IN TERMS OF 10 5 , AND THE BRACKETED VALUE IS THE NUMBER OF</figDesc><table><row><cell></cell><cell cols="2">SUCCESSFUL RUNS.</cell></row><row><cell>Prob</cell><cell>JADE2</cell><cell>CSM-JADE</cell></row><row><cell>f01</cell><cell>0.27 (50)</cell><cell>0.22 (50)</cell></row><row><cell>f02</cell><cell>0.45 (50)</cell><cell>0.35 (50)</cell></row><row><cell>f03</cell><cell>0.98 (5)</cell><cell>0.69 (50)</cell></row><row><cell>f05</cell><cell>0.10 (50)</cell><cell>0.08 (50)</cell></row><row><cell>f07</cell><cell>0.09 (50)</cell><cell>0.08 (50)</cell></row><row><cell>f08</cell><cell>0.89 (18)</cell><cell>0.64 (48)</cell></row><row><cell>f09</cell><cell>0.18 (50)</cell><cell>0.14 (50)</cell></row><row><cell>f11</cell><cell>NA (0)</cell><cell>0.99 (2)</cell></row><row><cell>f13</cell><cell>0.41 (50)</cell><cell>0.33 (50)</cell></row><row><cell>f14</cell><cell>0.28 (50)</cell><cell>0.23 (50)</cell></row><row><cell>f15</cell><cell>0.24 (50)</cell><cell>0.19 (50)</cell></row><row><cell>f16</cell><cell>0.29 (50)</cell><cell>0.23 (50)</cell></row><row><cell>f18</cell><cell>NA (0)</cell><cell>0.79 (4)</cell></row><row><cell>f25</cell><cell>0.22 (50)</cell><cell>0.18 (50)</cell></row><row><cell>f26</cell><cell>0.66 (49)</cell><cell>0.46 (50)</cell></row><row><cell>f30</cell><cell>0.60 (50)</cell><cell>0.40 (50)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>-I are reported in Table V. When no algorithm can get a successful run in the function, the results are not presented in Table V. The CSM-based JADE is compared with JADE2 (the second best JADE variant shown in Table</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VI MULTIPLE</head><label>VI</label><figDesc>PROBLEM ANALYSIS BY THE WILCOXON TEST BETWEEN CSM-OLPSO AND ITS COMPETITORS.</figDesc><table><row><cell></cell><cell>R +</cell><cell>R -</cell><cell>p-value</cell></row><row><cell>OLPSO-G</cell><cell>371.0</cell><cell>67.0</cell><cell>0.0025</cell></row><row><cell>OLPSO-L</cell><cell>343.0</cell><cell>95.0</cell><cell>0.0229</cell></row><row><cell>OLPSO-r</cell><cell>435.0</cell><cell>3.0</cell><cell>7.45E-08</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE VIII p</head><label>VIII</label><figDesc>-VALUES OBTAINED FOR BONFERRONI-DUNN'S, HOLM'S, AND HOCHBERG'S PROCEDURES BETWEEN CSM-OLPSO AND ITS COMPETITORS.</figDesc><table><row><cell></cell><cell>z</cell><cell>Unadjusted</cell><cell>Bonferroni-Dunn</cell><cell>Holm</cell><cell>Hochberg</cell></row><row><cell>OLPSO-G</cell><cell>3.2500</cell><cell>1.15E-03</cell><cell>3.46E-03</cell><cell>2.31E-03</cell><cell>2.31E-03</cell></row><row><cell>OLPSO-L</cell><cell>2.3000</cell><cell>2.14E-02</cell><cell>6.43E-02</cell><cell>2.14E-02</cell><cell>2.14E-02</cell></row><row><cell>OLPSO-r</cell><cell>4.8500</cell><cell>1.00E-06</cell><cell>4.00E-06</cell><cell>4.00E-06</cell><cell>4.00E-06</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE IX SINGLE</head><label>IX</label><figDesc>AND MULTIPLE PROBLEM ANALYSIS BY THE WILCOXON TEST BETWEEN CSM-COBIDE AND ITS COMPETITORS.</figDesc><table><row><cell></cell><cell cols="3">Single problem analysis</cell><cell cols="3">Multiple problem analysis</cell></row><row><cell></cell><cell>w</cell><cell>t</cell><cell>l</cell><cell>R +</cell><cell>R -</cell><cell>p-value</cell></row><row><cell>CoBiDE</cell><cell>26</cell><cell>1</cell><cell>3</cell><cell>386.5</cell><cell>78.5</cell><cell>3.59E-03</cell></row><row><cell>CoBiDE1</cell><cell>27</cell><cell>2</cell><cell>1</cell><cell>434.5</cell><cell>30.5</cell><cell>1.64E-05</cell></row><row><cell>CoBiDE2</cell><cell>26</cell><cell>2</cell><cell>2</cell><cell>412.5</cell><cell>52.5</cell><cell>2.90E-04</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE XI p</head><label>XI</label><figDesc>-VALUES OBTAINED FOR BONFERRONI-DUNN'S, HOLM'S, AND HOCHBERG'S PROCEDURES BETWEEN CSM-COBIDE AND ITSCOMPETITORS.</figDesc><table><row><cell></cell><cell>z</cell><cell>Unadjusted</cell><cell>Bonferroni-Dunn</cell><cell>Holm</cell><cell>Hochberg</cell></row><row><cell>CoBiDE</cell><cell>4.5500</cell><cell>5.00E-06</cell><cell>1.60E-06</cell><cell>1.10E-06</cell><cell>1.10E-06</cell></row><row><cell>CoBiDE1</cell><cell>5.1500</cell><cell>0.00E+00</cell><cell>1.00E-06</cell><cell>1.00E-06</cell><cell>1.00E-06</cell></row><row><cell>CoBiDE2</cell><cell>4.1000</cell><cell>4.10E-05</cell><cell>1.24E-04</cell><cell>4.10E-05</cell><cell>4.10E-05</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE XII SINGLE</head><label>XII</label><figDesc>AND MULTIPLE PROBLEM ANALYSIS BY THE WILCOXON TEST BETWEEN CSM-DE-PSO AND ITS COMPETITORS.</figDesc><table><row><cell></cell><cell cols="3">Single problem analysis</cell><cell cols="3">Multiple problem analysis</cell></row><row><cell></cell><cell>w</cell><cell>t</cell><cell>l</cell><cell>R +</cell><cell>R -</cell><cell>p-value</cell></row><row><cell>DE/rand/1/bin</cell><cell>19</cell><cell>3</cell><cell>8</cell><cell>288.5</cell><cell>207.5</cell><cell>≥0.2</cell></row><row><cell>DE/rand/2/bin</cell><cell>21</cell><cell>3</cell><cell>6</cell><cell>329.5</cell><cell>166.5</cell><cell>≥0.2</cell></row><row><cell>OLPSO-L</cell><cell>27</cell><cell>1</cell><cell>2</cell><cell>439.0</cell><cell>26.0</cell><cell>1.99E-06</cell></row><row><cell>DE-PSO-r</cell><cell>25</cell><cell>2</cell><cell>3</cell><cell>409.5</cell><cell>86.5</cell><cell>0.0037</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>TABLE XIII AVERAGE</head><label>XIII</label><figDesc>RANKINGS OF CSM-DE-PSO, DE/RAND/1/BIN, DE/RAND/2/BIN, OLPSO-L, AND DE-PSO-R (FRIEDMAN).</figDesc><table><row><cell>Algorithm</cell><cell>Ranking</cell></row><row><cell>DE/rand/1/bin</cell><cell>2.2419</cell></row><row><cell>DE/rand/2/bin</cell><cell>3.0645</cell></row><row><cell>OLPSO-L</cell><cell>4.0806</cell></row><row><cell>DE-PSO-r</cell><cell>3.4677</cell></row><row><cell>CSM-DE-PSO</cell><cell>2.1452</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>TABLE XIV p</head><label>XIV</label><figDesc>-VALUES OBTAINED FOR BONFERRONI-DUNN'S, HOLM'S, AND HOCHBERG'S PROCEDURES BETWEEN CSM-DE-PSO AND ITS COMPETITORS.In TableXII, CSM-DE-PSO can significantly outperform the four algorithms in the majority of the functions in terms of the single problem analysis by the Wilcoxon test at α = 0.05. With respect to the multiple analysis by the Wilcoxon test, Table XII also indicates that CSM-DE-PSO gets better results. Especially, it performs significantly better than OLPSO-L and DE-PSO-r by the Wilcoxon test at α = 0.05.Considering the average rankings by the Friedman's test, TableXIIIshows that CSM-DE-PSO obtains the first ranking, followed by DE/rand/1/bin, DE/rand/2/bin, DE-PSO-r, and OLPSO-L.</figDesc><table><row><cell></cell><cell>z</cell><cell>Unadjusted</cell><cell>Bonferroni-Dunn</cell><cell>Holm</cell><cell>Hochberg</cell></row><row><cell>DE/rand/1/bin</cell><cell>0.2410</cell><cell>8.10E-01</cell><cell>3.24E+00</cell><cell>8.10E-01</cell><cell>8.10E-01</cell></row><row><cell>DE/rand/2/bin</cell><cell>2.2892</cell><cell>2.21E-02</cell><cell>8.83E-02</cell><cell>4.41E-02</cell><cell>4.41E-02</cell></row><row><cell>OLPSO-L</cell><cell>4.8193</cell><cell>1.00E-06</cell><cell>6.00E-06</cell><cell>6.00E-06</cell><cell>6.00E-06</cell></row><row><cell>DE-PSO-r</cell><cell>3.2932</cell><cell>9.91E-04</cell><cell>3.96E-03</cell><cell>2.97E-03</cell><cell>2.97E-03</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>TABLE XV SINGLE</head><label>XV</label><figDesc>AND MULTIPLE PROBLEM ANALYSIS BY THE WILCOXON TEST BETWEEN CSM-JADE AND ITS COMPETITORS.</figDesc><table><row><cell></cell><cell cols="3">Single problem analysis</cell><cell cols="3">Multiple problem analysis</cell></row><row><cell></cell><cell>w</cell><cell>t</cell><cell>l</cell><cell>R +</cell><cell>R -</cell><cell>p-value</cell></row><row><cell>JADE-r</cell><cell>26</cell><cell>2</cell><cell>2</cell><cell>391.5</cell><cell>73.5</cell><cell>0.0023</cell></row><row><cell>PM-JADE</cell><cell>25</cell><cell>1</cell><cell>4</cell><cell>366.5</cell><cell>98.5</cell><cell>0.0162</cell></row><row><cell>AP-JADE</cell><cell>20</cell><cell>4</cell><cell>6</cell><cell>308.0</cell><cell>130.0</cell><cell>0.1624</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head></head><label></label><figDesc>PM-JADE, and AP-JADE in 26, 25, and 20 functions, respectively. In addition, in terms of the multiple problem analysis by the Wilcoxon test, the results indicate that CSM-JADE is significantly better than JADE-r and PM-JADE. Although CSM-JADE and AP-JADE are not significantly different, CSM-JADE is better than AP-JADE with respect to the sum of ranks.The average rankings in terms of the fitness values shown in TableXVIshow that CSM-JADE is the most effective algorithm among these four JADE variants.According to the p-values for the Bonferroni-Dunn's, Holm's, and Hochberg's procedures in Table XVII, CSM-JADE obtains significantly better results than JADE-r and PM-JADE. It is also better than AP-JADE.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">TABLE XVII</cell><cell></cell><cell></cell></row><row><cell cols="6">p-VALUES OBTAINED FOR BONFERRONI-DUNN'S, HOLM'S, AND</cell></row><row><cell cols="6">HOCHBERG'S PROCEDURES BETWEEN CSM-JADE AND ITS</cell></row><row><cell></cell><cell></cell><cell cols="2">COMPETITORS.</cell><cell></cell><cell></cell></row><row><cell></cell><cell>z</cell><cell>Unadjusted</cell><cell>Bonferroni-Dunn</cell><cell>Holm</cell><cell>Hochberg</cell></row><row><cell>JADE-r</cell><cell>4.9000</cell><cell>1.00E-06</cell><cell>3.00E-06</cell><cell>3.00E-06</cell><cell>3.00E-06</cell></row><row><cell>PM-JADE</cell><cell>2.4500</cell><cell>1.43E-02</cell><cell>4.29E-02</cell><cell>2.86E-02</cell><cell>2.86E-02</cell></row><row><cell>AP-JADE</cell><cell>1.8500</cell><cell>6.43E-02</cell><cell>1.93E-01</cell><cell>6.43E-02</cell><cell>6.43E-02</cell></row><row><cell cols="6">Table XV shows that CSM-JADE significantly outperforms</cell></row><row><cell>JADE-r,</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head></head><label></label><figDesc>The results of CoDE and CSM-CoDE are provided in Table S-IV in the supplementary file, where the better results are highlighted in boldface. The p-values by the Wilcoxon test are also reported in the table. When both CoDE and CSM-CoDE obtain the near global optimum for a function, the intermediate results at NFEs = 20, 000 are also reported. From Table S-IV, it is clearly observed that in 26 out of 30 functions CSM-CoDE significantly outperforms CoDE based on the Wilcoxon test at α = 0.05. In addition, according to the multiple problem analysis by the Wilcoxon test, R + = 373.0, R -= 92.0, and p = 0.0030 when comparing CSM-CoDE with CoDE, which mean that CSM-CoDE performs on the whole significantly better than CoDE.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head></head><label></label><figDesc>-V in the supplementary file. Comparing the results between CoDE and CSM-CoDE, CSM-CoDE significantly outperforms CoDE in 11 functions. In 15 functions there are no significant differences between them. In 2 functions c 06 and c 07 , CoDE gets significantly better results than CSM-CoDE. According to the multiple problem analysis by the Wilcoxon test, R + = 218.5, R -= 187.5, and p &gt; 0.2 between CSM-CoDE and CoDE, which suggests that CSM-CoDE is on the whole slightly better than CoDE. With respect to the results between CoBiDE and CSM-CoBiDE, Table S-V shows that CSM-CoBiDE provides significantly better results than CoBiDE in 15 functions, ties in 10 functions, and loses in 3 functions (c 06 , c 23 , and c 24 ). The results of the multiple problem analysis by the Wilcoxon test are R + = 251.0, R -= 155.0, and p &gt; 0.2 between CSM-CoBiDE and CoBiDE, which mean that CSM-CoBiDE can still obtain slightly better results than CoBiDE on the whole. Table S-V also shows that CSM-SHADE wins in 11 functions, ties in 15 functions, and loses in 2 functions compared with SHADE in terms of the Wilcoxon test at α = 0.05. The results of the multiple problem analysis by the Wilcoxon test are R + = 293.5, R -= 112.5, and p = 0.09574 between CSM-SHADE and SHADE, which reveal that CSM-SHADE can obtain on the whole significantly better results than SHADE at α = 0.1. Fig. S-2 and Fig. S-3 in the supplementary file also indicate that in the majority of functions CSM-SHADE converges faster than SHADE.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>TABLE XVIII AVERAGE</head><label>XVIII</label><figDesc>RANKINGS OF IDE, CODE, CSM-CODE, COBIDE, CSM-COBIDE, SHADE, AND CSM-SHADE (FRIEDMAN).</figDesc><table><row><cell>Algorithm</cell><cell>Ranking</cell></row><row><cell>IDE [58]</cell><cell>3.3571</cell></row><row><cell>CoDE</cell><cell>4.6964</cell></row><row><cell>CSM-CoDE</cell><cell>4.5536</cell></row><row><cell>CoBiDE</cell><cell>4.3929</cell></row><row><cell>CSM-CoBiDE</cell><cell>4.2321</cell></row><row><cell>SHADE [57]</cell><cell>3.6786</cell></row><row><cell>CSM-SHADE</cell><cell>3.0893</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>TABLE XIX ALGORITHM</head><label>XIX</label><figDesc>COMPLEXITY OF COBIDE AND CSM-COBIDE.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">CoBiDE</cell><cell></cell></row><row><cell></cell><cell>T 0</cell><cell>T 1</cell><cell>T 2</cell><cell>( T 2 -T 1)/T 0</cell></row><row><cell>n = 10</cell><cell></cell><cell>0.8110</cell><cell>1.0234</cell><cell>2.2839</cell></row><row><cell>n = 30</cell><cell>0.0930</cell><cell>2.4020</cell><cell>3.3726</cell><cell>10.4366</cell></row><row><cell>n = 50</cell><cell></cell><cell>3.9620</cell><cell>6.8266</cell><cell>30.8022</cell></row><row><cell></cell><cell></cell><cell cols="2">CSM-CoBiDE</cell><cell></cell></row><row><cell></cell><cell>T 0</cell><cell>T 1</cell><cell>T 2</cell><cell>( T 2 -T 1)/T 0</cell></row><row><cell>n = 10</cell><cell></cell><cell>0.8110</cell><cell>3.1324</cell><cell>24.9613</cell></row><row><cell>n = 30</cell><cell>0.0930</cell><cell>2.4020</cell><cell>9.1766</cell><cell>72.8452</cell></row><row><cell>n = 50</cell><cell></cell><cell>3.9620</cell><cell>17.3784</cell><cell>144.2624</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In this work, we suppose that each reproduction operator only generates one candidate point. However, the operators that generate more than one candidate points can also be used in our proposed CSM-based multi-operator search strategy.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Note that in the</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="30" xml:id="foot_2"><p>functions, most of them are also used in other literature, such as 12 functions used in<ref type="bibr" target="#b6">[7]</ref>, 21 functions used in<ref type="bibr" target="#b13">[14]</ref>.<ref type="bibr" target="#b2">3</ref> Due to the tight space limitation, some tables are provided in the supplementary file, which will be available online.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>The statistical tests used in this work are calculated by the KEEL software<ref type="bibr" target="#b50">[51]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>In the following sections, CSM-JADE4 is used. For brevity, it is denoted as CMS-JADE.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>For the sake of brevity, we do not report the detail results in the paper. Interested readers can contact the authors for more details.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors would like to thank Dr. Y. Wang for providing the source code of CoBiDE. The source code of SHADE is obtained from Prof. P. N. Suganthan's webpage. The first author would also like to thank Mr. J. Xu for the implementation of CSM-CoBiDE.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was partly supported by China National Instrumentation Program (2012YQ180132), the National Natural Science Foundation of China under Grant No. 61273313, 61203307, 61075063 and 61175063, the Fundamental Research Funds for the Central Universities at China University of Geosciences (Wuhan) under Grant No. CUG130413, and the Science and Technology Commission of Shanghai Municipality under research Grant No. Zhihua Cai received the Bsc degree from Wuhan University, China, in 1986, the Msc degree from Beijing University of Technology, China, in 1992, and the PhD degree from China University of Geosciences, in 2003.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Differential evolution-A simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. of Global Optim</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997-12">Dec 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE International Conference on Neural Networks IV</title>
		<meeting>of IEEE International Conference on Neural Networks IV</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Meta-Lamarckian learning in memetic algorithms</title>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="110" />
			<date type="published" when="2004-04">Apr 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Differential evolution algorithm with strategy adaptation for global numerical optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="398" to="417" />
			<date type="published" when="2009-04">Apr 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive strategy selection in differential evolution for numerical optimization: An empirical study</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fialho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="5364" to="5386" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A self-learning particle swarm optimizer for global optimization problems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics Part B: Cybernetics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="627" to="646" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">JADE: Adaptive differential evolution with optional external archive</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="945" to="958" />
			<date type="published" when="2009-10">Oct 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Orthogonal learning particle swarm optimization</title>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="832" to="847" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Differential evolution based on covariance matrix learning and bimodal distribution parameter setting</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="232" to="247" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Evolutionary programming made faster</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="82" to="102" />
			<date type="published" when="1999-07">Jul 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An orthogonal genetic algorithm with quantization for global numerical optimization</title>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="53" />
			<date type="published" when="2001-02">Feb 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A numerical evaluation of several stochastic algorithms on selected continuous global optimization test problems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Khompatraporn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Zabinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. of Global Optim</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="635" to="672" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Opposition-based differential evolution</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rahnamayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tizhoosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Salama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="79" />
			<date type="published" when="2008-02">Feb 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Problem definitions and evaluation criteria for the CEC 2013 special session and competition on real-parameter optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hernández-Díaz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<pubPlace>Singapore</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computational Intelligence Laboratory, Zhengzhou University, Zhengzhou China &amp; Nanyang Technological University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Differential evolution with composite trial vector generation strategies and control parameters</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="66" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Parameter control in evolutionary algorithms</title>
		<author>
			<persName><forename type="first">Á</forename><forename type="middle">E</forename><surname>Eiben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hinterding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="124" to="141" />
			<date type="published" when="1999-07">Jul 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Adaptation and self-organization in evolutionary algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Whitacre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ph.D. dissertation, School of Chemical Sciences and Engineering</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>The University of New South Wales</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On adaptive operator probabilities in real coded genetic algorithms</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J C</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Sá</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Advances and Trends in Artificial Intelligence for Problem Solving (SCCC &apos;00)</title>
		<meeting><address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Simultaneously applying multiple mutation operators in genetic algorithms</title>
		<author>
			<persName><forename type="first">T.-P</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Heuristics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="439" to="455" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An adaptive pursuit strategy for allocating operator probabilities</title>
		<author>
			<persName><forename type="first">D</forename><surname>Thierens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Genetic Evol. Comput. Conf</title>
		<imprint>
			<biblScope unit="page" from="1539" to="1546" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Evolutionary programming using a mixed mutation strategy</title>
		<author>
			<persName><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="312" to="327" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Self-adaptive learning based particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="4515" to="4538" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improved evolutionary optimization from genetically adaptive multimethod search</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Vrugt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the National Academy of Sciences</title>
		<meeting>of the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="708" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Self-adaptive multimethod search for global optimization in real-parameter spaces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vrugt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hyman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="243" to="259" />
			<date type="published" when="2009-04">Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Population-based algorithm portfolios for numerical optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="782" to="800" />
			<date type="published" when="2010-10">Oct. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An adaptive hybrid genetic algorithm for the three-matching problem</title>
		<author>
			<persName><forename type="first">G</forename><surname>Magyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johnsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Nevalainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2000-07">Jul. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An intelligent augmentation of particle swarm optimization with multiple adaptive methods</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Weir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">213</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="68" to="83" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An adaptive particle swarm optimization with multiple adaptive methods</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="705" to="720" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Classification of adaptive memetic algorithms: A comparative study</title>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-W</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="141" to="152" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A multi-facet survey on memetic computation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="591" to="607" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Enhanced differential evolution with adaptive strategies for numerical optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">X</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part: Cybernetics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="397" to="413" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Differential evolution algorithm with ensemble of parameters and mutation strategies</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mallipeddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tasgetiren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1679" to="1696" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multi-operator based evolutionary algorithms for solving constrained optimization problems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Sarker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Essam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Operations Research</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1877" to="1896" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A differential evolution algorithm with dual populations for solving periodic railway timetable scheduling problem</title>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="512" to="527" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A comprehensive survey of fitness approximation in evolutionary computation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="212" to="221" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Surrogate-assisted evolutionary computation: Recent advances and future challenges</title>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="61" to="70" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Expensive multiobjective optimization by MOEA/D with gaussian process model</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Virginas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="456" to="474" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A gaussian process surrogate model assisted evolutionary algorithm for medium scale expensive optimization problems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gielen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Evolutionary programming for high-dimensional constrained expensive black-box optimization using radial basis functions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Regis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Fitness modeling with markov networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brownlee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mccall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="862" to="879" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Max-min surrogate-assisted evolutionary algorithm for robust design</title>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="392" to="404" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Generalizing surrogateassisted evolutionary computation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="329" to="355" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The transferability approach: Crossing the reality gap in evolutionary robotics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Koos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Mouret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Doncieux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="122" to="145" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Meta-modeling in multiobjective optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nakayama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multiobjective Optimization, ser. Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5252</biblScope>
			<biblScope unit="page" from="245" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An estimation of distribution algorithm based on nonparametric density estimation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE Congress on Evolutionary Computation (CEC)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1597" to="1604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Stork</surname></persName>
		</author>
		<title level="m">Pattern Classification, 2nd Edition</title>
		<imprint>
			<publisher>John Wiley &amp; Sons, Inc</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Differential evolution with ranking-based mutation operators</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2066" to="2081" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Non-parametric estimation of a multivariate probability density</title>
		<author>
			<persName><forename type="first">V</forename><surname>Epanechnikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of Probability &amp; Its Applications</title>
		<imprint>
			<date type="published" when="1969">1969</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="153" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Adaptive Differential Evolution: A Robust Approach to Multimodal Problem Optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Sanderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">KEEL: A software tool to assess evolutionary algorithms to data mining problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Alcalá-Fdez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<ptr target="http://www.keel.es/" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">An extension on &quot;statistical comparisons of classifiers over multiple data sets&quot; for all pairwise comparisons</title>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal Of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2677" to="2694" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A study on the use of non-parametric tests for analyzing the evolutionary algorithms&apos; behaviour: A case study on the CEC&apos;2005 special session on real parameter optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lozano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Heuristics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="617" to="644" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Hybridizing differential evolution and particle swarm optimization to design powerful optimizers: A review and taxonomy</title>
		<author>
			<persName><forename type="first">B</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="744" to="767" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Selfadapting control parameters in differential evolution: A comparative study on numerical benchmark problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bošković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mernik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Žumer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="646" to="657" />
			<date type="published" when="2006-12">Dec 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Success-history based parameter adaptation for differential evolution</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fukunaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation (CEC)</title>
		<imprint>
			<biblScope unit="page" from="71" to="78" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Evaluating the performance of SHADE on CEC 2013 benchmark problems</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation (CEC)</title>
		<imprint>
			<biblScope unit="page" from="1952" to="1959" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Differential evolution with an individualdependent mechanism</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Multivariate online kernel density estimation with gaussian kernels</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Skočaj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">10 -11</biblScope>
			<biblScope unit="page" from="2630" to="2642" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Multiobjective evolutionary algorithms: A survey of the state of the art</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="49" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
