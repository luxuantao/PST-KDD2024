<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Particle Swarm Optimization With Interswarm Interactive Learning Strategy</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Quande</forename><surname>Qin</surname></persName>
							<email>qinquande@gmail.com</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Shi</forename><surname>Cheng</surname></persName>
							<email>shi.cheng@nottingham.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Qingyu</forename><surname>Zhang</surname></persName>
							<email>q.yu.zhang@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Li</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Yuhui</forename><surname>Shi</surname></persName>
							<email>yuhui.shi@xjtlu.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Shi</forename><forename type="middle">Cheng</forename><surname>Qin</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">College of Management</orgName>
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<postCode>518060</postCode>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Science and Technology</orgName>
								<orgName type="institution">Nanjing University of Information</orgName>
								<address>
									<postCode>210044</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Division of Computer Science</orgName>
								<orgName type="institution">University of Nottingham Ningbo</orgName>
								<address>
									<postCode>315100</postCode>
									<settlement>Ningbo</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Electrical and Electronic Engineering</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong-Liverpool University</orgName>
								<address>
									<postCode>215123</postCode>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Particle Swarm Optimization With Interswarm Interactive Learning Strategy</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E078C936676EBA1639E90D6593243A1D</idno>
					<idno type="DOI">10.1109/TCYB.2015.2474153</idno>
					<note type="submission">received September 26, 2014; revised April 10, 2015 and July 13, 2015; accepted August 21, 2015.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Global optimization</term>
					<term>interswarm interactive learning (IIL) strategy</term>
					<term>particle swarm optimization (PSO)</term>
					<term>population diversity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The learning strategy in the canonical particle swarm optimization (PSO) algorithm is often blamed for being the primary reason for loss of diversity. Population diversity maintenance is crucial for preventing particles from being stuck into local optima. In this paper, we present an improved PSO algorithm with an interswarm interactive learning strategy (IILPSO) by overcoming the drawbacks of the canonical PSO algorithm's learning strategy. IILPSO is inspired by the phenomenon in human society that the interactive learning behavior takes place among different groups. Particles in IILPSO are divided into two swarms. The interswarm interactive learning (IIL) behavior is triggered when the best particle's fitness value of both the swarms does not improve for a certain number of iterations. According to the best particle's fitness value of each swarm, the softmax method and roulette method are used to determine the roles of the two swarms as the learning swarm and the learned swarm. In addition, the velocity mutation operator and global best vibration strategy are used to improve the algorithm's global search capability. The IIL strategy is applied to PSO with global star and local ring structures, which are termed as IILPSO-G and IILPSO-L algorithm, respectively. Numerical experiments are conducted to compare the proposed algorithms with eight popular PSO variants. From the experimental results, IILPSO demonstrates the good performance in terms of solution accuracy, convergence speed, and reliability. Finally, the variations of the population diversity in the entire search process provide an explanation why IILPSO performs effectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>P ARTICLE swarm optimization (PSO) is a stochastic and population-based global optimization technique, which was invented by Eberhart and Kennedy <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref> in 1995. The underlying concept of PSO is to simulate the simplified social interaction behavior of birds flocking and fish schooling <ref type="bibr" target="#b0">[1]</ref>. Due to its easy implementation, rapid convergence rate, and good performance in solving real-world problems, PSO has become a widely-adopted optimization algorithm. However, a major problem associated with PSO is that it is prone to get trapped into local optima, which cause the premature convergence for a complex problem <ref type="bibr" target="#b2">[3]</ref>. Therefore, escaping from the local optima and accelerating the convergence simultaneously have become one of the most important research areas in the PSO community.</p><p>PSO relies on its learning strategy to guide its search direction. In the canonical PSO algorithm, each particle updates its velocity and position according to its own historically best position and its neighborhood's best position found so far. A particle's velocity and position update can be seen as the particle is learning from other particles and its own search experiences. This learning strategy enables the information to flow fast between particles and the particles' best historical experience. Fast information propagation among particles in PSO leads particles to cluster quickly, so all the solutions become similar and the diversity of the particle swarm declines rapidly. In general, the loss of diversity in the PSO algorithm is often blamed for being the main reason for particles to get trapped into the local optima <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>. The learning strategy of the canonical PSO algorithm lacks a mechanism to ensure the population diversity of the swarm and a momentum to escape from the local optima. Therefore, designing new efficient learning strategies, which can maintain an appropriate diversity during the entire search process, are promising ways to improve the algorithm's performance. So far, some efficient learning strategies have been developed <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b10">[11]</ref>.</p><p>Human beings are the most intelligent social animals in the world. The particle swarm's behavior can resort to the social interaction activities of a human group. A group in the human society has its strength and weakness in terms of possessing different resources. They often need to exchange or procure external resources for their own benefits.</p><p>They exist interdependently with others so that intergroup interactions may take place <ref type="bibr" target="#b11">[12]</ref>. Intergroup interaction is a bridge connecting different groups, and the level and intensity of the intergroup interaction affect a group's performance <ref type="bibr" target="#b12">[13]</ref>. Generally, the intergroup interaction acts mainly in two ways, constructive and destructive. When different groups cooperate, intergroup interaction is positive to each group and shown as constructive <ref type="bibr" target="#b12">[13]</ref>. On the contrary, when faced with conflicts of interests, the intergroup interaction will be destructive <ref type="bibr" target="#b13">[14]</ref>. In the constructive intergroup interaction, each member in a group has the momentum to learn from the other group. Through this mechanism, human can overcome their shortcomings by learning others' strengths. The most important characteristic of the intergroup interaction in the human society is that the role of a group can change. For example, a group is the learner now and may learn from the other group. But it may transform into the exemplar in the future from which the other group will learn. For each group, this intergroup interactive learning strategy offers mutual benefits and promotes common progress <ref type="bibr" target="#b14">[15]</ref>.</p><p>As a stochastic algorithm derived from the simulation of social behavior, PSO emphasizes on the information interaction among particles, i.e., intraswarm interaction. In this paper, we have transplanted the idea of the constructive intergroup interaction from the human society to the PSO algorithm. The PSO algorithm with interswarm interactive learning strategy (IILPSO) is proposed. The population of particles consists of two swarms in IILPSO. The two swarms have different roles, i.e., the learning swarm and the learned swarm. The learning swarm is the one that learns from the other; the learned swarm is the one which the other learns from. Each particle in the learning swarm has different probability to learn from the experience of its own swarm and that of the learned swarm. The degree of probability is determined according to their fitness values. Each particle in the learned swarm learns only from its own search experiences. Note that the roles of the two swarms can interchange as the iterations progress, which can alter the learning direction and help maintain the diversity.</p><p>The essence of the interswarm interactive learning (IIL) strategy is to provide a mechanism to maintain the diversity of the swarm and a new dynamics to escape from the local optima. The IIL strategy is applied to PSO with both global star and local ring structures, yielding the IILPSO-G and IILPSO-L algorithm, respectively. Other two strategies, named as velocity mutation and global best vibration strategy (GBVS), are utilized in the optimization. The IIL strategy provides a new momentum and may produce a "big" jump of particles to leave the local optima. However, this strategy may be less effective when the best position is similar in the two swarms. With the velocity mutation and GBVS, new perturbations added make both swarms evolve and improve the global search capabilities even if the global best position is similar in the two swarms. Experimental results on a set of benchmark functions will show that IILPSO has good performance compared with the other eight popular PSO variants.</p><p>In this paper, our goal is to demonstrate the performance and effectiveness of IILPSO and investigate why it performs effectively from the perspective of population diversity.</p><p>Compared with the published work on the interactive learning PSO algorithm <ref type="bibr" target="#b14">[15]</ref>, some new features are introduced in this paper. First, the IIL strategy is applied to PSO with different structures (i.e., global star and local ring structures). Second, a GBVS is added to enhance the global search ability of the proposed algorithm. Third, the population diversity variations are monitored to guide the progression of the iterations, which provides an explanation of IILPSOs' relatively good performance. In addition, the proposed algorithm is verified by the comprehensive experiments, and its performance is analyzed in detail.</p><p>The rest of this paper is organized as follows. Section II reviews the previous work related to PSO. The proposed strategies, which include ILL strategy, velocity mutation operator, and GBVS, are presented in Section III. The experimental settings are given in Section IV and results are given in Section V, followed by population diversity analyses in Section VI. Section VII concludes with some remarks and future research directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PARTICLE SWARM OPTIMIZATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Canonical Particle Swarm Optimization</head><p>Each individual, called a particle in PSO, in the swarm represents a candidate solution to the problem to be solved. Every particle is randomly initialized in search space. The ith particle is associated with two vectors, i.e., the velocity vector</p><formula xml:id="formula_0">V t i = [v t i1 , v t i2 , .</formula><p>. . , v t iD ] and the position vector</p><formula xml:id="formula_1">X t i = [x t i1 , x t i2 , . . . , x t iD ]</formula><p>, where i ∈ {1, 2, . . . , N}, N is the population size; D stands for the dimension of the solution space and t denotes the current iteration number.</p><formula xml:id="formula_2">x id ∈ [l d , u d ],</formula><p>d ∈ {1, 2, . . . , D}, where l d and u d are the lower and upper bound of the dth dimension of the search space, respectively. The velocity and the position of each particle are originally initialized in a uniform random manner within the corresponding ranges. The new velocities and the positions of the particles for the next iteration are updated according to the following two equations <ref type="bibr" target="#b15">[16]</ref>:</p><formula xml:id="formula_3">v t+1 id = wv t id + c 1 r 1 p t id -x t id + c 2 r 2 p t n i d -x t id (<label>1</label></formula><formula xml:id="formula_4">)</formula><formula xml:id="formula_5">x t+1 id = x t id + v t+1 id .<label>(2)</label></formula><p>In (1), r 1 and r 2 are random numbers, uniformly distributed within the interval [0, 1]. The c 1 and c 2 are acceleration coefficients. P t i = [p t i1 , p t i2 , . . . , p t iD ] is the best previous position which has been ever found by the ith particle. The best-so-far position found by particles in the ith particle's neighborhood is denoted as</p><formula xml:id="formula_6">P t n i = [p t n i 1 , p t n i 2 , . . . , p t n i D ].</formula><p>Generally, a maximum velocity on each dimension, v max,d , is specified to control excessive roaming of particles outside the user defined search space <ref type="bibr" target="#b16">[17]</ref>. If |v id | exceeds v max,d , then it is assigned to sign(v id )v max,d . The inertia weight w determines how much the previous velocity is preserved and is set to assist with the tradeoff between exploration and exploitation. A large inertia weight is in favor of the global search, while a small inertia weight enhances the ability of the local refinement.</p><p>It should be noted that in PSO a neighborhood is defined for each particle as the subset of particles with which it is able to communicate directly. Based on the size of the neighborhood of each particle, PSO algorithms are commonly classified into PSO with global star structure and PSO with local structure <ref type="bibr" target="#b17">[18]</ref>. In the PSO with the global star structure, a single best historical experience of the entire swarm is shared by all particles in the whole population. In a PSO with the local structure, each particle in the swarm includes a limited number of social neighbors which is defined by some topological structure, such as the ring structure, the four clusters structure, or the Von Neumann structure <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Related Works</head><p>A number of approaches have been proposed to improve the canonical PSO performance in various ways, thereby deriving many interesting variants. These improved PSO variants can be generally categorized into five groups.</p><p>1) The first adjusts the configuration parameters to balance the global and local search abilities <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>.</p><p>2) The second aims to increase the diversity by designing population topologies <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b22">[23]</ref>.</p><p>3) The third is the PSO hybridized with other auxiliary search techniques, including other evolutionary optimization operators <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, conventional local search <ref type="bibr" target="#b25">[26]</ref>, dissipative methods <ref type="bibr" target="#b3">[4]</ref>, and some biologyinspired operators <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, to enhance performance. 4) The fourth introduces multiple swarms to improve the global search ability <ref type="bibr" target="#b28">[29]</ref>- <ref type="bibr" target="#b30">[31]</ref>. 5) The fifth designs new efficient learning strategy, which may be the most promising way to improve the performance of PSO <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b10">[11]</ref>. In this paper, the proposed algorithm is related to the class of designing new learning strategies and multiple swarms. Liang et al. <ref type="bibr" target="#b5">[6]</ref> proposed a comprehensive learning particle swarm optimizer (CLPSO), in which particles are allowed to use different personal best positions to update its flying direction on different dimensions. An integrated learning particle swarm optimizer is proposed in <ref type="bibr" target="#b6">[7]</ref>. This algorithm finds the diverged particles and accelerates them toward the optimal solution, updating the velocity according to hyperspherical coordinates system <ref type="bibr" target="#b31">[32]</ref>. Wang et al. <ref type="bibr" target="#b10">[11]</ref> proposed a self-adaptive learning-based PSO which simultaneously adopts four PSO-based search strategies. The probability of a search strategy to be utilized is determined by its ability to generate better quality solutions in the past iterations. Huang et al. <ref type="bibr" target="#b7">[8]</ref> developed an example-based learning PSO. By the orthogonal experimental design, Zhan et al. <ref type="bibr" target="#b9">[10]</ref> proposed an orthogonal learning strategy for PSO to utilize more useful information previously discovered. This strategy can guide particles to fly in better direction by constructing a much promising and efficient exemplar. Considering the drawbacks of the single learning pattern, Li et al. <ref type="bibr" target="#b8">[9]</ref> developed a self-learning PSO for the global optimization. In this algorithm, each particle has four learning strategies, implemented by an adaptive learning framework, to cope with different situations.</p><p>The performance of a specific PSO algorithm is affected by the degree of information sharing <ref type="bibr" target="#b30">[31]</ref>. It means that the more information a PSO algorithm can efficiently utilizes during its search process, the better performance the PSO will have. So far, some information sharing strategies have been proposed to improve the performance of PSO <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b36">[37]</ref>. Multiswarm PSO (MS-PSO) technique is an effective way to maintain diversity through information sharing among different subswarms. The main idea of MS-PSO is to split the entire swarm into a set of interacting subswarms, and the subswarms exchange flying experience to explore wider solution space. Recently, several MS-PSO have been proposed to solve single-objective problems <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>, multiobjective problems <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>, and dynamic problems <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>. According to the roles of subswarms, MS-PSO algorithm model can be categorized into the following categories.</p><p>1) Homogenous MS-PSO: In the category, each subswarm will be allocated the same search behavior. In cooperative particle swarm optimizer, van den Bergh and Engelbrecht <ref type="bibr" target="#b28">[29]</ref> decomposed the potential solution into multiple parts and utilized different subswarms to cooperatively searching different parts of the potential solution. Zhan et al. <ref type="bibr" target="#b37">[38]</ref> proposed a novel co-evolutionary multiobjective PSO algorithm, in which each subswarm corresponds to one objective. Each subswarm of these PSO algorithms above mentioned is responsible for one subproblem. While in some other homogenous MS-PSO, each subswarm solves the whole problem independently. Liang and Suganthan <ref type="bibr" target="#b29">[30]</ref> presented a dynamic MS-PSO (DMS-PSO), characterized by several small subswarms and dynamically changing population topology. Zhang and Ding <ref type="bibr" target="#b41">[42]</ref> developed a multiswarm self-adaptive and cooperative PSO, where the entire swarm is divided into four subswarms and particles in each subswarm share the global historical best experience. 2) Heterogeneous MS-PSO: In this category, there is a hierarchy of roles among subswarms and different subswarms may be assigned to different search behavior. Niu et al. <ref type="bibr" target="#b42">[43]</ref> proposed a multiswarm master-slave PSO model, in which there are two kinds of subswarms, a master swarm and multiple slave swarms. The slave swarms explore the space independently while the master swarm evolves via collecting the best particles from the slave swarms. An MS-PSO developed by Chen et al. <ref type="bibr" target="#b43">[44]</ref> is used to handle complex optimization problems. The hierarchical interaction among multiswarms includes two levels, i.e., individual level and swarm level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PARTICLE SWARM OPTIMIZATION WITH INTERSWARM INTERACTIVE LEARNING STRATEGY</head><p>Inspired by the common social phenomenon of intergroup interactive learning behavior in human beings, we proposed a new PSO with IIL strategy, which can be seen as a heterogeneous multiple swarm PSO. In the proposed PSO algorithm, multiple swarms exchange the search information during the search. For the simplicity and clarity, two swarms are adopted in this paper. There are some methods that related to MS-PSO <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b44">[45]</ref>- <ref type="bibr" target="#b47">[48]</ref>, or PSO with new learning strategy <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b10">[11]</ref>. The characteristics of the proposed algorithm are as follows.</p><p>1) In many MS-PSO algorithms, the roles of each swarm are determined in advance <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>, such as master-slave model. In the master-slave model, there are two types of swarms, one is the master swarm, and the other is the slave swarm <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b45">[46]</ref>. In IILPSO, there is no determined master/slave swarm. The roles of different swarms can be exchanged during the search, i.e., the search information is bidirectionally propagated in the two swarms.</p><p>2) The MS-PSO algorithms normally use the migration operators and/or regroup operators, through which information is propagated among swarms at a regular interval <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b46">[47]</ref>. These strategies can generally improve the diversity of the whole swarm and the global search capability, but may decrease the search speed <ref type="bibr" target="#b48">[49]</ref>.</p><p>In the PSO with IIL strategy, the best particle has a probability to share its experience with particles in another swarm. Cooperating with velocity mutation operator and GBVS, IIL strategy can preserve the population diversity and fast convergence speed simultaneously. 3) IILPSO keeps a balance between intraswarm interaction and interswarm interaction. Some particles in the learning swarm can absorb the good experience from the learned swarm, and other particles maintain its original learning mechanism. This approach isolates particles to some extent, which is helpful to preserve the diversity. In addition, most existing learning strategies in PSO algorithm emphasize how to propagate the information effectively within swarm. The learning strategy in the proposed PSO focuses on information propagation between swarms. 4) The population diversities are used to monitor the PSO search process. Based on the population diversities observation, the properties of different PSO variants can be compared. Particles are grouped into two swarms, denoted as Swarm1 and Swarm2, in IILPSO. We use ] stand for the historical best position of each swarm, and the fitness value of P t g,1 and P t g,2 are denoted as f (P g,1 ) t and f (P g,2 ) t , respectively. In the initial phase of searching, two swarms update their velocity according to (1). The best particle position ever found at the tth iterations in two swarms and its fitness value are denoted as P t g and f (P g ) t , f (P g ) t = min( f (P g,1 ) t , f (P g,2 ) t ).</p><formula xml:id="formula_7">X t i,1 , V t i,</formula><p>The framework of IILPSO is described in Algorithm 1. Three strategies are used in IILPSO, which include the IIL strategy, velocity mutation, and GBVS.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Interswarm Interactive Learning Strategy</head><p>We designed an IIL strategy inspired by a common social learning behavior, and proposed a new PSO variant, i.e., IILPSO. The fitness value of the found-so-far global best position is monitored during the search process. When f (P g ) t is not improving within successive k iterations, i.e., f (P g ) tf (P g ) t-k = 0 (this means that the fitness of the found-so-far global best position is the same for the t and tk iterations, the f (P g ) t has no changes within k iterations), we assume that the algorithm may get trapped in the local optima, thus the IIL strategy begins to be executed in the two swarms. The main procedure of IIL strategy is described as follows.</p><p>1) Determining the Learning Swarm and Learned Swarm: In the two swarms, one will keep its original learning strategy and the other will change. We refer to the swarm maintaining its original learning strategy as the learned swarm, and the other as the learning swarm. We compare the fitness value of P t g,1 and P t g,2 to determine the roles of the two swarms. In (3), the softmax method is used to calculate the probability of selecting one as the learned swarm. This method will make the swarm with relatively poor global best position ever found have the opportunity to be the learned swarm. The probability p l of Swarm1 to be the learned swarm is obtained using the following equation:</p><formula xml:id="formula_8">p l = e -(f (Pg,1) -f (Pg))/T 2 j=1 e -(f (pg,j) -f (Pg))/T (3)</formula><p>where T stands for the global time-varying parameter, which called temperature, a high temperature causes the selections to have nearly equal probability, while a low temperature causes the selection probabilities to differ significantly between f (P g,1 ) and f (P g ) <ref type="bibr" target="#b49">[50]</ref>. We generate a random number uniformly distributed with the interval [0, 1]. If this random number is less than p l , Swarm1 is selected as the learned swarm; otherwise, Swarm2 is selected as the learned swarm.</p><p>The roles of two swarms can be interchanged in the next execution of the IIL strategy. It is obvious that this mechanism is useful for reserving the diversity.</p><p>2) Calculating Learning Probability: Parameter P c , referred to as learning probability, which can take different values for different particles, is used to determine the probability that each particle in the learning swarm learn from the learned swarm. Since better particles are more likely to have good search state, the probability they learn from the learned swarm should be relatively low in order to maintain their current search state. The learning probability P c i which ranges from 0.1 to 0.6 was empirically developed according to the following expressions:</p><formula xml:id="formula_9">p c i = 0.1 + 0.5 × (S i /N) 5 (<label>4</label></formula><formula xml:id="formula_10">)</formula><p>where N is the swarm size of the learning swarm; S i represents the serial number of the ith particle in the sequence that ranks all particles fitness value from small to large.</p><p>3) Updating the Velocity and Position in Each Swarm: The velocity updating strategy is different for the learning swarm and learned swarm. For the learned swarm, the velocity updating strategy is the same as the canonical PSO algorithm, i.e., velocities of particles in the learned swarm are updated according to (1). For particle i in the learning swarm, it has two learning modes: one is learning from the learned swarm which is simulated as its velocity updates in accordance with three dynamics: P t i , P t n i and the historical position ever found by the learned swarm; the other is keeping the previous search method. The learning mode of particle i in the learning swarm is determined by the parameter p c i . Without loss of generality, we assume that Swarm1 is the learning swarm and Swarm2 is the learned swarm. Then velocities of particles in Swarm1 are updated using ( <ref type="formula" target="#formula_16">5</ref>), shown at the bottom of the next page, where c 1 , c 2 are different settings from c 1 , c 2 , respectively. The c 3 is a parameter to control the magnitude of learning from another swarm. The r 1 -r 5 are random number uniformly distributed in [0, 1]. The p gd in the c 3 r 3 (p t gd,2x t id,1 ) component is the value of the found-so-far global best position in the learned swarm at dth dimension.</p><p>In <ref type="bibr" target="#b4">(5)</ref>, the c 3 r 3 (p t gd,2x t id,1 ) component indicates that the found-so-far global best position in Swarm2 guides the search of a particle in Swarm1. A particle is learning not only from its own swarm's search experiences, but also from the other swarm's search experiences. The population diversity will increase due to this strategy, and the probability of "jumping out" of the local optima also increases.</p><p>The flow chart of the IIL strategy is described in Fig. <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Velocity Mutation Operator</head><p>The IIL strategy may be less effective when the found-sofar global best position is similar in the two swarms. The velocities of particles may decrease to a tiny value when the particles get clustered. In order to enhance the global search capability, a velocity mutation operator is adopted to enhance IEEE TRANSACTIONS ON CYBERNETICS Algorithm 2: Procedure of Velocity Mutation Operator 1 Choosing a swarm j from Swarm1 and Swarm2, randomly (j = 1 when random number r 3 &lt; 0.5, otherwise, j = 2); 2 Select a particle i and dimension d, randomly; 3 Update the velocity v t id,j with the following equation:;</p><formula xml:id="formula_11">4 v t id,j = 0.5 × v max × r 5 r 4 &lt; 0.5 -0.5 × v max × r 5 otherwise.</formula><p>where r 3 , r 4 , and r 5 are three independently generated uniformly distributed random numbers in the range [0, 1].</p><p>the velocity diversity of particles. The mutation operator performed in the two swarms can be mathematically represented in Algorithm 2.</p><p>In the velocity mutation operator, one randomly selected dimension of the velocity vector in an arbitrary particle i within one arbitrary swarm is chosen to implement the velocity mutation. A random noise is added to one dimension, which provides negative entropy to construct an opening dissipative system and does not change the state of particle flying significantly. As every dimension has the same probability to be chosen, this mutation operation can be regarded as performing on every dimension in a statistical sense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Global Best Vibration Strategy</head><p>In the canonical PSO algorithm, all particles "fly" toward the found-so-far global best position. This position will be replaced when particles find a better one. However, if particles did not find a better position to replace the current global best, all particles will search in this small region, i.e., particles "stuck in" a local optimum.</p><p>In IILPSO, the global best particle discovered by the two swarms so far is denoted as P g . The algorithm may be prone to collapse when P g gets stuck in a local optima. It needs fresh dynamics to jump out of the local optima especially when complex multimodal problems are being optimized. Hence, a GBVS is developed to help P g push itself out to a potentially better region. The flow chart of GBVS strategy is described in Fig. <ref type="figure">2</ref>.</p><p>The GBVS performs on 1-D of P g . As P g is likely to have good structure of the global optimum, in order to protect these good structures, only one dimension is chosen to be perturbed. 1-D vibration has a higher probability of generating a new better position, while a few of dimensions perturbed can be distributed by other bad information obtained by the vibration. We use P d to represent the dth dimension of P g . Similar to the evolutionary programming, GBVS is performed through a Gaussian mutation</p><formula xml:id="formula_12">P d = P d + (u d -l d ) × Gaussian μ, σ 2 . (<label>6</label></formula><formula xml:id="formula_13">)</formula><p>Fig. <ref type="figure">2</ref>. Flowchart of GBVS.</p><p>The Gaussian (μ, σ 2 ) is a random number of a Gaussian distribution with a mean μ and a standard deviation (SD) σ . The proposed algorithm starts with a big vibration step size to increase the chance of searching new areas and enhance the global search ability. A small vibration step size is beneficial for exploitation at the later stage of searching. Hence, a timevarying scheme is given that σ is linearly decreased with the iterations number σ = σ max -(σ max -σ min ) × t/t max <ref type="bibr" target="#b6">(7)</ref> where σ max and σ min are the upper and lower bounds of σ . Vibration with a small step size exploits existing solutions. In contrast, vibration with a large step size is suited for the search space explorations. In this paper, empirical study shows that σ max = 1 and σ min = 0.2 leads to good performance. If P d is out of search range [l d , u d ], then P d is reset to as follows:</p><formula xml:id="formula_14">P d = min u d , 2u d -P d P d &lt; l d max l d , 2u d -P d P d &gt; u d . (<label>8</label></formula><formula xml:id="formula_15">)</formula><p>The new position will replace P g only if its fitness value is better than P g .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Complexity of IILPSO</head><p>In swarm intelligence, the most computational costs are spent on the function evaluations (FEs). The number of FE is </p><formula xml:id="formula_16">v t+1 id,1 = wv t id,1 + ⎧ ⎨ ⎩ c 1 r 1 p t id,1 -x t id,1 + c 2 r 2 p t nd,1 -x t id,1 + c 3 r 3 p t gd,2 -x t id,1 rand() ≤ pc i c 1 r 4 p t id,1 -x t id,1 + c 2 r 5 p t nd,1 -x t id,1 otherwise<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. BENCHMARK FUNCTIONS AND PARAMETER SETTINGS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Basic Benchmark Functions</head><p>A set of 18 basic benchmark functions in Table I are conducted to evaluate the performance of the proposed algorithm. These benchmark functions are divided into three groups: 1) group 1; 2) group 2; and 3) group 3. Group 1 includes f 1 -f 4 , four unimodal functions. Group 2 includes eight multimodal functions with many local optima. There exist two problems in the functions of groups 1 and 2: 1) the distribution of local optima in most functions is regular and the variables are separable and 2) each dimension value of the global optimum is always the same, and the global optimum is usually located at the center of the search space <ref type="bibr" target="#b10">[11]</ref>.</p><p>In group 3, f 13 -f 15 are rotated functions, in which the original variable x is rotated by left multiplying the orthogonal matrix M, i.e., y = M × x. The orthogonal rotation matrix does not affect the shape of the functions <ref type="bibr" target="#b5">[6]</ref>. In this paper, the method developed by Salomon <ref type="bibr" target="#b50">[51]</ref> is used to generate the orthogonal matrix. The global optima of f 16 -f 18 are shifted to different numerical values for different dimensions (z = xo), where o is the location of the new global optimum <ref type="bibr" target="#b51">[52]</ref>. We used x * and f (x * ) to represent global optimum and the corresponding fitness value. In each benchmark function, ξ stands for the upper bound of error. The fitness value of the best solution found by an algorithm in a run is denoted by f (x best ). The error of this run is defined as error = f (x best )f (x * ). This run is judged to be successful and the best solution found is acceptable if the error satisfies error ≤ ξ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Parameters Setting</head><p>To validate the effectiveness of the proposed algorithm, experiments were conducted to compare eight popular PSO variants with two IILPSO versions that were based on a global star topology (IILPSO-G) and a local ring topology (IILPSO-L) on 18 benchmark functions with dimension 30. Ten involved PSO algorithms are listed below.</p><p>1) PSO with inertia weight (PSO-w, w linearly decreases from 0.9 to 0.4) <ref type="bibr" target="#b15">[16]</ref>. 2) Local ring structured PSO with inertia weight (PSO-w-L). 3) Fully informed particle swarm (FIPS) <ref type="bibr" target="#b18">[19]</ref>. 4) Fitness-distance-ratio-based PSO (FDR-PSO) <ref type="bibr" target="#b22">[23]</ref>. 5) Hierarchical PSO with linearly time-varying acceleration coefficients (HPSO-TVAC) <ref type="bibr" target="#b16">[17]</ref>. 6) DMS-PSO <ref type="bibr" target="#b29">[30]</ref>. 7) Cooperative particle swarm optimizer (CPSO-H) <ref type="bibr" target="#b28">[29]</ref>. 8) CLPSO <ref type="bibr" target="#b5">[6]</ref>. 9) IILPSO-G. 10) IILPSO-L. Our goal is to demonstrate the performance of IILPSO and investigate why it performs effectively from the perspective of population diversity. Eight other popular PSO algorithms were selected to compare IILPSO against. The reason why these eight PSO variants are chosen is that they are representatives of the popular PSO variants in the literature. They are, in no means, inclusive or comprehensive. It is expected that under certain assumptions no algorithm is better than all other ones on average for all problems based on the "no free lunch theory" <ref type="bibr" target="#b52">[53]</ref>.</p><p>Among these PSO with local structures, PSO-w-local and IILPSO-L were chosen with ring structure, where a particle takes its left and right particle (by particle index) as its neighbors.</p><p>In the experiment, the parameters of IILPSO are set as follows: the acceleration coefficients in (1) are set to as the same as HPSO-TVAC, that is, c 1 is changing from 2.5 to 0.5 and c 2 from 0.5 to 2.5 over the full range of the search. In ( <ref type="formula" target="#formula_16">5</ref>), c 1 and c 2 are both set to 1.0, and c 3 is set to 2.0. If the global best position P g does not improve for 15 iterations, then IIL strategy begins to execute, it means that k = 15. The maximum velocity is limited to 12.5% of the search range, because IILPSO already uses IIL strategy to maintain the diversity for exploration, it no longer uses a large w to enhance global search. Unlike PSO-w, we set w lineally decreasing from 0.6 to 0.4 in the process of search. Parameters in (3) are set to change according to the following equations:</p><formula xml:id="formula_17">T 0 = -f (P g )/ ln(0.2) (9) T k+1 = αT k (<label>10</label></formula><formula xml:id="formula_18">)</formula><p>where T 0 is the initial temperature, and α is called cooling rate. In this paper, α is set to 0.9 by experimental study.</p><p>T k decreases with the iterations. This indicates that the swarm with good solution will have more possibilities to be the learned swarm. The parameters settings of the involved PSO algorithms are in accordance with the original references, except the swarm size and the maximum fitness evaluations. In order to make a fair comparison, the swarm size for all algorithms was set to 50 and the maximum FEs is set to be 400 000. The size of each swarm is set to 25 in IILPSO, N 1 = N 2 = 25, where N 1 and N 2 denote the size of Swarm1 and Swarm2, respectively. Dimensions D of all benchmark functions were set to 30. All experiments on each benchmark function were run 30 times independently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Solution Accuracy Results of Basic Benchmark Functions</head><p>The representative results including the mean of error values ( f (x)f (x * )) and SD of these benchmark function values were presented in Table <ref type="table" target="#tab_3">II</ref>, in which numbers in bold indicates the comparatively best values among the algorithms. The convergence characteristics of the evolutionary process for each PSO algorithm regarding all benchmark functions are given in the online supplementary materials. In these figures, each curve represents the variation of mean fitness over the FEs for a specific PSO.</p><p>In Table <ref type="table" target="#tab_3">II</ref>, we rank the algorithm's performance in terms of solution accuracy. It can be observed from the final average rank over the 18 functions that IILPSO-G offers the best overall performance based on the average residual error, while IILPSO-L is the second best, followed by CLPSO.</p><p>Specifically, we can observe that IILPSO-G achieves the best solutions on f 1 , f 4 , f 5 , f 9 , f 11 , f 13 , f 14 , f 16 , and f 17 . Although IILPSO-L is not the best on other benchmark functions except f 15 , it shows relatively better performance on each benchmark function compared with other PSO algorithms. DMS-PSO yields the best solution on f 2 , f 3 , f 7 , and f 12 . CLPSO performs the best on f 6 , f 8 , f 10 , and f 18 .</p><p>On the unimodal problems, IILPSO-G performs well on all four functions. For complicated unimodal problems f 4 , only IILPSOs can obtain high-quality solutions. On the multimodal problems, IILPSOs can achieve good performance. The Rosenbcok (f 5 ) has two optima when dimension is 30, in which the global optimum is inside a long, narrow, and parabolic shaped flat valley. This problem is a difficult task to find the global optimum for all the algorithms. IILPSO-G is shown to offer superior performance among all the involved PSO algorithms. We can observe that only IILPSO-G approaches the true global optimum, while the other algorithms are still stuck after the final iterations. Only CLPSO, CPSO-H, and IILPSO-G can obtain high-quality mean solutions with error value of 10 -3 to f 6 . With regard to f 8 , which has a D i=1 cos(x i / √ i) component causing linkage among variables, the complexity of which is due to deep local optima, which are far from the global optimum, is difficult to find the global optimum. LPSO, FIPS, and IILPSO-L outperform all the other PSO variants. The surface of f 9 is composed of a great number of peaks and valleys and this function has a second best minimum far from the global optimum. The search algorithms are potentially prone to convergence in the wrong direction in the optimization of this function. CLPSO and IPSO-G achieves the same best result as IILPSO-G on f 9 , and they both are much better than other algorithms on this problem. The problem f 10 is constructed based on f 6 , and has the same number of local optima as f 6 does. The performance of IILPSO-G in solving this problem is junior to CLPSO.</p><p>On the coordinate rotated and shifted functions, results for these problems appear that all PSO algorithms are affected; however, it is interesting to observe that IILPSO-G and IILPSO-L still do better than the other PSO algorithms. IILPSO-G performs best on f 13 , f 14 , f 16 , and f 17 , i.e., 4 out of the 6 functions, especially the performance of solving f 13 , f 16 , and f 17 is superior to other PSO algorithms. IILPSO-L does the best on f 15 , and only IILPSO-L, CLPSO, and FIPS achieve the global optimum on this problem.</p><p>With respect to the stability of algorithms, IILPSOs showed the best stability as compared to the other eight algorithms. The SDs of solutions found by IILPSOs were the smallest among all the algorithms on most functions. In general, IILPSOs are highly stable algorithms that are capable of obtaining reasonably consistent results. It should be noted that the results in Table II also demonstrate the comparisons between IILPSOs (PSOs with IIL strategy, velocity mutation, and GBVS) and PSOs without IIL strategy, velocity mutation, or GBVS. To be specific, they are IILPSO-G versus PSO-w with the final rank of no. 1 and no. 8, IILPSO-L versus PSO-w-L with the final rank of no. 2 and no. 9. We can observe that IILPSOs generally perform better than their counterpart on unimodal, multimodal, shifted and rotated functions. It illustrates the effectiveness of the proposed IILPSO algorithm.</p><p>In order to determine whether the results obtained by IILPSO-G and IILPSO-L are statistically different from the results generated by other PSO algorithms; a two-tailed t-test is used with a significance level of 0.05. Values of "1" in column "h 1 " and "h 2 " in Tables III and IV denoted that IILPSO-G and IILPSO-L performs significantly better than the corresponding algorithm, respectively. Values of "-1" indicate that IILPSO-G and IILPSO-L performs significant worse than the compared algorithm, respectively. The h 1 and h 2 values of "0" presents that the differences of the two algorithms is not statistically significant. The number of benchmark functions on which IILPSO-G and IILPSO-L obtains significantly better, almost the same or significantly worse are summarized in Table <ref type="table" target="#tab_5">IV</ref>. Although IILPSO-G and IILPSO-L performed slightly weaker on some functions, IILPSOs, especially IILPSO-G, in general offered much improved performance than all the PSOs compared.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Convergence Speed and Reliability Results of Basic Benchmark Functions</head><p>Convergence speed is measured on the number of FEs needed on average to reach the acceptable value, calculated only for the successful runs. The reliability of the algorithm is expressed by "successful rate (Suc%)," which stands for the percentage of the successful runs in the 30 independent runs. Although FDR-PSO converges very fast on some benchmark functions in terms of FEs, it needs to calculate the distance between particles, which is a time-consuming task. On the aspect of reliability, IILPSO significantly outperformed the other eight algorithms. IILPSO-L was capable of finding the global optimum with 100% successful rate on all the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Effects of Individual Components of IILPSO Algorithm</head><p>To understand clearly the effects of each individual component of the proposed IILPSO algorithm, we tested the IIL strategy, GBVS, and velocity mutations separately in the following sections.</p><p>1) Effects of the IIL Strategy: In order to test the effects of the IIL strategy, two variants of IILPSO algorithm without velocity mutation and GBVS, which termed as IILPSO-G-1 and IILPSO-L-1, are tested here. The IILPSO-G-1 has the global star structure, while the IILPSO-L-1 has the local ring structure. The solutions on 30 independent runs obtained by PSO-w, PSO-w-L, IILPSO-G-1, and IILPSO-L-1 are shown in Table <ref type="table" target="#tab_6">VI</ref>. We compare the mean values and the SDs on 30-dimensional problems in Table VI to demonstrate the effects of the IIL strategy. From the results in Table <ref type="table" target="#tab_6">VI</ref>, ILPSO-G-1 and ILPSO-L-1 outperform PSO-w and PSO-w-L, respectively.</p><p>Generally speaking, the IIL strategy can enhance the performance of PSO. When solving complex multimodal problems such as f 6 and f 9 , it performs better than PSO-w and PSO-w-L from the results in Table <ref type="table" target="#tab_6">VI</ref>. However, the IIL strategy performs less satisfactorily than it does on other functions in terms of achieving the real optimal solution of the function. For complex multimodal problems, the effectiveness of the IIL strategy is reduced when the best positions in two swarms getting similar rapidly.</p><p>2) Effects of GBVS: To quantify the effects of the GBVS, the IILPSO-G and IILPSO-L algorithm without GBVS strategy (termed as IILPSO-G-2 and IILPSO-L-2, respectively) are tested. Experiments are conducted on four variants of PSO algorithms, which include IILPSO-G-2, IILPSO-G, IILPSO-L-2, and IILPSO-L. Experimental results of 30 independent trials are presented in Table <ref type="table" target="#tab_7">VII</ref>. It demonstrates the IILPSO-G and IILPSO-L can search higher-quality solutions that IILPSO-G-2 and IILPSO-L-2, respectively. Thus, it can be seen that GBVS 3) Effects of Velocity Mutation: To study the effects of the velocity mutation, we dropped velocity mutation from the IILPSO-G and IILPSO-L. The obtained PSO algorithms are called as IILPSO-G-3 and IILPSO-L-3, respectively. Four variants of algorithms, IILPSO-G-3, IILPSO-G, IILPSO-L-3, and IILPSO-L, are tested on 18 benchmark functions with 30 independent trials. From the experimental results shown in Table <ref type="table" target="#tab_7">VIII</ref>, IILPSO-G suffers from relatively low accuracy on some unimodal functions such as f 2 and f 3 compared with IILPSO-G-3. It may be because the velocity mutation leads the search to reach the global optimal region with slow convergence speed on unimodal problems. On the multimodal problems, IILPSO-G can deliver solutions better than or comparable to IILPSO-G-3 and IILPSO-L-3. IILPSO-L performs worse than IILPSO-L-3 on f 7 and f 11 . Since IILPSO-L has a better exploration than IILPSO-G, the velocity mutation operator affects the refinement of solutions accuracy on relatively simple multimodal problems to some degree. From the results, it can conclude that the full IILPSO algorithms are the most effective and robust method for all the problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Influence of σ in GBVS</head><p>In order to investigate the influence of σ in GBVS, five time-varying strategies for setting the value of σ are tested on relevant functions including f 1 -f 6 , f 8 , f 9 , and f 11 . The mean  <ref type="table" target="#tab_2">IX</ref>, it reveals that the settings, σ max = 1.0, σ min = 0.2 offers the best performance of IILPSO-G and IILPSO-L, respectively. Therefore, the parameter σ of σ max = 1.0, σ min = 0.2 is recommended in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Results on the CEC 2013 Benchmark Functions</head><p>To further verify the of IILPSO, ten representative benchmark functions f 19 -f 28 , which include two rotated unimodal functions, five multimodal functions, and three composition functions, are chosen from a set of benchmark functions recently proposed at the CEC 2013 <ref type="bibr" target="#b53">[54]</ref>. The list of functions used is given in Table <ref type="table">X</ref> and more details can be found in <ref type="bibr" target="#b53">[54]</ref>.</p><p>Experimental results on the ten CEC 2013 benchmark functions are given in Table <ref type="table" target="#tab_9">XI</ref>. The best mean function value of the involved PSOs is marked in boldface. From Table XI, it can be seen that IILPSO-G obtains the best performance on f 19 and f 21 , and satisfactory results on the other problems. Although IILPSO-L do not perform the best on any function, the rank values illustrate it can solve these problems steadily. The IILPSO-G and IILPSO-L ranked the first and second on the final average rank list, respectively. It can be concluded that the IILPSO algorithm has strong global search ability and a good robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. POPULATION DIVERSITY ANALYSIS</head><p>The population diversity changes during the search process could give an intuitive explanation why IILPSOs performs better. The definitions of population diversity, which include position diversity, velocity diversity, and cognitive diversity,   <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b54">[55]</ref>, and <ref type="bibr" target="#b55">[56]</ref>. The detailed information about the population diversity is given in the online supplementary material. Position, velocity, and cognitive diversity are used to measure the distribution of particles' current positions, current velocities, and particles' personal best position, respectively. Without loss of generality, four benchmark functions in Table XII are selected as examples to illustrate the population diversity variation. Fig. <ref type="figure" target="#fig_2">3</ref> describes the population diversities on the representative functions. We only compare the population diversity variation between IILPSO-G, IILPSO-L, PSO-w, and PSO-w-L as IILPSO-G and IILPSO-L are improved versions of PSO-w and PSO-w-L, respectively.</p><p>In Fig. <ref type="figure" target="#fig_2">3</ref>, the position diversity and cognitive diversity of IILPSO-G and IILPSO-L decrease rapidly compared with PSO-w and PSO-w-L. As there is only one optimum in unimodal problems, fast decreasing in position and cognitive diversity is usually helpful to refine the current solution. In addition, the velocity diversity of IILPSO-G and IILPSO-L decreases rapidly and is relatively low compared with PSO-w and PSO-w-L, which can improve the ability of exploiting the potential regions to some extent. For this reason, IILPSO-G and IILPSO-L can find higher accuracy solutions than PSO-w and PSO-w-L. More rapid diversity declining helps the algorithm quickly converge to find a relatively good solution at the early stage of the search. However, it is not desirable for the algorithm to solve multimodal problems when it is at the later stage, since the algorithm may lose its global search ability if the diversity is too low. For function Rastrigin f 6 , we can observe that the position diversity and cognitive diversity of IILPSO-G and IILPSO-L decrease rapidly in the early stage, and stagnate at the later stage, whereas the diversity of PSO-w and PSO-w-L decline rapidly during the entire search process. Therefore, IILPSO-G and IILPSO-G perform better on complex multimodal problems f 6 than PSO-w and PSO-w-L.</p><p>The variations of position diversity and cognitive diversity of the rotated problem f 14 and shifted problem f 17 are similar to that of problem f 6 . For rotated Rastrigin function f 14 , and shifted Rosenbrock function f 17 , the velocity diversity of IILPSO-G and IILPSO-L remains at a relatively-higher value. This indicates that particles have a high probability to escape from the local optima, which can potentially enhance the exploration ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>In this paper, we have proposed a novel PSO variant with an IIL strategy, which is inspired by the learning behavior of the human society. There are two swarms in IILPSO, which are called the learning swarm and learned swarm, respectively. The two swarms can exchange information and their roles can be interchanged during the search process. Unlike the canonical PSO, IILPSO enables the particles in the learning swarm to learn from the experience of the learned swarm. The IIL strategy is applied to PSO with both global star and local ring structures, yielding the IILPSO-G and IILPSO-L algorithm, respectively.</p><p>In addition, velocity mutation and GBVS were used to improve the algorithm's global search capability. The IIL strategy may be less effective when the global best position is similar in these two swarms. With the velocity mutation and GBVS, particles could have the opportunity to "jump out" of the local optima.</p><p>Comprehensive experiments have been conducted to compare the proposed algorithm with the eight popular PSO variants on a set of benchmark functions including unimodal, multimodal, rotated, and shifted functions. The experimental results demonstrated that IILPSO-G and IILPSO-L have good global search capability and perform effectively and reliably in terms of solution accuracy and convergence speed. The effects of the IIL strategy, velocity mutation, and GBVS on the algorithm's performance have been examined separately. The population diversity sustained during the entire search process explains why IILPSOs perform so well.</p><p>Many real-world problems come with multiple conflicted objectives. The proposed IILPSO algorithm can be applied to solve multiobjective optimization problems in future. The idea of intergroup interaction can also be incorporated with other meta-heuristics methods such as differential evolution algorithm and artificial bee colony algorithm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Algorithm 1 :</head><label>1</label><figDesc>Framework of IILPSO</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Flowchart of IIL strategy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Population diversity observation of PSO variants solving benchmark functions, while "Pos.," "Vel.," and "Cog." mean position diversity, velocity diversity, and cognitive diversity, respectively. (a) Schwefel 1.2 f 1 Pos. (b) Rastrigin f 6 Pos. (c) Rotated Rastrigin f 14 Pos. (d) Shift Rosenbrock f 17 Pos. (e) Schwefel 1.2 f 1 Vel. (f) Rastrigin f 6 Vel. (g) Rotated Rastrigin f 14 Vel. (h) Shift Rosenbrock f 17 Vel. (i) Schwefel 1.2 f 1 Cog. (j) Rastrigin f 6 Cog. (k) Rotated Rastrigin f 14 Cog. (l) Shift Rosenbrock f 17 Cog.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>1</head><label></label><figDesc>Initialize positions and velocities of all particles in two swarms within search range; 2 Evaluate the fitness of all particles in two swarms;</figDesc><table><row><cell cols="2">3 Update X t i,1 , P t i,1 , P t n i ,1 , P t g,1 , X t i,2 , P t i,2 , P t n i ,2 , P t g,2 , and P t g ; 4 while (stop criterion is not satisfied) do</cell></row><row><cell>5</cell><cell>if global best fitness value f (P g ) not improved within k</cell></row><row><cell></cell><cell>iterations then</cell></row><row><cell>6</cell><cell>Determine the roles of each swarm;</cell></row><row><cell>7</cell><cell>Identify learning direction of each particle in the</cell></row><row><cell></cell><cell>learning swarm;</cell></row><row><cell>8</cell><cell>Update the velocity according to Eq. (1) and Eq. (5);</cell></row><row><cell>9</cell><cell>else</cell></row><row><cell>10</cell><cell>Update the velocity of each swarm according to</cell></row><row><cell></cell><cell>Eq. (1);</cell></row><row><cell>11</cell><cell>v t id,j = min(max(v t id,j , -v max ), v max ), j = 1, 2;</cell></row><row><cell>12</cell><cell>Update the position of each swarm;</cell></row><row><cell>13 14</cell><cell>Evaluate the fitness of all particles in two swarms; Update X t i,1 , P t i,1 , P t n i ,1 , P t g,1 , X t i,2 , P t i,2 , P t n i ,2 , P t g,2 , and P t g ;</cell></row></table><note><p>15 Velocity mutation operator; 16 Global best vibration strategy;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I BENCHMARK</head><label>I</label><figDesc>FUNCTIONS USED IN OUR EXPERIMENTAL STUDY, WHERE D IS THE DIMENSION OF EACH PROBLEM</figDesc><table /><note><p>used to measure the time complexity. In this paper, we compared different algorithms with the same number of FEs. Four additional computations are added in IILPSO, i.e., determining the roles of the two swarms, learning probability calculation, velocity mutation, and GBVS. However, the IILPSO did not involve many extra computational costs in comparison with the canonical PSO algorithm. The first two extra computations will trigger only when f (P g ) does not improve within successive k iterations. For the first three extra computations, we do not need to re-evaluate the fitness value, and it only needs one evaluation in each iteration for the GBVS.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II EXPERIMENTAL</head><label>II</label><figDesc>RESULTS ON BENCHMARK FUNCTIONS f 1 -f 18</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V COMPARISONS</head><label>V</label><figDesc>OF SEARCH SPEED AND RELIABILITY ON BENCHMARK FUNCTIONSThe ranking of the algorithms is based on the successful performance SP, which is defined as SP = (Average FEs)/Suc%. Table V reports the convergence speed, successful rate and successful performance of the involved PSO algorithms. On the aspect of convergence speed, IILPSOs are always one of the fastest algorithms in term of FEs. For example, IILPSO-G converges the fastest on f 8 , f 12 , f 13 , and f 17 , and keeps the three fastest algorithm on 17 benchmark functions except for f 4 .</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI EXPERIMENTAL</head><label>VI</label><figDesc>RESULTS ON EFFECT OF IIL STRATEGY benchmark functions; and IILPSO-G offers a 100% successful rate on 16 out of the 18 benchmark functions except for f 8 and f 15 . It is worth noting that IILPSO-G converges very fast on these two problems. The final rank based on SP metric of IILPSO-G and IILPSO-L is 1 and 3, respectively. These experimental results show that IILPSOs are very competitive on the convergence speed and reliability.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VII EXPERIMENTAL</head><label>VII</label><figDesc>RESULTS ON EFFECTS OF GBVS STRATEGYTABLE VIII EXPERIMENTAL RESULTS ON EFFECTS OF VELOCITY MUTATION increases solutions accuracy on unimodal problems such as f 2 and f 3 and contributes to get rid of local optima and enhances global search capability on multimodal functions such as f 6 and f 9 .</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE XI EXPERIMENTAL</head><label>XI</label><figDesc>RESULTS ON CEC 2013 FUNCTIONS f 19 -f 28</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE XII</head><label>XII</label><figDesc></figDesc><table><row><cell>FOUR REPRESENTATIVE BENCHMARK FUNCTIONS</cell></row><row><cell>are proposed in</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Natural Science Foundation of China under Grant 71402103, Grant 60975080, and Grant 61273367, in part by the National Science Foundation of SZU under Grant 836, in part by the Foundation for Distinguished Young Talents in Higher Education of Guangdong, China, under Grant 2012WYM_0116, in part by the MOE Youth Foundation Project of Humanities and Social Sciences at Universities in China under Grant 13YJC630123, in part by the PAPD and CICAEET project, and in part by the Ningbo Science and Technology Bureau under Science and Technology Project 2012B10055. This paper was recommended by Associate Editor H. Takagi.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A new optimizer using particle swarm theory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Int. Symp. Micro Mach</title>
		<meeting>6th Int. Symp. Micro Mach<address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="39" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Neural Netw</title>
		<meeting>IEEE Int. Conf. Neural Netw<address><addrLine>Perth, WA, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Evolutionary optimization versus particle swarm optimization: Philosophy and performance differences</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Angeline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Programming (LNCS 1447</title>
		<editor>
			<persName><forename type="first">V</forename><forename type="middle">W</forename><surname>Porto</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Saravanan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Waagen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Eiben</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A dissipative particle swarm optimization</title>
		<author>
			<persName><forename type="first">X.-F</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Congr</title>
		<meeting>4th Congr<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-05">May 2002</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1456" to="1461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Social interaction in particle swarm optimization, the ranked FIPS, and adaptive multi-swarms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Helwig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wanka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Genet. Evol. Comput. Conf. (GECCO)</title>
		<meeting>Genet. Evol. Comput. Conf. (GECCO)<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-07">Jul. 2008</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Comprehensive learning particle swarm optimizer for global optimization of multimodal functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="281" to="295" />
			<date type="published" when="2006-06">Jun. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Integrated learning particle swarm optimizer for global optimization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Sabat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Udgatab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="574" to="584" />
			<date type="published" when="2011-01">Jan. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Example-based learning particle swarm optimization for continuous optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="125" to="138" />
			<date type="published" when="2012-01">Jan. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A self-learning particle swarm optimizer for global optimization problems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="627" to="646" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Orthogonal learning particle swarm optimization</title>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="832" to="847" />
			<date type="published" when="2011-12">Dec. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Self-adaptive learning based particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="4515" to="4538" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Differential power and effects of expected competitive and cooperative intergroup interaction on intragroup and outgroup attitudes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rabbie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Benoist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Oosterbaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Visser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Pers. Soc. Psychol</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="46" to="56" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Intergroup cooperation and intergroup attraction: The effect of previous interaction and outcome on combined effort</title>
		<author>
			<persName><forename type="first">S</forename><surname>Worchel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Andreoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Folger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Soc. Psychol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="131" to="140" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Superordinate goals and intergroup conflict</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Deschamps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brit. J. Soc. Psychol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="189" to="195" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Interactive learning particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CAAI Trans. Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="557" to="563" />
			<date type="published" when="2012-12">Dec. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A modified particle swarm optimizer</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr<address><addrLine>Anchorage, AK, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-05">May 1998</date>
			<biblScope unit="page" from="69" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Self-organizing hierarchical particle swarm optimizer with time-varying acceleration coefficients</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ratnaweera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Halgamuge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="240" to="255" />
			<date type="published" when="2004-06">Jun. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Population structure and particle swarm performance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Congr</title>
		<meeting>4th Congr<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-05">May 2002</date>
			<biblScope unit="page" from="1671" to="1676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The fully informed particle swarm: Simpler, maybe better</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="204" to="210" />
			<date type="published" when="2004-06">Jun. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Population diversity based study on search information propagation in particle swarm optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr<address><addrLine>Brisbane, QLD, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-06">Jun. 2012</date>
			<biblScope unit="page" from="1272" to="1279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A novel particle swarm optimization algorithm with adaptive inertia weight</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nickabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ebadzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Safabakhsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3658" to="3670" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adaptive particle swarm optimization</title>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-H</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1362" to="1381" />
			<date type="published" when="2009-12">Dec. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fitness-distanceratio based particle swarm optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Peram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Veeramachaneni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Mohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Swarm Intell. Symp. (SIS)</title>
		<meeting>IEEE Swarm Intell. Symp. (SIS)<address><addrLine>Indianapolis, IN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-04">Apr. 2003</date>
			<biblScope unit="page" from="174" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Particle swarm and ant colony algorithms hybridized for improved continuous optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Shelokar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Siarry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Kulkarni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">188</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="129" to="142" />
			<date type="published" when="2007-05">May 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Using selection to improve particle swarm optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Angeline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr<address><addrLine>Anchorage, AK, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-05">May 1998</date>
			<biblScope unit="page" from="84" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dynamic multi-swarm particle swarm optimizer with local search</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr<address><addrLine>Edinburgh, U.K.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06">Jun. 2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="522" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Locating multiple optima using particle swarm optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Brits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Engelbrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Van Den Bergh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">189</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1859" to="1883" />
			<date type="published" when="2007-06">Jun. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Locating and tracking multiple dynamic optima by a particle swarm model using speciation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Parrott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="440" to="458" />
			<date type="published" when="2006-08">Aug. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A cooperative approach to particle swarm optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Van Den Bergh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Engelbrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="225" to="239" />
			<date type="published" when="2004-06">Jun. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dynamic multi-swarm particle swarm optimizer</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Swarm Intell. Symp. (SIS)</title>
		<meeting>IEEE Swarm Intell. Symp. (SIS)</meeting>
		<imprint>
			<date type="published" when="2005-06">Jun. 2005</date>
			<biblScope unit="page" from="124" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Competitive and cooperative particle swarm optimization with information sharing mechanism for global optimization problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">293</biblScope>
			<biblScope unit="page" from="370" to="382" />
			<date type="published" when="2015-02">Feb. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The hyperspherical acceleration effect particle swarm optimizer</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Sabat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="906" to="917" />
			<date type="published" when="2009-06">Jun. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Stereotyping: Improving particle swarm performance with cluster analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr<address><addrLine>La Jolla, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1507" to="1512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Bare bones particle swarms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Swarm Intell. Symp. (SIS)</title>
		<meeting>IEEE Swarm Intell. Symp. (SIS)<address><addrLine>Indianapolis, IN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-04">Apr. 2003</date>
			<biblScope unit="page" from="80" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A swarm with an effective information sharing mechanism for unconstrained and constrained single objective optimization problems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Liew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr<address><addrLine>Seoul, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="75" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Bare bones particle swarm optimization with scale matrix adaptation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Krohling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Enriquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1567" to="1578" />
			<date type="published" when="2014-09">Sep. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A competitive swarm optimizer for large scale optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="191" to="204" />
			<date type="published" when="2015-02">Feb. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Multiple populations for multiple objectives: A coevolutionary technique for solving multiobjective optimization problems</title>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="445" to="463" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Dynamic multiple swarms in multiobjective particle swarm optimization</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Leong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. A, Syst., Humans</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="890" to="911" />
			<date type="published" when="2009-07">Jul. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A novel multi-swarm algorithm for optimization in dynamic environments based on particle swarm optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yazdani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nasiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sepas-Moghaddam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Meybodi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2144" to="2158" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Multiswarms, exclusion, and anticonvergence in dynamic environments</title>
		<author>
			<persName><forename type="first">T</forename><surname>Blackwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="459" to="472" />
			<date type="published" when="2006-08">Aug. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A multi-swarm self-adaptive and cooperative particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eng. Appl. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="958" to="967" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">MCPSO: A multi-swarm cooperative particle swarm optimizer</title>
		<author>
			<persName><forename type="first">B</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1050" to="1062" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Discrete and continuous optimization based on multi-swarm coevolution</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="659" to="682" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Two sub-swarms particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Natural Computation</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3612</biblScope>
			<biblScope unit="page" from="515" to="524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A master-slave particle swarm optimization algorithm for solving constrained optimization problems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th World Congr</title>
		<meeting>6th World Congr<address><addrLine>Dalian, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06">Jun. 2006</date>
			<biblScope unit="page" from="3208" to="3212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Diversity-based information exchange among multiple swarms in particle swarm optimization</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Daneshyari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Intell. Appl</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="75" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Coevolutionary particle swarm optimization using AIS and its application in multiparameter estimation of PMSM</title>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1921" to="1935" />
			<date type="published" when="2013-12">Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Particle swarm optimization with an aging leader and challengers</title>
		<author>
			<persName><forename type="first">W.-N</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="258" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<title level="m">Reinforcement Learning: An Introduction (Adaptive Computation and Machine Learning</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Re-evaluating genetic algorithm performance under coordinate rotation of benchmark functions. A survey of some theoretical and practical aspects of genetic algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioSystems</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="263" to="278" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Problem definitions and evaluation criteria for the CEC 2005 special session on real-parameter optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kanpur Genet. Algorithms Lab., Nanyang Technol. Univ., Singapore, Tech. Rep. KanGAL</title>
		<imprint>
			<date type="published" when="2005">2005005. May 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">No free lunch theorems for optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Macready</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="82" />
			<date type="published" when="1997-04">Apr. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Problem definitions and evaluation criteria for the CEC 2013 special session on real-parameter optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hernández-Díaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Intell. Lab., Zhengzhou Univ</title>
		<imprint>
			<date type="published" when="2013">201212. Jan. 2013</date>
			<pubPlace>Zhengzhou, China</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Diversity control in particle swarm optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symp. Swarm Intell. (SIS)</title>
		<meeting>IEEE Symp. Swarm Intell. (SIS)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-04">Apr. 2011</date>
			<biblScope unit="page" from="110" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Population diversity in particle swarm optimization: Definition, observation, control, and application</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Electr. Eng. Electron., Univ. Liverpool</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<pubPlace>Liverpool, U.K.</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
