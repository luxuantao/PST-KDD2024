<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DSC: Scheduling Parallel Tasks on an Unbounded Number of Processors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Tao</forename><surname>Yang</surname></persName>
							<email>tyang@cs.ucsb.edu</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Apostolos</forename><surname>Gerasoulis</surname></persName>
							<email>gerasoulis@cs.rutgers.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Barbara</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>93 106</postCode>
									<settlement>Santa Barbara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<address>
									<addrLine>Rutgers Uni-versity</addrLine>
									<postCode>08903</postCode>
									<settlement>New Brunswick</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DSC: Scheduling Parallel Tasks on an Unbounded Number of Processors</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">921F7B21F92BB78E3A9B201F8D0A499B</idno>
					<note type="submission">received September 8, 1992; revised June 17, 1993.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Zndex Terms-Clustering</term>
					<term>directed acyclic graph</term>
					<term>heuristic algorithm</term>
					<term>optimality</term>
					<term>parallel processing</term>
					<term>scheduling</term>
					<term>task precedence</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a low-complexity heuristic, named the dominant sequence clustering algorithm (DSC), for scheduling parallel tasks on an unbounded number of completely connected processors. The performance of DSC is, on average, comparable to, or even better than, other higher-complexity algorithms. We assume no task duplication and nonzero communication overhead between processors. Finding the optimum solution for arbitrary directed acyclic task graphs (DAG's) is NP-complete. DSC finds optimal schedules for special classes of DAG's, such as fork, join, coarse-grain trees, and some fine-grain trees. It guarantees a performance within a factor of 2 of the optimum for general coarse-grain DAG's. We compare DSC with three highercomplexity general scheduling algorithms: the ETF by Hwang, Chow, Anger, and Lee; Sarkar's clustering algorithm; and the MD by Wu and Gajski. We also give a sample of important practical applications where DSC has been found useful.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present an efficient algorithm for the first step of Sarkar's approach. Algorithms for the second step are discussed elsewhere <ref type="bibr">[23]</ref>. The objective of scheduling is to allocate tasks onto the processors and then order their execution so that task dependence is satisfied and the length of the schedule, known as the parallel time, is minimized. In the presence of communication, the complexity of the above scheduling problem has been found to be much more difficult than in the classical scheduling probltm, where communication is ignored. The general problem is NP-complete, and even for simple graphs, such as fine-grain trees or the concatenation of a fork and a join, the complexity is still NP-complete <ref type="bibr">[3]</ref>, <ref type="bibr">[ 151, and [ 171.</ref> Only for special classes of DAG's, such as join, fork, and coarse-grain tree, special polynomial algorithms are known <ref type="bibr">[2]</ref>, <ref type="bibr">[4]</ref>.</p><p>There have been two approaches in the literature addressing the general scheduling problem. The first approach considers heuristics for arbitrary DAG's, and the second studies optimal algorithms for special classes of DAG's. When task duplication is allowed, Papadimitriou and Yannakakis [ 151 have proposed an approximate algorithm for a DAG with equal task weights and equal edge weights, which guarantees a performance within 50% of the optimum. This algorithm has a complexity of O(v3(v logv + e)), where ' U is the number of tasks and tl is the number of edges. Kruatrachue and Lewis [ 131 have also given an O(v4) algorithm for a general DAG based on task duplication. One difficulty in allowing task duplication is that duplicated tasks may require duplicated data among processors, and thus the space complexity could increase when executing parallel programs on real machines.</p><p>Without task duplication, many heuristic scheduling algorithms for arbitrary DAG'S have been proposed in the literature (e.g.. <ref type="bibr">[12]</ref>, <ref type="bibr">[17]</ref>, <ref type="bibr">[19]</ref>). A detailed comparison of four heuristic algorithms is given in [9]. One difficulty with most existing algorithms for general DAG's is their high complexity. As far as we know, no scheduling algorithm exists that works well for arbitrary graphs, finds optimal schedules for special DAG's, and also has a low complexity. We present one such algorithm in this paper with a complexity of O( (v + e) log U). called the Dominant Sequence Clustering (DSC) algorithm. We compare DSC with ETF algorithm by Hwang, Chow, Anger, and Lee [ 1 11, and discuss its similarities and differences with the MD algorithm proposed by <ref type="bibr">Wu and Gajski [19]</ref>.</p><p>The organization is as follows: Section I1 introduces the basic concepts. Section 111 describes an initial design of the DSC algorithm and analyzes its weaknesses. Section IV presents an improved version of DSC that takes care of 1045-9219/94$04.00 t 3 1994 IEEE the initial weaknesses and analyzes how DSC achieves both low complexity and good performance. Section V gives a performance bound for a general DAG. It shows that the performance of DSC is within 50% of the optimum for coarsegrain DAG'S, and it is optimal for join, fork, coarse-grain trees and a class of fine-grain trees. Section VI discusses the related work, presents experimental results and compares the performance of DSC with Sarkar's, ETF, and MD algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">~E L M N A R I E S</head><p>A directed acyclic task graph (DAG) is defined by a tuple G = (V, E , C, 7) where V is the set of task nodes and ' U = IVI is the number of nodes, E is the set of communication edges, e = IEl is the number of edges, C is the set of edge communication costs, and 7 is the set of node computation costs. The value c,,~ E C is the communication cost incurred along the edge ezIJ = (71%. n 3 ) E E , which is zero if both nodes are mapped in the same processor. The value 7% E 7 is the execution time of node nz E V . PRED(n,) is the set of immediate predecessors of n,, and SUCC(n,) is the set of immediate successors of n,. An example of DAG is shown in <ref type="bibr">Fig. l(a)</ref>, with seven tasks n1. n2, . . . ,717. Their execution times are on the right side of the bullets, and edge weights are written on the edges.</p><p>The task execution model is the compile time macro- dataflow model. A task receives all input before starting execution in parallel, executes to completion without interruption, and immediately sends the output to all successor tasks in parallel. (See <ref type="bibr">Wu and Gajski [ 191 and Sarkar [17]</ref>.) Duplication of the same task in separate processors is not allowed.</p><p>Given a DAG and an unbounded number of completely connected processors, the scheduling problem consists of two parts: the task to processor assignment, called clustering in this paper, and the task execution ordering for each processor. A DAG with a given clustering, but without the task execution ordering, is called a clustered graph. A communication edge weight in a clustered graph becomes zero if the start and end nodes of this edge are in the same cluster. CLUST(n,) stands for the cluster of node 71,. If a cluster contains only one task, it is called a unit cluster. We distinguish between two types of clusters: the linear and the nonlinear. Two tasks are called independent if there are no dependence paths between them. A cluster is called nonlinear if there are two independent tasks in the same cluster; otherwise, it is called linear. In <ref type="bibr">Fig. l(c)</ref>, there are two clusters: The cluster that contains n1 and 712 is linear; the other cluster is nonlinear, because n3 and n4 are independent tasks in <ref type="bibr">Fig. l(a)</ref>. A schedule imposes an ordering of tasks in nonlinear clusters. Thus, the nonlinear clusters of a DAG can be thought of as linear clusters in the scheduled DAG if the execution orders between independent tasks are counted as edges. A linear clustering preserves the parallelism present in a DAG, and nonlinear clustering reduces parallelism by sequentializing parallel tasks. A further discussion of this issue can be found in Gerasoulis and Yang <ref type="bibr">[8]</ref>.</p><p>The critical path of a clustered graph is the longest path in that graph, including both nonzero communication edge cost and task weights in that path. The parallel time in executing a clustered DAG is determined by the critical path of the scheduled DAG, not by the critical path of the clustered DAG. We call the critical path of a scheduled DAG the dominant sequence (DS), to distinguish it from the critical path of the clustered DAG. For Fig. <ref type="figure">l(c</ref>), the critical path of the clustered graph is ( n l , 712. n7). and the DS is still that path. If the weight of 715 is changed from 2 to 6, then the critical path of the clustered graph remains the same, ( n l r n 2 , n 7 ) , but the DS changes to ( ~5 , 7 1 3 , 7 1 4 . 7 1 6 , ? 1 7 ) . A path that is not a DS is called a SubDS.</p><p>Let tlevel(n,) be the length of the longest path from an entry (top) node to n,, excluding the weight of n, in a DAG. Symmetrically, let blevel(n,) be the length of the longest path from n, to an exit (bottom) node. For example, in Fig. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Scheduling as Successive Clustering Rejnements</head><p>Our approach for solving the scheduling problem with unlimited resources is to consider a scheduling algorithm as performing a sequence of clustering refinement steps. As a matter of fact, most of the existing algorithms can be characterized by using such a framework [9]. The initial step assumes that each node is mapped in a unit cluster. At each step, the algorithm tries to improve on the previous clustering by merging appropriate clusters. A merging operation is performed by zeroing an edge cost connecting two clusters. ' Sarkar's Algorithm: We consider <ref type="bibr">Sarkar's algorithm [ 17, pp. 123-1311</ref> as an example of an edge-zeroing clustering refinement algorithm. This algorithm first sorts the e edges of the DAG in a decreasing order of edge weights, and then performs e clustering steps by examining edges from left to right in the sorted list. At each step, it examines one edge and zeros this edge if the parallel time does not increase. Sarkar's algorithm requires the computation of the parallel time at each step, and this problem is also NP-complete. Sarkar uses the following strategy for ordering. Order independent tasks in a cluster by using the highest blevel first-priority heuristic, where blevel is the value computed in the previous step. The new parallel time is then computed by traversing the scheduled DAG in O(v + e ) time. Since there are e steps, the overall complexity is O(e(e + U)). Fig. <ref type="figure" target="#fig_4">2</ref> shows the clustering steps of Sarkar's algorithm for the DAG in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">AN INITIAL DESIGN OF THE DSC ALGORITHM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Design Considerations for the DSC Algorithm</head><p>As can be seen in the previous section, Sarkar's algorithm zeroes the highest communication edge. This edge, however, may not be in a DS, and as a result, the parallel time may not be reduced at all. (See the zeroing of edge ( n 4 , n e ) in step 1 Fig. <ref type="figure" target="#fig_4">2</ref>.) In order to reduce the parallel time, we must examine the schedule of a clustered graph to identify a DS and then try to reduce its length. The muin idea behind the DSC algorithm 'Two clusters will not be merged if there is no edge connecting them, because this cannot decrease the parallel time. is to per$orm a sequence of edge zeroing steps with the goal of reducing the length of a DS at each step, The challenge is to implement this idea with low complexity so that it can be used for large task graphs. Thus, we would like to develop an algorithm having the following goals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G1:</head><p>The complexity should be low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>62:</head><p>The parallel time should be minimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>63:</head><p>The efficiency should be maximized. There are several difficulties in the implementation of algorithms that satisfy the above goals.</p><p>1) The goals G1, G2, and G3 could conflict with each other. For example, the maximization of the efficiency conflicts with the minimization in the parallel time. When such conflicts arise, G 1 is given priority over G2 and G3, and G2 is given priority over G3. In other words, we are interested in algorithms with low complexity that attain the minimum possible parallel time and the maximum possible efficiency.</p><p>Let us assume that the DS has been determined. A careful selection of edges to be examined and zeroed must be made to avoid high complexity and simultaneously reduce the parallel time. Consider the example in Fig. <ref type="figure" target="#fig_4">2</ref>(a). Initially, the DS is ( ~~1 , 7 1 2 ~n 7 ) .</p><p>To reduce the length of that DS, we need to zero at least one edge in DS. Hence, we need to decide which edges should be zeroed. We could zero either one or both edges. If the edge (nl, n2) is zeroed, then the parallel time reduces from 13 to 10. If (712,717) is zeroed, the parallel time reduces to 11. If both edges are zeroed, the parallel time reduces to 9.5. Therefore, there are many possible ways of edge zeroing, and we discuss the following three approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AP1: Multiple DS edge zeroing with maximum</head><p>PT reduction: This is a greedy approach that will try to get the maximum reduction of the parallel time at each clustering step. However, it is not always true that multiple DS edge zeroing could lead to the maximum PT reduction, because after zeroing one DS edge of a path, the other edges in that path may not be in the DS of the new graph. AP2: One DS zeroing of maximum weight edge: Considering the fact that a DS could become a SubDS by zeroing only one edge of this DS, instead of multiple-edge zeroing, we could zero only one edge at each step to make smaller reductions in the parallel time, but then perform more steps. For example, we could choose one edge to zero at each step, say, the largest weighted edge in DS. In Fig. <ref type="figure" target="#fig_4">2</ref>(a), the length of current DS (711,712,717) could be reduced more by zeroing edge (721,712) instead of edge <ref type="bibr">(722,</ref><ref type="bibr">717)</ref>. Zeroing the largest weighted edge may increase the complexity, but may not necessarily lead to a better solution. AP3: One DS edge zeroing with low complexity: Instead of zeroing the highest edge weight, we could allow for more flexibility and choose to zero the one DS edge that leads to a lowcomplexity algorithm. Determining a DS for a clustered DAG could take at least O(v + e ) time if the computation is not done incrementally. Repeating this computation for all steps will result in at least O ( u 2 ) complexity. Thus, it is necessary to use an incremental computation of DS from one step to the next to avoid the traversal of the entire DAG at each step. A proper selection of a DS edge for zeroing simplifies the incremental computation of the DS at the next step.</p><p>It is not clear how to implement APl or AP2 with a low complexity, and also there is no guarantee that APl or AP2 will be better than AP3. We use AP3 to develop our algorithm.</p><p>1. E G = 0. (IEG = V.</p><p>2. Coiiipute blevel for eacli node aid set tlevel = 0 for eaclr eiitry node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>cluster. 4. While there is an uiiexauild node D o 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.</head><p>decreases in a iiiaxiniuiii degree. If all zeroiiigs incrcase t l r w l ( n j ) . in a unit cluster. 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">EndWhile</head><p>Every tmk is marked unezamaned and assuiiied to coirstitute one uiit Find a free node iif with highest priority froni U E G .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Merge I L ~</head><p>with the cluster of oue of its predecessors such that t l e u r l ( n f ) remains</p><p>Update the priority values of ,if's successors.</p><p>U E G = L'EG -{U,}; EG = EG t {nr}.</p><p>Fig. <ref type="figure">3</ref> 3)</p><p>4)</p><p>The DSC-I algorithm.</p><p>Since one of the goals is G3, i.e., reducing the number of unnecessary clusters and increasing the efficiency, we also need to allow for zeroing non-DS edges. The questions is when to do SubDS zeroing. One approach is to always zero DS edges until the algorithm stops, and then follow up with non-DS zeroing. Another approach, followed in this paper, is to interleave the non-DS zeroing with DS zeroing, which gives more flexibility and results in a lower complexity. Since backtracking could result in high complexity, we would like to avoid it as much as possible. For this reason, we need to impose the nonincrease in the parallel time constraint from one step to the next as follows:</p><p>PT-1 2 PT;.</p><p>Sarkar imposes this constraint explicitly in his edgezeroing process by comparing the parallel time at each step. Here we use an implicit constraint to avoid the explicit computation of parallel time in order to reduce the complexity. In the next subsection, we present an initial version of DSC algorithm and then identify its weaknesses so that we can improve its performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. DSC-I: An Initial Version of DSC</head><p>An algorithmic description of DSC-I is given in Fig. <ref type="figure">3</ref>. An unexamined node is called free if all of its predecessors have been examined. Fig. <ref type="figure">4</ref> shows the initial status (step 0), shown in Fig. <ref type="figure">4</ref>(a), and step i of DSC-I, corresponding to the While loop iteration i at Fig. <ref type="figure">3</ref>, 1 5 i 5 5, shown in Fig. <ref type="figure">4</ref>(b)4(f), in scheduling a DAG with five tasks. The thick paths of each step represent DS's, and the dashed edges represent pseudo execution edges. We provide an explanation of the DSC-I algorithm in Fig. <ref type="figure">3</ref>.</p><p>Priority Dejinition and DS Identijcation: (Line 5 in Fig. <ref type="figure">3</ref>) Based on (I), we define the priority for each task at each step as follows: PRIO(nf) = tfevel(lzf) + blevel(nf).</p><p>Thus, we can identify a DS node as the one with the highest priority. In Fig. <ref type="figure">4</ref>(a), the DS nodes are n l ? 712, and 725, and they have the highest priority value, 14.5.</p><p>The Topological Order for Task and Edge Examination: (Line 5 in Fig. <ref type="figure">3</ref>) During the execution of DSC-I, the graph consists of two parts, the examined part, EG, and the unexamined part, UEG. Initially, all nodes are marked unexumined,  <ref type="bibr">(See Fig. 4(a)</ref>.) DSC-I selects only an unexamined free task n f with the highest priority. Then it examines an incoming edge of this task for zeroing or not zeroing. In Fig. <ref type="figure">4</ref>, tasks selected at step 1, 2, 3, 4, and 5 are n1, nz. 714, n3, and 715, respectively. Notice that the selected task n f belongs to a DS if there are free DS nodes; otherwise, it belongs to a SubDS. In Fig. <ref type="figure">4</ref>, step 1 selects task 711, which is in a DS; but step 3 selects task n4, which is not in a DS. The order of such selection is equivalent to topologically traversing the graph.</p><p>The reason for following a topological order of task examination and zeroing one DS edge is that we can localize the effect of edge zeroing on the priority values for the rest of the unexamined tasks. In this way, even though zeroing changes the priorities of many nodes, DSC-I needs to compute only the changes for nodes that are immediate successors of the currently examined task n f . (See Line 7 of Fig. <ref type="figure">3</ref>.) For Fig. <ref type="figure">4</ref>(b), after n1 is examined, the priority of n5 does not need to be updated until one of its predecessors is examined at step 2. More explanations are given by Property 3.2.</p><p>Edge-Zeroing Criterion: (Line 6 in Fig. <ref type="figure">3</ref>) The criterion for accepting a zeroing is that the value of tlevel(nf) of the highest-priority free node does not increase by such a zeroing. If it does, then such zeroing is not accepted, and n f becomes a new cluster in EG. Notice that by reducing tlevel(nf), all paths going through n f could be compressed, and as a result, the DS length could be reduced. In Fig. <ref type="figure">4</ref>(c), 722 is selected and (n1. n2) is zeroed. The zeroing is accepted because tlevel(n2) reduces from 6 to I .</p><p>Task Placement in EG: (Line 6 in Fig. <ref type="figure">3</ref>) When an edge is zeroed, then a free task n f is merged to the cluster where one of its predecessors resides. Our scheduling heuristic adds a pseudo edge from the last task of this cluster to n f if they are independent. In Fig. <ref type="figure">4</ref>(d), n4 is selected, and the zeroing of (nl,n4) is accepted, because tlevel(n4) reduces from 3 to 2.5. A pseudo edge <ref type="bibr">(722,</ref><ref type="bibr">714)</ref> is added in EG. The DSC-I satisfies the following properties.</p><p>Property3.1: PTi-1 2 PTi.</p><p>Equation (1) implies that reducing the priority value of tasks would lead to the reduction of the parallel time. Thus, the constraint that tlevel values do not increase implies this property. A formal proof is given in Section IV-E.</p><p>In DSC-I, tlevel and blevel values are reused after each step, leading to a reduction of the complexity when determining DS nodes. The following property explains how the topological traversal and the cluster-merging rule of DSC-I reduces the complexity.</p><p>Property 3.2: For the DSC-I algorithm, tlevel(n,) remains unchanged if n, E EG and blevel(n,) remains unchanged if n, E UEG.</p><p>Proof: If n, E UEG, then the topological traversal implies that all descendants of n, are in UEG. Since n, and its descendants are in separate unit clusters, blevel(n,) remains unchanged before it is examined. Also, for nodes in EG, all clusters in EG can be considered "linear" by counting the pseudo execution edges. When a free node is merged with a "linear" cluster, it is always attached to the last node of that "linear" cluster. Thus, tlevel( n,) remains unchanged after n, has been examined. Proof: From Property 3.2, the priority of a free node n f can be easily determined by using</p><formula xml:id="formula_0">tlevel(nf) = max {tlevel(nj) + rJ + c J , f } . n,EPRED(nf)</formula><p>Once tlevel(n,) is computed after its examination at some step, where nJ is the immediate predecessor of n f , this value is propagated to tlevel(nf). Afterward tlevel(n,) remains unchanged and does not affect the value of tlevel(nf).</p><p>At each step of DSC-I, we maintain a priority list FL that contains all free tasks in UEG. This list can be implemented by using a balanced search tree data structure. At the beginning, FL is empty and there is no initial overhead in setting up this data structure. The overhead occurs while maintaining the proper order among tasks after an insertion or deletion of a task. This operation costs O(1og IFLI), where JFLJ 5 v.</p><p>Because each task in a DAG is inserted to and deleted from FL once during the entire execution of DSC-I, the total complexity of maintaining FL is at the most 2vlogv.</p><p>The main computational cost of DSC-I algorithm is spent in the While loop (Line 4 in Fig. <ref type="figure">3</ref>). The number of steps (iterations) is v . For Line 5, each step costs O(1ogv) â‚¬or finding the head of FL, and v steps cost O(w1ogv). For Line 6, each step costs O(IPRED(nf)() when examining the immediate predecessors of task n f . For the II steps, the cost is CnfEI., O(IPRED(nf)() = O ( e ) . For Line 7, each step costs O( (SUCC(nf)J) to update the priority values of the immediate successors of r i f , and, similarly, the cost for 2' steps is O(e). When a successor of nf is found free at Line 7, it is added to FL, and the overall cost is O(w log w ) . Thus, the total cost for 0</p><formula xml:id="formula_1">DSC-I is O(e + ZJ log U ) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. An Evaluation of DSC-I</head><p>In this subsection, we study the performance of DSC-I for some DAG's and propose modifications to improve its performance. Because a DAG is composed of a set of join and fork components, we consider the strengths and weaknesses of DSC-1 in scheduling fork and join DAG's. Then we discuss a problem arising when zeroing non-DS edges as a result of the topological ordering of the traversal.</p><p>DSC-Zfor fork DAG's: Fig. <ref type="figure" target="#fig_7">5</ref> shows the clustering steps of DSC-I for a fork DAG. Without loss of generality, assume that the leaf nodes in Fig. <ref type="figure" target="#fig_7">5</ref>(aj are sorted such that rj + /3j 2 r3+1 + &amp; + l , j = 1 : m -1. The steps are described below. It is easy to verify that DSC-I always zeros DS edges at each step for a fork DAG, and the parallel time strictly decreases monotonically. It turns out that the DSC-I algorithm is optimal for this case; a proof is given in Section V. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DSC-Z for Join DAG's:</head><p>Let us consider the DSC-1 algorithm for join DAG's. Fig. <ref type="figure">6</ref> shows a join DAG, the final clustering, and the optimum clustering. Again, we assume that rj + /3j 2 rj+l + &amp;+l, j = 1 : m -1. The steps of DSC-I are described below. Fig. <ref type="figure">6</ref>(a) shows the initial clustering. Nodes nlrn2,-..,nm are free. One DS is (nlln,). Step 1 selects n1, which is in DS. No incoming edge exists for n1, and no zeroing is performed. The DS is still (nl , n,) after step 1. Now n, becomes partially free. A node is partially free if it is in UEG and at least one of its predecessors has been examined, but not all of its predecessors have been examined. Step 2 selects 712, which is not in DS. No incoming edge exists, and n2 remains in a unit cluster in EG. Step m + 1 selects n,, which is now in the DS, and then (71.1, n,) is zeroed. The final result of DSC-I is shown in Fig. <ref type="figure">6</ref>(b), which may not be optimal. The optimal result for a join DAG shown in Fig. <ref type="figure">6</ref>(cj and the previous optimal solution for a fork are symmetrical.</p><p>The join example shows that zeroing only one incoming edge of n, is not sufficient to attain the optimum without backtracking. In general, when a free node is examined, zeroing multiple incoming edges of this free node instead of zeroing one edge could result in a reduction of tlevel in a maximum possible degree. As a consequence, the length of DS or SubDS going through this node could be reduced even more substantially. To achieve such a greedy goal, a low-complexity minimization procedure that zeros multiple incoming edges of the selected free node is needed to be incorporated in the DSC algorithm.</p><p>Chretienne [3] has proposed an optimal algorithm for a fork and join, which zeros multiple edges. The complexity of his algorithm is O(mlogB), where B = m i n { C z l ~i , P 1 + T I } + 7,. Al-Mouhamed [ 11 has also used the idea of zeroing multiple incoming edges of a task to compute a lower bound for scheduling 'a DAG, using an O ( m z ) algorithm; but no feasible schedules that reach the bound are produced by his algorithm. Since we are interested in lower-complexity algorithms, we use a new optimum algorithm with O ( m log m ) complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dominant Sequence Length Reduction Warranty (DSR W):</head><p>We describe another problem with DSC-I. When a DS node ny is partially free, DSC-I suspends the zeroing of its incoming edges and examines the current non-DS free nodes according to a priority-based topological order. Assume that tlevel(n,) could be reduced by 6 if such a zeroing were not suspended.</p><p>We should be able to get at least the same reduction for tlevel(n,) at some future step when DSC-I examines the free node ay. Then the length of DS going through ny will also be reduced. However, this is not the case with DSC-I.</p><p>Fig. <ref type="figure">4</ref>(c) shows the result of step 2 of DSC-I after n2 is merged to <ref type="bibr">CLUST(n1)</ref>. The new DS depicted by the thick arrow is ( n ~~ 7 1 ~~ ns), and it goes through partially free node 715. If (n2,ns) were zeroed at step 3, tlevel (ng) would have been decreased by 6 = 5. Then the length of the current DS (711 712, n j ) would also have been reduced by 5. But because of the topological traversal rule, a free task n4 is selected</p><formula xml:id="formula_2">at step 3, because PRIO(n4) = 9 2 PRlO(n3) = 4.5.</formula><p>Then 714 is merged with CLUST(nl), because tlevel(n4) can be reduced from 3 to 7-1 + 7-2 = 2.5. Such zeroing affects the future compression of DS (nl, 712, n5). When n j is free at step 5 , tlevel (ng) = 7 1 + 7-2 + ~2 . 5 = 7.5, and it is impossible to reduce tlevel ( 7 ~5 ) further by moving it to CLUST(n2). This is because n5 will have to be linked after 714, which makes tlevel ( n 5 ) = 7-1 + 7-2 + 7-4 = 8.5.</p><p>To guarantee the effective reduction of tlevel(n,) of a partially free DS node ny at the future step, we impose a condition called DSRW. The basic idea is to avoid the edgezeroing operations that affect the reduction of tlevel <ref type="bibr">(n,)</ref>. The details are described in Section IV-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Iv. THE FINAL FORM OF THE DSC ALGORITHM</head><p>The main improvements to DSC-I are the minimization procedure for tlevel ( n f ) , maintaining a partially free list (PFL) and imposing the constraint DSRW. The DSC algorithm is described in Fig. <ref type="figure" target="#fig_10">7</ref>.</p><p>The clustering sequence of Fig. <ref type="figure" target="#fig_10">7</ref> starts from examining the entry tasks of a DAG. We call it forward clustering. There is another way to obtain a schedule for a DAG. First, invert this DAG by changing the directions of all precedence edges, obtain a schedule using Fig. <ref type="figure" target="#fig_10">7</ref> for the inverted DAG, and then invert this schedule to produce a schedule with the same length for the original DAG. We call it backward clustering. These two approaches may have different performance because of different precedence structures. In fact, in Section V-C, we show that forward clustering cannot obtain the optimum for certain trees, but backward clustering can. The complete version of the DSC algorithm performs both forward and backward clustering and chooses the solution with a shorter schedule. We mainly analyze the properties of DSC with respect to forward clustering. Backward clustering has the same properties, except when dealing with an inverted graph, and it does not increase the order of the algorithm complexity.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Priority Lists</head><p>At each clustering step, we maintain two node priority lists: a partially free list, PFL, and a free list, FL, both sorted in a descending order of their task priorities. When two tasks have the same priority, we choose the one with the most immediate successors. If there is still a tie, we break it randomly. Function h e a d ( l ) returns the first node in the sorted list L, which is the task with the highest priority. If L = {}, h e a d ( l ) = NULL, and the priority value is set to 0.</p><p>The tlevel value of a node is propagated to its successors only after this node has been examined. Thus, the priority value of a partially free node can be updated by using only the tlevel from its examined immediate predecessors. Because only part of its predecessors are considered, we define the priority of a partially free task as follows:</p><formula xml:id="formula_3">pPRIO(n,) = ptlevel(n,) + blevel(n,), ptlevel( 71,) = n , E ~~~~( n , ) max n EG {tlevel(n,) + 7j + cj.,}.</formula><p>In general, pPRIO(n,) 5 PRIO(n,), and if a DS goes through an edge (njlny), where rij is an examined predecessor of n,, then we have pPRIO(n,) = PRIO(nj) = PRIO(n,). By maintaining pPRIO instead of PRIO, the complexity is reduced considerably. As we prove later, maintaining pPRIO does not adversely affect the performance of DSC, because it can still correctly identify the DS at each step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The Minimization Procedure for Zeroing Multiple Incoming Edges</head><p>To reduce tlevel <ref type="bibr">(n,)</ref> in DSC, a minimization procedure that zeros multiple incoming edges of free task n, is needed. An optimal algorithm for a join DAG has been described in [8], and an optimal solution is shown in Fig. <ref type="figure">6(c</ref>). The basic procedure is to first sort the nodes such that rJ + BJ 2 7]+1+ &amp;+I j = 1 : m -1, and then to zero edges from left to right, as long as the parallel time reduces after each zeroing, i.e., linear searching of the optimal point. This is equivalent to satisfying the condition (E;:: r3 5 ,&amp;) for each accepted zeroing. Another optimum algorithm for join is to determine the optimum point k , first by using a binary search between 1 and m such that ( E : : : rJ 5 /&amp;), and then zero all edges to the left of k .</p><p>We modify the optimum binary search join algorithm to minimize tlevel <ref type="bibr">(n,)</ref> when n, is free. The procedure is shown in Fig. <ref type="figure">8</ref>. Assume that PRED(n,) = (711. n2,. . . ~ a m } . Notice 2. Let h be the maximum integer from 2 to m such that for 2 5 I 5 h node ne satisfies the following constraint:</p><p>If nt is not in <ref type="bibr">CLUST(nl)</ref>. then n, does not have any children other than R..</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Find the optimum point k between 1 and h using the binary search algorithm.</head><p>Zero (nl,n.) up to (n&amp;,n%) so that tfeuel(n,) is minimum.</p><p>The minimization procedure for DSC. Fig. <ref type="figure">8</ref>. that all predecessors are in EG, but now CLUST(nl),..., CLUST(n,) may not be unit clusters. We sort the predecessors of n, such that tlevel ( n j ) + ~j + ~j , ~ 2 tlewel(nj+l) + ~j + 1 + cj+l,,. To reduce tlevel (n,), we must zero the edge (nl,n,). A problem arises when the algorithm zeros an edge of a predecessor np, which has other children than n,.</p><p>When task np is moved from CLUST(n,) to CLUST(nl), the tlevel of the children of np will be affected. As a result, the length of paths going through those children will most likely increase. The constraint P T i -1 2 PTi may no longer hold, and maintaining task priorities becomes complicated. To avoid such cases, we exclude from the minimization procedure predecessors* that have children other than n,, unless they are already in CLUST(nl). The binary search algorithm in Fig. <ref type="figure">8</ref> finds the best stopping point k, and those predecessors nj of nz (2 5 j 5 k) that are not in CLUST(n1) must be extracted from their corresponding clusters and attached to CLUST(n1).</p><p>In computing the new tlevel (n,), those predecessors of n, in CLUST(nl) are ordered for execution in an increasing order of their tlevel values. The tlevel ordering could be performed before the binary searching.</p><p>We determine the complexity of this procedure as follows. The tlevel ordering of all predecessors is done once at a cost of O(m1ogm). The ordering for step 1 at Fig. <ref type="figure">8</ref> costs O(m1ogm). The binary search computes the effect of the ordered predecessors to tlevel(n,) at a cost of O(m) at each step. The total number of search steps is O(1ogm). Thus, the total cost of the above algorithm is O ( m log m). If linear search were used instead, the total cost would increase to O ( m 2 ) , because the number of search steps would increase to m.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C, Imposing Constraint DSRW</head><p>As we saw previously, when there is no DS going through any free task and there is one DS passing through a partially free node ny, then zeroing non-DS incoming edges of free nodes can affect the reduction of tlevel (n,) in the future steps. We impose the following constraint on DSC to avoid such side effects.</p><p>DSRW: Zeroing incoming edges of a free node should not affect the reduction of ptlevel(n,) if it is reducible by zeroing an incoming DS edge of ny.</p><p>There are two problems that we must address in the implementation of DSRW. First, we must detect whetherptlevel(n,) is reducible. Second, we must make sure that DSRW is satisfied.</p><p>1) To detect the reducibility of ptlevel(n,), we must examine the result of the zeroing of an incoming DS edge of ny . To find such an incoming DS edge, we examine only the result of the zeroing each incoming edge ( n j , n,)</p><p>where nj is a predecessor of ny and nj E EG. As we prove in Section IV-E, ptlevel(n,) = tZevel(n,). This implies that such partial reducibility is sufficient to guarantee that if the parallel time was reducible by zeroing the DS incoming edges of a partially free DS node ny, then rlevel (ny) is reducible when ny becomes free. Hence, the DS can be compressed at that time.</p><p>2) After detecting the partial reducibility at step i for node ny, we implement the constraint DSRW as follows.</p><p>Assume that np is one examined predecessor of ny, and that zeroing ( n p , nY) would reduce ptlevel(n,). Then no other nodes are allowed to move to CLUST(n,) until ny becomes free.</p><p>For the example in Fig. <ref type="figure">4</ref>(c), ny = 715, ptleveZ(n5) = 71 + 72 -k ~2 , 5 = 7.5, pPRIO(n5) = 9.5, PRIO(n3) = 4.5, and PRIO(n4) = 9. We have the condition that pPRIO(n5) &gt; PRIO(n4), which implies, by Theorem 4.1 in Section IV-E, that DS goes through partially free node 725. In addition, ptlevel(n5) could be reduced if ( ~~2 , 7 2 5 ) were zeroed. Then CLUST(n2) cannot be touched before n5 becomes free. Thus, 123 and n4 cannot be moved to CLUST(n2), and they remain in the unit clusters in EG. When n5 finally becomes free, (n2, n5) is zeroed and PT is reduced from 9.5 to 9.</p><p>It should be pointed out that DSRW is a greedy heuristic that attempts to reduce the parallel time as much as possible. It is always possible that this constraint could prevent the generation of an optimal solution. In Section VI, we examine the performance of DSC on scheduling randomly generated DAG'S and compare it with other algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. A Running Trace of DSC</head><p>We demonstrate the DSC steps by using a DAG example shown in <ref type="bibr">Fig. l(a)</ref>. The steps 0, 1, 2, 5, 6, and 7 are shown in Fig. <ref type="figure" target="#fig_13">9</ref>(a)-9(f), respectively. The thick paths are the DS's and dashed pseudo edges are the execution order within a cluster. We provide an explanation for each step below. The superscript of a task node in FL or PFL indicates its priority value.</p><p>Initially, we have the following conditions: UEG = ( n i I n 2 , n 3 , n 4 , n j , n 6 , n ~} FL = { n!+l3, T Z : " . ~, n:+7.5} PTO = 13 PFL = {}. n1 is selected, tlevel (nl) = 0, and it cannot be reduced, so CLUST(n1) remains a unit cluster. Then we have the following condition: UEG = { ~1 2 , n 3 , ~~4 , 7 2 5 , 7 6 , ~~7 } = 13 FL = in;+9, ni.5+8 nO+9.5 nO+7.5</p><formula xml:id="formula_4">&gt; 4 I 5 1 P F L = O .</formula><p>722 is selected, n, = n2, nY = NULL, and flevel (722) = 4. By zeroing the incoming edge (n1,nz) of n 2 , tfevef (722) reduces to 1. Thus, this zeroing is accepted, and after that step, we have the following condition: UEG = (723, ~~, T z s , n6, 717) P T 2 = 10 FL = {nA.5+8, nO+9.5 , nO+7.5 } PFL= {TI;"}. d) n3 is selected, n, = 713 with PRIO(n3) = 1.5 + 8 = 9.5, and ny = 727 with pPRIO(n7) = 10. Notice that by zeroing (n2,n7), the tfevef (717) reduces to 8.5. Thus, we impose the DSRW constraint. Since zeroing (711,718) affects tZevef <ref type="bibr">(n,)</ref>, this zeroing is not accepted, because of DSRW. The tlevef (723) remains the same, and CLUST(n3) remains a unit cluster in EG. ( nq, 716) are zeroed by the minimization procedure. Node 72.4 is ordered for execution first, because tlevef (714) = 0, which is smaller than tlevef (n3) = 1.5. Then tfevef (n6) is reduced to 2.5, and we have the following condition:</p><formula xml:id="formula_5">UEG = (717) PT6 = 10 FL = {n;"} PFL = {}.</formula><p>g) 727 is selected, and (712,717) is zeroed so that tfevel (717) is reduced from 9 to 7. Then we have the following condition:</p><formula xml:id="formula_6">UEG={} P T 7 = 8 F L = { } PFL={}.</formula><p>Finally, three clusters are generated with PT= 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. DSC Properties</head><p>In this subsection, we study several properties of DSC related to the identification of DS, the reduction of the parallel time, and the computational complexity. Theorem 4.1 indicates that DSC (Lines 6 and 9 in Fig. <ref type="figure" target="#fig_10">7</ref>) correctly locates DS nodes at each step, even if we use the partial priority pPRI0. Theorems 4.2 and 4.3 show how DSC warranties guarantees the reduction of the parallel time. Theorem 4.4 studies the complexity of DSC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correctness in heating DS Nodes:</head><p>The goal of DSC is to reduce the length of DS's in a sequence of steps. To do that, it must correctly identify unexamined DS nodes. For Lemmas 4.1 and 4.2 and Theorem 4.1, we assume that a DS goes through UEG, because it is only then that DSC needs to identify and compress DS. If DS does not go through UEG, but only through EG, then all DS nodes have been examined, and the DS can no longer be compressed, because backtracking is not allowed in general.</p><p>Since the DSC algorithm examines the nodes topologically, the free list FL is always nonempty. By definition, all tasks in FL and PFL are in UEG. It is obvious that a DS must go through tasks in either FL or PFL when it goes through UEG.</p><p>The interesting question is whether a DS also goes through the heads of the priority lists of FL and PFL, because then the algorithm would correctly locate DS nodes for examination. The answer is given in the following lemmas and in Theorem 4.1.</p><p>Lemma 4.1: Assume that n, = head(FL) after step i. If there are DS's going through free nodes in FL, then one DS must go through n,.</p><p>Proof: At the completion of step i , the parallel time is PT, = PRIO(n,), where n, is a DS node. Assume that no DS goes through n,. Then one DS must go through another nonhead free node n f . This implies that PRIO(nf) = PT, &gt; PRIO(n,), which is a contradiction, because n, has the highest priority in FL. ProoJ First, observe that the starting node of a DS must be an entry node of this DAG. If this node is in UEG, then it must be free, which is impossible, because the assumption says that DS's go through only partially free nodes in UEG. Thus, the starting node must be in EG. As a result, a DS must start from a node in EG and go through an examined node nJ to its unexamined partially free successor n p . Then, because they are in the same DS, we have the condition that PRIO(n,) = PRIO(n,) = pPRIO(n,). The proof now becomes similar to the previous lemma. Suppose that no DS goes through n,. We have the condition that pPRIO(n,) 5 PRIO(n,) &lt; PT, = PRIO(n,) = pPRIO(np), which contradicts the assumption that n, is the head of PFL.</p><p>Next we prove that pPRIO(n,) = PRIO(n,). Suppose pPRIO(n,) &lt; PRIO(n,). This implies that the DS, to which n, belongs, does not pass through any examined immediate predecessor of n,. As a result, DS must go through some other nodes in UEG. Thus, there exists an ancestor node n, of n, such that the DS passes through an edge ( 7 ~~, n , ) , where nq is the examined predecessor of n, and n, is partially free because it is impossible to be free by the assumptions of this lemma. We have the condition that pPRIO(n,) = PRIO(n,) = PRIO(ny) &gt; pPRIO(n,). which shows ny is not the head of PFL. This a contradiction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0</head><p>The following theorem shows that the condition PRIO(n,) 2 pPRIO(n,), used by DSC algorithm in Line 6 of Fig. <ref type="figure" target="#fig_10">7</ref>, correctly identifies DS nodes.</p><p>Theorem 4.1: Assume that n, = head(FL) and n, = head(PFL) after step 2, and that there is a DS going through UEG. If PRIO(n,) 2 pPRIO(n,), then a DS goes through n,. If PRIO(n,) &lt; pPRIO(n,), then a DS goes through n,, and there is no DS going through any free node in FL.</p><p>Proof: If PRIO(n,) 2 pPRIO(n,), then we show that a DS goes through 71,. First, assume that DS goes through FL or through both FL and PFL. Then, according to Lemma 4.1, it must go through n,. Next assume that DS goes through PFL only. Then, from Lemma 4.2, it must go through n,, implying that pPRIO(n,) = PRIO(n,) = PT, &gt; PRIO(n,), which is a contradiction, because PRIO(n,) 3 pPRIO(n,).</p><p>If PRIO(n,) &lt; pPRIO(n,), suppose that a DS passes a free node. Then, according to Lemma 4.1, PRIO(n,) = PT, 2 P R I O ( n y ) 2 pPRIO(n,), which is a contradiction again.</p><p>Thus, the DS's must go through only partially free nodes, and U The Warranty in Reducing Parallel Time: We show that during DSC clustering steps, the parallel time of the clustered graph monotonically decreases. Moreover, after any clustering step i, if there exists an algorithm that could reduce the parallel time of the clustered graph by zeroing some edge, then DSC will guarantee a reduction at some future step.</p><p>Lemma4.3: Assume that n, = head(FL) and ny = h e a d ( P F L ) after step i. The following is the parallel time for executing the clustered graph after step z of DSC: one of them must go through n, by Lemma 4.2.</p><p>PT; = max{PRIO(n,),pPRIO(n,)3 max {PRIO(n,)}}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>n , E E G</head><p>Proof: There are three cases in the proof.  Proof: For this proof, we rename the priority values of n, = head(FL), and n, = head(PFL) after step i -1, because PRIO(n,, i -1) and pPRIO(n,, il), respectively.</p><p>We need to prove that _&gt; PTi, where the following is true:</p><formula xml:id="formula_7">PTi-1 = max{PRIO(n,, i -l),pPRIO(n,, z -l), max { PRIO(n.,, i -1))) n,EEG PT; = m ~{ P R I O ( n ~, i ) , p PRIO(n;, i)! max { PRIO(n,,i)}}, 71 e EEG U { n , 1</formula><p>and n: and ng are the new heads of FL and PFL after step i.</p><p>Since n: is in the free list after step i -1, it must be in UEG, and also it must be either the successor of n, or independent of n,.</p><p>At step i, DSC picks up task n, to examine its incoming edges for zeroing. We consider the effect of such zeroing on the priority value of n:. Since the minimization procedure does not increase tlevel (n,), the length of the paths going through n, decreases or remains unchanged. Thus, the priority values of the descendants of n, could decrease, but could not increase. The priority values of other nodes in EG remain the same because the minimization procedure excludes those predecessors of n, that have children other than n,. Thus, if n: is the successor of n,, then PRIO(n:, i) 5 PRIO(n:, 2-1); otherwise, PRIO(n:, z) = PRIO(n:, i-1). Since PRIO(n:, z-1) 5 PT,-l, PRIO(~;, i) 5 miv1. Similarly, we can prove that PRIO(ng,i) 5 PT-1.</p><p>Next we prove that maxn~EEGu~n,~{PRIO(n,, i)}} 5 PT;-l. We have PRIO(n,,Z) 5 PRIO(n,,z-1) from the minimization procedure. We need to examine the effect of zeroing only for n, on the priorities of nodes in EG. The minimization procedure may increase the tlevel values of some predecessors of n,, say, n,; but it guarantees that the lengths of the paths going through np and n, do not increase. Thus, the new value of PRIO(n,) satisfies PRIO(n,,Z) 5 PRIO(n,, 2-1). Because</p><p>The minimization procedure may also increase the blevel values of some nodes in the cluster in EG to which n, is attached. A pseudo edge is added from the last node of that cluster, say, ne, to nz if ne and n, are independent.</p><p>If there is an increase in the priority value of ne, then the reason must be that adding this pseudo edge introduces a new path going through n, with longer length than the other existing paths for ne. Since the minimization procedure has considered the effect of attaching n, after ne on tlevel (n,), the length of paths will be less than or equal to PRIO(n,, i -1 j 5 PZ-1. Thus, PRIO(n,,i) 5 PTi-1. Similarly, we can prove that other nodes in CLUST(n,) satisfy this inequality. Since the priority values of nodes, say, no, that are not the predecessors of n,, or that are not in CLUST(n,), will not be affected by the minimization procedure, we have PRIO(n,, i -1) = PRIO(n,,i). Thus, max,,EEGu{n,) {PRIO(n,, i)} 5 Theorem 4.3: After step i of DSC, if the current parallel time is reducible by zeroing one incoming edge of a node We prove first that PRIO(n:,i) 5 PRIO(n,,i -1) 5 PT;-1, PRIO(n,,i) 5 PTi-1.</p><p>PTa-1. U in UEG, then DSC guarantees that the parallel time will be reduced at some step greater or equal to i + 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proo$</head><p>The assumption that the parallel time reduces by zeroing one edge (n,, n,) implies that a DS must go through UEG. This implies that the edge (n,, n,) belongs to all DS's that go through UEG; otherwise, the parallel time is not reducible. There are three cases.</p><p>n, E EG and n, is free. We prove that the node n, must be the head of FL. If it is not, then another free node in UEG, n f , must have the same priority and thus belong to a DS. Because all DS's go through <ref type="bibr">(n,, n,)</ref>, n f must be a successor of n,. Then n, and n f cannot both be free, which is a contradiction.</p><p>Also, since F' T; = tlevel(n,) + blevel(n,) is reducible by zeroing <ref type="bibr">(n,,n,)</ref>, and since blevel(n,) does not change by such a zeroing, tlevel (n,) is reducible. Thus, during the DSC execution, n, = head(FL) will be picked up at step i + 1, and since tlevel(n,) is reducible, the minimization procedure will accept the zeroing of (n,, n,), and the parallel time will reduce at that step.</p><p>n, E EG and n, is partially free. We prove that ns must be the head of PFL. We show it by contradiction. Assume  <ref type="bibr">(n,,n,)</ref>. If, from z + 1 to step j, the parallel time has been reduced, then the theorem is true. If the parallel time has not been reduced, then at least one DS has not been compressed, and all DS's still go through (n,, n,), because the minimization procedure guarantees that no other DS's will be created. Thus, the parallel time will be reducible at step j by zeroing (n,, nS), and the proof becomes the same as in the above cases.</p><formula xml:id="formula_8">that n f ( n f # n,)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0</head><p>The following corollary is the direct result of Case 2 above. Corollary 4.3: Assume that ny E PFL, ny E DS at step i, and that zeroing of an incoming edge of ny from its scheduled predecessor would have reduced PT by 6. Then DSC guarantees that when ny becomes free at step j 0' &gt; i), PT can be reduced by at least S.</p><p>The Complexity: Lemma 4.4: After a node n, becomes free or partially free, bleweZ(n,) remains unchanged until n, is examined. Let nj be a predecessor of n,. tlevel ( n j ) remains unchanged from the step when nj becomes examined to the step when n, is examined.</p><p>Proof: Referring to Property 3.2 DSC-I, DSC is the same as DSC-I, except that the minimization procedure changes tlevel values of some examined predecessors, say, nh, of the currently selected free task, say, n,. But n h does not have any children other than n,. Thus, after a node n, becomes partially free or free, but before it is examined, the tlevel value of its 0 Theorem 4.4: The time complexity of DSC is O((w + e ) log w), and the space complexity is O(v + e ) .</p><p>Proof: The difference in the complexity between DSC-I and DSC results from the minimization procedure within the While loop in Fig. <ref type="figure" target="#fig_10">7</ref>. In DSC, we also maintain PFL; but the cost for the w steps is the same O(v10gv) when we use the balanced search trees. Therefore, for Lines 4 and 5 in Fig. <ref type="figure" target="#fig_10">7</ref>, w steps cost O(v1ogw). For Lines 7 and 8 (or for Lines 9 and lo), the minimization procedure costs O(IPRED(n,)l log I PRED(n,)l) at each step. Since En,EV IPRED(n,)l = e and IPRED(n,)l &lt; U , w steps cost O ( e log w). When imposing DSRW, the predecessors of a partially free node are checked, and the overall cost is at the most O(w + e).</p><p>For Line 13, the tlevel values of the successors of n, are updated. Those successors could be in PFL, and the list needs to be rearranged, because their pPRIO values could be changed. The cost of adjusting each successor in PFL is O(log IPFLI), where IPFLl &lt; U . The step cost for Line 13 is O(JSUCC(n,)llogv). Since ISUCC(n,)l = e, the total cost for maintaining PFL dunng w steps is O(e log w).</p><p>Also, for Line 13, when one successor becomes free, it needs to be added to FL with cost O(logIFLI), where lFLl 5 w.</p><p>Since there are a total of ' U task that could become free during w steps, the total cost in Line 13 spent for FL during v steps is O(v10gw). Notice that according to Lemma 4.4, after n, has been moved to EG at Line 13, its tlevel value will not affect the priority of tasks in PFL and FL in the rest of the steps. Thus, the updating of FL or PFL occurs only once with respect to each task. Therefore, the time complexity of DSC is O( ( e + v) log U). The space needed for DSC is to store the DAG and FLPFL. The space complexity is O(w + e). 0 examined predecessors will remain unchanged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>v. PERFORMANCE BOUNDS AND OFTIMALITY OF DSC</head><p>In this section, we study the performance characteristics of DS. We give an upper bound for a general DAG and prove the optimality for forks, joins, coarse-grain trees, and a class of fine-grain trees. Since this scheduling problem is NPcomplete for a general fine-grain tree and for a DAG that is a concatenation of a fork and a join (series parallel DAG) [3],</p><p>[ 5 ] , the analysis shows that DSC not only has a low complexity but also attains an optimality degree that a general polynomial algorithm could achieve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Pegormance Bounds for General DAG's</head><p>A DAG consists of fork <ref type="bibr">(F,)</ref> and/or join <ref type="bibr">(J,)</ref> structures such as the ones shown in Figs. <ref type="figure" target="#fig_8">5(a</ref>) and 6(a). In <ref type="bibr">[8]</ref>, we define the grain of DAG as follows.</p><p>Let the following conditions exist:</p><p>Then the granularity of G is: g(G) = minnZEv{g,} where</p><p>We call a DAG coarse grain if g(G) 2 1. For a coarse-grain DAG, each task receives or sends a small amount of communication compared to the computation of its neighboring tasks.</p><p>In [SI, we prove Theorems 5.1, 5.2, and 5.3. Theorem 5.1: For a coarse grain DAG, there exists a linear clustering that attains the optimal solution.</p><p>Theorem 5.2: Let ITopt be the optimum parallel time, and let PTl, be the parallel time of a linear clustering. Then PTlc 5</p><p>(1 + &amp;)FTOpt. For a coarse-grain DAG, PTlc 5 2 x PTo,t.</p><p>The following theorem is a performance bound of DSC for a general DAG. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0">B. Optimality for Join and Fork</head><p>Theorem 5.4: DSC derives optimal solutions for fork and join DAG's.</p><p>Proofi For a fork, DSC performs the exact same zeroing sequence as DSC-I. The clustering steps are shown in Fig. <ref type="figure" target="#fig_7">5</ref>. After n, is examined, DSC will examine free nodes ~~1 , 7 2 2 , . . . . n, in a decreasing order of their priorities. The priority value for each free node is the length of each path &lt; n,, n1 &gt;, . . -, &lt; n,, n,, &gt;. If we assume that P k + ~k 2 /3k+l + ~k + l for 1 5 IC 5 m -1, then the nodes are sorted as nl, n2, . . . , n, in the free list FL. We first determine the optimal time for the fork, and then show that DSC achieves the optimum. Assume that the optimal parallel time to be PTOpt. If PRIO(nh) = ~, + -r h + / 3 h &gt; PTopt for some h, then pi must have been zeroed for i = 1 : h; otherwise, we have a contradiction. All other edges i &gt; h need not be zeroed, because zeroing such edge does not decrease PT, but could increase PT. Let the optimal zeroing stopping point be h, and assume that &amp;+I = rm+l = 0. Then the optimal PT is PTO,, = 7, + max(C,,l T ~, Ph+l + T ~+ I ) . 1) If h &lt; IC, then E,"=, rJ &lt; E,"=, r3 I h +n I &amp;+I + ~h + 1 . Thus, nopt = ~, + l j j h + i + n + i L Tr++lo,,+rk 1 7, + Inax(C,=l 7,. Pk+l + n + ~) = PTd,,. 2) If h &gt; IC, then since E,"=, rJ 2 E , = l rJ &gt; I(jk+l + 7 k + 1 2 Yh+, + ~h + l , we have the condtion that PTopt =</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DSC zeroes as many</head><formula xml:id="formula_9">T, + E:=, 7, 2 7x + mlax(C,=l r J . P k + l + n + 1 ) = h k k + l k PTdsc.</formula><p>There is a contradiction in both cases.</p><p>For a join, the DSC uses the minimization procedure to minimize the tlevel value of the root, and the solution and the 0 optimal result for a fork are symmetrical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Optimality for In-Trees and Out-Trees</head><p>An in-tree is a directed tree in which the root has outgoing degree 0, and other nodes have the outgoing degree 1. An outtree is a directed tree in which the root has incoming degree 0, and other nodes have the incoming degree 1.</p><p>Scheduling in-trees and out-trees is still NP-complete in general as shown by Chretienne [ 5 ] , and DSC will not give the optimal solution. However, DSC will yield optimal solutions for coarse-grain trees and a class of fine-grain trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coarse-Grain Trees:</head><p>Theorem 5.5: DSC gives an optimal solution for a coarsegrain in-tree.</p><p>Proofi Since all paths in an in-tree go through the tree root, say, n,, F T = tlevel(n,) + blevel(n,) = tleveZ(n,) + 7,.</p><p>We claim that tlevel (n,) is minimized by DSC. We prove it by induction on the depth of the in-tree (d). When d = 0, it is trivial. When d = 1, it is a join DAG, and tlevel <ref type="bibr">(n,)</ref> is minimized. Assume that it is true for d &lt; IC.</p><p>When d = IC, let the predecessors of root 71, be n l , . . . , n,.</p><p>Since each sub-tree rooted with n, has depth &lt; IC and the disjoint subgraphs cannot be clustered together by DSC, DSC will obtain the minimum tlevel time for each n3 where 1 5 j 5 m according to the induction hypothesis. (DSC will not zero any more edges, because of the coarse-grain condition. DSC might zero ( n 2 , n,) when y(G) = 1, but tlevel <ref type="bibr">(n,)</ref> does not decrease.)</p><p>We need to prove that tlevel (n,) is as small as possible. Because the tree is coarse grain, by Theorem 5.1, linear clustering can be used for deriving the optimal solution. Thus, we can assume that S' is an optimal schedule that uses "0 Fig. <ref type="figure">11</ref>. A single-spawn out-tree named Tk+' with height h = 6 + 1. 2) If, in S*, the zeroed incoming edge of nz is not ( n l j n z ) , say it is (nm, n z ) . Thus, we have the following condition: 0 DSC solves an in-tree in time O(.ulogw), where .u is the number of nodes in this tree. It can be verified that the condition g(G) 2 1 for the in-tree optimality of DSC can be relaxed as g(J,) 2 1 for all join structures J, in this tree. Under the same or similar condition, <ref type="bibr">Chretienne [4]</ref> and <ref type="bibr">Anger,</ref><ref type="bibr">Hwang,</ref><ref type="bibr">and Chow [ 2 ]</ref> developed O ( v ) optimal tree scheduling algorithms. These two algorithms are specific to only this kind of tree.</p><p>For an out-tree, the forward clustering of DSC may not find the optimum directly. But for the inverted graph, the backward clustering can obtain the optimum, because an inverted out-tree is an in-tree.</p><p>Fine-Grain Trees: Finding optimal solutions for general fine-grain trees is NP-complete. However, DSC is able to obtain optimum for a class of fine-grain trees. A single-spawn out-tree is an out-tree such that at most one successor of a nonleaf tree node, say, n,, can spawn successors. Other successors of n, are leaf nodes. A single-merge in-tree is an inverse of a single-spawn out-tree. Examples of such trees are shown in Fig. <ref type="figure">10</ref>. Theorem 5.6: Given a single-spawn out-tree or a singlemerge in-tree with an equal computation weight w for each task and an equal communication weight c for each edge, DSC is optimal for this tree.</p><p>Proof: We present a proof for an out-tree by induction on the height ( h ) of this tree. The proof for an in-tree is similar. When h = 2, it is a fork, and DSC is optimal. Assume that DSC obtains the optimum when h = k .</p><p>When h = k + 1, we assume, without loss of generality, that the successors of root no are nl.n2,." ,n3, and that n1 spawns successors. First, we assume that no has more than one successor; i.e., j &gt; 1. Fig. <ref type="figure">11</ref> depicts this tree. We call the entire tree Tk++'; and the subtree rooted in n1, T k . The height of Tk is k , and it has q tasks where q &gt; 1. We claim that DSC will examine all nodes in the subtree T k first before examining other successors of no. At step 1, 710 is examined, and all successors of no become free. Node n l has priority PRIO(n1) 2 3111 + 2c, and other successors of no have priority 2w + c. Then n1 is examined at step 2, (no, n1) is zeroed, and all successors of n1 are added to the free list. The priority of 711's successors 2 3w + c. Thus, they will be examined before n2, . . . , n3 . Recursively, all of nl's descendants will be freed and have priority 2 3w + c. Thus, from step 2 to step q + 1, all q nodes in Tk are examined one-by-one. After step q + 1, DSC looks at n2,n3,-...n3.</p><p>Since, from step 2 to q + 1, DSC clusters T k only, DSC obtains an optimal clustering solution for this subtree by the induction hypothesis. We call the parallel time for this subtree PTOpt(Tk). Then the parallel time after step q + 1 is PT::~' = max(w + PT,,,(T')). 2w + c).</p><p>Let PTdsc be the time after the final step of DSC for Tk+l. We study the following two cases.</p><p>One edge in T k is not zeroed by DSC. Then PTopb(Tk) 2 2w + c, implying that P T ; : : = w + PT,,,(Tk). Let m d s c be the time of the final step, because the stepwise parallel time of DSC monotonically decreases, PT: ; 2 mdsc. Also, since the optimal parallel time for a graph should be no less than that for its subgraph, PTopt(Tk+') 2 w + PTOpt(Tk)).</p><p>Thus, PTdsc 5 PTopt(Tkt'), and DSC is optimal for this case. O((,v + e)logv) no no optimal optimal optimal optimal no optimal tree 7 ' " ' can be considered as clustering a fork, with "leaf-node" n1 having a weight qw. Because DSC is optimal for a fork, DSC will get the optimum for T k f l .</p><p>Finally, we examine the case in which no has only one successor; i.e., j = 1. DSC first zeroes edge (no, nl), and then gets the optimum for T k . Thus, m d s c = w + PTapt(Tk) =</p><p>We do not know of another proof of polynomiality of the above class of fine-grain DAG's in the literature. An open question remains: Does there exist a larger class of fine-grain trees that are tractable in polynomial time, say, where the weights are not uniform in the above trees? PTa,t(T"l).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0">VI. A COMPARISON WITH OTHER ALGORITHMS AND EXPERIMENTAL RESULTS</head><p>There are many clustering algorithms for general DAG's, e.g., <ref type="bibr">[12], [17], and [19]</ref>. A comparison of these algorithms is given in <ref type="bibr">[9]</ref>. In this section, we compare DSC with the MD algorithm [19] and the ETF <ref type="bibr">[ll]</ref>. We also provide an experimental comparison for ETF, DSC, and Sarkar's algorithms. The relative mobility of a node is defined by ( T L ( ~, )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The M D Algorithm</head><p>-T s ( n z ) ) / w ( n , ) , where w(n,) is the task weight.</p><p>The MCP algorithm uses T'(n,) as a node priority. It then selects the free node with the smallest node priority, which is equivalent to selecting the node with the largest bZevel(n,), and schedules it to a processor that allows its earliest starting time.</p><p>The MD algorithm uses the relative mobility as a node priority, and, at each step of scheduling, it identifies a task np using the smallest relative mobility. It then examines the available processors starting from PEo, and it schedules np to the first processor that satisfies a condition called Fact 1 <ref type="bibr">[19, pp. 336]</ref>.3 An intuitive explanation for Fact 1 is that scheduling a task np to a processor m should not increase the length of the current critical path (DS). The complexity of the original algorithm is O(v')), as shown in <ref type="bibr">[19, pp. 3371</ref>. The corrected version of MD has a better performance, but slightly higher complexity. This is because of the recomputation of TS and TF for each scanned processor.</p><p>For each scheduling step, the complexity of MD is O(p(v+e)),</p><p>where p is the number of scanned processors, and O(v + e)</p><p>for the mobility information, and checking Fact 1 for each processor, and because there are w steps, the total complexity for the revised MD is O(pw(v + e)).</p><p>The idea of identifying the important tasks in DSC is the same as in MD, i.e., the smallest relative mobility identifies DS nodes that have the maximum tlevel + blevel. However, the way to identify DS nodes is different. The DSC uses a priority function with an O(1og U) computing scheme, whereas MD uses the relative mobility function with a computing cost of O(v + e). Another difference is that when DSC picks a DS task np to schedule, it uses the minimization procedure to reduce the tlevel of this task and thus decrease the length of DS going through this task. On the other hand, the MD scans the processors from left to right to find the first processor satisfying Fact 1. Even though Fact 1 guarantees the nonincrease of the current critical path, it does not necessarily make the path length shorter.</p><p>For a fork or join, MD picks up the DS node at each step, and we can show that it produces an optimal solution. For a coarse-grain tree, as we saw in our optimality proof, the tlevel must be reduced at each step. Since the MD schedules a task to a processor that does not necessarily decrease the tlevel at each step, the MD may not produce the optimum in general. A summary of this comparison is given in Table <ref type="table">11</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The ETF Algorithm</head><p>ETF [ 111 is a scheduling algorithm for a bounded number of processors with arbitrary network topologies. At each scheduling step, ETF finds a free task whose starting time is the smallest, and then assigns this task to a processor in which the task execution can be started as early as possible. If there is a tie, then the task with the highest blevel is scheduled; in <ref type="bibr">[ll]</ref>, this heuristic is called the ETFKP. ETF is designed for scheduling on a bounded number of processors. Thus, to compare the performance of DSC and ETF, we first apply DSC to determine the number of processors (clusters), which we then use as an input to the ETF algorithm.</p><p>We discuss the differences and similarities of DSC and ETF as follows. For a node priority, DSC uses tlevel+ blevel and then selects the largest node priority. On the other hand, the ETF uses the earliest taskjrst, which is similar to using tlevel as node priority and then selecting the smallest node .</p><p>priority for scheduling. For the scheduling step DSC and ETF, use the same idea, i.e., try to reduce tlevel by scheduling to a processor that can start a task as early as possible. However, the technique for choosing a processor is different. ETF places a task to the processor that allows the earliest starting time without rescheduling its predecessors, whereas DSC uses the minimization procedure that could reschedule some of the predecessors. It should be mentioned that the MCP [19] algorithm also schedules a task to a processor that allows its earliest starting time as in ETF. However, the node priority for MCP is blevel, as opposed to tlevel used by ETF. The complexity of ETF is higher than that of DSC. Since at each step ETF examines all free tasks on all possible processors to find the minimum starting time, the complexity of ETF is O(pw), where p is the number of processors used and w is the maximum size of the free task list. For v tasks, the total complexity is O(pwv). In our case, p = O ( v ) and w = O(v); thus, the worst complexity is O(2l3). We have used the balanced searching tree structure for the ETF algorithm in finding the values of a clock variable, NM, [ 11, pp. 249-2501, However, the complexity of ETF for finding the earliest task at each step cannot be reduced, because the earliest starting time of a task depends on the location of processors to be assigned. In practice, the average complexity of ETF could be lower than 0 ( v 3 ) . For the Choleski decomposition DAG described in Section VI-C, p = O(fi) and w = O(fi); thus, the actual complexity is O(v2). In Section VI-C, we compare the central processing unit (CPU) time spent for DSC and ETF on a S U N 4 workstation.</p><p>For a join DAG, ETF does not use a minimization procedure such as DSC, and it may not be optimal. For a fork, ETF may pick up a task with the earliest starting time; but this task may not be in a DS, and thus ETF may not give the optimum. For a coarse-grain in-tree, ETF places a task to the processor of its successor, which allows the earliest starting time for this task. We can use a similar approach to that in DSC to prove the optimality of ETF for coarse-grain in-trees.</p><p>Table <ref type="table">I1 offers</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Random DAG's</head><p>Because of the NP-completeness of this scheduling problem, heuristic ideas used in DSC cannot always lead to an optimal solution. Thus, it is necessary to compare the average performance of different algorithms by using randomly generated graphs. Since both the MD and DSC are using the DS to identify the important tasks, we expect a similar performance from both methods. On the other hand, ETF, DSC, and Sarkar's are based on different principles, and it is of interest to conduct an experimental comparison of these three methods.</p><p>We have generated 180 random DAG's as follows. We first randomly generate the number of layers in each DAG. We then randomly place a number of independent tasks in each layer. Next we randomly link the edges between tasks at different layers. Finally, we assign random values to task and edge  weights. The following statistic information is important for analyzing the performance of scheduling algorithms:</p><p>W: the range of independent tasks in each layer, which approximates the average degree of parallelism;</p><p>L: the number of layers; and WC: the average ratio of task weights over edge weights.</p><p>The 180 graphs are classified into three groups of 60 graphs, each based on their R/C values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M1:</head><p>The R/C range is 0.8-1.2. The average weights of computation and communication are close.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M2:</head><p>The R/C range is 3-10. The graphs are coarse grain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M3:</head><p>The R/C range is 0.1-0. DSCIA = 1 --.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P T A</head><p>For group M1, DSCETF shows an improvement by 3%. and DSC/Sarkar's shows an improvement by 20%. For the coarsegrain group M2, the performance differences are insignificant between ETF and DSC and small between Sarkar's and DSC.</p><p>For the fine-grain group M3, the performance is similar to that of M1, except in the first subgroup, where Sarkar's performs the best. This is because, for this group, the degree of parallelism and the number of layers are small, and the granularity is relatively fine. This implies that communication dominates the computation, and because Sarkar's algorithm reduces the communication volume by zeroing the largest communication edge at each step, it can get the largest reduction sooner. This is not the case for the other subgroups, because then the size of graphs is larger, and DSC is given more opportunities (steps) to zero edges. A summary of the experiments for the 180 random DAG's is given in Table <ref type="table">VI</ref>. We list the percentage of cases in which the performance of DSC is better, the same, and worse than that of the other two algorithms. This experiment shows that the average performance of DSC is better than that of Sarkar's, and is slightly better than that of ETF.</p><p>To see the differences in complexity between DSC and ETF, and to demonstrate the practicality of DSC, we consider an important DAG in numerical computing, the Choleski</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>,</head><label></label><figDesc>Fig. 1. scheduled DAG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Fig. l(c) shows a clustering of the DAG in Fig. l(a), excluding the dashed edges for ordering. The tasks n1 and 712 constitute one cluster, and the rest of the tasks constitute another. Fig. l(b) shows a Gantt chart of a scheduling in which the processor assignment for each task and the starting and completion times are defined. An equivalent way of representing a schedule is shown in Fig. l(c), called a scheduled DAG. A scheduled DAG contains both clustering and task execution ordering information. The dashed pseudo edges between 713 and nl in Fig. I(c) represent the execution ordering imposed by the schedule. The task starting times are not explicitly given in a scheduled DAG, but can be computed by traversing this DAG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>l(c), tlevel(n1) = 0, blevel(n1) = 10, tlevel(n3) = 2,blevel(n3) = 4.The following formula can be used to determine the parallel time from a scheduled graph:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Fig. I(a). The sorted edge list with respect to edge weights is { ( n ~, w i ) ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Clustering steps of Sarkar's algorithm for Fig. ](a)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Fig. 4. 0. (b) Step I . (c) Step 2. (d) Step 3. (e) Step 4. (f) Step 5. The result of DSC-I after each step in scheduling a DAG. (a) Step</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>0</head><label></label><figDesc>Property 3.3: The time complexity of the DSC-I algorithm is O(e + v l o g v ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. (a) Fork DAG, (b) Initial clustering. (c) Step 2, nl is examined. (d) Step k + 1. (c) and (d) The results of DSC-I after step 2 and k + 1 for a fork DAG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5(b) shows the initial clustering, where each node is in a unit cluster. EG = {}, n, is the only free task in UEG, and PRlO(n,) = T, + ,B1 + rl. At step I, n, is selected, and it has no incoming edges. It remains in a unit cluster, and EG = { n,}. After that n l , n2, . . . , n, become free, and n1 has the highest priority, PRIO(n1) = T, + /31 + 71, and tlevel ( n ~) = 7, + 01. At step 2, shown in Fig.5(c), n1 is selected and merged with the cluster of n, and tlevel(n1) is reduced, in a maximum degree, to 7,. At step IC + 1, n k is selected. The original leftmost scheduled cluster in Fig.5(d) is a "linear" chain n,, nl, . . . , nk-1. If attaching nk to the end of this chain does not increase tlevel (nk) = r, + &amp;, the zeroing of edge (n,, nk) is accepted, and the new tlevel (nk) = r, + 1 , " : ; rJ . Thus, the condition for accepting or not accepting a zeroing can be expressed as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Fig. 6. (b) Final clustering for DSC-I. (c) An optimal clustering. DSC-I clustering for a join DAG. (a) Join DAG, initial clustering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. The DSC algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>1.</head><label></label><figDesc>Sort the predecessors of n, such that tfevel(n,) + T~ + ct,. 2 tfevel(nj+]) + T ~+ ] + C,+I,,, j = 1 : m -1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>e) 714 and 125 are selected, respectively, and their clusters again remain unit clusters. After that we have the following condition: UEG = {n,j,~,7) FL = ( ~1 : ' ~' ~) P T 5 = 10 PFL = {n;"}.f) n6 is selected, and its incoming edges (123, 126) and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. The result of DSC after each step in scheduling the DAG shown in Fig. ](a). (a) Step 0. (b) Step 1. (c) Step 2. (d) Step 5. (e) Step 6. (0 Step 7.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Lemma 4. 2 :</head><label>2</label><figDesc>Assume that ny = head(PFL) after step i. If DS's go through only partially free nodes in PFL, then one DS must go through ny. Moreover, pPRIO(71,) = PRIO(n,).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>1) If DS nodes are only within EG, then, by definition, 2) If a DS goes through a free node, then PT, = PRIO(n,) by Lemma 4.1. 3) If there is a DS passing through UEG, but this DS passes through only partially free nodes, then I T , = 0 PTz nlaxneEEG {PRIO(n,)}. PRIO(n,) = pPRIO(n,), by Lemma 4.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Theorem 4. 2 :</head><label>2</label><figDesc>For each step i of DSC, PTi-1 2 mi.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>Theorem 5.3: Let PTdsc be the parallel time by DSC for a DAG G. Then n d s c 5 (1 + &amp;)â‚¬Topt. For a coarse-grain Proof: In the initial step of DSC, all nodes are in the separate clusters, which is a linear clustering. By Theorems 5.2 and 4.2, we have the following conditions: gx = min{s(Fz),g(Jz)}. DAG, m d s c I 2 X mopt-PTdsc 5 ' " 5 mI, 5 " ' 5 P T I For coarse-grain DAG's, the statement is obvious.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>as edges possible from left to right up to the point k, as shown in Fig. 5(d), such that ~~~~ r3 5 ,&amp; and E,"=,T~ &gt; Pk+l. We prove that PTopt = m d s c by a contradiction. Suppose that IC # h, and â‚¬'Top, &lt; PTdSc. There are two cases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>CT(n,) = tlevel(n,) + r3. Without loss of generality, assume that ( n l , n,) is in a DS, and that tlevel ( n l ) + 7-1 + cl,, has the highest value and flevel (722) + 7 2 + c2,, has the second-highest value. DSC will zero (nl. n z ) , and flevel (n,) = max(CT(nl), m a ~2 ~~~, { C T ( n ~) + c ~, ~} ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig</head><label></label><figDesc>Fig. IO. (a) A single-spawn out-tree. (b) A single-merge in-tree.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>tlevel*(n,,) = max(CT*(n,), Inax { C T * ( n j ) + cj,,}) condition: tlevel*(n,) &gt;_ CT(n1) + ~1 , ~ &gt;_ tlpvel(n,).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>All edges in T k are zeroed by DSC. Then PTOpt(Tk) = qw, and PT: : ! = max(w + qw, 2w + e). If w + qw 2 2w + c, i.e., if c 5 ( q -1)w, then PTdsc 5 P T : ~ = TU + PTopt(Tk) 5 PTOpt(Tk++'), because otherwise c &gt; ( q -1)w and I T : : = 2w + c. We claim that all edges in T k and edge (no,n1) should be zeroed by same cluster, the optimal clustering for the entire out-(tleuel) IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS, VOL. 5. NO. 9, SEPTEMBER 1994</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head></head><label></label><figDesc>Wu and Gajski [ 191 have proposed two algorithms: the MCP and MD. We refer the reader to [ 191 for the description of both algorithms, as well as the description of the terms used in this paragraph. The authors use the notion of as-soon-as-possible (ASAP) starting time Ts (n,), the as-late-as-possible (ALAP) time TL(~,), and the latestfinishing time, T F ( ~, ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>'</head><label></label><figDesc>In a recent personal communication [20], the authors have made the following corrections to the MD algorithm presented in [19]: 1) For Fact 1, when considering processor m , the condition, "for each k," should change to, "There exists k" [19, pp. 3361. 2) The TF and Ts computation [19, pp. 3361 should assume that task nP is scheduled on processor m . 3) When n p is scheduled to processor m, n p is inserted before the first task in the task sequence of processor m that satisfies the inequality listed in Fact 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head></head><label></label><figDesc>a summary of the comparison. Notice the similarities and differences between MCP and ETF and between MD and DSC. For a detailed comparison of MCP and DSC, see [9]. Averraee I</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head></head><label></label><figDesc>3. The graphs are fine grain. Each group is further classified into six subgroups with 10 graphs each, based on the values of W and L. The results of scheduling groups M1, M2, and M3 are summarized in Tables 111, IV, and V. The fifth and sixth columns of the tables show the parallel time improvement ratio of DSC over ETF and Sarkar's algorithm. The improvement ratio of DSC over algorithm A is defined as follows: It approximates the graph granularity.m d s c</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>( n ~, n 7 ) is</head><label></label><figDesc>examined, and, by zeroing it, the parallel time increases from 10 to 11. Thus, this zeroing is rejected. Similarly, at step 6</figDesc><table /><note><p><p><p><p><p><p><p>Table</p>I</p>traces the execution of this algorithm, where PT stands for the parallel time and PT, is the parallel time for executing the clustered graph at the completion of step i. Initially, each task is in a separate cluster, as shown in Fig.</p>2(a)</p>, and the thick path indicates the DS whose length is PTO = 13. At step 1, edge ( n , 4 , n 6 ) is examined, and PT remains 13 if this edge is zeroed. Thus, this zeroing is accepted. In step 2, 3, and 4, shown in Fig.</p>2(c</p>), 2(d), and 2(e), all examined edges are zeroed, because each zeroing does not increase PT. At step 5, edge</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>, zeroing ( 7 ~~~ n 3 ) is</head><label></label><figDesc></figDesc><table /><note><p>rejected. At step 7, (715: ne) is zeroed and a pseudo edge from 715 to 713 is added, because after step 6, blevel(n3) = 3 and b!evel(n5) = 5. Finally, two clusters are produced with PT= 10, shown in Fig. 2(f).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>all free eutry nodes to FL. Compute blevel for each node and set tlpuel = 0 for each</head><label></label><figDesc></figDesc><table><row><cell>1.</cell><cell></cell></row><row><cell>2.</cell><cell></cell></row><row><cell>3.</cell><cell></cell></row><row><cell>4</cell><cell></cell></row><row><cell>5.</cell><cell></cell></row><row><cell>6.</cell><cell></cell></row><row><cell>7.</cell><cell></cell></row><row><cell>8</cell><cell></cell></row><row><cell>9</cell><cell>ELSE</cell></row><row><cell>10.</cell><cell></cell></row><row><cell>DSRW.</cell><cell></cell></row><row><cell>11.</cell><cell></cell></row><row><cell>12</cell><cell>ENDIF</cell></row><row><cell>13.</cell><cell></cell></row><row><cell>14.</cell><cell></cell></row></table><note><p><p>ENDWHILE EG = 0. U E G = V Add i</p>r w node. WHILE CJEG # 0 DO n. = heod(FL);/* the free task vlth the highest priority PRIO */ ny = head(PFL); /* the partial free task with the highest priunty pPRIO.'/ IF (PRlO(n,) 2 pPRlO(n,)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>) THEN Call the minimization procedure to reducp tlesel(n.). If no zeroing is xcepted. n. remains in a unit cluster. Call the minimization procedure to reducr tlevel(s.) under constraint</head><label></label><figDesc></figDesc><table /><note><p>l i n o zrroing</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>is accepted. it= remains in a unit cluster. Update the priorities of n . ' ~ successors and put nZ</head><label></label><figDesc></figDesc><table /><note><p>into EG.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE I11 DSC vs. ETF AND SARKAR'S FOR GROUP MI (WC range is between 0.8 and 1.2)</head><label>I11</label><figDesc>I Layer I Width I #tasks I #edge 1 DSC/ETF 1 DSC/Sarkar I Avg/Max I range I range 1 avg</figDesc><table><row><cell>9-11 9-11</cell><cell>1 4/11 I 9/20</cell><cell>144-94 164-107 I 118-255 14.49% [ 57-206 14.58%</cell><cell>I avg I 15.73% 117.49%</cell></row></table><note><p><p>range</p>I</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS. VOL. 5, NO. 9, SEPTEMBER 1994</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>'DSC reschedules all predecessors that have been examined and have n, as the only child. This is the only backtracking currently allowed in DSC without increasing complexity.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>We are very grateful to V. Sarkar for providing us with the programs of his system in [17]  and for his comments and suggestions, and to M.-Y. Wu for his help in clarifying the MD algorithm. We also thank referees for their useful suggestions in improving the presentation of this paper. We thank W. Wang for programming the random graph generator, and A. Darte, P. Sadayappan, and R. Wolski for their comments on this work. The analysis for a fine-grain tree was inspired by a conversation with T. Varvarigou.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the Advanced Research Projects Agency (ARPA) under Contract DABT43-93-C-0064, in part by the National Science Foundation under Grant DMS-8706122, in part by the the Office of Naval Research under Grant N000149310114, and in part by a startup fund and a Faculty Fellowship from the</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>decomposition (CD) DAG <ref type="bibr">[7]</ref>. For a matrix of size n, the degree of parallelism is n, the number of tasks U is about n 2 / 2 , and the number of edges e is about n2. The average R/C is 2. The performance of the two algorithms is given in Table <ref type="table">VII</ref>. We show the PT improvement, as well as the total CPU time spent in scheduling this DAG on a Sun-4 workstation.</p><p>To explain why the values of the CPU in Table <ref type="table">VI1</ref> makes sense for different values of 71, we examine the complexity of the algorithms for this DAG. The complexity of DSC is O((U + e ) log U ) , which is 0(7h2 log n) for this case. When n increases by 2, CPU&amp;, increases by about four times. For ETF, the complexity is O(pvw). For this case, p = w = n and o = n 2 / 2 ; thus, the complexity is O ( T L ~) .</p><p>When n increases by 2, CPU,,f increases by about 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>We have presented a low-complexity scheduling algorithm with performance comparable to, or even better, on average, than much-higher-complexity heuristics. The low complexity makes DSC very attractive in practice. DSC can be used in the first step of Sarkar's [ 171 two-step approach to scheduling on a bounded number of processors. We have already incorporated DSC into our programming environment PYRROS [23] that has produced very good results on real architectures such as nCUBE-I1 and INTELh860. DSC is also useful for partitioning and clustering of parallel programs [17], <ref type="bibr">[21]</ref>. A particular area in which DSC could be useful is scheduling irregular task graphs. Pozo [ 161 has used DSC to investigate the performance of sparse matrix methods for distributed memory architectures. <ref type="bibr">Wolski and Feo [18]</ref> have extended the applicability of DSC to program partitioning for NUMA architectures.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Lower bound on the number of processors and time for scheduling precedence graphs with communication costs</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ai-Mouhamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1390" to="1401" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scheduling with sufficient loosely coupled processors</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Anger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Parallel Distrib. Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="87" to="92" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Task scheduling over distributed memory machines</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chretienne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Workshop Parallel Distrib</title>
		<meeting>Int. Workshop Parallel Distrib</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A polynomial algorithm to optimially schedule tasks over an ideal distributed system under tree-like presedence constraints</title>
	</analytic>
	<monogr>
		<title level="j">European J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="225" to="230" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Complexity of tree scheduling with interprocessor communication delays</title>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep. M.A.S.I</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
		<respStmt>
			<orgName>Universite Pierre et Marie Curie</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">C. P. M. scheduling with small communication delays and task duplication</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Colin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chretienne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="680" to="684" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Parallel Gaussian elimination on an MIMD computer</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cosnard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marrakchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Trystram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parallel Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="275" to="296" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the granularity and clustering of directed acyclic task graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gerasoulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distrib. Sy.w</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">686701</biblScope>
			<date type="published" when="1993-06">June 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A comparison of clustering heuristics for scheduling DAG&apos;s on multiprocessors</title>
	</analytic>
	<monogr>
		<title level="j">J. Parallel Distrib. Computing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2 7 6 2 9 1</biblScope>
			<date type="published" when="1992-12">Dec. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Scheduling precedence graphs in systems with interprocessor communication times</title>
		<author>
			<persName><forename type="first">M</forename><surname>Girkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Polychronopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Anger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1988 ACM Inr. Con$ Supercomputing</title>
		<meeting>1988 ACM Inr. Con$ Supercomputing</meeting>
		<imprint>
			<date type="published" when="1988">1988. 1989</date>
			<biblScope unit="page" from="244" to="257" />
		</imprint>
	</monogr>
	<note>Partitioning programs for parallel execution</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A general approach to mapping of parallel computation upon multiprocessor architectures</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Browne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Inr. Con$ Parallel Processing</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Grain size determination for parallel proceysing</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kruatrachue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Sofmare</title>
		<imprint>
			<biblScope unit="page" from="23" to="32" />
			<date type="published" when="1988-01">Jan. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic determination of grain size for efficient parallel processing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mccreary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1073" to="1078" />
			<date type="published" when="1989-09">Sept. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Toward an architectureindependent analysis of parallel algorithms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yannakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Compur</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="322" to="328" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Performance modeling of sparse matrix methods for distributed memory architectures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pozo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Processing: CONPAR 92-VAPP V</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">634</biblScope>
			<biblScope unit="page" from="677" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Partitioning and Scheduling Parallel Programs for Execution on Multiprocessors</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sarkar</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Program parititoning for NUMA multiprocessor computer systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Parallel Distib. Computing (special issue on performance of supercomputers)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="203" to="218" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hypertool: A programming aid for messagepassing systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gajski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distrib. Sysi</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="33" to="343" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993-02">Feb. 1993</date>
		</imprint>
	</monogr>
	<note>personal commun.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A mapping strategy for MIMD computers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nicolau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1991 Int. Con$ Parallel Processing</title>
		<meeting>1991 Int. Con$ Parallel essing</meeting>
		<imprint>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="102" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A fast static scheduling algorithm for DAG&apos;S on an unbounded number of processors</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gerasoulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Supercomputing &apos;91</title>
		<meeting>Supercomputing &apos;91</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="633" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">PYRROS: Static scheduling and code generation for message passing multiprocessors</title>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th ACM Int. Conf: Supercomputing, 1992</title>
		<meeting>6th ACM Int. Conf: Supercomputing, 1992<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page">428437</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">His research interests are in the areas of numerical computing, parallel algorithms and programming, compilers, and parallel languages and environments. Dr. Gerasoulis has published extensively in both numerical computing and parallel processing areas. He has participated in the organization of several international conferences, and is an Editor of the Parallel Processing Letters Joumal, and Computer and Mathematics with</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gerasoulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applications International Journal, and is a Special Issue Editor of Applied Numerical Mathematics Journal</title>
		<imprint/>
	</monogr>
	<note>D. degrees in applied mathematics from the State University of New York at Stony Brook. He is a Professor of Computer Science at Rutgers University</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">He is an Assistant Professor of Computer Science at the University of California at Santa Barbara. His research interests include algorithms, programming languages</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">S&apos;92-M&apos;93) received the B.S. degree in computer science in 1984 and the M.E. degree in artificial intelligence in 1987 from Zhejiang University, China, and the M.S. degree in computer science in 1990 and the Ph.D. degree in computer science in 1993 from Rutgers University</title>
		<meeting><address><addrLine>New Brunswick, NJ</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
