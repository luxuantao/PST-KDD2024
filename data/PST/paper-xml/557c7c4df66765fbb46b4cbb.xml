<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Cooperative Parallel Search-Based Software Engineering Approach for Code-Smells Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wael</forename><surname>Kessentini</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marouane</forename><surname>Kessentini</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Houari</forename><surname>Sahraoui</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Slim</forename><surname>Bechikh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ali</forename><surname>Ouni</surname></persName>
						</author>
						<title level="a" type="main">A Cooperative Parallel Search-Based Software Engineering Approach for Code-Smells Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C9AD64DDB4CB6724FE189FDCDEA773BB</idno>
					<idno type="DOI">10.1109/TSE.2014.2331057</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TSE.2014.2331057, IEEE Transactions on Software Engineering This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TSE.2014.2331057, IEEE Transactions on Software Engineering</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>Abstract-We propose in this paper to consider code-smells detection as a distributed optimization problem. The idea is that different methods are combined in parallel during the optimization process to find a consensus regarding the detection of code-smells. To this end, we used Parallel Evolutionary algorithms (P-EA) where many evolutionary algorithms with different adaptations (fitness functions, solution representations, and change operators) are executed, in a parallel cooperative manner, to solve a common goal which is the detection of codesmells. An empirical evaluation to compare the implementation of our cooperative P-EA approach with random search, two single population-based approaches and two code-smells detection techniques that are not based on meta-heuristics search. The statistical analysis of the obtained results provides evidence to support the claim that cooperative P-EA is more efficient and effective than state of the art detection approaches based on a benchmark of 9 large open source systems where more than 85% of precision and recall scores are obtained on a variety of 8 different types of code-smells.</p><p>Index Terms-search-based software engineering, code-smells, software quality, distributed evolutionary algorithms.</p><p>I. INTRODUCTION ource code of large systems is iteratively refined, restructured and evolved due to many reasons such as correcting errors in design, modifying a design to accommodate changes in requirements, and modifying a design to enhance existing features. Many studies reported that these software maintenance activities consume up to 90% of the total cost of a typical software project <ref type="bibr" target="#b11">[12]</ref>.</p><p>This high cost could potentially be greatly reduced by providing automatic or semi-automatic solutions to increase their understandability, adaptability and extensibility to avoid bad-practices. As a result, there has been much research focusing on the study of bad design practices, also called code-smells, defects, anti-patterns or anomalies <ref type="bibr" target="#b12">[13]</ref> [14] <ref type="bibr" target="#b14">[15]</ref>  Marouane Kessentini and Slim Bechikh are with the University of Michigan, USA. E-mail: { marouane, bechikhs}@umich.edu.  Wael Kessentini, Houari Sahraoui and Ali Ouni are with University of Montreal, Canada. E-mail: {waelk, sahraoui, ouniali}@umontreal.ca Manuscript received (insert date of submission if desired). Please note that all acknowledgments should be placed at the end of the paper, before the bibliography. <ref type="bibr" target="#b24">[25]</ref> in the literature. Although these bad practices are sometimes unavoidable, they should be in general prevented by the development teams and removed from their code base as early as possible. In fact, detecting and removing these code-smells help developers to easily understand source code <ref type="bibr" target="#b12">[13]</ref>. In this work, we focus on the detection of code-smells.</p><p>The vast majority of existing work in code-smells detection relies on declarative rule specification <ref type="bibr" target="#b14">[15]</ref> [17] <ref type="bibr" target="#b17">[18]</ref> [19] <ref type="bibr" target="#b19">[20]</ref>. In these settings, rules are manually defined to identify the key symptoms that characterize a code-smell using combinations of mainly quantitative (metrics), structural, and/or lexical information. However, in an exhaustive scenario, the number of possible code-smells to manually characterize with rules can be large. For each code-smell, rules that are expressed in terms of metric combinations need substantial calibration efforts to find the right threshold value for each metric. Another important issue is that translating symptoms into rules is not obvious because there is no consensual symptom-based definition of code-smells <ref type="bibr" target="#b12">[13]</ref>. When consensus exists, the same symptom could be associated to many code-smells types, which may compromise the precise identification of codesmell types.</p><p>To address these issues, we proposed an approach based on the use of genetic programming (GP) to generate detection rules from examples of code-smells using structural metrics <ref type="bibr" target="#b20">[21]</ref>. However, the quality of the generated rules depends on the coverage of the different suspicious behaviors of codesmells, and it is difficult to ensure such coverage. Thus, there are still some uncertainties regarding the detected code-smells due to the difficulty to evaluate the coverage of the base of code-smell examples. In another recent work, we proposed an approach based on an artificial immune system metaphor to detect code-smells by deviation with examples of good codepractices and well-designed systems <ref type="bibr" target="#b21">[22]</ref>. Some of the detected code fragments that are different from well-designed code were not code-smells but just new good-practice behavior. Thus, we believe that an efficient approach will be to combine both detection algorithms to find better consensus when detecting code-smells.</p><p>We propose in this paper to consider code-smells detection as a distributed optimization problem. The idea is that different methods are combined in parallel during the optimization process to find a consensus regarding the detection of code-smells. To this end, we used Parallel Evolutionary algorithms (P-EA) <ref type="bibr" target="#b1">[2]</ref> where many evolutionary algorithms with different adaptations (fitness functions, solution representations, and change operators) are executed, in a parallel cooperative manner, to solve a common goal which is the detection of code-smells. We believe that a P-EA approach is suitable to our problem because it allows us to combine the different levels of expertise (algorithms) to detect code-smells. We show how this combination can be formulated as cooperation between many populations during the search process. In P-EA, many populations' individuals evolve simultaneously. Indeed, a first population generates a set of detection rules using genetic programming <ref type="bibr" target="#b10">[11]</ref> and simultaneously a second population tries to detect code-smells using a deviation from examples of well-designed codes <ref type="bibr" target="#b21">[22]</ref>. Both populations are executed, on the same system to evaluate, and the quality of solutions is updated based on the consensus found, i.e.: intersection between the detection results of both populations. The best detection results will be the code-smells detected by the majority of algorithms. The P-EA approach does not consist on just executing the two search-based algorithms in parallel but to build a consensus between them to classify the detected candidates based on several interactions in the fitness function level.</p><p>We implemented our P-EA approach and evaluated it on nine systems using an existing benchmark. We report the results on the effectiveness and efficiency of our approach, compared to a random search (RS) and to different existing single population-based approaches <ref type="bibr" target="#b20">[21]</ref>  <ref type="bibr" target="#b21">[22]</ref>. The statistical analysis of our results indicates that the P-EA approach has great promise; P-EA significantly outperforms random search, two single population-based approaches and two code-smells detection techniques (not based on meta-heuristics search) <ref type="bibr" target="#b15">[16]</ref> <ref type="bibr" target="#b47">[49]</ref> in terms of precision and recall based on existing benchmarks <ref type="bibr" target="#b16">[17]</ref>[16] <ref type="bibr" target="#b22">[23]</ref>.</p><p>The primary contributions of this paper can be summarized as follows:</p><p> A novel formulation of the code-smells detection as a distributed optimization problem. To the best of our knowledge and based on recent search-based software engineering (SBSE) surveys <ref type="bibr" target="#b23">[24]</ref>, this is the first work that uses parallel cooperative evolutionary algorithms to solve code-smells detection problem where various EAs, with different adaption schemes, are executed in parallel.  An empirical evaluation to compare the implementation of our cooperative P-EA approach with random search, existing single population-based approaches <ref type="bibr" target="#b22">[23]</ref>  <ref type="bibr" target="#b23">[24]</ref> and two code-smells detection techniques not based on meta-heuristics search <ref type="bibr" target="#b15">[16]</ref> <ref type="bibr" target="#b47">[49]</ref>. The statistical analysis of the obtained results provides evidence to support the claim that cooperative P-EA is more efficient and effective than state of the art refactoring solution on a benchmark of 9 large open source systems. The remainder of this paper is structured as follows: Section II presents the relevant background and the motivations for the presented work; Section III describes the cooperative parallel search scheme; the adaption of P-EA to code-smells detection is presented in Section IV; an evaluation of the algorithm is explained in Section V and its results are discussed in Section VI; different threats to validity are discussed in Section VII; Section VIII is dedicated to related work. Finally, concluding remarks and future work are provided in Section IX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. SOFTWARE REFACTORING: OPEN PROBLEMS</head><p>In this section, we first provide the necessary background of detecting code-smells and discuss the challenges and open problems that are addressed by our proposal.</p><p>A. Background 1) Code-smells Code-smells, also called design anomalies or design defects, refer to design situations that adversely affect the software maintenance <ref type="bibr" target="#b24">[25]</ref>. As stated by <ref type="bibr" target="#b12">[13]</ref>, bad-smells are unlikely to cause failures directly, but may do it indirectly. In general, they make a system difficult to change, which may in turn introduce bugs. Different types of code-smells, presenting a variety of symptoms, have been studied in the intent of facilitating their detection <ref type="bibr" target="#b12">[13]</ref> and suggesting improvement solutions. In <ref type="bibr" target="#b24">[25]</ref>, Beck defines 22 sets of symptoms of code smells. These include large classes, feature envy, long parameter lists, and lazy classes. Each code-smell type is accompanied by refactoring suggestions to remove it. Brown et al. <ref type="bibr" target="#b12">[13]</ref> define another category of code-smells that are documented in the literature, and named anti-patterns. In our approach, we focus on the eight following code-smell types:</p><p> Blob: It is found in designs where one large class monopolizes the behavior of a system (or part of it), and the other classes primarily encapsulate data.  Spaghetti Code (SC): It is a code with a complex and tangled control structure.  Functional Decomposition (FD): It occurs when a class is designed with the intent of performing a single function. This is found in code produced by nonexperienced object-oriented developers.  Feature Envy (FE): It occurs when a method is more interested in the features of other classes than its own. In general, it is a method that invokes several times accessor methods of another class.  Data Class (DC): It is a class with all data and no behavior. It is a class that passively stores data.  Lazy Class (LC): A class that isn't doing enough to pay for itself.  Long Parameter List (LPL): Methods with numerous parameters are a challenge to maintain, especially if most of them share the same data-type.  Shotgun Surgery (SS): It occurs when a method has a large number of external operations calling it, and these operations are spread over a significant number of different classes. As a result, the impact of a change in this method will be large and widespread.</p><p>We choose these code-smell types in our experiments because they are the most frequent and hard to detect and fix based on a recent empirical study <ref type="bibr">[25][18]</ref>[20] <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Code-smells detection</head><p>The code-smells' detection process consists in finding code fragments that violate structure or semantic properties such as the ones related to coupling and complexity. In this setting, internal attributes used to define these properties, are captured through software metrics and properties are expressed in terms of valid values for these metrics <ref type="bibr" target="#b25">[26]</ref>. This follows a long tradition of using software metrics to evaluate the quality of the design including the detection of code-smells <ref type="bibr">[14][15]</ref>. The most widely-used metrics are the ones defined by Chidamber and Kemerer <ref type="bibr" target="#b25">[26]</ref>. These metrics include: (1) Depth of Inheritance Tree (DIT), (2) Weighted Methods per Class (WMC), and (3) Coupling Between Objects (CBO). In this paper, we use variations of these metrics and adaptations of procedural ones as well, e.g., the number of lines of code in a class (LOCCLASS), number of lines of code in a method (LOCMETHOD), number of attributes in a class (NAD), number of methods (NMD), lack of cohesion in methods (LCOM5), number of accessors (NACC), and number of private fields (NPRIVFIELD).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Challenges and open problems</head><p>In the following, we introduce some code-smells' detection issues and challenges. Later, in section VI, we discuss these issues in more detail with respect to our approach.</p><p>Overall, there is no general consensus on how to decide if a particular design violates a quality heuristic. In fact, there is a difference between detecting symptoms and asserting that the detected situation is an actual code-smell. For example, an object-oriented program with a hundred classes from which one class implements all the behavior and all the other classes are only classes with attributes and accessors. No doubt, we are in presence of a Blob. Unfortunately, in real-life systems, we can find many large classes, each one using some data classes and some regular classes. Deciding which classes are Blob candidates heavily depends on the interpretation of each analyst. In some contexts, an apparent violation of a design principle may be consensually accepted as normal practice. For example, a "Log" class responsible for maintaining a log of events in a program, used by a large number of classes, is a common and acceptable practice. However, from a strict codesmell definition, it can be considered as a class with an abnormally large coupling.</p><p>Another issue is related to the definition of thresholds when dealing with quantitative information. For example, the Blob detection involves information such as class size. Although we can measure the size of a class, an appropriate threshold value is not trivial to define. A class considered large in a given program/community of users could be considered average in another.</p><p>Finally, detecting dozens of code-smells occurrences in a system is not always helpful except if the list of code-smells is sorted by priority. In addition to the presence of false positives that may create a rejection reaction from development teams, the process of using the detected lists, understanding the codesmell candidates, selecting the true positives, and correcting them is long, expensive, and not always profitable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. THE PROPOSED COOPERATIVE PARALLEL MODEL SCHEME</head><p>Nowadays, real life optimization problems are more and more complex. Consequently, their resource requirements are ever increasing. Optimization problems are often hard and expensive from a CPU time and/or memory viewpoint <ref type="bibr" target="#b0">[1]</ref>. The use of metaheuristics, such as Evolutionary Algorithms (EAs) and Particle Swarm Optimization (PSO), allows reducing the computational complexity of the search process. However, the latter remains computationally costly in different application domains where the objective functions and the constraints are resource intensive and the size of the search space is huge. In addition, to the problem of complexity, we find today resource-expensive search methods such as hybrid metaheuristics and multi-objective ones. The rapid technology development in terms of processors, networks and data storage tools renders parallel distributed computing very interesting to use. This fact has motivated researchers to more focus on designing and implementing parallel metaheuristics, mainly P-EAs, in order to solve more complex optimization problems <ref type="bibr" target="#b1">[2]</ref>.</p><p>There are several motivations behind the use of parallel and distributed computing for the design and implementation of P-EAs. Firstly, parallelization allows speeding up the search process by reducing the search time. This is very interesting in time-dependent and interactive resolution methods. Secondly, the quality of the obtained solutions may be significantly improved. In fact, cooperative P-EAs have been demonstrated to explore the fitness landscape more efficiently on different problems such as the code-smell identification problem <ref type="bibr" target="#b2">[3]</ref>. This is realized by portioning the search space and then exchanging information between the different search methods, which allows examining the search space more efficiently. Thirdly, the use of different metaheuristics (e.g., EAs) simultaneously in solving a given problem reduces the sensitivity to the parameter values. Indeed, each search method would be launched with a particular parameter value set which is different from the others' ones. Hence, the search process would work according to different parameter value sets which may augment the accuracy of the obtained results. Finally, P-EAs allow tackling the scalability. Several problems actually involve a very large number of decision variables (called large-scale problems <ref type="bibr" target="#b3">[4]</ref>), a high number of objectives (called many-objective problems ( <ref type="bibr" target="#b4">[5]</ref>), a large number of constraints (called highly-constrained problems <ref type="bibr" target="#b5">[6]</ref>), etc. These types of problems are very computationally costly. P-EAs can represent one possible remedy to tackle such problems.</p><p>Different models exist for designing P-EAs. According to Talbi <ref type="bibr" target="#b6">[7]</ref>, these models follow the following three hierarchical levels:</p><p> Algorithmic level: In this parallel model, independent or cooperating self-contained EAs are used. It can be seen as a problem-independent inter-algorithm parallelization. If the different EAs are independent, the search will be equivalent to the sequential execution of the EAs in terms of the quality of solutions. However, the cooperative model will In our proposal, we use a parallelization at the solution level without interchanging solutions between the considered search algorithms. In fact, in each generation, the fitness values of the best solutions are updated based on an intersection score that is detailed later.</p><p>Several research questions should be answered when designing P-EAs <ref type="bibr" target="#b7">[8]</ref>. The most important ones are the following:</p><p> What information to exchange between EAs? In a parallel evolutionary model, EAs communicate between themselves. The message content could be composed of:</p><p>(1) elite solutions that have been discovered during the search, e.g., the current iteration best solution, the locally best solutions, the global best solution, the neighborhood best solution, the most diversified solutions; and (2) search memory of the corresponding metaheuristic such as the pheromone trails for Ant Colony Optimization (ACO) and the probability model for Estimation of Distribution Algorithms (EDAs). In our parallel model, there is an implicit exchange of information without interchanging solutions. Indeed, the elite solutions' fitness values are updated based on the intersection score. Consequently, the information exchange could be seen as implicit since there is no solution migration between the search algorithms.  How to integrate the received information? The exchanged information is generally used to update the elite solution(s) of the recipient EA. Different replacement strategies may be applied to the local population by using the set of received solutions. For example, an elitist replacement strategy will integrate the obtained k solutions by replacing the k worst solutions of the local population. The implicit information exchange based on the consensus score will update the elite solutions' fitness values. In this way, some elite solutions will be emphasized w.r.t the parallel model and some others will be discouraged to remain in the race; thereby pushing the search algorithms to update their convergence process behavior based on the consensus score.</p><p> Where to send the useful information? Each parallel model is characterized by a particular communication exchange topology. The latter indicates for each EA its neighboring ones regarding the information exchange. In this way, the model will be able to detect the source/destination algorithm of the useful information. Among the most-used topologies, we find the ring, the mesh, the hypercube and the complete graph. Our parallel model topology could be seen as a ring where the search considered search algorithms communicates through the fitness update module.  When to exchange information? The information exchange moment between EAs could be decided periodically, probabilistically or adaptively. When using a periodic strategy, a change occurs in each algorithm after a fixed number of iterations/number of evaluations. This type of communication is called synchronous. When using a probabilistically strategy, an exchange occurs after each iteration according to given appearance probability. The adaptive strategy exploits information issued from the search process, such as the solution quality, to decide whether to launch an exchange or not. We use a synchronous communication between the two search algorithms since we update the fitness values of elite solutions periodically each generation. However, other strategies could be tested.</p><p>Although parallel distributed EAs' are still a challenging research field, several contributions are mature enough today to be exploited within the SBSE framework. Since the most studied and known models are based on EAs <ref type="bibr" target="#b8">[9]</ref>, the scope of this paper is to illustrate one of the first attempts of using P-EAs to solve software engineering problems, and particularly the code-smells detection one. Indeed, to the best of our knowledge and based on recent surveys <ref type="bibr" target="#b45">[47]</ref>  <ref type="bibr" target="#b23">[24]</ref>, this work represents the first research contribution to solve the code smells detection problem using P-EAs.</p><p>The parallelization proposed in this work intervenes in the solution level since it affects the solution evaluation module. Consequently, it could be seen as a problem-dependent intraalgorithm parallelization. In fact, in each generation of the parallel process, the top 5% elite solutions, i.e., those with the highest fitness values, are updated according to an intersection component. The update operation role is to penalize solutions that do not perform well according to the parallel model and to favor good solutions w.r.t. the parallelization. For the problem considered in this work, code-smells detection, we use a simple bi-algorithm parallel model illustrated by figure <ref type="figure">1</ref>. We see, from this figure, that the fitness of elite solutions of EA1 is updated based on the fitness values of elite solutions of EA2 and vice versa. The main goal of the fitness-update operation is alleviating the encountered challenges of the code-smell detection, which are discussed in the previous section. Indeed, the parallel model goal is to circumvent the absence of a welldefined consensus concerning the detection of code-smells (symptoms, threshold values, etc.). The next section describes in details our adaptation of P-EAs to our code-smells detection problem.</p><p>Fig. <ref type="figure">1</ref> The proposed cooperative parallel model scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. PARALLEL EVOLUTIONARY ALGORITHMS ADAPTATION</head><p>This section shows how parallel meta-heuristic search can be adapted to our problem of code-smells detection. In order to ease the understanding of this formulation, we first describe the pseudo-code of our adaptation. Then, we present the solution structure, the objective functions to optimize, and finally, the used change operators.</p><p>The first used evolutionary algorithm is based on genetic programming GP <ref type="bibr" target="#b26">[27]</ref> to generate code-smells detection rules. The second evolutionary algorithm executed in parallel is genetic algorithm GA <ref type="bibr" target="#b10">[11]</ref> that generates detectors (codesmells examples) from well-designed code examples. Both algorithms are powerful metaheuristic search optimization methods inspired by the Darwinian theory of evolution <ref type="bibr" target="#b26">[27]</ref>. The basic idea of both algorithms is to explore the search space by making a population of candidate solutions, also called individuals, evolve towards a "good" solution of a specific problem. To evaluate the solutions, the fitness function in both algorithms has two components. For the first component of the fitness function, GP evaluates the detection rules based on the coverage of code-smells examples (input) and GA evaluates the detectors by calculating the deviance from well-designed code (input) using global and local alignment techniques <ref type="bibr" target="#b33">[35]</ref>. Then, a set of best solutions are selected from both algorithms in each iteration. Both algorithms interact with each other using the second component of the fitness function called intersection_function where a new system, different from the ones used to produce the inputs, is evaluated using these solutions in order to maximize the intersection between the sets of detected codesmells by each solution. Thus, some solutions will be penalized due to the absence of consensus and others will be favored. In the initialization of the P-EA algorithm, one system from the base of examples is selected randomly to calculate the intersection function and removed from the base of examples used by the GP algorithm. Thus, P-EA is to be run for the system selected from the base of examples that needs to have code-smell(s) detected, as the intersections will be determined for this particular system and the system to evaluate is not considered in the training set. The best rules and detectors can be used to evaluate any new system without the need to execute again P-EA. The developers should execute P-EA again only in the case that major revisions are introduced to the base of examples.</p><p>The result of both algorithms executed in parallel is the fittest individual produced along all generations for each one. In our case, the P-EA generates the best detection rules and the best detectors. These rules and detectors can be executed by developers to detect code-smells on new systems.</p><p>A high-level view of our P-EA approach to the code-smells detection problem is introduced by Figure <ref type="figure" target="#fig_0">2</ref> where GA and GP algorithms are executed in parallel and interact using a fitness function in each generation. Lines 1-3 construct an initial GP and GA populations, which are sets of individuals that stand for possible solutions representing detection rules (metrics combination) for GP and detectors (artificial code that represents pseudo code-smell examples) for GA. Lines 4-15 encode the main GP and GA loops, which explores the search space and constructs new individuals by combining metrics for GP to generate rules and code elements to generate detectors for GA. In each iteration, we evaluate the quality of each individual in the population for each algorithm (lines 6 and 13) as described before. Then, the best solution for each algorithm is saved and a new population of individuals is generated by iteratively selecting pairs of parent individuals from population p and applying the crossover operator to them. We include both the parent and child variants in the new population pop. Then, we apply the mutation operator, with a probability score, for both parent and child to ensure the solution diversity; this produces the population for the next generation. When applying change operators, no individuals are exchanged between the parallel GA/GP. Both algorithms terminate when the termination criterion (maximum iteration number) is met, and returns the best set of rules and detectors. Finally, developers can use the best rules and detectors to detect code-smells on any new system to evaluate. The tool ranks the detected code-smells based on an intersection score that will be discussed in Section V.</p><p>In the following, we describe the three main steps of adaptation of both GP and GA algorithms to our problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Solution Representation</head><p>One key issue when applying a search-based technique is to find a suitable mapping between the problem to solve and the techniques to use, i.e., detecting code-smells. In GP, a solution is composed of terminals and functions. Therefore, when applying GP to solve a specific problem, they should be carefully selected and designed to satisfy the requirements of the current problem. After evaluating many parameters related to the code-smells detection problem, the terminal set and the function set are decided as follows. The terminals correspond to different quality metrics with their threshold values (constant values). The functions that can be used between these metrics are Union (OR) and Intersection (AND). More formally, each candidate solution S in this problem is a sequence of detection rules where each rule is represented by a binary tree such that:</p><p>(1) each leaf-node (Terminal) L belongs to the set of metrics (such as number of methods, number of attributes, etc.) and their corresponding thresholds generated randomly.</p><p>(2) each internal-node (Functions) N belongs to the Connective (logic operators) set C = {AND, OR}. The set of candidate solutions (rules) corresponds to a logic program that is represented as a forest of AND-OR trees. A solution is a set of detection rules where each rule detects a specific type of code-smell. Thus, every solution has a number of rules equivalent to the number of types of code-smells to detect. For example, consider the following logic program described in Figure <ref type="figure" target="#fig_2">3</ref>: For GA, detectors represent generated artificial code fragments composed by code elements. Thus, detectors are represented as a vector where each dimension is a code element. We represent these elements as sets of predicates. Each predicate type corresponds to a construct type of an object-oriented system: Class (C), attribute (A), method (M), parameter (P), generalization (G), and method invocation relationship between classes (R). For example, the sequence of predicates CGAAMPPM corresponds to a class with a generalization link, containing two attributes and two methods. The first method has two parameters. Predicates include details about the associated constructs (visibility, types, etc.). These details (thereafter called parameters) determine ways a code fragment can deviate from a notion of normality. The sequence of predicates must follow the specified order of predicate types (Class, Attribute, Method, Generalization, association, etc.) to ease the comparison between predicate sequences and then reducing the computational complexity. When several predicates of the same type exist, we order them according to their parameters. To generate an initial population for both algorithms, we start by defining the maximum tree/vector length (max number of metrics/code-elements per solution). The tree/vector length is proportional to the number of metrics/code-elements to use for code-smells detection. Sometimes, a high tree/vector length does not mean that the results are more precise. These parameters can be specified either by the user or chosen randomly. Figure <ref type="figure" target="#fig_3">4</ref> shows an example of a generated detector composed by one class, one generalization link, two attributes, two methods, and two parameters. The parameters of each predicate contain information generated randomly describing each code element (type, visibility, etc.). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R1 : IF (LOCCLASS ≥ 1500 AND LOCMETHOD ≥ 129) OR (NMD ≥ 100) THEN code-smell = blob R2 : IF (LOCMETHOD ≥ 151) THEN code-smell = functional decomposition R3 : IF (NPRIVFIELD ≥ 7 AND NMD = 16) THEN code-smell = spaghetti code</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Solution Evaluation</head><p>The encoding of an individual should be formalized as a mathematical function called the "fitness function". The fitness function quantifies the quality of the proposed detection rules and detectors. The goal is to define efficient and simple fitness functions in order to reduce the computational cost. For our GP adaptation, to evaluate detection-rules solutions the fitness function is based on: (1) maximizing the coverage of the base of code-smell examples and (2) maximizing the consensus, using an intersection function, with the GA, executed in parallel, regarding detected code-smells on a new system A. For our GA adaptation, to evaluate generated detectors the fitness function is based on:</p><p>(1) a dissimilarity score, to maximize, between detectors and different reference code fragments while minimizing the overlap between detectors (to maximize diversity) and ( <ref type="formula">2</ref>) maximizing the intersection function. In the following, we detail all these functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coverage of the base of code-smell examples (used by GP):</head><p>This objective function checks to maximize the number of detected code-smells in comparison to the expected ones in the base of examples. In this context, we define the objective function of a particular solution S, normalized in the range [0,1] as follows:</p><p>2  . The classes detected after executing the solution generating the rules R1, R2 and R3 are described in the detection result table. Thus, only one class corresponds to a true code-smell (Person). Classroom is a code-smell, but the type is wrong and Professor is not a codesmell. The fitness function has the value 0.25 as illustrated in the figure . 
The base of examples used by the GP contains only examples of code smells and not examples of good code. In fact, an example of BLOB could be at the same time an example of non-spaghetti code. However, if we consider that there is only one type of code smell, then a rule that simply classifies everything as being code smell would obtain very high fitness if the base of examples does not contain any example of good code. This section describes how a set of detectors is produced starting from the reference code examples. The idea is to produce a set of detectors that best covers the possible deviations from the reference code. As the set of possible deviations is very large, its coverage may require a huge number of detectors, which is infeasible in practice. For example, pure random generation was shown to be infeasible in <ref type="bibr" target="#b29">[30]</ref> for performance reasons. We, therefore, consider the detector generation as a search problem. A generation algorithm should seek to optimize the following two objectives:</p><formula xml:id="formula_0">) ( ) ( ) ( cov _ 1 1 p S a t S a S erage f p i i p i i      </formula><p>(1) Maximize the generality of the detector by minimizing the similarity with the reference code examples; (2) Minimize the overlap (similarity) between detectors. These two objectives define the cost function that evaluates the quality of a solution and, then guides the search. The cost of a solution D (set of detectors) is evaluated as the average costs of the included detectors. We derive the cost of a detector d i as a weighted average between the scores of respectively, the lack of generality and the overlap. Formally, 2</p><formula xml:id="formula_1">) ( ) ( ) ( cos i i i d O d LG d t  </formula><p>Here, we give equal weight to both scores. The lack of generality is measured by a matching score LG(d i ) between the predicate sequence of a detector d i and those of all the classes s j in the reference code (call it RC). It is defined as the average value of the alignment <ref type="bibr" target="#b21">[22]</ref> scores Sim(d i , s j ) between d i and classes s j in RC. Formally,  <ref type="formula">1</ref>To calculate the similarity Sim( ) between two code fragments, we adapted the Needleman-Wunsch alignment algorithm <ref type="bibr" target="#b27">[28]</ref> to our context. It is a dynamic programing algorithm used in bioinformatics to efficiently find similar regions between two sequences of DNA, RNA or protein <ref type="bibr" target="#b30">[31]</ref>. Because the Needleman-Wunsch algorithm finds the optimal alignment of the entire sequence of both proteins, it is a global alignment technique, and cannot be used to find local regions of high similarity. Global Alignment assumes that the two proteins are basically similar over the entire length of one another. The alignment attempts to match them to each other from end to end, even though parts of the alignment are not very convincing. An example of the algorithm is presented in Figure <ref type="figure" target="#fig_7">6</ref>. To adapt the global alignment to our code-smells detection problem, we represented the source code as textual strings as described in the solution representation section. We used textual string representation since we are interested more to the structure of the source code. Thus, we do not need to use the syntax tree representation. In addition, the syntax tree representation cannot be used to compare two code-fragments using the alignment algorithms used in our adaption. The textual representation can reduce the computational cost required to compare the different code-fragments. The Needleman-Wunsch alignment algorithm has been used in different work to detect code clone <ref type="bibr" target="#b31">[32]</ref>[33] with interesting results. This algorithm can efficiently compare two code fragments quickly. This represents one of the main motivations to choose a global alignment algorithm since we need to define an efficient fitness function with the lowest computational complexity. The Needleman-Wunsch global alignment algorithm <ref type="bibr" target="#b27">[28]</ref> is described recursively. When aligning two sequences (a 1 ,...,a n ) and (b 1 ,...,b m ), each position s i,j in the matrix corresponds to the best score of alignment considering the previously aligned elements of the sequences. The algorithm can introduce gaps (represented by "-") to improve the matching of subsequences.</p><formula xml:id="formula_2">             //match a for gap //insert b for gap //insert , 1 , 1 i 1 , j , 1 , j i j i j i j i j i sim s g s g s</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Max s</head><p>where s i,0 = g * i and s 0,j = g * j when aligning two sequences (a 1 ,...,a n ) and (b 1 ,...,b m ). At any given point, the algorithm considers two possibilities. First, it considers the case when a gap should be inserted. When a gap is inserted for either a or b, the algorithm applies a penalty of g. Second, it tries to match predicates. The similarity function sim i,j returns the reward or cost of matching a i to b j . The final similarity is contained in s n,m . Our adaptation of the algorithm is straightforward. We define the gap penalty g and the similarity function to match individual predicates (sim). We do not seek perfect matches in terms of number of predicates. A class with 4 methods is not necessarily different from one with 6 methods if the methods are similar. To eliminate the sensitivity of the algorithm to size, we set the gap penalty to 0. We define a predicate-specific function to measure the similarity. First, if the types differ, the similarity is 0. As we manipulate sequences of complex predicates and not strings, sim i,j is defined as a predicate-matching function, PM ij . PM ij measures the similarity with respect to the elements of the predicates associated to a i and b j . This similarity is the ratio of common parameters in both predicates:</p><p>where a i and b j are treated as sets of predicates. The equivalence between predicate parameters depends on each type of parameter. For visibility and element types, it means equality. Specific names are not considered. Instead, they are used to indicate a common reference by other predicates. For example, if a class defines an attribute and its related getter method, they will both share the same class name. To illustrate an example for the alignment algorithm, let us consider the detector (d32) generated by GA, described previously and a reference code fragment (c152) as described in Figure <ref type="figure" target="#fig_8">7</ref>. The goal is to evaluate the similarity, to maximize, between these two code fragments: the detector generated by GA and an example of a reference code fragment. The code fragments are sequentially numbered. According to the coding mentioned previously, the predicate sequence for d32 is CGAAMPPM and the one of C152 is CMMPR. The alignment algorithm finds the best alignment sequence as shown in Figure <ref type="figure" target="#fig_8">7</ref>. There are three matched predicates between d32 and c152: one class, one method, and one method parameter. If we consider the second matched predicates Method(C12, m154, void, Y, public) from d32 and Method(Options, isFractionalMetrics, boolean, N, public) from c152. The predicates have two common parameters out of possible five ones. The resulting similarity is consequently 40%. We normalize this absolute similarity measure, s n,m , by the maximum number of predicates to produce our overall similarity measure Sim(A,B) between two code fragments (classes): In a real-world scenario, there is no consensus about the definition of code-smells since developers can have diverged opinions about the detection of code-smells then they can converge to a final decision. In general, the consensus is built based on the majority of votes that correspond in our case to the intersection between different class candidates. Furthermore, only 50% of our defined fitness function is based on maximizing the consensus (intersection). In addition, the consideration of the union of GA and GP solutions may increase the recall and not the precision. A huge list of candidates will be proposed to the designer in this case and it is time consuming for him to validate the results to find codesmells. Larger intersection will improve both the precision and recall scores. In fact, if the classes are detected by both algorithms then there is a high probability that they are actual code-smells. To maximize the intersection there are two alternatives: 1) most of the defects are detected by algorithm A (and not by algorithm B) at iteration i will be detected in the future by algorithm B; or 2) most of the defects detected by algorithm A (and not by algorithm B) at iteration i will not be detected anymore in the future by algorithm A. In our adaption, since GA can detect the defects based on a risk score thus in the case that the risk of a defect is high and it is not detected by GP then this defect will be detected in the next iterations of GP because it is the only way to maximize the overall fitness functions of GP and GA (including the intersection). In the case that the risk score affected to a codesmell is low then GA will probably not detect this code-smell in the next iteration because this is the only way to maximize the overall fitness functions of GA and GP (including the intersection). A set of best solutions are selected from both algorithms, in each iteration, and then executed on a new system A to evaluate. A matrix is constructed where rows are composed by best solutions of GP {SGP i }, columns are composed by best solution of GA {SGA j } and each case (SGP i , SGA j ) is defined as: For GA, the best detectors (solution) are used to detect codesmells. The system to evaluate is compared using the alignment algorithm to the obtained detectors. The risk of being a code-smell, associated to a code fragment e i is defined as the average value of the alignment scores Sim(e i , d j ) obtained by comparing e i to respectively all the detectors of a set D. Formally,</p><formula xml:id="formula_3">        A in</formula><formula xml:id="formula_4">D d e Sim risk D d j i e j i    ) , (</formula><p>The code fragments can then be ranked according to their risks to be inspected by the maintainers. In our adaptation, we consider a code fragment to be a code-smell only if the risk is more than 75%. Thus, the fitness function of the GA for a solution O j is defined as: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SGA f O f</head><p>Figure <ref type="figure" target="#fig_9">8</ref> shows a new system A to evaluate. It contains 5 classes. Four best solutions generated by GP (S) and four best solutions are generated by GA are executed in parallel on the system A. Thus, a (4x4) matrix is generated to calculate the intersection between the detect code-smells as illustrated in Figure <ref type="figure" target="#fig_9">8</ref>. For example, two out of three are the same detected code-smells using solution S 12 and R 23 .  <ref type="formula">2</ref>) environmental selection (also named replacement) <ref type="bibr" target="#b26">[27]</ref>. In this work, we use an elitist scheme for both selection phases with the aim to: (1) exploit good genes of fittest solutions and (2) preserve the best solutions along the evolutionary process. The two selections schemes are described as follows. Concerning parent selection, once the population individuals are evaluated, we select the 2 / P best individuals of the population P to fulfill the mating pool, which size is equal to 2 / P . This allows exploiting the past experience of the EA in discovering the best chromosomes' genes. Once this step is performed, we apply genetic operators (crossover and mutation) to produce the offspring population Q, which has the same size as P ( Q P  ). Since crossover and mutation are stochastic operators, some offspring individuals can be worse than some of P individuals. In order to ensure elitism, we merge both population P and Q into U (</p><formula xml:id="formula_5">P Q P U 2   </formula><p>), and then the population P for the next generation will be composed by the P fittest individuals from U. By doing this, we ensure that we do not encourage the survival of a worse individual over a better one. We can say that this environmental selection is elitist, which is a desired property in modern EAs <ref type="bibr" target="#b6">[7]</ref>. Mutation For GP, the mutation operator can be applied to a function node, or a terminal node. It starts by randomly selected a node in the tree. Then, if the selected node is a terminal (quality metric), it is replaced by another terminal (metric or another threshold value); if it is a function (AND-OR), it is replaced by a new function; and if tree mutation is to be carried out, the node and its subtree are replaced by a new randomly generated subtree. For GA, The mutation operator consists of randomly changing a predicate (code element) in the generated predicates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Crossover</head><p>For GP, two parent individuals are selected and a subtree is picked on each one. Then crossover swaps the nodes and their relative subtrees from one parent to the other. This operator must ensure the respect of the depth limits. The crossover operator can be applied with only parents having the same rule category (code-smell type to detect). Each child thus combines information from both parents. In any given generation, a variant will be the parent in at most one crossover operation. For GA, the crossover operator allows to create two offspring o1 and o2 from the two selected parents p 1 and p 2 . It is defined as follows:</p><p>(1) A random position k, is selected in the predicate sequences. Finally, when applying change operators, no individuals are exchanged between the parallel GA/GP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EVALUATION</head><p>In order to evaluate our approach for detecting code-smells using P-EA, we conducted a set of experiments based on different versions of real-world models extracted from large open source systems. Each experiment is repeated 51 times, and the obtained results are subsequently statistically analyzed with the aim to compare our proposal with some single population-based approaches <ref type="bibr" target="#b20">[21]</ref> <ref type="bibr" target="#b21">[22]</ref> in addition to random search and two existing detection techniques not based on meta-heuristic search <ref type="bibr" target="#b15">[16]</ref> <ref type="bibr" target="#b47">[49]</ref>. In this section, we start by presenting our research questions. Then, we describe and discuss the obtained results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Research Questions and Objectives</head><p>The study was conducted to quantitatively assess the completeness and correctness of our code-smells detection approach when applied in real-world settings and to compare its performance with existing approaches. More specifically, we aimed at answering the following research questions (RQs):</p><p> RQ1: To what extent can the proposed approach detect efficiently code-smells (in terms of correctness and completeness)?  RQ2: What types of code-smells does it locate correctly?  RQ3: To what extent does the cooperative parallel meta-heuristic approach performs better than the considered single-population ones?  RQ4: How does P-EA perform compared to the existing code-smells detection approaches not based on the use of metaheuristic search? To answer RQ1, we used an existing corpus <ref type="bibr" target="#b16">[17]</ref> [16] <ref type="bibr" target="#b22">[23]</ref> containing an extensive study of code-smells on different open-source systems: ApacheAnt 1 , Xerces-J 2 , GanttProject 3 , Rhino 4 , Log4J 5 , Lucene 6 , Nutch 7 and JFreeChart 8 . Our goal is to evaluate the correctness and the completeness of our P-EA code-smells detection approach. For RQ2, we investigated the type of code-smells that were found. For RQ3, we compared our results to those produced, over 51 runs, by existing singlepopulation approaches <ref type="bibr" target="#b20">[21]</ref> <ref type="bibr" target="#b21">[22]</ref> in addition to random search. Further details about our experimental setting are discussed in the next subsection. While it is very interesting to show that our proposal outperforms existing search-based code-smells detection approaches, developers will consider our approach useful, if it can outperform other existing tools that are not based on optimization techniques such as DECOR <ref type="bibr" target="#b16">[17]</ref> and JDeodorant <ref type="bibr" target="#b47">[49]</ref>. We selected both techniques because they can detect some of the code-smell types considered in this paper and they are widely used in the literature. Furthermore, both techniques are based on the use of quality metrics to detect code-smells and it is interesting to evaluate the ability of our proposal to better define the detection rules based on quality metrics. The current version of JDeodorant is implemented as an Eclipse plug-in that identifies some types of design defects using quality metrics and then proposes a list of refactoring strategies to fix them. Moha et al. started by describing code-smell symptoms using a domain-specificlanguage (DSL) for their approach called DECOR. They proposed a consistent vocabulary and DSL to specify antipatterns based on the review of existing work on design codesmells found in the literature. To describe code-smell symptoms, different notions are involved, such as class roles and structures. Symptom descriptions are later mapped to detection algorithms. These techniques are not dedicated to all the eight code-smell types that we considered in our experiments thus we performed the comparison using only some specific types of code-smells.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Setting</head><p>Our study considers the extensive evaluation of nine opensource Java analyzed in the literature. JFreeChart is a powerful and flexible Java library for generating charts. GanttProject is a cross-platform tool for project scheduling. ApacheAnt is a build tool and library specifically conceived for Java applications. Nutch is an open source Java implementation of a search engine. Log4j is a Java-based logging utility. Lucene is a free/open source information retrieval software library. Xerces-J is a family of software packages for parsing XML. Finally, Rhino is a JavaScript interpreter and compiler written in Java and developed for the Mozilla/Firefox browser. Table <ref type="table" target="#tab_3">I</ref> reports the size in terms of classes of the analyzed systems. The table also reports the number of code-smells identified manually in the different systems. More than 800 code-smells have been identified manually. Indeed, in <ref type="bibr" target="#b21">[22]</ref>  <ref type="bibr" target="#b16">[17]</ref>, authors asked different groups of developers to analyze the libraries to tag instances of specific code-smells to validate their detection techniques. In our study, we verified the capacity of our approach to locate classes that correspond to instances of eight different types of code-smells: Blob, Spaghetti Code (SC), Functional Decomposition (FD), Feature Envy (FE), Data Class (DC), Lazy Class (LC), Long Parameter List (LPL), Shotgun Surgery (SS).</p><p>We selected these systems for our validation because they range from medium to large-sized open source projects that have been actively developed over the past 10 years, and include a large number of code smells. In addition, these systems are well studied in the literature, and their code smells have been detected and analyzed manually. For GP, one open source project is evaluated by using the remaining systems as a base of code-smells' examples to generate detection rules. For GA, JHotdraw [34] was chosen as an example of reference code because it contains very few known code-smells. In fact, previous work <ref type="bibr" target="#b46">[48]</ref> could not find any Blob in JHotdraw. In our experiments, we used all the classes of JHotdraw as our example set of well-designed code. In general, after executing our P-EA technique the best detectors and detection rules are used to find code-smells in new systems. These code-smells are ranked using a severity score defined as , where ) ( i c Risk represents the maximum global alignment distance between c i and detectors, and ) ( i c RulesDet takes the value 1 if the class c i is detected by the set of rules otherwise it takes 0. We consider a risk of 0.75 as an acceptable threshold value to consider a class as a code-smell. In our experiments, we performed a 9-fold cross validation to remove the system to evaluate from the base of examples. Thus, we repeated this process 9 times and we executed our P-EA approach 51 times on every system to evaluate for the statistical tests.</p><p>To assess the accuracy of our approach, we compute two measures, precision and recall, originally stemming from the area of information retrieval. When applying precision and recall in the context of our study, the precision denotes the fraction of correctly detected code-smells among the set of all detected code-smells. The recall indicates the fraction of correctly detected code-smells among the set of all manually identified code-smells. In general, the precision denotes the probability that a detected code-smell is correct, and the recall is the probability that an expected code-smell is detected. Thus, both values range between 0 and 1, whereas a higher value is better than a lower one. We remove the system to evaluate from the base of codesmell examples when executing our P-EA algorithm then precision and recall scores are calculated automatically based on a comparison between the detected code-smells and expected ones. We compared our results with existing singlepopulation approaches <ref type="bibr" target="#b20">[21]</ref> <ref type="bibr" target="#b21">[22]</ref>. Therefore, we consider GP and GA as separate algorithms. In addition, we compared our P-EA approach to random search. We used precision and recall scores for all these comparisons over 51 runs. Since the 2</p><formula xml:id="formula_6">) ( ) ( ) ( i i i c RulesDet c Risk c Severity  </formula><p>used algorithms are stochastic optimizers, they may produce different results when applied to the same problem instance over different runs. To cope with this stochastic nature, the use of a rigorous statistical testing is essential to provide support to the conclusions derived from analyzing such data. Thus, we used the Wilcoxon rank sum test in a pairwise fashion <ref type="bibr" target="#b33">[35]</ref> in order to detect significant performance differences between the algorithms under comparison. The Wilcoxon test allows testing the null hypothesis H0 that states that both algorithms' medians' values for a particular metric are not statistically different against H1 which states the opposite. The Wilcoxon test does not require that the data sets follow a normal distribution since it operates on values' ranks instead of operating on the values themselves <ref type="bibr" target="#b33">[35]</ref>. Since we are comparing more than two different algorithms, we performed several pairwise comparisons based on Wilcoxon test to detect the statistical difference in terms of performance. To compare two algorithms based on a particular metric, we record the obtained metric's values for both algorithms over 51 runs. After that, we compute the metric's median value for each algorithm. Besides, we launch the Wilcoxon test with a 95% confidence level (α = 0.05) on the recorded metric's values using the Wilcoxon MATLAB routine. If the returned p-value is less than 0.05 than, we reject H0 and we can state that one algorithm outperforms the other, otherwise we cannot say anything in terms of performance difference between the two algorithms. To compare our stochastic approach P-EA and the two deterministic methods DECOR and JDeodorant, we performed also the Wilcoxon test. All obtained results were statistically different against these deterministic methods. This observation is expected since each of DECOR and JDeodorant provides the same output over the 51 runs.</p><p>For our experiment, we generated 150 detectors from deviation with JHotDraw (about a quarter of the number of examples) with a maximum size of 256 characters. The same set of detectors was used on the different open source systems. For GP and GA, population size is fixed at 100 and the number of generations at 1000. For P-EA, the population size is 100 and number of generations 500. In this way, all algorithms perform 100 000 evaluations (fair comparison). A maximum of 15 rules per solution and a set of 13 metrics are considered for GP <ref type="bibr" target="#b8">[9]</ref> <ref type="bibr" target="#b26">[27]</ref>. These standard parameters are widely used in the literature <ref type="bibr" target="#b8">[9]</ref> <ref type="bibr" target="#b10">[11]</ref>. We used the trial and error method to set the population size and the number of generations for each algorithm. This means that we have made several experiments using different values for these parameters. Following these experiments, we concluded that when using a population size of 100 for GA/GP, the fitness function becomes stabilized around the 1000th generation. The same was done for the parallel EA where we concluded that the fitness becomes stabilized from the 500th generation. For these reasons, the algorithms did not suffer from premature convergence; thereby the comparison is fair not only from the stopping criterion viewpoint but also from the parameter setting one.</p><p>For the variation operators, we used crossover probability of 0.9 and a mutation one of 0.5. We used a high mutation rate since we are employing an elitist schema for both GP and GA. In fact, as noted by Eiben and Smith <ref type="bibr" target="#b55">[57]</ref>, elitism may encourage premature convergence to occur. In order to avoid such a problem, in each generation, we emphasize the diversity of the population by means of the high mutation rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Results</head><p>Tables II and III summarize our findings. We only considered classes as a code-smell with a severity level that is greater than or equal 75%; around 5% of the classes in the system are detected as code-smells in the different systems. Overall, as described in table II, we were able to detect codesmells on the different systems with an average precision higher than 85%. For Gantt, Xerces, and Log4J, the precision is higher than for the other systems with more than 90%. This can be explained by the fact that these systems are smaller than others and contain a lower number of code-smells to detect. For Ant-Apache, the precision is also high (around 89%), i.e., most of the detected code-smells are correct. This confirms that our P-EA precision results are independent from the size of the systems to evaluate. For JFreeChart, the precision using P-EA is the lowest (84%) but still acceptable. JFreeChart contains a high number of functional decomposition and feature envy anti-patterns that are difficult to detect using metrics but with the deviance with reference code thus more code-smells can be detected if we use a lower severity score than 75%. For the same dataset, we can conclude that our P-EA approach performs much better (with a 95% confidence level) than existing single-population approaches (GP and GA) on almost all systems since the median precision scores are considerably higher. In fact, P-EA provides better results since some code-smells cannot be detected using only one fitness function based on metrics or deviance from reference code examples. P-EA can detect and rank the detected classes based on the use of both detectors and detection rules that maximizes the consensus. The RS did not perform well in terms of precision due to the huge searchspaces of detectors and rule combinations to explore.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table II.</head><p>Precision median values of PEA, GP, GA and RS over 51 independent simulation runs. A "+" symbol at the i th position means that the algorithm precision median value is statistically different from the i th algorithm one. A "-" symbol at the i th position means the opposite (e.g., for Lucene v.1.4.3, GP precision is not statistically different from PEA and GA ones, however, it is statistically different from RS one). According to table III, The average recall score of P-EA on the different systems is around 87% (better than precision). JFreeChart has the lowest recall score with 81%. Singlepopulation approaches (GP and GA) provide also good results (an average of 74%) but lower than P-EA ones. Our approach is significantly different from existing ones that are rule-based and/or single-population-based. A key problem with existing single population approaches, which are based on detection rules, is that they simplify the different notions/symptoms that are useful for the detection of certain code-smells. In particular, to detect blobs, the notion of size is important. Most size metrics are highly correlated to each others, and the best measure of size can depend on the system itself. In this case, the use of different algorithms in parallel (not only metricsbased algorithms) can help to detect most of the code-smells more efficiently than a single population approach using quality metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table III.</head><p>Recall median values of PEA, GP, GA and RS over 51 independent simulation runs. A "+" symbol at the i th position means that the algorithm precision median value is statistically different from the i th algorithm one. A "-" symbol at the i th position means the opposite (e.g., for Log4J v1.2.1, PEA recall is not statistically different from GP one, however it is statistically different from GA and RS ones). As interesting observation from the results of Table <ref type="table" target="#tab_3">II</ref> and Table <ref type="table" target="#tab_3">III</ref> is that the medians are close, the results are statistically different but the effect size <ref type="bibr" target="#b54">[56]</ref>[57] which quantifies the difference is small for most of the systems and techniques considered in our experiments. The Wilcoxon rank sum test allows verifying whether the results are statistically different or not. However, it does not give any idea about the difference magnitude. The effect size could be computed by using the Cohen's d statistic <ref type="bibr" target="#b55">[57]</ref>. The effect size is considered: (1) small if 0.2 ≤ d &lt; 0.5, (2) medium if 0.5 ≤ d &lt; 0.8, or (3) large if d ≥ 0.8. In conclusion, our technique is able to accurately identify design code-smells (RQ1) more accurately than existing single-population approaches (RQ3). The statistical analysis of the obtained results using the Wilcoxon test confirms these experimental statements on almost all systems, especially for medium and large systems.</p><p>Based on the results of figure <ref type="figure" target="#fig_11">9</ref>, we noticed that our technique does not have a bias towards the detection of specific code-smells types. As described in Figure <ref type="figure" target="#fig_11">9</ref>, in all systems, we had an almost equal distribution of each codesmell types. On some systems such as Nutch, the distribution is not as balanced. This is principally due to the number of actual code-smell types in the system. Having a relatively good distribution of code-smells is useful for a quality engineer. Overall, all the eight code smell types are detected with good precision and recall scores in the different systems (more than 80%). This ability to identify different types of code-smells underlines a key strength to our approach. Most other existing tools and techniques rely heavily on the notion of size to detect code-smells. This is reasonable considering that some code-smells like the Blob are associated with a notion of size. For code-smells like FDs, however, the notion of size is less important and this makes this type of anomaly hard to detect using structural information. This difficulty limits the performance of GP in well detecting this type of code-smells. Thus, we can conclude that our P-EA approach detects well all the types of considered code-smells (RQ2).</p><p>Since it is not sufficient to compare our proposal with only search-based work, we compared the performance of P-EA with DECOR <ref type="bibr" target="#b15">[16]</ref> and JDeodorant <ref type="bibr" target="#b47">[49]</ref>. DECOR was mainly evaluated based on three types of code-smells using metricsbased rules that are identified manually: Blob, functional decomposition and spaghetti code. JDeodorant is an Eclipse plug-in that identifies two main types of bad-smells using a set of quality metrics: blob and LPL. The results of the execution of DECOR and JDeodorant are only available for the following systems: GanttProject, Nutch, Log4J, Lucene and Xerces-J. Figures <ref type="figure" target="#fig_12">10</ref> and<ref type="figure" target="#fig_13">11</ref> summarize the results of the precision and recall obtained on the above-mentioned 5 systems. The recall for DECOR in all the systems is 100% signifying that it is better than P-EA, however the precision scores are lower than our proposal on all systems. For example, the average precision to detect functional decompositions using DECOR is lower than 25%, whereas we can detect this type of code-smells with more than 90% of precision. The same observation is valid for the spaghetti-code (SC), BLOP is able to detect SC with more than 83% in terms of precision however DECOR detected the same type of codesmell with a precision lower than 62%. This can be explained by the high calibration effort required to define manually the detection rules in DECOR for some specific code-smell types and the ambiguities related to the selection of the best metrics set. The recall of P-EA is lower than DECOR, in average, but it is still acceptable, i.e., higher than 87%. The same observations are also valid for JDeodorant as described in Figure <ref type="figure" target="#fig_13">11</ref>. P-EA outperforms JDeodroant in terms of precision and recall on all the evaluated systems. The average precision and recall of JDeodorant for both code-smell types are respectively 76% and 73%. To conclude, our P-EA proposal also outperforms, in average, an existing approach not based on meta-heuristic search (RQ4).   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. DISCUSSIONS</head><p>In this section, we discuss different issues concerning our P-EA detection approach. An important factor to our detection technique is the severity threshold value that to decide if a detected class can be considered as a code-smell or not. In Figure <ref type="figure" target="#fig_10">12</ref>, we present the precision and recall scores of our approach when varying the severity threshold (St) with St  {95, 90, 85, 80, 75, 70, 65}. The figure shows that the precision of our approach improves as we consider a higher severity score whereas the recall score decreases and viceversa. In fact, we observe that 75% of severity threshold represents a good trade-off between precision and recall scores. We can generalize this threshold since we evaluate the different St values on the eight systems considered in the experiments. However, developers can choose other threshold values if they want to increase precision in some contexts (for example, to reduce the manual inspection time). Another observation is that our severity score represents a good indication of the risk of detected classes. In fact, all classes ranked in the top correspond to a real code-smell since the precision becomes lower if the severity threshold decreases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig 12.</head><p>The impact of the severity threshold on detection results (average precision and recall scores on all systems to evaluate).</p><p>Figure <ref type="figure" target="#fig_2">13</ref> shows that the performance of our approach improves as we increase the percentage of best solutions (from each population of detectors and rules) for intersection at each iteration. However, the results become stable after 5%. For this reason, we considered this threshold in our experiments. Our P-EA technique requires the comparison of every selected GP solution to every selected GA solution, thus the execution time needs to be considered (number of comparison). Indeed, we believe that 5% are a good threshold value for a population of 100 individuals (around 25 comparisons per iteration) to keep reasonable execution time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig 13.</head><p>The impact of percentage of best solutions selected for the intersection process on detection results (average precision and recall scores on all systems to evaluate).</p><p>The reliability of the proposed approach requires an example set of good code and code-smell examples. It can be argued that constituting such a set might require more work than identifying and adapting code-smells detection rules. In our study, we showed that by using JHotdraw directly, without any adaptation, the P-EA method can be used out of the box and this will produce good detection results for the detection of code-smells for the eight studied systems. In an industrial setting, we could expect a company to start with JHotDraw, and gradually transform its set of good code examples to include context-specific data. This might be essential if we consider that different languages and software infrastructures have different best/worst practices. Figures <ref type="figure" target="#fig_15">14 shows that</ref>   The detection results might vary depending on the search space exploration, since solutions are randomly generated, though guided by a meta-heuristic. To ensure that our results are relatively stable, we compared the results of multiple executions for P-EA on GanttProject as shown in figure <ref type="figure" target="#fig_16">15</ref> (over 51 runs). Based on the statistical analysis, described previously, similar observations were obtained with the other projects regarding the stability. We believe that our approach is stable, since the scores are approximately the same for 51 different executions on the different systems. In addition, the statistical analysis performed, during the comparison against the other algorithms, confirms the stability of our results. Usually in the optimization research field, the most time consuming operation is the evaluation step <ref type="bibr" target="#b6">[7]</ref>. Thus, we show how our P-EA is more efficient than the GA and GP from a CPU time viewpoint. In fact, all the algorithms under comparison were executed on machines with Intel Xeon 3 GHz processors and 4 GB RAM. We note that each of GA and GP were run on a single machine. However, our P-EA was executed on two nodes (machines) following the previously described parallel model. We recall that all algorithms were run for 100 000 evaluations. This allows us to make a fair comparison between CPU times. Figure <ref type="figure" target="#fig_17">16</ref> illustrates the obtained CPU times of all algorithms on each of the considered systems (cf. table <ref type="table" target="#tab_3">III</ref>). We note that the results presented in this figure were analyzed by using the same previously described statistical analysis methodology. In fact, based on the obtained p-values regarding CPU times, the P-EA is demonstrated to be faster than GA and GP as highlighted through figure <ref type="figure" target="#fig_17">16</ref>. The P-EA spends approximately the half amount of time required for GA or GP. This observation could be explained by the fact that the performed 100 000 evaluations are distributed between the two machines (50 000 for each). In this way, the P-EA is able to evaluate 200 individuals at each iteration, which is not the case for GA or GP which evaluates only 100 individuals at each iteration. We can see that parallelization seems to be an interesting approach to tackle software engineering problems where the individual evaluations are expensive like the codesmells detection problem.</p><p>Figure <ref type="figure" target="#fig_18">17</ref> illustrates the evolution of precision, recall and CPU time with respect to the increase of system size (number of classes). We see from this figure that the precision and recall values are stable even if the system size increases. The same observation could be seen for CPU time which is between 1 hour and 1 hour and 45 minutes. We can say that PEA is scalable with respect to system size since it gives high precision and recall values for an acceptable execution time.  One of the main reasons explaining the outperformance of our technique relative to DECOR and JDeodroant is that they use relatively permissive constraints/rules, which sacrifice the precision and guarantee a high recall. In addition, these tools do not provide a ranking of the severity of the detected code smells. Thus, the classes that do not satisfy the rules are not considered as code smells (deterministic process). However, in our technique, we rank the detected classes based on the severity score, and this can explain the high-precision scores obtained by our technique. Furthermore, some types of code smells such as the functional decomposition are difficult to detect using quality metrics. The use of two different detection techniques in parallel explains the detection of code smells that are hard to detect using only quality metrics (GP). Another observation is related to the systems used in our experiments where some of them have different programming contexts. This explains why the performance of P-EA is different on the systems under evaluation since the results depend on the base of examples that should contain a diversified set of systems with different programming contexts to generate good quality of rules and detectors. However, this is an issue that can be fixed by improving the quality of the base of examples and classifying the systems based on their size, context, etc. The base of examples is updated automatically with new code smell examples detected by our tool on new systems after validating them manually by software engineers. Thus, after several revisions of the base of examples, the P-EA algorithm can be executed to refine the rules and detectors. A software company can use our tool using their previous projects as a training set to generate a high quality of rules and detectors that take into consideration the programming behaviour of their developers. However, our experiments show that open source systems can be considered as a good starting point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. THREATS TO VALIDITY</head><p>Following the methodology proposed by Wohlin et al. <ref type="bibr" target="#b51">[53]</ref>, there are four types of threats that can affect the validity of our experiments. We consider each of these in the following paragraphs. Conclusion validity is concerned with the statistical relationship between the treatment and the outcome. We used the Wilcoxon rank sum test with a 95% confidence level to test if significant differences exist between the measurements for different treatments. This test makes no assumption that the data is normally distributed and is suitable for ordinal data, so we can be confident that the statistical relationships we observed are significant. In our comparison with the techniques not based on heuristic search, we considered the parameters provided with the tools. This is can be considered as a threat that can be addressed in the future by evaluating the impact of different parameters on the quality of the results of DECOR and JDeodorant. Internal validity is concerned with the causal relationship between the treatment and the outcome. We consider the internal threats to validity in the use of stochastic algorithms since our experimental study is performed based on 51 independent simulation runs for each problem instance and the obtained results are statistically analyzed by using the Wilcoxon rank sum test <ref type="bibr" target="#b33">[35]</ref> with a 95% confidence level (α = 5%). However, the parameter tuning of the different optimization algorithms used in our experiments creates another internal threat that we need to evaluate in our future work. The parameters' values used in our experiments are found by trial-and-error method, which is commonly used in the SBSE community <ref type="bibr" target="#b53">[55]</ref>. However, it would be an interesting perspective to design an adaptive parameter tuning strategy <ref type="bibr" target="#b52">[54]</ref> for our approach so that parameters are updated during the execution in order to provide the best possible performance. Construct validity is concerned with the relationship between theory and what is observed. Most of what we measure in our experiments are standard metrics such as precision and recall that are widely accepted as good proxies for quality of codesmells detection solutions. The notion of "intersection" we use in this paper is new and so constitutes a possible threat to construct validity. However, we discussed in the experimentations section several threshold values regarding the number of solutions considered at each iteration for intersection. We also used two evolutionary algorithms in our P-EA approach. We do not anticipate that very different results would be obtained using other meta-heuristics algorithm with the same problem formulation. In our future work, we plan to compare the performance of P-EA using different meta-heuristics search algorithms. Another construct validity threat is related to the absence of similar work that uses distributed evolutionary algorithms for code-smells detection. For that reason, we compare our proposal with other existing techniques not based on distributed algorithms.</p><p>Another threat to construct validity arises because, although we considered 8 types of code-smells, we did not evaluate the detection of other types of code-smells. In future work, we plan to evaluate the performance of our P-EA proposal to detect some other types of code-smell. Another construct threat can be related to the corpus of manually detected code smells since developers do not all agree if a candidate is a code smell or not. We will ask some new experts to extend the existing corpus and provide additional feedback regarding the detected code smells. External validity refers to the generalizability of our findings. In this study, we performed our experiments on eight different widely used open-source systems belonging to different domains and with different sizes, as described in table 1. However, we cannot assert that our results can be generalized to industrial Java applications, other programming languages, and to other practitioners. Future replications of this study are necessary to confirm our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. RELATED WORK</head><p>There are several studies that have recently focused on detecting code-smells in software using different techniques. These techniques range from fully automatic detection to guided manual inspection. Nevertheless, there is no work that focuses on combining different detection algorithms to find a consensus when identifying code-smells. In this paper, we classify existing approaches for code-smells detection into seven broad categories: manual approaches, symptom-based approaches, rule-based approaches, probabilistic approaches, visualization-based approaches, search-based approaches and cooperative-based approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Manual approaches</head><p>In the literature, the first book that has been specially written for design smells was by Brown et al. <ref type="bibr" target="#b12">[13]</ref> which provide broad-spectrum and large views on design smells, and antipatterns that aimed at a wide audience for academic community as well as in industry. Indeed, in <ref type="bibr" target="#b24">[25]</ref>, Fowler and Beck have described a list of design smells which may exist in a program. They suggested that software maintainers should manually inspect the program to detect existing design smells. In addition, they specify particular refactorings for each codesmell type. Travassos et al. <ref type="bibr" target="#b34">[36]</ref> have also proposed a manual approach for detecting code-smells in object-oriented designs. The idea is to create a set of "reading techniques" which help a reviewer to "read" a design artifact for finding relevant information. These reading techniques give specific and practical guidance for identifying code-smells in objectoriented design. So that, each reading technique helps the maintainer focusing on some aspects of the design, in such a way that an inspection team applying the entire family should achieve a high degree of coverage of the design code-smells. In addition, in <ref type="bibr" target="#b35">[37]</ref>, another proposed approach is based on violations of design rules and guidelines. This approach consists of analyzing legacy code, specifying frequent design problems as queries and locating the occurrences of these problems in a model derived from the source code. However, the majority of the detected problems were simple ones, since it is based on simple conditions with particular threshold values. As a consequence, this approach did not address complex design code-smells. The main disadvantage of exiting manual approaches is that they are ultimately a human-centric process which requires a great human effort and strong analysis and interpretation effort from software maintainers to find design fragments that correspond to code-smells. In addition, these techniques are time-consuming, error-prone and depend on programs in their contexts. Another important issue is that locating code-smells manually has been described as more a human intuition than an exact science. To circumvent the above-mentioned problems, some semi-automated approaches have emerged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Symptom-based detection</head><p>Moha et al. <ref type="bibr">[16][17]</ref> started by describing code-smell symptoms using a domain-specific-language (DSL) for their approach called DECOR. They proposed a consistent vocabulary and DSL to specify anti-patterns based on the review of existing work on design code-smells found in the literature. To describe code-smell symptoms, different notions are involved, such as class roles and structures. Symptom descriptions are later mapped to detection algorithms. However, converting symptoms into rules needs a significant analysis and interpretation effort to find the suitable threshold values. In addition, this approach uses heuristics to approximate some notions, which results in an important rate of false positives. Similarly, Munro <ref type="bibr" target="#b36">[38]</ref> have proposed description and symptoms-based approach using a precise definition of bad smells from the informal descriptions given by the originators Fowler and Beck <ref type="bibr" target="#b24">[25]</ref>. The characteristics of design code-smells have been used to systematically define a set of measurements and interpretation rules for a subset of design code-smells as a template form. This template consists of three main parts: a code smell name, a text-based description of its characteristics, and heuristics for its detection. The major limitation of symptoms-based approaches is that there exists no consensus in defining symptoms. A code-smell may have several and different interpretations by a maintainer. Another limitation is that for an exhaustive list of code-smells, the number of possible code-smells to be manually described, characterized with rules and mapped to detection algorithms can be very large. Indeed, the background and knowledge of maintainers affect their understanding of code-smells, given a set of symptoms. As a consequence, symptoms-based approaches are also considered as time-consuming and errorprone. Thus automating the detection of design code-smells is still a real challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Metric-based approaches</head><p>The idea to automate the problem of design code-smells detection is not new; neither is the idea to use quality metrics to improve the quality of software systems. Marinescu <ref type="bibr" target="#b18">[19]</ref> have proposed a mechanism called "detection strategy" for formulating metrics-based rules that capture deviations from good design principles and heuristics. Detection strategies allow to a maintainer to directly locate classes or methods affected by a particular design code-smell. As such, Marinescu has defined detection strategies for capturing around ten important flaws of object-oriented design found in the literature. After his suitable symptom-based characterization of design code-smells, Munro <ref type="bibr" target="#b36">[38]</ref> proposed metric-based heuristics for detecting code-smells, which are similar to Marinescu's detection strategies. Munro has also performed an empirical study to justify his choice of metrics and thresholds for detecting smells. Salehie et al. <ref type="bibr" target="#b38">[40]</ref> proposed a metric-based heuristic framework to detect and locate object-oriented design flaws similar to those illustrated by Marinescu <ref type="bibr" target="#b13">[14]</ref>. It is accomplished by evaluating design quality of an object-oriented system through quantifying deviations from good design heuristics and principles by mapping these design flaws to class level metrics such as complexity, coupling and cohesion by defining rules. Erni et al. <ref type="bibr" target="#b39">[41]</ref> introduce the concept of multi-metrics, as an n-tuple of metrics expressing a quality criterion (e.g., modularity). Unfortunately, multi-metrics neither encapsulate metrics in a more abstract construct, nor do they allow a flexible combination of metrics. In general, the effectiveness of combining metric/threshold is not obvious. That is, for each code-smell, rules that are expressed in terms of metric combinations need a significant calibration effort to find the fitting threshold values for each metric. Since there exists no consensus in defining design smells, different threshold values should be tested to find the best ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Probabilistic approaches</head><p>Probabilistic approaches represent another way for detecting code-smells. Alikacem et al <ref type="bibr" target="#b40">[42]</ref> have considered the codesmells detection process as a fuzzy-logic problem, using rules with fuzzy labels for metrics, e.g., small, medium, large. To this end, they proposed a domain-specific language that allows the specification of fuzzy-logic rules that include quantitative properties and relationships among classes. The thresholds for quantitative properties are replaced by fuzzy labels. Hence, when evaluating the rules, actual metric values are mapped to truth values for the labels by means of membership functions that are obtained by fuzzy clustering. Although, fuzzy inference allows to explicitly handle the uncertainty of the detection process and ranks the candidates, authors did not validate their approach on real programs. Recently, another probabilistic approach has been proposed by Khomh et al. <ref type="bibr" target="#b19">[20]</ref> extending the DECOR approach <ref type="bibr" target="#b15">[16]</ref>, a symptom-based approach, to support uncertainty and to sort the code-smell candidates accordingly. This approach is managed by Bayesian belief network (BBN) that implements the detection rules of DECOR. The detection outputs are probabilities that a class is an occurrence of a code-smell type, i.e., the degree of uncertainty for a class to be a code-smell. They also showed that BBNs can be calibrated using historical data from both similar and different context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Visualization-based approaches</head><p>The high rate of false positives generated by the abovementioned approaches encouraged other teams to explore semi-automated solutions. These solutions took the form of visualization-based environments. The primary goal is to take advantage of the human capability to integrate complex contextual information in the detection process. Kothari et al. <ref type="bibr" target="#b43">[45]</ref> present a pattern-based framework for developing tool support to detect software anomalies by representing potential code-smells with different colors. Dhambri et al. <ref type="bibr" target="#b44">[46]</ref> have proposed a visualization-based approach to detect design anomalies by automatically detecting some symptoms and letting others to human analyst. The visualization metaphor was chosen specifically to reduce the complexity of dealing with a large amount of data. Although visualization-based approaches are efficient to examine potential code-smells on their program and in their context, they do not scale to large systems easily. In addition, they require great human expertise, and thus they are still time-consuming and errorprone strategies. Moreover, the information visualized is mainly metric-based, meaning that complex relationships can be difficult to detect. Indeed, since visualization approaches and tools such as VERSO <ref type="bibr" target="#b37">[39]</ref> are based on manual and human inspection, they still, not only, slow and timeconsuming, but also subjective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Search-based approaches</head><p>Our is inspired by contributions in the domain of Search-Based Software Engineering (SBSE) <ref type="bibr">[24][47]</ref>. SBSE uses search-based approaches to solve optimization problems in software engineering. Once a software engineering task is framed as a search problem, many search algorithms can be applied to solve that problem. In <ref type="bibr" target="#b40">[42]</ref>, we have proposed another approach, based on search-based techniques, for the automatic detection of potential code-smells in code. The detection is based on the notion that the more code deviates from good practices, the more likely it is bad. In another work <ref type="bibr" target="#b20">[21]</ref>, we generated detection rules defined as combinations of metrics/thresholds that better conform to known instances of bad-smells (examples). Then, the correction solutions, a combination of refactoring operations, should minimize the number of bad-smells detected using the detection rules. Thus, our previous work treats the detection and correction as two different steps. In this work, we combine between our two previous work <ref type="bibr" target="#b20">[21]</ref>[22] using P-EA to detect code-smells. Machine learning represents another alternative for detecting design code-smells. Catal et al. <ref type="bibr" target="#b49">[51]</ref> used different machine learning algorithms to predict defective modules. They investigated the effect of dataset size, metrics set, and feature selection techniques for software fault prediction problem. They employed several algorithms based on artificial immune systems (AIS). Kessentini et al. <ref type="bibr" target="#b21">[22]</ref> have proposed a codesmell detection algorithm based on the idea that the more code deviates from good practices, the more likely it is bad. This approach learns from examples of well-designed and implemented software elements, to estimate the risks of classes to deviate from "normality", i.e., a set of classes representing "good" design that conforms to object-oriented principles. Elements of assessed systems that diverge from normality to detectors are considered as risky. Although this approach succeeded in discovering risky code, it does not provide a mechanism to identify the type of the detected codesmell. Similarly, Hassaine et al. <ref type="bibr" target="#b50">[52]</ref> have proposed an approach for detecting design smells using machine learning technique inspired from the AIS. Their approach is designed to systematically detect classes whose characteristics violate some established design rules. Rules are inferred from sets of manually-validated examples of code-smells reported in the literature and freely-available. The major benefit of machinelearning based approaches is that it does not require great experts' knowledge and interpretation. In addition, they succeeded, to some extent, to detect and discover potential code-smells by reporting classes that are similar (even not identical) to the detected code-smells. However, these approaches depend on the quality and the efficiency of data, i.e., code-smell instances, to learn from. Indeed, the high level of false positives represents the main obstacle for these approaches. Based on recent SBSE surveys <ref type="bibr" target="#b45">[47]</ref>, the use of parallel metaheuristic search is still very limited in software engineering. Indeed, there is no work that uses cooperative parallel metaheuristic search to detect code smells. This is the first adaptation of cooperative parallel metaheuristics to solve a software engineering problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Cooperative-based approaches in Software Engineering</head><p>Some cooperative approaches to address software engineering problems have been proposed recently. Arcuri and Yao <ref type="bibr" target="#b48">[50]</ref> handled the bug fixing problem using a competitive coevolutionary approach in which programs and test cases coevolve, influencing each other with the aim of fixing the maximum number of bugs in the programs. Adamopoulos et al. <ref type="bibr" target="#b49">[51]</ref> tackled the mutation testing problem using a competitive co-evolutionary approach. The goal is to improve the efficiency of generated test cases by evaluating their capabilities to kill mutants (introduced errors in the system). Ren et al. <ref type="bibr" target="#b50">[52]</ref> proposed a cooperative co-evolutionary approach for software project staff assignments and job scheduling to minimize the completion time. The two main tasks that are handled in parallel are finding the best sequence of work packages and staff assignments to teams. Our P-EA proposal is different from existing co-evolutionary approaches. First, we propose this is the first time that the problem of code-smells detection is formulated in a cooperative way. Second, existing co-evolutionary approaches are composed by two populations addressing two different problems. However, our P-EA proposal is based on two populations that are addressing the same problem from different perspectives. Third, the P-EA formulation presented in this paper is based on the notion of "intersection" which is not used by existing work. Finally, the two populations are executed on two different machines in parallel in our P-EA framework. However, most of the co-evolutionary approaches are implemented in a sequential way (co-evolution).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. CONCLUSION</head><p>In this paper, we proposed a new search-based approach for code-smells detection. In our cooperative parallel metaheuristic adaptation, two populations evolve simultaneously with the objective of each depending upon the current population of the other in a cooperative manner. The first population generates a set of detection rules using genetic programming and simultaneously a second population tries to detect code-smells using a deviation from examples of welldesigned codes. Both populations are executed, on the same system to evaluate, and the solutions are penalized based on the consensus found, i.e.: intersection between the detection results of both populations. The best detection results will be the code-smells detected by the majority of the algorithms. The statistical analysis of the obtained results provides compelling evidence that cooperative P-EA outperforms single population evolution and random search based on a benchmark of several large open-source systems.</p><p>Future work should validate our approach with additional code-smell types in order to conclude about the general applicability of our methodology. Furthermore, in this paper, we only focused on the detection of code-smells. We are planning to extend the approach by automating the correction of code-smells. In addition, we will consider the importance of code-smells during the detection step using previous codechanges, classes-complexity, etc. Thus, the detected codesmells will be ranked not only based on the severity score but also an importance score. We will evaluate also the use of more than two algorithms executed in parallel as part of our future work. An increase of the number of algorithms executed in parallel can have a negative impact on the quality of the results since it will be more difficult to find a consensus between them. Another future research direction related to our work is to adapt our parallel evolutionary approach to several other software engineering problems such as software testing and the next release problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig 2 .</head><label>2</label><figDesc>Fig 2. High-level pseudo-code for P-EA adaptation to our problem: (a) GP is executed to generate detection rules from code-smell examples; (b) GA is executed in parallel to generate detectors from well-designed code examples. Both algorithms interact with each other using "fitness_intersection" function in each interaction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Input:</head><label></label><figDesc>Set of quality metrics M. Input: Set of systems S evaluated manually (defects examples). Input: New system A. Output: Detection rules. 1: I1:= rules(M, Defect_Type); 2: P1:= set_of(I1); 3: initial_populationGP(P1, Max_size) ; 4: repeat 5: for all I1 P1 do 6: detected_defects _GP(S) := execute_rules(I1, S); 7: fitness(I1) := compare(detected_defects, defects_examples); 8: end for 9: best_sol_P1 := select(P1, number_best_solutions); 10: send (best_sol_P1); 11: best_sol_P2 := receive(best_sol_P2); 12: for all I1 best_sol_P1 do 13: detected defects _GP(A) := execute_rules(I1, A); 14: fitness_intersection (I1) := Max_intersection(detected defects _GP(A, I1)  detected_defects _GA(A, best_sol_P2)); 15: fitness(I1) := updatefitness (I1, fitness_intersection); 16: end for 17: best_solution_P1 := best_fitness(P1); 18: P1 := generate_new_population(P1); 19: it:=it+1; 20: until it=max_it 21: return best_solution_rules Input: Set of well-designed code examples GE. Input: New system A Output: Detectors. 1: I2 := detectors(GE); 2: P2= set_of(I2) ; 3: initial_populationGA(P2, Max_size) ; 4: repeat 5: for all I2 P2 do 6: fitness(I2) := distance(detectors_I2, GE); 7: end for 8: best_sol_P2 := select(P2, number_solutions); 9: send(best_sol_P2); 10: best_sol_P1 := receive(best_sol_P1); 11: for all I2 best_sol_P2 do 12: detected_defects _GA(A) := execute_detectors(I2, A); 13: fitness_intersection (I2) := Max_intersection(detected defects _GA(A, I2)  detected_defects _GP(A, best_sol_P1)); 14: fitness(I2) := updatefitness (I2, fitness_intersection); 15: end for 16: best_solution_P2 := best_fitness(P2); 17: P2 := generate_new_population(P2); 18: it:=it+1; 19: until it=max_it 20: return best_solution_detectors</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig 3 .</head><label>3</label><figDesc>Fig 3. Solution representation: Tree (GP) to generate rules</figDesc><graphic coords="6,313.20,50.40,246.55,148.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig 4 .</head><label>4</label><figDesc>Fig 4. Solution representation: vector (GA) to generate detectors</figDesc><graphic coords="6,313.20,589.87,251.30,125.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5</head><label>5</label><figDesc>Figure5illustrates the above-described function where we consider a base of examples containing one system evaluated manually. The true code-smells of this system are described in the base of examples' table. The classes detected after executing the solution generating the rules R1, R2 and R3 are described in the detection result table. Thus, only one class corresponds to a true code-smell (Person). Classroom is a code-smell, but the type is wrong and Professor is not a codesmell. The fitness function has the value 0.25 as illustrated in the figure. The base of examples used by the GP contains only examples of code smells and not examples of good code. In fact, an example of BLOB could be at the same time an example of non-spaghetti code. However, if we consider that there is only one type of code smell, then a rule that simply classifies everything as being code smell would obtain very high fitness if the base of examples does not contain any example of good code.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig 5 .</head><label>5</label><figDesc>Fig 5. Coverage of the base of code-smell examples Detector evaluation (used by GA):This section describes how a set of detectors is produced starting from the reference code examples. The idea is to produce a set of detectors that best covers the possible deviations from the reference code. As the set of possible deviations is very large, its coverage may require a huge number of detectors, which is infeasible in practice. For example, pure random generation was shown to be infeasible in<ref type="bibr" target="#b29">[30]</ref> for performance reasons. We, therefore, consider the detector generation as a search problem. A generation algorithm should seek to optimize the following two objectives:(1) Maximize the generality of the detector by minimizing the similarity with the reference code examples; (2) Minimize the overlap (similarity) between detectors. These two objectives define the cost function that evaluates the quality of a solution and, then guides the search. The cost of a solution D (set of detectors) is evaluated as the average costs of the included detectors. We derive the cost of a detector d i as a weighted average between the scores of respectively, the lack of generality and the overlap. Formally,</figDesc><graphic coords="7,313.20,50.40,252.00,141.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>overlap O i , is measured by the average value of the individual Sim(d i , d j ) between the detector d i and all the other detectors d j in the solution D. Formally,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig 6 .</head><label>6</label><figDesc>Fig 6. Global alignments of two strings (code-fragments).</figDesc><graphic coords="8,46.80,245.88,269.00,118.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig 7 .</head><label>7</label><figDesc>Fig 7. Global alignment illustrationIntersection score (used by both algorithms)In a real-world scenario, there is no consensus about the definition of code-smells since developers can have diverged opinions about the detection of code-smells then they can converge to a final decision. In general, the consensus is built based on the majority of votes that correspond in our case to the intersection between different class candidates. Furthermore, only 50% of our defined fitness function is based on maximizing the consensus (intersection). In addition, the consideration of the union of GA and GP solutions may increase the recall and not the precision. A huge list of candidates will be proposed to the designer in this case and it is time consuming for him to validate the results to find codesmells. Larger intersection will improve both the precision and recall scores. In fact, if the classes are detected by both algorithms then there is a high probability that they are actual code-smells. To maximize the intersection there are two alternatives: 1) most of the defects are detected by algorithm A (and not by algorithm B) at iteration i will be detected in the future by algorithm B; or 2) most of the defects detected by algorithm A (and not by algorithm B) at iteration i will not be detected anymore in the future by algorithm A. In our adaption, since GA can detect the defects based on a risk score thus in the case that the risk of a defect is high and it is not detected by GP then this defect will be detected in the next iterations of GP because it is the only way to maximize the overall fitness functions of GP and GA (including the intersection). In the case that the risk score affected to a codesmell is low then GA will probably not detect this code-smell in the next iteration because this is the only way to maximize the overall fitness functions of GA and GP (including the intersection). A set of best solutions are selected from both algorithms, in each iteration, and then executed on a new system A to evaluate. A matrix is constructed where rows are composed by best solutions of GP {SGP i }, columns are composed by best solution of GA {SGA j } and each case (SGP i , SGA j ) is defined as:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig 8 .</head><label>8</label><figDesc>Fig 8. Illustration of the intersection function C. Evolutionary Operators Selection One of the most important steps in any EA is selection. There are two selection phases in EAs: (1) parent selection (also named mating pool selection) and (2) environmental selection (also named replacement)<ref type="bibr" target="#b26">[27]</ref>. In this work, we use an elitist scheme for both selection phases with the aim to: (1) exploit good genes of fittest solutions and (2) preserve the best solutions along the evolutionary process. The two selections schemes are described as follows. Concerning parent selection, once the population individuals are evaluated, we</figDesc><graphic coords="10,46.80,50.40,252.70,177.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>( 2 )</head><label>2</label><figDesc>The first k elements of p 1 become the first k elements of o 1 . Similarly, the first k elements of p 2 become the first k elements of o 2 . (3) The remaining elements of, respectively, p 1 and p 2 are added as second parts of, respectively, o 2 and o 1 . For instance, if k = 3 and p 1 = CAMMPPP and p 2 = CMPRMPP, then o 1 = CAMRMPP and o 2 = CMPMPPP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig 9 .</head><label>9</label><figDesc>Fig 9. Distribution of detected code-smells on the 9 systems.</figDesc><graphic coords="14,63.55,62.00,485.59,157.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig 10 .</head><label>10</label><figDesc>Fig 10. The average precision and recall scores of P-EA and DECOR obtained on GanttProject, Nutch, Log4J, Lucene and Xerces-J based on three code-smell types (Blob, SC and FD).</figDesc><graphic coords="14,63.55,242.55,485.00,185.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig 11 .</head><label>11</label><figDesc>Fig 11. The average precision and recall scores of P-EA and JDeodorant obtained on GanttProject, Nutch, Log4J, Lucene and Xerces-J based on two code-smell types (Blob and LPL).</figDesc><graphic coords="14,63.55,463.05,485.00,182.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>only code-smell examples extracted from five different open source systems can be used to obtain good precision and recall scores.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig 14 .</head><label>14</label><figDesc>Fig 14. The impact of the number of code-smell examples on detection results (precision and recall scores are calculated on GanttProject).</figDesc><graphic coords="15,313.95,392.48,249.95,123.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig 15 .</head><label>15</label><figDesc>Fig 15. Execution of P-EA algorithm over 51 runs on GanttProject.</figDesc><graphic coords="16,51.23,50.40,243.15,128.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig 16 .</head><label>16</label><figDesc>Fig 16. Average execution time comparison (over 51 runs) on the different systems.</figDesc><graphic coords="16,314.55,50.40,249.30,139.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig 17 .</head><label>17</label><figDesc>Fig 17. Scalability of P-EA with respect to system size.One of the main reasons explaining the outperformance of our technique relative to DECOR and JDeodroant is that they use relatively permissive constraints/rules, which sacrifice the precision and guarantee a high recall. In addition, these tools do not provide a ranking of the severity of the detected code smells. Thus, the classes that do not satisfy the rules are not considered as code smells (deterministic process). However, in our technique, we rank the detected classes based on the severity score, and this can explain the high-precision scores obtained by our technique. Furthermore, some types of code smells such as the functional decomposition are difficult to detect using quality metrics. The use of two different detection techniques in parallel explains the detection of code smells that are hard to detect using only quality metrics (GP). Another observation is related to the systems used in our experiments where some of them have different programming contexts. This explains why the performance of P-EA is different on the systems under evaluation since the results depend on the base of examples that should contain a diversified set of systems with different programming contexts to generate good quality of rules and detectors. However, this is an issue that can be fixed by improving the quality of the base of examples and classifying the systems based on their size, context, etc. The base of examples is updated automatically with new code smell examples detected by our tool on new systems after validating them manually by software engineers. Thus, after several revisions of the base of examples, the P-EA algorithm can be executed to refine the rules and detectors. A software company can use our tool using their previous projects as a training set to generate a</figDesc><graphic coords="16,313.20,224.40,254.70,155.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Then, the intersection score for each solution is defined as: To sum-up, the fitness function of the GP algorithm for a solution S i is defined as:</figDesc><table><row><cell>f</cell><cell cols="3">int</cell><cell cols="2">er</cell><cell cols="3">sec</cell><cell cols="3">tion</cell><cell cols="2">(</cell><cell cols="5">SGP i</cell><cell></cell><cell cols="2">,</cell><cell cols="3">SGA</cell><cell>j</cell><cell>)</cell><cell></cell><cell>2 PR</cell><cell>,</cell><cell>where</cell></row><row><cell cols="5">PR</cell><cell cols="3"></cell><cell cols="17">on A on SGA j SGA by by detected detected smells smells -code -code # A, j  on A SGP i on SGP by detected by detected smells smells -code -code (# M ax i</cell><cell>A)</cell></row><row><cell cols="2"></cell><cell></cell><cell></cell><cell></cell><cell cols="6">code</cell><cell cols="2">-</cell><cell></cell><cell cols="9">smells</cell><cell cols="2">detected</cell><cell>by</cell><cell>- code A on actual SGP # i</cell><cell>smells -code</cell><cell>smells</cell><cell>detected</cell><cell>by</cell><cell>SGA</cell><cell>j</cell><cell>on</cell><cell>A</cell></row><row><cell cols="3">f</cell><cell cols="4">int</cell><cell cols="3">er</cell><cell cols="4">sec</cell><cell></cell><cell cols="3">tion</cell><cell cols="3">(</cell><cell cols="4">i SGP</cell><cell>)</cell><cell></cell><cell>Min</cell><cell></cell><cell>f</cell><cell>int</cell><cell>er</cell><cell>sec</cell><cell>tion</cell><cell>(</cell><cell>i SGP</cell><cell>,</cell><cell>j  SGA</cell><cell>)</cell><cell></cell><cell>and</cell></row><row><cell cols="3">f</cell><cell cols="4">int</cell><cell cols="3">er</cell><cell cols="3">sec</cell><cell cols="4">tion</cell><cell cols="3">(</cell><cell cols="5">SGA</cell><cell>j</cell><cell>)</cell><cell>Min</cell><cell></cell><cell>f</cell><cell>int</cell><cell>er</cell><cell>sec</cell><cell>tion</cell><cell>(</cell><cell>SGP</cell><cell>i</cell><cell>,</cell><cell>SGA</cell><cell>j</cell><cell>)</cell><cell></cell></row><row><cell></cell><cell cols="15">fitness</cell><cell cols="3">_</cell><cell cols="6">( GP</cell><cell>S</cell><cell>i</cell><cell>)</cell><cell></cell><cell>f</cell><cell>_</cell><cell>cov</cell><cell>( erage</cell><cell>S</cell><cell>2 ) i</cell><cell></cell><cell>f</cell><cell>int</cell><cell>er</cell><cell>sec</cell><cell>tion</cell><cell>(</cell><cell>S</cell><cell>i</cell><cell>)</cell><cell>,</cell></row><row><cell cols="11">where</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">f</cell><cell cols="4">int</cell><cell cols="4">er</cell><cell cols="5">sec</cell><cell cols="3">tion</cell><cell cols="3">(</cell><cell cols="3">S</cell><cell>i</cell><cell>)</cell><cell></cell><cell>   0 , int if er the sec solution ( tion SGP S ), is otherwise selected not i f</cell><cell>among</cell><cell>best</cell><cell>solutions</cell></row></table><note><p> </p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table I</head><label>I</label><figDesc>Studied Systems.</figDesc><table><row><cell>Systems</cell><cell>Release</cell><cell cols="3">#Classes #Smells KLOC</cell></row><row><cell>JFreeChart</cell><cell>v1.0.9</cell><cell>521</cell><cell>94</cell><cell>170</cell></row><row><cell>GanttProject</cell><cell>v1.10.2</cell><cell>245</cell><cell>72</cell><cell>41</cell></row><row><cell>ApacheAnt</cell><cell>v1.5.2</cell><cell>1024</cell><cell>172</cell><cell>255</cell></row><row><cell>ApacheAnt</cell><cell>v1.7.0</cell><cell>1839</cell><cell>169</cell><cell>327</cell></row><row><cell>Nutch</cell><cell>v1.1</cell><cell>207</cell><cell>79</cell><cell>39</cell></row><row><cell>Log4J</cell><cell>v1.2.1</cell><cell>189</cell><cell>68</cell><cell>31</cell></row><row><cell>Lucene</cell><cell>v1.4.3</cell><cell>154</cell><cell>41</cell><cell>33</cell></row><row><cell>Xerces-J</cell><cell>V2.7.0</cell><cell>991</cell><cell>114</cell><cell>238</cell></row><row><cell>Rhino</cell><cell>v1.7R1</cell><cell>305</cell><cell>82</cell><cell>57</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>0098-5589 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>http://ant.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>http://xerces.apache.org/xerces-j/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>http://sourceforge.net/p/ganttproject/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>http://logging.apache.org/log4j/2.x/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>http://lucene.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>http://nutch.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p>http://www.jfree.org/ 0098-5589 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TSE.2014.2331057, IEEE Transactions on Software Engineering</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>(+++) 0098-5589 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TSE.2014.2331057, IEEE Transactions on Software Engineering</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Advances in metaheuristics for hard optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Siarry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Computing Series</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Parallel metaheuristics: new Class of algorithms</title>
		<author>
			<persName><forename type="first">E</forename><surname>Alba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">ISBN</biblScope>
			<biblScope unit="page" from="0" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Optimization and defect identification using distributed evolutionary algorithms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Burczyńskia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kuśa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Długosza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Oranteka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="337" to="344" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cooperatively coevolving particle swarms for large scale optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="224" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evolutionary many-objective optimization: many once or one many?</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Congress on Evolutionary Computation</title>
		<meeting>IEEE Congress on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="222" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multiobjective optimization and hybrid evolutionary algorithm to solve constrained optimization problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="560" to="575" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Metaheuristics -From design to implementation</title>
		<author>
			<persName><forename type="first">E-G</forename><surname>Talbi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Designing heterogeneous distributed GAs by efficiently self-adapting the migration period</title>
		<author>
			<persName><forename type="first">C</forename><surname>Salto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="800" to="808" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Guest editorial: special issue on parallel and distributed evolutionary algorithms, part two</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tomassini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vanneschi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetic Programming and Evolvable Machines</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="130" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Search-based model transformation by example</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kessentini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Sahraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boukadoum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ben Omar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software and System Modeling</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="209" to="226" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Genetic algorithms in search, optimization and machine learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Measurement of the maintenance process from a demand-based perspective</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hguyenkim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Software Maintenance: Research and Practice</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="63" to="90" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Anti patterns: refactoring software, architectures, and projects in crisis</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Malveau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Mowbray</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="page" from="978" to="0471197133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Detection strategies: metrics-based rules for detecting design flaws</title>
		<author>
			<persName><forename type="first">R</forename><surname>Marinescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Software Maintenance</title>
		<meeting>the 20th International Conference on Software Maintenance</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="350" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Software metrics: a rigorous and practical approach</title>
		<author>
			<persName><forename type="first">N</forename><surname>Fenton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Pfleeger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>International Thomson Computer Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">DECOR: a method for the specification and detection of code and design smells</title>
		<author>
			<persName><forename type="first">N</forename><surname>Moha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">G</forename><surname>Guéhéneuc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Duchien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Le Meur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="20" to="36" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Decor: a tool for the detection of design defects</title>
		<author>
			<persName><forename type="first">N</forename><surname>Moha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">G</forename><surname>Guéhéneuc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on Automated Software Engineering</title>
		<meeting>the international conference on Automated Software Engineering</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="527" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Facilitating software refactoring with appropriate resolution order of bad smells</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Software Engineering Conference (ESEC) and the ACM SIGSOFT Symposium on the Foundations of Software Engineering</title>
		<meeting>the European Software Engineering Conference (ESEC) and the ACM SIGSOFT Symposium on the Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="265" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Detection strategies: metrics-based rules for detecting design flaws</title>
		<author>
			<persName><forename type="first">R</forename><surname>Marinescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference of Software Maintenance</title>
		<meeting>the International Conference of Software Maintenance</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="350" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A bayesian approach for the detection of code and design smells</title>
		<author>
			<persName><forename type="first">F</forename><surname>Khomh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vaucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">G</forename><surname>Guéhéneuc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Sahraoui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Quality Software</title>
		<meeting>the International Conference on Quality Software</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="305" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Design defects detection and correction by example</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kessentini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kessentini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Sahraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boukadoum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ouni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Program Comprehension</title>
		<meeting>the International Conference on Program Comprehension</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deviance from perfection is a better criterion than closeness to evil when identifying risky code</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kessentini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vaucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Sahraoui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on Automated Software Engineering (ASE)</title>
		<meeting>the international conference on Automated Software Engineering (ASE)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="113" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Maintainability defects detection and correction: a multi-objective approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ouni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kessentini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Sahraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boukadoum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automated Software Engineering</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="79" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The current state and future of search based software engineering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Future of Software Engineering</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Briand</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Wolf</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="342" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Refactoring -Improving the design of existing code</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Opdyke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roberts</surname></persName>
		</author>
		<idno>978-0201485677</idno>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Addison Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A metrics suite for object-oriented design</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Chidamber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Kemerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="293" to="318" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Genotype-phenotype-mapping and neutral variation -A case study in genetic programming</title>
		<author>
			<persName><forename type="first">W</forename><surname>Banzhaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on Parallel Problem Solving from Nature</title>
		<meeting>the international conference on Parallel Problem Solving from Nature</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="322" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Generalized needleman-wunsch algorithm for the recognition of t-cell epitopes</title>
		<author>
			<persName><forename type="first">L</forename><surname>Nanni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lumini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1463" to="1467" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">An introduction to genetic algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An evaluation of negative selection algorithm with constraint-based detectors</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dozier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Southeast Regional Conference</title>
		<meeting>the ACM Southeast Regional Conference</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="134" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Algorithms for comparison of DNA sequences</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brudno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<pubPlace>Stanford University, CA, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">CCFinder: a multilinguistic token-based code clone detection system for large scale source code</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kamiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kusumoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Inoue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="654" to="670" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An empirical study of code clone genealogies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sazawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Notkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Software Engineering Conference (ESEC) and the ACM SIGSOFT Symposium on the Foundations of Software Engineering (FSE)</title>
		<meeting>the European Software Engineering Conference (ESEC) and the ACM SIGSOFT Symposium on the Foundations of Software Engineering (FSE)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="187" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Use of ranks in one-criterion variance analysis</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Kruskal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Wallis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">260</biblScope>
			<biblScope unit="page" from="583" to="621" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Detecting defects in object-oriented designs: using reading techniques to increase software quality</title>
		<author>
			<persName><forename type="first">G</forename><surname>Travassos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fredericks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Basili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on Object-Oriented Programming, Systems, Languages, and Applications</title>
		<meeting>the international conference on Object-Oriented Programming, Systems, Languages, and Applications</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="47" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Personal use is permitted, but republication/redistribution requires IEEE permission</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ciupke</surname></persName>
		</author>
		<ptr target="http://www.ieee.org/publications_standards/publications/rights/index.html" />
	</analytic>
	<monogr>
		<title level="m">Proceeding of international conference on 0098-5589 (c) 2013 IEEE</title>
		<meeting>eeding of international conference on 0098-5589 (c) 2013 IEEE</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="18" to="32" />
		</imprint>
	</monogr>
	<note>for more information. Technology of Object-Oriented Languages and Systems</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Product metrics for automatic identification of &apos;Bad Smell&apos; design problems in Java source-code</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Munro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE METRICS</title>
		<meeting>IEEE METRICS</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="15" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Visualization-based analysis of quality for large-scale software systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Langelier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Sahraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Poulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on Automated Software Engineering</title>
		<meeting>the international conference on Automated Software Engineering</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A metric-based heuristic framework to detect object-oriented design flaws</title>
		<author>
			<persName><forename type="first">M</forename><surname>Salehie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tahvildari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Program Comprehension</title>
		<meeting>the International Conference on Program Comprehension</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Applying design metrics to object-oriented frameworks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Erni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lewerentz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE MTRICS</title>
		<meeting>IEEE MTRICS</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="64" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Détection d&apos;anomalies utilisant un langage de description de règle de qualité</title>
		<author>
			<persName><forename type="first">H</forename><surname>Alikacem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Sahraoui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference in Langages et Modèles à Objets</title>
		<meeting>the international conference in Langages et Modèles à Objets</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="185" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Investigating the effect of dataset size, metrics sets, and feature selection techniques on software fault prediction problem</title>
		<author>
			<persName><forename type="first">C</forename><surname>Catal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Diri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1040" to="1058" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">IDS: an immune-inspired approach for the detection of software design smells</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hassaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Khomh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">G</forename><surname>Guéhéneuc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hamel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on the Quality of Information and Communications Technology (QUATIC)</title>
		<meeting>the international conference on the Quality of Information and Communications Technology (QUATIC)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="343" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A patternbased framework for software anomaly detection</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Kothari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sauceda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Daugherty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software Quality Journal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="120" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Visual detection of design anomalies</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dhambri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Sahraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Poulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international Conference on Software Maintenance and Reengineering</title>
		<meeting>the international Conference on Software Maintenance and Reengineering</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="279" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Search-based software engineering: Trends, techniques and applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mansouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">61</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Clustering based automatic refactorings identification</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Czibula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Czibula</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Symbolic and Numeric Algorithms for Scientific Computing</title>
		<meeting>the International Symposium on Symbolic and Numeric Algorithms for Scientific Computing</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="253" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">JDeodorant: Identification and removal of type-checking bad smells</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tsantalis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chaikalis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chatzigeorgiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international Conference on Software Maintenance and Reengineering</title>
		<meeting>the international Conference on Software Maintenance and Reengineering</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="329" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A novel co-evolutionary approach to automatic software bug fixing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arcuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Congress on Evolutionary Computation</title>
		<meeting>IEEE Congress on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="162" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">How to overcome the equivalent mutant problem and achieve tailored selective mutation using co-evolution</title>
		<author>
			<persName><forename type="first">K</forename><surname>Adamopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Hierons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference</title>
		<meeting>the Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1338" to="1349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Cooperative co-evolutionary optimization of Software project staff assignments and job scheduling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Di</forename><surname>Penta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international Symposium on Search-Based Software Engineering</title>
		<meeting>the international Symposium on Search-Based Software Engineering</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="127" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Experimentation in Software engineering --An introduction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wohlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Runeson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Höst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Ohlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Regnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wesslén</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Why parameter control mechanisms should be benchmarked against random variation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Karafotias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hoogendoorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Eiben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="page" from="349" to="355" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Parameter tuning for configuring and analyzing evolutionary algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Eiben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Smit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="31" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Not going to take this anymore: multi-objective overtime planning for software engineering projects</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ferrucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Internation Conference on Software Engineering</title>
		<meeting>the Internation Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="462" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Statistical power analysis for the behavioral sciences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<idno>978-0805802832</idno>
	</analytic>
	<monogr>
		<title level="j">Routledge</title>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
