<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Simple Exponential Family Framework for Zero-Shot Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Vinay</forename><surname>Kumar Verma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">IIT Kanpur</orgName>
								<address>
									<region>Kanpur</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Piyush</forename><surname>Rai</surname></persName>
							<email>piyush@cse.iitk.ac.in</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">IIT Kanpur</orgName>
								<address>
									<region>Kanpur</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Simple Exponential Family Framework for Zero-Shot Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">14A38597540A67E7549C62533568F207</idno>
					<idno type="DOI">10.1007/978-3-319-71246-8_48</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a simple generative framework for learning to predict previously unseen classes, based on estimating class-attributegated class-conditional distributions. We model each class-conditional distribution as an exponential family distribution and the parameters of the distribution of each seen/unseen class are defined as functions of the respective observed class attributes. These functions can be learned using only the seen class data and can be used to predict the parameters of the class-conditional distribution of each unseen class. Unlike most existing methods for zero-shot learning that represent classes as fixed embeddings in some vector space, our generative model naturally represents each class as a probability distribution. It is simple to implement and also allows leveraging additional unlabeled data from unseen classes to improve the estimates of their class-conditional distributions using transductive/semi-supervised learning. Moreover, it extends seamlessly to few-shot learning by easily updating these distributions when provided with a small number of additional labelled examples from unseen classes. Through a comprehensive set of experiments on several benchmark data sets, we demonstrate the efficacy of our framework.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The problem of learning to predict unseen classes, also popularly known as Zero-Shot Learning (ZSL), is an important learning paradigm which refers to the problem of recognizing objects from classes that were not seen at training time <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b26">26]</ref>. ZSL is especially relevant for learning "in-the-wild" scenarios, where new concepts need to be discovered on-the-fly, without having access to labelled data from the novel classes/concepts. This has led to a tremendous amount of interest in developing ZSL methods that can learn in a robust and scalable manner, even when the amount of supervision for the classes of interest is relatively scarce.</p><p>A large body of existing prior work for ZSL is based on embedding the data into a semantic vector space, where distance based methods can be applied to find the most likely class which itself is represented as a point in the same semantic space <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b33">33]</ref>. However, a limitation of these methods is that each class is represented as a fixed point in the embedding space which does not adequately account for intra-class variability <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b18">18]</ref>. We provide a more detailed overview of existing work on ZSL in the Related Work section.</p><p>Another key limitation of most of the existing methods is that they usually lack a proper generative model of the data. Having a generative model has several advantages <ref type="bibr" target="#b19">[19]</ref>. For example, (1) data of different types can be modeled in a principled way using appropriately chosen class-conditional distributions; <ref type="bibr" target="#b1">(2)</ref> unlabeled data can be seamlessly integrated (for both seen as well as unseen classes) during parameter estimation, leading to a transductive/semi-supervised estimation procedure, which may be useful when the amount of labeled data for the seen classes is small, or if the distributions of seen and unseen classes are different from each other <ref type="bibr" target="#b11">[11]</ref>; and (3) a rich body of work, both frequentist and Bayesian, on learning generative models <ref type="bibr" target="#b19">[19]</ref> can be brought to bear during the ZSL parameter estimation process.</p><p>Motivated by these desiderata, we present a generative framework for zeroshot learning. Our framework is based on modelling the class-conditional distributions of seen as well as unseen classes using exponential family distributions <ref type="bibr" target="#b2">[3]</ref>, and further conditioning the parameters of these distributions on the respective class-attribute vectors via a linear/nonlinear regression model of one's choice. The regression model allows us to predict the parameters of the class-conditional distributions of unseen classes using only their class attributes, enabling us to perform zero-shot learning.</p><p>In addition to the generality and modelling flexibility of our framework, another of its appealing aspects is its simplicity. In contrast with various other state-of-the-art methods, our framework is very simple to implement and easy to extend. In particular, as we will show, parameter estimation in our framework simply reduces to solving a linear/nonlinear regression problem, for which a closed-form solution exists. Moreover, extending our framework to incorporate unlabeled data from the unseen classes, or a small number of labelled examples from the unseen classes, i.e., performing few-shot learning <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b23">23]</ref> is also remarkably easy under our framework which models class-conditional distributions using exponential family distributions with conjugate priors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A Generative Framework for ZSL</head><p>In zero-shot learning (ZSL) we assume there is a total of S seen classes and U unseen classes. Labelled training examples are only available for the seen classes. The test data is usually assumed to come only from the unseen classes, although in our experiments, we will also evaluate our model for the setting where the test data could come from both seen and unseen classes, a setting known as generalised zero-shot learning <ref type="bibr" target="#b5">[6]</ref>.</p><p>We take a generative modeling approach to the ZSL problem and model the class-conditional distribution for an observation x from a seen/unseen class c (c = 1, . . . , S + U ) using an exponential family distribution <ref type="bibr" target="#b2">[3]</ref> with natural parameters</p><formula xml:id="formula_0">θ c p(x |θ c ) = h(x ) exp θ c φ(x ) -A(θ c )<label>(1)</label></formula><p>where φ(x ) denotes the sufficient statistics and A(θ c ) denotes the log-partition function. We also assume that the distribution parameters θ c are given conjugate priors</p><formula xml:id="formula_1">p(θ c |τ 0 , ν 0 ) ∝ exp(θ c τ 0 -ν 0 A(θ c ))<label>(2)</label></formula><p>Given a test example x * , its class y * can be predicted by finding the class under which x * is most likely (i.e., y * = arg max c p(x * |θ c )), or finding the class that has the largest posterior probability given x * (i.e., y * = arg max c p(θ c |x * )). However, doing this requires first estimating the parameters {θ c } S+U c=S+1 of all the unseen classes.</p><p>Given labelled training data from any class modelled as an exponential family distribution, it is straightforward to estimate the model parameters θ c using maximum likelihood estimation (MLE), maximum-a-posteriori (MAP) estimation, or using fully Bayesian inference <ref type="bibr" target="#b19">[19]</ref>. However, since there are no labelled training examples from the unseen classes, we cannot estimate the parameters {θ c } S+U c=S+1 of the class-conditional distributions of the unseen classes.</p><p>To address this issue, we learn a model that allows us to predict the parameters θ c for any class c using the attribute vector of that class via a gating scheme, which is basically defined as a linear/nonlinear regression model from the attribute vector to the parameters. As is the common practice in ZSL, the attribute vector of each class may be derived from a human-provide description of the class or may be obtained from an external source such as Wikipedia in form of word-embedding of each class. We assume that the class-attribute of each class is a vector of size K. The class-attribute of all the classes are denoted as {a c } S+U c=1 , a c ∈ R K .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Gating via Class-Attributes</head><p>We assume a regression model from the class-attribute vector a c to the parameters θ c of each class c. In particular, we assume that the class-attribute vector a c is mapped via a function f to generate the parameters θ c of the class-conditional distribution of class c, as follows</p><formula xml:id="formula_2">θ c = f θ (a c )<label>(3)</label></formula><p>Note that the function f θ itself could consist of multiple functions if θ c consists of multiple parameters. For concereteness, and also to simplify the rest of the exposition, we will focus on the case when the class-conditional distribution is a D dimensional Gaussian, for which θ c is defined by the mean vector μ c ∈ R D and a p.s.d. covariance matrix Σ c ∈ S D×D</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>+</head><p>. Further, we will assume Σ c to be a diagonal matrix defined as</p><formula xml:id="formula_3">Σ c = diag(σ 2 c ) where σ 2 c = [σ 2 c1 , . . . , σ 2 cD ].</formula><p>Note that one can also assume a full covariance matrix but it will significantly increase the number of parameters to be estimated. We model μ c and σ 2 c as functions of the attribute vector a c</p><formula xml:id="formula_4">μ c = f μ (a c ) (4) σ 2 c = f σ 2 (a c )<label>(5)</label></formula><p>Note that the above equations define two regression models. The first regression model defined by the function f μ has a c as the input and μ c as the output. The second regression model defined by f σ 2 has a c as the input and σ 2 as the output. The goal is to learn the functions f μ and f σ 2 from the available training data. Note that the form of these functions is a modelling choice and can be chosen appropriately. We will consider both linear as well as nonlinear functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learning the Regression Functions</head><p>Using the available training data from all the seen classes c = 1, . . . , S, we can form empirical estimates of the parameters { μc , σ2 c } S c=1 of respective classconditional distributions using MLE/MAP estimation. Note that, since our framework is generative, both labeled as well as unlabeled data from the seen classes can be used to form the empirical estimates { μc , σ2 c } S c=1 . This makes our estimates of { μc , σ2 c } S c=1 reliable even if each seen class has very small number of labeled examples. Given these estimates for the seen classes</p><formula xml:id="formula_5">μc = f μ (a c ) c = 1, . . . , S (6) σ2 c = f σ 2 (a c ) c = 1, . . . , S<label>(7)</label></formula><p>We can now learn f μ using "training" data {a c , μc } S c=1 and learn f σ 2 using training data {a c , σ2 c } S c=1 . We consider both linear and nonlinear regression models for learning these.</p><p>The Linear Model. For the linear model, we assume μc and σ2 c to be linear functions of the class-attribute vector a c , defined as</p><formula xml:id="formula_6">μc = W μ a c c = 1, . . . , S (8) ρc = log σ2 c = W σ 2 a c c = 1, . . . , S<label>(9)</label></formula><p>where the regression weights W μ ∈ R D×K , W σ 2 ∈ R D×K , and we have reparameterized σ2 c ∈ R D + to ρc ∈ R D as ρc = log σ2 c . We use this re-parameterization to map the output space of the second regression model f σ 2 (defined by W σ 2 ) to real-valued vectors, so that a standard regression model can be applied (note that σ2 c is positive-valued vector). Estimating Regression Weights of Linear Model: We will denote M = [ μ1 , . . . , μS ] ∈ R D×S , R = [ρ 1 , . . . , ρS ] ∈ R D×S , and A = [a 1 , . . . , a S ] ∈ R K×S . We can then write the estimation of the regression weights W μ as the following problem Ŵμ = arg min</p><formula xml:id="formula_7">Wμ ||M -W μ A|| 2 2 + λ μ ||W μ || 2 2 (<label>10</label></formula><formula xml:id="formula_8">)</formula><p>This is essentially a multi-output regression <ref type="bibr" target="#b7">[7]</ref> problem W μ : a s → μs with least squares loss and an 2 regularizer. The solution to this problem is given by</p><formula xml:id="formula_9">Ŵμ = MA (AA + λ μ I K ) -1 (11)</formula><p>Likewise, we can then write the estimation of the regression weights W σ 2 as the following problem Ŵσ 2 = arg min</p><formula xml:id="formula_10">W σ 2 ||R -W σ 2 A|| 2 2 + λ σ 2 ||W σ 2 || 2 2 (12)</formula><p>The solution of the above problem is given by</p><formula xml:id="formula_11">Ŵσ 2 = RA (AA + λ σ 2 I K ) -1 (13)</formula><p>Given Ŵμ and Ŵσ 2 , parameters of the class-conditional distribution of each unseen class c = S + 1, . . . , S + U can be easily computed as follows</p><formula xml:id="formula_12">μc = Ŵμ a c (<label>14</label></formula><formula xml:id="formula_13">)</formula><formula xml:id="formula_14">σ2 c = exp(ρ c ) = exp( Ŵσ 2 a c )<label>(15)</label></formula><p>The Nonlinear Model: For the nonlinear case, we assume that the inputs {a c } S c=1 are mapped to a kernel induced space via a kernel function k with an associated nonlinear mapping φ. In this case, using the representer theorem <ref type="bibr" target="#b24">[24]</ref>, the solution for the two regression models f μ and f σ 2 can be written as the spans of the inputs {φ(a c )} S c=1 . Note that mappings φ(a c ) do not have to be computed explicitly since learning the nonlinear regression model only requires dot products φ(a c ) φ(a c ) = k(a c , a c ) between the nonlinear mappings of two classes c and c .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Estimating Regression Weights of Nonlinear Model:</head><p>Denoting K to be the S × S kernel matrix of the pairwise similarities of the attributes of the seen classes, the nonlinear model f μ is obtained by αμ = arg min</p><formula xml:id="formula_15">α μ ||M -α μ K|| 2 2 + λ μ ||α μ || 2 2 (<label>16</label></formula><formula xml:id="formula_16">)</formula><p>where αμ is a D × S matrix consists of the coefficients of the span of {φ(a c )} S c=1 defining the nonlinear function f μ . Note that the problem in Eq. 16 is essentially a multi-output kernel ridge regression <ref type="bibr" target="#b7">[7]</ref> problem, which has a closed form solution. The solution for αμ is given by αμ</p><formula xml:id="formula_17">= M(K + λ μ I S ) -1 (17)</formula><p>Likewise, the nonlinear model f σ 2 is obtained by solving ασ 2 = arg min</p><formula xml:id="formula_18">α σ 2 ||M -α σ 2 K|| 2 2 + λ σ 2 ||α σ 2 || 2 2 (<label>18</label></formula><formula xml:id="formula_19">)</formula><p>where ασ 2 is a D ×S matrix consists of the coefficients of the span of {φ(a c )} S c=1 defining the nonlinear function f σ 2 . The solution for ασ 2 is given by</p><formula xml:id="formula_20">ασ 2 = R(K + λ μ I S ) -1 (19)</formula><p>Given αμ , ασ 2 , parameters of class-conditional distribution of each unseen class c = S + 1, . . . , S + U will be</p><formula xml:id="formula_21">μc = αμ k c (20) σ2 c = exp(ρ c ) = exp( ασ 2 k c )<label>(21)</label></formula><p>where k c = [k(a c , a 1 ), . . . , k(a c , a S )] denotes an S × 1 vector of kernel-based similarities of the class-attribute of unseen class c with the class-attributes of all the seen classes.</p><p>Other Exponential Family Distributions: Although we illustrated our framework taking the example of Gaussian class-conditional distributions, our framework readily generalizes to the case when these distributions are modelled using any exponential family distribution. The estimation problems can be solved in a similar way as the Gaussian case with the basic recipe remaining the same: Form empirical estimates of the parameters Θ = { θc } S c=1 for the seen classes using all the available seen class data and then learn a linear/nonlinear regression model from the class-attributes A (or their kernel representation K in the nonlinear case) to Θ.</p><p>In additional to its modeling flexibility, an especially remarkable aspect of our generative framework is that it is very easy to implement, since both the linear model as well as the nonlinear model have closed-form solutions given by Eqs. 11, 13, 17 and 19, respectively (the solutions will be available in similar closedforms in the case of other exponential family distributions). A block-diagram describing our framework is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Note that another appealing aspect of our framework is its modular architecture where each of the blocks in Fig. <ref type="figure" target="#fig_0">1</ref> can make use of a suitable method of one's choice. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Transductive/Semi-supervised Setting</head><p>The procedure described in Sect. 2.2 relies only on the seen class data (labeled and, optionally, also unlabeled). As we saw for the Gaussian case, the seen class data is used to form empirical estimates of the parameters { μc , σ2 c } S c=1 of the class-conditional distributions of seen classes, and then these estimates are used to learn the linear/nonlinear regression functions f μ and f σ 2 . These functions are finally used to compute the parameters { μc , σ2 c } S+U c=S+1 of class-conditionals of unseen classes. We call this setting the inductive setting. Note that this procedure does not make use of any data from the unseen classes. Sometimes, we may have access to unlabeled data from the unseen classes.</p><p>Our generative framework makes it easy to leverage such unlabeled data from the unseen classes to further improve upon the estimates { μc , σ2 c } S+U c=S+1 of their class-conditional distributions. In our framework, this can be done in two settings, transductive and semi-supervised, both of which leverage unlabeled data from unseen classes, but in slightly different ways. If the unlabeled data is the unseen class test data itself, we call it the transductive setting. If this unlabeled data from the unseen classes is different from the actual unseen class test data, we call it the semi-supervised setting.</p><p>In either setting, we can use an Expectation-Maximization (EM) based procedure that alternates between inferring the labels of unlabeled examples of unseen classes and using the inferred labels to update the estimates of the parameters { μc , σ2 c } S+U c=S+1 of the distributions of unseen classes. For the case when each class-conditional distribution is a Gaussian, this procedure is equivalent to estimating a Gaussian Mixture Model (GMM) using the unlabeled data {x n } Nu n=1 from the unseen classes. The GMM is initialized using the estimates { μc , σ2 c } S+U c=S+1 obtained from the inductive procedure of Sect. 2.2. Note that each of the U mixture components of this GMM corresonds to an unseen class.</p><p>The EM algorithm for the Gaussian case is summarized next  Note that the same procedure can be applied even when each class-conditional distribution is some exponential family distribution other than Gaussian. The E and M steps in the resulting mixture model are straightforward in that case as well. The E step will simply require the Gausian likelihood to be replaced by the corresponding exponential family distribution's likelihood. The M step will require doing MLE of the exponential family distribution's parameters, which has closed-form solutions.</p><formula xml:id="formula_22">p(y n = c|x n , π, Θ) = π c N (x n | μc , σ2 c ) c π c N (x n | μc , σ2 c ) 3.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Extension for Few-Shot Learning</head><p>In few-shot learning, we assume that a very small number of labeled examples may also be available for the unseen classes <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b23">23]</ref>. The generative aspect of our framework, along with the fact the the data distribution is an exponential family distribution with a conjugate prior on its parameters, makes it very convenient for our model to be extended to this setting. The outputs { μc , σ2 c } S+U c=S+1 of our generative zero-shot learning model can naturally serve as the hyper-parameters of a conjugate prior on parameters of class-conditional distributions of unseen classes, which can then be updated given a small number of labeled examples from the unseen classes. For example, in the Gaussian case, due to conjugacy, we are able to update the estimates { μc , σ2 c } S+U c=S+1 in a straightforward manner when provided with such labeled data. In particular, given a small number of labeled examples {x n } Nc n=1 from an unseen class c, μc and σ2 c can be easily updated as</p><formula xml:id="formula_23">μ (F S) c = μc + Nc n=1 x n 1 + N c (<label>22</label></formula><formula xml:id="formula_24">)</formula><formula xml:id="formula_25">σ 2 c (F S) = 1 σ2 c + N c σ 2 -1<label>(23)</label></formula><p>where</p><formula xml:id="formula_26">σ 2 = 1 Nc Nc n=1 (x n -μc ) 2</formula><p>denotes the empirical variance of the N c observations from the unseen class c.</p><p>A particularly appealing aspect of our few-shot learning model outlined above is that it can also be updated in an online manner as more and more labelled examples become available from the unseen classes, without having to re-train the model from scratch using all the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>Some of the earliest works on ZSL are based on predicting attributes for each example <ref type="bibr" target="#b13">[13]</ref>. This was followed by a related line of work based on models that assume that the data from each class can be mapped to the class-attribute space (a shared semantic space) in which each seen/unseen class is also represented as a point <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b33">33]</ref>. The mapping can be learned using various ways, such as linear models or feed forward neural networks or convolutional neural networks. Predicting the label for a novel unseen class example then involves mapping it to this space and finding the "closest" unseen class. Some of the work on ZSL is aimed at improving the semantic embeddings of concepts/classes. For example, <ref type="bibr" target="#b29">[29]</ref> proposed a ZSL model to incorporate relational information about concepts. In another recent work, <ref type="bibr" target="#b3">[4]</ref> proposed a model to improve the semantic embeddings using a metric learning formulation. A complementary line of work to the semantic embedding methods is based on a "reverse" mapping, i.e., mapping the class-attribute to the observed feature space <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b37">37]</ref>.</p><p>In contrast to such semantic embedding methods that assume that the classes are collapsed onto a single point, our framework offers considerably more flexibility by modelling each class using its own distribution. This makes our model more suitable for capturing the intra-class variability, which the simple pointbased embedding models are incapable of handling.</p><p>Another popular approach for ZSL is based on modelling each unseen class as a linear/convex combination of seen classes <ref type="bibr" target="#b20">[20]</ref> or of a set of "abstract" or "basis" classes <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b22">22]</ref>. The latter class of methods, in particular, can be seen as a special case of our framework since, for our linear model, we can view the columns of the D × K regression weights as representing a set of K basis classes. Note however that our model has such regression weights for each parameter of the class-conditional distribution, allowing it to be considerably more flexible. Moreover, our framework is also significantly different in other ways due to its fully generative framework, due to its ability to incorporate unlabeled data, performing few-shot learning, and its ability to model different types of data using an appropriate exponential family distribution.</p><p>A very important issue in ZSL is the domain shift problem which may arise if the seen and unseen class come from very different domains. In these situations, standard ZSL models tend to perform badly. This can be somewhat alleviated using some additional unlabeled data from the unseen classes. To this end, <ref type="bibr" target="#b11">[11]</ref> provide a dictionary learning based approach for learning unseen class classifiers in which the dictionary is adapted to the unseen class domain. The dictionary adaptation is facilitated using unlabeled data from the unseen classes. In another related work, <ref type="bibr" target="#b8">[8]</ref> leverage unlabeled data in a transductive ZSL framework to handle the domain shift problem. Note that our framework is robust to the domain shift problem due to its ability to incorporate unlabeled data from the unseen classes (the transductive setting). Our experimental results corroborate this.</p><p>Semi-supervised learning for ZSL can also be used to improve the semantic embedding based methods. <ref type="bibr" target="#b16">[16]</ref> provide a semi-supervised method that leverages prior knowledge for improving the learned embeddings. In another recent work, <ref type="bibr" target="#b37">[37]</ref> present a model to incorporate unlabeled unseen class data in a setting where each unseen class is represented as a linear combination of seen classes. <ref type="bibr" target="#b34">[34]</ref> provide another approach, motivated by applications in computer vision, that jointly facilitates the domain adaptation of attribute space and the visual space. Another semi-supervised approach presented in <ref type="bibr" target="#b15">[15]</ref> combines a semisupervised classification model over the observed classes with an unsupervised clustering model over unseen classes together to address the zero-shot multi-class classification.</p><p>In contrast to these models for which the mechanism for incorporating unlabeled data is model-specific, our framework offers a general approach for doing this, while also being simple to implement. Moreover, for large-scale problems, it can also leverage more efficient solvers (e.g., gradient methods) for estimating the regression coefficients associated with class-conditional distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate our generative framework for zero-shot learning (hereafter referred to as GFZSL) on several benchmark data sets and compare it with a number of state-of-the-art baselines. We conduct our experiments on various problem settings, including standard inductive zero-shot learning (only using seen . Each image has a binary 312-dimensional class-attribute vector, specifying the presence or absence of various attribute of that image <ref type="bibr" target="#b28">[28]</ref>.</p><p>The attribute vectors for all images in a class are averaged to construct its continuous class-attribute vector <ref type="bibr" target="#b1">[2]</ref>. We use the same train/test split for this data set as used in <ref type="bibr" target="#b1">[2]</ref>. -SUN attribute (SUN): The SUN data set contains 14340 images with 707 seen classes (training set) and 10 unseen classes (test set). Each image is described by a 102-dimensional binary class-attribute vector. Just like the CUB-200 data set, we average the attribute vectors of all images in each class to get its continuous attribute vector <ref type="bibr" target="#b10">[10]</ref>. We use the same train/test split for this data set as used in <ref type="bibr" target="#b10">[10]</ref>.</p><p>For image features, we considered both GoogleNet features <ref type="bibr" target="#b27">[27]</ref> and VGG-19(4096) fc7 features <ref type="bibr" target="#b25">[25]</ref> and found that our approach works better with VGG-19. All of the state-of-the-art baselines we compare with in our experiments use VGG-19 fc7 features or GoogleNet features <ref type="bibr" target="#b27">[27]</ref>. For the nonlinear (kernel) variant of our model, we use a quadratic kernel. Our set of experiments include:</p><p>-Zero-Shot Learning: We consider both inductive ZSL as well as transductive ZSL.</p><p>• Inductive ZSL: This is the standard ZSL setting where the unseen class parameters are learned using only seen class data. • Transductive ZSL: In this setting <ref type="bibr" target="#b34">[34]</ref>, we also use the unlabeled test data while learning the unseen class parameters. Note that this setting has access to more information about the unseen class; however, it is only through unlabeled data. -Few-Shot Learning: In this setting <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b23">23]</ref>, we also use a small number of labelled examples from each unseen class.</p><p>-Generalized ZSL: Whereas standard ZSL (as well as few-shot learning) assumes that the test data can only be from the unseen classes, generalized ZSL assumes that the test data can be from unseen as well as seen classes. This is usually a more challenging setting <ref type="bibr" target="#b5">[6]</ref> and most of the existing methods are known to be biased towards predicting the seen classes.</p><p>We use the standard train/test split as given in the data description section. For selecting the hyperparameters, we further divide the train set further into train and validation set. In our model, we have two hyper-parameter λ μ and λ σ 2 , which we tune using the validation dataset. For AwA, from the 40 seen classes, a random selection of 30 classes are used for the training set and 10 classes are used for the validation set. For CUB-200, from the 150 seen classes, 100 are used for the training set and rest 50 are used for the validation set. Similarly, for the SUN dataset from the 707 seen classes, 697 are used for the training set and rest 10 is used for the validation set. We use cross-validation on the validation set to choose the best hyperparameter [λ μ , λ σ 2 ] for the each data set and use these for testing on the unseen classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Zero-Shot Learning</head><p>In our first set of experiments, we evaluate our model for zero-shot learning and compare with a number of state-of-the-art methods, for the inductive setting (which uses only the seen class labelled data) as well as the transductive setting (which uses the seen class data and the unseen class unlabeled data).</p><p>Inductive ZSL: Table <ref type="table" target="#tab_0">1</ref> shows our results for the inductive ZSL setting. The results of the various baselines are taken from the corresponding papers. As shown in the Table <ref type="table" target="#tab_0">1</ref>, on CUB-200 and SUN, both of our models (linear and nonlinear) perform better than all of the other state-of-the-art methods. On AwA, our model has only a marginally lower test accuracy as compared to the best performing baseline <ref type="bibr" target="#b34">[34]</ref>. However, we also have an average improvement 5.67% on all the 3 data sets as compared to the overall best baseline <ref type="bibr" target="#b34">[34]</ref>. Among baselines using VGG-19 features (bottom half of Table <ref type="table" target="#tab_0">1</ref>), our model achieves a 21.05% relative improvement over the best baseline on the CUB-200 data, which is considered to be a difficult data set with many fine-grained classes.</p><p>In contrast to other models that embed the test examples in the semantic space and then find the most similar class by doing a Euclidean distance based nearest neighbor search, or models that are based on computing the similarity scores between seen and unseen classes <ref type="bibr" target="#b33">[33]</ref>, for our models, finding the "most probable class" corresponds to computing the distance of each test example from a distribution. This naturally takes into account the shape and spread of the class-conditional distribution. This explains the favourable performance of our model as compared to the other methods. Transductive Setting: For transductive ZSL setting <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b36">36]</ref>, we follow the procedure described in Sect. 2.3 to estimate parameters of the class-conditional distribution of each unseen class. After learning the parameters, we find the most probable class for each test example by evaluating its probability under each unseen class distribution and assign it to the class under which it has the largest probability. Tables <ref type="table" target="#tab_1">2</ref> and<ref type="table" target="#tab_2">3</ref> compare our results from the transductive setting with other state-of-the-art baselines designed for the transductive setting. In addition to accuracy, we also report precision and recall results of our model and the other baselines (wherever available). As we can see from Tables <ref type="table" target="#tab_1">2</ref> and<ref type="table" target="#tab_2">3</ref>, both of our models (linear and kernel) outperform the other baselines on all the 3 data sets. Also comparing with the inductive setting results presented in Table <ref type="table" target="#tab_0">1</ref>, we observe that our generative framework is able to very effectively leverage unlabeled data and significantly improve upon the results of a purely inductive setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Few-Shot Learning (FSL)</head><p>We next perform an experiment with the few-shot learning setting <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b23">23]</ref> where we provide each model with a small number of labelled examples from each of the unseen classes. For this experiment, we follow the procedure described in Sect. 4.2 to learn the parameters of the class-conditional distributions of the unseen classes. In particular, we train the inductive ZSL model (using only the seen class training data) and the refine the learned model further using a very small number of labelled examples from the unseen classes (i.e., the few-shot learning setting). To see the effect of knowledge transfer from the seen classes, we use a multiclass SVM as a baseline that is provided with the same number of labelled examples from each unseen class. In this experiment, we vary the number of labelled examples of unseen classes from 2 to 20 (for SUN we only use 2, 5, and 10 due to the small number of labelled examples). In Fig. <ref type="figure" target="#fig_4">2</ref>, we also compare with standard (inductive) ZSL which does not have access to the labelled examples from the unseen classes. Our results are shown Table <ref type="table" target="#tab_3">4</ref> and Fig. <ref type="figure" target="#fig_4">2</ref>.</p><p>As shown in Table <ref type="table" target="#tab_3">4</ref> (all data sets) and Fig. <ref type="figure" target="#fig_4">2</ref>, the classification accuracy on the unseen classes shows a significant improvement over the standard inductive ZSL, even with as few as 2 or 5 additional labelled examples per class. We also observe that the few-shot learning method outperform multiclass SVM which only relies on the labelled data from the unseen classes. This demonstrates the advantage of the knowledge transfer from the seen class data.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Generalized Few-Shot Learning (GFSL)</head><p>We finally perform an experiment on the more challenging generalized few-shot learning setting <ref type="bibr" target="#b5">[6]</ref>. This setting assumes that test examples can come from seen as well as unseen classes. This setting is known to be notoriously hard <ref type="bibr" target="#b5">[6]</ref>.</p><p>In this setting, although the ZSL models tend to do well on predicting test examples from seen classes, the performance on correctly predicting the unseen class example is poor <ref type="bibr" target="#b5">[6]</ref> since the trained models are heavily biased towards predicting the seen classes. One way to mitigate this issue could be to use some labelled examples from the unseen classes (akin to what is done in few-shot learning). We, therefore, perform a similar experiment as in Sect. 4.2. In Table <ref type="table" target="#tab_4">5</ref>, we show the results of our model on classifying the unseen class test examples in this setting.</p><p>As shown in Table <ref type="table" target="#tab_4">5</ref>, our model's accuracies on the generalized FSL task improve as it gets to see labelled examples from unseen classes. However, it is still outperformed by a standard multiclass SVM. The better performance of SVM can be attributed to the fact that it is not biased towards the seen classes since the classifier for each class (seen/unseen) is learned independently. Our findings are also corroborated by other recent work on generalized FSL <ref type="bibr" target="#b5">[6]</ref> and suggest the need of finding more robust ways to handle this setting. We leave this direction of investigation as a possible future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have presented a flexible generative framework for zero-shot learning, which is based on modelling each seen/unseen class using an exponential family classconditional distribution. In contrast to the semantic embedding based methods for zero-shot learning which model each class as a point in a latent space, our approach models each class as a distribution, where the parameters of each class-conditional distribution are functions of the respective class-attribute vectors. Our generative framework allows learning these functions easily using seen class training data (and optionally leveraging additional unlabeled data from seen/unseen classes).</p><p>An especially appealing aspect of our framework is its simplicity and modular architecture (cf., Fig. <ref type="figure" target="#fig_0">1</ref>) which allows using a variety of algorithms for each of its building blocks. As we showed, our generative framework admits natural extensions to other related problems, such as transductive zero-shot learning and few-shot learning. It is particularly easy to and scale to a large number of classes, using advances in large-scale regression. Our generative framework can also be extended to jointly learn the class attributes from an external source of data (e.g., by learning an additional embedding model with our original model). This can be an interesting direction of future work. Finally, although we considered a point estimation of the parameters of class-conditional distributions, it is also possible to take a fully Bayesian approach for learning these distributions. We leave this possibility as a direction for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Block-diagram of our framework. Ds denotes the seen class data (can be labeled (and optionally also unlabeled); As denotes seen class attributes; Au denotes unseen class attributes; Θs denotes the estimated seen class parameters; Θu denotes the estimated unseen class parameters. The last stage -transductive/few-shot refinement -is optional (Sects. 2.3 and 4.2)</figDesc><graphic coords="6,104.49,396.77,243.22,116.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 .</head><label>1</label><figDesc>Initialize mixing proportions π = [π 1 , . . . , π U ] uniformly set mixture parameters as Θ = { μc , σ2 c } S+U c=S+1 2. E Step: Infer the probabilities for each x n belonging to each of the unseen classes c = S + 1, . . . , S + U as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>4 .</head><label>4</label><figDesc>M Step: Use to inferred class labels to re-estimate π and Θ = { μc , σ2 c } S+U c=S+1 . Go to step 2 if not converged.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>-</head><label></label><figDesc>class labeled examples), transductive zero-shot learning (using seen class labeled examples and unseen class unlabeled examples), and few-shot learning (using seen class labeled examples and a very small number of unseen class labeled examples). We report our experimental results on the following benchmark data sets: Animal with Attribute (AwA): The AwA data set contains 30475 images with 40 seen classes (training set) and 10 unseen classes (test set). Each class has a human-provided binary/continuous 85-dimensional class-attribute vector [12]. We use continuous class-attributes since prior works have found these to have more discriminative power. -Caltech-UCSD Birds-200-2011 (CUB-200): The CUB-200 data set contains 11788 images with 150 seen classes (training set) and 50 unseen class (test set)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (On AwA data): a comparison on classification accuracies of the few-shot learning variant of our model with multi-class SVM (training on labeled examples from seen classes) and the inductive ZSL</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Accuracy (%) of different type of images features. Top: Deep features like AlexNet, GoogleNet, etc. Bottom: Deep VGG-19 features. The '-' indicates that this result was not reported.</figDesc><table><row><cell>Method</cell><cell>AwA</cell><cell>CUB-200</cell><cell>SUN</cell><cell>Average</cell></row><row><cell>Akata et al. [2]</cell><cell>66.70</cell><cell>50.1</cell><cell>-</cell><cell>-</cell></row><row><cell>Qiao et al. [21]</cell><cell cols="2">66.46 ± 0.42 29 ± 0.28</cell><cell>-</cell><cell>-</cell></row><row><cell>Xian et al. [31]</cell><cell>71.9</cell><cell>45.5</cell><cell>-</cell><cell>-</cell></row><row><cell>Changpimyo et al. [5]</cell><cell>72.9</cell><cell>54.7</cell><cell>62.7</cell><cell>63.43</cell></row><row><cell>Wang et al. [29]</cell><cell>75.99</cell><cell>33.48</cell><cell>-</cell><cell>-</cell></row><row><cell>Lampert et al. [14]</cell><cell>57.23</cell><cell>-</cell><cell>72.00</cell><cell>-</cell></row><row><cell>Romera and Torr [22]</cell><cell cols="2">75.32 ± 2.28 -</cell><cell cols="2">82.10 ± 0.32 -</cell></row><row><cell>Bucher et al. [4]</cell><cell cols="4">77.32 ± 1.03 43.29 ± 0.38 84.41 ± 0.71 68.34</cell></row><row><cell cols="5">Zhang and Saligrama [35] 79.12 ± 0.53 41.78 ± 0.52 83.83 ± .29 68.24</cell></row><row><cell>Wang and Chen [30]</cell><cell>79.2 ± 0.0</cell><cell>46.7 ± 0.0</cell><cell>-</cell><cell>-</cell></row><row><cell cols="5">Zhang and Saligrama [34] 81.03 ± 0.88 46.48 ± 1.67 84.10 ± 1.51 70.53</cell></row><row><cell>GFZSL: Linear</cell><cell>79.90</cell><cell>52.09</cell><cell>86.50</cell><cell>72.23</cell></row><row><cell>GFZSL: Nonlinear</cell><cell>80.83</cell><cell>56.53</cell><cell>86.50</cell><cell>74.59</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>ZSL accuracy (%) obtained in the transductive setting: results reported using the VGG-19 feature. Average Precision and recall for the all dataset with its standard deviation over the 100 iteration. The '-' indicates that this result was not reported in the original paper.</figDesc><table><row><cell>Method</cell><cell>AwA</cell><cell>CUB-200</cell><cell>SUN</cell><cell>Average</cell></row><row><cell>Guo et al. [9]</cell><cell>78.47</cell><cell>-</cell><cell>82.00</cell><cell>-</cell></row><row><cell>Romera and Torr [22] + Zhang and Saligrama [36]</cell><cell>84.30</cell><cell>-</cell><cell>37.50</cell><cell>-</cell></row><row><cell cols="5">Zhang and Saligrama [35] + Zhang and Saligrama [36] 92.08 ± 0.14 55.34 ± 0.77 86.12 ± 0.99 77.85</cell></row><row><cell cols="5">Zhang and Saligrama [34] + Zhang and Saligrama [36] 88.04 ± 0.69 55.81 ± 1.37 85.35 ± 1.56 76.40</cell></row><row><cell>GFZSL: Linear</cell><cell>94.20</cell><cell>57.14</cell><cell>87.00</cell><cell>79.45</cell></row><row><cell>GFZSL: Kernel</cell><cell>94.25</cell><cell>63.66</cell><cell>87.00</cell><cell>80.63</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>ZSL precision and recall scores obtained in the transductive setting: results reported using the VGG-19 features. Average precision and recall for the all dataset with its standard deviation over the 100 iteration. Note: Precision and recall scores not available for Guo et al.<ref type="bibr" target="#b9">[9]</ref> and Romera et al.<ref type="bibr" target="#b22">[22]</ref> + Zhang et al.<ref type="bibr" target="#b36">[36]</ref> </figDesc><table><row><cell></cell><cell></cell><cell cols="2">Average Precision</cell><cell></cell><cell cols="2">Average Recall</cell></row><row><cell>Method</cell><cell>AwA</cell><cell>CUB-200</cell><cell>SUN</cell><cell>AwA</cell><cell>CUB-200</cell><cell>SUN</cell></row><row><cell cols="7">Zhang et al.[35]+Zhang et al. [36] 91.37±14.75 57.09±27.91 85.96±10.15 90.28±8.08 55.73±31.80 86.00±13.19</cell></row><row><cell cols="7">Zhang et al.[34]+Zhang et al. [36] 89.19±15.09 57.20±25.96 86.06± 12.36 86.04±9.82 55.77±26.54 85.50±13.68</cell></row><row><cell>GFZSL: Linear</cell><cell>93.70</cell><cell>57.90</cell><cell>87.40</cell><cell>92.20</cell><cell>57.40</cell><cell>87.00</cell></row><row><cell>GFZSL: Kernel</cell><cell>93.80</cell><cell>64.09</cell><cell>87.40</cell><cell>92.30</cell><cell>63.96</cell><cell>0.87</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Accuracy (%) in the few-shot learning setting: For each data set, the accuracies are reported using 2, 5, 10, 15, 20 labeled examples for each unseen class</figDesc><table><row><cell cols="3">Dataset Method 2</cell><cell>5</cell><cell>10</cell><cell>15</cell><cell>20</cell></row><row><cell>AwA</cell><cell cols="6">GFZSL 87.96 ± 1.47 91.64 ± 0.81 93.31 ± 0.50 94.01 ± .36 94.30 ± 0.33</cell></row><row><cell></cell><cell>SVM</cell><cell>74.81</cell><cell>83.19</cell><cell>90.44</cell><cell>91.22</cell><cell>92.04</cell></row><row><cell cols="7">CUB-200 GFZSL 60.84 ± 1.39 64.81 ± 1.14 68.44 ± 1.21 70.11 ± 0.93 71.23 ± 0.87</cell></row><row><cell></cell><cell>SVM</cell><cell>46.19</cell><cell>59.33</cell><cell>68.75</cell><cell>73.87</cell><cell>75.42</cell></row><row><cell>SUN</cell><cell cols="5">GFZSL 75.57 ± 4.79 83.05 ± 3.60 82.09 ± 3.30 -</cell><cell>-</cell></row><row><cell></cell><cell>SVM</cell><cell>56.00</cell><cell>77.00</cell><cell>78.00</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Accuracies (%) in the generalized few-shot learning setting. GFZSL 6.64 ± 0.87 15.12 ± 1.17 22.02 ± 0.76 25.03 ± 0.71 26.47 ± 0.83</figDesc><table><row><cell cols="3">Dataset Method 2</cell><cell>5</cell><cell>10</cell><cell>15</cell><cell>20</cell></row><row><cell>AwA</cell><cell cols="6">GFZSL 25.32 ± 2.43 37.42 ± 1.60 43.20 ± 1.39 45.09 ± 1.17 45.96 ± 1.09</cell></row><row><cell></cell><cell>SVM</cell><cell>40.84</cell><cell>60.81</cell><cell>75.36</cell><cell>77.00</cell><cell>77.10</cell></row><row><cell cols="2">CUB-200 SVM</cell><cell>25.97</cell><cell>37.98</cell><cell>47.10</cell><cell>53.87</cell><cell>54.42</cell></row><row><cell>SUN</cell><cell cols="5">GFZSL 1.17 ± 1.16 4.20 ± 1.77 9.48 ± 2.22 -</cell><cell>-</cell></row><row><cell></cell><cell>SVM</cell><cell>9.94</cell><cell>20.00</cell><cell>27.00</cell><cell>-</cell><cell>-</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. This work is supported by a grant from Tower Research CSR, Dr. Deep Singh and Daljeet Kaur Fellowship, and Research-I Foundation, IIT Kanpur. Vinay Verma acknowledges support from Visvesvaraya Ph.D. fellowship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Label-embedding for attributebased classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Evaluation of output embeddings for fine-grained image classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fundamentals of statistical exponential families</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Institute of Mathematical Statistics</title>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Improving semantic embedding consistency by metric learning for zero-shot classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Herbin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.08085</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Synthesized classifiers for zeroshot learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Changpinyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-L</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An empirical study and analysis of generalized zero-shot learning for object recognition in the wild</title>
		<author>
			<persName><forename type="first">W.-L</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Changpinyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV 2016</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Leibe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">9906</biblScope>
			<biblScope unit="page" from="52" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46475-6_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-46475-64" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Elements of Statistical Learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-0-387-21606-5</idno>
		<ptr target="https://doi.org/10.1007/978-0-387-21606-5" />
	</analytic>
	<monogr>
		<title level="s">Springer Series in Statistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2001">2001</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Transductive multi-view zero-shot learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2332" to="2345" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Transductive zero-shot recognition via shared model space learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Zero-shot recognition with unreliable attributes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for zero-shot learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning to detect unseen object classes by between-class attribute transfer</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Attribute-based classification for zeroshot visual object categorization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="453" to="465" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Max-margin zero-shot learning for multi-class classification</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AISTATS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semi-supervised zero-shot classification with label representation learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Costa: co-occurrence statistics for zero-shot classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gavves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Gaussian visual-linguistic embedding for zero-shot recognition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<title level="m">Machine Learning: A Probabilistic Perspective</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Zero-shot learning by convex combination of semantic embeddings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Less is more: zero-shot learning from online textual documents with noise suppression</title>
		<author>
			<persName><forename type="first">R</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Hengel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An embarrassingly simple approach to zero-shot learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning with hierarchical-deep models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1958" to="1971" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Zero-shot learning through crossmodal transfer</title>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ganjoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<title level="m">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Relational knowledge transfer for zero-shot learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Zero-shot visual recognition via bidirectional latent embedding</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.02104</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Latent embeddings for zero-shot classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Learning a deep embedding model for zero-shot learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05088</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Zero-shot learning via semantic similarity embedding</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Learning joint feature adaptation for zero-shot recognition</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07593</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Zero-shot learning via joint latent similarity embedding</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Zero-shot recognition via structured prediction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46478-7_33</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-46478-733" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2016</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Leibe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9911</biblScope>
			<biblScope unit="page" from="533" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Zero-shot learning via revealing data distribution</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.00560</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
