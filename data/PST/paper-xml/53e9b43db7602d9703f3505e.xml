<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Using Part-of-speech Patterns to Reduce Query Ambiguity</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">James</forename><surname>Allan</surname></persName>
							<email>allan@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01003</postCode>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hema</forename><surname>Raghavan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01003</postCode>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Using Part-of-speech Patterns to Reduce Query Ambiguity</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">831D54B9F789DD1903BF2024FF19A906</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing-linguistic processing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval-query formulation</term>
					<term>search process Clarity</term>
					<term>part of speech</term>
					<term>query ambiguity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Query ambiguity is a generally recognized problem, particularly in Web environments where queries are commonly only one or two words in length. In this study, we explore one technique that finds commonly occurring patterns of parts of speech near a one-word query and allows them to be transformed into clarification questions. We use a technique derived from statistical language modeling to show that the clarification queries will reduce ambiguity much of the time, and often quite substantially.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>A generally acknowledged issue in information retrieval, particularly with Web search engines, is that users provide very short queries <ref type="bibr" target="#b15">[15]</ref> that are sometimes very ambiguous. A classic example of this problem is the meaning of "Java" as a query: is the searcher's interest in coffee, a programming language, or tourism in Indonesia? There is quite a range of ways in which ambiguity can appear. In the "java" example, it is based on subject matter. A query could also be ambiguous because the user's underlying task is unclear (e.g., buy Java, use Java, introduction to Java), because the type of user is unknown (e.g., expert or novice), or because the style of querying is not clear (e.g., obtain facts, an overview, exhaustive coverage, or summary).</p><p>In this study, we investigate a particular technique for resolving ambiguity that is motivated by task-level ambiguity. How do the query words relate to other words in the text?</p><p>What roles can they assume and which is the user interested in? For example, given a query "boat", the user might be interested in:</p><p>• things a boat does (floats, anchors, overturns)</p><p>• types of boats (whaling, fishing, red)</p><p>• ways to boat (quickly, safely)</p><p>• things to do with boats (drive them, paint them, sink them)</p><p>The intent is for the system to present a list of clarifying options to the searcher that can be selected if needed. Choosing one of those options focuses the query by including only those documents that use the query words in the right manner.</p><p>Ultimately, these ideas should be evaluated by field-testing a system that incorporates them. In this study we are laying the groundwork for such a system. Our focus is a novel evaluation to demonstrate that this approach generates useful clarifications of an ambiguous query. In the next section, we sketch some prior work toward coping with ambiguity. In Section 4 we discuss the approach that we use to find the clarifying options; the actual implementation is described in Section 3. We describe our evaluation technique in Section 5 and present results showing the value of this approach in Section 6. We conclude in Section 7 by describing where this work is headed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>There has been substantial work investigating issues surrounding word sense disambiguation <ref type="bibr" target="#b16">[16]</ref>, a type of query ambiguity that arises regularly in information retrieval. That type of ambiguity is often resolved implicitly when queries are long enough-the additional words provide sufficient context to clear up confusion-but is still a critical problem when queries are short <ref type="bibr" target="#b20">[20]</ref>. Users of Web search engines generally provide short queries <ref type="bibr" target="#b15">[15]</ref>, and we are focusing on that situation in this study.</p><p>There is a range of information retrieval interface ideas that attempt to help the user deal with ambiguous queries. Sanderson, Lawrie, and Croft have been working on concept hierarchies that provide a hierarchical map of words and their relationships <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr" target="#b17">17]</ref>. A user can navigate the hierarchy to find the sense that is relevant. To date that research has not directly investigated whether the hierarchies help with disambiguation, looking instead at their ability to affect recall and precision.</p><p>Clustering the retrieved document set is another way to deal with ambiguity: ideally documents covering different senses of a word will be placed in different clusters. Much work has been done on clustering, either investigating the clustering directly <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b2">2,</ref><ref type="bibr" target="#b14">14]</ref> or exploring issues related to clustering and interactive search <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b23">23]</ref>. The Web service Northern Light<ref type="foot" target="#foot_0">1</ref> classifies returned documents into a set of labeled clusters, showing the clusters as well as the top ranked documents. All of these clustering techniques group documents by topic rather than by the way that the query word is used.</p><p>A limited number of studies have been done that directly evaluate the effectiveness of query reformulation when searching. It has been shown that query reformulation can improve the effectiveness of a query <ref type="bibr" target="#b5">[5]</ref>, though the focus was on the cognitive burden it places on the searcher.</p><p>This work was inspired by Tables <ref type="table">8</ref> and<ref type="table">9</ref> of a paper by Church et al. <ref type="bibr" target="#b7">[7]</ref>. That work describes how statistical occurrence patterns of words in text can be used to find lexically interesting items. One of those is to look for verbs that occur near a particular word in an interesting way (measured by mutual information), allowing someone to find "what does a boat do?" or "what do you typically do with food and water ?" We felt that if a query "boat" were used, then a possible clarification might be that question, and that documents containing the appropriate pattern (viz., boat as a subject and a verb "interestingly" near it) would be appropriate matches.</p><p>AltaVista<ref type="foot" target="#foot_1">2</ref> at one point provided a service called Live-Topics <ref type="bibr" target="#b22">[22]</ref> that showed the inter-relationships between query terms and other terms in the corpus. This map was derived from the corpus (and human corrections) and provided another form of a "hyperindex" to allow the user to select words to improve a query.</p><p>The HiB system <ref type="bibr" target="#b4">[4]</ref> allows the user to clarify (refine) the query by offering well-formed phrases in which the query appears. The user's query is mapped into a "hyperindex" by this approach, that shows relationships between words based on their occurrence in the titles of retrieved documents. The motivation for this work is similar to ours, but requires a much more elaborate infrastructure. They do not appear to have evaluated the value of the technique for query disambiguation. Grefenstette also suggests a system similar to ours <ref type="bibr" target="#b12">[12]</ref>, but also has no evaluation of its effectiveness.</p><p>Anick and Tipirneni <ref type="bibr" target="#b3">[3]</ref> developed a query refinement technique based on calculating the lexical dispersion of words occurring in the top-ranked documents. Their work is similar to this study in that the candidates are identified by part-ofspeech patterns at index time, but they use a substantially reduced set of patterns ("adjective? noun+"), they present patterns to the user on the assumption that the top ranked documents are a good source for them, and they are more focussed on query expansion than disambiguation (though the difference is often subtle). We believe that some aspects of their approach (e.g., using dispersion to find good candidates) may be valuable for our work, but we have not yet investigated those ideas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXPERIMENTAL SETUP</head><p>All experiments in this study were conducted using about  178,000 documents from the trec5-fbis, the FBIS subset of the fifth TREC volume. These are documents from FBIS dated 1994. We also used a second corpus, tdt2, which includes the English news stories from the TDT-2 collection, amounting to approximately 40,000 news stories from newswire and broadcast news sources. For stories from an audio source, the closed caption was used rather than speech recognition output. Our indexing and retrieval was done using V3.2 of the CIIR's InQuery retrieval system <ref type="bibr" target="#b6">[6]</ref>. This system incorporates fast and reasonably accurate part of speech tagging using JTAG <ref type="bibr" target="#b24">[24]</ref>. JTAG uses the Brown tag-set (some tags of which are listed in Figure <ref type="figure" target="#fig_0">1</ref>).</p><p>When documents were indexed, each word was indexed along with its part of speech. Proximity operators allow a particular part of speech to be selected for a word, as well as restrictions on which parts of speech occurred nearby. For example, #1(boat VBD) means the word "boat" immediately followed by the past participle of a verb (e.g., "boat sank"). The query #0(boat NN) means the word "boat" used as a noun rather than as another part of speech. The combined query, #3( #0(boat NN) VBZ) means "boat" as a noun followed within three words by the present third person singular form a verb (e.g., "boat sinks" or "boat quickly sinks"). This type of construction allows us to build up quite complex restrictions on query words and nearby parts of speech.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">APPROACH</head><p>Given a corpus that has parts of speech indexed and that provides flexible query support such as that outlined above, we can attempt query disambiguation as follows. We <ref type="bibr" target="#b1">(1)</ref> analyze the text to find patterns of parts of speech that occur frequently near the query word, (2) map the patterns to questions that reflect the patterns, (3) present the questions to the user as options to consider, and (4) re-run the retrieval based on the disambiguated question(s) the searcher selects.</p><p>In this section, we sketch how this approach works in a functional system. We show several examples that illustrate the value of this approach and suggest that it will be effective. In Section 5 we empirically evaluate the effectiveness of this approach toward reducing ambiguity. Our longer term goal is to implement these ideas in a fully functioning system to get user feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Finding patterns</head><p>The patterns that we are looking for center around a single query word and incorporate a small number of words on either side. For example, given the query word boat we might look for the pattern "an adjective followed by the noun boat." In the trec5-fbis corpus, we would find adjectives such as Haitian, fishing, wooden, speed, and so on. If we find a sufficient number of occurrences of that pattern (regardless of how many different adjectives there are), we would note that "JJ boat:NN" is an interesting pattern ("JJ" is the part of speech code for an adjective, and "NN" denotes a singular noun).</p><p>Looking for all such patterns near a query word would be prohibitively expensive to carry out at search time. For that reason, we enhanced InQuery's indexing stage to extract all patterns centered around non-stopwords so that we could use it at run-time, and organized them by that keyword. To make this process slightly less expensive we used a 50% random sample of the corpus. For example, Figure <ref type="figure" target="#fig_3">2</ref> shows a sample of patterns and counts that appear in the 80,000 document subset of the trec5-fbis corpus.</p><p>We found by observation that any pattern that occurs more than 50 times in the corpus is "interesting" and ignored all others (a pattern might occur less than 50 times with particular query word, but many more than 50 times overall). Given the large number of patterns, making this decision in that way does not seem unreasonable, though it would ultimately be preferable to use a measure such as mutual information to select and keep the more interesting patterns <ref type="bibr" target="#b7">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Patterns to questions</head><p>The patterns are interesting, but they are not appropriate for displaying to a user. Instead, we convert them into questions that disambiguate the query. For example, here are some patterns and corresponding questions for the query word party: For each pattern that has a corresponding question, we index the pattern by the query word and keep track of the number of times the pattern occurs. Given a user's single-word query, all patterns including that query word are obtained from the index, and the list of questions is constructed. Patterns that correspond to the same question are collapsed into a single question.</p><p>The questions are presented ranked in order of the most frequently occurring first. (The evaluation in Section 6 suggests that questions with many matches are not much less ambiguous than the original query, so it may be preferable to rank them by an approximation of ambiguity reduction.)</p><p>A partial list of patterns and corresponding questions is presented in Figure <ref type="figure" target="#fig_2">3</ref>. Note that some language processing could be useful to handle variants of queries (e.g., to change "varieties of mouse" into "varieties of mice").</p><p>We wish to make it clear that the mapping from patterns  In the pattern, "Q:pos" means the query word occurring in that part of speech. The codes "noun," "verb," and "adj" are macros that indicate all varieties of nouns that the tagger identifies. In the Question column, QQ would be replaced by the query word.</p><p>to questions was created by hand. We found that a surprisingly small set of questions could accommodate most patterns, but it is most likely that some questions are absent. We are currently exploring better approaches for generating this mapping.</p><p>It is likely that the clarifying questions themselves may not be sufficient to help the user recognize the distinction. To help with that, we present the user which a list of several sample phrases that match the corresponding patterns. For example, for the query "boat", we might get (examples taken from our corpora):</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Are you interested in varieties of boats?</head><p>Haitian boat, makeshift boat, wooden boat, Cuban boat, big boat, . . . Are you interested in things a boat did? boat followed, boat capsized, boat sank, boat hit, boat had, . . . Are you interested in things done with a boat? rescue the boat, rock the boat, miss the boat, . . . This sort of "keyword in context" list provides more information about the meaning of the clarification question, and does it in a corpus-specific way. That is, on a different corpus, the clarification questions chosen might not be the same, and the sample phrases including the query word would also be different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Running the clarification question</head><p>When the user selects one of the query questions, the system then transforms it into an appropriate query and provides a new list of matching documents. The InQuery query is a logical "or" of all patterns that correspond to the selected query. For example, for the question "Are you interested in things done to a boat?", the following query could be generated  . . . ) In practice, the patterns generally need to be relaxed slightly to find matches that are very close to the patterns. We have observed that allowing a few extra words improves the recall of useful documents, though we have not carried out a formal study of that effect. The above query is transformed into, #or( #3( #0(boat NN) BER verb ) #3( #0(boat NN) NV BEN verb ) #3( HVZ VBN #0(boat NN) ) . . . )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EVALUATION</head><p>We are interested in whether the clarifying questions result in a more focused set of documents in response to the searcher's query. One way to measure that would be to ask someone to judge each set of returned documents to decide whether they were more or less focused than the original set. Such a process is time consuming and unwieldy.</p><p>Instead, we will use a measure of query clarity based on vocabulary distribution in both sets of retrieved documents <ref type="bibr">[8,</ref><ref type="bibr" target="#b9">9]</ref>. If one query has more "clarity" than another, it is less ambiguous, and perhaps more useful for retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Query clarity</head><p>Clarity is defined <ref type="bibr">[8]</ref> as the Kullback-Liebler (KL) divergence between the collection and the query:</p><formula xml:id="formula_0">clarity(Q) ≡ w∈V P (w|Q) log 2 P (w|Q) P (w)</formula><p>where V is the set of all terms in the collection (e.g., trec5fbis or tdt2), Q represents the query, and P (w) represents the probability of the word occurring in a document in the collection. To estimate the probability distribution of words given the query (the "query language model"), we use,</p><formula xml:id="formula_1">P (w|Q) ∼ = d∈R P (w|d)P (d|Q)</formula><p>where R is the set of documents retrieved in response to the query, and P (w|d) = λPML(w|d) + (1λ)P (w), a linear combination of the corpus probability and the maximum likelihood estimate based on the document. We set λ = 0.6. What the clarity measure does is compare the language model (probability distribution of words) of the corpus with the language model generated by a query. The way it is calculated means that if the distributions are identical, the clarity will be zero, and as they become more and more different, the value will rise. As a result, if the set of retrieved documents has roughly the same coverage as the entire corpus, the query that generated them will have a low clarity value-i.e., it is an ambiguous query.</p><p>It has also been shown that there is a strong correlation between clarity and the performance of the query as measured by average precision <ref type="bibr" target="#b10">[10]</ref>, so it is possible to predict, to some extent, the performance of a query on a collection without relevance information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Using clarity</head><p>To determine whether the clarification questions are providing any focusing of the results, we compare the clarity of the original query word with that of the modified query. Each query Qi has a set of clarifying questions Qi,1 through Qi,n Q where nQ varies by query and indicates the number of questions whose patterns occurred more than 50 times in the corpus.</p><p>We compute the following measures to compare the effectiveness of the system.</p><p>• The number of times that the clarification question is clearer than the original query. • The increase in clarity moving from the original query to the clarification question. If the number is negative or near zero, it means that the questions were not an improvement.</p><formula xml:id="formula_2">n Q j=1 clarity(Qi,j) -clarity(Qi)</formula><p>In addition, both measures are averaged across all clarification questions (per-question average, also called a pooled average), and weighted by the original queries (per-query average). The latter is important because nQ can vary dramatically between queries and we do not want queries with few clarification possibilities to be overshadowed by the others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RESULTS</head><p>To evaluate the disambiguation potential of this technique, we choose 50 one-word queries using a mix of several different ways:</p><p>• We used 25 common one word queries from web logs.</p><p>This we found from multiple sources as follows: <ref type="bibr" target="#b1">(1)</ref> words that were listed as being common single word queries using a Word Tracker<ref type="foot" target="#foot_2">3</ref> report that lists commonly used query terms mined from a large log of metasearch queries;</p><p>(2) common one-word queries as reported by Google<ref type="foot" target="#foot_3">4</ref> and Metacrawler<ref type="foot" target="#foot_4">5</ref> . These words were all verified to occur within the trec5-fbis corpus.</p><p>• Since our database is a trec-5 collection, we analyzed the TREC-5 topics 251-300 that could be narrowed down to one word. We used 25 such queries. For example TREC topic 269 is "Foreign Trade," which we generalized to "trade".</p><p>We report below analysis of the clarity impact in the aggregate and then present detailed analysis of some of the query words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Overall trends</head><p>Overall, the query clarity improves an average of 41% for TREC queries and 25% for Web queries (per-query average). The top of Figure <ref type="figure">4</ref> shows a breakdown of the improvement on a per-query basis for TREC queries and the bottom half shows the same for Web queries. Almost all queries have average improvements in clarity, and even when the average is negative, most of the clarification questions reduce ambiguity. For example, for the original query word defense there were 85 patterns that occurred often enough to be recorded. The clarity of defense was 0.511 (not shown in the table). Of the 85 patterns, 71 of them (83.52%) showed an improvement in clarity, averaging 0.171 or 33% (the values ranged from -25% to 200%). About 95% of the questions for the trec5 questions and 62% for the general web queries improved query clarity, strongly suggesting their value in reducing ambiguity. The reasonable similarity between the pooled and query-weighted averages suggests that the results are comparable across queries.</p><p>The percent improvement in clarity ranged from 347% to improve mines to JJ mines:NNS NP down to -51% trying to improve heart to CD heart:NN CC in the set of TREC questions. In the set of general Web queries this range is from 412% improving apartment to AT apartment:NN VBN to -62% for trying to improve computer to NN computer:NN NNS. It appears that the queries where ambiguity could be reduced the most were cases where the word could be either a noun or a verb (e.g., tour, defense) or where the word often appeared as a proper noun (e.g., airline).</p><p>If clarity numbers are calculated or approximated in advance, it would be possible to remove clarification questions that actually reduce clarity (i.e., increase ambiguity), making this technique even more useful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Detailed analysis</head><p>The query word tour is not very common in the trec5-fbis corpus that we used: it occurs in 1668 out of the 178,000 stories. The word tour has a clarity value of 0.525. We show a partial breakdown of the results for tour clarification in Figure <ref type="figure">6</ref>. The results are ordered by percent improvement in the original clarity value, ranging from a 283% improvement to a drop of almost 20%. Figure <ref type="figure" target="#fig_5">5</ref>   such as "typical tourist visiting" and does not provide much focusing of the query. On the other hand, the pattern NP tourist:NP NP represents phrases such as "National Tourist Board" and the documents in which such phrases are present focus more on information, announcements, etc., for tourists, providing a fairly tight set of retrieved documents. Figure <ref type="figure" target="#fig_6">7</ref> shows a similar effect for the query word defense, the word with a high improvement of clarity in the TREC query set. Note that defense also occurs about as often as tour : 1199 times in trec5-fbis. The clearest clarification in this case is "IN defense:NP BEZ " which corresponds to "[Department/Ministry] of Defense is" and occurs 27 times. The clarification "CD defense:NN CC" corresponding to phrases such as "[team will use] a 52 defense and" which although it occurs an equal number of times, does not show as great an improvement in clarity. In the first case almost all documents are military related, whereas defense as a common noun could appear in any contextviz. defense, sports, law, etc. There is no apparent relation between the number of occurrences of a pattern and clarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSION AND FUTURE WORK</head><p>We have shown a method for extracting patterns of word usage from a corpus and for using those patterns to help the user clarity an ambiguous query. The patterns represent sequences of parts of speech that occur around the query word often enough in the corpus that they are likely to be meaningful. Frequent patterns are mapped to human-generated clarification questions that the user may choose from. Note that we envision this as an optional side-bar to the return of query results-there seems little value in requiring the searcher to clarify the question if his or her desired document is already in the top ranks.</p><p>Once the user has selected a clarification question, we can re-issue the query based on the part of speech patterns, though slightly relaxed to increase recall. A list of sample patterns is generally helpful for the user interpreting the question.</p><p>We used a statistical measure called query clarity <ref type="bibr">[8]</ref> to demonstrate that the clarification questions generally provide a much more focused set of documents.</p><p>We are working on extending these ideas to build a better set of clarification questions for the patterns and to determine ways for automatically constructing such questions (because it is tedious to do so by hand). In Figure <ref type="figure" target="#fig_2">3</ref> it is apparent that certain clarification questions have multiple patterns associated with them. We are studying methods by which these patterns for a given question can be learned using training data. We are also building a system that implements these ideas to field test an interface to find out what works best in live settings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Some of the common part of speech tags and their corresponding parts of speech in the Brown corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>JJ party:NN varieties of a party NP party:NP names of a party NN IN party:NN NNS things done with a party VB party:NN NN things done to a party</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: Partial list of patterns recognized by the query clarification index component, along with the questions corresponding to those patterns. In the pattern, "Q:pos" means the query word occurring in that part of speech. The codes "noun," "verb," and "adj" are macros that indicate all varieties of nouns that the tagger identifies. In the Question column, QQ would be replaced by the query word.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Some patterns that occur frequently in the trec5-fbis corpus, and selected instances of the patterns with a query word. The instances list the pattern with the query word inserted, the number of times that pattern occurs in the 80,000 document subset of the corpus, and then one or two examples of the pattern in the text.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(Qi,j) &gt; clarity(Qi))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Graph shows the clarity values for the clarifying questions related to tour, the values shown in Figure 6. The values were sorted in order of clarity. The original clarity of tour is the solid horizontal line at 0.525</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Breakdown of changes in clarity for the patterns recorded for the query defense. The original clarity of that query was 0.511</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>shows a graph of the clarity values, with a straight line representing the original clarity of the query. It is clear that improvement is usually seen, and often quite large.</figDesc><table><row><cell></cell><cell cols="2">TREC</cell><cell cols="3">Query</cell><cell>Num. Percent</cell><cell cols="2">Number</cell><cell cols="2">Percent Change in</cell><cell>Percent</cell></row><row><cell>Pattern</cell><cell cols="9">topic Count Clarity Improvement word Quests improved improved</cell><cell>clarity improved</cell></row><row><cell cols="2">257 np tourists:nns cc</cell><cell>12</cell><cell cols="3">cigarette 2.01</cell><cell>15 283.1</cell><cell></cell><cell>5</cell><cell>33.33</cell><cell>-0.15</cell><cell>-9.69</cell></row><row><cell>nn toured:vbd at</cell><cell>282</cell><cell>20</cell><cell>1.98</cell><cell cols="2">crime</cell><cell>93 278.5</cell><cell></cell><cell>47</cell><cell>50.53</cell><cell>0.08</cell><cell>10.41</cell></row><row><cell>jj tour:nn np</cell><cell>268</cell><cell>34</cell><cell cols="3">defense 1.91</cell><cell>85 264.8</cell><cell></cell><cell>71</cell><cell>83.52</cell><cell>0.17</cell><cell>33.47</cell></row><row><cell>np tourist:np np</cell><cell>288</cell><cell>23</cell><cell>1.85</cell><cell></cell><cell>diet</cell><cell>16 253.9</cell><cell></cell><cell>8</cell><cell>50.00</cell><cell>0.04</cell><cell>4.16</cell></row><row><cell>np tourist:nn nn</cell><cell cols="2">282,284 24</cell><cell>1.78</cell><cell></cell><cell>drug</cell><cell>95 240.4</cell><cell></cell><cell>78</cell><cell>82.10</cell><cell>0.18</cell><cell>23.05</cell></row><row><cell>cc tourism:nn np</cell><cell>255</cell><cell>27</cell><cell cols="3">environment 1.76</cell><cell>97 236.0</cell><cell></cell><cell>72</cell><cell>74.22</cell><cell>0.13</cell><cell>23.65</cell></row><row><cell>jj tourists:nns cc</cell><cell>298</cell><cell>22</cell><cell>1.75</cell><cell></cell><cell>gun</cell><cell>80 233.6</cell><cell></cell><cell>32</cell><cell>40.00</cell><cell>-0.07</cell><cell>-6.13</cell></row><row><cell>cc tourism:nn nn</cell><cell>275</cell><cell>39</cell><cell cols="3">health 1.71</cell><cell>82 227.2</cell><cell></cell><cell>46</cell><cell>56.09</cell><cell>0.07</cell><cell>7.73</cell></row><row><cell>jj tour:nn wdt</cell><cell>254</cell><cell>24</cell><cell>1.61</cell><cell></cell><cell>heart</cell><cell>37 208.1</cell><cell></cell><cell>15</cell><cell>40.54</cell><cell>-0.03</cell><cell>-2.85</cell></row><row><cell>jj tour:nn in</cell><cell>289</cell><cell>188</cell><cell cols="3">hospital 1.56</cell><cell>70 197.1</cell><cell></cell><cell>59</cell><cell>84.28</cell><cell>0.31</cell><cell>27.67</cell></row><row><cell cols="2">294 nn tourism:nn nns</cell><cell>15</cell><cell cols="3">husbandry 1.50</cell><cell>16 186.4</cell><cell></cell><cell>15</cell><cell>93.75</cell><cell>0.51</cell><cell>86.22</cell></row><row><cell>cd tourist:nn nns</cell><cell>279</cell><cell>14</cell><cell cols="3">magnetic 1.48</cell><cell>29 181.9</cell><cell></cell><cell>25</cell><cell>86.20</cell><cell>0.52</cell><cell>55.14</cell></row><row><cell>at tour:nn nn</cell><cell>293</cell><cell>35</cell><cell cols="3">military 1.45</cell><cell>91 177.1</cell><cell></cell><cell>58</cell><cell>63.73</cell><cell>0.09</cell><cell>18.63</cell></row><row><cell>nn tourism:in nn</cell><cell>277</cell><cell>14</cell><cell cols="3">mines 1.41</cell><cell>51 169.0</cell><cell></cell><cell>50</cell><cell>98.03</cell><cell>0.67</cell><cell>129.65</cell></row><row><cell>in tour:at nn</cell><cell>258</cell><cell>33</cell><cell cols="3">security 1.35</cell><cell>88 158.6</cell><cell></cell><cell>67</cell><cell>76.13</cell><cell>0.13</cell><cell>26.91</cell></row><row><cell>jj tours:nns in</cell><cell>252</cell><cell>13</cell><cell cols="3">smuggling 1.35</cell><cell>64 157.2</cell><cell></cell><cell>50</cell><cell>78.12</cell><cell>0.40</cell><cell>54.96</cell></row><row><cell>cc tourism:nn at</cell><cell>271</cell><cell>21</cell><cell>1.33</cell><cell></cell><cell>solar</cell><cell>29 153.8</cell><cell></cell><cell>25</cell><cell>86.20</cell><cell>0.31</cell><cell>35.51</cell></row><row><cell>in tourism:nn at</cell><cell>285</cell><cell>15</cell><cell cols="3">submarine 1.29</cell><cell>64 147.0</cell><cell></cell><cell>63</cell><cell>98.43</cell><cell>0.57</cell><cell>90.30</cell></row><row><cell>...</cell><cell>287</cell><cell></cell><cell cols="3">surveillance</cell><cell>30</cell><cell></cell><cell>28</cell><cell>93.33</cell><cell>0.70</cell><cell>102.57</cell></row><row><cell>...</cell><cell>291</cell><cell></cell><cell></cell><cell></cell><cell>tax</cell><cell>97</cell><cell></cell><cell>42</cell><cell>43.29</cell><cell>-0.01</cell><cell>-1.48</cell></row><row><cell>cc tourist:nn nns</cell><cell cols="2">269,283 40</cell><cell>0.52</cell><cell></cell><cell>trade</cell><cell>94 0.8</cell><cell></cell><cell>64</cell><cell>68.08</cell><cell>0.07</cell><cell>14.81</cell></row><row><cell cols="2">300 jj tourists:nns vbg</cell><cell>19</cell><cell cols="3">traffic 0.52</cell><cell>87 -0.6</cell><cell></cell><cell>69</cell><cell>79.31</cell><cell>0.22</cell><cell>26.89</cell></row><row><cell>np tour:nn in</cell><cell>276</cell><cell>54</cell><cell cols="3">uniform 0.42</cell><cell>44 -19.7</cell><cell></cell><cell>40</cell><cell>90.90</cell><cell>0.53</cell><cell>64.63</cell></row><row><cell></cell><cell>265</cell><cell></cell><cell cols="3">violence</cell><cell>73</cell><cell></cell><cell>53</cell><cell>72.60</cell><cell>0.20</cell><cell>22.60</cell></row><row><cell cols="8">292 Figure 6: Breakdown of changes in clarity for the welfare 46</cell><cell>33</cell><cell>71.73</cell><cell>0.32</cell><cell>51.80</cell></row><row><cell cols="8">patterns recorded for the query tour. The original</cell><cell></cell><cell></cell></row><row><cell cols="6">Per-question averages clarity of that query was 0.525</cell><cell>1165</cell><cell></cell><cell>1118</cell><cell>95.96</cell><cell>0.24</cell><cell>35.68</cell></row><row><cell></cell><cell cols="5">Per-query averages</cell><cell>46</cell><cell></cell><cell>45</cell><cell>97.8</cell><cell>0.27</cell><cell>40.96</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">airlines</cell><cell>36</cell><cell></cell><cell>19</cell><cell>52.77</cell><cell>0.05</cell><cell>4.15</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">apartment</cell><cell>45</cell><cell></cell><cell>30</cell><cell>66.66</cell><cell>0.18</cell><cell>17.27</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">attorney</cell><cell>29 Percent</cell><cell></cell><cell>20</cell><cell>68.96</cell><cell>0.24</cell><cell>21.80</cell></row><row><cell>Pattern</cell><cell></cell><cell cols="5">author Count Clarity Improvement 92</cell><cell></cell><cell>32</cell><cell>34.78</cell><cell>-0.04</cell><cell>-5.14</cell></row><row><cell>in defense:np bez</cell><cell></cell><cell>27</cell><cell cols="3">biotech 2.01</cell><cell>24 302.3</cell><cell></cell><cell>24</cell><cell>100.00</cell><cell>0.55</cell><cell>76.012</cell></row><row><cell>np defense:np in</cell><cell></cell><cell>56</cell><cell cols="3">birthday 1.98</cell><cell>16 297.4</cell><cell></cell><cell>12</cell><cell>75.00</cell><cell>0.26</cell><cell>22.95</cell></row><row><cell cols="2">punc defense:np np</cell><cell>147</cell><cell cols="3">cheap 1.91</cell><cell>44 283.1</cell><cell></cell><cell>40</cell><cell>90.90</cell><cell>0.48</cell><cell>64.65</cell></row><row><cell>at defense:nn cc</cell><cell></cell><cell>84</cell><cell cols="3">computer 1.85</cell><cell>75 271.6</cell><cell></cell><cell>11</cell><cell>14.66</cell><cell>-0.34</cell><cell>-24.50</cell></row><row><cell>at defense:np in</cell><cell></cell><cell>109</cell><cell cols="3">divorce 1.78</cell><cell>13 257.5</cell><cell></cell><cell>3</cell><cell>23.08</cell><cell>-0.22</cell><cell>-14.73</cell></row><row><cell>in defense:np rb</cell><cell></cell><cell>32</cell><cell cols="3">employment 0.99</cell><cell>92 98.5</cell><cell></cell><cell>76</cell><cell>82.60</cell><cell>0.23</cell><cell>44.91</cell></row><row><cell>in defense:nn at</cell><cell></cell><cell>49</cell><cell cols="2">0.98</cell><cell>fish</cell><cell>72 96.1</cell><cell></cell><cell>58</cell><cell>80.55</cell><cell>0.34</cell><cell>43.16</cell></row><row><cell>nns defense:nn np</cell><cell></cell><cell>39</cell><cell cols="2">0.96</cell><cell>free</cell><cell>96 93.8</cell><cell></cell><cell>66</cell><cell>68.75</cell><cell>0.17</cell><cell>26.56</cell></row><row><cell>in defense:np cc</cell><cell></cell><cell>192</cell><cell cols="3">homes 0.95</cell><cell>23 91.4</cell><cell></cell><cell>2</cell><cell>8.69</cell><cell>-0.70</cell><cell>-34.10</cell></row><row><cell>np defense:np np</cell><cell></cell><cell>3978</cell><cell cols="3">house 0.94</cell><cell>83 89.7</cell><cell></cell><cell>65</cell><cell>78.31</cell><cell>0.27</cell><cell>37.66</cell></row><row><cell>in defense:nn nns</cell><cell></cell><cell>272</cell><cell cols="3">international 0.94</cell><cell>94 88.5</cell><cell></cell><cell>82.00</cell><cell>87.23</cell><cell>0.29</cell><cell>74.17</cell></row><row><cell>nn defense:np np</cell><cell></cell><cell>137</cell><cell cols="3">investing 0.94</cell><cell>29 88.3</cell><cell></cell><cell>22</cell><cell>75.86</cell><cell>0.29</cell><cell>49.72</cell></row><row><cell>nn defense:cc nn</cell><cell></cell><cell>59</cell><cell cols="2">0.90</cell><cell>job</cell><cell>78 80.2</cell><cell></cell><cell>34</cell><cell>43.58</cell><cell>0.04</cell><cell>5.064</cell></row><row><cell>at defense:nn nn</cell><cell></cell><cell>1470</cell><cell cols="2">0.87</cell><cell>loan</cell><cell>82 75.2</cell><cell></cell><cell>36</cell><cell>43.90</cell><cell>0.02</cell><cell>2.59</cell></row><row><cell>in defense:np nn</cell><cell></cell><cell>47</cell><cell cols="3">marijuana 0.87</cell><cell>37 74.7</cell><cell></cell><cell>37</cell><cell>100.00</cell><cell>0.53</cell><cell>54.64</cell></row><row><cell>np defense:np nn</cell><cell></cell><cell>46</cell><cell cols="3">master 0.86</cell><cell>38 73.2</cell><cell></cell><cell>21</cell><cell>55.26</cell><cell>0.13</cell><cell>13.60</cell></row><row><cell>cc defense:np np</cell><cell></cell><cell>265</cell><cell cols="3">software 0.85</cell><cell>50 71.2</cell><cell></cell><cell>16</cell><cell>32.00</cell><cell>-0.18</cell><cell>-15.19</cell></row><row><cell>nn defense:np</cell><cell></cell><cell>31</cell><cell cols="2">0.85</cell><cell>tour</cell><cell>65 70.3</cell><cell></cell><cell>63</cell><cell>96.92</cell><cell>0.59</cell><cell>113.60</cell></row><row><cell>nn defense:in nn</cell><cell></cell><cell>84</cell><cell cols="3">travel 0.80</cell><cell>67 60.8</cell><cell></cell><cell>31</cell><cell>46.26</cell><cell>0.02</cell><cell>1.63</cell></row><row><cell>...</cell><cell></cell><cell></cell><cell cols="3">vacation</cell><cell>23</cell><cell></cell><cell>19</cell><cell>82.60</cell><cell>0.22</cell><cell>23.02</cell></row><row><cell>...</cell><cell></cell><cell></cell><cell cols="3">vietnam</cell><cell>45</cell><cell></cell><cell>20</cell><cell>44.44</cell><cell>-0.09</cell><cell>-9.12</cell></row><row><cell cols="2">toin defense:np np</cell><cell>55</cell><cell cols="2">0.52</cell><cell></cell><cell>4.4</cell><cell></cell><cell></cell><cell></cell></row><row><cell>in defense:nn in</cell><cell cols="5">Per-question averages 373 0.42</cell><cell>1351 -15.7</cell><cell></cell><cell>842</cell><cell>62.32</cell><cell>0.14</cell><cell>23.76</cell></row><row><cell></cell><cell cols="5">Per-query averages</cell><cell>54</cell><cell></cell><cell>33</cell><cell>61.10</cell><cell>0.14</cell><cell>25.43</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">The pattern JJ tourist:NN VBG corresponds to phrases</cell></row></table><note><p>Figure 4: Summary evaluation of change in clarity broken down by query and overall for TREC queries (top) and general Web queries (bottom).</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://www.northernlight.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://www.altavista.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>http://www.wordtracker.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>http://www.google.com/press/zeitgeist2001.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>http://www.metaspy.com</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The original motivation for this work arose out of conversations with W. Bruce Croft. We are grateful to Ted Allen and Hema Krishnan for some preliminary work they did suggesting that this technique could succeed. We also thank Victor Lavrenko, Steve Cronen-Townsend, Margie Connell, and Steve Harding for their help making software work.</p><p>This material is based on work supported in part by the Center for Information Retrieval, in part by NSF grant numbers IIS-9907018 and IIS-9907331, and in part by Advanced Research and Development Activity under contract number MDA904-01-C-0984. Any opinions, findings and conclusions or recommendations expressed in this material are the authors' and do not necessarily reflect those of the sponsors.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Evaluating document clustering for interactive information retrieval</title>
		<author>
			<persName><forename type="first">A</forename><surname>Leuski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM CIKM 2001 Tenth International Conference on Information and Knowledge Management</title>
		<meeting>the ACM CIKM 2001 Tenth International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Interactive Information Organization: Techniques and Evaluation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Leuski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<pubPlace>Amherst</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The paraphrase search assistant: Terminological feedback for iterative information seeking</title>
		<author>
			<persName><forename type="first">G</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suresh</forename><surname>Anick</surname></persName>
		</author>
		<author>
			<persName><surname>Tipirneni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Research in Information Retrieval (SIGIR)</title>
		<meeting>the ACM Conference on Research in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="153" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Query-reformulation on the internet: empirical data and the hyperindex search engine</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Bruza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dennis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the RIAO Conference: Intelligent Text and Image Handling</title>
		<meeting>the RIAO Conference: Intelligent Text and Image Handling<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="488" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Interactive internet search: Keyword, directory and query reformulation mechanisms compared</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bruza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Mcarthur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Dennis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Research in Information Retrieval (SIGIR)</title>
		<meeting>the ACM Conference on Research in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="280" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The INQUERY retrieval system</title>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">M</forename><surname>Harding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of DEXA-92, 3rd International Conference on Database and Expert Systems Applications</title>
		<meeting>DEXA-92, 3rd International Conference on Database and Expert Systems Applications</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="78" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Using statistics in lexical analysis</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hindle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="115" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Relevance feedback and personalization: A language modeling perspective</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Cronen</forename><surname>Townsend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the DELOS-NSF Worshop on Personalization and Recommender Systems in Digital Libraries</title>
		<meeting>the DELOS-NSF Worshop on Personalization and Recommender Systems in Digital Libraries</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="49" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Quantifying query ambiguity</title>
		<author>
			<persName><forename type="first">Steve</forename><surname>Cronen-Townsend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Human Language Technology (HLT 2002)</title>
		<meeting>the Conference on Human Language Technology (HLT 2002)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="94" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Predicting query performance</title>
		<author>
			<persName><forename type="first">Steve</forename><surname>Cronen-Townsend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Research in Information Retrieval (SIGIR)</title>
		<meeting>the ACM Conference on Research in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Finding topic words for hierarchical summarization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lawrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Research in Information Retrieval (SIGIR)</title>
		<meeting>the ACM Conference on Research in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="349" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">SQLET: Short query linguistic expansion techniques: Palliating one or two-word queries by providing intermediate structure to WWW pages</title>
		<author>
			<persName><forename type="first">G</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RIAO &apos;97</title>
		<meeting>RIAO &apos;97</meeting>
		<imprint>
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reexamining the cluster hypothesis: Scatter/gather on retrieval results</title>
		<author>
			<persName><forename type="first">Marti</forename><surname>Hearst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Research in Information Retrieval (SIGIR)</title>
		<meeting>the ACM Conference on Research in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="76" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Evaluating combinations of ranked lists and visualizations of inter-document similarity</title>
		<author>
			<persName><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leuski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Swan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Byrd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Processing and Management (IPM)</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="435" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Verbosity and interface design</title>
		<author>
			<persName><forename type="first">K</forename><surname>Franzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</author>
		<idno>T2000:04</idno>
		<ptr target="http://citeseer.nj.nec.com/313985.html" />
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Swedish Institute of Computer Science (SICS)</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Word Sense Disambiguation for Large Text Databases</title>
		<author>
			<persName><forename type="first">R</forename><surname>Krovetz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>Amherst</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Discovering and comparing topic hierarchies</title>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Lawrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RIAO 2000 Conference</title>
		<meeting>RIAO 2000 Conference</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="314" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Lighthouse: Showing the way to relevant information</title>
		<author>
			<persName><forename type="first">Anton</forename><surname>Leuski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Information Visualization 2000 (InfoVis 2000)</title>
		<meeting>the IEEE Symposium on Information Visualization 2000 (InfoVis 2000)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="125" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Building, testing, and applying concept hierarchies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lawrie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval: Recent Research from the CIIR, W. Bruce Croft</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</editor>
		<imprint>
			<publisher>Kluwer Academic Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="235" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Word sense disambiguation and information retrieval</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Research in Information Retrieval (SIGIR)</title>
		<meeting>the ACM Conference on Research in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="142" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deriving concept hierarchies from text</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Research in Information Retrieval (SIGIR)</title>
		<meeting>the ACM Conference on Research in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="206" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Taking &quot;snapshots&quot; with livetopics: Watch out for mirages</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Seltzer</surname></persName>
		</author>
		<ptr target="http://www.samizdat.com/cobb/oct97.html" />
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Aspect windows, 3-d visualizations, and indirect comparisons of information retrieval systems</title>
		<author>
			<persName><forename type="first">Russell</forename><forename type="middle">C</forename><surname>Swan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Research in Information Retrieval (SIGIR)</title>
		<meeting>the ACM Conference on Research in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="173" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The design and implementation of a part of speech tagger for english</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Broglio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<idno>IR-52</idno>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts, Amherst, Center for Intelligent Information Retrieval</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
