<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Nonlocal Discrete Regularization on Weighted Graphs: A Framework for Image and Manifold Processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Abderrahim</forename><surname>Elmoataz</surname></persName>
							<email>abder.elmoataz@greyc.ensicaen.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">ENSICAEN in the GREYC Laboratory</orgName>
								<orgName type="institution" key="instit1">Université de Caen Basse-Normandie</orgName>
								<orgName type="institution" key="instit2">Image Team</orgName>
								<address>
									<postCode>F-14050</postCode>
									<settlement>CAEN cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Olivier</forename><surname>Lezoray</surname></persName>
							<email>olivier.lezoray@uni-caen.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">ENSICAEN in the GREYC Laboratory</orgName>
								<orgName type="institution" key="instit1">Université de Caen Basse-Normandie</orgName>
								<orgName type="institution" key="instit2">Image Team</orgName>
								<address>
									<postCode>F-14050</postCode>
									<settlement>CAEN cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sébastien</forename><surname>Bougleux</surname></persName>
							<email>sebastien.bougleux@greyc.ensicaen.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">ENSICAEN in the GREYC Laboratory</orgName>
								<orgName type="institution" key="instit1">Université de Caen Basse-Normandie</orgName>
								<orgName type="institution" key="instit2">Image Team</orgName>
								<address>
									<postCode>F-14050</postCode>
									<settlement>CAEN cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Nonlocal Discrete Regularization on Weighted Graphs: A Framework for Image and Manifold Processing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">512A9E858AE29AE7F7ED92988EDA0673</idno>
					<idno type="DOI">10.1109/TIP.2008.924284</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Image and manifold processing</term>
					<term>nonlocal discrete regularization</term>
					<term>-Laplacian</term>
					<term>weighted graph</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce a nonlocal discrete regularization framework on weighted graphs of the arbitrary topologies for image and manifold processing. The approach considers the problem as a variational one, which consists of minimizing a weighted sum of two energy terms: a regularization one that uses a discrete weighted -Dirichlet energy and an approximation one. This is the discrete analogue of recent continuous Euclidean nonlocal regularization functionals. The proposed formulation leads to a family of simple and fast nonlinear processing methods based on the weighted -Laplace operator, parameterized by the degree of regularity, the graph structure and the graph weight function. These discrete processing methods provide a graph-based version of recently proposed semi-local or nonlocal processing methods used in image and mesh processing, such as the bilateral filter, the TV digital filter or the nonlocal means filter. It works with equal ease on regular 2-D and 3-D images, manifolds or any data. We illustrate the abilities of the approach by applying it to various types of images, meshes, manifolds, and data represented as graphs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the context of mesh processing, smoothing and denoising are also key processes dedicated to noise removal causing minimal damage to geometric features. Most mesh smoothing methods are based on the discrete Laplace-Beltrami regularization or on the discrete curvature regularization <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. Other smoothing methods, based on feature preserving were mostly inspired by anisotropic diffusion in image processing <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b8">[9]</ref>. Geometric flows have been extensively used in mesh processing <ref type="bibr" target="#b9">[10]</ref>. In particular, surface flows based on functional minimization (i.e., evolving a surface so as to progressively decrease an energy functional) is a common methodology in geometric processing with applications to spanning surface diffusion <ref type="bibr" target="#b10">[11]</ref>, denoising of scanned meshes <ref type="bibr" target="#b11">[12]</ref>, shape optimization and surface design <ref type="bibr" target="#b12">[13]</ref>, minimal surfaces <ref type="bibr" target="#b13">[14]</ref>, etc.</p><p>In the context of manifold and data processing, dimensionality reduction <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b16">[17]</ref> (extracting low-dimensional structure from high-dimensional data), clustering <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref> (automatic identification of groups of similar objects), and classification <ref type="bibr" target="#b19">[20]</ref>- <ref type="bibr" target="#b21">[22]</ref> (assigning labels to instances) are key processes. In particular, methods based on graph Laplacian have became increasingly popular in machine learning to perform any of the above-mentioned key processes. However, manifolds and discrete data, as images and meshes, can also contain inner noise. Therefore, regularization occurs as a natural candidate for manifold processing <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref> since, e.g., noise filtering can be useful to avoid overfitting in a learning process. Manifold regularization denotes also a family of learning algorithms <ref type="bibr" target="#b19">[20]</ref> based on regularization with both labeled and unlabeled data. Transductive graph learning algorithms and standard methods like support vector machines <ref type="bibr" target="#b21">[22]</ref> can then be considered as special cases of manifold regularization. All these methods are based on the assumption that the data lies on a submanifold. However, sampled data lies almost never exactly on the submanifold due to the noise scattered around it. Since most previous methods are sensitive to noise, it is essential to denoise the manifold data to project it onto a submanifold <ref type="bibr" target="#b24">[25]</ref>.</p><p>As we have just mentioned, regularization is a principle the interest of which concerns a wide range of computer science domains. The application of partial and variational methods to images, meshes, manifolds and any discrete data processing has shown its effectiveness allowing high quality regularization processes. However, there are some limitations to the functionals used in regularization such as total variational ones <ref type="bibr" target="#b1">[2]</ref>. Indeed, the latter are based on derivatives which consider local features of the data. Since the advent of the nonlocal means filter <ref type="bibr" target="#b0">[1]</ref>, the use of nonlocal interactions, to capture the complex struc-ture of the data, has received a lot of interest and has shown to be very effective. A variational understanding of the nonlocal means filter was first developed in <ref type="bibr" target="#b25">[26]</ref> as a non convex functional and later in <ref type="bibr" target="#b26">[27]</ref> and <ref type="bibr" target="#b27">[28]</ref> as a convex quadratic functional. Moreover, the use of manifolds to describe nonlocal interactions of geometric structures in signals and images has recently been explored <ref type="bibr" target="#b22">[23]</ref>. In this latter work, diffusion over these manifolds is shown to be equivalent to nonlocal processing methods. However, most of these variational nonlocal formulations are expressed in a continuous setting and unfortunately the discretization of the underlying differential operators is difficult for high-dimensional data.</p><p>Moreover, whatever the origin of the data (images or databases), a common representation can be used to model them: graphs. For the particular case of images, pixels have a specific organization expressed by their spatial connectivity. Therefore, a typical graph used to represent images is a grid graph. For the particular case of unorganized data, a graph can also be associated with by modeling neighborhood relationships between the data elements. As a consequence, by using the same adapted underlying graph representation to model data with a given organization (images) or without any (general databases), one can define a framework which can be used to process general databases. We take that point of view of processing any data ranging from images to manifolds.</p><p>Inspired by continuous regularization of images and recent works on nonlocal functional for continuous regularization, we propose a general framework extending our previous works <ref type="bibr" target="#b28">[29]</ref>- <ref type="bibr" target="#b31">[32]</ref> based on a nonlocal discrete regularization on weighted graphs of the arbitrary topologies. This framework can also be considered as a discrete analogue of the nonlocal continuous regularization for the case of images <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b32">[33]</ref>. Furthermore, the proposed framework works on any discrete data represented by weighted graphs which enables a nonlocal regularization with equal ease on images and manifolds. Our approach starts directly with a discrete variational problem and works with data living on any general discrete domain. To take into account the nonlocal interactions in images and manifolds, we explicitly introduce discrete nonlocal derivatives and functionals on graphs of the arbitrary topologies, to transcribe the continuous regularization. This framework unifies the regularization of images, meshes, manifolds and data. The latter regularization enables local, semi-local or nonlocal regularization by using appropriate graph topologies and edge weights. Let be a weighted graph consisting of a set of vertices , a set of edges , and a similarity weight function defined on edges. Let be a Hilbert space defined on the vertices of . We formalize the discrete data regularization of a function by the following minimization problem:</p><p>(1) where is the smoothness degree, is the fidelity parameter, and represents the weighted local variation of the function over the graph. The solution of problem <ref type="bibr" target="#b0">(1)</ref> leads to a family of nonlinear processing methods, parameterized by the weight function, the degree of smoothness, and the fidelity parameter. There exists two main advantages of using this framework, which can be considered as a discrete analogue of continuous regularization on weighted graphs.</p><p>First, the regularization is expressed directly in a discrete setting. Involved processing methods are computed by simple and efficient iterative algorithms, without solving any PDEs. Second, the topology of graphs can be arbitrary. Since the proposed approach is general, any discrete data set can be transformed into a weighted graph, by using a similarity measure between data features. Thus, we can consider any function defined on these data as a function defined on the graph vertices.</p><p>The regularization term in problem ( <ref type="formula">1</ref>) is obtained by defining nonlocal functionals on weighted graphs. The idea of using functionals on graphs, in a regularization process, has also been proposed in other contexts, such as semi-supervised data learning <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref> and image segmentation <ref type="bibr" target="#b35">[36]</ref>. In this paper, we introduce a large family of regularization problems based on the -Laplacian which is the discrete analogue of the well-known Euclidean -Laplacian to graphs. This leads to a family of discrete linear and nonlinear filters which includes and extends several well-known models used in image processing for the classical cases of or . The case of is also considered in this paper. Moreover, the proposed framework naturally embeds local to nonlocal processing. To summarize, the proposed regularization framework on graphs unifies several existing discrete image filters, generalizes them and extends them to the processing of arbitrary data.</p><p>In this paper, we first define functionals on weighted graphs in Section II. Section III presents the discrete regularization problem (1), and the associated filter family. Section IV analyzes the obtained filters and gives relations to existing methods. In Section V, we show some regularization examples, in the context of images, meshes, manifolds, and data processing. Section VI concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. OPERATORS ON WEIGHTED GRAPHS</head><p>In this section, we recall some basic definitions on graphs, and we define nonlocal operators which can be considered as discrete versions of continuous differential operators. Analogous definitions and properties have also been used in the context of semi-supervised learning <ref type="bibr" target="#b33">[34]</ref> and differential calculus on graphs <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Preliminary Notations and Definitions</head><p>A weighted graph consists of a finite set of vertices and a finite set of weighted edges. We assume to be undirected, with no selfloops and no multiple edges. Let be the edge of that connects vertices and of . Its weight, denoted by , represents the similarity between its vertices. Similarities are usually computed by using a positive symmetric function satisfying if is not an edge of . The notation is also used to denote two adjacent vertices. We say that is connected whenever, for any pair of vertices there is a finite sequence such that is a neighbor of for every .</p><p>Let be the Hilbert space of real-valued functions defined on the vertices of a graph . A function of assigns a real value to each vertex . Clearly, the function can be represented by a column vector . By analogy with functional analysis on continuous spaces, the integral of a function , over the set of vertices , is defined as . The space is endowed with the usual inner product , where . Similarly, let be the space of real-valued functions defined on the edges of . It is endowed with the inner product</p><p>, where are two functions of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Difference Operator and Its Adjoint</head><p>Let be a weighted graph, and let be a function of . The difference operator of , noted , is defined on an edge by</p><p>(2)</p><p>The directional derivative (or edge derivative) of , at a vertex , along an edge , is defined as</p><formula xml:id="formula_0">(3)</formula><p>This definition is consistent with the continuous definition of the derivative of a function: , , and if then . The adjoint of the difference operator, noted , is a linear operator defined by <ref type="bibr" target="#b3">(4)</ref> for all and all . Proposition 1: The adjoint operator , of a function , can by expressed at a vertex by the following expression:</p><p>(5) Proof: By using the definition of the inner product in , the left term of ( <ref type="formula">4</ref>) is rewritten as</p><p>The proof is completed by comparing the last two equations.</p><p>The divergence operator, defined by , measures the net outflow of a function of , at each vertex of the graph. Proposition 2: Each function has a null divergence over the entire set of vertices:</p><p>. Proof: From Proposition 1, is the sum of terms . Since is symmetric, then this sum is null. Other general definitions of the difference operator have been proposed in literature. In particular, the difference operator recently proposed by Zhou and Schölkopf <ref type="bibr" target="#b33">[34]</ref>, and defined by with , is not null when the function is locally constant (also pointed out by Hein et al. <ref type="bibr" target="#b38">[39]</ref>). Moreover, its adjoint does not satisfy Proposition 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Gradient Operator</head><p>The weighted gradient operator of a function , at a vertex , is the vector operator defined by</p><p>The -norm of this vector represents the local variation of the function at a vertex of the graph. It is defined by <ref type="bibr" target="#b5">(6)</ref> The local variation is a semi-norm which measures the regularity of a function around a vertex of the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Family of Weighted P-Laplace Operators</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Let</head><p>be a real number. The weighted -Laplace operator of a function , noted , is defined by <ref type="bibr" target="#b6">(7)</ref> Proposition 3: The -Laplace operator of , at a vertex , can be computed by ( <ref type="formula">8</ref>) with ( <ref type="formula">9</ref>)</p><p>Proof: From ( <ref type="formula">2</ref>), ( <ref type="formula">5</ref>), and ( <ref type="formula">7</ref>), we have This last term is exactly <ref type="bibr" target="#b7">(8)</ref>.</p><p>Remark 1: In ( <ref type="formula">7</ref>), is chosen to be evaluated at . If one chooses to evaluate at , the same expression of ( <ref type="formula">7</ref>), but with a minus sign in ( <ref type="formula">9</ref>), is obtained. To have as a positive expression, we prefer to have to be evaluated at . The -Laplace operator is nonlinear, with the exception of . In this latter case, it corresponds to the combinatorial graph Laplacian, which is one of the classical second order operators defined in the context of spectral graph theory <ref type="bibr" target="#b39">[40]</ref> (10)</p><p>Another particular case of the -Laplace operator is obtained with . In this case, it is the weighted curvature of the function on the graph <ref type="bibr" target="#b10">(11)</ref> If the graph is unweighted ( , ), corresponds to the curvature operator proposed in <ref type="bibr" target="#b40">[41]</ref> and <ref type="bibr" target="#b41">[42]</ref> in the context of image restoration. More generally, is the discrete analogue of the mean curvature of the level curve of a function defined on a continuous domain of . This is explained by the following property, which is a rewriting of Proposition 3.</p><p>Corollary 1: The -Laplace operator of a function can be expressed, at a vertex , by</p><p>Proof: We show that ( <ref type="formula" target="#formula_1">12</ref>) is equivalent to <ref type="bibr" target="#b7">(8)</ref>. From (3), the right term of ( <ref type="formula" target="#formula_1">12</ref>) is equal to By using (3) again, we obtain exactly the first equation of the proof of Proposition 3, which completes the proof.</p><p>Then, the -Laplace operator (8) can be seen as an extension of and . To avoid zero denominator in (11) when , the local variation ( <ref type="formula">6</ref>) is replaced by its regularized version:</p><p>, where is a small fixed constant <ref type="bibr" target="#b41">[42]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. REGULARIZATION ON WEIGHTED GRAPHS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Let</head><p>be a given function defined on the vertices of a weighted graph . In a given context, the function represents an observation of a clean function corrupted by a given noise such that . Such noise is assumed to have zero mean and variance , which usually corresponds to observation errors.</p><p>To recover the uncorrupted function , a commonly used method is to seek for a function which is regular enough on , and also close enough to . This inverse problem can be formalized by the minimization of an energy functional, which typically involves a regularization term plus an approximation term (also called fitting term). In this paper, we propose to consider the following variational problem: <ref type="bibr" target="#b12">(13)</ref> where the regularization functional is the discrete -Dirichlet form of the function <ref type="bibr" target="#b13">(14)</ref> The tradeoff between the two competing terms in the functional , is specified by the fidelity parameter . By varying the value of , the variational problem (13) allows one to describe the function at different scales, each scale corresponding to a value of .</p><p>The degree of regularity, which has to be preserved, is controlled by the value of . When , the minimizer (13) corresponds to the well-known Tikhonov regularization on weighted graphs. When , it is the fitted total variation, previously proposed on unweighted graphs in <ref type="bibr" target="#b40">[41]</ref> and <ref type="bibr" target="#b41">[42]</ref>. The more general problem treated in this paper can be seen as a natural extension of these two latter cases. In the sequel, we discuss the existence of its solution, then we show that the solution is based on the -Laplace operator (8), and we give an iterative algorithm to approximate it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Existence of the Solution and Regularization Equations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>When</head><p>, the energy is a convex functional of functions of . As we have when , by standard arguments in convex analysis, there exists a global minimum for the minimizer <ref type="bibr" target="#b12">(13)</ref>. Then, any local minimum of is a global minimum of . Let be the set of constant functions , such that for all , . So, is also a strictly convex functional of functions in . In this is case, the minimization of has a unique solution. This is also the case for functions in . Indeed, is translation invariant, e.g., for all . Thus, there exists only one global minimum. To get the solution of the minimizer (13), we consider the following system of equations: <ref type="bibr" target="#b14">(15)</ref> which is rewritten as <ref type="bibr" target="#b15">(16)</ref> If this system has a solution, then it is the solution of ( <ref type="formula">13</ref>). When , is nonconvex, and the global minimum of ( <ref type="formula">13</ref>) is not insured. However, this case is also considered in this paper, in order to analyze the behavior of the associated diffusion processes beyond the usual bound . The solution of the system ( <ref type="formula">16</ref>) is computed by using the following property.</p><p>Proposition 4: Let be a function in . Then <ref type="bibr" target="#b16">(17)</ref> Proof: Let be a vertex of . From ( <ref type="formula">14</ref>), the th term of the derivative of is given by It only depends on the edges incident to . Let be the vertices of connected to by an edge of . Then, by using the chain rule, we have which is equal to From <ref type="bibr" target="#b7">(8)</ref>, this latter expression is exactly . By using Proposition 4, the system ( <ref type="formula">16</ref>) is rewritten as <ref type="bibr" target="#b17">(18)</ref> which is equivalent to the following system of algebraic equations (see Proposition 3): <ref type="bibr" target="#b18">(19)</ref> This can be considered as the discrete Euler-Lagrange equation associated to the problem <ref type="bibr" target="#b12">(13)</ref>. Contrary to the continuous case, it does not involve any PDEs. To get its solution, several methods can be used, depending on the value of the regularity parameter . In the linear case , iterative methods such as the Gauss-Jacobi method, or the infinitesimal steepest descent method, converge close to the solution of <ref type="bibr" target="#b12">(13)</ref>. In Section III-B, we give a general method to approximate the solution for .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Family of Discrete Diffusion Processes</head><p>We propose to use the linearized Gauss-Jacobi iterative method to solve the system <ref type="bibr" target="#b18">(19)</ref>. Let be an iteration step, and let be the solution of ( <ref type="formula">19</ref>) at the step . Then, the method is given by the following algorithm: . ( <ref type="formula">20</ref>) It describes a family of discrete diffusion processes, which is parameterized by the structure of the graph (topology and weight function), the parameter , and the parameter . Also, the stopping time can be given a priori, or can be determined by a stopping criterion. To get the convergence of the process, a classical stopping criterion is , where is a small fixed constant.</p><p>These processes can be interpreted as forced low-pass filters on graphs. Let be the filter coefficients defined by if otherwise.</p><p>Then, the regularization algorithm ( <ref type="formula">20</ref>) is rewritten as ( <ref type="formula">22</ref>) One can remark that satisfies the following properties:</p><p>.</p><p>At each iteration of the algorithm <ref type="bibr" target="#b21">(22)</ref>, the new value depends on two quantities: the original value , and a weighted average of the filtered values of in a neighborhood of .</p><p>Proposition 5: For all , if the algorithm (20), or equivalently <ref type="bibr" target="#b21">(22)</ref>, converges, then it converges to the solution of the minimizer <ref type="bibr" target="#b12">(13)</ref>. Moreover, when , it converges. Proof: From (23), we can observe that is a convex combination of and , for all . Thus, we have Then, by recursion, an iteration step of ( <ref type="formula">22</ref>) satisfies the minimum-maximum principle Let be the set of functions such that , where is the infinity norm. From <ref type="bibr" target="#b21">(22)</ref>, an iteration can be written as , with . Then the minimum-maximum principle stability implies that . By considering that , then each component is continuous with respect to , for all . This implies that is a continuous mapping. As is nonempty, compact and convex, the Schauder fixed point theorem <ref type="bibr" target="#b42">[43]</ref> shows that there exists which satisfies . Then, if the algorithm ( <ref type="formula">22</ref>) converges, it is to the limit function which satisfies <ref type="bibr" target="#b18">(19)</ref>. Since for , <ref type="bibr" target="#b18">(19)</ref> is the solution of the minimizer ( <ref type="formula">13</ref>), ( <ref type="formula">22</ref>) also converges to the solution of <ref type="bibr" target="#b12">(13)</ref>.</p><p>When , we can remark that an iteration of the diffusion process <ref type="bibr" target="#b21">(22)</ref> can be written in matrix form as</p><p>, where is a stochastic matrix (nonnegative, symmetric, unit row sum). Then, as demonstrated in <ref type="bibr" target="#b43">[44]</ref>, this discrete diffusion process satisfies the minimum-maximum principle, and converges to a constant as . Remark 2: From Proposition 5, when (nonconvex case), if the algorithm <ref type="bibr" target="#b21">(22)</ref> [or equivalently <ref type="bibr" target="#b19">(20)</ref>] converges to some function , the latter is not insured to be the global minimum of the minimizer <ref type="bibr" target="#b12">(13)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. REGULARIZATION OF FUNCTIONS ON DISCRETE DATA</head><p>The minimization problem <ref type="bibr" target="#b12">(13)</ref>, and the discrete diffusion processes <ref type="bibr" target="#b19">(20)</ref>, can be used to regularize any function defined on a finite set of discrete data . This is achieved by constructing a weighted graph , and by considering the function to be regularized as a function , defined on the vertices of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Construction of Graphs</head><p>There exist several popular methods that transform the set , with a given pairwise distance measure , into a neighborhood graph (or similarity graph). Constructing such a graph consists of modeling neighborhood relationships between data. Among the existing graphs, the simplest of them is the -neighborhood graph, where two data are connected by an edge of if , with . We can also quote the minimum spanning tree, the -nearest neighbors graph, the Delaunay triangulation, or the relative neighborhood graph, as other possible graph topologies (see <ref type="bibr" target="#b44">[45]</ref> for a survey on neighborhood graphs used in pattern recognition problems). The choice of the graph topology enables us to perform several regularization processes that can integrate local, semi-local or nonlocal interactions between the data. These interactions are said to be fully nonlocal if the constructed graph is the complete graph , with . The weights are computed according to a measure of similarity , which satisfies if otherwise.</p><p>(</p><formula xml:id="formula_4">)<label>24</label></formula><p>This measure can simply be defined as the inverse of the distance measure:</p><p>. Distances between data are estimated by comparing their features which generally depend on the initial function and on the set . To this aim, every data is assigned with a feature vector denoted by . Several choices can be considered for the expression of , depending on the nature of the features to be preserved during the regularization. In the simplest case, one can consider . It also can be computed from the values of , taken in the neighborhood of , and from the data in that neighborhood. Therefore, the weight function , associated to a given graph, can naturally incorporate local, semi-local or nonlocal features according to the topology of the graph. For instance, one can consider the three following general weight functions:</p><p>1) ; 2)</p><p>; 3) where and are two parameters depending respectively on the variations of the function and the function over the graph. These parameters are usually given a priori. Also, they can be computed automatically from the topology of the graph and the initial function . In particular, can be computed locally at each vertex of the graph (see <ref type="bibr" target="#b30">[31]</ref> and references therein).</p><p>The graph topology, associated with one of the above weight functions, describes a general family of regularizers. By changing the graph topology and the edge weights, we naturally obtain an expression of local, semi-local, or nonlocal processing methods which is embedded in the graph structure. Indeed, once edges are added between vertices, they are considered as direct neighbors and the processing is local over the graph. From these considerations, we show that with an adapted graph topology and a given appropriate weight function, the proposed family is linked to several filters defined in the context of image and mesh processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Related Works in Image Processing</head><p>First, we analyze the case of , e.g., without approximation term. In this case, when , the proposed diffusion (20) is linear and becomes .</p><p>(</p><formula xml:id="formula_5">)<label>25</label></formula><p>As described in Section III-A, when this latter diffusion is iterated until convergence, the function is the solution of the heat equation , for all . Moreover, from Proposition 5, is also the solution of the minimization of the Dirichlet energy</p><p>. By considering a fixed number of iterations, the diffusion (25) performs Laplacian smoothing, which is a general neighborhood filter used in image processing. Also, the rewriting of (25) in matrix form leads to Markov matrix filtering and spectral graph filtering <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b45">[46]</ref>. Many specific filters are related to the diffusion <ref type="bibr" target="#b24">(25)</ref>. In particular, one iteration of the diffusion process <ref type="bibr" target="#b24">(25)</ref>, associated with the weight function and the scalar feature , is equivalent to the bilateral filter introduced in the context of image denoising <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>. For this filter, the distance functions and are Euclidean distances. Another important case is obtained by using and the feature vector , where is a bounding box of size centered at . In this case, one iteration of (25) corresponds to the nonlocal means (NLMeans) filter <ref type="bibr" target="#b0">[1]</ref> (see also <ref type="bibr" target="#b22">[23]</ref> and <ref type="bibr" target="#b23">[24]</ref>). For this latter filter, the function is the Euclidean distance between feature vectors, weighted by a Gaussian kernel. Bilateral and NLMeans filters have also been redefined to denoise meshes <ref type="bibr" target="#b48">[49]</ref>- <ref type="bibr" target="#b50">[51]</ref>. These two filters, and all the filters described by <ref type="bibr" target="#b24">(25)</ref>, are generalized by the proposed method: by the regularity parameter , and by the scale parameter .</p><p>When and is constant over the set of edges (unweighted graph), the diffusion (20) corresponds exactly to the digitized PDE filters proposed in the context of image restoration <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>. If , it is the fitted TV regularization; and if , it is the Tikhonov regularization. Table <ref type="table">I</ref> resumes how our framework includes and extends some above-mentioned discrete models used in image processing. Table I reads in the following way. The first three columns present four different configurations given by the parameters and , and the graph topology. Once these latter parameters are fixed, one can then consider different values of (next columns in the row of each given configuration).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Related Works in Local and Nonlocal Continuous Regularization</head><p>The regularization of a given function , on a complete graph , takes into account fully nonlocal interactions between the data of , through the local variations that are involved in the discrete -Dirichlet form <ref type="bibr" target="#b25">(26)</ref> One can observe that this last functional is exactly the same as the functional <ref type="bibr" target="#b13">(14)</ref>, where can be replaced by ( if ). This shows that local, semi-local and nonlocal regularizations on graphs have the same formulation. One can remark that the corresponding continuous analogue of the above discrete regularization functionals, which considers only local interactions, is where is a continuous function defined in a bounded domain . Similarly, the discrete diffusion process (26) can also be rewritten in a continuous setting which uses nonlocal interactions In particular, for and , it corresponds to the nonlocal functionals introduced in <ref type="bibr" target="#b26">[27]</ref> and <ref type="bibr" target="#b27">[28]</ref> in the context of image processing Moreover, in <ref type="bibr" target="#b51">[52]</ref>, we show that, with the same gradient operator, replacing by a -norm leads to the following expression: which can be considered as the discrete analogue of the recently proposed continuous nonlocal anisotropic functionals <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. APPLICATIONS</head><p>The family of filters proposed in Section III can be used to regularize any function defined on the vertices of a graph, or on any discrete data set.</p><p>For any of these different applications, one wants to regularize a function , where and is the th component of . When the regularization operates on vector-valued functions, one regularization process per vector component is considered. Each component is processed independently and this comes to have independent iterative regularization schemes <ref type="bibr" target="#b26">(27)</ref> The p-Laplace operator is different for each component and one has <ref type="bibr" target="#b27">(28)</ref> for the th component. Applying the regularization in a component-wise manner is interesting to develop a computationally efficient solution. However, component-wise processing of vector-valued data can have serious drawbacks contrary to vector processing solutions. To overcome this limitation, a regularization process acting on vector-valued data needs to be driven by equivalent geometric attributes, taking the coupling between vector components into account <ref type="bibr" target="#b52">[53]</ref>, <ref type="bibr" target="#b53">[54]</ref>. Therefore, component-wise regularization does not have to use different local geometries but a vector one. In the case of , the p-Laplace operator is the same for all the components, but in the case of it is different. As we have just mentioned, this is not interesting. Indeed, in this case, the regularization processes can be totally independent if does not incorporate any intercomponent information resulting in no coupling between the independent regularizations. To overcome this limitation and in order to take into account the inner correlation aspect of vectorial data, the -Laplace operator is considered as being the same for the component regularizations (component coupling). This is achieved by using the same vectorial local variation defined by <ref type="bibr" target="#b28">(29)</ref> where replaces , for all in <ref type="bibr" target="#b27">(28)</ref>. The inner correlation is also considered by using vectorial weight functions, such as the ones defined in Section IV-A.</p><p>In the sequel, we provide examples of obtained results with the proposed framework for the simplification of images (scalar or vectorial), polygonal curves, meshes, manifolds, and databases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Scalar Image Smoothing:</head><p>Let be a scalar image of pixels, with which defines a mapping from the vertices to gray levels. We illustrate the abilities of the proposed framework for smoothing scalar images. All the results are shown at convergence. To this aim, Fig. <ref type="figure" target="#fig_0">1</ref> shows sample results obtained with different parameters of the proposed regularization: different values of , different values of and different weight functions.</p><p>The first line of Fig. <ref type="figure" target="#fig_0">1</ref> presents the initial image (first column) and the computed gradient on the initial image with constant weights ( , second column), with computed weights in local (third column, for ) or nonlocal configurations (fourth column, for ). For the nonlocal configuration, we consider a 19 19 neighborhood window and a 11 11 patch as a feature vector. In the table part of Fig. <ref type="figure" target="#fig_0">1</ref>, the first two grouped columns present local regularizations with constant weights and with different values of (provided above each column). For these cases, the considered graph is a 4-adjacency grid graph and the results obtained for or correspond exactly to the digital TV and filters of Chan and Osher <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>. In the table part of Fig. <ref type="figure" target="#fig_0">1</ref>, the grouped third and fourth columns present results obtained with the proposed framework with the same parameters but with computed weights . For these cases, the considered graph is a 8-adjacency grid graph. The first thing to consider is that our approach is a direct extension of <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref> to weighted graphs that enables the production of better visual results by using computed edge weights. The second thing to notice is that a low value of enables a better preservation of edges and fine structures. Moreover, it tends leveling the image in flat zones. Changing the value of parameter enables us to obtain solutions either close or far from the original image. All these noticed points become more evident once one uses a nonlocal configuration which enhances once again the preservation of edges and the production of flat zones. Nonlocal results are provided in last column of the table part of Fig. <ref type="figure" target="#fig_0">1</ref>. This shows how our proposed frameworks generalizes the NLmeans filter <ref type="bibr" target="#b0">[1]</ref>.</p><p>2) Vectorial Image Smoothing and Denoising: Let be a color image of pixels, with which defines a mapping from the vertices to a vector of color channels. . This extends the vectorial digital TV filter <ref type="bibr" target="#b41">[42]</ref> to weighted graphs as mentioned above for scalar images. Fig. <ref type="figure" target="#fig_2">2(d</ref>), (g), and (j) presents results of a nonlocal processing, for , , and , on a 120-adjacency grid graph (a search window of size <ref type="bibr">11 11)</ref> with edges weighted by and defined on a patch of size 5 5. Fig. <ref type="figure" target="#fig_2">2(d</ref>), (g), and (j) presents results with the same nonlocal parameters except that . Parameters and (for ) are automatically estimated (see <ref type="bibr" target="#b30">[31]</ref> for further details). A visual analysis of the results shows that values of enable a better preservation of edges while increasing the graph connectivity and using patches for similarities enable to better preserve some details. Fig. <ref type="figure" target="#fig_2">2(i)-(k)</ref> shows the importance of the similarity measure for computing the edges weights. Indeed, with , an over-smoothing effect is obtained without preserving details. This confirms that this is not a nonlocal view but the use of an appropriate similarity measure which enables the preservation of fine structures.</p><p>3) Image simplification: On the contrary to classical image simplification which considers grid graphs, one can simplify an image by first considering a fine partition of this image (or over-segmentation), where the pixel values of each region of the partition are replaced by the mean or the median pixel value of this region. The partition can be associated with a region adjacency graph (RAG), where vertices represent regions and where edges link adjacent regions. Let be a RAG. Let be a mapping from the vertices of to the mean or median value of their regions. Then, the simplification is achieved by regularizing the function on . Moreover, we can build an irregular pyramid of partitions by alternating simplification (only one iteration) and graph decimation since one iteration of the simplification brings neighbor vertices to similar models. We present the results of a local simplification per- formed with different values of and after iterations of sequential graph filtering and graph decimation. The edges of the RAG are weighted by . The graph is decimated along the iterations by merging regions the difference of which is lower than a given arbitrary threshold of 2 in our experiments. The first row of Fig. <ref type="figure" target="#fig_3">3</ref> presents the original image, its fine partition (obtained by the concept of homogeneous zones <ref type="bibr" target="#b54">[55]</ref>) and the associated color median image . When a color median image is presented in Fig. <ref type="figure" target="#fig_3">3</ref>, we provide the PSNR between the original and the color median image. When a partition is presented in Fig. <ref type="figure" target="#fig_3">3</ref>, we provide the number of vertices of the RAG. Last rows of Fig. <ref type="figure" target="#fig_3">3</ref> present results (color median and partition images) where each row corresponds to a value of for two different values of . When , a small value of enables a better preservation of the initial image content with a lower number of vertices. When , a small value of also enables a good preservation of the initial image content but with a higher number of vertices. It is worth noting that merging similar regions to decimate the RAG during the simplification enables to accelerate the simplification process. Therefore, the use of the RAG instead of the classical grid-graph enables a faster processing <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b55">[56]</ref> since there are less vertices as compared to the number of pixels. Similar works based on RAGs have also been proposed <ref type="bibr" target="#b56">[57]</ref>, <ref type="bibr" target="#b57">[58]</ref>.</p><p>4) Polygonal Curve and Surface Simplification: By nature, polygonal curves and surface meshes have a graph structure. First, we consider the case of a polygonal curve represented by a graph: and edges are weighted by a constant . Fig. <ref type="figure">4</ref> presents results of filter <ref type="bibr" target="#b26">(27)</ref> on a polygonal curve. The behavior is studied and illustrated in Fig. <ref type="figure">4</ref> for different values of parameters and for a local regularization. First, as attended, acting on parameter enables to reach different levels of simplification. One important thing to note here is that the presented graphs all have the same number of vertices: simplification enables to groups similar vertices around high curvature regions. The second thing to point out is that acting on enables to perform a denoising of the graph but also to smooth (for ) or to preserve sharp angles (for ). Second, we consider the case of surface meshes. Let be the set of mesh vertices, and let be the set of mesh edges. If the input mesh is noisy, we can regularize vertex coordinates or any other function defined on the graph . Results of filter <ref type="bibr" target="#b26">(27)</ref> are given in Fig. <ref type="figure">5</ref> for triangular meshes with a local regularization for edges weighted by Fig. <ref type="figure">4</ref>. Behavior of the regularization of a polygonal curve G (first row, first column) by using the discrete diffusion process (until convergence). First row presents the graph constructed over an initial set of points. Following rows present simplification results where each row corresponds to a value of p. For each p, the four regularizations are obtained with decreasing values of the scale parameter &gt; 0. The original mesh (jV j = 24930) is from Shape Repository, Aim@Shape Project (http://shapes.aim-at-shape.net).</p><p>function . We can observe the same key points as with polygonal curves. Moreover, the shrinkage effect obtained with or when is highly reduced with low values of which shows the benefits of our approach (see the cropped and zoomed areas in three last columns of the first row in Fig. <ref type="figure">5</ref>). As for image simplification on a RAG, one could also merge vertices along the iterations as they become similar.</p><p>5) Manifold Smoothing: Graph-based methods have recently emerged as a powerful tool for analyzing high-dimensional data that has been sampled from a low-dimensional submanifold <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b19">[20]</ref>. These methods begin by constructing a graph in which the nodes represent input patterns and the edges represent neighborhood relations. The resulting graph (assumed connected) can be viewed as a discretized approximation of the submanifold sampled by the input patterns. Let be a graph defined over the manifold. Typical graphs are the complete graph and the k-nearest neighbor graph. Typical manifolds being image libraries, we consider the USPS handwritten digit database for illustration. Each digit is a 16 16 image which is considered as a vector of 256 dimensions. Let be a mapping from the vertices of to the elements of the manifold. We consider the complete graph weighted by function and constructed over the manifold. To each vertex is associated a feature vector representing each Fig. <ref type="figure">5</ref>. Behavior of the regularization of a triangular mesh (first row, first column), by using the discrete diffusion process (until convergence). First line presents the original mesh (first column), a zoom on a part of this mesh (the ear of the lion) before (second column) and after regularization for p = 1 and p = 0:1 with = 0:04. The following rows present simplification results where each row corresponds to a value of p. For each p, four regularizations are obtained with decreasing values of the scale parameter &gt; 0.</p><p>digit. The filter <ref type="bibr" target="#b26">(27)</ref> is considered (256 coupled regularization processes are performed) with and different amounts of data attachment. Since the complete graph is considered, the regularization is naturally nonlocal. Fig. <ref type="figure" target="#fig_4">6</ref> presents regularization results on 200 digits from the USPS database. Without the data term, the manifold reduces to its main digit which is an artificial one since the manifold is smoothed. By increasing the data term, the regularized manifold remains closer to the original one. Such manifold regularization can be useful for classification purposes on a noiseless submanifold <ref type="bibr" target="#b24">[25]</ref> extracted from a noisy manifold.</p><p>6) Data Smoothing: Given any data, the latter can be associated with a graph by considering a similarity measure. Therefore, any database can be regularized with our method as long as it is associated with a graph structure. To show the efficiency of such processing, we consider two well-known databases: Iris and Ionosphere <ref type="bibr" target="#b58">[59]</ref>. Iris database contains three classes of samples in four dimensions with 50 samples in each class. Ionosphere database contains two classes of samples in 34 dimen-sions with for each class 225 and 126 samples. Fig. <ref type="figure" target="#fig_5">7</ref>(a) presents a pairwise feature projection of the Iris database. Due to the high dimensionally of Ionosphere, only few relevant feature pairs projections are shown. With such real-world databases, some noise is present and data smoothing is, therefore, of interest. Let be a graph defined over the data. Let be a mapping from the vertices of to the elements of the database ( for Iris and for Ionosphere). We consider a complete graph and regularization is performed with and after iterations. Fig. <ref type="figure" target="#fig_5">7</ref>(b) presents the regularization result on original Iris data depicted in Fig. <ref type="figure" target="#fig_5">7</ref>(a). Fig. <ref type="figure" target="#fig_5">7(d</ref>) presents the regularization result on original Ionosphere data depicted in Fig. <ref type="figure" target="#fig_5">7(c</ref>). One can see the benefits of the regularization: input points which belong to the same class tend to be closer than in the original database. Therefore, this is an efficient method to map input points into a regularized space where clusters are more easily separable: the submanifold where the data lies has been recovered. This effect is illustrated by the results obtained with a standard -means classification  on the original and the regularized versions: the processing enables to increase the recognition rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>We proposed a general discrete framework for regularizing real-valued or vector-valued functions on weighted graphs of ar-bitrary topology. The regularization, based on the -Laplace operator, leads to a family of nonlinear iterative filters. This family includes the TV digital filter, the nonlocal means filter and the bilateral filter, widely used in image processing. Also, the family is linked to spectral graph filtering and is the discrete analogue of recent continuous nonlocal regularizations.</p><p>The choice of the graph topology and the choice of the weight function enable one to regularize any discrete data set or any function on it. Indeed, the data can be structured by neighborhood graphs weighted by functions depending on data features. This can be applied in the contexts of image smoothing, denoising or simplification. We also show that mesh smoothing and denoising can be performed by the same filtering process. Similarly, manifolds can be processed by the same means to recover a noiseless submanifold from a noisy manifold.</p><p>Abderrahim Elmoataz is a full-time Professor of computer science at the Computer Science Department, Université de Caen Basse-Normandie, France. His research concerns graph-based and discrete variational methods for image and data processing.</p><p>Olivier Lezoray received the M.S. and doctoral degrees, both in computer science, from the Université de Caen Basse-Normandie, France, respectively, in 1996 and 2000.</p><p>From 1999 to 2000, he was an Assistant Professor with the Computer Science Department, Université de Caen Basse-Normandie. Since 2000, he has been an Associate Professor with the Cherbourg Institute of Technology in the Communications, Networks, and Services Department. His research concerns color image segmentation and filtering (graph-based variational and morphological methods) and machine learning techniques for image mining (neural networks and support vector machines).</p><p>Sébastien Bougleux received the M.S. degree in artificial intelligence and algorithmic and the Ph.D. degree in computer science from the Université de Caen Basse-Normandie, France, in 2002 and 2007, respectively.</p><p>He is currently a postdoctoral research fellow in image processing at the Université de Paris-Dauphine, France. His research interests include computational geometry, perceptual grouping, pattern recognition, and graph-based data processing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Scalar image simplification on a gray level image with different parameters values of p, and different weight functions in local or nonlocal configurations.First row presents the original image and the gradient in different configurations; following rows present simplification results where each row corresponds to a value of p (see text for more details).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc>presents several results of image denoising on an original image [Fig. 2(a)] corrupted by Gaussian noise [ , PSNR between original and corrupted images is 85.04 dB, Fig. 2(b)]. Results are shown at convergence. Fig. 2(c), (f), and (i) presents results of a local processing, for , and , on a 8-adjacency grid graph with edges weighted by and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Image denoising illustration on an original color image [Fig. 2(a)] corrupted by Gaussian noise [Fig. 2(b) with = 15, PSNR between original and corrupted images is 85.04 dB]. Results are provided for different values of p for local [Fig. 2(c), (f), and (i) with w = g and a 3 2 3 neighborhood] and nonlocal processing [Fig. 2(d), (g), and (j) for w = g , Fig. 2(e), (h), and (k) for w = g , both with a 11 2 11 neighborhood and 5 2 5 patch]. (a) Original. (b) Corrupted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Image simplification illustration. From an original image, one computes a presegmentation and the associated color median image (images in first row). Regularization and decimation are applied on the RAG of the presegmentation and simplified region maps and color median images are obtained for different values of and p (following rows).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Nonlocal manifold regularization (p = 2) for different values of . The original manifold is the digit 0 from the USPS handwritten digit database. See text for details. (a) Original USPS handwritten digit 0 database. (b) Nonlocal regularization with = 0:01. (c) Nonlocal regularization with = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Nonlocal data base regularization (p = 2, = 0:01, t = 10) with recognition rates obtained with a k-means (averaged over 50 runs). (a) Original Iris database (recognition rate: 85.3%). (b) Regularized Iris database with w = g (Recognition rate: 95.3%). (c) Original Ionosphere database (recognition rate: 71.8%). (d) Regularized Ionosphere database with w = g (recognition rate: 75.4%).</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank the reviewers for their valuable comments and suggestions that improved the quality of the paper. They would also like to thank V. T. Ta for providing the results on manifold and data smoothing.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A review of image denoising algorithms, with a new one</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Model. Simul</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="490" to="530" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Image Processing and Analysis-Variational, PDE, Wavelets, and Stochastic Methods</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>SIAM</publisher>
			<pubPlace>Philadelphia, PA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Total variation and level set methods in image science</title>
		<author>
			<persName><forename type="first">Y.-H</forename><forename type="middle">R</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Numer</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="509" to="573" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Axioms and fundamental equations of image processing</title>
		<author>
			<persName><forename type="first">L</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Guichard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-L</forename><surname>Lions</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Arch. Rational Mech. Anal</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="199" to="257" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Geometric signal processing on polygonal meshes</title>
		<author>
			<persName><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>presented at the Eurographics, State of the Art Rep</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mesh regularization and adaptive smoothing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ohtake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Belyaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bogaeski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput.-Aided Design</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="789" to="800" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Anisotropic feature-preserving denoising of height fields and bivariate data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Desbrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schröder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Graph. Interface</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Anisotropic diffusion of surfaces and functions on surfaces</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="32" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Anisotropic filtering of non-linear surface features</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hildebrandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Polthier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="391" to="400" />
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
	<note>Eurographics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generalized surface flows for mesh processing</title>
		<author>
			<persName><forename type="first">I</forename><surname>Eckstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Pons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C J</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Desbrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics Symp. Geometry Processing</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A signal processing approach to fair surface design</title>
		<author>
			<persName><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH</title>
		<meeting>SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="351" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Implicit fairing of irregular meshes using diffusion and curvature flow</title>
		<author>
			<persName><forename type="first">M</forename><surname>Desbrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schröder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Barr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIG-GRAPH</title>
		<meeting>SIG-GRAPH</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="317" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Discrete surface modelling using partial differential equations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Bajaj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Aided Geom. Design</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="145" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Computing discrete minimal surfaces and their conjugates</title>
		<author>
			<persName><forename type="first">U</forename><surname>Pinkall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Polthier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Exp. Math</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps for dimensionality reduction and data representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1373" to="1396" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Data fusion and multicue data matching by diffusion maps</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lafon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Coifman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1784" to="1797" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Diffusion maps and coarse-graining: A unified framework for dimensionality reduction, graph partitioning and data set parameterization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lafon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1393" to="1403" />
			<date type="published" when="2006-09">Sep. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A tutorial on spectral clustering</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statist. Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="395" to="416" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000-08">Aug. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Regularization and semi-supervised learning on large graphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Matveeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Computational Learning Theory</title>
		<meeting>Conf. Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="624" to="638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A regularization framework for learning from graph data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML Workshop on Statistical Relational Learning and Its Connections to Other Fields</title>
		<meeting>ICML Workshop on Statistical Relational Learning and Its Connections to Other Fields</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="132" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Kernels and regularization on graphs</title>
	</analytic>
	<monogr>
		<title level="m">Proc. 16th Annu. Conf. Computational Learning Theory</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Kondor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Warmuth</surname></persName>
		</editor>
		<meeting>16th Annu. Conf. Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="144" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Manifold models for signals and images</title>
		<author>
			<persName><forename type="first">G</forename><surname>Peyré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ceremade</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>to be published</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A general framework for adaptive regularization based on diffusion processes on graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maggioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Coifman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<pubPlace>New Haven, CT</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Yale Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Manifold denoising</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deblurring and denoising of images by nonlocal functionals</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kindermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep., Univ. California</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Los Angeles</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Nonlocal linear image regularization and supervised segmentation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gilboa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Multiscale Model. Simul</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="595" to="630" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Nonlocal operators with applications to image processing</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gilboa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<idno>07-23</idno>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Univ. California, Los Angeles</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. CAM Report</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Graph regularization for color image processing</title>
		<author>
			<persName><forename type="first">O</forename><surname>Lezoray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elmoataz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bougleux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Understand</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="38" to="55" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Discrete regularization on weighted graphs for image and mesh filtering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bougleux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Melkemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elmoataz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Scale Space and Variational Methods in Computer Vision</title>
		<meeting>Int. Conf. Scale Space and Variational Methods in Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4485</biblScope>
			<biblScope unit="page" from="128" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Parameterless discrete regularization on graphs for color image filtering</title>
		<author>
			<persName><forename type="first">O</forename><surname>Lezoray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bougleux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elmoataz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>presented at the ICIAR</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Graphs regularization for data sets and images: Filtering and semi-supervised classification</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lezoray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elmoataz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PASCAL Workshop: Learning from and with graphs, 6th IAPR-TC-15 Workshop on Graph based Representations in Pattern Recognition</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Nonlocal convex functionals for image regularization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gilboa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Darbon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CAM Rep. 06-57</title>
		<meeting><address><addrLine>Los Angeles</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>Univ. California</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Regularization on discrete spaces</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 27th DAGM Symp</title>
		<meeting>27th DAGM Symp</meeting>
		<imprint>
			<date type="published" when="2005-08">Aug. 2005</date>
			<biblScope unit="volume">3663</biblScope>
			<biblScope unit="page" from="361" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Discrete regularization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semi-Supervised Learning</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Zien</surname></persName>
		</editor>
		<meeting><address><addrLine>MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="221" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Image smoothing and segmentation by graph regularization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bougleux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elmoataz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. Visual Computing</title>
		<meeting>Int. Symp. Visual Computing</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3656</biblScope>
			<biblScope unit="page" from="745" to="752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Difference equations on weighted graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bensoussan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Menaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Convex Anal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="44" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Wave equations for graphs and the edgebased laplacian</title>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Tillich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pacific J. Math</title>
		<imprint>
			<biblScope unit="volume">216</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="229" to="266" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Convergece of graph laplacians on random neighborhood graphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Audibert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1325" to="1370" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Spectral graph theory</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CBMS Regional Conf</title>
		<meeting>CBMS Regional Conf</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="1" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Digitized PDE method for data restoration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">in In Analytical-Computational methods in Applied Mathematics</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">G A</forename><surname>Anastassiou</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="751" to="771" />
			<date type="published" when="2000">2000</date>
			<publisher>Chapman &amp; Hall/CRC</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The digital TV filter and nonlinear denoising</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="231" to="241" />
			<date type="published" when="2001-02">Feb. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Fixed Points, Algorithms and Applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Karamadian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977">1977</date>
			<publisher>Academic</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Anisotropic Diffusion in Image Processing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Teubner-Verlag</publisher>
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">in Handbook of Discrete and Computational Geometry</title>
		<author>
			<persName><forename type="first">J</forename><surname>O'rourke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Toussaint</surname></persName>
		</author>
		<editor>J. Goodman and J. O&apos;Rourke</editor>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Chapman &amp; Hall/CRC</publisher>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="1135" to="1162" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Pattern recognition</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Geometric diffusions as a tool for harmonic analysis and structure definition of data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lafon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maggioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Warner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Nat. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">21</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Bilateral filtering for gray and color images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manduchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Int. Conf. Computer Vision</title>
		<meeting>6th Int. Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="839" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A fundamental relationship between bilateral filtering, adaptive smoothing, and the nonlinear diffusion equation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Barash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="844" to="847" />
			<date type="published" when="2002-06">Jun. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Bilateral mesh denoising</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fleishman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Drori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="950" to="953" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Non-iterative, feature-preserving mesh smoothing</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Desbrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="943" to="949" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Smoothing by example: Mesh denoising by averaging with similarity-based weights</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yoshizawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Belyaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Seidel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Shape Modeling and Applications</title>
		<meeting>International Conference on Shape Modeling and Applications</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="38" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Nonlocal anisotropic discrete regularization for image, data filtering and clustering</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bougleux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elmoataz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lezoray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep., Univ. Caen</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>Caen, France</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Vector-valued image regularization with PDEs: A common framework for different applications</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tschumperlé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deriche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="506" to="517" />
			<date type="published" when="2005-04">Apr. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Coherence-enhancing diffusion of colour images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="201" to="212" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A new method of morphological hierarchical segmentation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Meurie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lezoray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Information Engineering. Piscataway</title>
		<meeting><address><addrLine>NJ</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Multi-scale image segmentation in a hierarchy of partitions</title>
		<author>
			<persName><forename type="first">O</forename><surname>Lezoray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meurie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Belhomme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elmoataz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>presented at the EU-SIPCO</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Fast multiscale image segmentation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Sharon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="2070" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Scale-sets image analysis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Guigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Cocquerez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Men</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="289" to="317" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">UCI Repository of Machine Learning Databases Dept</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hettich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Merz</surname></persName>
		</author>
		<ptr target="http://www.ics.uci.edu/~mlearn/MLReposi-tory.html" />
	</analytic>
	<monogr>
		<title level="j">Inf. Comput. Sci., Univ. California</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<pubPlace>Irvine</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
