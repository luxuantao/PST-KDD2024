<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Co-training Improves Prompt-based Learning for Large Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-02-02">2 Feb 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hunter</forename><surname>Lang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mit</forename><surname>Csail</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Monica</forename><surname>Agrawal</surname></persName>
							<email>magrawal@mit.edu</email>
						</author>
						<author>
							<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
							<email>yoonkim@mit.edu</email>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Sontag</surname></persName>
							<email>dsontag@mit.edu</email>
						</author>
						<title level="a" type="main">Co-training Improves Prompt-based Learning for Large Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-02-02">2 Feb 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2202.00828v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We demonstrate that co-training <ref type="bibr" target="#b1">(Blum &amp; Mitchell, 1998)</ref> can improve the performance of promptbased learning by using unlabeled data. While prompting has emerged as a promising paradigm for few-shot and zero-shot learning, it is often brittle and requires much larger models compared to the standard supervised setup. We find that cotraining makes it possible to improve the original prompt model and at the same time learn a smaller, downstream task-specific model. In the case where we only have partial access to a prompt model (e.g., output probabilities from GPT-3 (Brown et al., 2020)) we learn a calibration model over the prompt outputs. When we have full access to the prompt model's gradients but full finetuning remains prohibitively expensive (e.g., T0 (Sanh et al., 2022)), we learn a set of soft prompt continuous vectors to iteratively update the prompt model. We find that models trained in this manner can significantly improve performance on challenging datasets where there is currently a large gap between prompt-based learning and fully-supervised models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Prompt-based learning, in which a pretrained language model is adapted to various tasks by priming on natural language prompts, has emerged as a promising framework for few-shot and zero-shot learning <ref type="bibr" target="#b2">(Brown et al., 2020;</ref><ref type="bibr" target="#b19">Liu et al., 2021;</ref><ref type="bibr" target="#b38">Wei et al., 2021;</ref><ref type="bibr" target="#b28">Sanh et al., 2022)</ref>. While intriguing, these methods can be sensitive to trivial cosmetic artifacts, including variations in prompt wording and the ordering of examples <ref type="bibr" target="#b20">(Lu et al., 2021;</ref><ref type="bibr" target="#b41">Zhao et al., 2021;</ref><ref type="bibr" target="#b14">Kumar &amp; Talukdar, 2021)</ref>. Further, the models used in prompt-based learning (e.g., <ref type="bibr">T0)</ref> are much larger than those typically used for standard fine-tuning. These factors make prompt-based learning difficult to use and deploy in practice.</p><p>Given a small amount of labeled data, one could evaluate the performance of each prompt and re-calibrate the prompt outputs to improve performance. However, (i) this reliance on labeled data goes against the goal of few-shot learning, and (ii) even with oracle calibration, some prompts have sub-par accuracy. Recently, to address issue (i), <ref type="bibr" target="#b41">Zhao et al. (2021)</ref> developed a data-free calibration method that can dramatically improve the accuracy of few-shot prompts for GPT-3. We build on their work by showing how to use unlabeled data to further improve performance.</p><p>To leverage unlabeled data, we use co-training <ref type="bibr" target="#b1">(Blum &amp; Mitchell, 1998)</ref>, which operates on two views of each data point X: φ 0 (X) and φ 1 (X). For example, in a clinical diagnosis system, φ 0 (X) could be laboratory test results and φ 1 (X) an X-ray image. A pair of models (h 0 and h 1 respectively) takes turns labeling a large unlabeled training set, and each model is trained on the confident pseudo-labels from the other. Model h 0 only uses φ 0 (X), and model h 1 uses φ 1 (X). By using complementary information in the views φ 0 , φ 1 and the different inductive biases from models h 0 , h 1 , co-training allows each model to learn from the other without the need for labeled data. The initial signal to start the co-training process is provided by a "guess" at a model h 0 . To combine co-training and prompt-based learning, we use outputs from a large prompt-based model as φ 0 (X) and the pre-trained representation from a much smaller language model (e.g., DeBERTa <ref type="bibr" target="#b9">(He et al., 2021)</ref>) as φ 1 (X). We specify the models h 0 and h 1 based on whether we have partial access to the prompt model (querying GPT-3) or full access (locally training T0).</p><p>In partial access, we only have access to the large model's output probabilities. In this case, we use unlabeled data to learn a model h 0 that both calibrates individual prompts and ensembles multiple prompts. We refer to this as the label model. We use Calibrate-Before-Use <ref type="bibr" target="#b41">(Zhao et al., 2021)</ref> to initialize the calibration parameters of this model for each prompt, and we initialize the ensembling parameters to approximate majority vote. We then refine this initial guess for h 0 with co-training. We use the pre-trained representation from DeBERTa <ref type="bibr" target="#b9">(He et al., 2021)</ref> for φ 1 (X) and train the last few layers of that model as h 1 . The only labeled data used is the set of k examples used in the input prompts. Figure <ref type="figure">1</ref> (left) shows the co-training process in the partial access setting.</p><p>We also study a full access setting using T0 <ref type="bibr" target="#b28">(Sanh et al., 2022)</ref> instead of GPT-3, so we can introspect the large prompt model. We derive the view φ 0 (X) and the model h 0 from T0. However, instead of fully fine-tuning T0 during co-training, we focus on soft prompt tuning, which trains several orders-of-magnitude fewer parameters while attaining similar performance <ref type="bibr" target="#b18">(Li &amp; Liang, 2021;</ref><ref type="bibr" target="#b17">Lester et al., 2021)</ref>. The parameter space for model h 0 is the set of soft prompts, which are matrices R L×d , where L is a sequence Figure <ref type="figure">1</ref>: The setup for our two applications of co-training to prompting for a binary entailment classification dataset (RTE). Parameters in blue are trainable; models in gray are fixed. Left: training a "label model" for post-hoc calibration and ensembling of multiple prompts. Here the prompts and the model (GPT-3) are fixed, and we co-train the calibration / ensembling parameters with the task-specific model (e.g., DeBERTa). Right: training a soft prompt. Here the input is encoded as a hard prompt and the embedding matrix of the input sequence is obtained. A L × d matrix of trainable parameters (the "soft prompt") is prepended to this embedding, and the combined embedding sequence is passed through T0 to get output predictions. We co-train the soft prompt with the view 1 model (e.g., DeBERTa). length hyperparameter and is d the dimension of the pretrained T0 embeddings. Each row of the soft prompt mimics the embedding of a token, but the soft prompt need not correspond to the embedding of any actual token sequence. This matrix is prepended to the input embedding and the output of h 0 is computed with the frozen T0 model. The initial guess at h 0 (i.e., the initial soft prompt vector for use in co-training) is the repeated embedding of the [PAD] token. Since T0 was trained to perform well at zero-shot learning with prompts, this provides a good initial hypothesis. We co-train this model with a pre-trained DeBERTa representation as φ 1 (X) and the last few layers of DeBERTa as h 1 . This is is shown in Figure <ref type="figure">1</ref>, right.</p><p>We apply our approach to standard few-shot and zeroshot benchmarks and find that (i) iteratively co-training both models using unlabeled data consistently improves performance, (ii) pseudo-labels from a prompted model are an effective signal for fine-tuning smaller task-specific models, and (iii) this approach can significantly improve results on datasets previously considered difficult for prompt-based learning. We conclude with a brief analysis of success and failure cases and describe high-level criteria required for our method to work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Prompting and prompt tuning. <ref type="bibr" target="#b20">Lu et al. (2021)</ref> find optimal orderings of prompt examples based on an artificially constructed development set. Given the variance in performance across different prompts, others have focused on engineering suitable prompts, manually or otherwise <ref type="bibr" target="#b19">(Liu et al., 2021)</ref>. <ref type="bibr" target="#b11">Jiang et al. (2020)</ref>, <ref type="bibr" target="#b32">Shin et al. (2020), and</ref><ref type="bibr" target="#b8">Gao et al. (2021)</ref> use data-driven techniques and language models to automatically generate candidate prompts. Rather than being constrained to human-readable prompts, <ref type="bibr" target="#b18">Li &amp; Liang (2021)</ref> and <ref type="bibr" target="#b17">Lester et al. (2021)</ref> instead learn a continuous soft task-specific "prompt" to condition language models. While effective, these methods typically require nontrivial amounts of labeled data.</p><p>Another line of work uses the outputs from a prompted language model as weak labels, as we do in this work. <ref type="bibr" target="#b36">Wang et al. (2021)</ref> propose to train smaller models on labels from GPT-3 to reduce annotation cost, but they train from individual, uncalibrated prompts and do not attempt to refine the prompt model alongside the smaller model. <ref type="bibr">Schick &amp; Schütze (2021)</ref> fine-tune a separate RoBERTa model for each prompt using a small amount of labeled data. They next aggregate the outputs of these individual fine-tuned models as a soft pseudo-label and train a final model to match the soft aggregation. In contrast, we train a single BERT-style model on the ensembled prompt output without any additional labeled data. We use this model to refine the ensemble parameters <ref type="bibr">(and vice-versa)</ref>. In our approach we only use prompt outputs as training signal, and we consider different types of prompts (open-ended instead of cloze).</p><p>Self-training for few-shot text classification. Our work relies on access to a large amount of unlabeled data to iteratively grow a confidently-labeled training set for each model. Similarly, self-training first trains a model on a small set of initial data, uses the trained model to produce pseudo-labels on a set of unlabeled data, and then iteratively includes the confidently pseudo-labeled data as new training labels <ref type="bibr" target="#b31">(Scudder, 1965)</ref>. In the context of few-shot text classification, <ref type="bibr" target="#b22">Mukherjee &amp; Awadallah (2020)</ref> develop an uncertainty-aware technique for choosing which data points to include, which requires a small amount of labeled data. <ref type="bibr" target="#b12">Karamanolakis et al. (2019</ref><ref type="bibr" target="#b13">Karamanolakis et al. ( , 2021) )</ref> employ self-training and iterative co-training with weak supervision as the initial label signal, and they similarly use a neural network with pretrained embeddings as a downstream model. However, they explore hand-written or keyword-based rules as weak supervision, in contrast to the present work, where we derive our weak signals from prompted models. The parameterization of h 0 in our partial access setting is similar to the weighting they use to combine rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Co-training.</head><p>Co-training dates back to <ref type="bibr" target="#b1">Blum &amp; Mitchell (1998)</ref>, who assumed that φ 0 (X) and φ 1 (X) are two distinct views and conditionally independent given the true label. Under this strict condition, they proved that the algorithm finds a good classifier after just one step. Many subsequent analyses (e.g., <ref type="bibr" target="#b5">Dasgupta et al., 2002;</ref><ref type="bibr" target="#b0">Balcan et al., 2005)</ref> relax this condition, showing that views can be dependent or even identical as long as certain relationships hold between the models being trained (essentially, they are "different enough"). In a similar vein, <ref type="bibr" target="#b37">Wei et al. (2020)</ref> give a theoretical explanation of why (and when) models can learn to be more accurate than the pseudo-labels used to train them. We take implicit advantage of these results in our work. The views we use are highly dependent, and yet the models we train are often able to outperform the pseudo-labels we used to train them in each co-training iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Co-training with prompting</head><p>The skeleton of our approach is shown in Algorithm 1 (full detail is provided in Algorithms 4 and 5 in the supplement). First, a hypothesis h 0 over view φ 0 is initialized such that its initial predictions are reasonable. (We discuss initialization in depth in the following sections.) Next, we obtain the confidently labeled training data L 0 0 , which is a subset of the unlabeled data points, together with pseudo-labels for those points from h 0 . In iteration t, we select a β + tβ fraction of the data. (We discuss techniques for selection of confident data in Section 4 and the choice of β and β in Section 5.) These confidently-labeled points are then used to train a model h 1 on view φ 1 , and h 1 's confidentlylabeled data is extracted as L 0 1 . This is used to train a new h 0 , and the process continues for T steps. Train performs standard supervised training on the pseudo-labels for that iteration. In this section, we give details for how to construct the views φ 0 and φ 1 , the hypothesis classes we use for the model h 0 , and the initialization schemes for h 0 in both the partial access and full access settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Partial access: co-training a label model</head><p>In the usual few-shot setting with prompting, k labeled examples ({x i , y i }) k i=1 are converted into a single natural language prompt following a prompt template. We call this prompt k-shot, since it uses k labeled examples. Instead of using one k-shot prompt, we use k one-shot prompts, only including one example in the template at a time. This gives us k outputs. Separating out the signal from each labeled</p><formula xml:id="formula_0">Algorithm 1 Co-training algorithm input U = {x n } U n=1 unlabeled examples input {(x j , y j )} k j=1 labeled examples (optional) input initial coverage β, coverage increase β h 0 ← InitClassifier(φ 0 ) for t in {0, . . . , T − 1} do β ← β + tβ // GetConfData * defined in Algorithms 2, 3 L t 0 ← GetConfData * U; h 0 , φ 0 , β h 1 ← Train(φ 1 , L t 0 ) L t 1 ← GetConfData * U; h 1 , φ 1 , β h 0 ← Train(φ 0 , L t 1 ) end for return (h 0 , h 1 )</formula><p>example in this way allows us to combine the examples more effectively than the one k-shot prompt model.</p><formula xml:id="formula_1">View. Let φ (i) 0 (x) ∈ R |V |</formula><p>be the vector of probabilities output by GPT-3 on input x formatted in a one-shot prompt with labeled example (x i , y i ). Here V is a subset of the full token vocabulary-the verbalizer tokens-and consists of the "label tokens" for the prompt as well as other tokens related to the label. For example, in sentiment analysis, if x 1 is "this movie was great!", φ and V might include the label tokens Positive / Negative and related tokens such as uncased label tokens or synonyms. <ref type="foot" target="#foot_0">1</ref> To select the verbalizer tokens in a taskagnostic way, we obtain the top 10 predictions for GPT-3 on each prompt, sort tokens by the total probability assigned to them on the unlabeled training set, and choose the top 25%. This ensures that other frequent tokens appear in the feature set for φ 0 . For example, Date appears for TREC question classification even though the closest true label category is Number. The label model automatically learns this association during the co-training iterations. Henceforth we assume that V is ordered and the first elements of V correspond to the label tokens. By concatenating φ (i) 0 (x) for each of the k labeled examples, we obtain a matrix φ 0 (x) ∈ R k×|V | , the first view for co-training. The second view, φ 1 (x), is the frozen representation of a pretrained model like DeBERTa <ref type="bibr" target="#b9">(He et al., 2021)</ref>. In our experiments, we use the representation in the penultimate layer as φ 1 (x), and the hypothesis class over this view is the last layer and the linear classifier.</p><p>Hypothesis class. This leaves the hypothesis class for model h 0 : how do we combine k prompt signals into one pseudo-label? Probabilities from these models are often miscalibrated <ref type="bibr" target="#b41">(Zhao et al., 2021)</ref>, and thus averaging or majority voting does not yield good results. Instead, we propose to learn a label model that scales each prompt vector φ (i) 0 (x) by a prompt-specific calibration matrix W (i)  before averaging. The combined architecture for this model is given by h 0 (x; W, α):</p><formula xml:id="formula_2">2 l i = ReLU W (i) φ (i) 0 (x) ; h 0 (x; W, α) = softmax k i=1 α i l i ,<label>(1)</label></formula><p>where α ∈ R k is a vector of weights for ensembling the scaled prompt outputs. The ReLU(•) allows the model to easily ignore particular prompt/label combinations. For example, if prompt j has very poor precision when it outputs label z, setting W (j) zz to be negative causes l jz to be 0. Note that we directly calibrate probabilities rather than log-probabilities, following <ref type="bibr" target="#b41">Zhao et al. (2021)</ref> </p><formula xml:id="formula_3">(i.e., φ (i) 0 ∈ [0, 1] |V | and φ (i) 0 1 = 1).</formula><p>In each iteration of co-training, we train this model using the standard crossentropy loss on the confident data for that iteration.</p><p>Initialization. The calibration matrices W (i) are initialized using Calibrate-Before-Use (CBU) <ref type="bibr" target="#b41">(Zhao et al., 2021)</ref>, which first computes the probability vector φ (i) 0 (x cf ) on content-free inputs x cf (e.g., N/A or the empty string), and then uses these as a scaling factor:</p><formula xml:id="formula_4">W (i) = Diag 1 φ (i) 0 (x cf )</formula><p>.</p><p>This initialization scheme ensures that the scaled prompt outputs are neutral on truly neutral inputs, improving calibration. We also set α i = 1 for each i ∈ {1, . . . , k} to initially weight each prompt equally in the ensemble. When V consists of more than just label tokens, we initialize W (i)  in blocks: we use CBU for the label tokens, and initialize the rest of W to be 0. That is, for an l-way classification task, where W (i) ∈ R l×|V | , we initialize the first l columns of W (i) using CBU (since we assumed V was ordered, these columns correspond to the label tokens) and set the rest to 0. Hence only the label tokens (e.g., Negative, Positive) are used at initialization, but subsequent iterations of cotraining can use nonzero weights on the extra tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Full access: co-training a soft prompt</head><p>In this setting, our prompt model is the T0 model <ref type="bibr" target="#b28">(Sanh et al., 2022)</ref>, which achieves zero-shot generalization by fine-tuning T5 <ref type="bibr" target="#b25">(Raffel et al., 2020)</ref> on multiple tasks whose labeled examples have been transformed into natural language question-answer pairs. Since T0 is publicly available and smaller than GPT-3, we can introspect the model and compute gradients in this case.</p><p>View. We set φ 0 (X) to the initial word embeddings of T0 and leave φ 1 (X) and h 1 unchanged (i.e., φ 1 is the penultimate layer of a pretrained DeBERTa representation).</p><p>Hypothesis class. The model h 0 is parameterized by a continuous soft prompt <ref type="bibr" target="#b18">(Li &amp; Liang, 2021;</ref><ref type="bibr" target="#b17">Lester et al., 2021)</ref>. Concretely, letting d = 2048 be the dimension of the T0 word embeddings, a soft prompt is a matrix of parameters P ∈ R L×d , where L is a sequence length hyperparameter. Each row of the soft prompt acts like the embedding of a "token" (but needn't correspond to the embedding of any real token-i.e., there are no constraints on P ). The hypothesis h 0 (x; P ) is thus given by prepending the soft prompt to the input word embedding sequence and using the concatenation (P ; φ 0 (X)) as input to T 0. The subsequent T0 layers are frozen and not updated during training. Given enough labeled data, soft prompt tuning can match the performance of full-fine-tuning with far fewer trainable parameters <ref type="bibr" target="#b17">(Lester et al., 2021;</ref><ref type="bibr" target="#b15">Le Scao &amp; Rush, 2021</ref>).<ref type="foot" target="#foot_2">3</ref> </p><p>Initialization. T0 is specifically trained to perform well at zero-shot tasks with a variety of hard prompts, so using a hard prompt out-of-the-box gives good initial performance. Hence, to initialize a soft prompt hypothesis, we encode the input using a hard prompt and then set the soft prompt to be the repeated embedding of the tokenizer's padding token.</p><p>Using the RTE dataset <ref type="bibr" target="#b4">(Dagan et al., 2005)</ref> as a running example, we first encode the input using a hard prompt, where each input example x is formatted as:</p><p>{{x.premise}} Question: {{x.hypothesis}} True or False?</p><p>We then set h 0 to be the repeated embedding of the T0 padding token, i.e., at initialization the T0 model sees: This combination of hard prompt encoding with soft prompting differs from the usual soft prompting setup <ref type="bibr" target="#b18">(Li &amp; Liang, 2021;</ref><ref type="bibr" target="#b17">Lester et al., 2021)</ref>. We discuss this issue in more depth in Section B.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Selecting confident data</head><p>The key step in co-training is selecting confidently-labeled data for use in the next training iteration. The literature on co-training has identified a large number of methods for performing this data selection (GetConfData, in Algorithm 1). We consider two simple approaches in this work: model confidence and cut statistic. In both cases, we specify an initial coverage fraction β and a coverage increase fraction β . Given U unlabeled examples, the amount of pseudo-labeled data in round t ≥ 0 is therefore U (β + tβ ).</p><p>Model confidence. For model confidence, we sort every example by the scores output by each model and select the top β + tβ fraction in iteration t. While simple, this can result in very imbalanced updates to the pseudo-labeled dataset if the model is only confident for one label or if one label is inherently more noisy than the others. If additional knowledge regarding the marginal label distribution is available (e.g., approximate label balance or a constraint on the minimum label frequency), we can imbue this knowledge into the data selection process by grouping examples by their predicted label and then performing the sort-and-select procedure for each label separately. Knowledge of the approximate label balance is a standard assumption in weak supervision (e.g., <ref type="bibr" target="#b7">Fu et al., 2020)</ref>, but we make a much weaker assumption when using the model confidence ranking: we assume we know a lower bound γ such that for all labels y, P[Y = y] ≥ γ. We set γ = 0.01, i.e., that every class accounts for at least 1% of the data. The detailed procedure for confident data selection using model confidence is shown in Algorithm 2 (supplement).</p><p>Cut statistic. The cut statistic is a ranking heuristic that uses the view geometry more than the model confidence approach <ref type="bibr" target="#b21">(Muhlenbach et al., 2004;</ref><ref type="bibr" target="#b40">Zhang &amp; Zhou, 2011)</ref>. Suppose we want to select data confidently labeled by a model over view φ(X) (we omit the subscript i for clearer notation). First, we form a graph G = (V, E) with one vertex for each unlabeled training example and edges connecting vertices who are K-nearest neighbors in φ(X) (or a representation related to φ(X)-for example, for T0 we can use a contextual representation from inside the model instead of the uncontextual embeddings φ 0 ). Let Ŷ (X) = argmax h(φ(X)) be the hard pseudo-label assigned to input X by model h. We say an edge</p><formula xml:id="formula_5">(x u , x v ) is cut if Ŷ (x u ) = Ŷ (x v ).</formula><p>Intuitively, we can feel confident about examples that have few cut edges, since they have the same label as most of their neighbors. Regions of G with high noise are less likely to be correctly labeled. The cut statistic heuristically quantifies this idea to rank examples.</p><p>Suppose (as a null hypothesis) that the labels Ŷ were sampled i.i.d. from the marginal distribution P[ Ŷ = y] (i.e., independently of X). For vertices u and v corresponding to examples x u , x v , define</p><formula xml:id="formula_6">I uv = I[ Ŷ (x u ) = Ŷ (x v )].</formula><p>Consider the test statistic: J u = v∈N (u) w uv I uv , where w uv = 1/(1 + φ(x u ) − φ(x v ) 2 ) are edge weights that decrease as the distance between u and v increases, and N (u) are the neighbors of u. The mean of J u under the null hypothesis is: µ = (1 − P[ Ŷ (x u )]) v∈N (u) w uv , and the variance is:</p><formula xml:id="formula_7">σ 2 = P[ Ŷ (x u )](1 − P[ Ŷ (x u )]) v∈N (u) w 2</formula><p>uv . Following <ref type="bibr" target="#b40">Zhang &amp; Zhou (2011)</ref>, we approximate the distribution of J with a normal distribution of mean µ and variance σ 2 . Then we can rank examples x u by the leftsided tail probability for J u (lower is better). If J u is much smaller than expected, then the total cut edge weight is much smaller than expected under the null hypothesis. To select confident data, we sort examples by J u and choose the top β + tβ fraction in iteration t. The detailed procedure for confident data selection using the cut statistic is shown in Algorithm 3 (supplement).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Relabeling.</head><p>Pseudo-labels from previous iterations can either be re-used or thrown out. If the initial hypothesis has high precision but low coverage, it is typically preferable to re-use the pseudo-labels from previous iterations, since as coverage increases the quality of the pseudo-labels is likely to go down. On the other hand, if the models being trained are capable of correcting incorrect pseudo-labels, it is preferable to relabel, since this can improve the quality of the training data in each iteration. We exclusively use the latter, since we found that the pseudo-label accuracy on the covered subset of data often increased with more iterations. The original co-training algorithm <ref type="bibr" target="#b1">(Blum &amp; Mitchell, 1998)</ref> builds L cumulatively, but subsequent co-training procedures also use relabeling <ref type="bibr" target="#b40">(Zhang &amp; Zhou, 2011)</ref>. We discuss relabeling further in Section A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>Datasets. We investigate the benefit of co-training on several standard natural language benchmarks, focusing on datasets with a large gap between the best prompt-based methods and fully-supervised learning <ref type="bibr">(Wang et al., 2019b,a;</ref><ref type="bibr" target="#b2">Brown et al., 2020)</ref>. We use the RTE <ref type="bibr" target="#b4">(Dagan et al., 2005)</ref>, CB <ref type="bibr" target="#b6">(De Marneffe et al., 2019)</ref>, TREC <ref type="bibr" target="#b33">(Voorhees &amp; Tice, 2000)</ref>, and BoolQ <ref type="bibr" target="#b3">(Clark et al., 2019)</ref> datasets. Full details for these datasets are in Appendix B. In the partial access setting, we do not evaluate on BoolQ due to the large amount of GPT-3 quota required for labeling. In the full access setting, we do not evaluate on TREC as T0 was pretrained on TREC.</p><p>Training methods, partial access. In the few-shot setting we randomly select k = 4 training examples from each dataset until the initial label model assigns every pseudolabel at least γβU times (i.e., we resample prompts until we can initialize the label model in accordance with the constraint that P[Y = y] ≥ γ for all y). While larger k might improve performance, k = 4 gives a good balance between performance and GPT-3 quota usage. (Indeed, with our 4 one-shot prompts, we are able to beat the GPT-3 32shot accuracy on CB).</p><p>In each co-training iteration, we train the label model over view φ 0 using Adam with learning 1e-4, weight decay 5e-3, and batch size 64 for 40 epochs. We train the DeBERTa-large model over φ 1 for 20 epochs using Adam with learning rate 1e-5, weight decay 0.01, batch size 16. All parameters were frozen except the last language model layer, the pooler, and the linear classification layer. In order to avoid indirect label leakage, we did not tune these hyperparameters and instead chose common hyperparameters used for these types of models. For early stopping, each model was evaluated every epoch on a pseudo-labeled validation set and the best model checkpoint was chosen based on balanced accuracy on the pseudo-labels at the end of each round. Using the balanced accuracy (average of the recall for each label) avoids collapsing to the majority class even when the pseudo-labels are relatively imbalanced. This validation set was sampled uniformly from the training set to give a training/validation split of 90%/10%.</p><p>To determine β, β , T for co-training, we performed a light hyperparameter search based on performance on a gold-labeled validation set of 500 examples sampled from the TREC training set. <ref type="foot" target="#foot_4">4</ref> This resulted in the the following values: initial coverage of β = 0.5, per-step coverage increase of β = 0.1, and total co-training steps T = 5. We emphasize that this gold validation set was not used during any co-training iteration (e.g. for model selection, early stopping, learning rate tuning, etc.) We set the minimum label frequency γ = 0.01 and did not tune this value. We used model confidence to add confident data in view 0 and the cut statistic to add confident data in view 1. <ref type="foot" target="#foot_5">5</ref> We used the <ref type="bibr">[CLS]</ref> token embedding in the last layer of DeBERTa for cut statistic nearest neighbors in view 1. We used K = 20 nearest neighbors for the cut statistic and performed no tuning on this value.</p><p>Training methods, full access. In the zero-shot setting, for training the soft prompt over view φ 0 (x) we mainly used the hyperparameters suggested by <ref type="bibr" target="#b17">Lester et al. (2021)</ref>, which were obtained by performing gold soft prompt tuning using T5 on SuperGLUE. We used Adafactor with constant learning rate 0.3, weight decay 1e-5, and batch size 24 for 30000 training steps. For DeBERTa-large, we used the same hyperparameters as in the partial access setting. As in the partial access setting, we used balanced pseudo-label accuracy to select the best model checkpoint at the end of each training round. We used the cut statistic for confident selection in both views, since with T0 we have access to the internal embeddings, unlike with GPT-3. We used the T0 decoder's contextual embedding for the first decoded token to compute nearest neighbors for the view 0 cut statistic. Training details (e.g., β, β , T , etc.) are otherwise exactly the same as in the partial access setting.</p><p>During training, the pseudo-label for each example is first mapped to a token that matches the hard prompt (e.g. 0→True and 1→False for the RTE example above). These token labels are then mapped to embedding indices using the T0 tokenizer, and the soft prompt is trained via regular sequence-to-sequence training with the maximum likelihood objective. This is identical to the soft prompt training technique from <ref type="bibr" target="#b17">Lester et al. (2021)</ref>.</p><p>Caveat. As noted by <ref type="bibr" target="#b23">Perez et al. (2021)</ref>, much current work on prompt-based learning does not constitute "true" few-shot/zero-shot learning as they often implicitly assume access to a small labeled set to select various model configurations (e.g., prompts and hyperparameters). Insofar as we inherit such configurations from existing work, our work is similarly not few-shot/zero-shot in the strictest sense, although we tried to minimize such issues by using exactly the same co-training parameters (β, β , T, γ) and model hyperparameters for all datasets. (We also did not perform an extensive tuning of these parameters.) While we are encouraged by the observation that model configurations seem to work well across diverse datasets, investigating co-training in the context of true few-shot/zero-shot learning <ref type="bibr">(Schick &amp; Schütze, 2021)</ref> is an important avenue for future work.</p><p>Baselines. For baselines we compare against:</p><p>• GPT-3 32-shot: From <ref type="bibr" target="#b2">Brown et al. (2020)</ref>. 32 examples combined in one prompt. Uncalibrated.</p><p>• Calibrate Before Use: Performance of CBU using 4-shot prompts (from <ref type="bibr" target="#b41">(Zhao et al., 2021)</ref>).</p><p>• Prompt-based FT: Our reproduction of the fine-tuning method from <ref type="bibr" target="#b8">(Gao et al., 2021)</ref>, using 2 labels per class.</p><p>• Snorkel on GPT-3 output: Snorkel generative label model, which aggregates over the four GPT-3 1-shot outputs without using any labeled data. <ref type="bibr" target="#b27">(Ratner et al., 2016</ref><ref type="bibr" target="#b26">(Ratner et al., , 2020))</ref>.</p><p>• Snorkel + DeBERTA-large: DeBERTA-large fine-tuned on outputs from Snorkel label model using the same hyperparameters as our co-training methods.</p><p>• Label Model (no co-training): the label model after initialization with (1). The baselines that use (roughly) the same amount of labeled data as our method are shown in the top section of Table <ref type="table">1</ref> and Table <ref type="table" target="#tab_1">2</ref>. The bottom sections contain baselines that use more labeled data, including oracle upper-bounds based on full training data. Training details for the baselines are in Section B.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Results</head><p>Table <ref type="table">1</ref> shows the results for the partial access setting, where we co-train the label model, which calibrates and combines multiple GPT-3 outputs, with a smaller pretrained model (DeBERTa-large). For view 0, our co-trained label model (Label Model + co-training) improves over the initial label model (Label Model before co-training) and the average performance of GPT-3 4-shot before (GPT-3 4-shot) and after (Calibrate Before Use) calibration. It also improves over Snorkel on GPT-3, which, like our method, uses unlabeled data to combine the outputs of our four 1-shot prompts. For CB, the co-trained label model outperforms GPT-3 32-shot despite only using 4 labeled examples. This suggests that using unlabeled data to learn to ensemble k 1-shot prompts can be more label-efficient than putting all k labeled examples in one prompt. For TREC and CB, the co-trained label model also outperforms prompt-based fine-tuning (Prompt-based FT <ref type="bibr" target="#b8">(Gao et al., 2021)</ref>) with the same amount of labeled data (Prompt-based FT also uses a gold-labeled validation set of k examples per class, whereas our method only uses a pseudo-labeled validation set). For RTE and CB, we nearly match the fully-supervised performance on view 0 (Label Model on full train), suggesting that co-training is able to extract nearly all of the signal from the GPT-3 probabilities in these cases without using any extra labeled data.</p><p>For view 1, the co-trained DeBERTa-large model outperforms all of the baselines that use the same amount of label information. For RTE and TREC, it outperforms Promptbased FT even when the latter uses 4x (for RTE) and 12x (for TREC) the number of labeled examples (Prompt-based FT with 8 labels per class). This suggests that the pseudo-Table <ref type="table">1</ref>: Few-shot learning results. (Top) Results against various baselines that use exactly 4 labels per dataset (except for Prompt-based FT, which uses 8 labels for CB and 12 labels for TREC, since this approach uses labels at the "per-class" level). GPT-3 and CBU results are copied from <ref type="bibr" target="#b41">Zhao et al. (2021)</ref>, while we train our own Prompt-based FT <ref type="bibr" target="#b8">(Gao et al., 2021)</ref> and Snorkel <ref type="bibr" target="#b26">(Ratner et al., 2020)</ref> models. (Bottom) Results from baselines trained on more data (for reference only). Standard deviation (when applicable) numbers are given by 4 runs over prompts (GPT-3, CBU) or random seeds (Snorkel, Prompt-based FT, Co-training). † rows show accuracy on the private SuperGLUE test set. Otherwise, the accuracies are on the public SuperGLUE validation sets, which we treated as a test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>View Table <ref type="table" target="#tab_1">2</ref> shows the results for the full access setting with T0. For RTE and CB, co-training improves on the performance of the initial zero-shot prompt (T0-3B zero-shot (no co-training)). For RTE, the co-trained view 0 and view 1 models nearly match the performance of their fullysupervised counterparts. The difference in co-training performance on RTE in Table <ref type="table">1</ref> and Table <ref type="table" target="#tab_1">2</ref> shows the benefit of having full access to h 0 . Since we can introspect the prompt model, we can use the cut statistic in both views. In the first step of co-training, the cut statistic on view 0 selects confident data with 90%-accurate pseudo-labels. The confident data selection on CB is similarly good: in the first co-training step, the cut statistic selects pseudo-labels with 89% accuracy. The pseudo-labels extracted by the view 1 model after the first step of co-training (L 0 1 ) are 98% accurate, so after training on the initial pseudo-labels, the view 1 model is able to select a very high quality training set at coverage β = 0.5. However, the CB performance is worse than in Table <ref type="table">1</ref> despite the strong initial signal in L 0 0 and the near-perfect training data in L 0 1 . Similarly, for BoolQ, co-training makes the soft prompt worse than the initial zero-shot model. We explore the reasons behind this below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">When (and how) does co-training work?</head><p>Figure <ref type="figure">2</ref> (left) shows the evolution of the test accuracy for h 0 and h 1 over co-training iterations on TREC (from Table 1). Multiple rounds of co-training increase performance for both views as the models become more precise and the coverage increases. Figure <ref type="figure">2</ref> (right) shows the precision of the confident data extracted by h 0 for each iteration of co-training, broken down by label. This figure shows two distinct phenomena. For most labels, precision decreases as coverage goes up, as we expect from usual co-training theory (see e.g. <ref type="bibr" target="#b0">Balcan et al., 2005)</ref>. However, for label 1, precision actually increases over iterations. Model h 1 (De-BERTa) is able to select new confident data for label 1 that is better than the weak labels used to train it, which improves the h 0 precision for label 1 in subsequent iterations. For example, in iteration 2, h 0 's confident precision for label 1 is 0.39, but after h 1 is trained on that data, it proposes new confident data for label 1 with precision 0.58 (not shown in Figure <ref type="figure">2</ref>). Pseudo-label correction is one of the benefits of having two complementary models (though it can also happen with a single model with appropriate regularization <ref type="bibr" target="#b37">(Wei et al., 2020)</ref>).</p><p>Figure <ref type="figure">3</ref> shows what can happen when h 0 and h 1 are not complementary enough. The left display shows the accuracy of each model over co-training iterations. The right display shows the balanced accuracy of the confident data extracted from each model. In the first co-training step, h 1 greatly improves over the initial h 0 , and selects extremely accurate confident data (nearly 100% accurate) at coverage β = 0.5. This improves the performance of the soft prompt for the next iteration (h 0 , left, iteration 1), but the confident balanced accuracy of h 0 sharply decreases. Inspecting the training of h 0 on L 0 1 , the soft prompting procedure appears to have overfit to the pseudo-labels on L 0 1 . Due to the small size of CB (250 training examples), coverage β = 0.5 and our 90/10 train/val split gives only 112 data points for training h 0 in the first iteration, but the soft prompt is a very flexible hypothesis class. This overfitting causes the accuracy of confident data to decrease, which in turn degrades the performance of h 0 , and eventually the two models converge to almost identical predictors. This suggests that CB does not have enough unlabeled data for co-training to perform well with T0, at least when β = 0.5. Using larger initial coverage (e.g. β = 1.0, β = 0) or a less flexible hypothesis class for h 0 might improve performance.</p><p>Finally, Table <ref type="table" target="#tab_1">2</ref> showed that co-training decreased performance on BoolQ even though the initial soft prompt seemed to have reasonably strong signal (56.4% accuracy). However, the finer-grained statistics are less promising. After the first training iteration, with β = 0.5, h 1 assigns pseudolabel 0 to 3270 training examples with precision 0.4 and pseudolabel 1 to 1848 examples with precision 0.66. This means the "total noise" η = P[ Ŷ = 1|Y = 0] + P[ Ŷ = 0|Y = 1] in the pseudo-labels is 0.93. At the beginning of iteration t = 1, when β = 0.6, the total noise in the confident data assigned by h 0 is 0.98. For comparison, the total noise for the initial h 0 on CB is 0.21. Even under ideal conditions on φ 0 and φ 1 , η &lt; 1 is required for learning to work, and the sample complexity depends on 1/(1 − η) <ref type="bibr" target="#b1">(Blum &amp; Mitchell, 1998)</ref>. Unfortunately, the same issue persists on BoolQ for different β values. The negative result on BoolQ suggests that the initialization for h 0 needs to have less total noise. A different prompt or a better initial hypothesis (e.g., full T0 instead of T0-3B) could be more amenable to co-training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>Our results indicate that using unlabeled data to co-train a prompted model with a smaller model can boost the performance of prompt-based learning on few-shot and zero-shot classification tasks. As a side effect, this procedure also produces a smaller performant model on the task of interest, distilling and refining the knowledge in the large prompted model. Using two complementary models and views allows the models to learn from each other despite training on partially incorrect pseudo-labels. We showed that the benefit of co-training is limited when the initial signal provided by the prompted model is too noisy (BoolQ, full access), when there is not enough unlabeled data to obtain good (pseudo-label) generalization performance (CB, full access), and when there is a large gap in fully-supervised accuracy on view 0 and view 1 (RTE, partial vs full access). Developing methods to overcome these limitations in the context of prompting is an interesting direction for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Algorithm details</head><p>A.1. Relabeling Pseudolabels from previous iterations can either be re-used or thrown out. If the initial hypothesis has high precision but low coverage, it is typically preferable to re-use the pseudolabels from previous iterations, since as coverage increases the quality of the pseudolabels is likely to go down. On the other hand, if the models being trained are capable of correcting incorrect pseudolabels, it is preferable to relabel, since this can improve the quality of the training data in each iteration.</p><p>In iteration t of co-training, we extract a pseudolabeled dataset L t i from model h i and use it to train model h 1−i . Let N ⊂ [U ] be a set of indices that correspond to the data points confidently pseudolabeled by model h i in this iteration (according to either the model confidence or cut statistic rankings). Define S = {(x n , ŷn ) : n ∈ N } as the set of these points together with their pseudolabels ŷn := argmax h i (φ i (x n )). Let L t−1 i = {(x n , ỹn )} be the confident data used in the previous iteration to train model h 1−i . For x n that appear in L t−1 i but where n ∈ N , we have a choice to make: do we use the old pseudolabel ỹn , or the new one ŷn ? These need not agree, since h i has been updated.</p><p>Let</p><formula xml:id="formula_8">S = {(x n , ŷn ) ∈ S | ¬∃y : (x n , y) ∈ L t−1 i</formula><p>} be the set of newly pseudolabeled examples-points that do not appear in L t−1 i with any pseudolabel. If we choose to re-use the pseudolabels from the previous iteration, the GetConfData update is:</p><formula xml:id="formula_9">L t i ← L t−1 i ∪ S</formula><p>On the other hand, if we throw out the previously pseudolabeled data, the update is simply:</p><formula xml:id="formula_10">L t i ← S</formula><p>We exclusively use the latter, since our models can learn to correct bad initial labels (see Figure <ref type="figure">2</ref>, Label 1). We found that the pseudolabel accuracy on the covered subset of data often increased with more iterations. This relabeling technique is different from the original cotraining algorithm <ref type="bibr" target="#b1">(Blum &amp; Mitchell, 1998)</ref>, which builds L cumulatively, but subsequent cotraining procedures also use relabeling <ref type="bibr" target="#b40">(Zhang &amp; Zhou, 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Warm starting</head><p>Instead of warm-starting the models h 0 and h 1 (initializing them from the output of the previous iteration), we initialize them from scratch each co-training iteration to reduce the effect of a "bad" training iteration and so that we can use the same training hyperparameters for every iteration. This takes advantage of the fact that there exists a robust set of initial hyperparameters that have been shown to work well for fine-tuning large language models. However, further exploration of warm-starting is an interesting direction for future work, since it may yield significant reduction in the computational burden of co-training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Confident data selection</head><p>Algorithm 2 shows how to select confident data using model confidence, and Algorithm 3 shows how to select confident data using the cut statistic. As mentioned in the main text, φ 0 and φ 1 themselves needn't be the representations used to compute nearest neighbors for the cut statistic. For example, φ 0 (x) for T0 is the non-contextual T0 input embedding of x. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Full algorithms</head><p>The detailed algorithms for co-training in the partial access setting and full access setting are shown in Algorithms 4 and 5, respectively. Algorithm 4 uses model confidence for view 0 and cut statistic for view 1. Algorithm 5 uses cut statistic for both views. The detailed procedures for model confidence and the cut statistic are shown in Algorithms 2 and 3, respectively. As mentioned in the previous section, the view 1 cut statistic uses the [CLS] token embedding in the last layer of h 1 . In the full access case, the view 0 cut statistic uses the T0 decoder's hidden state for the first decoded token. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Training and dataset details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Training details</head><p>Prompt-based FT. We fine-tuned the MLM-pretrained RoBERTa-large model using Adam for 1000 steps with batch size 16, learning rate 1e-5 and weight decay 0.01. We sampled a validation set the same size as the training set while ensuring that the validation set also had an equal number of examples per class. This small validation set was used to select the best model checkpoint in each run and the test results were averaged over four random seeds. This is similar to the "no D dev " setting in <ref type="bibr" target="#b8">Gao et al. (2021)</ref> in that we didn't use the small validation set for hyperparameter tuning-we used the same hyperparameters as the "no D dev " setting. However, we still allow the method to use the labeled validation set for model selection. We used the same prompt templates as <ref type="bibr" target="#b8">Gao et al. (2021)</ref>.</p><p>For RTE, the label words were Yes, No. For CB, the label words were Yes, No, Maybe. For TREC, the label words were Description, Entity, Abbreviation, Person, Number, Location.</p><p>Calibrate Before Use (CBU). For x cf , we followed <ref type="bibr" target="#b41">Zhao et al. (2021)</ref> and used "N/A", the empty string, and "[MASK]". We obtained the GPT-3 outputs for each of these x cf 's, renormalized the outputs over the label tokens, averaged the re-normalized outputs across the three x cf 's, and used the average result as the scaling factor for W (i) . This is identical to <ref type="bibr" target="#b41">Zhao et al. (2021)</ref>.</p><p>Co-training. Following RoBERTa and DeBERTa, we used an MNLI-pretrained checkpoint for RTE and CB (microsoft/deberta-large-mnli on Hug-gingFaceHub). Otherwise, we used DeBERTa-large (microsoft/deberta-large). We did not experiment with DeBERTa V2 or V3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3. Soft prompt encoding</head><p>As detailed in Section 3, we combine hard prompt encoding with soft prompting. That is, we format the input using a hard prompt, and combine this formatted input embedding with the soft prompt matrix. This differs from the usual soft prompting setup <ref type="bibr" target="#b18">(Li &amp; Liang, 2021;</ref><ref type="bibr" target="#b17">Lester et al., 2021)</ref>, where the input is encoded more neutrally, without a naturallanguage hard prompt:</p><formula xml:id="formula_11">sentence1: {{x.premise}} sentence2: {{x.hypothesis}}</formula><p>A priori, this difference in input encoding could affect the performance of soft prompt tuning and the zero-shot performance of the initial prompted model. However, the fulltraining-dataset soft-prompt tuning baseline in Table <ref type="table" target="#tab_1">2</ref> (T0 soft prompts on full training set) uses our hard prompt encoding + soft prompting, and it matches fully fine-tuned DeBERTa-large. This suggests that the accuracy loss from choosing a hard prompt (at least for the prompts that we chose) is minimal.</p><p>Using the hard prompt encoding might improve the label efficiency of soft prompt tuning, since the soft prompt parameters can focus on "fixing up" the given hard prompt instead of learning a prompt-like embedding from scratch. On the other hand, if the hard prompt performs poorly, the hard prompt encoding might put an unnecessary upper limit on the soft prompt tuning performance, since the soft prompt may not be able to "undo" the hard prompt performance. An in-depth comparison between the neutral encoding from the traditional soft-prompting setup and the hard prompt + soft prompt encoding we propose is an interesting direction for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4. Hardware</head><p>All models were trained on two NVIDIA A100 80Gb GPUs using PyTorch and the Transformers library <ref type="bibr" target="#b39">(Wolf et al., 2020)</ref>. For the partial access setting, a full run of T = 5 co-training iterations with DeBERTa-large takes roughly two hours on this hardware. For the full access setting, a full run of T = 5 co-training iterations with T0-3B and DeBERTa-large takes roughly 40 hours.  , extracted from the initial label model using the model confidence method (Algorithm 2). The precision of some labels (e.g., 2, 3) begins to decline more sharply after β = 0.5. This gives additional evidence for our choice of β = 0.5: it trades off between the initial precision of L 0 0 and the coverage for each label. At smaller values of β, there are no pseudolabeled examples for label 1 and very few for label 0. At larger values of β, the precision of the other labels is worse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Additional co-training analysis</head><p>In this section, we provide more information regarding the evolution of h 0 and h 1 over the co-training iterations for TREC. We focus on the TREC dataset since its 6 classes enable us to investigate more complex co-training dynamics.</p><p>To see the effect of β on the quality of the initial confident data L 0 0 , we plot the precision and recall for each label for different values of β in Figure <ref type="figure" target="#fig_3">4</ref>. This figure indicates that the tradeoff when choosing β is between having high precision for each label (lower β) and having enough coverage for each label to train on (high β).</p><p>To show how co-training affects label balance across multiple iterations, we plot the total variation distance between the true label balance and the balance estimated using the pseudolabels in each iteration's confident data L t 0 . Figure <ref type="figure">5</ref> indicates that this distance decreases with co-training iterations, so the label model automatically learns to have a balance closer to the unseen true balance.</p><p>In Figures <ref type="figure">6, 7</ref>, and 8, we plot the recall, normalized coverage, and precision for each label in L t 0 and L t 1 . The normalized coverage for label j is the number of examples with pseudolabel j divided by the number of examples with true label j; it separates coverage from the precision, unlike recall. By comparing the evolution of label curves in Figure <ref type="figure">7</ref> and 8, we can see that the models tend to add more confident data when they are more precise and add less confident data when they are less precise, which is the desired behavior. Additionally, these figures show two different ways in which co-training works to improve models: "coverage-expansion" and "pseudolabel-correction." In the coverage-expansion regime, the precision for a label slightly decreases as iterations increase, but the coverage improves; this regime was predicted by early work on co-training <ref type="bibr" target="#b0">(Balcan et al., 2005)</ref>. In the pseudolabel-correction regime, both precision and coverage increase, because models are able to learn to be more accurate than the pseudolabels used to  Figure <ref type="figure">7</ref>: Normalized coverage of the confident pseudolabel set L t 0 (extracted from h 0 using Algorithm 2) for each label versus co-training iteration t. Normalized coverage for label j is computed as |{(x, ŷ) ∈ L t i : ŷ = j}| / |{x : y(x) = j}| (the number of examples with confident pseudolabel j divided by the number of examples with true label j). This metric decouples the coverage from the precision. The increasing slope of label 1 (left) indicates that h 0 adds more confident data for label 1 in the later iterations. Combining this with the label 1 precision versus iteration curve in Figure <ref type="figure" target="#fig_6">8</ref> (left) indicates that the model adds more confident data for label 1 as it gets more precise, which is the desired behavior. On the other hand, for other labels (e.g. label 4) the rate of confident data addition and the precision stay relatively constant. For labels 0 and 2-5, the precision decreases or remains the same while the coverage increases roughly linearly. This is the "coverage-expansion" regime, where the initial confident pseudolabels are high-precision and the model learns to imperfectly extend that initial signal to the uncovered data with some losses in precision. This regime is present in classical co-training results <ref type="bibr" target="#b0">(Balcan et al., 2005)</ref>. On the other hand, for label 1, both the coverage and the precision increase with the iteration t. This is the pseudolabel-correction regime, because the models are able to learn to be more accurate than the pseudolabels used to train them (compare h 0 precision for label 1 to h 1 precision for label 1 in the same iteration-the h 1 model is trained on the labels from h 0 , but is able to select confident data with better precision than those labels).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>is GPT-3's output on: Review: this movie was great! Positive or Negative? Positive Review: {{x.review}} Positive or Negative?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Partial access setting, TREC. Left: Test accuracy vs co-training iteration for the label model h 0 and the De-BERTa model h 1 . Right: precision per label vs co-training iteration, h 0 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: Precision (left) and Recall (right) versus β for each label in the initial confident set L 0 0 , extracted from the initial label model using the model confidence method (Algorithm 2). The precision of some labels (e.g., 2, 3) begins to decline more sharply after β = 0.5. This gives additional evidence for our choice of β = 0.5: it trades off between the initial precision of L 0 0 and the coverage for each label. At smaller values of β, there are no pseudolabeled examples for label 1 and very few for label 0. At larger values of β, the precision of the other labels is worse.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Figure 5: Total variation distance between the true label balance and the label balance estimated from the pseudolabels L t 0 at each iteration. As co-training iterations proceed, the label model automatically learns a balance closer to the true unseen label balance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure8: Precision per label vs co-training iteration, h 0 (left-identical to right display of Figure2) and h 1 (right). Together with Figure7, this indicates the two regimes of co-training. For labels 0 and 2-5, the precision decreases or remains the same while the coverage increases roughly linearly. This is the "coverage-expansion" regime, where the initial confident pseudolabels are high-precision and the model learns to imperfectly extend that initial signal to the uncovered data with some losses in precision. This regime is present in classical co-training results<ref type="bibr" target="#b0">(Balcan et al., 2005)</ref>. On the other hand, for label 1, both the coverage and the precision increase with the iteration t. This is the pseudolabel-correction regime, because the models are able to learn to be more accurate than the pseudolabels used to train them (compare h 0 precision for label 1 to h 1 precision for label 1 in the same iteration-the h 1 model is trained on the labels from h 0 , but is able to select confident data with better precision than those labels).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell>RTE (2-class) CB (3-class) TREC (6-class)</cell></row></table><note>Zero-shot learning results with T0 as the initial view 0 model and DeBERTa as the second model. We also show the results trained on the full dataset in the bottom two rows. For T0, we take the best prompts from<ref type="bibr" target="#b28">Sanh et al. (2022)</ref> and replicate their results as exact numbers for each prompt were not provided in the original paper. Standard deviations are not provided in this case as even a single run takes a nontrivial amount of time.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Instead of computing nearest neighbors in this view, we use the contextual embedding from much later in the T0 model: the final decoder embedding of the first decoded token. This is a function of both φ 0 (x) and the current hypothesis h 0 . Because the embeddings are contextual, this representation has better nearest neighbors than φ 0 (x); because it also takes h 0 into account, these neighbors are adapted to the current task. Similarly, for DeBERTa-large in view 1, we use the [CLS] token embedding in the last layer of the DeBERTa representation rather than the penultimate layer, since this layer has been adapted to the task of interest by the time we select confident data.Validation datasetWe use a pseudolabeled validation set to perform model selection during the co-training iterations. Since the confident-data-selection methods can pick out the most precisely pseudolabeled examples (w.r.t. the true label), we also use them to select a confident validation set from the larger val set for each Train step. In particular, when training model h i , we use model h 1−i to select a β = β + tβ confident fraction of full validation data in each step (the same fraction used for the confident training set). This allows us to use a more precise validation set for model selection.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">In the running sentiment analysis example we might have V = {Negative, Positive, negative, positive, bad, good, . . .}.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Here we use W to refer to {W (i) } k i=1 .</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">We use L = 20 in our experiments, following<ref type="bibr" target="#b17">Lester et al. (2021)</ref>, so the soft prompt has 20 × 2048 =</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="40960" xml:id="foot_3">parameters.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4">Hence our few-shot experiments on TREC are not few-shot in the truest sense of the term.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5">This works better than using the cut statistic in both views-since the cut statistic relies heavily on good nearest neighbors, it makes the most sense in a view that already has a good distance function for examples (the pretrained DeBERTa representation).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>DS and HL were partially supported by NSF AiTF award CCF-1723344. MA was supported by the Takeda Fellowship. Thanks to Dr. Steven Horng of Beth Israel Deaconess Medical Center for providing access to an NVIDIA DGX machine <ref type="bibr" target="#b10">(Horng, 2022)</ref>, and thanks to NVIDIA Corporation for their donation of two NVIDIA A100 GPUs. Thanks to OpenAI and AI21 for providing quota to access their davinci and Jurassic-Jumbo models (respectively). Finally, thanks to Rebecca Boiarsky and Catherine Wong for their feedback on drafts of this paper and to Aravindan Vijayaraghavan for helpful discussions on co-training theory.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Prompts</head><p>Here we list the prompts used for our experiments, largely taken from <ref type="bibr" target="#b28">Sanh et al. (2022)</ref> </p><p>// first, select top γ% for each class by score ms ← γ βU // min num points to select for l in {1, . . . , numlabels} do I l = {(x n , ŷn , s n ) : ŷn = l} // sort I l by score s n (ascending) S l ←Sort(I l , key=lambda q: q[2]) // add top α% to L (read off end of S l ) L ← L ∪ S l [-ms:] end for // now select the rest of the points rs ← βU − |L| // num remaining points to select </p><p>end for // now sort by statistic and return top data</p><p>n=1 unlabeled examples input initial coverage β, coverage increase β input minimum percentage per class γ // build view 0 for unlabeled examples for n in {1, . . . , U } do for j in {1, . . . , k} do φ</p><p>// initialize h 0 according to (1) for j in {1, . . . , k} do // get GPT-3 outputs on content-free input φ (j) 0 (x cf ) ← GPT3(x cf , (x j , y j )) </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Co-training and expansion: Towards bridging theory and practice. Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">M.-F</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Combining labeled and unlabeled data with co-training</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eleventh annual conference on Computational learning theory</title>
				<meeting>the eleventh annual conference on Computational learning theory</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="92" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploring the surprising difficulty of natural yes/no questions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Boolq</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1300</idno>
		<ptr target="https://aclanthology.org/N19-1300" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">June 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2924" to="2936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The pascal recognising textual entailment challenge</title>
		<author>
			<persName><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning Challenges Workshop</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="177" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pac generalization bounds for co-training</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="375" to="382" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The commitmentbank: Investigating projection in naturally occurring discourse</title>
		<author>
			<persName><forename type="first">M.-C</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tonhauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of Sinn und Bedeutung</title>
				<meeting>Sinn und Bedeutung</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="107" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast and three-rious: Speeding up weak supervision with triplet methods</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fatahalian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3280" to="3291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Making pre-trained language models better few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.acl-long.295" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
				<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08">August 2021</date>
			<biblScope unit="page" from="3816" to="3830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Decodingenhanced bert with disentangled attention</title>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Deberta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
				<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Machine learning core</title>
		<author>
			<persName><forename type="first">S</forename><surname>Horng</surname></persName>
		</author>
		<idno type="DOI">10.6084/m9.figshare.19104917.v1</idno>
		<ptr target="https://figshare.com/articles/preprint/Machine_Learning_Core/19104917/1" />
		<imprint>
			<date type="published" when="2022-02">Feb 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">How can we know what language models know? Transactions of the</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="423" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Leveraging just a few keywords for fine-grained aspect detection through weakly supervised co-training</title>
		<author>
			<persName><forename type="first">G</forename><surname>Karamanolakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gravano</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1468</idno>
		<ptr target="https://aclanthology.org/D19-1468" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page" from="4611" to="4621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Self-training with weak supervision</title>
		<author>
			<persName><forename type="first">G</forename><surname>Karamanolakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hassan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter</title>
				<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="845" to="863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Reordering examples helps during priming-based few-shot learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
				<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08">August 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">How many data points is a prompt worth?</title>
		<author>
			<persName><forename type="first">T</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rush</surname></persName>
		</author>
		<idno>doi: 10.18653</idno>
		<ptr target="/v1/2021.naacl-main" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-06">June 2021</date>
			<biblScope unit="page" from="2627" to="2636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<ptr target="https://aclanthology.org/2021.naacl-main.208" />
		<title level="m">URL</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The power of scale for parameter-efficient prompt tuning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.emnlp-main.243" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-11">November 2021</date>
			<biblScope unit="page" from="3045" to="3059" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Prefix-tuning: Optimizing continuous prompts for generation</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.353</idno>
		<ptr target="https://aclanthology.org/2021.acl-long.353" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
				<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2021-08">August 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4582" to="4597" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.13586</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08786</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Identifying and handling mislabelled instances</title>
		<author>
			<persName><forename type="first">F</forename><surname>Muhlenbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lallich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Zighed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Information Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="89" to="109" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Uncertainty-aware selftraining for few-shot text classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Awadallah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">True few-shot learning with language models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.11447</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Pilehvar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.09121</idno>
		<title level="m">Wic: the word-incontext dataset for evaluating context-sensitive meaning representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Snorkel: Rapid training data creation with weak supervision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ehrenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="709" to="730" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Data programming: Creating large training sets, quickly</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>De Sa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Selsam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3567" to="3575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multitask prompted training enables zero-shot task generalization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chaffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stiegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Tenth International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Exploiting cloze-questions for few-shot text classification and natural language inference</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter</title>
				<meeting>the 16th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>Main Volume</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="255" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">True few-shot learning with prompts -a real-world perspective</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.13440</idno>
		<ptr target="http://arxiv.org/abs/2001.07676" />
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Probability of error of some adaptive patternrecognition machines</title>
		<author>
			<persName><forename type="first">H</forename><surname>Scudder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="363" to="371" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Eliciting Knowledge from Language Models with Automatically Generated Prompts</title>
		<author>
			<persName><forename type="first">T</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Razeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Autoprompt</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.emnlp-main.346" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020-11">November 2020</date>
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Building a question answering test collection</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</title>
				<meeting>the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="200" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Superglue: a stickier benchmark for general-purpose language understanding systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Neural Information Processing Systems</title>
				<meeting>the 33rd International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019a</date>
			<biblScope unit="page" from="3266" to="3280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Glue: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno>ICLR 2019</idno>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Want to reduce labeling cost? GPT-3 can help</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zeng</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.findings-emnlp.354" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
				<meeting><address><addrLine>Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-11">November 2021</date>
			<biblScope unit="page" from="4195" to="4205" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Theoretical analysis of self-training with deep networks on unlabeled data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.01652</idno>
		<title level="m">Finetuned language models are zero-shot learners</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Transformers: Stateof-the-art natural language processing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.emnlp-demos.6" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-10">October 2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Confident cotraining with data editing</title>
		<author>
			<persName><forename type="first">M.-L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><surname>Cotrade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1612" to="1626" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Part B (Cybernetics)</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Calibrate before use: Improving few-shot performance of language models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
				<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="12697" to="12706" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
