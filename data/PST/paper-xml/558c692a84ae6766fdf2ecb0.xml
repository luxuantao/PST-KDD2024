<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Turin</orgName>
								<address>
									<postCode>10149</postCode>
									<settlement>Turin</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5A87BE190CC1232F5E3AF4348364DAC1</idno>
					<idno type="DOI">10.1109/TITS.2013.2247760</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fabio Tango received the B.S. degree in physics (solid state) and the Ph.D. degree in computer science from the University of Turin, Turin, Italy, in  1995 and 2009, respectively.   Since 1999, he has been with the Department of Electric and Electronic Systems, Fiat Center of Research (CRF), Orbassano, Italy, where is currently a Senior Researcher working in the area of preventive safety systems. He is also the technical coordinator of the projects ISI-PADAS and D3COS, as well as the internal CRF project manager of the INTERACTIVE/PERCEPTION project (all co-founded by the European Commission). His research interests include human-automation interaction; user's status modeling (distraction and fatigue detection); pattern recognition and analysis; data fusion and objects classification, with applications in image processing; and applications of machine learning techniques for automatic driving.</p><p>Marco Botta received the B.S. (cum laude) and Ph.D. degrees in computer science from the University of Turin, Turin, Italy, in 1987 and 1993, respectively.</p><p>Since 2001, he has been an Associate Professor of computer science with the Faculty of Mathematical, Physical, and Natural Sciences, University of Turin. He is also affiliated with the Department of Computer Science, University of Turin. In his early research years, he mainly studied and developed new methods for learning concepts from instances. Such methods were oriented both toward the construction of knowledge bases for expert systems and their refinement. His current research interests include artificial intelligence, machine learning problems, the integration of symbolic and subsymbolic learning approaches with the aim of combining the expressive power of first-order logic with the refinement mechanisms that are typical of a connectionist approach, and bioinformatics research, where he has developed many collaborations with biologists on several topics, such as protein folding prediction, microarray data analysis, and prediction of transcription factor binding sites.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Real-Time Detection System of Driver Distraction</head><p>Using Machine Learning</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fabio Tango and Marco Botta</head><p>Abstract-There is accumulating evidence that driver distraction is a leading cause of vehicle crashes and incidents. In particular, increased use of so-called in-vehicle information systems (IVIS) and partially autonomous driving assistance systems (PADAS) have raised important and growing safety concerns. Thus, detecting the driver's state is of paramount importance, to adapt IVIS and PADAS accordingly, therefore avoiding or mitigating their possible negative effects. The purpose of this paper is to show a method for the nonintrusive and realtime detection of visual distraction, using vehicle dynamics data and without using the eye-tracker data as inputs to classifiers. Specifically, we present and compare different models that are based on well-known machine learning (ML) methods. Data for training the models were collected using a static driving simulator, with real human subjects performing a specific secondary task [i.e., a surrogate visual research task (SURT)] while driving. Different training methods, model characteristics, and feature selection criteria have been compared. Based on our results, using a support vector machine (SVM) has outperformed all the other ML methods, providing the highest classification rate for most of the subjects. Potential applications of this paper include the design of an adaptive IVIS and of a "smarter" PADAS. Index Terms-Accident prevention, artificial intelligence and machine learning (ML), driver distraction and inattention, intelligent supporting systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>D RIVER inattention and distraction do not have a generally accepted definition. The related terms are frequently discussed in the literature, but very often, they are inconsistently defined, and the relationship between them is unclear <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. In addition, the extent to which driver distraction is responsible for accidents is not completely understood. Therefore, Wang et al. <ref type="bibr" target="#b2">[3]</ref> estimated that 13.3% of crashes involved what they considered distraction and 9.7% of crashes were in a category called "looked but did not see." Such a percentage can even increase (+2.6%) if drowsiness is also considered. In <ref type="bibr" target="#b3">[4]</ref>, it was found that almost 80% of all crashes and 65% of all near-crashes involved driver distraction. In fact, it is well known that the majority of road accidents (surely &gt; 80%) are due to human error <ref type="bibr" target="#b4">[5]</ref> or (wrong) human behavior, with increasing evidence suggesting that driver distraction and inattention are major contributing factors in car and truck crashes and incidents, with the National Highway Traffic Safety Administration (NHTSA) estimating that, in 25% of all crashes, some form of inattention (including distraction) is involved <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b8">[9]</ref>. Based on this picture, crashes due to driver distraction result in as many as 5000 fatalities and $40 billion in damages each year [based on studies from the NHTSA carried out in the U.S. Some European studies also confirm such values (see, e.g., the European projects AIDE and D3COS, http://www.aide-eu.org, or http://www.d3cos.eu/)] [10]- <ref type="bibr" target="#b11">[12]</ref>.</p><p>Notwithstanding the ambiguity in its definition and actual impact, it seems that the scientific community agrees on one thing. Driver distraction-and inattention-is an important safety concern <ref type="bibr" target="#b12">[13]</ref>. Overall, driver distraction is not a new problem in road safety. We may say that it has been around for as long as people have been driving cars.</p><p>It is likely that the problem will increase as more wireless or mobile technologies find their way into vehicles <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b13">[14]</ref>. Although, in the last few years, many European countries have prohibited the use of mobile phones, for example, when driving, nonetheless, it should not be expected that the amount of driving distraction will necessarily decrease. In fact, even without the distraction caused by mobile devices, the use of socalled in-vehicle information systems (IVIS), e.g., navigation systems, can be additional sources of potential distraction. One method, which is followed by many car manufacturers and automotive suppliers, aims at minimizing the risk of crashes rather than distraction (as pointed out by Woeller et al. in <ref type="bibr" target="#b8">[9]</ref>) by means of the development of dedicated supporting systems. These include so-called advanced driving assistance systems (ADAS) and partially autonomous driving assistance systems (PADAS), such as the lane-keeping assistance system, the forward-collision warning system, the emergency braking system, etc. However, it is also true that such PADAS may induce their own forms of distraction.</p><p>In this context, allowing drivers to benefit from the use of these IVIS and PADAS without diminishing safety is a big and important challenge. One promising strategy for dealing with such a problem involves the classification of the driver's state, i.e., in this case, a distracted driver, in real time and then using this classification for a twofold goal: 1) the adaption of IVIS technologies, to mitigate the effects of distraction; and 2) the adaption of PADAS strategies, to minimize the effects of distraction on the driving task.</p><p>Machine learning (ML) and data mining (DM) technologies may be able to provide the right algorithms for coping with such a challenge. ML is the technique of searching large volumes of data for unknown patterns. It has been successfully applied in business, health care, and other domains <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>. In particular, this technology can be applied to build a discrimination model that captures the differences in behavior when people drive normally and when they are distracted.</p><p>The main goal of this paper is to present a nonintrusive approach for a real-time system to detect and classify driver distraction, applying ML algorithms (comparing different methods) and using only vehicle dynamic data as inputs to the model. In particular, here, we mainly address the driver visual distraction that has been considered as an important aspect in the investigated maneuvers. In this context, looking away for a short while (at least 1.8 s) can be considered a driver visual distraction from her/his main activity.</p><p>This paper is organized as follows. Section II provides the definition of driver distraction based on the current discussion in the literature. Then, Section III briefly describes the investigated ML techniques for modeling driver distraction. The experimental setup will be shown in Section IV, whereas Section V shows the main results achieved. Finally, Section VI aims at critically discussing these results; comparing our results to the most important results obtained by similar works in this area; pointing out the differences, our innovations, and weaknesses; and highlighting possible future activities. Finally, Section VII concludes this paper with a summary of the main points of interest in this research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DEFINITION OF DISTRACTION</head><p>As previously asked, is it possible to reliably detect and recognize the driver's state so that a system (such as the PADAS) could give as much assistance as the driver needs? For instance, the intervention of a forward-collision assistance system can be triggered, based on the driver's state. If distraction is detected, the function strategies can be accordingly adjusted (e.g., braking is modulated differently, or warning signals are anticipated). On the contrary, if the system detects that the driver is not distracted but intends to overtake, the warning can be delayed or suppressed, even when approaching a vehicle ahead. Such smart assistance, which recognizes driver's intention and state, would allow for a greater safety margin, without irritating the driver with false alarms or inappropriate interventions in normal driving conditions, therefore enhancing the user acceptability. In recent years, several methods have been published aimed at estimating driver distraction (e.g., <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b19">[20]</ref>) or concentrating on the detection and modeling of fatigue or stress as fundamental causes for driver inattention (such as <ref type="bibr" target="#b20">[21]</ref> and <ref type="bibr" target="#b21">[22]</ref>).</p><p>However, in the literature, there is no unique and commonly agreed upon definition of distraction. Several definitions very often overlapped and mixed with inattention or with other driver's states, such as drowsiness and workload. For what concerns the definition of distraction adopted in this paper, we have considered the taxonomy proposed by Regan et al. <ref type="bibr" target="#b1">[2]</ref> and by Lee et al. <ref type="bibr" target="#b22">[23]</ref>. In particular, we start from the following definition:</p><p>"Driver distraction is the diversion of attention away from activities critical for safe driving toward a competing activity." This has been extended by <ref type="bibr">Regan et al.</ref>, adding the concept of driver inattention, which means insufficient or no attention to critical activities for safe driving toward a competing activity.</p><p>It is worth noting, that such a definition suffers from hindsight bias since it is really difficult to say if the driver is distracted until after something dangerous happens, and then it will be too late for the system to intervene (Regan et al. mentioned this fact in his article). Given that, Regan et al. pointed out that "how to develop taxonomy of driver inattention without the benefit of hindsight is an important theoretical and practical challenge beyond the scope of this paper;" therefore, this is still an open point in the literature (and this is definitely beyond the scope of this paper). Although this statement is absolutely true, nevertheless, it would almost be impossible to use the concept of distraction without some preliminary assumptions, even if the situation does not lead to an accident in 100 instances but it does on the 101st instance. Although the behavior is not different, these are potentially critical situations, and we want that our systems can prevent such risky conditions (because we do not know which conditions could lead to an accident). In fact, in these situations, drivers are not ready to react appropriately to any unexpected event; thus, the accidents are more likely.</p><p>To sum up, distinct from other forms of driver inattention, distraction occurs when a driver's attention is diverted away from driving by a secondary task that requires focusing on an object, an event, or a person not related to the driving task. Although existing data are inadequate and not representative of the driving population, it is estimated that drivers engage in potentially distracting secondary tasks approximately 30% of the time that their vehicles are in motion. (Having a conversation with passengers is the most frequent secondary task, followed by eating, smoking, manipulating controls, reaching inside the vehicle, and using cell phones). Thus, we have considered visual distraction as the diversion of visual attention away from the road. This category of "driver distraction" is also the one used by Lee et al. <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. MODELING DRIVER'S STATE</head><p>Given the current state of the art and with reference to our previous works (see <ref type="bibr" target="#b18">[19]</ref> and <ref type="bibr" target="#b23">[24]</ref>) we have selected a widely used ML technique and some other methods not deeply investigated in the literature to model the driver's state. These include support vector machines (SVMs), static and dynamic neural networks (NNs) [feedforward NNs (FFNNs) and layerrecurrent NNs (LRNNs), respectively], and adaptive neurofuzzy inference systems (ANFISs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Description of the SVM Method</head><p>In recent years, SVMs have been arguably one of the most important developments in supervised classification. First proposed by Vapnik in 1998, SVMs are based on a statistical learning technique, and can be used for pattern classification and inference of nonlinear relationships between variables <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>. This method has been successfully applied to a wide variety of domains, such as image processing (e.g., face recognition), text and speech recognition, and bioinformatics (e.g., protein classification) <ref type="bibr" target="#b26">[27]</ref>. SVMs often achieve superior classification performance compared with other learning algorithms across most domains and tasks; they are fairly insensitive to the curse of dimensionality and are efficient enough to handle very large scale problems in both sample and variables. The "classical" application of SVMs concerns a binary classification task. The main idea behind SVMs is to map implicitly data to a higher dimensional space via a kernel function and then solve an optimization problem to identify the maximum-margin hyperplane that separates training instances. The hyperplane is based on a set of boundary training instance called support vectors. New instances are classified according to the side of the hyperplane that they fall into. The optimization problem is most often formulated in a way that allows for nonseparable data by penalizing misclassifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Description of the FFNN Method</head><p>Artificial NNs (ANNs), or simply NNs, are an information processing system, which is inspired by the biological nervous system (the brain) and consist of a large number of highly interconnected processing elements, working together to solve specific problems <ref type="bibr" target="#b27">[28]</ref>. In an NN, signals are transmitted through connection links, characterized by an associated weight, which is multiplied by the incoming signal (the input of the net) for any typical neural net. The output signal of a unit is obtained by squashing the net input into an activation function. One of the most important types of NNs-used within this paperare the FFNNs. FFNNs have a layered structure, where each layer consists of units receiving their input from units in a layer directly below them and sending their output to units in a layer directly above them. There are no connections within the units of the same layer. FFNNs are considered static networks since they have no feedback elements and contain no delays; the output is calculated directly from the input through feedforward connections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Description of the LRNN Method</head><p>In addition to static NNs (FFNNs) (whose topology corresponds to acyclic directed graphs), there are also the dynamic (recurrent) NNs, where the output depends not only on the current input to the network but also on the previous inputs, outputs, or states of the network. LRNNs, which were introduced by Elman <ref type="bibr" target="#b28">[29]</ref> in an earlier simplified version, are a specific type of dynamic networks.</p><p>Overall, recurrent networks are ANNs that apply to timeseries data and that use outputs of network units at time t as input to other units at time t + 1. Under this viewpoint, they support a form of directed cycles in the network. In the LRNNs, there is a feedback loop, with a single delay, around each layer of the network, except for the last layer. In particular, this type of network is used when the prediction of an output y(t + 1), e.g., the next day's stock market average, based on the current days economic indicators <ref type="bibr" target="#b29">[30]</ref>, and depends not only on the input value x(t) but also on earlier values x(ti), i ∈ 0, 1, . . . , ti.</p><p>To train an LRNN, a simple variant of the back-propagation method is used. In practice, however, LRNNs are more expensive to train than networks with no feedback loops.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Description of the FIS and ANFIS Method</head><p>The starting point for talking about Fuzzy Logic (FL) is the consideration of the relative importance of precision. Sometimes, logic is based only on two truth values, true and false, and can be inadequate when describing human reasoning. FL uses all values inside the interval [0, 1] (where 0 is regarded as false and 1 as true) to describe human reasoning; therefore, it is a fascinating area of research because it does a good job of trading off between significance and precision. This is something that humans have been managing for a very long time. In this sense, FL has the ability to mimic the human mind to effectively employ modes of reasoning that are approximate rather than exact.</p><p>In more "mathematical terms," FL is a way to map an input space to an output space. In particular, since an FL system (FLS) is able to simultaneously handle numerical data and linguistic knowledge, it is a nonlinear mapping of an input data (feature) vector into a scalar output (i.e., it maps numbers into numbers). Between the input and output, we can put a "black box" that does the work, and inside it, we can find any number of things, from FLS to expert systems, from linear systems to NNs, and so on.</p><p>One of the key concepts behind FL is the fuzzy set(s), which is a set without crisp and clearly defined boundaries. It contains elements with only a partial degree of membership: The truth of any statement becomes a matter of degree. In this context, the membership functions (MFs) are curves that define how each point in the input space is mapped to a membership value (also called degree of membership) in the interval [0, 1]. There are several types of MFs, but in most cases, a triangular shape or a Gaussian shape is used.</p><p>Fuzzy sets and fuzzy operators can be regarded as the subjects and verbs of FL, but to say anything useful, we need to make complete sentences. Therefore, the conditional statements, i.e., if-then rules, are the things that make FL useful.</p><p>Even if the output of each rule is a fuzzy set, in general, we want the output for an entire collection of rules to be a single number. To achieve this, first, the output fuzzy sets for each rule are aggregated into a single output fuzzy set. Then, the resulting set is defuzzified or resolved to a single number. Many defuzzification techniques have been proposed in the literature. Perhaps, the most popular defuzzification method is the centroid calculation, which returns the center of area under the curve. (For details on FIS, see <ref type="bibr" target="#b30">[31]</ref> and <ref type="bibr" target="#b31">[32]</ref>.)</p><p>In a traditional FIS, the MFs are fixed and somewhat arbitrarily chosen. Moreover, fuzzy inference is applied to modeling systems whose rule structure is essentially predetermined by the user's interpretation of the characteristics of the variables in the model. Hence, one of the key points in fuzzy set theory is the choice and tuning of MFs, which are done very often arbitrarily and manually. One possibility is to use the architecture and learning procedure called ANFIS, which is an FIS in the framework of adaptive networks. An adaptive network is a superset of all kinds of FFNNs with supervised learning capability. In particular, it is a network structure consisting of nodes and direct links through which the nodes are connected. A part or all of the nodes are adaptive, which means that each output of these nodes depends on the parameter(s) pertaining to the node itself; the learning rule specifies how these parameters should be changed to minimize a given error measure. Since the basic learning rule focuses on the gradient method, which is notorious for its slowness and tendency to become trapped in local minima, Jang et al. <ref type="bibr" target="#b32">[33]</ref> have proposed a hybrid learning rule, which can substantially speed up the learning process.</p><p>Nowadays, ANFIS has been used in several fields, with wellfounded applications to automatic control and signal processing. The nonlinearity and structured knowledge representation of ANFIS are the primary advantages over classical linear approaches in adaptive filtering and adaptive signal processing, such as identification, inverse modeling, predictive coding, adaptive channel equalization, adaptive interference (noise or echo) canceling, etc. <ref type="bibr" target="#b33">[34]</ref> IV. DESCRIPTION OF THE EXPERIMENTS The data related to distraction and vehicle dynamics have been collected by means of dedicated experiments using a static driving simulator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Subjects</head><p>Twenty participants with previous experience on the driving simulator have been selected and divided into two groups. There are ten drivers between 20 and 25 years of age and ten drivers between 30 and 45 years of age. A minimum amount of driver experience was required. This entailed possession of a driver's license for at least two years and 6000 km driven per year. The driver's gender was not an investigated variable. (There were three females and seven males in each group).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Setup</head><p>As mainly done in other works studying distracted driving, a driving experiment has been conducted on a driving simulator because of safety issues and better control of the environment, and logistic and economic reasons. In particular, a ScanerII (www.scaner2.com) car simulator has been used. It is a fixed based system that comprises a mock-up of a car with real driving controls (i.e., seat, steering wheel, pedals, gear, and handbrake), a digitally simulated dashboard displaying a traditional instrumental panel, and a frontal projection screen where the simulated environment is displayed to the driver (see Fig. <ref type="figure" target="#fig_0">1</ref>). Distraction has been induced by means of a secondary visual research task, called a surrogate visual research task (SURT), which is methodology developed by S. Mattes in the project ADAM, and here reproduced on an in-vehicle display system (7 thin-film transistor touchscreen installed on the right-hand side of the car cabin) <ref type="bibr" target="#b49">[50]</ref>. Fig. <ref type="figure" target="#fig_0">1</ref> shows the situation.</p><p>SURT was chosen with the aim of evaluating the interference caused by a generic visual search task rather than a specific IVIS, which can be "simulated" in such a way. Like most commercial IVIS, it requires visual perception and manual response. Such activities, according to Wickens' multiple resources model <ref type="bibr" target="#b34">[35]</ref>, requires the same mental resources of the driving task and is therefore more likely to interfere, possibly causing a degradation of driving task performances. Of course, each IVIS has a different potential distraction, as a function of its position, size, human machine interface, working conditions, etc. However, authors believe this is really relevant in real vehicles. Unlike in the investigation of Jiménez et al. <ref type="bibr" target="#b50">[51]</ref>, we did not have the possibility of installing a real IVIS device in the driving simulator; in the next step of our research, where we use data sets from the real world, the SURT methodology will be replaced by the use of a specific IVIS (such as the navigation system, as done in <ref type="bibr" target="#b8">[9]</ref>). Overall, for this type of study based on a driving simulator, we think SURT can be effective in modeling the distraction of the drivers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Procedure</head><p>Participants performed a practice drive in the driving simulator for 15 min. Then, they were asked to drive for approximately 50 min on a simulated three lane highway. The driving task consisted of keeping the lane and driving at an average speed of 100 km/h at a safe distance from the vehicles encountered ahead. For the moment, we have considered a motorway scenario for a couple of reasons. First, it represents a more structured and controlled environment; and second, it is more suitable for the integration with the ADAS application under investigation, i.e., the adaptive cruise control.</p><p>During this driving phase, each participant was asked to complete 16 secondary task sessions, with each one lasting 3 min. When SURT is activated, the display shows a black screen with 30 symbols (each 1.4 cm high): 14 blue circles, 15 red squares, and 1 red circle. The screen is equally divided into two vertical sides, and each time the SURT is presented, the driver is asked to touch the side where the red circle is located. The time interval between two consecutive screens was pseudorandomized between 3 and 9 s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Data Collection and Processing</head><p>Distraction data constitute the target set since we have adopted a supervised learning method. In this methodology using SURT, the eye position of the subjects has been extracted from videos with video processing laboratory software and transferred to a log file as Boolean values (1: eyes on the SURT; 0: eyes in front of the screen). Then, the change of SURT status, from 0 to 1 and from 1 to 0, has been considered as the key factor to understanding if the driver was distracted or not. In fact, in the literature (see <ref type="bibr" target="#b35">[36]</ref> and <ref type="bibr" target="#b36">[37]</ref>), if the drivers look away from the road for an interval between 1 and 2 s, they can be regarded as distracted. The switches in SURT status identify the period where drivers were engaged with secondary task completion. The number of correct answers, together with drivers' reaction time on the SURT (i.e., the difference between the instant the task is presented and the touch of the driver) has been recorded.</p><p>Since we consider a supervised learning approach, we needed to define a target set for the training of the classifiers; this target set has been built in a postprocessing phase as follows.</p><p>An infrared camera, with a precision of 25 frames/s, was pointed to the face of the subject, and the experimenter visualized on a display if the user was looking at the road or at the SURT. To limit the possible false positives, the experimenter used another camera (same precision), which pointed to the SURT, to check if the subject was interacting with it (e.g., clicking on the SURT display). When the experimenter saw that the subject was interacting with the SURT device (therefore looking away from the road scene), he will press "1" on the PC keyboard; otherwise, he will press "0," and then will write these values into the log file of the simulator.</p><p>Given the log file, the experimenter has considered all the sequential 1's in it, for a period of time equal to at least 1.8 s. From the literature, this is a good time period over which a driver can be regarded as visually distracted. When we found this type of situation, an instance in the target set was labeled as driver distracted; otherwise, it was labeled driver not distracted.</p><p>For what concerns the vehicle dynamic data, the following variables have been collected and used:</p><p>• These values are directly available on the prototype vehicle controller-area-network bus (the same one installed on a real vehicle). The frequency of data collection was 20 Hz (1 data point per 0.05 s), which is the output rate of the simulator. Values are then averaged over a period of 1.8 s to be consistent with the target variable (distracted or not distracted).</p><p>It is worth noting here that these variables constitute the only inputs to the classifiers. The eye movement data do not appear since they have been used by the experimenter only to label the target set, as explained earlier.</p><p>Following the ordinary procedure for supervised learning, each data set has been split into three different subsets:</p><p>• training data (around 60% of the whole data set), which are used to train the classifiers; • verification data (around 15% of the whole data set), which are used to measure classifier generalization and to halt training when generalization stops improving; • testing data (around 25% of the whole data set), which have no effect on training and therefore provide an independent measure of learning performance after training.</p><p>Because of the way the experiment is designed, we consider here the visual distraction (eyes off the road). Although we cannot directly address other types of distraction (e.g., cognitive) by this experiment, nonetheless, visual distraction has been shown to be of greatest concern in naturalistic driving studies, as stated in <ref type="bibr" target="#b7">[8]</ref> and <ref type="bibr" target="#b55">[56]</ref>, where both have shown that texting (visual distraction) is associated with greater odds to crash-relevant conflict than cell phone conversation (cognitive distraction).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. DATA ANALYSIS AND RESULTS</head><p>In our previous work <ref type="bibr" target="#b23">[24]</ref>, we had shown an "intersubject" analysis, where we followed a "leave-one-out" approach. One model has been trained on the data from 9 out of 10 subjects and tested on the data of the left-out subject (in turn, on every subject), and results are averaged. Unfortunately, the results were not really satisfactory since the best obtained performance was around 75% of instances correctly classified. (This is a very poor result, meaning that such a classification rate is rarely accepted by users). Very likely, this is because the response to distraction is highly personal and subjective; therefore, the normal behavior of one driver can be similar (= too similar for a model) to the distracted behavior of another driver.</p><p>Therefore, in this paper, we present an "intrasubject" analysis, where one model for each participant is created and the performances of every classifier have been compared, to assess how a specific model can fit a specific subject (which is very interesting for personalization).</p><p>To measure the performances of each classifier, we have considered the following indexes:</p><p>• correct rate (CR), which is the number of instances correctly classified; • sensitivity (SENS), which is the correctly classified positive instances or true positive instances; • specificity (SPEC), which is the correctly classified negative instances or true negative instances.</p><p>In the following, the best model is the one with the highest CR value, a good model is a model with CR &gt; 90%, and an acceptable model is a model with CR &gt; 80%. (These values are inferred reading similar works in literature and based on our personal experience).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE I PERFORMANCES OF THE DISTRACTION CLASSIFIER BASED ON FFNNS</head><p>Finally, we used the MATLAB Neural Networks Toolbox for the FFNN and the LRNN models, the MATLAB Fuzzy Logic Toolbox for the ANFIS model, the MATLAB Bioinformatics Toolbox for the SVM model, and WEKA 3: Data Mining Software in Java for the logistic regression (LR) model (http:// www.cs.waikato.ac.nz/ml/weka/).</p><p>The reported values are averaged over five runs with the same parameter configuration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Performances for the FFNN Distraction Classifier</head><p>Different network configurations and topologies have been analyzed for each subject, with different characteristics. The chosen (winning) network has the following characteristics:</p><p>• training method = scaled conjugate gradient back propagation; • number of layers = two-layer topology with one hidden layer (HL) and one output layer (OL); • transfer function = a sigmoid transfer function has been used for both the HL and OL. It is a very rare case that more than one HL is needed; an NN with only an HL can approximate any continuous function. An NN with two or more HLs can approximate even noncontinuous functions. (In principle, we did not know if the classification function is continuous or not.) In the HL, different numbers of hidden neurons (HNs) have been tested. The mean square error (MSE) has been used to evaluate the performances and as a stop criterion. Training automatically stops when generalization stops improving, as indicated by an increase in the MSE on the validation set (which is the 15% of the data set).</p><p>As Table <ref type="table">I</ref> shows, we only obtained a good model from 3 out of the 20 subjects, and an acceptable model from 7 out of the 20 subjects. The best performance has been obtained for subject 1, with a CR equal to 94.4%. In this case, the training time was 88.2 s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Performances for the SVM Distraction Classifier</head><p>For SVM, several kernels and different values of their parameters have been tried:</p><p>• linear; • quadratic; • polynomial; • radial basis function (RBF); • multilayer perceptron.</p><p>The results are reported in Table <ref type="table" target="#tab_0">II</ref>. As Table <ref type="table" target="#tab_0">II</ref> shows, the RBF has proven to be the best kernel function in 17 cases out of 20. Its expression is</p><formula xml:id="formula_0">K(x i , x j ) = e -σ|x i , x j | 2</formula><p>where x i and x j represent the data points, and σ is a predefined positive scaling factor parameter.</p><p>The RBF is a very robust kernel function, for which it is possible to implement both linear mapping and nonlinear mapping by manipulating the values of its parameters. Moreover, the RBF can reduce numerical difficulties and ends to obtain more robust results than other kernels, such as polynomial and linear (also confirmed by results in <ref type="bibr" target="#b37">[38]</ref>).</p><p>As shown in Table <ref type="table" target="#tab_0">II</ref>, the SVM produces good models from every subject. In particular, the best results are obtained for subjects 16 and 17, which have a CR &gt; 97%. The former uses a polynomial kernel, whereas the latter uses an RBF kernel. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Performances for the ANFIS Distraction Classifier</head><p>In our experiments, we used the Sugeno-type FIS, which is similar to the Mamdani method in many respects. The first two parts of the fuzzy inference process, input fuzzification, and application of the fuzzy operators (see Section III-D) are exactly the same; the main difference between Mamdani and Sugeno is that the Sugeno output MFs are either linear or constant.</p><p>For the creation of this Sugeno-type FISs, there are two main methods for partitioning the input data: grid partitioning and subclustering. We have selected subclustering, which generates an initial model for the ANFIS by first applying subtractive clustering to the data. Different values of the clustering centers and the radius have been tested, as shown in Table <ref type="table" target="#tab_1">III</ref>. The best results are achieved with values not exceeding 0.11, to have an acceptable tradeoff between training time and performances.</p><p>The rule extraction method first uses the subclustering function to determine the number of rules and antecedent MFs, and then it uses linear least squares estimation to determine each rule's consequent equation. This function returns an FIS structure that contains a set of fuzzy rules to cover the feature space. For this type of FIS structure, Gaussian-type MFs have been used.</p><p>To optimize MF parameters, our ANFIS model used a combination of the least squares method and the back-propagation gradient descent method.</p><p>Finally, the training process stops whenever a given number of epochs is reached or the training error goal is achieved.</p><p>Table <ref type="table" target="#tab_1">III</ref> reports the results obtained by the ANFIS classifier. It also achieved very good results, producing acceptable models for 7 out of 20 subjects, and good models for the others, with the best performance for subject 1, topping at 96.58% of instances correctly classified. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Performances for the LRNN Distraction Classifier</head><p>Overall, LRNNs are similar to FFNNs, except that each layer has a recurrent connection with a tap delay associated with it.</p><p>The training function updates weight and bias values according to the Broyden-Fletcher-Goldfarb-Shanno quasi-Newton method (using the algorithm implemented in the trainbfg routine of MATLAB). For the adaptation learning function, we have used the gradient descent with a momentum weight and a bias learning function.</p><p>As done with the FFNNs, we tried different numbers of HNs and reported the results obtained using only one HL, with 20, 50 and 100 neurons. For the HL neurons, we used a tangentsigmoid transfer function, whereas for the OL neurons, we used a linear function.</p><p>In addition, in this case, the MSE has been used as the performance measure for training the network.</p><p>For this type of NNs, we only considered ten subjects, due to the very long training time of the LRNNs (more than 12 h for each subject) and the poorer results obtained (compared with the other methods). It is worth noting here that the LRNNs were an interesting case study since they have infinite dynamic response; hence, time history can be taken into account very easily. The results are reported in Table <ref type="table" target="#tab_2">IV</ref>.</p><p>The LRNNs produced a good model only in 2 cases out of the 10 cases, i.e., for subjects 1 and 6, with a CR &gt; 90%. The best performances are obtained again for subject 1 and are almost comparable to those for the other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Comparison Between the Different Distraction Classifiers</head><p>We show here some comparison plots that report the CR, SENS, and SPEC for every subject, for each classifier. In addition, we report the performance indexes obtained by an LR classifier, to know what we have gained using more complex nonlinear models. Fig. <ref type="figure" target="#fig_2">2</ref> shows the CR of the tested models on the first ten subjects. (Therefore, the LRNN model can be included).</p><p>The SVM classifier outperforms all the others, even if the ANFIS achieves very similar performances. The LRNN model provides quite good results, even if not as good as the ANFIS and the SVM. However, it should be pointed   out that the LRNNs outperform the FFNN models. The LR classifier presents the worst performances, confirming the fact that using nonlinear models provides valuable gain. This is also confirmed by the SENS and SPEC plots, as shown in Figs. <ref type="figure" target="#fig_3">3</ref> and<ref type="figure" target="#fig_4">4</ref>. In Fig. <ref type="figure" target="#fig_3">3</ref>, the SVM outperforms all the other classifiers in terms of SENS, even if, in this case, the LRNN and the ANFIS obtain very good results. Much worse, the behavior of the FFNN model provides results similar to LR in many cases. This is also true for the SPEC index in Fig. <ref type="figure" target="#fig_4">4</ref>, where the SVM, the ANFIS, and the LRNNs deliver a good capacity to recognize the negative instances as such, whereas the FFNN and LR give the worst results (LR has the absolute least values).</p><p>It is worth noting that the performances of the SVM are quite stable for different subjects, whereas for the other method, they vary quite a lot from subject to subject.</p><p>Table <ref type="table" target="#tab_3">V</ref> provides a summary of the average performances obtained on all the subjects by the different classifiers, including CR, SENS, and SPEC.</p><p>The SVM shows the better performances, with respect to all the performance indexes; it is worth noting here that there is a good balance between SENS and SPEC, meaning that the model is able to recognize and classify both positive and negative instances, (This is really important because, in reality, the driver is not distracted most of the time). This tendency can be found also for the other classifiers, even if the ANFIS and the LRNNs show higher values for SPEC rather than for SENS.</p><p>Let us consider now other parameters, in addition to performance. The training time for the best performances of the FFNN model took about 99.89 s on average for the whole data set, whereas the training time of the SVM models took 47.06 s. Similarly, for the LRNNs, we have 148408.7 s on average and 13804 s for the ANFIS.</p><p>Although the SVM training time is the lowest, nonetheless, response time is crucial, and under this viewpoint, the NNbased models are usually better. In fact, while the SVM has to compute a kernel function every time, NNs have an infinitesimal response time once the weights and the topology have been defined. Therefore, the delay coming from data reduction and response time of the models has to be evaluated since the final choice can depend also on the application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. DISCUSSION</head><p>The idea of using ML techniques to detect driver distraction is not completely new. In particular, Woeller et al. <ref type="bibr" target="#b8">[9]</ref> and Zhang et al. <ref type="bibr" target="#b37">[38]</ref> suggested that there are basically three approaches to such a recognition problem: 1) monitoring driver's perception; 2) monitoring driver's steering and lane keeping behavior; and 3) recognizing the driver's involvement in a given secondary task. Despite the fact that different classification methods can be found in the literature to detect distraction or inattention while driving, nevertheless, since the mental state of the driver is not directly observable, no simple measure can weight distraction precisely; thereby, all traditional methods show some limits <ref type="bibr" target="#b40">[41]</ref>. In this context, the predominant approach is to use ML techniques, which seem to be much more appropriate for this type of a classification problem. From a more "philosophical" point of view, one of the most ambitious goals of automatic learning systems is to mimic the learning capability of humans, and the capability of humans to drive is widely based on experience, particularly on the possibility of learning from experience. From a more technical point of view, data collected from vehicle dynamics and external environment are definitely nonlinear. From the literature, several studies have proven that, in such situations, ML approaches can outperform the traditional analytical methods. Moreover, a human's mental and physical driving behavior is nondeterministic <ref type="bibr" target="#b41">[42]</ref>- <ref type="bibr" target="#b44">[45]</ref>.</p><p>On the other hand, vehicle dynamics data are user, road, and situation dependent; therefore, the classifiers, based on ML techniques, are strongly tailored to the conditions and situation that are selected for the training phase. In fact, we suggest building a specific model for each driver and for each situation. How to adapt and generalize such a model to other situations is still an open problem worth investigating.</p><p>In our opinion, the most representative works are <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b45">[46]</ref> and <ref type="bibr" target="#b47">[48]</ref>, since they are more strongly related to this paper and have been a source of inspiration to us.</p><p>In particular, the predominant approach is to use static classifiers such as SVMs. Liang et al. developed real-time methods for distraction classification using SVMs <ref type="bibr" target="#b45">[46]</ref> and Bayesian networks <ref type="bibr" target="#b47">[48]</ref>. Their results are comparable to ours since, in <ref type="bibr" target="#b45">[46]</ref>, they achieved the best performance of more than 95%, whereas in <ref type="bibr" target="#b46">[47]</ref>, modeling the dynamic of the driver's behavior using a dynamic Bayesian network (DBN) led to accuracy of about 80.1% on average. However, here, we pointed out that time dependence is highly relevant when predicting the current state of a driver. Our best case was &gt; 96% (considering also the differences in the experiments even if both carried out in a driving simulator), which is absolutely comparable with their best result of 95%. In addition, it is worth noting here that such comparisons can only be indicative since the data sets are different for each case, and the methods and the tools used for training are not the same.</p><p>Similar approaches to driver behavior or estimating the driver's state that model contextual information via DBNs or Markov models can also be found in <ref type="bibr" target="#b16">[17]</ref> and <ref type="bibr" target="#b48">[49]</ref>. Another promising approach can be found in <ref type="bibr" target="#b40">[41]</ref>, where SVMs are used to detect driver distraction based on data captured under real traffic conditions, resulting in accuracy values of 65%-80%. Features are thereby computed from fixed-length time windows, i.e., the amount of context that is incorporated into the classification decision, which is predefined .</p><p>Other classification strategies include the application of FL or NNs <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b36">[37]</ref> and <ref type="bibr" target="#b37">[38]</ref>.</p><p>In addition, here, it is worth mentioning two specific and recent works. In <ref type="bibr" target="#b0">[1]</ref>, Ersal et al. proposed a framework for studying the individual effects of secondary tasks and classifying driving behavior. They showed that the different effects of secondary tasks on different drivers can be studied using a model-based approach. Furthermore, they pointed out that using the model-based framework in conjunction with SVMs systematically helps in classifying the driving behavior as distracted or nondistracted. In details, this SVM classifier is used with a radial-basis neural-network-based modeling framework, developed to characterize the normal driving behavior of a driver when driving without secondary tasks. Such a developed model is then used in a driving scenario with a secondary task to predict the hypothetical actions of the driver: The difference between the predicted normal behavior and the actual distracted behavior gives individual insight into how the secondary tasks affect the driver. When this framework is used together with the SVM, it can help systematically classify normal and distracted driving conditions for each driver. Therefore, what is interesting here is that authors consider a model-based approach, where eye-tracker or gaze data are not present; however, to build the target set, they state: "For the purposes of the classification, all the instances in normal driving are labeled as vigilant, and all the instances in driving with secondary task are labeled as distracted." This seems to be inadequate to our scenarios.</p><p>In <ref type="bibr" target="#b8">[9]</ref>, Woeller et al. introduced a framework and a technique for online driver distraction detection based on modeling contextual information in driving and head tracking data captured during test drives in real traffic. Their approach is based on long short-term memory (LSTM) RNNs, exploiting their ability to capture the long-range temporal evolution of data sequences, to reliably detect inattention and can be seen as a basis for adaptive lane-keeping assistance. The amount of contextual information that is used for classification is thereby learned by the LSTM network itself during the training phase. This LSTM recurrent NNs enable a reliable subject-independent detection of inattention with accuracy of &gt; 95%. Thereby, they claim that LSTM framework significantly outperforms conventional approaches such as SVMs.</p><p>There are two aspects for which this activity is very interesting for us. First, it is based on data collected on real car prototype vehicles, whereas our data are acquired from a driving simulator. Second, they address the distraction caused by IVIS (visual and manual), i.e., similar to ours, obtained by the SURT. Although a real comparison on the same data has not been done, we obtained similar results with the SVM on the same task; therefore, as they claim LSTM outperforms SVM, it would be interesting to try their approach on our data.</p><p>With respect to all these works, our adequate and significant contribution is twofold. The first concerns the comparison of different classification techniques, many of them not considered enough in the literature (e.g., ANFIS). The second mainly concerns a different use of input features for the classifiers. In fact, most of the aforementioned works used eye-tracker information as inputs to the classifier. When using the simulator, it is relatively easy to have eye-tracker data, but in a real-time application in the car, this is extremely difficult since there are several limitations. The first limitation concerns the problem of integration. A dedicated camera and related electronic control unit is needed and has to be integrated into the cockpit of the vehicle (with the associated problems of design and costs). Second, although the information provided by the eye tracker are absolutely useful, nonetheless, they require, for example, that the drivers do not wear sunglasses or glasses, or eye cosmetics because these conditions may negatively affect tracking accuracy <ref type="bibr" target="#b45">[46]</ref>. Moreover, there is the problem of obtaining consistent and reliable sensor data. Eye trackers may lose tracking accuracy when vehicles are traveling on rough roads or when the lighting conditions are variable. Of course, the use of other physiological measures (such as heart rate or respiration rate, skin conductance, etc.) can provide other excellent indicators, but they are even more intrusive and difficult to use in real time in ordinary cars. In this context, our challenge was to provide a DM-based method, which does not require the mandatory use of eye-tracker information (or other physiological measures) for the classification phase and is only based on vehicle dynamic data.</p><p>In addition, this paper has proven an excellent method for personalizing the model. On one side, a "generic" distraction classifier is easier to apply and train; however, on the other side, the performances obtained with the application of a specific model for each driver are definitely better. Perhaps, this is a direction to take into account in the distraction classification field since different drivers respond to external or internal stimuli-which are responsible for distraction-in very different manners, as our data have proven.</p><p>Finally, with respect to our previous research <ref type="bibr" target="#b23">[24]</ref>, we have extended the analysis both in terms of the ML classification techniques investigated (more models) and in terms of the number of subjects for the experiments (more data points). In such a way, the results and the comparisons are much more representative and meaningful.</p><p>Overall, some limitations are present in this paper. First, with reference to the works of Woeller et al. <ref type="bibr" target="#b8">[9]</ref> and Liang et al. <ref type="bibr" target="#b46">[47]</ref>, it would be interesting to explore in more detail the approach based on modeling the dynamics of driver behavior, rather than the static network, to possibly improve the generalization capability of the classifier itself. Therefore, one of the next steps of our research will involve the use of DBNs and/or hidden Markov models. Furthermore, a deeper investigation of the LRNN classifier will be carried out, due to the very promising results achieved in <ref type="bibr" target="#b8">[9]</ref>. In particular, the use of different methods to cluster the data can be considered (e.g., different values for the moving average and to use the window length as an optimization parameter for the classifier), despite the fact that such networks have been extremely long to train. In fact, one key point to consider, as highlighted by <ref type="bibr" target="#b54">[55]</ref>, consists of taking the time history into account. This has been already done in some way in the preprocessing phase of this work, but as future steps, this information can be included already in the features, to benefit all ML approaches.</p><p>A second fundamental aspect concerns the need to collect and then perform tests directly on road data coming from a real prototype car. We have proven that our model can run in real time, but we have assessed it using a driving simulator. In fact, as pointed out in <ref type="bibr" target="#b51">[52]</ref> and <ref type="bibr" target="#b52">[53]</ref>, it is necessary to attempt validation of such research by making comparisons of simulated driving with real road driving. An absolute validation study of driver distractions during real road driving compared with simulated driving would require a comparison of different levels of distractions, using the road characteristics of the real roads in the simulator and running the same subjects under simulated and real conditions. This activity is foreseen as future research for us, and if we could use online data, it would be really interesting to compare our results with those achieved by Woeller et al. In addition, as mentioned in <ref type="bibr" target="#b53">[54]</ref>, Greenberg et al. indicated that motion cueing might have a strong impact on lateral driving performance indicators when disturbances (secondary tasks) are present. This point has to be considered, to verify if the features that we used are meaningful in real driving situations. Currently, we can say that other works, such as <ref type="bibr" target="#b8">[9]</ref>, have already considered and used them.</p><p>Finally, we want to test our distraction classifier in a more diverse set of conditions and scenarios (in simulator or realtraffic); in this paper, we have mainly investigated the motorway, but we want to extend the experimental phase in urban scenarios above all, which is a fundamental step to assessing the generality of our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>This paper has presented an overview of different driver distraction classifiers based on ML techniques. We explored the performances of several models: SVM, FFNN, LRNN, and ANFIS. All have been proven to constitute a viable means of detecting driver inattention, whose cognitive and visual distractions are particular forms. In this paper, we have pointed out the personalization aspect, with one specific model for each subject. With reference to the results shown in Section V, the SVM outperformed all the other classifiers, for which we have obtained accuracy comparable that in the literature. Our major innovative aspect consists of not using information on eye movements or head movements as inputs for the classifier.</p><p>The European cofunded Integrated Project D3COS (http://www.d3cos.eu/), started in March 2011, allows us to investigate at least some of the future activities previously mentioned.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. SURT display on the right part of the driving simulator cockpit.</figDesc><graphic coords="4,317.75,70.13,216.14,170.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>speed [m/s]; • time to collision [s]; • time to lane crossing [s]; • steering angle [deg]; • lateral position [m]; • position of the accelerator pedal [%]; • position of the brake pedal [%].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Performances of different classifiers (see legend). The measure of performance, i.e., the CR that gives the number of correct instances, is shown for each subject and for each type of classifier.</figDesc><graphic coords="8,39.71,70.37,246.14,152.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Performances of different classifiers (see the legend) concerning the SENS parameter, which measures the proportion of actual positives that are correctly identified as such. This is shown for the first ten subjects, to include LRNN as well.</figDesc><graphic coords="8,39.71,276.77,246.14,151.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Performances of different classifiers (see the legend) concerning the SPEC parameter, which measures the proportion of negatives that are correctly identified. This is shown for the first ten subjects, to include LRNN as well.</figDesc><graphic coords="8,39.71,491.33,246.14,152.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE II PERFORMANCES</head><label>II</label><figDesc>OF THE DISTRACTION CLASSIFIER BASED ON SVMS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE III PERFORMANCES</head><label>III</label><figDesc>OF THE DISTRACTION CLASSIFIER BASED ON ANFIS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE IV PERFORMANCES</head><label>IV</label><figDesc>OF THE DISTRACTION CLASSIFIER BASED ON LRNNS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE V AVERAGE</head><label>V</label><figDesc>PERFORMANCE INDEXES FOR THE DIFFERENT DISTRACTION CLASSIFIERS</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the European Commission under the ISI-PADAS project. The Associate Editor for this paper was F.-Y. Wang. F. Tango is with the Department of Electric and Electronic Systems, Fiat Center of Research, Orbassano 10043, Italy</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Modelbased analysis and classification of driver distraction under secondary tasks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ersal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J A</forename><surname>Fuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tsimhoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Fathy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="692" to="701" />
			<date type="published" when="2010-09">Sep. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Driver distraction and driver inattention: Definition, relationship and taxonomy</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Regan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hallet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Accid. Anal. Prev. J</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1771" to="1781" />
			<date type="published" when="2011-09">Sep. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The role of driver inattention in crashes: New statistics from the 1995 crashworthiness data system</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Knipling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 40th AAAM</title>
		<meeting>40th AAAM<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="377" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The 100-car naturalistic driving study, phase II-results of the 100-car field experiment</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Dingus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Klauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Neale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sudweeks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hankey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">R</forename><surname>Doerzaph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jermeland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Knipling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Transp., Nat. Highway Traffic Safety Admin</title>
		<imprint>
			<biblScope unit="volume">810</biblScope>
			<biblScope unit="page">593</biblScope>
			<date type="published" when="2006">2006</date>
			<pubPlace>Washington, DC, USA</pubPlace>
		</imprint>
	</monogr>
	<note>HS</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tri-level study of the causes of traffic accidents: Final report</title>
		<author>
			<persName><forename type="first">J</forename><surname>Treat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Tumbas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shinar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Hume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Stansifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Castellan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Federal Highway Administration</title>
		<meeting><address><addrLine>US DOT, Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1979">1979</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Driver inattention monitoring system for intelligent vehicles: A review</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Uchimura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Murayama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="596" to="614" />
			<date type="published" when="2011-06">Jun. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Driver distraction: A review of the current state-ofknowledge?</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Ranney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NHTSA</title>
		<imprint>
			<biblScope unit="volume">810</biblScope>
			<biblScope unit="issue">704</biblScope>
			<date type="published" when="2008-04">Apr. 2008</date>
			<pubPlace>Washington, DC, USA, DOT</pubPlace>
		</imprint>
	</monogr>
	<note>HS</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Driver distraction in commercial vehicle operations</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Hanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Hickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bocanegr</surname></persName>
		</author>
		<idno>FMCSA-RRR-09-042</idno>
	</analytic>
	<monogr>
		<title level="j">U.S. Dept. Transportation</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<pubPlace>Washington, DC, USA, Rep</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Online driver distraction detection using long short-term memory</title>
		<author>
			<persName><forename type="first">M</forename><surname>Woeller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blaschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schhindl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Faerber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Trefflich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="574" to="582" />
			<date type="published" when="2011-06">Jun. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Driver inattention and highway safety</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Sussman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Madnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Walter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transp. Res. Rec</title>
		<imprint>
			<biblScope unit="volume">1047</biblScope>
			<biblScope unit="page" from="40" to="48" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The role of driver inattention in crashes; New statistics from the 1995 crashworthiness data system (CDS)</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Knipling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 40th Annu</title>
		<meeting>40th Annu</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="377" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The Role of Driver Distraction in Traffic Crashes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Stutts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Reinfurt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Staplin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Rodgman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>AAA Foundation Traffic Safety</publisher>
			<pubPlace>Washington, DC, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Driver distraction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Caird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Dewar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Factors in Traffic Safety</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Dewar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Olsen</surname></persName>
		</editor>
		<meeting><address><addrLine>Tucson, AZ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Lawyers &amp; Judges Publ</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="195" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mobile (cellular) phone use and driving: A critical review of research methodology</title>
		<author>
			<persName><forename type="first">D</forename><surname>Haigney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Westerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ergonomics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="132" to="143" />
			<date type="published" when="2001-02">Feb. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Introduction to Data Mining</title>
		<author>
			<persName><forename type="first">P.-N</forename><surname>Tan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Boston, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brunak</surname></persName>
		</author>
		<title level="m">Bioinformatics: The Machine Learning Approach</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Modeling and prediction of human behavior</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="229" to="242" />
			<date type="published" when="1999-01">Jan. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning algorithm of environmental recognition in driving vehicle</title>
		<author>
			<persName><forename type="first">L</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Takeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="917" to="925" />
			<date type="published" when="1995-06">Jun. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Evaluation of distraction in a driver-vehicleenvironment framework: An application of different data-mining techniques</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tango</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th ICDM</title>
		<meeting>9th ICDM<address><addrLine>Leipzig, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="176" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Driver distraction based lane-keeping assistance</title>
		<author>
			<persName><forename type="first">C</forename><surname>Blaschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Breyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Färber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Limbacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transp. Res. Part F, Traffic Psychol. Behav</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="288" to="299" />
			<date type="published" when="2009-07">Jul. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Identification of real-time diagnostic measures of visual distraction with an automatic eye-tracking system</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R H</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Witt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum. Factors</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="805" to="821" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Attentional competition between tasks and its implications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hoel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaffard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Van Elslande</surname></persName>
		</author>
		<ptr target="http://www.conference2010.humanist-vce.eu/" />
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Human Centred Des</title>
		<meeting>Eur. Conf. Human Centred Des</meeting>
		<imprint>
			<date type="published" when="2010">Apr. 29 and 30. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Defining driver distraction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Regan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Driver Distraction: Theory, Effects</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Mitigation</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Regan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><surname>Young</surname></persName>
		</editor>
		<meeting><address><addrLine>Boca Raton, FL, USA</addrLine></address></meeting>
		<imprint>
			<publisher>CRC</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Non-intrusive detection of driver distraction using machine learning algorithms</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tango</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Minin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Montanari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 19th ECAI</title>
		<meeting>19th ECAI<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">Aug. 16-19, 2010</date>
			<biblScope unit="page" from="157" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The Nature of Statistical Learning Theory</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">An Introduction to Support Vector Machines and Other Kernel-Based Learning Methods</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Cambridge Univ. Press</publisher>
			<pubPlace>Cambridge, U.K.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Applications of support vector machines for pattern recognition: A survey</title>
		<author>
			<persName><forename type="first">H</forename><surname>Byun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st Int. Workshop Pattern Recog. SVM</title>
		<meeting>1st Int. Workshop Pattern Recog. SVM<address><addrLine>Niagara Falls, ON, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="213" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Neural Networks: A Comprehensive Foundation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Haykin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Finding structure in time</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognit. Sci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="211" />
			<date type="published" when="1990-03">Mar. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<title level="m">Machine Learning</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bezdec</surname></persName>
		</author>
		<title level="m">Pattern Recognition with, Fuzzy Objective Function Algorithms</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Plenum</publisher>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Introduction to Fuzzy Arithmetic</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Gupta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Reinhold</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">ANFIS: Adaptive-network-based fuzzy inference system</title>
		<author>
			<persName><forename type="first">J.-S</forename><forename type="middle">R</forename><surname>Jang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="665" to="685" />
			<date type="published" when="1993-06">May/Jun. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Industrial Applications of Fuzzy Control</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sugeno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Elsevier</publisher>
			<pubPlace>Amsterdam, The Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multiple resources and performance prediction</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Wickens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theor. Issues Ergonom. Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="177" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The lane change task as a tool for driver distraction evaluation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mattes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Quality of Work and Products in Enterprises of the Future</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Strasser</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bubb</surname></persName>
		</editor>
		<meeting><address><addrLine>Stuttgart, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Ergonomia Verlag</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Driver distraction a review of the literature</title>
		<author>
			<persName><forename type="first">K</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Regan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Accident Research Center, Monash Univ</title>
		<imprint>
			<biblScope unit="volume">206</biblScope>
			<date type="published" when="2003-11">Nov. 2003</date>
			<pubPlace>Victoria, Australia</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Driver cognitive workload estimation: A data-driven perspective</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Owechko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intell</title>
		<meeting>IEEE Intell<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="642" to="647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Automation effects on driver&apos;s behaviour when integrating a PADAS and a distraction classifier</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tango</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Aras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Pietquin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. HCI</title>
		<meeting>HCI<address><addrLine>Orlando, FL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09-14">Jul. 9-14, 2011</date>
			<biblScope unit="page" from="503" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Batch reinforcement learning for optimizing driving assistance strategies</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tango</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Aras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Pietquin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS Conf</title>
		<meeting>NIPS Conf<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">Dec. 10 and 11. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Driver cognitive distraction detection: Feature estimation and implementation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Kutila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jokela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mäkinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Viitanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Markkula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Victor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Inst. Mech. Eng., Part D, J. Automobile Eng</title>
		<imprint>
			<biblScope unit="volume">221</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1027" to="1040" />
			<date type="published" when="2007-09">Sep. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The feasibility of detecting phone-use related driver distraction</title>
		<author>
			<persName><forename type="first">D</forename><surname>De Waard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Brookhuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hernandez-Gress</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Veh. Des</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="85" to="95" />
			<date type="published" when="2003-08">Aug. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A visual approach for driver inattention detection</title>
		<author>
			<persName><forename type="first">T</forename><surname>D'orazio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guaragnella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Distante</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2341" to="2355" />
			<date type="published" when="2007-08">Aug. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A probabilistic framework for modeling and real-time monitoring human fatigue</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Looney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. A, Syst., Humans</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="862" to="875" />
			<date type="published" when="2006-09">Sep. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Detecting stress during real-world driving tasks using physiological sensors</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Healey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="156" to="166" />
			<date type="published" when="2005-06">Jun. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Real-time detection of driver cognitive distraction using support vector machines</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="340" to="350" />
			<date type="published" when="2007-06">Jun. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Nonintrusive detection of driver cognitive distraction in real time using Bayesian networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Reyes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transp. Res. Rec., J. Transp. Res. Board</title>
		<imprint>
			<biblScope unit="volume">2018</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Driver Cognitive Distraction Detection Using Eye Movements</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="285" to="300" />
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Prediction of human driving behavior using dynamic Bayesian networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kumagai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Akamatsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEICE Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="857" to="860" />
			<date type="published" when="2006-02">Feb. 2006</date>
		</imprint>
	</monogr>
	<note>E89-D</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Report on the influence of relevant factors (characteristics, state, situation) on driving behavior and driving errors</title>
		<author>
			<persName><forename type="first">L</forename><surname>Minin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mayenobe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Briest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Vega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ó</forename><surname>Martín</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Muhrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vollrath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Montanari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tango</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Heers</surname></persName>
		</author>
		<idno>ISI-PADAS EU Project</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>Internal Project Deliverable</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Gaze fixation system for the evaluation of driver distractions induced by IVIS</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jiménez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Bergasa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nuevo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Daza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hernández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1167" to="1178" />
			<date type="published" when="2012-09">Sep. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Detecting driver sleepiness</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sandberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PhD. dissertation, Dept. Appl. Mech. Chalmers Univ. Technol</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<pubPlace>Göteborg, Sweden</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Realtime system for monitoring driver vigilance</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Bergasa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nuevo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Sotelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="77" />
			<date type="published" when="2006-03">Mar. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">The effect of lateral motion cues during simulated driving</title>
		<author>
			<persName><forename type="first">J</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Artz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cathey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DSC North Amer</title>
		<meeting>DSC North Amer<address><addrLine>Dearborn, MI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>CD-ROM</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">How do distracted and normal driving differ: An analysis of the ACAS naturalistic driving data</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Oberholtzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Eoh</surname></persName>
		</author>
		<idno>UMTRI-2006-35</idno>
	</analytic>
	<monogr>
		<title level="j">Univ. Michigan Transp. Res. Inst</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>Arbor, MI, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Distraction in commercial trucks and buses: Assessing prevalence and risk in conjunction with crashes and near-crashes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Hickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Hanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bocanegra</surname></persName>
		</author>
		<idno>RRR-10-049</idno>
	</analytic>
	<monogr>
		<title level="j">U.S. Dept. Transp</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<pubPlace>Washington, DC, USA, FMCSA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
