<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Noise Reduction in Oversampled Filter Banks Using Predictive Quantization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Helmut</forename><surname>BÃ¶lcskei</surname></persName>
							<email>bolcskei@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Systems Laboratory</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305-9510</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Communications and Radio Frequency Engineering</orgName>
								<orgName type="institution">Vienna University of Technology</orgName>
								<address>
									<postCode>A-1040</postCode>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Franz</forename><surname>Hlawatsch</surname></persName>
							<email>fhlawats@email.tuwien.ac.at</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Systems Laboratory</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305-9510</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute of Communications and Radio-Frequency Engineering</orgName>
								<orgName type="institution">Vienna University of Technology</orgName>
								<address>
									<postCode>A-1040</postCode>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Noise Reduction in Oversampled Filter Banks Using Predictive Quantization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F4AC06F78F00059BC15985C8AE5F3568</idno>
					<note type="submission">received April 2, 1998; revised December 15, 1999.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Filter banks</term>
					<term>frame theory</term>
					<term>linear prediction</term>
					<term>noise reduction</term>
					<term>noise shaping</term>
					<term>oversampling</term>
					<term>quantization</term>
					<term>ratedistortion theory</term>
					<term>sigma-delta converter</term>
					<term>subband coding</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce two methods for quantization noise reduction in oversampled filter banks. These methods are based on predictive quantization (noise shaping or linear prediction). It is demonstrated that oversampled noise shaping or linear predictive subband coders are well suited for subband coding applications where, for technological or other reasons, low-resolution quantizers have to be used. In this case, oversampling combined with noise shaping or linear prediction improves the effective resolution of the subband coder at the expense of increased rate. Simulation results are provided to assess the achievable quantization noise reduction and resolution enhancement, and to investigate the rate-distortion properties of the proposed methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION AND OUTLINE</head><p>R ECENTLY, oversampled filter banks (FBs) have received increased attention <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b9">[10]</ref>, which is mainly due to their noise reducing properties and increased design freedom (i.e., nonuniqueness of the perfect reconstruction synthesis FB for a given analysis FB). In this paper, we introduce two techniques for quantization noise reduction in oversampled FBs. These techniques are based on predictive quantization, specifically, on noise prediction (noise shaping) and signal prediction. The corresponding oversampled subband coders can be viewed as extensions of oversampled predictive A/D converters <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b12">[13]</ref> and of critically sampled predictive subband coders <ref type="bibr" target="#b13">[14]</ref>- <ref type="bibr" target="#b15">[16]</ref>.</p><p>We show that predictive quantization in oversampled FBs yields significant noise reduction at the cost of increased bit rate. Hence, oversampled predictive subband coders allow to trade bit rate for quantizer accuracy. They are, therefore, well suited for subband coding applications where, for technological or other reasons, quantizers with low accuracy (even single-bit) have to be used. The practical advantages of using low-resolution quantizers at the cost of increased rate are indicated by the popular sigma-delta techniques <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b12">[13]</ref>. Using low-resolution quantizers increases circuit speed and reduces circuit complexity. 1-bit codewords, for example, eliminate the need for word framing <ref type="bibr" target="#b13">[14]</ref>. We, furthermore, study rate-distortion properties of oversampled predictive subband coders. Specifically, we demonstrate by means of simulation results that oversampled predictive subband coders are inferior to critically sampled subband coders from a pure rate-distortion point of view. (An information-theoretic treatment of the rate-distortion properties of one specific class of redundant representations, namely, frames of sinc functions or equivalently oversampled A/D conversion, can be found in <ref type="bibr" target="#b16">[17]</ref> and <ref type="bibr" target="#b17">[18]</ref>.)</p><p>As a basis for our development of predictive quantization in oversampled FBs, we provide a subspace-based noise analysis of oversampled FBs. In particular, it is proven that the perfect reconstruction (PR) synthesis FB corresponding to the parapseudo-inverse of the analysis polyphase matrix minimizes the reconstruction error variance resulting from uncorrelated white noise in the subbands. This result is then generalized to include correlated and/or colored subband noise signals. The fact that other PR synthesis FBs lead to an additional reconstruction error corresponds to a fundamental tradeoff between noise reduction and design freedom.</p><p>The paper is organized as follows. In Section II, we develop a subspace-based stochastic noise analysis of oversampled FBs and we calculate the PR synthesis FB minimizing the reconstruction error due to noise. Section III introduces oversampled noise shaping (noise predictive) subband coders. We calculate the optimum noise shaping system and provide simulation results demonstrating the achievable noise reduction. Oversampled signal predictive subband coders are introduced in Section IV. The optimum multichannel prediction system is calculated and the achievable resolution enhancement is demonstrated by simulation results. Finally, Section V concludes our presentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. SUBSPACE-BASED NOISE ANALYSIS OF OVERSAMPLED FBS</head><p>In this section, we provide a subspace-based noise analysis of oversampled FBs and demonstrate that oversampled FBs have noise-reducing properties. We start with a brief review of frame theory on which some of our results will be based, followed by a brief discussion of oversampled A/D conversion where the subspaces involved have a particularly simple structure. We then turn to oversampled FBs and study the reconstruction error caused by noisy subband signals. Bounds on the error variance are derived, and the dependence of the error variance on the frame bounds and oversampling factor is discussed. We finally calculate the PR synthesis FB minimizing the reconstruction error variance due to noise and describe a tradeoff between noise reduction and design freedom in oversampled FBs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Brief Review of Frame Theory</head><p>The theory of frames <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref> is a powerful tool for the study of redundant (overcomplete) signal expansions. A function set with is called a frame for if <ref type="foot" target="#foot_0">1</ref>(1)</p><p>with the frame bounds and . If is a frame for , any signal can be decomposed as <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref> Here, where is the inverse of the frame operator that is defined as The function set is again a frame (the "dual" frame), with frame bounds and . The frame bounds determine important numerical properties of the frame <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref>. A frame is called snug if and tight if . For a tight frame we have (where is the identity operator on ), and hence there is simply .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Noise Analysis and Design Freedom in Oversampled A/D Conversion</head><p>As a motivation of our noise analysis of oversampled FBs (to be presented in Section II-C), this subsection provides a frametheoretic, subspace-based interpretation of noise reduction in oversampled A/D conversion.</p><p>We shall first interpret A/D conversion as a frame expansion <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref>. From the sampling theorem <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, we know that a band-limited continuous-time signal with bandwidth can be perfectly recovered from its samples , where with , i.e.,</p><p>Here, and is the oversampling factor. The samples can be written as , where . Thus, (2) can be rewritten as <ref type="bibr" target="#b2">(3)</ref> (where the superscript 3 stands for complex conjugation) denotes the inner product of the functions x(t) and y(t), and kxk = hx; xi. for -band-limited, we can conclude that is a tight frame for the space of -band-limited functions, with frame bounds . Hence, the dual frame is given by . This shows that the interpolation formula (2) or (3) corresponds to a reconstruction using the dual frame. Moreover, it is easily checked that for critical sampling ( or ) the are orthogonal to each other, i.e., . In the oversampled case, the set is redundant. The reconstruction of from its samples can alternatively be interpreted as the application of a low-pass filter to the signal . In the case of critical sampling (i.e.,</p><p>), the ideal low-pass filter of bandwidth is the only filter that provides PR of [see Fig. <ref type="figure" target="#fig_0">1(a)</ref>]. In the oversampled case (i.e.,</p><p>), an infinite number of reconstruction low-pass filters will provide PR [see Fig. <ref type="figure" target="#fig_0">1(b)]</ref>; the resulting design freedom <ref type="bibr" target="#b11">[12]</ref> can be exploited for designing reconstruction filters with desirable filter characteristics like, e.g., rolloff.</p><p>Assuming quantization errors modeled as additive white noise, with the quantization error variance per sample held constant, and employing an ideal low-pass reconstruction filter with bandwidth , it follows from Fig. <ref type="figure" target="#fig_0">1</ref> that the reconstruction error variance in the oversampled case is given by <ref type="bibr" target="#b11">[12]</ref> where is the reconstruction error variance in the critically sampled case and is the oversampling factor. Any other reconstruction filter providing PR must pass some of the noise outside the signal band [see Fig. <ref type="figure" target="#fig_0">1</ref>(b)] and will thus lead to a larger reconstruction error variance. In this sense, there exists a tradeoff between noise reduction and design freedom in oversampled A/D conversion. Practically desirable (or realizable) reconstruction filters (i.e., filters with rolloff) lead to an additional reconstruction error.</p><p>We shall finally provide a frame-theoretic, subspace-based interpretation of these well-known facts. For oversampling factor , the range space of the analysis (sampling) operator is the space of discrete-time functions bandlimited to the interval . Reconstruction of using the ideal low-pass filter of bandwidth (or, equivalently, in the discrete-time domain, bandwidth ) corresponds to an orthogonal projection onto ; on the other hand, we recall that it also corresponds to a reconstruction using the dual frame . Hence, it follows that reconstruction using the dual frame involves an orthogonal projection onto . This projection suppresses the noise component lying in the orthogonal complement of the range space (corresponding to the out-of-band region</p><p>). This intuitively explains why reconstruction using the dual frame leads to minimum reconstruction error.</p><p>In Section II-C, we shall see that a similar tradeoff between noise reduction and design freedom arises in oversampled FBs. The analysis is less intuitive there, however, since the signal spaces and do not correspond to simple frequency bands.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Noise Analysis and Design Freedom in Oversampled FBs</head><p>After this discussion of oversampled A/D conversion, we now turn to oversampled FBs. In this subsection, we will provide a stochastic noise analysis of oversampled FBs and describe a tradeoff between noise reduction and design freedom. We begin with a brief review of oversampled FBs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Oversampled FBs:</head><p>We consider an -channel FB (see Fig. <ref type="figure" target="#fig_1">2</ref>) with subsampling by the integer factor in each channel. The transfer functions of the analysis and synthesis filters are and , with corresponding impulse responses and , respectively. <ref type="foot" target="#foot_2">3</ref> In a critically sampled (or maximally decimated) FB we have and thus the subband signals contain exactly as many samples per unit of time as the input signal . In the oversampled case , the subband signals are redundant in that they contain more samples per unit of time than the input signal. (In a finite-dimensional setting, oversampling would correspond to representing an vector using expansion coefficients.)</p><p>The analysis polyphase matrix is defined as , where <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref> Similarly, the synthesis polyphase matrix is defined as</p><p>, where</p><p>We have <ref type="bibr" target="#b3">(4)</ref> with and For an FB with PR and zero delay, we have where and denote the input and reconstructed signal, respectively. FB analysis and synthesis can here be interpreted as a signal expansion <ref type="bibr" target="#b23">[24]</ref>- <ref type="bibr" target="#b25">[26]</ref>. The subband signals can be written as the inner products with Furthermore, with the PR property, we have with This shows that the FB corresponds to an expansion of the input signal into the function set with and . Critically sampled FBs correspond to orthogonal or biorthogonal signal expansions <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b24">[25]</ref>, whereas oversampled FBs correspond to redundant (overcomplete) expansions <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b27">[28]</ref>. If is a frame for , we say that the FB provides a frame expansion. The frame bounds and or, equivalently, and determine important numerical properties of the FB <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b0">[1]</ref>. The subband signals of an FB providing a frame expansion satisfy [cf. <ref type="bibr" target="#b0">(1)</ref>]</p><formula xml:id="formula_1">with</formula><p>. It is shown in <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b8">[9]</ref> that the (tightest possible) frame bounds and of an FB providing a frame expansion are given by the essential infimum and supremum, respectively, of the eigenvalues of the matrix <ref type="foot" target="#foot_3">4</ref>(5)</p><p>2) Design Freedom in Oversampled FBs: An oversampled FB satisfies the PR condition if and only if <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref> (6</p><formula xml:id="formula_2">)</formula><p>where is the identity matrix. For analysis polyphase matrix given, the PR synthesis polyphase matrix is not uniquely determined: any solution of (6) can be written as <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref> (assuming rank a.e.)</p><p>Here, is the para-pseudo-inverse of , which is a particular solution of (6) defined as<ref type="foot" target="#foot_4">5</ref>  <ref type="bibr" target="#b7">(8)</ref> and is an matrix with arbitrary elements satisfying . Choosing the PR synthesis FB according to corresponds to reconstruction using the dual frame <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref>.</p><p>This nonuniqueness of the PR synthesis FB corresponds to an increased design freedom (as compared to critically sampled FBs) <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref> that is a major advantage of oversampled FBs. Certain PR synthesis FBs have desirable properties (such as good frequency selectivity, linear phase, etc.) that may not be shared by the PR synthesis FB corresponding to the para-pseudo-inverse . Such properties are especially important in coding applications where the synthesis filters determine the perceptual impact of quantization errors. In the oversampled case, therefore, we can impose additional properties (besides PR) on the synthesis filters and perform an optimization over all PR synthesis FBs. Using the parameterization <ref type="bibr" target="#b6">(7)</ref> or related ones <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref>, this can be done by means of an unconstrained optimization procedure since PR need not be incorporated via a side constraint. We note that this increased design freedom in oversampled FBs is similar to that in oversampled A/D conversion (see Section II-B). In Section II-C4, we shall show that again there exists a tradeoff between noise reduction and design freedom.</p><p>3) Noise Analysis in Oversampled FBs: We next investigate the sensitivity of oversampled FBs to (quantization) noise added to the subband signals . The -dimensional vector noise process is assumed wide-sense stationary and zero-mean. The power spectral matrix of is with the autocorrelation matrix , where denotes the expectation operator.</p><p>It is convenient to redraw the FB in the polyphase domain as shown in Fig. <ref type="figure" target="#fig_3">3</ref>  <ref type="bibr" target="#b23">[24]</ref>. Here  Hence, the reconstruction error vector is given by</p><p>In the time domain, the reconstruction error is wide-sense stationary and zero-mean, with power spectral matrix <ref type="bibr" target="#b23">[24]</ref> and variance 6   In particular, for uncorrelated white noise signals (i.e., and are uncorrelated for and also for ) with identical variances , i.e., and , the reconstruction error variance simplifies to <ref type="bibr" target="#b8">(9)</ref> This result permits an interesting frame-theoretic interpretation. Assuming reconstruction using the dual frame, i.e., [see ( <ref type="formula">8</ref>)], and using with denoting the eigenvalues of the matrix it follows from [cf. <ref type="bibr" target="#b4">(5)</ref>] that <ref type="bibr" target="#b9">(10)</ref> i.e., the reconstruction error variance is bounded in terms of the frame bounds , , and the subband noise variance . For normalized analysis filters, i.e., for , it can be shown <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref> that where is the oversampling factor. For a paraunitary 6 Here, Trf1g denotes the trace of a matrix.</p><p>FB (corresponding to a tight frame expansion <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref>) with normalized analysis filters, we have <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref> and (10) yields <ref type="bibr" target="#b10">(11)</ref> Similarly, for an FB corresponding to a snug frame, and thus</p><p>. Hence, paraunitary FBs or FBs providing snug frame expansions are desirable since it is guaranteed that small errors in the subband signals will result in small reconstruction errors. This is important in signal coding applications involving quantization errors and in signal processing applications involving intentional modifications of the subband signals.</p><p>Since in the critically sampled case , ( <ref type="formula">11</ref>) can be rewritten as Thus, for a paraunitary FB, the reconstruction error variance is inversely proportional to the oversampling factor , which means that more oversampling entails better noise reduction. Such a " behavior" has been observed in Section II-B for oversampled A/D conversion, which was shown to correspond to a tight frame expansion. Since also a paraunitary FB corresponds to a tight frame expansion, its behavior does not come as a surprise. A behavior has furthermore been observed for tight frames in finite-dimensional spaces <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b28">[29]</ref> and for reconstruction from a finite set of Weyl-Heisenberg (Gabor) or wavelet coefficients <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b29">[30]</ref>. Under additional conditions, a behavior has been demonstrated for Weyl-Heisenberg frames in <ref type="bibr" target="#b29">[30]</ref>. In <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b30">[31]</ref>- <ref type="bibr" target="#b33">[34]</ref>, based on a deterministic quantization noise model, a nonlinear set-theoretic estimation method is used to achieve a behavior for frames of sinc functions (A/D conversion) and for Weyl-Heisenberg frames. In Sections III and IV, we shall propose oversampled predictive subband coders that are based on a stochastic quantization noise model. These subband coders also achieve a performance and in some cases can do even better.</p><p>Unfortunately, the assumption of uncorrelated white noise is not justified for . For arbitrary (possibly correlated and/or nonwhite) noise with power spectral matrix , a noise whitening approach can be employed. Using the factorization (which is guaranteed to exist <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>), it is easily seen that the system depicted in Fig. <ref type="figure" target="#fig_3">3</ref> is equivalent to a system with noise power spectral matrix (corresponding to uncorrelated white noise with equal variances in all channels) if and are replaced by and respectively. The double inequality <ref type="bibr" target="#b9">(10)</ref> continues to hold if the frame bounds in <ref type="bibr" target="#b9">(10)</ref> are replaced by the frame bounds of the FB . Similarly, <ref type="bibr" target="#b10">(11)</ref> continues to hold if is paraunitary. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Noise Reduction Versus Design Freedom in Oversampled FBs:</head><p>We shall now establish a subspace-based interpretation of noise reduction in oversampled FBs that is analogous to the interpretation given for oversampled A/D conversion in Section II-B. Let us define the FB analysis operator that assigns to each input signal the subband vector signal . The orthogonal projection operator on the range space of is given by <ref type="bibr" target="#b20">[21]</ref>. Since the analysis operator , its adjoint , and the frame operator are represented by the matrices , , and</p><p>, respectively <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref>, the matrix representation of is Similarly, is the matrix representation of the orthogonal projection operator on the orthogonal complement of (see Fig. <ref type="figure" target="#fig_4">4</ref>).</p><p>Let us consider an oversampled FB with chosen as in (7) <ref type="bibr" target="#b11">(12)</ref> so that PR is satisfied. With <ref type="bibr" target="#b11">(12)</ref> ), it follows from the orthogonality of the spaces and that the error components and are uncorrelated <ref type="bibr" target="#b36">[37]</ref>. Hence, their variances, denoted, respectively, and , can simply be added to yield the overall reconstruction error variance <ref type="bibr" target="#b13">(14)</ref> This relation leads to the following result.</p><p>Proposition 1: For an oversampled PR FB with uncorrelated and white subband noise signals with equal variance in all channels, the synthesis FB minimizing the reconstruction error variance among all PR synthesis FBs (i.e., among all satisfying ) is the para-pseudo-inverse of , and the resulting minimum reconstruction error variance is <ref type="bibr" target="#b14">(15)</ref> Proof: According to (13), the variance component does not depend on the parameter matrix , and thus it does not depend on the particular chosen. On the other hand, the "orthogonal" variance component in ( <ref type="formula">13</ref>) and ( <ref type="formula">14</ref>) is an additional variance that is zero for all if and only if , which yields . The expression for in <ref type="bibr" target="#b14">(15)</ref> is obtained from (9).</p><p>Hence, using will suppress all noise components orthogonal to the range space , whereas any other PR synthesis FB (possibly with desirable properties such as improved frequency selectivity, etc.) will lead to an additional error variance since also noise components orthogonal to are passed to the FB output. Thus, similar to oversampled A/D conversion (see Section II-B), there exists a tradeoff between noise reduction and design freedom. Even though in the FB case the spaces and no longer correspond to frequency bands, the same interpretations and conclusions as in oversampled A/D conversion apply.</p><p>In the case of correlated and/or colored noise signals, the above results continue to hold if the matrices and are replaced by and respectively (cf. Section II-C3). In particular, for a given analysis FB with polyphase matrix and for a given noise power spectral matrix , the synthesis FB minimizing the reconstruction error variance is defined by [cf. <ref type="bibr" target="#b7">(8)</ref>] which yields</p><p>We finally note that the tradeoff between noise reduction and design freedom discussed above is not restricted to redundant shift-invariant signal expansions (such as oversampled A/D conversion and oversampled FBs) but is inherent in general redundant representations. In general, more oversampling tends to result in better noise reduction since the range space -and thus also the fixed noise component -becomes "smaller."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. OVERSAMPLED NOISE-SHAPING (NOISE PREDICTIVE) SUBBAND CODERS</head><p>This section introduces a method for noise reduction in oversampled FBs that is based on noise prediction. The resulting noise-shaping (noise-predictive) subband coders can be viewed as extensions of oversampled noise-shaping A/D converters, which will be reviewed first.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Oversampled Noise-Shaping A/D Converters</head><p>Noise feedback coding has found widespread use in A/D conversion <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b13">[14]</ref>. A noise-shaping coder, modeled as an entirely discrete-time system <ref type="bibr" target="#b10">[11]</ref>, is shown in Fig. <ref type="figure" target="#fig_5">5</ref>. Here, denotes the -transform of the input signal (the oversampled version of the analog signal ) and is the noise-shaping filter of order . The quantization noise estimate is obtained as where is the -transform of the quantization noise sequence . The noise-shaping system is designed such that optimally estimates or predicts the in-band component of the current quantization noise sample based on the past noise samples <ref type="bibr" target="#b10">[11]</ref>. In this sense, noise-shaping coders can be interpreted as noise-predictive coders. Equivalently, the goal is to minimize the in-band component of , i.e., the component lying in , the range space of the analysis/sampling operator from Section II-B. The out-of-band component (lying in</p><p>) is subsequently attenuated by the reconstruction low-pass filter in the decoder (not shown in Fig. <ref type="figure" target="#fig_5">5</ref>).</p><p>The signal presented to the quantizer is , which results in an effective noise reduction while leaving the A/D converter's dynamic range unchanged (this is fundamentally different from a signal predictive coder discussed in Section IV-A). Since the in-band noise power is reduced relative to the quantization noise power of the A/D converter, it is possible to increase the quantization step size and thereby reduce the overall converter complexity. From Fig. <ref type="figure" target="#fig_5">5</ref>, it follows that the coder output signal is given by or, equivalently, . Note that is not affected by the noise-shaping system, whereas is passed through . Hence, the reconstruction error is We now provide a frame-theoretic, subspace-based interpretation of noise shaping which will motivate our results in Section III-B. In a noise-shaping coder, the quantization noise is effectively moved to a high-frequency band which is then attenuated by the low-pass reconstruction filter (see Fig. <ref type="figure">6</ref>). Equivalently (recall from Section II-B that the signal band corresponds to the range space of the analysis/sampling operator ), the quantization noise is moved to the orthogonal complement of . Reconstruction using the dual frame, i.e., ideal low-pass filtering with minimum bandwidth, then performs an orthogonal projection onto that suppresses all noise components in <ref type="foot" target="#foot_5">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Noise Shaping in Oversampled FBs</head><p>We recall from Section II-C that the subband signals in an oversampled PR FB constitute a redundant representation of the FB input signal , with the range space of the FB analysis operator being a subspace of . This analogy to oversampled A/D converters again suggests the application of noise shaping. The goal is to exploit the redundancy of the subband signal samples in order to push the quantization noise to the orthogonal complement space . The noise-shaping subband coders introduced here combine the advantages of subband coding with those of noise or error feedback coding.</p><p>1) The Noise-Shaping Subband Coder: We propose a multiinput multi-output (MIMO) noise-shaping system, represented by an transfer matrix , that is cradled between the analysis FB and the synthesis FB as depicted in Fig. <ref type="figure" target="#fig_6">7</ref>. The quantization noise is fed back through the noise-shaping system to yield the quantization noise estimate , which is then subtracted from the subband signal vector . Assuming an FB with PR (i.e.,</p><p>), the reconstructed signal is obtained as It follows that the reconstruction error equals filtered by and then by the synthesis FB <ref type="bibr" target="#b15">(16)</ref> Hence, the power spectral density matrix of is <ref type="bibr" target="#b23">[24]</ref> Fig. <ref type="figure">6</ref>. Typical noise-shaping filter. and the reconstruction error variance is <ref type="bibr" target="#b16">(17)</ref> The optimum noise-shaping system minimizes . Without further constraints, the noise could be completely removed ( ) using . Indeed, inserting this into <ref type="bibr" target="#b15">(16)</ref>, it follows with that . In the case of reconstruction using the dual frame, i.e., , this ideal noise shaper is the orthogonal projection operator on the orthogonal complement of the analysis FB's range space (see Section II-C4). Thus, the ideal noise shaper projects the noise onto , and the projected noise is then suppressed by the synthesis FB that involves an orthogonal projection onto . This is similar to oversampled A/D conversion where the theoretically ideal noise-shaping filter was seen to be an ideal high-pass (projection) filter.</p><p>Unfortunately, this ideal noise shaper is inadmissible since it is not causal and therefore cannot operate in a feedback loop. Hence, we hereafter constrain to be a causal finite-impulse response (FIR) MIMO system of the form <ref type="bibr" target="#b17">(18)</ref> resulting in a strictly causal feedback loop system Here denotes the order of the noise-shaping system. The quantization noise estimate now becomes</p><p>The purpose of the noise-shaping system is to estimate or predict the quantization noise component that will be passed by the synthesis FB , based on the past noise samples . In the case of reconstruction using the dual frame, i.e., , the synthesis FB passes everything in the range space . In this case, the noise-shaping system has to predict the in-range component of , i.e., the quantization noise component in . Equivalently, the optimum noise-shaping system pushes the quantization noise to the orthogonal complement space that is subsequently suppressed by . 2) Calculation of the Optimum Noise-Shaping System: We now derive the optimal noise-shaping system, i.e., the matrices minimizing the reconstruction error variance in <ref type="bibr" target="#b16">(17)</ref>. We shall first assume uncorrelated white quantization noise with equal noise variance in all channels, i.e., and . Inserting <ref type="bibr" target="#b17">(18)</ref> and ( <ref type="formula">4</ref>) into <ref type="bibr" target="#b16">(17)</ref>, it follows after lengthy but straightforward manipulations that <ref type="bibr" target="#b18">(19)</ref> with the matrices that satisfy . Here, the FB has been assumed real-valued and we recall that was defined in (4). Setting for and using the matrix derivative rules (see <ref type="bibr" target="#b37">[38,</ref><ref type="bibr">Sec. 5</ref> </p><p>This linear system of equations has block Toeplitz form and can be solved efficiently using the multichannel Levinson recursion <ref type="bibr" target="#b38">[39]</ref>. The maximum possible system order is determined by the rank of the block matrix in <ref type="bibr" target="#b20">(21)</ref>, which, in turn, depends on the synthesis filters. Inserting ( <ref type="formula">20</ref>) into ( <ref type="formula">19</ref>), the minimum reconstruction error variance is obtained as <ref type="bibr" target="#b21">(22)</ref> where denotes the solution of <ref type="bibr" target="#b19">(20)</ref> or <ref type="bibr" target="#b20">(21)</ref>. The paraunitary case merits special attention. For a paraunitary FB with normalized, real-valued analysis filters, we have and thus , with defined in (4). This implies <ref type="bibr" target="#b22">(23)</ref> If the analysis filters are furthermore causal and of finite length (with some ), we have for and and hence which implies for . (In the nondecimated case , we have for and and hence which implies for .) Hence, the block Toeplitz matrix in (21) will become increasingly banded for small analysis filter length.</p><p>For a paraunitary FB with normalized analysis filters , we have . Hence, ( <ref type="formula">22</ref>) becomes <ref type="bibr" target="#b23">(24)</ref> where is the reconstruction error variance obtained without noise shaping [see <ref type="bibr" target="#b10">(11)</ref>].</p><p>We finally extend our results to the general case of correlated and/or colored quantization noise. Inserting the factorization (cf. Section II-C3) into ( <ref type="formula">17</ref>), we obtain with <ref type="bibr" target="#b24">(25)</ref> Comparing ( <ref type="formula">25</ref>) with ( <ref type="formula">17</ref>), we see that is minimized if is the optimum noise-shaping system for , i.e., for uncorrelated white noise with equal variances in all channels. This system, denoted , can be calculated as explained above. The optimum noise-shaping system for correlated and/or colored quantization noise is then obtained as 3) Constrained Optimum Noise Shaping: The computational complexity of oversampled noise-shaping subband coders can be reduced by restricting to exploit only intrachannel dependencies or to exploit interchannel dependencies only between neighboring channels. Especially the latter strategy can be expected to perform well if the analysis filters are well localized in frequency so that only the transfer functions of neighboring channels are overlapping significantly. In the following, we restrict ourselves to uncorrelated and white noise for simplicity.</p><p>We shall first calculate the optimum intrachannel noise-shaping system (i.e., there are separate noise-shaping systems in the individual subchannels). Here and the matrices are diagonal. Specializing <ref type="bibr" target="#b18">(19)</ref> to diagonal , we obtain <ref type="bibr" target="#b25">(26)</ref> where and . Setting the derivatives of with respect to ( , ) equal to zero, we obtain the following Toeplitz systems of equations: <ref type="bibr" target="#b26">(27)</ref> or, briefly, for , where , , and . Inserting ( <ref type="formula">27</ref>) into (26) and using , we obtain the minimum reconstruction error variance as <ref type="bibr" target="#b27">(28)</ref> where denotes the solution of ( <ref type="formula">27</ref>). We next consider the noise-shaping system that exploits only neighboring channel dependencies. Here, only the main, first upper, and first lower diagonals of may be nonzero. Hence, setting the derivatives of with respect to , , and equal to zero, we obtain the system of equations for , (here, the 's and 's with indexes or are considered to be zero). This can be rewritten as the block Toeplitz system of equations with the -dimensional vectors and shown at the bottom of the page and the block diagonal matrices where and</p><p>The minimum reconstruction error variance is obtained as 4) An Example: As a simple example, we consider a paraunitary two-channel FB (i.e.,</p><p>) with and, hence, oversampling factor</p><p>. The analysis filters are the Haar filters and and the synthesis filters (corresponding to ) are and We assume uncorrelated and white quantization noise, i.e., . Without noise shaping, the reconstruction error variance is obtained from ( <ref type="formula">9</ref>) as <ref type="bibr" target="#b28">(29)</ref> where we used . This is consistent with our result in <ref type="bibr" target="#b10">(11)</ref>. We next calculate the optimum first-order (i.e.,</p><p>) noiseshaping system. The analysis polyphase coefficient matrices are given by and . With <ref type="bibr" target="#b22">(23)</ref>, we obtain and for</p><p>. Inserting this into <ref type="bibr" target="#b20">(21)</ref>, it follows that the optimal noise-shaping system of order is with The corresponding (minimum) reconstruction error variance is obtained from ( <ref type="formula">24</ref>) as <ref type="bibr" target="#b29">(30)</ref> Comparing ( <ref type="formula">30</ref>) with ( <ref type="formula">29</ref>), we see that the first-order noiseshaping system achieves an error variance reduction by a factor of . It is instructive to compare this result with the optimum intrachannel noise-shaping system of order (see Section III-B3). Here, it follows from ( <ref type="formula">27</ref>) that and and hence we obtain The corresponding reconstruction error variance is obtained from <ref type="bibr" target="#b27">(28)</ref> as . Thus, as expected, failing to exploit the interchannel redundancy leads to a larger error variance, which, however, is still smaller than the error variance obtained without noise shaping. Fig. <ref type="figure" target="#fig_7">8</ref> shows the transfer functions of the noise-shaping filters in the diagonal of (note that these are identical for the general and the intrachannel noise-shaping systems) and the transfer functions of the synthesis filters. We see that the noise-shaping system operating in the low-pass channel attenuates the noise at low frequencies (note that subsequently attenuates high frequencies), whereas the noise-shaping system operating in the high-pass channel attenuates the noise at high frequencies (subsequently, attenuates low frequencies). Thus, the noise-shaping system shifts part of the noise to those frequencies that are subsequently attenuated by the synthesis filters.</p><p>5) Simulation Study 1: Further insight into the performance of noise-shaping subband coders was obtained by evaluating (24) for the reconstruction error variance for three paraunitary, odd-stacked, cosine-modulated FBs <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> with channels, normalized analysis filters of length , and oversampling factors , , and . The quantization noise was assumed uncorrelated and white with variance in each channel. Fig. <ref type="figure" target="#fig_8">9</ref> shows the normalized reconstruction error variance as a function of the noise-shaping system's order . For increasing , the reconstruction error variance decreases up to a certain point, after which it remains constant. The maximum system order (i.e., the order after which the reconstruction error variance does not decrease any more) depends on the rank of the block Toeplitz matrix in <ref type="bibr" target="#b20">(21)</ref>, which is determined by the oversampling factor and the analysis filters.</p><p>The results in Fig. <ref type="figure" target="#fig_8">9</ref> show that for large values of , the reconstruction error variance of the proposed noise-shaping subband coders follows a behavior. However, for small , an increase of is observed to produce a stronger reduction of the reconstruction error variance, i.e., the reconstruction error variance can drop faster than according to . Specifically, for noise-shaping system order , we can see from Fig. <ref type="figure" target="#fig_8">9</ref> that doubling the oversampling factor results in a reduction of the reconstruction error variance by about 9 dB, and for system order , we even get about 12-dB error-variance reduction. Next, we investigate the quantization error-redundancy behavior in an implemented noise-shaping subband coder. We coded an audio signal using a paraunitary, 64-channel, odd-stacked, cosine-modulated FB and a noise-shaping system designed under the assumption of uncorrelated and white quantization noise. <ref type="foot" target="#foot_6">8</ref> Uniform quantizers with equal stepsizes in all subbands were employed. Fig. <ref type="figure" target="#fig_9">10</ref> depicts the resulting SNR (defined as SNR ) as a function of the quantization step size for different oversampling factors . For each , we used the maximum possible noise-shaping system order. For between and , we observe a 6-dB SNR increase for each  doubling of , corresponding to a -dependence of the SNR. The SNR increase in going from to is about 9 dB, and thus stronger than . 6) Simulation Study 2: Our next experiment demonstrates that noise shaping in oversampled FBs is capable of drastically improving the effective resolution of the resulting subband coder. We coded an audio signal using a paraunitary, 64-channel, critically sampled, odd-stacked, cosine-modulated FB using uniform quantizers with 63 quantization intervals (6-bit quantizers) in each subband. The resulting SNR was 23.80 dB. Then, we coded the same signal using a paraunitary, 64-channel, odd-stacked, cosine-modulated FB with oversampling factor , a noise-shaping system with order (designed under the assumption of uncorrelated and white quantization noise), and quantizers with 15 quantization intervals (4-bit quantizers). The resulting SNR was 23.76 dB. Thus, in the oversampled case, the same SNR was achieved using a quantization with far lower resolution (corresponding to a reduction of 2 bits in each of the 64 channels) than in the critical case. For oversampling factor 64, quantizers with 15 intervals (4-bit quantizers), and noise-shaping system order , we obtained an SNR of 39.49 dB. In order to achieve an SNR of 39.47 dB in the critically sampled case, we had to use quantizers with 593 intervals (10-bit quantizers). Thus, here we were able to save 578 quantization intervals (or, equivalently, 6 bits of quantizer resolution) in each of the 64 channels. Table <ref type="table" target="#tab_2">I</ref> summarizes these results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7) Simulation Study 3:</head><p>In the previous simulation study, we observed that oversampling and noise shaping drastically improve the effective resolution of a subband coder. However, this resolution enhancement comes at the cost of increased sample rate. It is therefore natural to ask how oversampled noise-shaping subband coders perform from a rate-distortion point of view, i.e., how the coding rate behaves in relation to the resolution enhancement. The following simulation results pertain to this problem. This is investigated by the following simulation study. We coded an audio signal, using a paraunitary, odd-stacked, cosine-modulated FB with channels, filter length , and oversampling factors . Uniform quantizers with equal step sizes in all subbands were employed. The quantizer outputs were entropy-coded using a Huffman coder which jointly operates on all channel outputs, i.e., all subband signal samples (for and for the total range of values) were collected and jointly Huffman coded. The optimum noise-shaping system was calculated under the assumption of uncorrelated white quantization noise with equal variance in all channels.</p><p>Fig. <ref type="figure" target="#fig_10">11</ref> shows the measured distortion-rate performance, i.e., the SNR as a function of the number of bits per sample (bps) required to encode the input signal. The distortion-rate performance obtained with and noise-shaping system order is seen to be better than that obtained with and no noise shaping but poorer than that obtained with and no noise shaping. We furthermore observed that the distortion rate performance of oversampled noise-shaping coders is poorer than that of critically sampled coders without noise shaping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. OVERSAMPLED SIGNAL-PREDICTIVE SUBBAND CODERS</head><p>This section introduces an alternative method for noise reduction in oversampled FBs. This method is based on linear prediction of the FB's subband signals. The resulting oversampled signal predictive subband coders can be motivated by oversampled signal-predictive A/D converters <ref type="bibr" target="#b10">[11]</ref>, which will be briefly reviewed first.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Oversampled Signal-Predictive A/D Converters</head><p>In contrast to noise-shaping A/D converters which predict the inband quantization noise (see Section III-A), signal-predictive A/D converters predict the current sample of the signal to be quantized. The signal-predictive coder (again modeled as an entirely discrete-time system) is depicted in Fig. <ref type="figure" target="#fig_11">12</ref>. Here is the prediction error filter of order . The predictor uses the past noisy signal samples to estimate the current signal sample The prediction error , which forms the input to the quantizer, is given by Choosing the filter such that the prediction error is minimized leads to a reduced dynamic range over which the quantizer must operate. This allows to improve the effective quantizer resolution for a fixed number of quantization intervals. The decoder output is given by , so that the overall reconstruction error is equal to the quantization error . An oversampled signal-predictive coder exploits two types of redundancies: the "natural" redundancy which is inherent in the input signal whenever it has a nonflat power spectral density function, and the "synthetic" redundancy which is introduced by oversampling the analog signal, i.e., by expanding the input signal into a redundant signal set (time-shifted sinc functions, see Section II-B). Increasing the oversampling factor yields more synthetic redundancy and hence better prediction accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Signal Prediction in Oversampled FBs</head><p>Signal-predictive oversampled A/D converters exploit the redundancy inherent in the signal samples to estimate the current sample to be quantized. This principle will now be extended to oversampled PR FBs whose subband signals are a redundant representation of the input signal. The resulting oversampled signal-predictive subband coders extend critically sampled signal-predictive subband coders <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b24">[25]</ref>.</p><p>1) The Signal-Predictive Subband Coder: Fig. <ref type="figure" target="#fig_12">13</ref> shows the structure of the oversampled signal-predictive subband coder. The prediction error system is an MIMO system given by <ref type="bibr" target="#b30">(31)</ref> which results in a strictly causal feedback loop (prediction) system</p><p>The predictor uses the past noisy subband signal vectors to estimate the current subband signal vector This is a "noisy" vector prediction problem. For subband coding using high-resolution quantizers, the effect of quantization noise can be neglected and hence However, here we are primarily interested in low-resolution quantization.</p><p>The prediction error forms the input to the quantizer. It can be shown that <ref type="bibr" target="#b31">(32)</ref> By choosing such that the dynamic range of the quantizer input vector is reduced, it is possible to improve the effective quantizer resolution for a fixed number of quantization intervals.</p><p>With <ref type="bibr" target="#b31">(32)</ref>, it follows that the quantizer output is , which, in turn, implies (assuming existence of the inverse of ) that the decoder output is . Using a PR FB (i.e.,</p><p>), we have so that</p><p>This yields the following result that can be interpreted as an extension of the fundamental theorem of predictive quantization <ref type="bibr" target="#b39">[40]</ref>. Proposition 2: For an oversampled signal-predictive subband coder using a PR FB, the reconstruction error is given by Thus, the reconstruction error is the quantization noise filtered by the synthesis FB . With our results from Section II-C.4, this leads to the important conclusion that the parapseudo-inverse minimizes the reconstruction error variance in the case of uncorrelated and white quantization noise since it suppresses the component of that lies in . Just like an oversampled signal-predictive A/D converter, an oversampled signal-predictive subband coder exploits two types of redundancies: the natural redundancy that is inherent in the input signal and the synthetic redundancy that is introduced by the oversampled analysis FB, i.e., by expanding the input signal into a redundant set of functions (see Section II-C). An increase of the oversampling factor yields more synthetic redundancy in the subband signals and hence better prediction accuracy.</p><p>Since, in general, the matrices are not diagonal, we are performing interchannel (cross-channel) prediction in addition to intrachannel prediction. Exploiting interchannel correlations (which are due to the overlap of the channel filters' transfer functions) may yield an important performance gain. In fact, it has previously been demonstrated <ref type="bibr" target="#b14">[15]</ref> for a two-channel, critically sampled Haar FB that using information from the high-frequency band for prediction in the low-frequency band yields rate-distortion optimality. Critically sampled subband coders employing interchannel prediction have also been considered in <ref type="bibr" target="#b15">[16]</ref>.</p><p>The MIMO system is said to be minimum phase or minimum delay if all the roots of lie inside the unit circle in the -plane. This condition ensures that the inverse filter , and hence the feedback loop, will be stable <ref type="bibr" target="#b39">[40]</ref>. In the noiseless case , it is shown in <ref type="bibr" target="#b39">[40]</ref> that is minimum phase if the process is stationary and nondeterministic. Although we do not have a proof of the minimum phase property of in the noisy case, we always observed stability of in our simulation examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Calculation of the Optimum Prediction System:</head><p>We now derive the optimum prediction system. In contrast to the case of noise-shaping subband coders, the input signal will here be modeled as a random process that is assumed wide-sense stationary, zero-mean, real-valued, and uncorrelated with the quan-tization noise process . For simplicity, the analysis and synthesis filters are assumed real-valued as well. It will be convenient to introduce the "FB input vector" with correlation matrices and power spectral matrix Using , the power spectral matrix of is given by where <ref type="bibr" target="#b32">(33)</ref> with . With (32) and using the fact that (and hence also ) is uncorrelated with , it follows that the power spectral matrix of the prediction error is given by Hence, the prediction error variance is obtained as <ref type="bibr" target="#b33">(34)</ref> Inserting ( <ref type="formula">31</ref>) into (34) and using and , we obtain further <ref type="bibr" target="#b34">(35)</ref> In order to calculate the matrices minimizing , we set <ref type="foot" target="#foot_7">9</ref>and use the matrix derivative rules from Sec-of the quantizer is obtained as . Next, we use a first-order prediction system . From <ref type="bibr" target="#b36">(37)</ref> The resulting (minimum) prediction error variance is obtained from <ref type="bibr" target="#b37">(38)</ref> as</p><p>Let us compare this result with the optimum first-order intrachannel prediction system (see Section IV-B3). From (41) it follows that and and hence</p><p>The corresponding prediction error variance is obtained from (42) as . It is larger than the error variance obtained with interchannel prediction but still smaller than that obtained without prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Simulation Study 4:</head><p>The next simulation example demonstrates that linear prediction is able to exploit the synthetic redundancy introduced by the oversampled analysis FB for improving prediction accuracy and hence enhancing resolution. The coder uses a paraunitary, odd-stacked, cosine-modulated FB <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> with channels, normalized analysis filters of length , and various oversampling factors . We evaluated the expression <ref type="bibr" target="#b37">(38)</ref> for the prediction error variance for a zero-mean white input process (i.e., ) and in the absence of quantization (noiseless prediction). Since the input is white, it contains no natural redundancy and hence all the prediction gain is due to synthetic redundancy. Fig. <ref type="figure" target="#fig_13">14(a)</ref> shows as a function of the predictor order for different values of . For increasing , is seen to decrease up to a certain point, after which it remains constant. There is no prediction gain for since the function set corresponding to the FB is orthogonal. Note that there is a one-to-one correspondence between the prediction error variance and the overall prediction gain.</p><p>Fig. <ref type="figure" target="#fig_13">14(b)</ref> shows the corresponding measured prediction error variance obtained for an implemented coder. This result was obtained by averaging over five realizations (of length 1024) of the white input process. For prediction system order (not shown), the performance of the implemented coder deteriorated significantly. This is probably due to the near-singularity of the block matrix in (37) for , which introduces numerical errors in the computation of the prediction system coefficient matrices. These numerical problems also explain the deviation between the computed and measured performance for . 6) Simulation Study 5: Our next simulation example demonstrates that oversampling combined with linear prediction is a powerful means to improve the effective resolution of a subband coder. We coded realizations of an AR-1 process (length 1024) with correlation coefficient using a paraunitary, 16-channel, critically sampled, odd-stacked, cosine-modulated FB and quantizers with 152 quantization intervals (8-bit quantizers) in each channel. The resulting SNR was 32.49 dB. Next, we coded the same signal using an FB with oversampling factor and a predictor with order (designed under the assumption of uncorrelated and white quantization noise <ref type="foot" target="#foot_8">10</ref> ). Here, quantizers with only 15 quantization intervals (4-bit quantizers) achieved an SNR of 32.51 dB. Hence, oversampling and prediction allowed us to save 4 bits of quantizer resolution in each of the 16 channels, of course at the cost of increased sample rate. For oversampling factor , quantizers with 15 quantization intervals (4-bit quantizers), and a predictor with order , we obtained an SNR of 50.48 dB. In order to achieve an SNR of 50.43 dB with a critically sampled subband coder without prediction, we had to use 1219 quantization intervals (11-bit quantizers). Hence, oversampling and prediction here saved 7 bits of quantizer resolution. Table II summarizes these results.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7) Simulation Study 6:</head><p>We finally investigate the rate distortion and related properties of an implemented oversampled signal-predictive subband coder. As we observed in Section IV-B5, the variance of the quantizer input decreases for increasing oversampling factor and for increasing prediction system order . Therefore, for a fixed number of quantization intervals (which in this case was 255), we can reduce the quantization step size, thereby reducing the quantization error and, in turn, the overall reconstruction error (see Proposition 2). Fig. <ref type="figure" target="#fig_14">15</ref>(a) shows the SNR, averaged over five realizations (of length 1024) of an AR-1 input signal with correlation coefficient , as a function of the predictor order for various oversampling factors . The FB is as in Simulation Study 4. The predictor was designed for uncorrelated and white quantization noise with variance in each channel, where denotes the quantization stepsize used. In Fig. <ref type="figure" target="#fig_14">15</ref>(b), the differences of the curves in Fig. <ref type="figure" target="#fig_14">15(a)</ref> with respect to the curve are depicted. One can observe that a predictive subband coder of order and oversampling factor leads to SNR improvements of more than 55 dB as compared to the critical case.</p><p>Fig. <ref type="figure" target="#fig_14">15</ref>(c) shows the number of bps required by the predictive subband coder (with subsequent Huffman coding as in Section III-B7) as a function of the predictor order for various oversampling factors . We see that the number of bps increases slightly with , which is due to the fact that prediction whitens the signal. Throughout this experiment, the number of quantization intervals was fixed to 255.</p><p>Finally, Fig. <ref type="bibr">15(d)</ref> shows the distortion-rate characteristic (SNR versus bps) of the signal-predictive subband coder, again with Huffman coding, for various oversampling factors and predictor orders . The distortion rate performance obtained with and (which in this case is the maximum possible predictor order) is seen to be poorer than that of a critically sampled subband coder without prediction. Hence, whereas the proposed oversampled signal-predictive subband coders yield substantial noise reduction and allow the use of low-resolution quantizers, they cannot compete with critically sampled subband coders from a rate distortion point of view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>We have introduced two methods for noise reduction in oversampled filter banks. These methods are based on predictive quantization; they can be viewed as extensions of oversampled predictive A/D converters. We demonstrated that predictive quantization in oversampled FBs yields considerable quantization noise reduction at the cost of increased rate. The combination of oversampled filter banks with noise shaping or linear prediction improves the effective resolution of subband coders and is thus well suited for applications where-for technological or other reasons-quantizers with low resolution (even single bit) have to be used. Using low-resolution quantizers increases circuit speed and allows for lower circuit complexity.</p><p>Our simulation results furthermore suggested that, from a rate-distortion point of view, oversampled subband coders are inferior to critically sampled subband coders. However, it should be noted that from a perceptual point of view, oversampled subband coders have potential advantages over critically sampled coders. Finally, it is worthwhile to point out that the proposed methods are not limited to oversampled FBs but can be generalized to arbitrary frame expansions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Reconstruction of analog signal by low-pass filtering. (a) Critical case. (b) Oversampled case.</figDesc><graphic coords="2,302.64,168.24,258.96,102.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. N-channel uniform filter bank.</figDesc><graphic coords="3,98.82,62.28,392.64,143.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>is just a notational aid since may not converge.) Assuming an arbitrary PR synthesis FB , we have [see Fig.3and (6)]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Adding noise to the subband signals (polyphase-domain representation).</figDesc><graphic coords="5,38.10,62.28,255.60,70.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Range space of analysis FB and its orthogonal complement.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Noise-shaping A/D converter. The quantizer (box labeled Q) adds quantization noise q[n] $ Q(z).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Oversampled noise-shaping subband coder (polyphase-domain representation).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Noise-shaping filters and synthesis filters in an oversampled two-channel FB. (a) jG (e</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Normalized reconstruction error variance 10 log( = ) as a function of the noise-shaping system order L.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. SNR improvement as a function of the quantization stepsize for various oversampling factors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Distortion-rate characteristic of oversampled noise-shaping subband coders with and without noise shaping.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Signal-predictive A/D converter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Oversampled signal-predictive subband coder (polyphase-domain representation).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Prediction error variance 10 log</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Signal-predictive subband coder with 255 quantization intervals and various oversampling factors; simulation results for an AR-1 signal. (a) SNR as a function of the prediction system order L. (b) SNR differences with respect to K = 1. (c) bps as a function of the prediction system order L for different oversampling factors K. (d) Distortion-rate characteristic in comparison to alternative subband coders with various oversampling factors and predictor orders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I IMPROVING</head><label>I</label><figDesc>THE EFFECTIVE RESOLUTION OF A SUBBAND CODER BY MEANS OF OVERSAMPLING AND NOISE SHAPING (N DENOTES THE NUMBER</figDesc><table /><note><p>OF QUANTIZATION INTERVALS REQUIRED)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II IMPROVING</head><label>II</label><figDesc>THE EFFECTIVE RESOLUTION OF A SUBBAND CODER BY MEANS OF OVERSAMPLING AND PREDICTION (N DENOTES THE NUMBER OF QUANTIZATION INTERVALS REQUIRED)</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Here L ( ) denotes the space of square-integrable functions x(t). Furthermore, hx; yi = x(t)y (t) dt</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Here, rect (f ) = 1 for jf j B and rect (f ) = 0 else.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Here H (z) = h [n]z denotes the z-transform of h [n].</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>The superscript H denotes conjugate transposition.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>Here, áº¼(z) = E (1=z ) is the para-conjugate of E(z).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>From this interpretation, it appears that the optimal noise-shaping filter G(z) would be the ideal high-pass filter with passband jj 1=2, since this filter projects the noise onto R and after reconstruction no noise would be left. However, this filter is not realizable and would lead to a noncausal system 1 0 G(z) that cannot operate in a feedback loop.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6"><p>Similar to oversampled A/D conversion<ref type="bibr" target="#b11">[12]</ref>, the assumption of uncorrelated white noise is not justified in the oversampled case, which causes the performance of implemented coders to be poorer than the theoretical performance observed further above. Nonetheless, we are forced to use this assumption because estimating the actual quantization noise statistics and designing the noise-shaping system accordingly is not possible since the quantizer is placed within a feedback loop<ref type="bibr" target="#b13">[14]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_7"><p>The optimum prediction system can equivalently be derived using the orthogonality principle.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_8"><p>We recall, however, that especially in the oversampled case the assumption of uncorrelated and white quantization noise is not realistic.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors wish to thank T. Stranz for carrying out the simulation work. They are also grateful to the reviewers for their comments which led to an improvement of the paper.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by FWF under Grants P10531-ÃPH, P12228-TEC, and J1629-TEC. The material in this paper was presented in part at the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Munich, Germany, April 1997, and at the IEEE International Symposium on Time-Frequency and Time-Scale Analysis (TFTS), Pittsburgh, PA, October 1998.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>tion III-B2. This yields the following block Toeplitz system of linear equations: for <ref type="bibr" target="#b35">(36)</ref> or, equivalently, . . . . . . . . . . . . . . . . . . with <ref type="bibr" target="#b36">(37)</ref> Using <ref type="bibr" target="#b35">(36)</ref> in <ref type="bibr" target="#b34">(35)</ref>, the minimum prediction error variance is obtained as <ref type="bibr" target="#b37">(38)</ref> where denotes the solution of ( <ref type="formula">36</ref>) or <ref type="bibr" target="#b36">(37)</ref>. In the noiseless case, (36) reduces to for <ref type="bibr" target="#b38">(39)</ref> which can be solved efficiently using the multichannel Levinson recursion <ref type="bibr" target="#b38">[39]</ref>. Another important special case where this is possible is the noisy case with white (but possibly correlated) quantization noise, i.e., . Here, <ref type="bibr" target="#b35">(36)</ref> reduces to (39) with replaced by . We finally note that the above derivation can be extended to incorporate correlations between and .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Constrained Optimum Prediction:</head><p>Reducing the computational complexity of predictive subband coding is often important, especially for adaptive prediction. Hence, in analogy to noise shaping (see Section III-B3), we shall consider the case of no interchannel prediction ("intrachannel prediction") or interchannel prediction between neighboring channels only.</p><p>We shall first calculate the optimum intrachannel prediction system. Specializing <ref type="bibr" target="#b34">(35)</ref> to diagonal , we obtain <ref type="bibr" target="#b39">(40)</ref> where , , and with . Proceeding as in Section III-B3, we obtain the following Toeplitz systems of equations:</p><p>(41) or, briefly, for , where , , and . Inserting (41) into <ref type="bibr" target="#b39">(40)</ref> and using , we obtain the minimum prediction error variance as <ref type="bibr">(42)</ref> where denotes the solution of (41). We next calculate the optimum prediction system that exploits only neighboring channel dependencies. Proceeding similarly to the case of noise shaping, we obtain the block Toeplitz system of equations with the -dimensional vectors and shown at the bottom of this page and the block diagonal matrices where and The minimum prediction error variance is here obtained as 4) An Example: Let us reconsider the two-channel FB with oversampling factor previously considered in Section III-B4. The input process is an AR-1 process defined by with correlation coefficient and white driving noise with variance . The autocorrelation function of is <ref type="bibr" target="#b36">[37]</ref>. Inserting and into <ref type="bibr" target="#b32">(33)</ref>, we obtain The quantization noise is assumed uncorrelated white with variance in each channel, i.e., . Without prediction (i.e., or ), the variance at the input</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Frame-theoretic analysis of oversampled filter banks</title>
		<author>
			<persName><forename type="first">H</forename><surname>BÃ¶lcskei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hlawatsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Feichtinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="3256" to="3268" />
			<date type="published" when="1998-12">Dec. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Oversampled filter banks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cvetkovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1245" to="1255" />
			<date type="published" when="1998-05">May 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Oversampled cosine modulated filter banks with perfect reconstruction</title>
		<author>
			<persName><forename type="first">H</forename><surname>BÃ¶lcskei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hlawatsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. II (Special Issue on Multirate Systems, Filter Banks, Wavelets, and Applications)</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="1057" to="1071" />
			<date type="published" when="1998-08">Aug. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Oversampled modulated filter banks and tight Gabor frames in l (Z)</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cvetkovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP-95</title>
		<meeting>IEEE ICASSP-95<address><addrLine>Detroit, MI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-05">May 1995</date>
			<biblScope unit="page" from="1456" to="1459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Overcomplete expansions for digital signal processing</title>
	</analytic>
	<monogr>
		<title level="j">Univ. Calif</title>
		<imprint>
			<date type="published" when="1995-12">Dec. 1995</date>
			<pubPlace>Berkeley, CA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Oversampled FIR and IIR DFT filter banks and Weyl-Heisenberg frames</title>
		<author>
			<persName><forename type="first">H</forename><surname>BÃ¶lcskei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hlawatsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Feichtinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP-96</title>
		<meeting>IEEE ICASSP-96<address><addrLine>Atlanta, GA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-05">May 1996</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1391" to="1394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Density theorems for filter banks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J E M</forename><surname>Janssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philips Res. Lab</title>
		<imprint>
			<biblScope unit="volume">6858</biblScope>
			<date type="published" when="1995-04">Apr. 1995</date>
			<pubPlace>Eindhoven, The Netherlands</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Oversampled modulated filter banks</title>
		<author>
			<persName><forename type="first">H</forename><surname>BÃ¶lcskei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hlawatsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Gabor Analysis and Algorithms: Theory and Applications</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Feichtinger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Strohmer</surname></persName>
		</editor>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>BirkhÃ¤user</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="295" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Oversampled filter banks and predictive subband coders</title>
		<author>
			<persName><forename type="first">H</forename><surname>BÃ¶lcskei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997-11">Nov. 1997</date>
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Vienna Univ. Technol</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Oversampled filter banks: Optimal noise shaping, design freedom, and noise analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>BÃ¶lcskei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hlawatsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP-97</title>
		<meeting>IEEE ICASSP-97<address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-04">Apr. 1997</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2453" to="2456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Oversampled, linear predictive and noise-shaping coder of order N 1</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Tewksbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Hallock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="436" to="447" />
			<date type="published" when="1978-07">July 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Oversampling Delta-Sigma Data Converters</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Candy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Temes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>IEEE Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Oversampled sigma-delta modulation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="481" to="489" />
			<date type="published" when="1987-04">Apr. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Digital Coding of Waveforms</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Jayant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Noll</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rate distortion efficiency of subband coding with crossband prediction</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="352" to="356" />
			<date type="published" when="1997-01">Jan. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multiple-input/multiple-output prediction of subbands and image compression</title>
		<author>
			<persName><forename type="first">L</forename><surname>Vandendorpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Maison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. COST 254 (Emerging Techniques for Communication Terminals)</title>
		<meeting>COST 254 (Emerging Techniques for Communication Terminals)<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-07">July 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rate-distortion performance in coding bandlimited sources by sampling and dithered quantization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="141" to="154" />
			<date type="published" when="1995-01">Jan. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Information rates of pre/post-filtered dithered quantizers</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1340" to="1353" />
			<date type="published" when="1996-09">Sept. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A class of nonharmonic Fourier series</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Duffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Schaeffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Amer. Math. Soc</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="341" to="366" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Continuous and discrete wavelet transforms</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Heil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Walnut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="628" to="666" />
			<date type="published" when="1989-12">Dec. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Ten Lectures on Wavelets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>SIAM</publisher>
			<pubPlace>Philadelphia, PA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The Shannon sampling theorem-Its various extensions and applications: A tutorial review</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Jerri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="1565" to="1596" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Introduction to Shannon Sampling Theory and Interpolation Theory</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Marks</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Multirate Systems and Filter Banks</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Vaidyanathan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kovacevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Â´</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Wavelets</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Subband</forename><surname>Coding</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Vector space framework for unification of one-and multidimensional filter bank theory</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Vaidyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="2006" to="2021" />
			<date type="published" when="1994-08">Aug. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Wavelets and filter banks: Theory and design</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Herley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2207" to="2232" />
			<date type="published" when="1992-09">Sept. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The duality condition for Weyl-Heisenberg frames</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J E M</forename><surname>Janssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Gabor Analysis and Algorithms: Theory and Applications</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Feichtinger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Strohmer</surname></persName>
		</editor>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>BirkhÃ¤user</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="33" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Quantized overcomplete expansions in r : Analysis, synthesis and algorithms</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Thao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="16" to="31" />
			<date type="published" when="1998-01">Jan. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Noise reduction in tight Weyl-Heisenberg frames</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Munch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="608" to="616" />
			<date type="published" when="1992-03">Mar. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deterministic analysis of oversampled A/D conversion and decoding improvement based on consistent estimates</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Thao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="519" to="531" />
			<date type="published" when="1994-03">Mar. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Lower bound on the mean squared error in oversampled quantization of periodic signals using vector quantization analysis</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="469" to="479" />
			<date type="published" when="1996-03">Mar. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Vector quantization analysis of sigma-delta modulation</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Thao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="808" to="817" />
			<date type="published" when="1996-04">Apr. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Overcomplete expansions and robustness</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cvetkovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE TFTS-96</title>
		<meeting>IEEE TFTS-96<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-06">June 1996</date>
			<biblScope unit="page" from="325" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The prediction theory of multivariate stochastic processes-I</title>
		<author>
			<persName><forename type="first">N</forename><surname>Wiener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Masani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta. Math</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="111" to="150" />
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The prediction theory of multivariate stochastic processes-II</title>
	</analytic>
	<monogr>
		<title level="j">Acta Math</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="93" to="137" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Papoulis</surname></persName>
		</author>
		<title level="m">Probability, Random Variables, and Stochastic Processes</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>rd ed</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Weinmann</surname></persName>
		</author>
		<title level="m">Uncertain Models and Robust Control. Vienna, Austria</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kay</surname></persName>
		</author>
		<title level="m">Modern Spectral Estimation</title>
		<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Vector Quantization and Signal Compression</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gersho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Gray</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Kluwer</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
