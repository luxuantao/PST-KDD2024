<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ARTICLE IN PRESS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">G</forename><surname>Model</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Mojtaba</forename><surname>Taherkhani</surname></persName>
							<email>taherkhani.mojtaba@aut.ac.ir</email>
						</author>
						<author>
							<persName><forename type="first">Reza</forename><surname>Safabakhsh</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering Department</orgName>
								<orgName type="institution">Amirkabir University of Technology</orgName>
								<address>
									<settlement>Tehran</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<postBox>688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740</postBox>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<postBox>848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876</postBox>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ARTICLE IN PRESS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7CC96F4FD49D172DE716F26A84877D91</idno>
					<idno type="DOI">10.1016/j.asoc.2015.10.004</idno>
					<note type="submission">Received 17 March 2015 Received in revised form 22 September 2015 Accepted 5 October 2015</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Particle swarm optimization (PSO) Adaptive inertia weight Stability analysis Radar system design</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Particle swarm optimization (PSO) is a stochastic population-based algorithm motivated by intelligent collective behavior of birds. The performance of the PSO algorithm highly depends on choosing appropriate parameters. Inertia weight is a parameter of this algorithm which was first proposed by Shi and Eberhart to bring about a balance between the exploration and exploitation characteristics of PSO. This paper presents an adaptive approach which determines the inertia weight in different dimensions for each particle, based on its performance and distance from its best position. Each particle will then have different roles in different dimensions of the search environment. By considering the stability condition and an adaptive inertia weight, the acceleration parameters of PSO are adaptively determined. The corresponding approach is called stability-based adaptive inertia weight (SAIW). The proposed method and some other models for adjusting the inertia weight are evaluated and compared. The efficiency of SAIW is validated on 22 static test problems, moving peaks benchmarks (MPB) and a real-world problem for a radar system design. Experimental results indicate that the proposed model greatly improves the PSO performance in terms of the solution quality as well as convergence speed in static and dynamic environments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Particle swarm optimization (PSO) is a stochastic populationbased algorithm first introduced by Kennedy and Eberhart <ref type="bibr" target="#b0">[1]</ref>. The advantages of this algorithm include fast convergence toward the global optimum, easy implementation and few parameters to adjust. Its effective searching strategy makes it a potential method for solving different optimization problems in a wide variety of applications <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>.</p><p>In PSO, each potential solution is treated as a particle. Each particle has several parameters such as the current position, velocity and the best position found by the particle so far. For a Ddimensional search space, these parameters are represented with D-dimensional vectors. The position and velocity of the ith particle is presented as:</p><formula xml:id="formula_0">x i = (x i1 , x i2 , . . ., x iD ) v i = (v i1 , v i2 , . . ., v iD ) (1)</formula><p>At each time step, the position and velocity of the particles are updated according to the following equations:</p><p>x i (t + 1) = x i (t) + v i (t + 1) v i (t + 1) = wv i (t) + R 1 c 1 (P i -x i (t)) + R 2 c 2 (P g -x i (t)) <ref type="bibr" target="#b1">(2)</ref> where w is the inertia weight, R 1 and R 2 are two distinct random values between 0 and 1, c 1 and c 2 are the acceleration constants known as cognitive and social scaling parameter; P i is give the best previous position of the particle itself and P g 's denote the best previous position of all particles of the swarm. Large values of w facilitate exploration, with increased diversity, whereas a small values promote local exploitation <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref>.</p><p>The balance between global and local search throughout the course of a run is critical to the success of an optimization algorithm <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. In the present work, different inertia weight adaptation mechanisms are examined to bring about a balance between the global and local search, since by changing the inertia weight dynamically, the search capability is dynamically adjusted <ref type="bibr" target="#b3">[4]</ref>. Inertia weight is one of the most important parameters of the algorithm and basically tends to memorize the previous direction of each particle. If this quantity is large, the particles will tend to memorize their previous direction, which leads to increasing the convergence speed and sometimes causes increased searching of the environment. But if this quantity is small, particles will not memorize their previous direction.</p><p>Most of the common strategies of adjusting the inertia weight are efficient if their parameters are set properly based on the fitness landscape and default information (e.g. maximum iterations). In the majority of the problems, such information is not accessible, so the strategies will not necessarily have a good performance. Besides, the inertia weight should be compatible with the problem conditions and the algorithm itself. For example, in multi-swarm particle swarm optimizers, the main population is divided into a number of sub-swarms with the hope of exploring different areas of the search space <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>. While the inertia weight is only adjusted according to the iteration number of the overall algorithm, the sub-swarms may be created at any time during a run of the algorithm and hence require a w value compatible with their needs. In addition, there are some optimization problems that show the need for a new inertia weight adaptation mechanism. For example, in dynamic environments with moving peaks, the global best PSO fails to follow the extrema due to the small velocity values of the particles <ref type="bibr" target="#b10">[11]</ref>.</p><p>None of the existing inertia weight adjustment strategies have paid attention to the stability of PSO. As the inertia weight dynamically changes the searching ability, the stability conditions change dynamically. By satisfying the stability conditions in PSO, the speed and precision of the convergence are improved <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. The objective of this paper is to design an adaptive inertia weight considering the stability conditions for the particle swarm optimization method. SAIW uses the historical performance of each particle and its best position for adjusting that particle's inertia weight in different dimensions. The inertia weight is adjusted separately in different dimensions to speed up the convergence speed. By using the inertia weight, SAIW adjusts the acceleration coefficients adaptively to satisfy the algorithm's stability conditions dynamically.</p><p>The rest of this paper is organized as follows. Section 2 provides a review of different inertia weight adaptation mechanisms. In this section, the inertia weight adaptation mechanisms are classified based on the feedback that they use. In Section 3, a novel adaptive inertia weight mechanism is proposed. The experimental setup and parameters setting are discussed in Section 4. Section 5 is devoted to the performance evaluation of the proposed method and comparison with other methods and Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Inertia weight adaptation mechanisms</head><p>Inertia weight is one of the most important parameters of the PSO algorithm. In this section, various inertia weighting strategies are categorized into three classes. The first class contains strategies in which the value of the inertia weight is constant during the search or is determined randomly. None of these methods use any input argument. In the second class, the inertia weight is defined as a function of time or iteration number and hence the strategy is referred to as the time-varying inertia weight strategy. Despite claims made in some other papers, these methods are not considered adaptive since they do not monitor the situation of the particles in the search space. The third class contains those methods which use a feedback parameter to monitor the state of the algorithm and adjust the value of the inertia weight. These three classes are further discussed in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Constant and random inertia weights</head><p>The inertia weight parameter was originally introduced by Yuhui and Eberhart <ref type="bibr" target="#b13">[14]</ref>. They used a range of constant w values. They showed that if the value of this parameter is small, particles will tend to get trapped in the local optima and if it is within the range [0.8, 1.2], particles will tend to do global search. Li et al. <ref type="bibr" target="#b14">[15]</ref> used a constant value of 0.6 for the inertia weight to optimize the algorithm.</p><p>These strategies tend to carry out either global or local search, while the algorithm requires the combination of both of them. When these strategies are used, the global and local search ability throughout the course of a run have to be balanced in a different way. For example, Huang et al. <ref type="bibr" target="#b15">[16]</ref> proposed an example set of multiple global best particles to update the position of the particle, Wang et al. used a diversity enhancing mechanism and neighborhood search strategies to achieve a trade-off between exploration and exploitation abilities <ref type="bibr" target="#b16">[17]</ref>, Chen et al. <ref type="bibr" target="#b17">[18]</ref> added an aging mechanism to particle swarm optimization (PSO), and Sun et al. <ref type="bibr" target="#b18">[19]</ref> used the slave and the master swarm with the clear division of their works.</p><p>Eberhart <ref type="bibr" target="#b19">[20]</ref> used a random value for the inertia weight to enable PSO to track the optima in a dynamic environment:</p><formula xml:id="formula_1">w = 0.5 + rand() 2<label>(3)</label></formula><p>where rand() is a random number in [0,1]. The inertia weight is then a uniform random variable in the range [0.5, 1]. It is difficult to predict at a given time whether exploration (large values of w) or exploitation (small values of w) is required in dynamic environments. So, a random value of w is selected to address this problem.</p><p>In this method, when the algorithm needs diversity, the algorithm may not be able to increase the diversity by decreasing the inertia weight. In addition, the algorithm cannot properly converge to the optima since the inertia weight has a limit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Time-varying inertia weights</head><p>An inertia weight determination strategy was introduced in which the value of w was adjusted linearly, according to Eq. ( <ref type="formula">4</ref>) <ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref>:</p><formula xml:id="formula_2">w(t) = iter max -t iter max (w max -w min ) + w min (4)</formula><p>where the value of w is linearly decreased from an initial value (w max ) to a final value (w min ), t is the current iteration of the algorithm and iter max is the maximum number of iterations the algorithm is allowed to continue. In this model, the particles' tendency to local search is increased continuously. So when diversity is needed, the inertia weight cannot help. At the beginning of the run, the particles have a higher global search ability, whereas at the end of the run, they have a higher local search ability <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>In other studies, a chaotic term is added to the linearly decreasing inertia weight model <ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref>. Based on the used chaotic model, the inertia weight can either increase or decrease in sequential steps. However, in general, the inertia weight gradually decreases. The proposed w is:</p><formula xml:id="formula_3">w(t) = (w max -w min ) × iter max -t iter max + w min × Z (<label>5</label></formula><formula xml:id="formula_4">)</formula><p>where Z is the chaotic term. Different chaotic models such as Logistic, Lozi, Dissipative, Arnold's Cat, etc. can be used for this term. Some researchers have introduced nonlinear decreasing strategies based on accepting the general idea of decreasing the inertia weight. In these methods, the local and global search ability of the particles are adjusted more properly. Peram et al. <ref type="bibr" target="#b40">[41]</ref> have shown that these strategies are more suitable than linear strategies for smoother spaces. Liao et al. <ref type="bibr" target="#b41">[42]</ref> proposed a nonlinear decreasing variant of the inertia weight formula based on Eq. ( <ref type="formula" target="#formula_5">6</ref>)</p><formula xml:id="formula_5">w(t) = (iter max -t) d (iter max ) d (w max -w min ) + w min (<label>6</label></formula><formula xml:id="formula_6">)</formula><p>where d is the nonlinear modulation index. If the value of d is greater than one (d &gt; 1), at the beginning of the run, particles will have global search ability; but after that, they will have local search ability. If d has a value in the range [0,1], the situation will be the opposite. Due to the fast and decreasing nature of exponential functions, these functions have received much attention as an option for a decreasing inertia weight strategy <ref type="bibr" target="#b42">[43]</ref>. In <ref type="bibr" target="#b43">[44]</ref>, based on the sensitivity analysis of the PSO performance, 1/ 2 is selected for d to adjust the time-varying inertia weight. Distinct from the widely used decreasing inertia weight, Yongling et al. <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46]</ref> proposed a PSO with an increasing inertia weight and confirmed its validity in terms of the convergence speed and solution precision by testing it with four standard test functions. They showed that the PSO with increasing inertia weight (increasing from 0.4 to 0.9) outperforms the PSO with decreasing inertia weight in all benchmarks used in their tests.</p><p>Another nonlinear increasing inertia weight has been proposed by Jiao et al. <ref type="bibr" target="#b46">[47]</ref>. In this model, w is increased over time based on the following equation:</p><formula xml:id="formula_7">w(t) = w min × u t<label>(7)</label></formula><p>where w min is selected in the range [0,1] and u is a constant value in the range [1.0001, 1.005]. In the conducted experiments <ref type="bibr" target="#b46">[47]</ref>, u is set to 1.0002 and the performance of the algorithm is evaluated for different values of w initial . Strategies of this class, linearly or nonlinearly, increase or decrease the value of the inertia weight. These strategies try to solve the problems of the constant inertia weight strategy. The major goal of these methods is considering a curve for adjusting the inertia weight which leads to the maximum performance of the algorithm in different environments. The information in this curve can be, for instance, the maximum or minimum value of the inertia weight, the slope of the inertia weight changes, changing the situation between the exploration and exploitation characteristics, and the maximum number of iterations of the algorithm. The fitness landscape is highly effective in the performance of the algorithm with selected curve. Inappropriate parameter adjustment may lead to loosing time because of undue exploration or may lead to loosing exploration appetite. Both of these situations result in the low performance of the algorithm. From the exploration/exploitation perspective, this means that different problems require different amounts of exploration and exploitation. This implies that a good ratio between exploration and exploitation, and hence a proper or good balance, is problem-dependent, too <ref type="bibr" target="#b6">[7]</ref>.</p><p>We conclude that to improve the algorithm performance, the shape of the fitness landscape should be known; which is impossible in most of the applications. In many of the strategies reviewed in this section, the maximum number of iterations of the algorithm is assumed to be known by default; an assumption which can be incorrect in some applications (e.g. dynamic environments).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Adaptive inertia weights</head><p>The last category of inertia weight determination strategies studied in this paper are those that monitor the search situation and adapt the inertia weight value based on one or more feedback parameters. In <ref type="bibr" target="#b47">[48]</ref>, w is adapted based on two characteristic parameters in the search course of PSO; namely, the speed factor and the aggregation degree factor. The speed factor is defined as:</p><formula xml:id="formula_8">h t i = min(fit(P t-1 i ), fit(P t i )) max(fit(P t-1 i ), fit(P t i ))<label>(8)</label></formula><p>where P t i is the best position found by particle i until iteration t and fit() is the function to be optimized. The aggregation degree is defined as:</p><formula xml:id="formula_9">S = min(F tbest , Ft ) max(F tbest , Ft ) (<label>9</label></formula><formula xml:id="formula_10">)</formula><p>where Ft is the mean fitness of all particles in the swarm at the tth iteration and F tbest is the best fitness achieved by the particles at the same iteration. Using the speed and the aggregation factors, the inertia weight of particle i at iteration t is determined as:</p><formula xml:id="formula_11">w i (t) = w min -˛(1 -h t i ) + ˇS<label>(10)</label></formula><p>where ˛ and ˇ are two constants typically within the range [0,1]. The performance of the PSO algorithm is evaluated for different values of ˛ and ˇ in <ref type="bibr" target="#b47">[48]</ref>.</p><p>There are other researchers who have used the fitness of the particles as a characteristic of the particles to adapt the inertia weight of each particle. In <ref type="bibr" target="#b48">[49]</ref>, Arumugam use the ratio of the global best fitness and the average of particles' local best fitness to determine the inertia weight in each iteration:</p><formula xml:id="formula_12">w = 1.1 - fit(P g ) 1 n n i=1 fit(P i ) (<label>11</label></formula><formula xml:id="formula_13">)</formula><p>where n is the number of particles.</p><p>In the adaptive PSO algorithm proposed by Panigrahi et al. <ref type="bibr" target="#b49">[50]</ref>, different inertia weights are assigned to different particles based on the ranks of the particles:</p><formula xml:id="formula_14">w i = w min + (w max -w min ) Rank i n (<label>12</label></formula><formula xml:id="formula_15">)</formula><p>where Rank i is the position of the ith particle when the particles are ordered based on their particle best fitness. The rational of this approach is that the positions of the particles are adjusted in a way that highly fitted particles move more slowly compared to the lowly fitted ones.</p><p>Nickabadi in <ref type="bibr" target="#b3">[4]</ref> uses success percentage to compute the inertia weight; and the particle fitness for computing the success percentage:</p><formula xml:id="formula_16">P s (t) = n i=1 S(i, t) n S(i, t) = ⎧ ⎨ ⎩ 1 if fit(pbest t i ) &lt; fit(pbest t-1 i ) 0 if fit(pbest t i ) = fit(pbest t-1 i ) (<label>13</label></formula><formula xml:id="formula_17">)</formula><p>where P s ∈ [0, 1] is the percentage of the particles which have had an improvement in their fitness in the last iteration. In <ref type="bibr" target="#b3">[4]</ref>, a linear function is used to map the values of P s to the possible range of inertia weights as follows:</p><formula xml:id="formula_18">w(t) = (w max -w min )P s (t) + w min<label>(14)</label></formula><p>In this strategy, if the success percentage becomes smaller, the inertia weight will become smaller too. And if the success percentage becomes larger, the inertia weight will become larger too.</p><p>In <ref type="bibr" target="#b1">[2]</ref> a simple adaptive nonlinear strategy is introduced. The selected strategy mainly depends on each particle's performance and is determined by the absolute distance of the particle's personal best and the global best position according to the iterations:</p><formula xml:id="formula_19">w i (t + 1) = w i (t) -(w i (t) -0.4) × exp -(P g -P i ) × t iter max (15)</formula><p>It combines the effects of both the nonlinear and the exponential inertia weights. The large values of w when the particle is very far from the global optimum provide exploration. But as the particles approach the global optimum, w decreases dynamically to a small value (close to 0.4) which facilitates exploitation.</p><p>The strategy introduced in <ref type="bibr" target="#b1">[2]</ref> incorporates a dying double exponential function; namely the Gompertz function for selecting the inertia weight:</p><formula xml:id="formula_20">w i (t + 1) = exp(-exp(-R i (t))) R i (t) = |P g -P i | × iter max -t iter max (<label>16</label></formula><formula xml:id="formula_21">)</formula><p>First a performance index (R i ) is evaluated for each particle at each iteration based on the particle's personal best position and the global best position of the swarm. The performance index is then fed as an input to the Gompertz function to evaluate the momentum for each particle. In this strategy, the inertia weight is about 0.4 at the beginning of the run. Then to speed up the convergence, the inertia weight becomes approximately 1 after some iterations.</p><p>The strategies in this class do not have the limitations and assumptions of the time-varying inertia weight strategies. However, this does not mean that the adaptive approaches are always better than time-varying based approaches. Especially in multimodal environments, the two approaches are comparable.</p><p>In this group, the environment should be monitored with some measures which are then used to adjust the parameters of the algorithm. There are two issues about these measures or feedback parameters that should be taken into account before devising an adaptive strategy. The first issue is that they should be acceptable and easy to compute. The other important factor about the feedback parameters is that it should provide good insight into the way that the inertia weight should be changed. The majority of the proposals for adaptive inertia weight use the fitness and its derivations, such as particle's ranks, to adjust the inertia weight. It is clear that the fitness by itself is not a good criterion for evaluating the appropriateness of the inertia weight value <ref type="bibr" target="#b3">[4]</ref>.</p><p>Furthermore, in adaptive strategies, the performance of the algorithm changes dynamically, but the algorithm should remain stable based on the stability conditions in <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. Changing the inertia weight adaptively will change the stability conditions adaptively. None of the current works have paid attention to this point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The proposed method</head><p>The inertia weight model proposed in this paper, which is called the stability-based adaptive inertia weight (SAIW), is inspired by the following idea. Considering the previous discussion, the adaptive inertia weight adjusting strategy is chosen for improvement. Each particle's situation in the population is important in adjusting the inertia weight <ref type="bibr" target="#b3">[4]</ref>; so for adjusting the inertia weight for each particle, its feedback is used. The particle's performance shows its tendency to memorize its last direction. In the proposed strategy, the value of inertia weight is considered different for each dimension, so that the convergence speed increases, especially in asymmetric environments. The value of the inertia weight in each dimension is used to compute the acceleration coefficients adaptively, based on the stability condition <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>.</p><p>To provide an adaptive inertia weight strategy, one first needs to determine the feedback parameter for each particle. To achieve this, in addition to the success of the particle, the displacement in its best position is used as the feedback. To be sure of making decisions about the value of the inertia weight, the last two steps during the course of run are analyzed. When a particle successes in some sequential steps, it will have more tendency to memorize its direction. Probably because it will have more successes in this direction. When a particle does not succeed in some sequential steps, it has less tendency to memorize its previous direction. Probably because it will have no more success in this direction.</p><p>The success of particle i at iteration t + 1 in a minimization problem is defined as:</p><formula xml:id="formula_22">ı i (t) = 1 if fit(x i (t + 1)) &lt; fit(P t i ) -1 else (17)</formula><p>Fig. <ref type="figure" target="#fig_1">1</ref> shows two different situations in which a particle of PSO may succeed during the search. When the Particle's best positions in the last two iterations are close to each other, making decision about memorizing the direction becomes more confident; so the value of the inertia weight changes greatly. In Fig. <ref type="figure" target="#fig_1">1</ref>(a), increasing the inertia weight in large amounts results in fast convergence. When two Particle's best positions in last two iteration are not close to each other, making decision about memorizing the direction becomes less confident; so the value of inertia weight changes less. In Fig. <ref type="figure" target="#fig_4">1(b)</ref>, increasing the inertia weight in small amounts results in fast convergence. If in some sequential steps there is not any improvement in the particle's best position, the inertia weight changes will be the opposite of the previous situation. Based on the above discussion, we introduce Eq. ( <ref type="formula" target="#formula_23">18</ref>) for determining the inertia weight:</p><formula xml:id="formula_23">Q6 W ij (t + 1) = ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ min 1, w ij (t) + (1 -w 0 ) × exp (x ij (t + 1) -Pbest ij (t)) 2 -2 2 + ε if (ı i (t) &gt; 0 and ı i (t -1) &gt; 0) max 0.1, w ij (t) -w 0 × 1 -exp (x ij (t + 1) -Pbest ij (t)) 2 -2 2 -ε if (ı i (t) &lt; 0 and ı i (t -1) &lt; 0) w ij (t) else ⎫ ⎪ ⎪ ⎪ ⎪ ⎪ ⎬ ⎪ ⎪ ⎪ ⎪ ⎪ ⎭<label>(18)</label></formula><p>where w ij (t + 1) is ith particle's inertia weight in the jth dimension, in (t + 1)th iteration. w 0 is the initial inertia weight which is considered equal for all particles in all dimensions. x ij (t + 1) is the ith particle's position in the jth dimension, in the (t + 1)th step.</p><p>Pbest ij (t) is the ith particle's best position in the jth dimension until the (t + 1)th step. The Gaussian kernel width ( ) is adjusted in a way that covers the maximum particles' movement. ε is a small positive number (e.g. ε = 0.005) used to ensure proper increase or decrease of the inertia weight. Its value is not critical. The velocity of the particle is updated according to the sum of three vectors v i (t), (P i -x i (t))</p><p>and (P gx i (t)) with their scaling parameters equal to w, R 1 c 1 and</p><formula xml:id="formula_24">R 2 c 2 .</formula><p>In the worst situation, the value of epsilon scales v i (t) with 0.005 (constant value as mentioned in this study), but the social learning and cognitive learning vectors are scaled randomly within the range [0,2] by R 1 c 1 and R 2 c 2 . Thus, the influence of epsilon is covered by these random numbers. The range of the inertia weight ([w min , w max ]) is selected to be [0.1, 1]. In the stability analyses in <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>, the PSO algorithm's stability is proved by Eq. ( <ref type="formula">19</ref>). When the inertia weight changes adaptively, it is necessary that the acceleration constants change during the run, too. Otherwise, the following condition will not always be satisfied:</p><formula xml:id="formula_25">1 -ω ij (t) ≥ 0 2ω ij (t) + 2 -R 1 c 1,ij (t) -R 2 c 2,ij (t) ≥ 0 (19)</formula><p>If similar to <ref type="bibr" target="#b3">[4]</ref>, the constants c 1 and c 2 are set equal to each other, the following equation for computing the acceleration will always satisfy the stability condition:</p><formula xml:id="formula_26">c 1,ij (t) = c 2,ij (t) = c ij (t) = ω ij (t) + 1 (<label>20</label></formula><formula xml:id="formula_27">)</formula><p>where c ij (t) is ith particle's acceleration in the jth dimension that should be computed in iteration t. In the next section, we will show the appropriateness of the feedback parameter and the proposed inertia weight model at a given iteration during a course of run. The overall structure of the local best PSO algorithm is shown in Fig. <ref type="figure" target="#fig_3">2</ref>. This basic PSO is used to clearly show the influence of the inertia weight determination model. The local best topology is selected because it maintains diversity of the swarm better than the global best topology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental setup</head><p>In order to test and compare different inertia weight strategies reviewed in this paper, a suit of commonly used static test functions and moving peaks benchmark (MPB) as well as a real-world problem for a radar system design are used. Static problems are used to investigate the convergence speed and solution quality of the methods while the dynamic problems are used to evaluate the ability of the methods in tracking the extrema points in a dynamic environment.</p><p>Dynamic problems are more challenging for adaptive inertia weight strategies since after the convergence of the particles on peaks, the peaks may move and the algorithms should be able to speed up the particles to move toward the new positions of the peaks and then slow them down to refine the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Static test functions</head><p>To investigate the performance of the optimization algorithms, 22 test problems are adopted in this paper. Table <ref type="table">1</ref> provides a detailed description of unimodal and un-rotated multimodal problems and Table <ref type="table">2</ref> gives a detailed description of rotated multimodal problems and composition problems. The first 8 functions are unimodal functions while the rest of the functions are multimodal optimization problems. Unimodal functions f 2 , and f 4 -f 8 have asymmetric environment. In Table <ref type="table">2</ref>, the same method as that in <ref type="bibr" target="#b31">[32]</ref> is used to generate the orthogonal matrix (M). All the selected problems are minimization problems. For each of these problems, the best solution (X*), the best fitness and dimensions considered for functions are shown in Tables <ref type="table">1</ref> and<ref type="table">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Moving peaks benchmark</head><p>In order to evaluate the extrema tracking performance of the proposed inertia weight, dynamic test functions are generated using the MPB. MPB is a widely used benchmark problem proposed by Branke <ref type="bibr" target="#b50">[51]</ref>. The parameters applied to MPB are given in Table <ref type="table" target="#tab_0">3</ref>.</p><p>In the dynamic test functions, it is important to detect the environmental changes; so a method that detects environmental  Rosenbrock</p><formula xml:id="formula_28">f5(x) = D-1 i=1 [100(x 2 i -x i+1 ) 2 + (x i -1) 2 ] 30 [-5,10] D [1, . . ., 1] 0 McCormick f6(x) = sin(x1 + x2) + (x1 -x2) 2 -1.5x1 + 2.5x2 + 1 2 -1.5 ≤ x1 ≤ 4 -3 ≤ x2 ≤ 4 [-0.5471, -0.5471] -1.9133 Beale f7(x, y) = (1.5 -x + xy) 2 + (2.25 -x + xy 2 ) 2 + (2.625 -x + xy 3 ) 2 2 [-4.5,4.5] D [3,0.5] 0 Bukin N.6 f8(x, y) = 100 |y -0.01x 2 | + 0.01|x + 10| 2 -15 ≤ x ≤ -5 -3 ≤ y ≤ 3 [-10,1] 0 Schwefel f9(x) = D i=1 -x i sin |x i | 30 [-500,500] D [1, . . ., 1] -418.982D Rastrigin f10(x) = D i=1 (x 2 i -10 cos (2 x i ) + 10)<label>30</label></formula><p>[-5.12,5.12] D [0, . . ., 0] 0 Noncontinuois Rastrigin</p><formula xml:id="formula_29">f11(x) = D i=1</formula><p>(y 2 i -10 cos (2 y i ) + 10) </p><formula xml:id="formula_30">y i = x i |x i | &lt; 0.5 round(2x i ) 2 else</formula><formula xml:id="formula_31">(y i -1) 2 [1 + 10 sin 2 ( y i + 1)] + (yD -<label>1 2</label></formula><p>)</p><formula xml:id="formula_32">y i = 1 + x i -1 4 30 [-10,10] D [1, . . ., 1] 0 Shubert f15(x) = 5 i=1 i cos ((i + 1)x1 + i) 5 i=1 i cos ((i + 1)x2 + i) 2 [-10,10] D 18 global optima -186.7309</formula><p>changes and refreshes particles' memories are needed. If particles' memories are not updated, they will not have the ability to track the extrema <ref type="bibr" target="#b51">[52]</ref>. The method which is considered for detecting environmental changes is re-evaluating the global best particle before updating the global best particle. If its fitness changes, it indicates that an environmental change has occurred <ref type="bibr" target="#b52">[53]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Radar system design problem</head><p>In this section, a 20-dimensional spread spectrum radar polyphase code design problem in dynamic environments is introduced. This problem has been used in a noise-free static environment before <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b54">55]</ref>. Pulse compression technique is the most widely accepted technique in radar systems. The problem is a continuous min-max global optimization problem with numerous local optima. The min-max model is defined as</p><formula xml:id="formula_33">Global min f (x) = max{ 1 (X), 2 (X), . . ., 2m (X)} (<label>21</label></formula><formula xml:id="formula_34">)</formula><p>where</p><formula xml:id="formula_35">X = {(x 1 , x 2 , . . ., x D ) ∈ R D |0 ≤ x j ≤ 2 } , m = 2D -1 and (X) is 2i-1 (X) = D j=i cos ⎛ ⎝ J k=|2i-j-1|+1 x k + N k ⎞ ⎠ , i = 1, 2, . . ., D 2i (X) = 0.5 + D j=i+1 cos ⎛ ⎝ J k=|2i-j-1|+1 x k + N k ⎞ ⎠ , i = 1, 2, . . ., D -1 m+i (X) = -i (X), i = 1, 2, . . ., m Noise = {(N 1 , N 2 , . . ., N D ) ∈ R D | -0.5 ≤ N j ≤ 0.5}<label>(22)</label></formula><p>where Noise changes in every T function evaluations. Any change in Noise is introduced as environmental change. In each environmental change, T is a random number between 2000 and 5000. Thus, it is unknown that how long the algorithm needs to search the parameters under new conditions. Detection of environmental changes and refreshing the particles' memories is done as discussed in Section 4.2.  </p><formula xml:id="formula_36">z i = y i |y i | &lt; 0.5 round(2y i ) 2 else , Y = M * X 30 [-5.12,5.12] D [0, . . ., 0] 0 Rotated Ackley f19(x) = -20 exp ⎛ ⎝ -0.2 1 D D i=1 y 2 i ⎞ ⎠ + exp 1 D D i=1 cos (2 y i ) + 20 + ε Y = M * X 30 [-32,32] D [0, . . ., 0] 0 Rotated Griewank f 20 (x) = 1 4000 D i=1 y 2 i - D i=1 cos y i √ i + 1 Y = M * X<label>30</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Parameters setting</head><p>In all the experiments conducted in this paper, the number of particles in the swarm is 20 and the maximum allowed number of function evaluations is 200,000. The range of w ([w min , w max ]) for SAIW is [0.1, 1] and the initial value for all particles is 0.729 <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b55">56]</ref>. The parameters of other algorithms are set based on the recommended values in their corresponding references. The results of all experiments are averaged over 30 independent runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental results and discussion</head><p>In this section, the proposed strategy (SAIW) is compared with some other adjusting inertia weight models. In the first subsection, the stability of SAIW will be analyzed in two static problems with symmetric and asymmetric environments. Then the results are extended to the other problems. In the second subsection, different inertia weight adjusting strategies, including SAIW, are applied to static problems and MPB; then the results are compared based on the final accuracy and the convergence speed. In the third subsection, SAIW is integrated with some recently published PSO variants and the resulting methods are applied to static problems and the radar system design problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Stability analysis of SAIW</head><p>Stable PSO often performs better than an unstable PSO <ref type="bibr" target="#b56">[57]</ref>. The upper border stability limit (USL) map will be used to analyze the stability of the SAIW <ref type="bibr" target="#b11">[12]</ref>. Every optimization algorithm has a specific USL map for each benchmark considering the way it adjusts the parameters and uses random distributions. The best algorithm performance results if the parameters are tuned close to the optimum area in the USL map <ref type="bibr" target="#b11">[12]</ref>, although it does not guarantee an optimal solution for different problems.</p><p>To generate the map, first, the possible values for accelerations and inertia weight are determined in a way that they do not refute the stability condition. Then, these values are divided into specific intervals. The best fitness of the algorithm in these intervals are averaged for 50 independent runs and the normalized average is shown in the map. The distance is considered equal to 0.1. Fig. <ref type="figure" target="#fig_7">3</ref> shows the USL map for the two functions Rosenbrock (f 5 ) and Sphere (f 1 ).</p><p>In this figure, E(w) is the mean inertia weight and E(phi) is the mean acceleration. Using the adaptive inertia weight and adaptive acceleration, the USL map of SAIW has a wide optimum area. If the optimum area is wide, the inertia weight and acceleration will be in this area with a higher probability. Then the performance is optimal in most of the iterations. For example, in Fig. <ref type="figure" target="#fig_8">4</ref> the mean of inertia weight, acceleration and the final best value for functions Sphere (f 1 ) and Rosenbrock (f 5 ) are shown. The inertia weight mean and the acceleration mean for these two functions are in the optimum area of their corresponding USL map. Similarly, it can be concluded that the proposed strategy for all of the functions usually selects the inertia weight and acceleration in the optimum area of that problem's corresponding USL map. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Comparison with other inertia weight adjusting methods</head><p>From all strategies introduced in the previous sections, six strategies are adopted in this study for comparisons: Fine Grained Inertia Weight(FGIW) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b57">58]</ref>, Double Exponential Self-adaptive Inertia Weight (DESIW) <ref type="bibr" target="#b1">[2]</ref>, Rank-based Inertia Weight (Rankbased) <ref type="bibr" target="#b3">[4]</ref>, Adaptive Inertia Weight (AIW) <ref type="bibr" target="#b3">[4]</ref>, Linear Decreasing Inertia Weight (LDIW) <ref type="bibr" target="#b4">[5]</ref>, Chaotic Descending Inertia Weight (CDIW) <ref type="bibr" target="#b39">[40]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1.">Static test functions</head><p>The six inertia weight strategies and SAIW are applied to the static test functions. The mean, standard deviation and the best fitness value found by each method are recorded in Table <ref type="table" target="#tab_1">4</ref>. The bold numbers in this table indicate the best solutions for functions according to a t-test with a significance level of 5%.</p><p>Results indicate that the proposed strategy provides the best accuracy in 17 out of 22 test problems. This good performance results due to the adaptive nature of the inertia weight and acceleration in SAIW. By stability analyses done, the performance of the algorithm is the best one in most of the iterations. Although the algorithm's performance is comparable with those of the other successful algorithms in 5 out of 22 test problems, but SAIW could not sufficiently maintain the particles' diversity, and thus produced a lower performance.</p><p>A closer look at the convergence curves of different algorithms for some test functions (Fig. <ref type="figure" target="#fig_10">5</ref>) provides more insight into their searching behavior. For most of the functions, the proposed strategy is better than other strategies and particles converge faster to the better value. In addition, inertia weight adjustment in different dimensions has greatly improved the convergence speed in asymmetric environments.</p><p>The convergence curve in unimodal functions indicates that no matter how far the best particle is from the global optimum, the SAIW's convergence is continuous during a course of run. The convergence speed of the proposed method is also independent from the iteration number. In multi modal environments, keeping diversity is one of the reasons that the algorithms operate appropriately. The proposed method was able to keep diversity in most of the iterations, by adjusting acceleration parameters larger than one, increasing the inertia weight and using local best topology. For the multimodal functions, the horizontal regions of the SAIW curves appear due to the convergence of the algorithm to the optima.</p><p>Discussions in the next section present more details about the operation of these inertia weight methods in the static environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">Extrema tracking</head><p>In this section, the seven inertia weight strategies are applied to the dynamic test function defined in Section 4.2. The performance measures used to investigate the effectiveness of strategies are the current error and the offline error defined in <ref type="bibr" target="#b58">[59]</ref>. Table <ref type="table" target="#tab_2">5</ref> lists the mean and standard deviation of the offline errors found by each method. The bold number indicate the best solution according to a t-test with a significance level of 5%. Based on the    information presented in this table, the proposed method (SAIW) operates much better than other methods. The method uses adaptive inertia weight and adaptive acceleration. As a result, it can track the optima despite environmental changes and can converge to the optima better than the other methods. The method adjusts the inertia weight for each particle in each dimension. Thus after environmental changes, diversity increases to improve the ability of tracking the optima.</p><p>LDIW and CDIW methods use no feedback for adjusting the inertia weight. In these methods, the inertia weight is initially about 1 and in the final iterations, it is about 0.4. Although they could converge to better values in the last steps, because of the big inertia they could not converge to the appropriate value in initial steps; so they do not have the ability to track the optima. The CDIW method has a better performance in comparison to LDIW, because the chaotic parameter in this method randomly increases or decreases the The other methods use feedback to adjust the inertia weight. The number of fitness computations for changing the environment is set to 3000 so that the convergence speeds become comparable. The Rank-based method adjusts the inertia weight for each particle similar to the proposed method. This method has some particles with appropriate inertia weight that can increase the diversity after each objective function change, but it cannot adjust the suitable inertia weight for all of the particles. It sets the inertia weight of half of the particles to a value larger than 0.5. So, this approach needs more function evaluations when improving the convergence ability is needed.</p><p>Since the AIW method sets the acceleration parameters to 2 and uses the success rate feedback, it can easily increase the diversity and improve the ability of tracking the optima when the environmental change occurs. But in situations where the particles are close to the optima, a high convergence ability is desired, while the success rate will approximately be zero. This happens since most of the particles cannot improve their fitness. Thus, the algorithm operation will depend on the acceleration and the diversity increase is more probable. This operation happens frequently for narrow and asymmetric peaks; so the algorithm needs more function evaluations.</p><p>The FGIW method highly decreases the inertia weights of the particles which are close to the global best particle, and slightly decreases the inertia weights of the particles which are far from the global best particle. But this method uses a Gaussian kernel for computing the distance which has a large standard deviation close to the maximum number of iterations at the beginning. It does not matter how far the particles from each other are, the inertia weight of all of the particles will be about 0.4 due to the extremely large standard deviation at the beginning of a run. From this point on, since there is no mechanism for increasing the inertia weight, the particles will continue searching with the constant inertia weight of 0.4.</p><p>The DESIW method is similar to the FGIW method, with the only difference being in determination of the Gaussian kernel standard deviation. This method's standard deviation is initially small and becomes very large in the final steps. DESIW adjusts the inertia weight properly at first; but after several iterations, by increasing the standard deviation of the kernel, the performance index becomes zero and the Gompertz function sets all of the particles' inertia weights close to 1. Therefore, this method can track the optima in initial iterations, but its convergence ability is low. After several iterations, it loses the ability of tracking the optima. Fig. <ref type="figure" target="#fig_11">6(c)</ref> shows the performance of this method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Integration with several PSO variants</head><p>In this section, five state-of-the-art PSO algorithms are selected for integration with SAIW: Comprehensive Learning PSO (CLPSO) <ref type="bibr" target="#b31">[32]</ref>, Orthogonal Learning Local PSO (OLPSO-L) <ref type="bibr" target="#b33">[34]</ref>, PSO algorithm with Adaptive Inertia Weight (AIWPSO) <ref type="bibr" target="#b3">[4]</ref>, PSO with an Aging  Leader and Challengers (ALC-PSO) <ref type="bibr" target="#b17">[18]</ref>, Low-discrepancy Sequence Initialized Particles and High-order Nonlinear Dynamic Varying Inertia Weight (LHNPSO) <ref type="bibr" target="#b43">[44]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1.">Integration with some PSO variants on static test problems</head><p>These PSO algorithms are applied to the static test functions with and without SAIW. Table <ref type="table" target="#tab_3">6</ref> lists the mean, standard deviation and the best fitness value found by each method. The bold numbers in each column indicate the best solutions for each method according to a t-test with a significance level of 5%.</p><p>Results show that the best accuracy in 15 out of 22 test problems is obtained when CLPSO is integrated with SAIW. Similarly, 21 out of 22 test problems and 17 out of 22 test problems have the best accuracy when OLPSO-L and ALC-PSO are integrated with SAIW. This good performance results due to the adaptive nature of the inertia weight in SAIW. Preservation of diversity in CLPSO, OLPSO and ALC-PSO is one of the reasons that the algorithms operate appropriately. The proposed method was able to balance between exploration and exploitation properly when it was integrated with the above methods.</p><p>SAIW leads to efficiency improvement for AIWPSO, especially on unimodal functions; but its performance is comparable on multimodal functions, since AIWPSO is affected by mutation. From the exploration/exploitation perspective, the mutation in this method firstly plays exploration role and plays exploitation role at last. Thus, original method loses time because of undue exploration in unimodal function.</p><p>SAIW did not make any improvement in the performance of LHNPSO. The difference between LHNPSO and the standard PSO is in the way the inertia weight is adjusted. The inertia weight in the LHNPSO method is in the range [0.4, 1]. Thus, the particles' diversity in this algorithm is maintained for a longer period in comparison with LHNPSO using SAIW.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2.">Integration with some PSO variants on radar system design</head><p>The mentioned PSO algorithms are applied to the radar system design problem defined in Section 4.3. Then the results of the algorithms before and after integration with SAIW are compared based on the offline accuracy ( ) defined as</p><formula xml:id="formula_37">= 1 K K i=1 f i<label>(23)</label></formula><p>where f i is the best solution obtained by an algorithm just before the ith environmental change and K is the total number of environments. Table <ref type="table" target="#tab_4">7</ref> lists the mean and standard deviation of the found by each method before and after integration with SAIW. The bold numbers in each column indicate the best solution according to a t-test with a significance level of 5%.</p><p>Results indicate that SAIW leads to efficiency improvement for CLPSO and OLPSO-L. This model, however, cannot change the performance of AIWPSO, since it is affected by mutation. In consequence, the inertia weight has low effect on this algorithm. The inertia weight model used in this algorithm is compared with SAIW in Table <ref type="table" target="#tab_1">4</ref>.</p><p>Due to the assumed value for the challenge parameter in ALC-PSO and fast environmental change, the ALC-PSO executes the aging challenge for two or three times. Hence, its performance is similar to the standard PSO. In this algorithm, the particles' diversity decreases very fast and SAIW cannot increase the particles' diversity due to very high diversity decreasing pressure. LHNPSO is the standard PSO. Thus the problem of fast diversity decrease still exists. But there is a difference: the inertia weight in LHNPSO varies between 0.4 and 0.7. The particles' diversity in the original algorithm is maintained for a longer period in comparison with LHNPSO using SAIW. Thus in this complex multi-modal problem, SAIW could not improve the results of LHNPSO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>The balance between global and local search throughout the course of a run is critical to the success of an optimization algorithm. In the PSO algorithm, the inertia weight is introduced for higher balance between the global and local search. When the inertia weight changes dynamically, the search capability is also adjusted dynamically. Many different strategies have been proposed for determining the value of the inertia weight, among which, adaptive approaches were selected for development. Adaptive approaches do not show the limits of have other approaches and can adjust the value of the inertia weight by using appropriate feedback. Adaptive approaches have some shortcomings in selecting proper feedback and disregarding the stability conditions. By changing the inertia weight adaptively, stability conditions change adaptively, too.</p><p>This paper proposed a new adaptive inertia weight strategy based on the success of particles in the last two iterations and the displacement of its best position. Each particle's situation in the swarm affects the adjustment of the inertia weight. Thus, in the proposed method, each particle has its own inertia weight in different dimensions. In addition, acceleration coefficients are adaptively adjusted with the help of inertia weight and stability condition.</p><p>Experimental results clearly show the superiority of the proposed model over other inertia weight adjusting models. The comparisons are made in terms of convergence speed and solution accuracy. This method's good experimental results are due to adaptive nature of the inertia weight and acceleration of each particle. With regard to stability analyses in most of the iterations, the proposed algorithm has the best performance. Also it is possible to use a different method for adjusting acceleration adaptively, so that in addition to satisfying the stability condition, it would have more effect on keeping the diversity, if needed.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Two different situations that a particle of PSO may succeed during the search. The particle's best position in the last two iterations are (a) close to each other, and (b) far from each other.</figDesc><graphic coords="4,319.19,56.20,216.00,389.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Pseudo code of lbest particle swarm optimization algorithm.</figDesc><graphic coords="5,330.00,484.16,216.00,243.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1</head><label>1</label><figDesc>Unimodal and un-rotated multimodal problems used in the experiments of this paper.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>2</head><label>2</label><figDesc>Rotated multimodal problems and composition problems used in the experiments of this paper. i -10 cos (2 z i ) + 10)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Upper border stability limit (USL) Map on (a) Rosenbrock (f5), (b) sphere (f1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The mean of inertia and acceleration of swarm in each iteration on (a) Rosenbrock (f5), (b) Sphere (f1).</figDesc><graphic coords="8,100.45,540.68,384.00,186.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>15 M</head><label>15</label><figDesc>article in press as: M. Taherkhani, R. Safabakhsh, A novel stability-based adaptive inertia weight for particle swarm optimization, Appl. Soft Comput. J. (2015), http://dx.doi.org/10.1016/j.asoc.2015.10.004 . Taherkhani, R. Safabakhsh / Applied Soft Computing xxx (2015) xxx-xxx</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The curve of the best fitness from 30 independent runs of seven inertia weight adjusting methods on (a) Sphere (f1), (b) Rotated hyper ellipsoid (f2), (c) Rosenbrock (f5), (d) Schwefel (f9), (e) levy (f14) and (f) Griewank.</figDesc><graphic coords="10,77.45,56.08,429.60,566.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Simulation results for dynamic test function (a) LDIW, (b) CDIW, (c) DESIW.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 3</head><label>3</label><figDesc>Parameters setting for the moving peaks benchmark (MPB).</figDesc><table><row><cell>[-600,600] D</cell><cell>[0, . . ., 0]</cell><cell>0</cell></row></table><note><p>f22(x) is composed using ten different benchmark functions: two rotated Rastrigin's functions, two rotated Weierstrass functions, two rotated Griewank's functions, two rotated Ackley's functions, and two sphere functions</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 4</head><label>4</label><figDesc>The mean, standard deviation and best fitness value of seven inertia weigh adjusting methods on static test functions.</figDesc><table><row><cell></cell><cell></cell><cell>SAIW</cell><cell>FGIW</cell><cell>DESIW</cell><cell>Rank-based</cell><cell>AIW</cell><cell>LDIW</cell><cell>CDIW</cell></row><row><cell>f1</cell><cell>MeanStdBest</cell><cell>3.8378e-147</cell><cell>0.0781e-77</cell><cell>4.5631e+03</cell><cell>0.0447e-20</cell><cell>5.5930</cell><cell>0.0638e-05</cell><cell>0.0639e-16</cell></row><row><cell></cell><cell></cell><cell>(7.8531e-147)</cell><cell>(0.2454e-77)</cell><cell>(2.5657e+03)</cell><cell>(0.1128e-20)</cell><cell>(12.6900)</cell><cell>(0.1387e-05)</cell><cell>(0.2011e-16)</cell></row><row><cell></cell><cell></cell><cell>3.3406e-154</cell><cell>1.9524e-89</cell><cell>0.0176</cell><cell>5.6974e-69</cell><cell>2.2847e-163</cell><cell>7.2529e-54</cell><cell>7.1738e-115</cell></row><row><cell>f2</cell><cell>MeanStdBest</cell><cell>4.1457e-16</cell><cell>1.3589e+03</cell><cell>2.8422e+04</cell><cell>53.29</cell><cell>611.7399</cell><cell>451.3564</cell><cell>174.2312</cell></row><row><cell></cell><cell></cell><cell>(5.0652e-16)</cell><cell>(2.7174e+03)</cell><cell>(0.4586e+04)</cell><cell>(62.5558)</cell><cell>(264.9155)</cell><cell>(332.4188)</cell><cell>(123.4947)</cell></row><row><cell></cell><cell></cell><cell>1.0884e-17</cell><cell>3.5262e-04</cell><cell>1.9653e+04</cell><cell>1.5252e-04</cell><cell>2.9107e-04</cell><cell>0.0016</cell><cell>8.9977e-06</cell></row><row><cell>f3</cell><cell>MeanStdBest</cell><cell>1.4</cell><cell>0.2</cell><cell>1.2</cell><cell>0.1</cell><cell>0.1</cell><cell>0.1</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>(1.3499)</cell><cell>(0.4216)</cell><cell>(1.5492)</cell><cell>(0.3162)</cell><cell>(0.3162)</cell><cell>(0.3162)</cell><cell>(0)</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>f4</cell><cell>MeanStdBest</cell><cell>15.8519</cell><cell>15.8519</cell><cell>15.8519</cell><cell>15.8519</cell><cell>15.7234</cell><cell>15.8519</cell><cell>15.8519</cell></row><row><cell></cell><cell></cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0.4062)</cell><cell>(0)</cell><cell>(0)</cell></row><row><cell></cell><cell></cell><cell>15.8519</cell><cell>15.8519</cell><cell>15.8519</cell><cell>15.8519</cell><cell>14.5673</cell><cell>15.8519</cell><cell>15.8519</cell></row><row><cell>f5</cell><cell>MeanStdBest</cell><cell>9.8863</cell><cell>33.5664</cell><cell>64.1105</cell><cell>47.7654</cell><cell>88.6711</cell><cell>53.3994</cell><cell>27.9060</cell></row><row><cell></cell><cell></cell><cell>(19.9640)</cell><cell>(24.7951)</cell><cell>(59.3005)</cell><cell>(25.2630)</cell><cell>(61.0362)</cell><cell>(54.4457)</cell><cell>(15.8846)</cell></row><row><cell></cell><cell></cell><cell>0.0087</cell><cell>18.7568</cell><cell>6.0143</cell><cell>19.9631</cell><cell>5.7984</cell><cell>20.5944</cell><cell>8.3201</cell></row><row><cell>f6</cell><cell>MeanStdBest</cell><cell>-1.9132</cell><cell>-1.9132</cell><cell>-1.9132</cell><cell>-1.9132</cell><cell>-1.9132</cell><cell>-1.9132</cell><cell>-1.9132</cell></row><row><cell></cell><cell></cell><cell>(4.6811e-16)</cell><cell>(8.8564e-11)</cell><cell>(8.6181e-04)</cell><cell>(5.6922e-06)</cell><cell>(3.1936e-15)</cell><cell>(3.7821e-12)</cell><cell>(3.6711e-13)</cell></row><row><cell></cell><cell></cell><cell>-1.9132</cell><cell>-1.9132</cell><cell>-1.9132</cell><cell>-1.9132</cell><cell>-1.9132</cell><cell>-1.9132</cell><cell>-1.9132</cell></row><row><cell>f7</cell><cell>MeanStdBest</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.0762</cell><cell>0</cell><cell>0.0762</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0.2410)</cell><cell>(0)</cell><cell>(0.2410)</cell><cell>(0)</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>f8</cell><cell>MeanStdBest</cell><cell>0.0092</cell><cell>0.0346</cell><cell>0.0337</cell><cell>0.0114</cell><cell>0.0539</cell><cell>0.0121</cell><cell>0.0069</cell></row><row><cell></cell><cell></cell><cell>(0.0056)</cell><cell>(0.0153)</cell><cell>(0.0176)</cell><cell>(0.0112)</cell><cell>(0.0367)</cell><cell>(0.0119)</cell><cell>(0.0056)</cell></row><row><cell></cell><cell></cell><cell>0.0016</cell><cell>0.0090</cell><cell>0.0128</cell><cell>0.0014</cell><cell>0.0101</cell><cell>0.0017</cell><cell>6.6342e-04</cell></row><row><cell>f9</cell><cell>MeanStdBest</cell><cell>-6.3762e+03</cell><cell>-1.0755e+04</cell><cell>-6.6590e+03</cell><cell>-6.5581e+03</cell><cell>-6.6957e+03</cell><cell>-8.0975e+03</cell><cell>-7.4893e+03</cell></row><row><cell></cell><cell></cell><cell>(0.746e+03)</cell><cell>(0.1069e+04)</cell><cell>(0.2557 e+03)</cell><cell>(1.0642e+03)</cell><cell>(1.2556e+03)</cell><cell>(0.8399e+03)</cell><cell>(0.3785e+03)</cell></row><row><cell></cell><cell></cell><cell>-7.5154e+03</cell><cell>-1.1622e+04</cell><cell>-7.0421e+03</cell><cell>-7.9304e+03</cell><cell>-9.3526e+03</cell><cell>-9.2911e+03</cell><cell>-8.0490e+03</cell></row><row><cell>f10</cell><cell>MeanStdBest</cell><cell>29.8487</cell><cell>49.5532</cell><cell>182.3460</cell><cell>26.8000</cell><cell>83.1217</cell><cell>64.5921</cell><cell>46.3624</cell></row><row><cell></cell><cell></cell><cell>(10.5401)</cell><cell>(41.7900)</cell><cell>(66.2803)</cell><cell>(11.0330)</cell><cell>(53.5285)</cell><cell>(47.3677)</cell><cell>(39.8611)</cell></row><row><cell></cell><cell></cell><cell>15.9193</cell><cell>11.9399</cell><cell>65.6672</cell><cell>13.9785</cell><cell>0.9950</cell><cell>16.9391</cell><cell>18.9042</cell></row><row><cell>f11</cell><cell>MeanStdBest</cell><cell>31.8</cell><cell>69.0454</cell><cell>139.6252</cell><cell>58.4801</cell><cell>76.1743</cell><cell>78.8984</cell><cell>70.6844</cell></row><row><cell></cell><cell></cell><cell>(10.3043)</cell><cell>(42.5711)</cell><cell>(53.6502)</cell><cell>(47.1976)</cell><cell>(35.1449)</cell><cell>(33.1547)</cell><cell>(45.9553)</cell></row><row><cell></cell><cell></cell><cell>14</cell><cell>28</cell><cell>61</cell><cell>0</cell><cell>1.1369e-13</cell><cell>11</cell><cell>1.1369e-13</cell></row><row><cell>f12</cell><cell>MeanStdBest</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell></row><row><cell></cell><cell></cell><cell>(3.7449e-15)</cell><cell>(3.7449e-15)</cell><cell>(3.7449e-15)</cell><cell>(5.7433e-10)</cell><cell>(3.7449e-15)</cell><cell>(5.3520e-09)</cell><cell>(3.7449e-15)</cell></row><row><cell></cell><cell></cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell></row><row><cell>f13</cell><cell>MeanStdBest</cell><cell>0.0022</cell><cell>0.0513</cell><cell>162.7438</cell><cell>0.0199</cell><cell>0.4080</cell><cell>0.0140</cell><cell>0.0152</cell></row><row><cell></cell><cell></cell><cell>(0.0047)</cell><cell>(0.0625)</cell><cell>(44.8815)</cell><cell>(0.0279)</cell><cell>(0.5215)</cell><cell>(0.0198)</cell><cell>(0.0182)</cell></row><row><cell></cell><cell></cell><cell>1.1102e-16</cell><cell>0</cell><cell>102.5002</cell><cell>0</cell><cell>0.0024</cell><cell>1.4651e-10</cell><cell>0</cell></row><row><cell>f14</cell><cell>MeanStdBest</cell><cell>0.2347</cell><cell>0.2237</cell><cell>2.6163</cell><cell>0.0385e-14</cell><cell>0.0022</cell><cell>0.0647</cell><cell>0.0647</cell></row><row><cell></cell><cell></cell><cell>(0.2511)</cell><cell>(0.6619)</cell><cell>(2.5672)</cell><cell>(0.1215e-14)</cell><cell>(0.0068)</cell><cell>(0.2045)</cell><cell>(0.2045)</cell></row><row><cell></cell><cell></cell><cell>1.5705e-32</cell><cell>1.5705e-32</cell><cell>0.1612</cell><cell>1.5705e-32</cell><cell>1.5705e-32</cell><cell>7.5942e-15</cell><cell>1.0688e-28</cell></row><row><cell>f15</cell><cell>MeanStdBest</cell><cell>-186.7309</cell><cell>-186.7306</cell><cell>-186.7309</cell><cell>-186.7309</cell><cell>-186.7309</cell><cell>-186.7309</cell><cell>-186.7309</cell></row><row><cell></cell><cell></cell><cell>(4.9228e-14)</cell><cell>(0.0009)</cell><cell>(3.2819e-14)</cell><cell>(2.6101e-13)</cell><cell>(1.6409e-14)</cell><cell>(2.8422e-14)</cell><cell>(2.5066e-14)</cell></row><row><cell></cell><cell></cell><cell>-186.7309</cell><cell>-186.7309</cell><cell>-186.7309</cell><cell>-186.7309</cell><cell>-186.7309</cell><cell>-186.7309</cell><cell>-186.7309</cell></row><row><cell>f16</cell><cell>MeanStdBest</cell><cell>-6.1921e+03</cell><cell>-6.3181e+03</cell><cell>-6.3236e+03</cell><cell>-5.8098e+03</cell><cell>-5.6386e+03</cell><cell>-7.0441e+03</cell><cell>-6.2642e+03</cell></row><row><cell></cell><cell></cell><cell>(0.548e+03)</cell><cell>(0.712e+03)</cell><cell>(0.428e+03)</cell><cell>(0.752e+03)</cell><cell>(0.557e+03)</cell><cell>(0.847e+03)</cell><cell>(0.677e+03)</cell></row><row><cell></cell><cell></cell><cell>-7.4426e+03</cell><cell>-8.2104e+03</cell><cell>-7.2761e+03</cell><cell>-7.5399e+03</cell><cell>-7.0624e+03</cell><cell>-8.7169e+03</cell><cell>-7.8240e+03</cell></row><row><cell>f17</cell><cell>MeanStdBest</cell><cell>45.7844</cell><cell>216.4813</cell><cell>259.2239</cell><cell>180.2389</cell><cell>177.2325</cell><cell>184.2437</cell><cell>177.7256</cell></row><row><cell></cell><cell></cell><cell>(18.0821)</cell><cell>(24.3625)</cell><cell>(18.6855)</cell><cell>(11.8019)</cell><cell>(9.7481)</cell><cell>(12.5113)</cell><cell>(12.2096)</cell></row><row><cell></cell><cell></cell><cell>22.8840</cell><cell>166.0213</cell><cell>211.3691</cell><cell>158.9275</cell><cell>156.8937</cell><cell>157.1682</cell><cell>150.6781</cell></row><row><cell>f18</cell><cell>MeanStdBest</cell><cell>59.8541</cell><cell>188.7777</cell><cell>257.6426</cell><cell>146.4381</cell><cell>145.7129</cell><cell>141.6934</cell><cell>135.4173</cell></row><row><cell></cell><cell></cell><cell>(20.1018)</cell><cell>(22.3233)</cell><cell>(27.02)</cell><cell>(18.8966)</cell><cell>(9.7481)</cell><cell>(18.3782)</cell><cell>(20.6140)</cell></row><row><cell></cell><cell></cell><cell>23</cell><cell>139.5610</cell><cell>189.3334</cell><cell>103.3431</cell><cell>129.1654</cell><cell>100.0498</cell><cell>73.1810</cell></row><row><cell>f19</cell><cell>MeanStdBest</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell></row><row><cell></cell><cell></cell><cell>(3.6134e-15)</cell><cell>(3.6134e-15)</cell><cell>(3.6134e-15)</cell><cell>(3.6134e-15)</cell><cell>(3.6134e-15)</cell><cell>(3.6134e-15)</cell><cell>(3.6134e-15)</cell></row><row><cell></cell><cell></cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell><cell>22.7183</cell></row><row><cell>f20</cell><cell>MeanStdBest</cell><cell>0.0207</cell><cell>0.0248</cell><cell>613.8306</cell><cell>0.0373</cell><cell>1.9256</cell><cell>0.4159</cell><cell>0.0502</cell></row><row><cell></cell><cell></cell><cell>(0.0197)</cell><cell>(0.0224)</cell><cell>(119.5419)</cell><cell>(0.0403)</cell><cell>(2.3674)</cell><cell>(0.2267)</cell><cell>(0.0531)</cell></row><row><cell></cell><cell></cell><cell>2.5535e-15</cell><cell>7.0985e-08</cell><cell>399.8084</cell><cell>0.0014</cell><cell>0.3297</cell><cell>0.1323</cell><cell>0.0024</cell></row><row><cell>f21</cell><cell>MeanStdBest</cell><cell>25.3333</cell><cell>26.6667</cell><cell>27.2022</cell><cell>56.6667</cell><cell>93.3102</cell><cell>63.3333</cell><cell>56.6667</cell></row><row><cell></cell><cell></cell><cell>(41.9307)</cell><cell>(44.9776)</cell><cell>(45.0720)</cell><cell>(72.7932)</cell><cell>(109.5172)</cell><cell>(85.0287)</cell><cell>(81.7200)</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>f22</cell><cell>MeanStdBest</cell><cell>62.3127</cell><cell>26.5788</cell><cell>58.1712</cell><cell>108.8475</cell><cell>59.8144</cell><cell>88.5331</cell><cell>59.1237</cell></row><row><cell></cell><cell></cell><cell>(62.3360)</cell><cell>(39.8361)</cell><cell>(98.4262)</cell><cell>(140.0772)</cell><cell>(94.1110)</cell><cell>(140.0682)</cell><cell>(97.1951)</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1.3672</cell><cell>0</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 5</head><label>5</label><figDesc>The mean and standard deviation of offline error for seven inertia weigh adjusting methods on MPB.</figDesc><table><row><cell></cell><cell>SDIW</cell><cell>FGIW</cell><cell>DESIW</cell><cell>Rank-based</cell><cell>AIW</cell><cell>LDIW</cell><cell>CDIW</cell></row><row><cell>Mean offline</cell><cell>0.7631</cell><cell>2.2198</cell><cell>91.5260</cell><cell>65.1170</cell><cell>26.8419</cell><cell>86.7336</cell><cell>59.4043</cell></row><row><cell>Error std</cell><cell>(0.4336)</cell><cell>(0.4689)</cell><cell>(0.6693)</cell><cell>(2.5729)</cell><cell>(2.5470)</cell><cell>(1.9571)</cell><cell>(3.0890)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6</head><label>6</label><figDesc>The mean, standard deviation and best fitness value of five PSO variants on static test functions before integration with SAIW and after it.</figDesc><table><row><cell></cell><cell></cell><cell>CLPSO</cell><cell></cell><cell>OLPSO-L</cell><cell></cell><cell>AIWPSO</cell><cell></cell><cell>ALC-PSO</cell><cell></cell><cell>LHNPSO</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Original</cell><cell>Integrated</cell><cell>Original</cell><cell>Integrated</cell><cell>Original</cell><cell>Integrated</cell><cell>Original</cell><cell>Integrated</cell><cell>Original</cell><cell>Integrated</cell></row><row><cell>f1</cell><cell>Mean</cell><cell>2.500e-06</cell><cell>1.201e-02</cell><cell>3.542e-158</cell><cell>0</cell><cell>1.163e-144</cell><cell>7.096e-109</cell><cell>4.188e-38</cell><cell>7.391e-122</cell><cell>1.500e-04</cell><cell>5.200e-03</cell></row><row><cell></cell><cell>Std</cell><cell>(0.046e-15)</cell><cell>(6.026e-04)</cell><cell>(4.090e-40)</cell><cell>(0)</cell><cell>(2.05e-144)</cell><cell>(1.58e-108)</cell><cell>(8.236e-38)</cell><cell>(1.42e-121)</cell><cell>(6.29e-10)</cell><cell>(1.92e-04)</cell></row><row><cell></cell><cell>Best</cell><cell>5.631e-24</cell><cell>4.390e-06</cell><cell>1.411e-287</cell><cell>0</cell><cell>9.749e-151</cell><cell>5.812e-123</cell><cell>2.438e-160</cell><cell>1.770e-124</cell><cell>6.38e-13</cell><cell>3.00e-08</cell></row><row><cell>f2</cell><cell>Mean</cell><cell>4.170e+04</cell><cell>2.594e+04</cell><cell>1.014</cell><cell>0.783</cell><cell>0.006</cell><cell>2.566e-14</cell><cell>5.360e-11</cell><cell>5.221e-17</cell><cell>8.016e+04</cell><cell>2.160e+05</cell></row><row><cell></cell><cell>Std</cell><cell>(7.400e+03)</cell><cell>(8.757e+03)</cell><cell>(1.240)</cell><cell>(1.430)</cell><cell>(0.007)</cell><cell>(5.738e-14)</cell><cell>(3.601e-11)</cell><cell>(8.231e-17)</cell><cell>(6.33e+04)</cell><cell>(1.49e+05)</cell></row><row><cell></cell><cell>Best</cell><cell>3.418e+04</cell><cell>1.398e+04</cell><cell>0.001</cell><cell>0.009</cell><cell>3.141e-04</cell><cell>1.046e-19</cell><cell>1.905e-11</cell><cell>1.503e-20</cell><cell>1.666e+04</cell><cell>4.166e+04</cell></row><row><cell>f3</cell><cell>Mean</cell><cell>2.250</cell><cell>6.600</cell><cell>3.89</cell><cell>0</cell><cell>0</cell><cell>7.400</cell><cell>0</cell><cell>0</cell><cell>325</cell><cell>347</cell></row><row><cell></cell><cell>Std</cell><cell>(3.201)</cell><cell>(5.518)</cell><cell>(2.497)</cell><cell>(0)</cell><cell>(0)</cell><cell>(10.502)</cell><cell>(0)</cell><cell>(0)</cell><cell>(150)</cell><cell>(88.580)</cell></row><row><cell></cell><cell>Best</cell><cell>0</cell><cell>1.7</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>200</cell><cell>302</cell></row><row><cell>f4</cell><cell>Mean</cell><cell>14.391</cell><cell>14.212</cell><cell>13.191</cell><cell>3.612</cell><cell>11.889</cell><cell>11.016</cell><cell>15.851</cell><cell>15.851</cell><cell>15.851</cell><cell>16.035</cell></row><row><cell></cell><cell>Std</cell><cell>(0.262)</cell><cell>(0.310)</cell><cell>(0.163)</cell><cell>(0.653)</cell><cell>(0.834)</cell><cell>(1.682)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0.409)</cell></row><row><cell></cell><cell>Best</cell><cell>14.189</cell><cell>14.123</cell><cell>12.957</cell><cell>2.949</cell><cell>10.704</cell><cell>8.661</cell><cell>15.851</cell><cell>15.851</cell><cell>15.851</cell><cell>15.851</cell></row><row><cell>f5</cell><cell>Mean</cell><cell>56.589</cell><cell>29.460</cell><cell>60.350</cell><cell>0.313</cell><cell>11.842</cell><cell>1.722</cell><cell>22.885</cell><cell>1.633</cell><cell>102.605</cell><cell>98.935</cell></row><row><cell></cell><cell>Std</cell><cell>(31.383)</cell><cell>(5.539)</cell><cell>(43.355)</cell><cell>(0.607)</cell><cell>(8.148)</cell><cell>(2.308)</cell><cell>(35.217)</cell><cell>(2.148)</cell><cell>(139.923)</cell><cell>(85.712)</cell></row><row><cell></cell><cell>Best</cell><cell>33.987</cell><cell>19.910</cell><cell>19.103</cell><cell>0.001</cell><cell>3.986</cell><cell>6.302e-04</cell><cell>0.005</cell><cell>5.308e-06</cell><cell>7.612</cell><cell>6.121</cell></row><row><cell>f6</cell><cell>Mean</cell><cell>-2.538</cell><cell>-2.153</cell><cell>-1.913</cell><cell>-1.913</cell><cell>-11.459</cell><cell>-14.401</cell><cell>-1.913</cell><cell>-1.913</cell><cell>-1.913</cell><cell>-1.913</cell></row><row><cell></cell><cell>Std</cell><cell>(1.250)</cell><cell>(0.412)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0.900)</cell><cell>(0.976)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell></row><row><cell></cell><cell>Best</cell><cell>-4.413</cell><cell>-2.865</cell><cell>-1.913</cell><cell>-1.913</cell><cell>-12.762</cell><cell>-16.076</cell><cell>-1.913</cell><cell>-1.913</cell><cell>-1.913</cell><cell>-1.913</cell></row><row><cell>f7</cell><cell>Mean</cell><cell>2.165e-12</cell><cell>2.124e-13</cell><cell>0.749</cell><cell>5.529e-29</cell><cell>0</cell><cell>0</cell><cell>0.190</cell><cell>0.152</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>Std</cell><cell>(4.329e-12)</cell><cell>(4.484e-12)</cell><cell>(0.869)</cell><cell>7.545e-29</cell><cell>(0)</cell><cell>(0)</cell><cell>(0.381)</cell><cell>(0.340)</cell><cell>(0)</cell><cell>(0)</cell></row><row><cell></cell><cell>Best</cell><cell>1.581e-20</cell><cell>1.042e-20</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>f8</cell><cell>Mean</cell><cell>0.032</cell><cell>0.005</cell><cell>0.018</cell><cell>0.015</cell><cell>0.025</cell><cell>0.018</cell><cell>0.008</cell><cell>0.020</cell><cell>0.009</cell><cell>0.009</cell></row><row><cell></cell><cell>Std</cell><cell>(0.009)</cell><cell>(0.004)</cell><cell>(0.008)</cell><cell>(0.004)</cell><cell>(0.015)</cell><cell>(0.015)</cell><cell>(0.007)</cell><cell>(0.013)</cell><cell>(0.007)</cell><cell>(0.007)</cell></row><row><cell></cell><cell>Best</cell><cell>0.022</cell><cell>0.001</cell><cell>0.010</cell><cell>0.010</cell><cell>0.003</cell><cell>0.003</cell><cell>1.259e-04</cell><cell>0.010</cell><cell>0.003</cell><cell>0.003</cell></row><row><cell>f9</cell><cell>Mean</cell><cell>-9.500e+03</cell><cell>-9.538e+03</cell><cell>-6.561e+03</cell><cell>-1.156e+04</cell><cell>-1.381e+04</cell><cell>-1.565e+04</cell><cell>-1.094e+04</cell><cell>-1.062e+04</cell><cell>-9.25e+03</cell><cell>-7.87e+03</cell></row><row><cell></cell><cell>Std</cell><cell>(267.926)</cell><cell>(292.662)</cell><cell>(5.647e+03)</cell><cell>(371.275)</cell><cell>(1.036e+03)</cell><cell>(4.084e+03)</cell><cell>(425.664)</cell><cell>(361.188)</cell><cell>(4.02e+03)</cell><cell>(4.06e+03)</cell></row><row><cell></cell><cell>Best</cell><cell>-9.865e+03</cell><cell>-9.847e+03</cell><cell>-1.150e+04</cell><cell>-1.216e+04</cell><cell>-1.517e+04</cell><cell>-2.260e+04</cell><cell>-1.150e+04</cell><cell>-1.091e+04</cell><cell>-1.15e+04</cell><cell>-1.17e+04</cell></row><row><cell>f10</cell><cell>Mean</cell><cell>92.632</cell><cell>58.667</cell><cell>24. 497</cell><cell>9.153</cell><cell>71.388</cell><cell>74.422</cell><cell>3.410e-13</cell><cell>3.751e-13</cell><cell>262.187</cell><cell>272.972</cell></row><row><cell></cell><cell>Std</cell><cell>(12.969)</cell><cell>(19.572)</cell><cell>(28.045)</cell><cell>(2.268)</cell><cell>(22.882)</cell><cell>(15.800)</cell><cell>(4.933e-13)</cell><cell>(4.697e-13)</cell><cell>(31.932)</cell><cell>(32.311)</cell></row><row><cell></cell><cell>Best</cell><cell>74.381</cell><cell>34.332</cell><cell>0</cell><cell>6.964</cell><cell>52.732</cell><cell>48.752</cell><cell>5.684e-14</cell><cell>5.684e-14</cell><cell>225.854</cell><cell>242.058</cell></row><row><cell>f11</cell><cell>Mean</cell><cell>121.762</cell><cell>33.525</cell><cell>21.435</cell><cell>8.127</cell><cell>25.250</cell><cell>67.400</cell><cell>3.565e-06</cell><cell>2.955e-13</cell><cell>173.750</cell><cell>242</cell></row><row><cell></cell><cell>Std</cell><cell>(42.053)</cell><cell>(7.783)</cell><cell>(24.046)</cell><cell>(3.511)</cell><cell>(21.077)</cell><cell>(25.948)</cell><cell>(7.131e-06)</cell><cell>(4.779e-13)</cell><cell>(53.835)</cell><cell>(45.384)</cell></row><row><cell></cell><cell>Best</cell><cell>77.022</cell><cell>24.327</cell><cell>0</cell><cell>4.618</cell><cell>7</cell><cell>40</cell><cell>5.684e-14</cell><cell>0</cell><cell>108</cell><cell>196</cell></row><row><cell>f12</cell><cell>Mean</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell></row><row><cell></cell><cell>Std</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell></row><row><cell></cell><cell>Best</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell><cell>22.718</cell></row><row><cell>f13</cell><cell>Mean</cell><cell>0.468</cell><cell>7.379</cell><cell>0.283</cell><cell>0</cell><cell>0.022</cell><cell>0.022</cell><cell>0.009</cell><cell>0.005</cell><cell>90.044</cell><cell>396.822</cell></row><row><cell></cell><cell>Std</cell><cell>(0.530)</cell><cell>(4.019)</cell><cell>(0.327)</cell><cell>(0)</cell><cell>(0.024)</cell><cell>(0.021)</cell><cell>(0.002)</cell><cell>(0.009)</cell><cell>(0.612)</cell><cell>(102.594)</cell></row><row><cell></cell><cell>Best</cell><cell>0.013</cell><cell>4.678</cell><cell>0</cell><cell>0</cell><cell>0.007</cell><cell>1.554e-15</cell><cell>0.007</cell><cell>7.771e-16</cell><cell>89.253</cell><cell>270.786</cell></row><row><cell>f14</cell><cell>Mean</cell><cell>4.365</cell><cell>1.854</cell><cell>1.680e-14</cell><cell>1.846e-19</cell><cell>2.280</cell><cell>0.838</cell><cell>6.624e-18</cell><cell>2.273e-16</cell><cell>86.272</cell><cell>24.241</cell></row><row><cell></cell><cell>Std</cell><cell>(3.508)</cell><cell>(1.396)</cell><cell>(2.070e-14)</cell><cell>(4.114e-19)</cell><cell>(1.080)</cell><cell>(0.479)</cell><cell>(1.324e-17)</cell><cell>(2.116e-16)</cell><cell>(85.647)</cell><cell>(40.136)</cell></row><row><cell></cell><cell>Best</cell><cell>0.021</cell><cell>0.905</cell><cell>1.570e-32</cell><cell>1.570e-32</cell><cell>1.359</cell><cell>0.173</cell><cell>1.570e-32</cell><cell>6.332e-17</cell><cell>13.554</cell><cell>13.791</cell></row><row><cell>f15</cell><cell>Mean</cell><cell>-186.730</cell><cell>-186.730</cell><cell>-120.137</cell><cell>-186.730</cell><cell>-186.730</cell><cell>-186.730</cell><cell>-186.730</cell><cell>-186.730</cell><cell>-128.214</cell><cell>-128.745</cell></row><row><cell></cell><cell>Std</cell><cell>(7.564e-12)</cell><cell>(7.564e-13)</cell><cell>(76.921)</cell><cell>(7.564e-13)</cell><cell>(1.640e-14)</cell><cell>(1.640e-14)</cell><cell>(3.281e-14)</cell><cell>(1.640e-14)</cell><cell>(0)</cell><cell>(1.185)</cell></row><row><cell></cell><cell>Best</cell><cell>-186.730</cell><cell>-186.730</cell><cell>-186.730</cell><cell>-186.730</cell><cell>-186.730</cell><cell>-186.730</cell><cell>-186.730</cell><cell>-186.730</cell><cell>-128.214</cell><cell>-130.865</cell></row><row><cell>f16</cell><cell>Mean</cell><cell>-5.633e+03</cell><cell>-5.023e+03</cell><cell>-4.525e+03</cell><cell>-5.994e+03</cell><cell>-1.351e+04</cell><cell>-1.507e+04</cell><cell>-5.735e+03</cell><cell>-6.330e+03</cell><cell>-9.14e+03</cell><cell>-7.123+03</cell></row><row><cell></cell><cell>Std</cell><cell>(1.010e+03)</cell><cell>(595.760)</cell><cell>(3.109e+03)</cell><cell>(875.094)</cell><cell>(1.156e+03)</cell><cell>(2.115e+03)</cell><cell>(1.208e+03)</cell><cell>(735.182)</cell><cell>(361.078)</cell><cell>(2.08e+03)</cell></row><row><cell></cell><cell>Best</cell><cell>-6.657e+03</cell><cell>-5.535e+03</cell><cell>-7.370e+03</cell><cell>-7.374e+03</cell><cell>-1.474e+04</cell><cell>-1.800e+04</cell><cell>-7.328e+03</cell><cell>-7.100e+03</cell><cell>-9.48e+03</cell><cell>-9.26e+03</cell></row><row><cell>f17</cell><cell>Mean</cell><cell>283.291</cell><cell>273.430</cell><cell>246.693</cell><cell>116.378</cell><cell>102.977</cell><cell>108.450</cell><cell>77.793</cell><cell>84.770</cell><cell>349.649</cell><cell>407.102</cell></row><row><cell></cell><cell>Std</cell><cell>(46.591)</cell><cell>(42.656)</cell><cell>(119.307)</cell><cell>(49.983)</cell><cell>(27.314)</cell><cell>(23.365)</cell><cell>(29.242)</cell><cell>(8.033)</cell><cell>(59.855)</cell><cell>(141.787)</cell></row><row><cell></cell><cell>Best</cell><cell>244.938</cell><cell>220.801</cell><cell>157.115</cell><cell>41.788</cell><cell>82.581</cell><cell>86.561</cell><cell>53.727</cell><cell>75.616</cell><cell>276.56</cell><cell>191.681</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 7</head><label>7</label><figDesc>The mean and standard deviation of offline accuracy for five PSO variants on radar system design problem.</figDesc><table><row><cell></cell><cell></cell><cell>CLPSO</cell><cell>OLPSO-L</cell><cell>AIWPSO</cell><cell>ALC-PSO</cell><cell>LHNPSO</cell></row><row><cell>Original</cell><cell>Mean offline</cell><cell>2.9643</cell><cell>1.6268</cell><cell>1.1629</cell><cell>1.2034</cell><cell>1.1434</cell></row><row><cell></cell><cell>Accuracy</cell><cell>(0.1978)</cell><cell>(0.2041)</cell><cell>(0.1111)</cell><cell>(0.0903)</cell><cell>(0.0775)</cell></row><row><cell></cell><cell>std</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Integration</cell><cell>Mean offline</cell><cell>2.2943</cell><cell>1.4244</cell><cell>1.1247</cell><cell>1.1913</cell><cell>1.1824</cell></row><row><cell>with SAIW</cell><cell>Accuracy</cell><cell>(0.0418)</cell><cell>(0.1644)</cell><cell>(0.1163)</cell><cell>(0.1327)</cell><cell>(0.0920)</cell></row><row><cell></cell><cell>std</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Neural Networks</title>
		<meeting><address><addrLine>Perth, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Novel inertia weight strategies for particle swarm optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chauhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memet. Comput</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="229" to="251" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hybridizing particle swarm optimization with differential evolution for constrained numerical and engineering optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="629" to="640" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A novel particle swarm optimization algorithm with adaptive inertia weight</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nickabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ebadzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Safabakhsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3658" to="3670" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the performance of linear decreasing inertia weight particle swarm optimization for global optimization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Arasomwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">O</forename><surname>Adewumi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. World J</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fuzzy adaptive particle swarm optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yuhui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="page" from="101" to="106" />
			<date type="published" when="2001">2001</date>
			<pubPlace>Seoul</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploration and exploitation in evolutionary algorithms: a survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Črepinšek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mernik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv. (CSUR)</title>
		<imprint>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptively choosing neighbourhood bests using species in a particle swarm optimizer for multimodal function optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation -GECCO 2004</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin/Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="105" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">DNPSO: a Dynamic Niching Particle Swarm Optimizer for multi-modal optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nickabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ebadzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Safabakhsh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>IEEE Congress on Evolutionary Computation, Hong Kong</publisher>
			<biblScope unit="page" from="26" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A hybrid multi-swarm particle swarm optimization to solve constrained optimization problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Comput. Sci. China</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="38" to="52" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Evaluating the performance of DNPSO in dynamic environments</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nickabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ebadzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Safabakhsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Systems, Man and Cybernetics</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="2640" to="2645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Convergence and stochastic stability analysis of particle swarm optimization variants with generic parameter distributions</title>
		<author>
			<persName><forename type="first">E</forename><surname>García-Gonzalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Fernández-Martínez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">249</biblScope>
			<biblScope unit="page" from="286" to="302" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A review of convergence analysis of particle swarm optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Grid Distrib. Comput</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="117" to="128" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A modified particle swarm optimizer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yuhui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Evolutionary Computation</title>
		<meeting><address><addrLine>Anchorage, AK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="69" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Competitive and cooperative particle swarm optimization with information sharing mechanism for global optimization problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">293</biblScope>
			<biblScope unit="page" from="370" to="382" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Example-based learning particle swarm optimization for continuous optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="page" from="125" to="138" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Diversity enhanced particle swarm optimization with neighborhood search</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rahnamayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">223</biblScope>
			<biblScope unit="page" from="119" to="135" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Particle swarm optimization with an aging leader and challengers</title>
		<author>
			<persName><forename type="first">W.-N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-H</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evolut. Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="241" to="258" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A two-swarm cooperative particle swarms optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm Evolut. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Tracking and optimizing dynamic systems with particle swarms</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yuhui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>IEEE Congress on Evolutionary Computation</publisher>
			<biblScope unit="page" from="94" to="100" />
			<pubPlace>Seoul</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Empirical study of particle swarm optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yuhui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="page">1950</biblScope>
			<date type="published" when="1999">1999</date>
			<pubPlace>Washington, DC</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multi-swarm particle swarm optimization with a center learning strategy</title>
		<author>
			<persName><forename type="first">B</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Swarm Intelligence</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Tan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Mo</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin/Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="72" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A hybrid particle swarm optimization method for structure learning of probabilistic relational models</title>
		<author>
			<persName><forename type="first">X.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-D</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">283</biblScope>
			<biblScope unit="page" from="258" to="266" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Memetic binary particle swarm optimization for discrete optimization problems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Beheshti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Shamsuddin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">299</biblScope>
			<biblScope unit="page" from="58" to="84" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Search performance improvement of Particle Swarm Optimization by second best particle information</title>
		<author>
			<persName><forename type="first">Y.-B</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">246</biblScope>
			<biblScope unit="page" from="346" to="354" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Enhanced comprehensive learning particle swarm optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">242</biblScope>
			<biblScope unit="page" from="265" to="276" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Comparing nonlinear inertia weights and constriction factors in particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tuppadung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kurutach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Knowl. Based Intell. Eng. Syst</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="65" to="70" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">S-shaped versus V-shaped transfer functions for binary Particle Swarm Optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm Evolut. Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Mat Isa, Bidirectional teaching and peer-learning particle swarm optimization</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">280</biblScope>
			<biblScope unit="page" from="111" to="134" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An adaptive two-layer particle swarm optimization with elitist learning strategy</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Mat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isa</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="page" from="49" to="72" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A new fitness estimation strategy for particle swarm optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="355" to="370" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Comprehensive learning particle swarm optimizer for global optimization of multimodal functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evolut. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="281" to="295" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A new particle swarm optimization method enhanced with a periodic mutation strategy and neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">V</forename><surname>Pehlivanoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evolut. Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="436" to="452" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Orthogonal learning particle swarm optimization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhi-Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu-Hui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evolut. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="832" to="847" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Superior solution guided particle swarm optimization combined with local search techniques</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="7536" to="7548" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Particle swarm optimiser with neighbourhood operator</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="page">1962</biblScope>
			<date type="published" when="1999">1999</date>
			<pubPlace>Washington, DC</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A particle swarm optimization for reactive power and voltage control in electric power systems considering voltage security assessment</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fukuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Takayama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nakanishi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Systems, Man, and Cybernetics</title>
		<meeting><address><addrLine>Tokyo</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="497" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Chaotic inertia weight in particle swarm optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gui-Fa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ai-Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yong-Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second International Conference on Innovative Computing, Information and Control</title>
		<meeting><address><addrLine>Kumamoto</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page">475</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Comparing with chaotic inertia weights in particle swarm optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yong-Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ai-Xin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning and Cybernetics</title>
		<meeting><address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="329" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">On the behavior and performance of chaos driven PSO algorithm with inertia weight</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pluhacek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Senkerik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Davendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kominkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Oplatkova</surname></persName>
		</author>
		<author>
			<persName><surname>Zelinka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Math. Appl</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="122" to="134" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Fitness-distance-ratio based particle swarm optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Peram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Veeramachaneni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Mohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Swarm Intelligence Symposium</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="174" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Nonlinear inertia weight variation for dynamic adaptation in particle swarm optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Swarm Intelligence</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Tan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Chai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin/Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="80" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Natural exponential inertia weight strategy in particle swarm optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Guimin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xinbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jianyuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhengfeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Sixth World Congress on Intelligent Control and Automation, (WCICA)</title>
		<meeting><address><addrLine>Dalian</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="3672" to="3675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Low-discrepancy sequence initialized particle swarm optimization algorithm with high-order nonlinear time-varying inertia weight</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="386" to="394" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Empirical study of particle swarm optimizer with an increasing inertia weight</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yong-Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Long-Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li-Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ji-Xin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>IEEE Congress on Evolutionary Computation</publisher>
			<biblScope unit="page" from="221" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">On the convergence analysis and parameter selection in particle swarm optimization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yong-Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Long-Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li-Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ji-Xin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second International Conference on Machine Learning and Cybernetics</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1802" to="1807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A dynamic inertia weight particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chaos Solitons Fract</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="698" to="705" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A modified particle swarm optimizer with dynamic adaptation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">189</biblScope>
			<biblScope unit="page" from="1205" to="1213" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">On the improved performances of the particle swarm optimization algorithms with adaptive parameters, cross-over operators and root mean square (RMS) variants for computing optimal control of a class of hybrid systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Arumugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V C</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="324" to="336" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Adaptive particle swarm optimization approach for static and dynamic economic load dispatch</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Panigrahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pandi</surname></persName>
		</author>
		<author>
			<persName><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Energy Convers. Manag</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1407" to="1415" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Memory enhanced evolutionary algorithms for changing optimization problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="page">1882</biblScope>
			<date type="published" when="1999">1999</date>
			<pubPlace>Washington, DC</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A competitive clustering particle swarm optimizer for dynamic optimization problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nickabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ebadzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Safabakhsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="177" to="206" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Changhe</surname></persName>
		</author>
		<title level="m">Particle Swarm Optimization in Stationary and Dynamic Environments</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Leicester</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Self regulating particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Tanweer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sundararajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">294</biblScope>
			<biblScope unit="page" from="182" to="202" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Problem Definitions and Evaluation Criteria for CEC 2011 Competition on Testing Evolutionary Algorithms on Real World Optimization Problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suganthan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<pubPlace>Kolkata</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Jadavpur University, Nanyang Technological University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Adaptive acceleration coefficients for a new search diversification strategy in particle swarm optimization algorithms</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ardizzon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cavazzini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pavesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">299</biblScope>
			<biblScope unit="page" from="337" to="378" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Order-2 stability analysis of particle swarm optimization</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="187" to="216" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Deep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chauhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pant</surname></persName>
		</author>
		<title level="m">A new fine grained inertia weight Particle Swarm Optimization</title>
		<meeting><address><addrLine>Mumbai</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="424" to="429" />
		</imprint>
	</monogr>
	<note>Congress on Information and Communication Technologies (WICT)</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Designing evolutionary algorithms for dynamic optimization problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schmeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Evolutionary Computing</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Tsutsui</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin/Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="239" to="262" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
