<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Operational Approach to Information Leakage</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ibrahim</forename><surname>Issa</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aaron</forename><forename type="middle">B</forename><surname>Wagner</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sudeep</forename><surname>Kamath</surname></persName>
						</author>
						<title level="a" type="main">An Operational Approach to Information Leakage</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7742542809603F9307CB299269303056</idno>
					<idno type="DOI">10.1109/TIT.2019.2962804</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIT.2019.2962804, IEEE Transactions on Information Theory 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Given two random variables X and Y , an operational approach is undertaken to quantify the "leakage" of information from X to Y . The resulting measure L (X→Y ) is called maximal leakage, and is defined as the multiplicative increase, upon observing Y , of the probability of correctly guessing a randomized function of X, maximized over all such randomized functions. A closedform expression for L (X→Y ) is given for discrete X and Y , and it is subsequently generalized to handle a large class of random variables. The resulting properties are shown to be consistent with an axiomatic view of a leakage measure, and the definition is shown to be robust to variations in the setup. Moreover, a variant of the Shannon cipher system is studied, in which performance of an encryption scheme is measured using maximal leakage. A singleletter characterization of the optimal limit of (normalized) maximal leakage is derived and asymptotically-optimal encryption schemes are demonstrated. Furthermore, the sample complexity of estimating maximal leakage from data is characterized up to subpolynomial factors. Finally, the guessing framework used to define maximal leakage is used to give operational interpretations of commonly used leakage measures, such as Shannon capacity, maximal correlation, and local differential privacy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>How much information does an observation "leak" about a quantity on which it depends? This basic question arises in many secrecy and privacy problems in which the quantity of interest is considered sensitive and I. Issa is with the Department of Electrical and Computer Engineering at the American University of Beirut, Beirut, Lebanon (e-mail: ii19@aub.edu.lb), and was with the School of Electrical and Computer Engineering at Cornell University, Ithaca, NY, when much of this work was conducted. A. B. Wagner is with the School of Electrical and Computer Engineering, Cornell University, Ithaca, NY (e-mail: wagner@cornell.edu). S. Kamath is with PDT Partners, New York, NY (e-mail: sudeep.kamath@gmail.com). Parts of this work were presented at the 2016 Annual Conference on Information Sciences and Systems, and at the 2016 and 2017 IEEE International Symposium on Information Theory.</p><p>an observation is available to an adversary. The observation could be intentionally provided to the adversary, as occurs when a curator publishes statistical information about a given population. Or the observation could be an inevitable, if undesirable, consequence of a design. In the latter case, which is the focus of this paper, we call the observation the output of a side channel. Some examples of side channels include:</p><p>• When using the Secure Shell (SSH), after the initial handshake, each keystroke is sent immediately to the remote machine, as shown in Figure <ref type="figure" target="#fig_4">1</ref>. When communicating over a wireless network, an eavesdropper can observe the timing of the packets which are correlated with the timing of the keystrokes, and hence with the input of the user (e.g., the interkeystroke delay in 'ka' is significantly smaller than that in '9k' <ref type="bibr" target="#b0">[1]</ref>).</p><p>Fig. <ref type="figure" target="#fig_4">1</ref>. The Secure Shell: each keystroke is sent immediately to the remote machine.</p><p>• Consider an on-chip network that has several processes running simultaneously, one of which is malicious. Because resources such as memory and buses are shared on the chip, the timing characteristics (e.g., memory access delays) observed by the malicious application are affected by the behavior of the other applications (e.g., memory access patterns) and can leak sensitive information such as keys. Similar phenomena occur when users share links or buffers in a communication network <ref type="bibr" target="#b1">[2]</ref>. • Consider the Shannon cipher system (shown in Figure <ref type="figure">2</ref>) in which a transmitter and a receiver are connected through a public noiseless channel and share a secret key. Unless the key rate is very high, the public message depends on the message <ref type="bibr" target="#b2">[3]</ref>.</p><p>Fig. <ref type="figure">2</ref>. The Shannon cipher system.</p><p>• An adversary could "wiretap" a communication channel to intercept transmissions. The wiretap channel is typically noisier than the main channel, but its output nevertheless depends on the transmitted message <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. • Suppose one would like to anonymously transmit a message through a given network (say, a call for protest on a social network). A powerful adversary (say, a government) could learn the spread of the message (i.e., who received it), which is correlated with the identity of its author <ref type="bibr">[6,</ref><ref type="bibr" target="#b6">7]</ref>. • Cellular networks track the locations of its users in order to route calls. Such tracking data might reveal private information of the user (such as their political affiliation, their place of work, etc.) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>.</p><p>Although at first glance such side-channels may seem innocuous, many works have shown that they pose a significant security threat <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">10]</ref>- <ref type="bibr" target="#b15">[16]</ref>. For instance, Zhang and Wang <ref type="bibr" target="#b9">[10]</ref> show how to use the keystroke timing in SSH to reduce the search space for passwords by a factor of at least 250. Kocher <ref type="bibr" target="#b12">[13]</ref> shows how to break implementations of RSA using timing information. Ristenpart et al. <ref type="bibr" target="#b16">[17]</ref> show how secret keys can be extracted from co-resident virtual machines on production Amazon EC2 servers through microarchitectural timing channels.</p><p>Addressing such threats first requires an answer to the question posed at the outset. That is, if X is a random variable representing sensitive information and Y is the output of a side-channel with input X, How much information does Y leak about X?</p><p>Let L (X→Y ) denote a potential answer. Before discussing existing approaches, we posit that a good choice of L (X→Y ) should satisfy the following requirements: (R1) It should have a cogent operational interpretation.</p><p>That is, a system designer should be able to explain what guarantees on the system an upper bound on L (X→Y ) provides. In the context of side channels, the design goal is typically to prevent the adversary from guessing sensitive, discrete quantites such as keys and passwords. Thus the leakage measure should be interpretable in terms of the adversary's difficulty in guessing such quantities. (R2) Assumptions about the adversary should be minimal (since guarantees are void if any assumption does not hold true). Indeed, one would like to take into account a large family of potential adversaries. (R3) It should satisfy axiomatic properties of an information measure:</p><p>a) The data processing inequality:</p><formula xml:id="formula_0">L (X→Z) ≤ min{L (X→Y ) , L (Y →Z)} if X -Y -Z is a Markov chain. b)</formula><p>The independence property: L (X→Y ) = 0 if and only if X and Y are independent. c) The additivity property: if</p><formula xml:id="formula_1">(X 1 , Y 1 )</formula><p>and (X 2 , Y 2 ) are independent, then L X 2 1 →Y 2 1 = L (X 1 →Y 1 ) + L (X 2 →Y 2 ). (R4) It should accord with intuition. That is, it should not mis-characterize the (severity of) information leakage in systems that we understand well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Common Information-Theoretic Approaches</head><p>Notably, many commonly-used information leakage metrics do not satisfy the above requirements. For example, mutual information, which has been frequently used as a leakage measure <ref type="bibr" target="#b2">[3]</ref>- <ref type="bibr" target="#b4">[5]</ref>[18]- <ref type="bibr" target="#b21">[22]</ref>, arguably fails to satisfy both (R1) and (R4). Regarding the latter, consider the following example proposed by Smith <ref type="bibr" target="#b22">[23]</ref>.</p><p>Example 1: Given n ∈ N, let X = {0, 1} 8n and X ∼ Unif(X ). Now consider the following two conditional distributions: Y = X, if X mod 8 = 0, 1, otherwise.</p><p>and Z = (X 1 , X 2 , . . . , X n+1 ).</p><p>Then the probability of guessing X correctly from Y is at least 1/8, whereas the probability of guessing X correctly from Z is only 2 -7n+1 for Z. However, one can readily verify that I(X; Y ) ≈ (n + 0.169) log 2 ≤ I(X; Z) = (n + 1) log 2 <ref type="bibr" target="#b22">[23]</ref>.</p><p>Regarding the former, note that operational interpretations of mutual information arise in transmission and compression settings, which are different from the security setting at hand. Moreover, in those settings, mutual information arises as part of a computable characterization of the solution, rather than as part of the formulation itself, i.e., the transmission and compression problems are not defined in terms of mutual information.</p><p>Mutual information could potentially be justified by appealing to rate-distortion theory <ref type="bibr" target="#b23">[24,</ref><ref type="bibr">Section V]</ref>. In fact, a number of leakage measures in the literature are based on rate-distortion theory. For instance, Yamomoto <ref type="bibr" target="#b24">[25]</ref> introduces a distortion function d and measures the privacy of P Y |X using inf x(•) E[d(X, x(Y ))]. Schieler and Cuff <ref type="bibr" target="#b23">[24]</ref> discuss (and generalize) an example that shows the inadequacy of this approach, if conventional distortion measures such as Hamming distortion are used.</p><p>Example 2: Given n ∈ N, let X n be i.i.d ∼ Ber(1/2) and let K ∼ Ber(1/2) be independent of X n . Suppose d is the Hamming distortion and let P Y |X n be as follows: if K = 0, Y = X n ; otherwise, Y = Xn (i.e., flip all the bits of X n ). Then inf x(•) E[d(X, x(Y ))] = 1/2, which is the maximum distortion the adversary could incur. The proposed scheme is hence optimal from an expected distortion point of view. However, by observing Y , the adversary can guess X n with probability 1/2. Moreover, they can guess it exactly with two attempts.</p><p>Similarly to expected distortion, the expected number of guesses <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref> to find X n fails on the fourth requirement: it can label obviously insecure systems as secure (see <ref type="bibr" target="#b27">[28]</ref> for an example). Another approach is to use the probability of successfully guessing X n (up to some distortion, say) as a leakage measure <ref type="bibr" target="#b27">[28]</ref>- <ref type="bibr" target="#b29">[30]</ref>. However, rate-distortion-based approaches generally do not meet the second requirement (R2): they assume there is a known distortion function, and in some cases a particular distortion level, up to which the adversary is interested in reproducing the sensitive information X.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Contributions</head><p>We introduce a new metric, maximal leakage, that meets all the above requirements. To do so, we first describe a threat model that captures the side-channel setup.</p><p>Threat model. We assume the adversary is interested in a (possibly randomized) function of X, called U . We restrict U to be discrete, which captures most scenarios of interest (in the side-channel examples above, all functions of interest are discrete, e.g., a password, a message, an identity, etc). However, P U |X is unknown to the system designer. This models the case in which we do not know the adversary's function of interest, and wish to account for a large family of potential adversaries, as in the second requirement of L (X→Y ) above. Even if it is known, P U |X could be so complicated that it might as well be unknown. The adversary observes a random variable Y , and the Markov chain U -X -Y holds. They wish to guess U and can verify if their guess is correct (if, say, U is a password for a given system, then they can attempt to log in using it). Hence, they would like to maximize the probability of guessing U correctly. Finally, we assume the system designer accepts low risks (i.e., a random event that reveals U is tolerable as long as it has very low probability), or that the leakage is concentrated with respect to Y (i.e., we can average over P Y , which is the case in side-channels where the input and output are running processes).</p><p>Operational, robust measure of information leakage. We now define maximal leakage, which we denote by L (X→Y ), as the (logarithm of the) ratio of the probability of correctly guessing U from Y to the probability of correctly guessing U with no observation, maximized over all U satisfying U -X -Y (cf. Definition 1). The maximization over U guarantees that our definition satisfies the requirement (R2) of making minimal assumptions about the adversary. Moreover, the operational meaning of this quantity is clear: a leak of bits means that for any U , the multiplicative increase (upon observing Y ) in the correct guessing probability is upper-bounded by, but can be arbitrary close to, 2 . So defined, it is not clear a priori that maximal leakage is computable, since it requires maximizing over all auxiliary random variables U . A standard approach to obtaining a computable characterization in such problems is to bound the necessary alphabet size for U in terms of the alphabet size of X using Carathéodory's theorem (e.g., <ref type="bibr" target="#b30">[31,</ref><ref type="bibr">Lemma 5.4]</ref>). This technique fails for the present problem, however: even a binary X can require arbitrarily large U in order to approach the supremum. Nonetheless, Theorem 1 provides a simple formula for maximal leakage for the case of discrete X and Y . In particular, it shows that L (X→Y ) is equal to the Sibson mutual information of order infin-ity I ∞ (X; Y ) <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref>. Consequently, maximal leakage meets our third requirement (R3) of satisfying axiomatic properties of an information measure. That is, it is zero if and only if X and Y are independent; it satisfies the data processing inequality; and it is additive over independent pairs {(X i , Y i )} n i=1 . Interestingly, it is lowerbounded by I(X; Y ), indicating that mutual information underestimates leakage.</p><p>Moreover, the definition of maximal leakage is shown to be robust: the result is unaffected if the adversary picks the function of interest U only after observing Y (cf. Theorem 2), if they only wish to approximate U (cf. Theorem 3), if they are allowed several guesses (cf. Theorem 4), or if they wish to maximize some arbitrary gain function (cf. Theorem 5). We also extend the notion of maximal leakage in two directions. We propose a conditional form of maximal leakage, which attempts to answer the question: how much does Y leak about X when Z is given? Here Z represents side information that is available to the adversary. We again provide an operational definition in the guessing framework (cf. Definition 6), and derive a simple form for L (X→Y |Z) (cf. Theorem 6). Moreover, we generalize the computable characterization for maximal leakage to cover a large class of random variables and stochastic processes (cf. <ref type="bibr">Theorem 7)</ref>. Both the general and the conditional form retain the axiomatic properties of a leakage measure, and are lower-bounded by mutual information and conditional mutual information, respectively.</p><p>New insights for mechanism design. The new metric is useful to develop new mechanisms to mitigate leakage, as well as to evaluate existing mechanisms for this purpose. A common approach in such designs is to add independent noise to successive inputs of the system. For example, in the SSH scenario, packets could be passed through an ./M/1 queue before being sent over the network. We provide examples of such memoryless schemes to show that, roughly speaking, they do not perform well under maximal leakage, and are outperformed by quantization-based schemes. More concretely, we consider the Shannon cipher system with lossy communication and evaluate the performance of an encryption scheme using maximal leakage between the source and the public message (other works have considered this setup under different metrics <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">34]</ref>). For a discrete memoryless source, we show that memoryless schemes are strictly suboptimal (cf. Lemma 9), whereas optimal schemes correspond to good rate-distortion codes. Moreover, we derive a singleletter characterization of the optimal (normalized) limit (cf. Theorems 8 and 9).</p><p>Complexity of estimating maximal leakage. The computation of maximal leakage might become intractable for complicated schemes. For example, in the setup of multiple processes running on the same chip as described above, what determines the information leakage between processes is the memory controller, the operation of which might depend on many variables. Thus, we consider the problem of estimating maximal leakage from data. We show that this task is feasible only if we know (a lower bound on) the minimum strictly positive probability of a symbol x ∈ X , denoted by θ. More specifically, we show that the number of samples needed to estimate L (X→Y ) up to -additive-accuracy is Ω (|Y|/(θ log |Y|)) (cf. <ref type="bibr">Theorem 10)</ref>. Note that the lower bound diverges to infinity as θ tends to zero. On the other hand, we show that O |Y| log |X | θ samples are sufficient (cf. <ref type="bibr">Theorem 11)</ref>. This suggests that we should take into account amenability to analysis while designing leakage-mitigating mechanisms.</p><p>Guessing framework to interpret leakage measures. Finally, we use the guessing framework used to define maximal leakage to give new operational interpretations for different information leakage measures. This provides a common framework with which to compare them, and elucidates in which setups each should be used. More specifically, we study the following commonly used metrics: Shannon capacity, local differential privacy <ref type="bibr" target="#b34">[35]</ref>, and maximal correlation <ref type="bibr" target="#b35">[36]</ref>.</p><p>We show that 1) Shannon capacity captures the multiplicative increase of the probability of correct guessing over the restricted set of functions of X that can be reliably reconstructed from Y , hence underestimating leakage (cf. Theorem 12); 2) Local differential privacy captures the multiplicative increase of the guessing probability of functions of randomized X, maximized over realizations of Y and over distributions P X (cf. Theorem 14); Moreover, maximizing over realizations of Y for a fixed P X yields the maximum information rate (cf. Theorem 13); 3) Maximal correlation captures the multiplicative change in the variance of functions of X, rather than the guessing probability (cf. <ref type="bibr">Theorem 16)</ref>. We extend this last notion to a new measure we call maximal cost leakage (cf. <ref type="bibr">Definition 11)</ref>, which captures the worst-case multiplicative reduction over all cost functions defined on any hidden variable U .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Related Work</head><p>Calmon et al. <ref type="bibr" target="#b36">[37]</ref> and Li and El Gamal <ref type="bibr" target="#b35">[36]</ref> use maximal correlation, ρ m (X; Y ), as a secrecy measure (Calmon et al. also generalize it to k-correlation, which is defined as the sum of the k largest principal inertial components of the joint distribution P XY ). A key motivating result <ref type="bibr" target="#b37">[38,</ref><ref type="bibr">Theorem 9]</ref> shows that maximal correlation bounds the additive increase in the correct guessing probability of any deterministic function of X. Although ρ m (X; Y ) is zero only if X and Y are independent, the correct guessing probability of any deterministic function might be unchanged even if X and Y are not independent, as illustrated in the following example.</p><p>Example 3: Suppose P XY satisfies the following condition: there exists x ∈ X such that for all y ∈ Y, P X|Y (x |y) ≥ 1/2. Then for any deterministic function f , f (x ) is the adversary's best guess for f (X), both with and without the observation of Y . Hence, observing Y does not affect the probability of guessing any deterministic function of X. Note, however, that X and Y may be dependent.</p><p>The literature on leakage and privacy measures extends beyond information theory to computer security and computer science more generally. The closest to our work in fact comes from computer security <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b38">39]</ref>- <ref type="bibr" target="#b41">[42]</ref>. In particular, Smith <ref type="bibr" target="#b22">[23]</ref> defines leakage from X to Y as the logarithm of the multiplicative increase, upon observing Y , of the probability of guessing X itself correctly, neglecting that the adversary might be interested in certain functions of X. Braun et al. <ref type="bibr" target="#b38">[39]</ref> consider a worst case modification of the metric, and maximize the previous quantity over all distributions on the alphabet of X (while P Y |X is fixed). The resulting quantity turns out to equal L (X→Y )-it is called "maximal leakage" in the computer security literature as well. It is denoted by M L(P Y |X ), and its properties were further studied by Espinoza and Smith <ref type="bibr" target="#b40">[41]</ref> and Alvim et al. <ref type="bibr" target="#b39">[40]</ref>. The latter also define g-leakage by introducing a gain function g : X × X → [0, 1] and considering the normalized maximal gain (for g). Alvim et al. <ref type="bibr" target="#b41">[42]</ref> consider several variants of g-leakage (i.e., additive or multiplicative increase, fixing or maximizing over the marginal P X , etc). They show that maximizing g-leakage over gain functions g yields maximal leakage. However, no operational significance is attached to the g that achieves the maximum. Moreover, the result is given only as one of many possible computable variations of leakage <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref>.</p><p>Another connected line of work stems from cryptography, and in particular from the notion of semantic security <ref type="bibr" target="#b43">[44]</ref> which considers the security of encryption schemes. Goldwasser and Micali <ref type="bibr" target="#b43">[44]</ref> define the "advantage" for a given function of the messages as the additive increase of the correct guessing probability upon observing the encrypted message (i.e., the ciphertext). Semantic security then requires that, for an adversary that can work only for a polynomial (in the length of the message) amount of time, the advantage is negligible for all input distributions and for all deterministic functions that are computable in polynomial time.</p><p>There are several variants of semantic security. In particular, entropic security <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46]</ref> drops the computational bounds (on the adversary and the considered functions), but restricts its attention to input distributions with high min-entropy. Bellare et al. <ref type="bibr" target="#b46">[47]</ref> introduce semantic security to the wiretap channel, and do not restrict it to computationally-bounded adversaries or to deterministic polynomial-time computable functions. For a given encryption scheme, they then upper and lowerbound the advantage of semantic security in terms of "mutual information security advantage", which is defined as the maximum, over all input distributions, of the mutual information between the message and the output of the channel whose input is the encryption of the message. For further discussion of leakage metrics, we refer the reader to Wagner and Eckhoff's work <ref type="bibr" target="#b47">[48]</ref>, which categorizes over eighty such metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Outline</head><p>We describe our threat model and define maximal leakage in Section II. We also give a closed-form expression of maximal leakage (for discrete X and Y ), discuss its properties, and compare it to related leakage metrics. In Section III, we prove the robustness of our definition by considering several variations on the setup, and show that they all lead to the same quantity. Furthermore, we generalize the formula of maximal leakage and analyze a simple model of the SSH side-channel. We also present a conditional form of maximal leakage. In Section IV, we consider the Shannon cipher system and derive (asymptotically) optimal schemes. We show that memoryless schemes are strictly suboptimal in general. We study the complexity of estimating maximal leakage from data in Section V. Finally, in Section VI, we use the guessing framework to give new operational interpretations for common information leakage metrics, and we introduce a cost-based notion of leakage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MAXIMAL LEAKAGE</head><p>Let X be a random variable representing sensitive information, and Y be the output of a side-channel the input of which is X. To give an operational definition of information leakage between X and Y , we specify a threat model as follows.</p><p>• The adversary is interested in a possibly randomized, discrete function of X called U . • The adversary observes Y and the Markov chain U -X -Y holds.</p><p>• The adversary wishes to guess U and can verify if the guess is correct. • The distribution P U |X is unknown to the system designer. • From the system designer's viewpoint, if the probability of guessing U correctly is high for some realizations of Y , then it suffices that the probability of such realizations is suitably small.</p><p>To clarify our model, consider how it applies to the SSH side-channel. In this case, X represents the nominal packet timings. Suppose we perturb the packet timings before sending them over the network, in which case Y represents the post-perturbation timings observed by the adversary. U corresponds to the input of the user, e.g., their password. The adversary wishes to guess U (e.g., the password) and can verify their guess (e.g., by attempting to log into the system). So they wish to maximize the probability that the guess is correct, and the system designer wishes to minimize it. The distribution of passwords given packet timings is complicated, so we assume it is unknown to the system designer. Finally, the system designer only requires the probability that the system is compromised to be small.</p><p>One might be tempted to restrict the range of U to deterministic functions of X. However, this is too restrictive as implied by Example 3 in the introduction. Moreover, in most side-channel examples we mentioned, the U of interest is a randomized function of X (passwords given packet timings, key values given memory access patterns, political affiliation given location traces, etc). On the other hand, the restriction to discrete U 's still captures most scenarios of interest, as in the above examples. Indeed even when X represents location traces, for instance, the U of interest is typically discrete, e.g., home/work address, political affiliation, etc. Finally, assuming P U |X is unknown allows us to take into account a wide range of adversaries having different objectives. That is, as in our requirement (R2), we do not assume we know the function of interest to the adversary.</p><p>We are now ready to present the definition of maximal leakage. Since the adversary wishes to guess U , we consider the maximum advantage in the probability of guessing U from Y , as compared with guessing with no observations. Maximal leakage captures the maximum advantage over all U 's as in the following definition.</p><p>Definition 1 (Maximal Leakage): Given a joint distribution P XY on alphabets X and Y, the maximal leakage from X to Y is defined as</p><formula xml:id="formula_2">L (X→Y ) = sup U -X-Y - Û log Pr U = Û max u∈U P U (u) ,<label>(1)</label></formula><p>where the supremum is over all U and Û taking values in the same finite, but arbitrary, alphabet.</p><p>Remark 1: log is the natural logarithm so L (X→Y ) is in nats. Using log 2 instead gives an answer in bits.</p><p>The guarantee that a small leakage provides is as follows. Whatever function U the adversary is interested in, if L (X→Y ) ≤ , then sup û(•) Pr (U = û(Y )) ≤ e max u P U (u). Note that the upper bound can be decomposed into two quantities: max u P U (u) which is completely outside the control of the system designer, and e which is determined by the designer's choice of P Y |X (which is typically subject to quality constraints related to the performance of the underlying system). Moreover, the definition directly implies several important properties of maximal leakage.</p><p>Lemma 1: For any joint distribution P XY on alphabets X and Y,</p><formula xml:id="formula_3">1) (Data Processing Inequality) If the Markov chain X -Y -Z holds, L (X→Z) ≤ min{L (X→Y ) , L (Y →Z)}. 2) If Y is discrete, L (X→Y ) ≤ log |supp(Y )|. 3) If X is discrete, L (X→Y ) ≤ log |supp(X)|. 4) L (X→Y ) ≥ 0 with equality if X and Y are independent.</formula><p>The proof is given in Appendix A-A. Note that properties 1) and 4) were two of our axioms for a leakage measure (R3). Properties 2) and 3) are consistent with intuitive understanding of information. In particular, a binary variable Y cannot leak more than one bit about any variable X. Similarly, a binary variable X has no more than one bit of information to be leaked. Despite the useful properties of the definition, it involves an infinite-dimensional optimization problem, so it is not clear a priori that it is computable. In fact, one can show that it is impossible to bound the cardinality of the alphabet U in terms of the cardinalities of the alphabets X and Y. Nonetheless, we can show that maximal leakage is indeed computable and actually takes a simple form. We focus first on the discrete case and consider general alphabets later.</p><p>Theorem 1: For any joint distribution P XY on finite alphabets X and Y, the maximal leakage from X to Y is given by the Sibson mutual information of order infinity, I ∞ (X; Y ). That is,</p><formula xml:id="formula_4">L (X→Y ) = log y∈Y max x∈X : PX (x)&gt;0 P Y |X (y|x) = I ∞ (X; Y ).</formula><p>Remark 2: Sibson's mutual information <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref> of order α (α ≥ 0, α = 1), which can be expressed (in the discrete case) as</p><formula xml:id="formula_5">I α (X; Y ) = inf QY D α (P XY ||P X × Q Y )<label>(2)</label></formula><p>where</p><formula xml:id="formula_6">D α (P ||Q) = 1 α -1 log a P α (a)Q 1-α (a) ,<label>(3)</label></formula><p>is one of several suggested extensions of the concept of Rényi entropy H α (X) (itself an extension of entropy) and Rényi divergence D α (P ||Q). Verdú <ref type="bibr" target="#b32">[33]</ref> argues for the adoption of Sibson's extension, and the above result supports that choice by providing an operational interpretation of</p><formula xml:id="formula_7">I ∞ (X; Y ) = lim α→∞ I α (X; Y ) (4) = inf QY D ∞ (P XY ||P X × Q Y ),<label>(5)</label></formula><p>where</p><formula xml:id="formula_8">D ∞ (P ||Q) = lim α→∞ D α (P ||Q) (6) = log sup a P (a) Q(a)<label>(7)</label></formula><p>and the interchange of the limit and infimum in (4) and ( <ref type="formula" target="#formula_7">5</ref>) is implied by <ref type="bibr" target="#b48">[49,</ref><ref type="bibr">Theorem 4]</ref> (see also (118) to follow).</p><p>Before proving the theorem, we investigate some of its consequences. First, it reveals two of the more useful aspects of maximal leakage from an engineering perspective: minimizing L(X→Y ) over P Y |X , for a fixed support of P X , amounts to minimizing a convex function, and L(X→Y ) depends on P X only through its support. The latter fact is very useful because in practice P X is typically complicated and outside our control. P X is also typically used to model the adversary's prior knowledge of X, which is not necessarily known to us.</p><p>The following corollary (the proof of which is given in Appendix A-B) summarizes some useful properties of L (X→Y ).</p><p>Corollary 1: For any joint distribution P XY on finite alphabets X and Y,</p><formula xml:id="formula_9">1) L (X→Y ) = 0 iff X and Y are independent. 2) (Additivity) If {(X i , Y i )} n i=1 are mutually indepen- dent, then L (X n →Y n ) = n i=1 L (X i →Y i ) . 3) L (X→Y ) = log |X | iff X is a deterministic function of Y (assuming X has full support). 4) L (X→X) = H 0 (X) = log |supp(X)|. 5) L (X→Y ) is not symmetric in X and Y . 6) exp{L (X→Y )} is convex in P Y |X for fixed sup- port of P X . 7) L (X→Y ) is concave in P X for fixed P Y |X .</formula><p>Note that properties 1) and 2) along with the data processing inequality are the axioms we stated in (R3). Property 5) reveals a potential "weakness" in some suggested leakage metrics, including mutual information. In particular, there is no reason to expect a priori that X leaks about Y as much as Y leaks about X. Therefore, metrics that are symmetric by design miss that fact (this is in contrast with Rényi's axiom that a dependence measure should be symmetric <ref type="bibr" target="#b49">[50]</ref>). Finally, property 6) shows that minimizing maximal leakage, for a fixed support of P X , amounts to minimizing a convex function. That is, one can efficiently solve the problem of finding the randomization mechanism P Y |X that minimizes maximal leakage, subject to a convex constraint.</p><p>We evaluate L (X→Y ) for some special cases. Example 4: If X ∼ Ber(q), 0 &lt; q &lt; 1, and Y is the output of a BSC with parameter p, 0 ≤ p ≤ 1/2, then L (X→Y ) = log(2(1 -p)).</p><p>Example 5: If X ∼ Ber(q), 0 &lt; q &lt; 1, and Y is the output of a BEC with parameter , 0 ≤ &lt; 1, then L (X→Y ) = log(2 -), and L(Y →X) = log 2.</p><p>Example 6: For any deterministic law</p><formula xml:id="formula_10">P Y |X , L (X→Y ) = log |supp(Y )|.</formula><p>Consider the examples from the introduction that showed that expected distortion and mutual information do not meet our fourth requirement (R4).</p><p>Example 7 (cf. Example 2): Given n ∈ N, let X n be i.i.d ∼ Ber(1/2) and let K ∼ Ber(1/2) be independent of X n . Let P Y |X n be as follows: if K = 0, Y = X n ; otherwise, Y = Xn (i.e., flip all the bits of X n ). This scheme is optimal from an expected Hamming distortion viewpoint. On the other hand, L (X n →Y ) = (n -1) log 2, which is exactly describing that we know X n except for 1 bit.</p><p>Example 8 (cf. Example 1): Given n ∈ N, let X = {0, 1} 8n and X ∼ Unif(X ). Now consider the following two conditional distributions:</p><formula xml:id="formula_11">Y = X, if X mod 8 = 0, 1, otherwise. and Z = (X 1 , X 2 , . . . , X n+1 ).</formula><p>Then L (X→Y ) = log(2 8n-3 + 1) &gt; L (X→Z) = (n + 1) log 2, whereas I(X; Y ) ≈ (n + 0.169) log 2 &lt; I(X; Z) = (n + 1) log 2.</p><p>In the next section, we elaborate on the comparison between mutual information and maximal leakage. We also comment on the relation to the computer security and computer science literature, before proving Theorem 1 in Section II-B.</p><p>A. Comparison with Related Metrics 1) Mutual Information: We first compare maximal leakage with mutual information in the following lemma.</p><p>It shows that L (X→Y ) upper-bounds I(X; Y ), and no scalar multiple of I(X; Y ) can upper-bound L (X→Y ).</p><p>Lemma 2: For any joint distribution P XY on finite alphabets X and Y, L (X→Y ) ≥ I(X; Y ). Moreover, for any c &gt; 0, there exists P XY such that L (X→Y ) ≥ cI(X; Y ). Furthermore. L (X→Y ) = I(X; Y ) if and only if 1) If P XY (x, y) &gt; 0 and P XY (x , y) &gt; 0, then</p><formula xml:id="formula_12">P Y |X (y|x) = P Y |X (y|x ).</formula><p>2) For all y, y ∈ supp(Y ),</p><p>x:PXY (x,y)&gt;0 P X (x) =</p><p>x :PXY (x ,y )&gt;0 P X (x ). Proof: That I ∞ (X; Y ) ≥ I(X; Y ) is already known <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref>. For the stronger statement, it suffices to show it for binary X and Y. To that end, let X ∼ Ber(1/2) and let P Y |X be a BSC with parameter p ∈ (0, 1/2). Then L (X→Y ) = log(2(1 -p)) and I(X; Y ) = log 2 -H(p) (where the entropy function is computed using the natural logarithm). One can readily verify that</p><formula xml:id="formula_13">lim p→1/2 log(2(1 -p)) log 2 -H(p) = +∞.</formula><p>The conditions for equality can be readily verified, and are included in Appendix A-C for completeness.</p><p>The lemma shows that a small maximal leakage is a more stringent requirement than a small mutual information. Since L (X→Y ) depends on P X only through its support, it follows that maximal leakage is at least the Shannon capacity of the channel P Y |X when X has full support, and this inequality can be strict (as in the BSC example in the proof of the lemma). This justifies the claim in the introduction that the Shannon capacity of a side-channel does not necessarily upper-bound its leakage. The maximization in the definition of maximal leakage hints at the reason why. In particular, Shannon capacity is concerned with (the size of) message sets that can be reliably reconstructed at the receiver, i.e., Pr(U = Û (Y )) ≥ 1for some small . Leakage, on the other hand, is concerned with the advantage in guessing, without any notion of reliability. This observation is made mathematically precise in Section VI-A.</p><p>On the other hand, local differential privacy <ref type="bibr" target="#b34">[35]</ref>, which some regard as too pessimistic (e.g., <ref type="bibr" target="#b34">[35]</ref>), does upperbound maximal leakage. This is further explored in Section VI-C.</p><p>2) g-leakage: Given a conditional P Y |X on finite alphabets X and Y, Braun et al. <ref type="bibr" target="#b38">[39]</ref> define leakage as follows</p><formula xml:id="formula_14">M L(P Y |X ) = sup PX log sup X-Y -X Pr(X = X) max x∈X P X (x) .<label>(8)</label></formula><p>This definition assumes the adversary wishes to guess X itself, and hence does not meet our second requirement (R2). However, it is equal to L (X→Y ) when X has full support. Remark 4: Smith <ref type="bibr" target="#b22">[23]</ref> initially considered the optimization in (8) without taking the supremum over P X . However, as shown by Example 3, this can be zero even if X and Y are not independent. Hence, it fails the independence property in (R3). See also Iwamoto and Shikata <ref type="bibr" target="#b51">[52]</ref>. Alvim et al. <ref type="bibr" target="#b39">[40]</ref> define g-leakage by introducing a gain function g : X × X → [0, 1], where X is a finite set. Then</p><formula xml:id="formula_15">ML g (P X , P Y |X ) = log sup X-Y -X E[g(X, X)] max x∈ X E[g(X, x)] .<label>(9)</label></formula><p>It is shown <ref type="bibr" target="#b41">[42]</ref> that sup</p><formula xml:id="formula_16">X ,g:X × X →[0,1] ML g (P X , P Y |X ) = L (X→Y ) . (<label>10</label></formula><formula xml:id="formula_17">)</formula><p>This definition however does not explicitly account for random functions of X, whereas we have seen that in many cases the adversary could be interested in a hidden random variable U . Moreover, there is no operational interpretation attached to the g that achieves the maximum. Nonetheless, these metrics are quite similar to the one introduced here.</p><p>3) Semantic Security: The semantic and entropic security literature <ref type="bibr" target="#b43">[44]</ref>- <ref type="bibr" target="#b45">[46]</ref> consider the difference between the guessing probabilities as opposed to the ratio considered in Definition 1. Since U 's of interest, such as passwords, are typically hard to guess (i.e., max u P U (u) is small), the ratio is arguably the more appropriate measure of the change. It is also the more natural choice when viewing leakage in terms of leaked bits. Nevertheless, the following simple argument bounds the maximum difference in terms of maximal leakage.</p><p>Lemma 3: For any joint distribution P XY on alphabets X and Y, sup</p><formula xml:id="formula_18">U :U -X-Y sup û(•) Pr(U = û(Y )) -max u∈U P U (u) ≤ 1 -e -L(X→Y ) ,</formula><p>where the supremum is over all U taking values in a finite, but arbitrary, alphabet.</p><formula xml:id="formula_19">Proof: Consider any U satisfying U -X -Y . Then sup û(•) Pr(U = û(Y )) max u∈U P U (u) ≤ e L(X→Y ) .</formula><p>Hence,</p><formula xml:id="formula_20">sup û(•) Pr(U = û(Y )) -max u∈U P U (u) ≤ sup û(•) Pr(U = û(Y )) 1 -e -L(X→Y ) ≤ 1 -e -L(X→Y ) .</formula><p>This bound is nontrivial when</p><formula xml:id="formula_21">max u P U (u) &lt; e -L(X→Y ) , i.e., H ∞ (U ) &gt; L (X→Y ), where H ∞ (U ) = -log max u P U (u) is the min-entropy. It is worth noting that Alvim et al. showed that sup X ,g:X × X →R sup X-Y - X E[g(X, X)] -max x∈ X E[g(X, x)] ,</formula><p>where g is "1-spanning" [42, Definition 3], can be efficiently computed <ref type="bibr" target="#b41">[42,</ref><ref type="bibr">Theorem 17,</ref><ref type="bibr">Corollary 18]</ref>. On the other hand, for a given threshold t, it is NP-hard <ref type="bibr" target="#b41">[42,</ref><ref type="bibr">Theorem 11]</ref> to decide whether</p><formula xml:id="formula_22">sup PX sup x(•) Pr(X = x(Y )) -max x∈X P X (x) ≥ t. (11)</formula><p>Lemma 3, however, gives a simple bound on the latter quantity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Proof of Theorem 1</head><p>Assume, without loss of generality, that P</p><formula xml:id="formula_23">X (x) &gt; 0 for all x ∈ X . To show that L (X→Y ) ≤ I ∞ (X; Y ), consider any U satisfying U -X -Y . Define L (X→Y ) [U ] = log y∈Y max u∈U P U Y (u, y) max u∈U P U (u) ,<label>(12)</label></formula><formula xml:id="formula_24">so that L (X→Y ) = sup U :U -X-Y L (X→Y ) [U ]. Then y∈Y max u∈U P U Y (u, y) = y∈Y max u∈U x∈X P X (x)P U |X (u|x)P Y |X (y|x) ≤ y∈Y max u∈U x∈X P X (x)P U |X (u|x) max x ∈X P Y |X (y|x ) = y∈Y max x ∈X P Y |X (y|x ) max u∈U x∈X P X (x)P U |X (u|x) = y∈Y max x∈X P Y |X (y|x) max u∈U P U (u). Therefore, L (X→Y ) [U ] ≤ I ∞ (X; Y ) for all P U |X , hence L (X→Y ) ≤ I ∞ (X; Y ).</formula><p>For the reverse inequality, we construct a P U |X for which L (X→Y ) [U ] = I ∞ (X; Y ), which we will call the "shattering" P U |X . To that end, let p = min x∈X P X (x). For each x ∈ X , let k(x) = P X (x)/p , and let U = x∈X {(x, 1), (x, 2), . . . , (x, k(x) )}. For each u = (i u , j u ) ∈ U and x ∈ X , let P U |X (u|x) be:</p><formula xml:id="formula_25">P U |X ((i u , j u )|x) (13) =        p PX (x) , i u = x, 1 ≤ j u ≤ k(x) , 1 -( k(x) -1)p PX (x) , i u = x, j u = k(x) , 0, i u = x, 1 ≤ j u ≤ k(i u ) .</formula><p>It is easy to check that if k(x) = k(x) , then the corresponding formulas are equal. Then, for each</p><formula xml:id="formula_26">((i u , j u ), x) ∈ U × X , P U X ((i u , j u ), x) = (14)        p , i u = x, 1 ≤ j u ≤ k(x) , P X (x) -( k(x) -1)p , i u = x, j u = k(x) , 0, i u = x, 1 ≤ j u ≤ k(i u ) .</formula><p>Note that the supports of P U |X=x is disjoint for each distinct x, and it effectively "shatters" x into shards of probability p . Now note that</p><formula xml:id="formula_27">max u∈U P U (u) = max (iu,ju)∈U P U X ((i u , j u ), i u ) = p . (<label>15</label></formula><formula xml:id="formula_28">)</formula><p>Now consider any (u, y) ∈ U × Y. We have</p><formula xml:id="formula_29">P U Y ((i u , j u ), y) = x∈X P X (x)P U |X ((i u , j u )|x)P Y |X (y|x) = P X (i u )P U |X ((i u , j u )|i u )P Y |X (y|i u ) = p P Y |X (y|i u ), 1 ≤ j u ≤ k(i u ) , (P X (x) -( k(x) -1)p )P Y |X (y|i u ), j u = k(i u ) .<label>(16)</label></formula><p>Then, for a given y ∈ Y,</p><formula xml:id="formula_30">max (iu,ju)∈U P U Y ((i u , j u ), y) = max (iu,1)∈U p P Y |X (y|i u ) = max x∈X p P Y |X (y|x).<label>(17)</label></formula><p>Finally, we get</p><formula xml:id="formula_31">L (X→Y ) ≥ L (X→Y ) [U ] = log y∈Y max x∈X P Y |X (y|x),</formula><p>where the inequality follows from the definition, and the equality follows from equations ( <ref type="formula" target="#formula_23">12</ref>), <ref type="bibr" target="#b14">(15)</ref>, and <ref type="bibr" target="#b16">(17)</ref>.</p><p>Note that in the above proof, the conditional distribution (given in <ref type="bibr" target="#b12">(13)</ref>) that achieves the supremum in (1) depends on P XY only through the X-marginal, P X . So we get the following proposition.</p><p>Proposition 4: Let X be a finite alphabet and P X a distribution on X . Then the "shattering" P U |X defined in <ref type="bibr" target="#b12">(13)</ref> achieves the supremum in (1) for all finite alphabets Y and conditional distributions P Y |X .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. MAXIMAL LEAKAGE: VARIATIONS AND EXTENSIONS</head><p>We now consider several natural variations to our threat model. In particular, we consider the following scenarios.</p><p>1) The adversary chooses the variable of interest U after observing Y , i.e., for different realizations of Y , they might attempt to guess different functions of X.</p><p>2) The adversary only needs their guess to be within a certain distance of the true value of U .</p><p>3) The adversary can make several guesses. 4) The adversary attempts to maximize a gain function defined on U × Û for some alphabet Û.</p><p>We modify the definition of maximal leakage accordingly for each scenario. However, for each of these cases, the resulting computable characterization is unchanged. This shows that the definition of maximal leakage is robust, and meets the requirements we presented in the introduction. In particular, it has several useful operational interpretations, and it requires minimal assumptions about the adversary's goal. Furthermore, we extend the notion of maximal leakage in two directions. First, we propose a conditional form of leakage L (X→Y |Z), where Z represents side information available at the adversary. Finally, we generalize Theorem 1 to account for a large class of random variables, including point processes. We use the general formula to analyze a simple model of the SSH sidechannel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multiple Functions of Interest</head><p>In our threat model, we assumed that the adversary is interested in a specific randomized function of X. However, they could be interested in several functions and choose which one to guess only after seeing the realization of Y . To account for this, we modify the definition of maximal leakage as follows.</p><p>Definition 2 (Opportunistic Maximal Leakage): Given a joint distribution P XY on alphabets X and Y, define</p><formula xml:id="formula_32">L (X→Y ) = log y∈Y P Y (y) sup U :U -X-Y max u∈U P U |Y (u|y) max u∈U P U (u)<label>(18)</label></formula><p>= sup</p><formula xml:id="formula_33">(Uy,y∈Y)-X-Y log y∈Y P Y (y) max u∈Uy P Uy|Y (u|y) max u∈Uy P Uy (u)<label>(19)</label></formula><p>= sup</p><formula xml:id="formula_34">U log y∈Y P Y (y) max u x P U |X,Y (u|x, y)P X|Y (x|y) max u x P U |X,Y (u|x, y)P X (x) ,<label>(20)</label></formula><p>where the U variables in all three suprema take values in finite but arbitrary alphabets.</p><p>The different U y , y ∈ Y in ( <ref type="formula" target="#formula_33">19</ref>) can be interpreted as different secrets that the adversary might attempt to guess. The adversary opportunistically attempts to guess secret U y when it observes Y = y. Notably, allowing the adversary this additional freedom does not change the result.</p><p>Theorem 2: For any joint distribution P XY on finite alphabets X and Y, L (X→Y ) = L (X→Y ) .</p><p>Proof: It follows straightforwardly from the definitions that L (X→Y ) ≥ L (X→Y ). For the reverse direction, consider the following proposition.</p><p>Proposition 5: Suppose U , X, and Y are discrete random variables that satisfy the Markov chain U -X -Y . Then for each y ∈ supp(Y ),</p><formula xml:id="formula_35">max u∈U P U |Y (u|y) max u∈U P U (u) ≤ max x:PX|Y (x|y)&gt;0 P Y |X (y|x) P Y (y) .</formula><p>It follows from the proposition that</p><formula xml:id="formula_36">exp{ L (X→Y )} ≤ y∈supp(Y ) max x:PX|Y (x|y)&gt;0 P Y |X (y|x) ≤ y∈Y max x:PX (x)&gt;0 P Y |X (y|x).</formula><p>Then it remains to prove Proposition 5. To that end, consider a triple of discrete random variables U , X, and Y satisfying U -X -Y , and fix y ∈ supp(Y ). Then</p><formula xml:id="formula_37">max u∈U P U |Y (u|y) = max u∈U x:PX|Y (x|y)&gt;0 P U |X (u|x)P X|Y (x|y) = max u∈U x:PX|Y (x|y)&gt;0 P U |X (u|x)P X (x) P Y |X (y|x) P Y (y) ≤ max x :PX|Y (x |y)&gt;0 P Y |X (y|x ) P Y (y) max u∈U x:PX|Y (x|y)&gt;0 P U X (u, x) ≤ max x :PX|Y (x |y)&gt;0 P Y |X (y|x ) P Y (y) max u∈U P U (u),</formula><p>as desired.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Approximate Guessing</head><p>Consider the case in which the adversary only needs the guess to be within a certain distance of the true function value, according to a given distance metric. As such, the random variable U , over which we are optimizing, now lives in a given metric space U and is no longer restricted to be discrete. We call this modified measure maximal locational leakage. The term "locational" is motivated by the scenario in which the variable of interest U is a geographical location, such as a person's home address (potentially revealed by GPS traces <ref type="bibr" target="#b52">[53]</ref>) or a person's physical location (potentially revealed by cellular tracking data <ref type="bibr" target="#b7">[8]</ref>).</p><p>Definition 3 (Maximal Locational Leakage): Given a joint distribution P XY on finite alphabets X and Y, and a metric space U (with its associated Borel σ-field), the maximal locational leakage from X to Y is defined as</p><formula xml:id="formula_38">L U (X→Y ) = sup U :U -X-Y ∃u:Pr(U ∈B(u))&gt;0 log sup û(•) Pr(U ∈ B(û(Y ))) sup û Pr(U ∈ B(û)) ,<label>(21)</label></formula><p>where B(u) is the closed unit ball centered at u ∈ U.</p><p>Theorem 3: For any joint distribution P XY on finite alphabets X and Y, and any metric space U,</p><formula xml:id="formula_39">L U (X→Y ) ≤ L(X→Y ),</formula><p>with equality if U has a countably infinite subset S such that no pair of its elements can be contained in a single unit ball.</p><p>Proof: Assume, without loss of generality, that X has full support. Now consider any U and û(Y ) in the maximization of <ref type="bibr" target="#b20">(21)</ref>:</p><formula xml:id="formula_40">Pr(U ∈ B(û(Y )) ≤ y∈Y sup u∈U P (U ∈ B(u), Y = y) = y∈Y sup u∈U x∈X P (U ∈ B(u), X = x, Y = y) = y∈Y sup u∈U x∈X P (U ∈ B(u))P (X = x|U ∈ B(u))• P Y |X (y|x) ≤ y∈Y sup u∈U P (U ∈ B(u)) sup x∈X P Y |X (y|x) =   y∈Y sup x∈X P Y |X (y|x)   sup u∈U P (U ∈ B(u)).</formula><p>Therefore,</p><formula xml:id="formula_41">L U (X→Y ) ≤ log y∈Y sup x∈X P Y |X (y|x) = L(X→Y ).</formula><p>If there exists a countably infinite S ⊆ U such that no pair of its elements can be contained in a single unit ball (e.g., U is unbounded), then exact guessing of discrete quantities can be simulated by using S for the support of a discrete random variable U . Hence L U (X →Y ) ≥ L(X→Y ), which implies the equality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Multiple Guesses</head><p>The definition of maximal leakage (Definition 1) allowed the adversary a single guess. However, an adversary might be able to make several guesses in some practical scenarios. For example, if the adversary is trying to guess a password U of some system, they can typically try several passwords before they are locked out. Similarly, if they are trying to guess a secret key to decrypt an encrypted message, they can make several attempts. We modify the definition to allow for k guesses, for any integer k, as follows.</p><p>Definition 4 (k-Maximal Leakage): Given a joint distribution P XY on finite alphabets X and Y, and a positive integer k, the k-maximal leakage from X to Y is defined as</p><formula xml:id="formula_42">L (k) (X→Y ) = sup U -X-Y -( Ûi) k i=1 log Pr k i=1 U = Ûi max S⊆U |S|≤k P U (S)</formula><p>,</p><p>where U takes values in a finite, but arbitrary, alphabet.</p><p>It turns out that k-maximal leakage and maximal leakage are equivalent.</p><p>Theorem 4: For any joint distribution P XY on finite alphabets X and Y, and any k ∈ N,</p><formula xml:id="formula_43">L (k) (X→Y ) = L (X→Y ) .</formula><p>The proof is given in Appendix B-A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. General Gains</head><p>We now consider the case in which different realizations of U might have different significance for the adversary. For example, an adversary monitoring the timing of packet transmissions over a given network <ref type="bibr" target="#b53">[54]</ref> might seek to deduce source-destination pairs. However, they might be more interested in detecting communication between specific pairs, corresponding to (say) suspicious persons, governmental agencies, etc. Hence, there is more value to the detection of the existence of a link, rather than its absence. This mirrors the asymmetric cost of false alarm and missed detection in hypothesis testing. To account for this, we use a gain function g : U × Û → [0, ∞) and maximize over gain functions as follows.</p><p>Definition 5 (Maximal Gain Leakage): Given a joint distribution P XY on finite alphabets X and Y, the maximal gain leakage is defined as</p><formula xml:id="formula_44">L G (X→Y ) = sup U :U -X-Y Û ,g:U× Û→[0,∞): sup û E[g(U,û)]&gt;0 log sup û(•) E[g(U, û(Y ))] sup û E[g(U, û)] ,</formula><p>where U is a finite, but arbitrary, alphabet.</p><p>Similarly to previous variations, maximal gain leakage turns out to be equivalent to maximal leakage. Theorem 5: For any joint distribution P XY on finite alphabets X and Y,</p><formula xml:id="formula_45">L (X→Y ) = L G (X→Y ) .</formula><p>Remark 5: For a similar result in which U = X but one takes the supremum over all X distributions, see Alvim et al. <ref type="bibr" target="#b41">[42]</ref>.</p><p>Proof: It follows straightforwardly from the definitions that L G (X→Y ) ≥ L (X→Y ). For the reverse direction, consider any U satisfying U -X -Y , any (non-empty) set Û and function g :</p><formula xml:id="formula_46">U × Û → [0, ∞). Then sup û(•) E[g(U, û(Y ))] = y∈Y sup û∈ Û u∈U g(u, û)P U Y (u, y) = y∈Y sup û∈ Û u∈U x∈supp(X) g(u, û)P X (x)P U |X (u|x)• P Y |X (y|x) ≤ y∈Y max x ∈supp(X) P Y |X (y|x ) • sup û∈ Û u∈U x∈supp(X) g(u, û)P X (x)P U |X (u|x) = y∈Y max x ∈supp(X) P Y |X (y|x ) sup û E[g(U, û)],</formula><p>as desired.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Conditional Maximal Leakage</head><p>One of the main challenges in information leakage problems comes from the fact that the adversary can acquire information from multiple sources. This prompted researchers in database security to make very conservative assumptions about the knowledge of the adversary: differential privacy is introduced in a setup in which the adversary knows all the entries of the database except one <ref type="bibr" target="#b54">[55]</ref>. This also raises interest in the behavior of mechanisms under composition <ref type="bibr" target="#b55">[56]</ref>. That is, if the adversary receives multiple independent observations released by a given secure mechanism, how do the security guarantees degrade? In order to answer these questions, we propose a conditional form of maximal leakage, which is defined analogously to Definition 1.</p><p>Definition 6 (Conditional Maximal Leakage): Given a joint distribution P XY Z on alphabets X , Y and Z, the conditional maximal leakage from X to Y given Z is defined as</p><formula xml:id="formula_47">L (X→Y |Z) = sup U :U -X-Y |Z log Pr(U = Û (Y, Z)) Pr(U = Ũ (Z)) ,<label>(22)</label></formula><p>where U takes values in a finite, but arbitrary, alphabet, and Û (Y, Z) and Ũ (Z) are the optimal (i.e., MAP) estimators of U given (Y, Z) and Z, respectively.</p><formula xml:id="formula_48">Remark 6: The Markov chain U -X -Y |Z is equiv- alent to U -(X, Z) -Y .</formula><p>The above definition is hence conservative, in that it allows the channel from X to U to depend on Z. One could instead consider U s satisfying the Markov chain U -X -(Y, Z). The quantity so modified appears to be considerably more difficult to analyze.</p><p>Theorem 6: Given a joint distribution P XY Z on finite alphabets X , Y and Z, the conditional maximal leakage from X to Y given Z is given by</p><formula xml:id="formula_49">L (X→Y |Z) = log max z:PZ (z)&gt;0 y max x: PX|Z (x|z)&gt;0 P Y |XZ (y|x, z).<label>(23)</label></formula><p>In other terms, L (X→Y |Z) = max z∈supp(Z) L(X → Y |Z = z), where L(X→Y |Z = z) is interpreted as the unconditional maximal leakage evaluated with respect to the joint distribution P XY |Z=z . The following corollary summarizes important properties of conditional maximal leakage.</p><p>Corollary 2: Given a joint distribution P XY Z on finite alphabets X , Y and Z,</p><formula xml:id="formula_50">1) (Data Processing Inequality) If the Markov chain X -Y -V |Z holds for a discrete random variable V , then L (X→V |Z) ≤ min{L (X→Y |Z) , L (Y →V |Z)}. 2) L (X→Y |Z) ≤ min{log |X |, log |Y|}. 3) L (X→Y |Z) = 0 iff X -Z -Y holds. 4) (Additivity) If {(X i , Y i , Z i )} n i=1 are mutually inde- pendent, then L (X n 1 →Y n 1 |Z n 1 ) = n i=1 L (X i →Y i |Z i ) . 5) L (X→Y |Z) ≥ I(X; Y |Z). 6) L (X→Y |Z) is not symmetric in X and Y . 7) If Z -X -Y holds, then L (X→Y |Z) ≤ L (X→Y ) ,</formula><p>with equality if for some z ∈ supp(Z), supp(P X|Z=z ) = supp(P X ).</p><formula xml:id="formula_51">8) L (X→(Y, Z)) ≤ L (X→Z) + L (X→Y |Z) .</formula><p>Similarly to maximal leakage, properties 1)-4) can be seen as axiomatic for a conditional leakage metric. Property 5) is analogous to the relationship between maximal leakage and mutual information. <ref type="bibr">Property 7)</ref> is interesting in that it exhibits a behavior similar to mutual information. Indeed, if Z -X -Y holds, then I(X; Y |Z) ≤ I(X; Y ). Property 8) can be viewed as a one-sided chain rule. A simple consequence of properties 7) and 8) is the following composition lemma.</p><p>Lemma 6 (Composition Lemma): Given a joint distribution P XY Z on finite alphabets X , Y and Z, if Z -X -Y holds, then</p><formula xml:id="formula_52">L (X→(Y, Z)) ≤ L (X→Z) + L (X→Y ) .</formula><p>Hence, if an adversary has access to side information Z and this is not known to the system designer (which is often the case in practice), then minimizing L (X→Y ) (irrespective of Z) is still a reasonable objective.</p><p>The proofs of Theorem 6 and Corollary 2 are given in Appendices B-B and B-C, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. General Alphabets</head><p>Finally, we generalize Theorem 1 to allow for a large class of random variables and stochastic processes. We use the general formula to study a simple model of the SSH side-channel and analyze the performance of commonly used mechanisms. Our analysis suggests that memoryless schemes generally do not perform well under maximal leakage.</p><p>Before stating the theorem for general alphabets, we introduce the following notation. For a given probability distribution P X , and a measurable function f : X → R, the essential supremum of f with respect to P X is defined as:</p><formula xml:id="formula_53">ess-sup PX f (X) = inf{α : P X ({x : f (x) &gt; α}) = 0}.<label>(24)</label></formula><p>Equivalently,</p><formula xml:id="formula_54">ess-sup PX f (X) = sup{β : P X ({x : f (x) &gt; β}) &gt; 0}. (<label>25</label></formula><formula xml:id="formula_55">)</formula><p>Theorem 7: Let (X ×Y, σ XY , P XY ) be a probability space with associated probability spaces (X , σ X , P X ) and (Y, σ Y , P Y ), where σ XY is the product sigmaalgebra.</p><p>1) If P XY P X × P Y and σ X is generated by a countable set, then</p><formula xml:id="formula_56">L (X→Y ) = log Y ess-sup PX f (X, y)P Y (dy),<label>(26)</label></formula><p>where f (x, y) = dPXY d(PX ×PY ) (x, y). 2) If absolute continuity fails, then L (X→Y ) = +∞.</p><p>In the discrete case, L (X→Y ) depends on P XY only through P Y |X and the support of P X . Although it is not immediately clear from <ref type="bibr" target="#b25">(26)</ref>, this holds true in the general case in the following sense. Define an equivalence relation on the set of probability measures on a given measurable space as follows:</p><formula xml:id="formula_57">P ≡ Q if P Q and Q P.<label>(27)</label></formula><p>Then L (X→Y ) depends on P XY only through P Y |X and the equivalence class of P X . We formalize this observation in the following lemma.</p><p>Lemma 7: Let (X , σ X , P X1 ) be a probability space, and let (Y, σ Y ) and (X ×Y, σ XY ) be measurable spaces, where σ XY is the product sigma-algebra. Fix a kernel µ from X to Y, that is, a function µ :</p><formula xml:id="formula_58">X × σ Y → [0, ∞) that satisfies: 1) For every B ∈ σ Y , µ(•, B) is σ X -measurable. 2) For every x ∈ X , µ(x, •) is a probability measure on (Y, σ Y ).</formula><p>Let P X1Y1 and P Y1 be the probability measures induced by</p><formula xml:id="formula_59">P X1 and µ(•, •) on (X × Y, σ XY ) and (Y, σ Y ), respectively. If P X1Y1 P X1 × P Y1 , then µ(x, •) P Y1 . If, in addition, σ X is generated by a countable set, L (X 1 →Y 1 ) = log Y ess-sup PX 1 dµ(X, •) dP Y1 P Y1 (dy) = log Y ess-sup PX dµ(X, •) dQ Y Q Y (dy),<label>(28)</label></formula><p>where P X is an arbitrary representative of the equivalence class (cf. ( <ref type="formula" target="#formula_57">27</ref>)) of P X1 and Q Y is any measure satisfying P Y1 Q Y . Consequently, if P X2 is a probability measure on (X , σ X ) satisfying P X2 ≡ P X1 , then P X2Y2 P X2 × P Y2 , P Y1 ≡ P Y2 , and</p><formula xml:id="formula_60">L (X 2 →Y 2 ) = L (X 1 →Y 1 ) ,</formula><p>where P X2Y2 and P Y2 are the induced probability measures on (X × Y, σ XY ) and (Y, σ Y ), respectively.</p><p>The proofs of Theorem 7 and Lemma 7 are given in Appendices B-D and B-E, respectively. We now discuss implications and examples of the theorem.</p><p>Corollary 3: Let (X ×Y, σ XY , P XY ) be a probability space with associated probability spaces (X , σ X , P X ) and (Y, σ Y , P Y ). Assume P XY P X × P Y and σ X is generated by a countable set. Then</p><formula xml:id="formula_61">1) L (X→Y ) = 0 iff X and Y are independent. 2) (Additivity) If {(X i , Y i )} n i=1 are mutually indepen- dent, then L (X n 1 →Y n 1 ) = n i=1 L (X i →Y i ) .</formula><p>3) L (X→Y ) ≥ I(X; Y ).</p><p>Proof: For 3) it suffices to consider the case in which P XY P X ×P Y . Let f (•, •) denote the derivative of P XY with respect to P X × P Y and consider the following.</p><formula xml:id="formula_62">I(X; Y ) = E[log f (X, Y )] (a) ≤ log E[f (X, Y )] = log Y X f 2 (x, y)P X (dx)P Y (dy) ≤ log Y ess-sup PX f (X, y) • X f (x, y)P X (dx)P Y (dy) (b) = L (X→Y ) ,</formula><p>where (a) follows from Jensen's inequality, and (b) follows from the fact X f (x, y)P</p><formula xml:id="formula_63">X (dx) = 1 Y -a.s. because Y X f (x, y)P X (dx) 1(y ∈ B)P Y (dy) = P (Y ∈ B)</formula><p>for all B. 1) follows from the definition and 3). 2) follows from the fact that if</p><formula xml:id="formula_64">(X 1 , Y 1 ) is independent of (X 2 , Y 2 ), then f (x 1 , x 2 , y 1 , y 2 ) = f (x 1 , y 1 )f (x 2 , y 2 ).</formula><p>Recall that the data processing inequality also holds by Lemma 1. Hence, the general formula of maximal leakage retains the axiomatic properties we required in (R3). It also covers the case in which X is discrete and Y is continuous, or vice versa. </p><formula xml:id="formula_65">L (X→Y ) = log R ess-sup PX f Y |X (y|x)dy,<label>(29)</label></formula><p>where</p><formula xml:id="formula_66">f Y |X (•|•) is the conditional pdf of Y given X.</formula><p>Moreover, if the marginal pdf of X, f X (x), is continuous, and for almost all</p><formula xml:id="formula_67">y ∈ R, f Y |X (y|x) is continuous on D := {x : f X (x) &gt; 0}, then L (X→Y ) = log R sup x:fX (x)&gt;0 f Y |X (y|x)dy,<label>(30)</label></formula><p>Proof: Equation ( <ref type="formula" target="#formula_65">29</ref>) follows directly from Lemma 7. To show <ref type="bibr" target="#b29">(30)</ref>, we first show that for all y ∈ R,</p><formula xml:id="formula_68">sup x:fX (x)&gt;0 f Y |X (y|x) ≥ ess-sup PX f Y |X (y|x). Let M y := ess-sup PX f Y |X (y|x). Given &gt; 0, let S y, = {x : f Y |X (y|x) &gt; M y -}.</formula><p>By definition of M y , P X (S y, ) &gt; 0. Hence, there exists x ∈ S y, such that f X (x) &gt; 0. Consequently, sup x:fX (x)&gt;0 f Y |X (y|x) ≥ M y -. The inequality follows since can be chosen arbitrarily small.</p><p>To show the other direction, fix</p><formula xml:id="formula_69">y such that f Y |X (y|x) is continuous on D = {x : f X (x) &gt; 0}, and let N y := sup x:fX (x)&gt;0 f Y |X (y|x). Assume N y &gt; 0 (otherwise, the inequality is trivial). Consider 0 &lt; &lt; N y and x such that f X (x ) &gt; 0 and f Y |X (y|x ) &gt; N y -. Given 0 &lt; &lt; min{f (x )/2, N y -}, choose δ &gt; 0 such that |x -x| &lt; δ ⇒ |f (x ) -f (x)| &lt; and |f Y |X (y|x ) - f Y |X (y|x)| &lt; . Hence, for all x satisfying |x -x| &lt; δ, f Y |X (y|x) &gt; N y --, and P X (x : f Y |X (y|x) &gt; N y --) ≥ P X (x : |x -x| &lt; δ) = x +δ x -δ f X (x) &gt; δf X (x ) &gt; 0.</formula><p>The inequality follows since and can be chosen to be arbitrarily small.</p><p>Example 9: If X and Y are jointly Gaussian, then</p><formula xml:id="formula_70">L (X→Y ) = 0, if X and Y are independent, +∞, otherwise.</formula><p>Example 10: Suppose X is real and its pdf satisfies</p><formula xml:id="formula_71">f X (x) &gt; 0 for all x ∈ R. Let Y = X + Z, where Z is a continuous real random variable independent of X. Let z 0 = argmax f Z (z). Then L (X→Y ) = log R sup x∈R f Y |X (y|x)dy = log R sup x f Z (y -x)dy = log R f Z (z 0 )dy = +∞.</formula><p>The above examples suggest that "adding independent noise" is not necessarily secure in the maximal leakage sense. The following example considers a simple model of the SSH side-channel and further illustrates this point.</p><p>Example 11: Consider the SSH side-channel and suppose we wish to perturb the packet timings before they are sent over the network so that we decrease information leakage. We represent the process of incoming packets as a Poisson process of a given rate, λ. More formally, fix T ∈ R + and let Ω T be the set of all counting functions on [0, T ], i.e., ω ∈ Ω T is an integer-valued, nondecreasing, right-continuous function on [0, T ] and ω(0) = 0. Let {F t } T t=0 be the filtration over Ω T generated by the mapping ω → ω t . Let X T 0 be a Poisson process of rate λ, representing the incoming packets. Let Y T 0 be a point process on (Ω T , F T ) representing the outgoing packets.</p><p>a) Memoryless scheme: Suppose we hold each packet for an independent random amount of time before releasing it into the network. More specifically, let Y T 0 be the output of an initially-empty exponential-server queue with rate µ &gt; λ and input</p><formula xml:id="formula_72">X T 0 . Then 1 T L X T 0 →Y T 0 = µ,<label>(31)</label></formula><p>and, as T → ∞, the average waiting time for a packet (between arrival and transmission) tends to 1 µ-λ . Note that the system is unstable if µ &lt; λ.</p><p>Proof: Let P 0 be the probability measure on (Ω T , F T ) under which the output is distributed as a Poisson process of rate one. It is known <ref type="bibr" target="#b56">[57]</ref> [58, Ch. VI, Theorem T3] that for (x, y)</p><formula xml:id="formula_73">∈ Ω T × Ω T , dP XY dP X × P 0 (x, y) = exp T 0 log(µI(x t &gt; y t-))dy t + T 0 (1 -µI(x t &gt; y t ))dt =: L(x, y). Now note that, dP XY dP X × P Y dP Y = dP XY dP X × P Y dP X × P 0 dP X × P 0 dP Y dP 0 dP 0 = LdP 0 ,</formula><p>where the equalities follow from [59, Ex. 32.6, p. 426] and the fact that dPX ×P0 dPX ×PY = dP0 dPY . Then</p><formula xml:id="formula_74">L X T 0 →Y T 0 = log ΩT ess-sup PX L(X, y)P 0 (dy).</formula><p>It is easy to verify that ess-sup PX L(X, y) = exp(y T log µ + T ). By noting that y T is distributed as Poi(T ) under P 0 , we get</p><formula xml:id="formula_75">1 T L X T 0 →Y T 0 = 1 T log ΩT exp [y T log µ + T ] P 0 (dy) = 1 T log exp[T (µ -1) + T ] = µ.</formula><p>The computation of the average waiting time is standard (e.g., <ref type="bibr">[60, (3.26)</ref>]). b) Accumulate-and-dump: Fix τ ∈ R + and m ∈ N. Assume (for simplicity) that τ divides T , and consider the following scheme. The packets are accumulated, then released ("dumped") only at integer multiples of τ . If in a given interval more than m packets are received, only the first m are sent and the remaining ones are dropped. Then</p><formula xml:id="formula_76">1 T L X T 0 →Y T 0 = 1 τ log(m + 1),<label>(32)</label></formula><p>and the average waiting time for a packet is τ /2 assuming it is not dropped. Moreover,</p><formula xml:id="formula_77">P e ≤ e λτ (ν-(1+ν) log(1+ν)) ,<label>(33)</label></formula><p>where P e is the probability that the number of packets exceeds m in a given interval of length τ , and ν = (m+1)/(λτ )-1. Hence, choosing m to be (1+ν)λτ -1, for some ν &gt; 0, yields</p><formula xml:id="formula_78">1 T L X T 0 →Y T 0 = 1 τ log((1 + ν)λτ ),</formula><p>and a probability of dropping a packet that is exponentially small in ν. Note that, as opposed to the memoryless scheme above, accumulate-and-dump can make the leakage arbitrarily small. For a more direct comparison, suppose we wish the average waiting time to be no more than 1/λ. Hence, for the memoryless scheme we choose µ = 2λ, which leads to a leakage of 2λ. For the accumulate-and-dump scheme, choose τ = 2/λ and ν = e 3 /2 -1(≈ 9). Then one can readily verify that the leakage is 3λ/2 and P e is on the order of 10 -12 .</p><p>Proof: Since the number of arrivals in a Poisson process are identically distributed and independent for non-overlapping intervals of the same length,</p><formula xml:id="formula_79">1 T L X T 0 →Y T 0 = 1 T T τ L (X τ 0 →Y τ 0 ) = 1 τ L (X τ 0 →Y τ ) = 1 τ log(m + 1),</formula><p>where the last equality follows from the fact that Y τ is a deterministic function of X τ 0 that takes values in {0, 1, . . . , m}. To compute the average waiting time, it is enough to consider the waiting time for the packets that arrive in the first interval </p><p>Remark 7: In <ref type="bibr" target="#b0">[1]</ref>, the authors do not suggest an upper bound on the number of packets that can be released in a given interval. They implicitly assume that there exists an m for which the number of arrivals in a given interval is at most m almost surely. This is not true for the Poisson process, but for any process that satisfies this property, the leakage of accumulate-and-dump + inject-dummypackets is upper-bounded by the right hand side of <ref type="bibr" target="#b33">(34)</ref>.</p><p>The choice of m and m b provides a trade-off between the overhead of injecting dummy packets and the probability of dropping a packet. Song et al. <ref type="bibr" target="#b0">[1]</ref> also point out an important drawback of the memoryless scheme. If the adversary observes several independent instances of the output for the same input (e.g., they eavesdrop several times on the same user while they are inputting their password), they can diminish the effect of randomization by considering the average (over the different observations) of the inter-arrival times between successive packets. Similar observations hold for the optimal mechanism for the Shannon cipher system, to which we turn next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. SHANNON CIPHER SYSTEM</head><p>The main goal in quantifying information leakage is to enable the design of mechanisms to mitigate it. As an application, we study a (traditional) secrecy setup known as the Shannon cipher system <ref type="bibr" target="#b2">[3]</ref>. The setup consists of a transmitter and a legitimate receiver that are linked by a public noiseless channel and share a common key, and an eavesdropper who has access to the public channel and is aware of the source statistics and the used encryption schemes. The encryption schemes must allow the legitimate receiver to perfectly reconstruct the source sequence. Shannon <ref type="bibr" target="#b2">[3]</ref> showed that perfect secrecy (i.e., making the source X n and the public message M independent) requires a key rate as high as the message rate, which is typically not feasible in practice. Hence several works <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b23">24]</ref>- <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b33">34]</ref> studied the optimal partial secrecy achievable for a given key rate r, and used different measures to assess secrecy guarantees.</p><p>Fig. <ref type="figure" target="#fig_0">3</ref>. The Shannon cipher system with lossy communication: the transmitter and the legitimate receiver have access to a common key K, which consists of nr purely random bits, where r is called the key rate. Using both the public message M and the secret key K, the legitimate receiver generates a reconstruction Y n that should satisfy a given distortion constraint. The eavesdropper has access to the public message M only.</p><p>In this section, we use maximal leakage to assess the performance of any feasible encryption scheme. Similarly to previous works, we are concerned with the dependence between the source and the public message (i.e., L (X n →M ) in our case, as opposed to the dependence between the secret key and the public message). Moreover, we allow for lossy communication by introducing a distortion function d at the legitimate receiver, as shown in Figure <ref type="figure" target="#fig_0">3</ref>. For a given distortion level D, we require that the probability of violating the distortion constraint decays as 2 -nα , for a given α &gt; 0. Then, for a given D and α, we study the asymptotic behavior of the normalized maximal leakage.</p><p>For a discrete memoryless source (DMS), we derive the optimal (i.e., minimal) limit of the normalized maximal leakage. The scheme we propose for the primary user (i.e., the transmitter-legitimate receiver pair) operates on a type-by-type basis. With each type, we associate a good rate-distortion code. The codebooks are then divided into bins, and the key is used to randomize, within a bin, the choice of codeword associated with a particular source sequence. However, types with low enough probability are discarded, i.e., a dummy message is associated with all the source sequences belonging to such types. We also derive the optimal limit when the requirement of a decaying probability of violating the distortion constraint is replaced with an expected distortion con-straint. In this scenario, one might expect that memoryless schemes are sufficient for optimality. We evaluate this claim by considering the case in which there is no common key and the rate of the channel is high (cf. Figure <ref type="figure" target="#fig_1">4</ref>). This setup was dubbed the "information blurring system" in <ref type="bibr" target="#b27">[28]</ref>, and it represents a stylized model of side-channels. For instance, in the SSH setup, X n could represent the timings of the incoming packets, Y n could represent the perturbed timings of the outgoing packets, and the distortion function could represent required quality (e.g., delay) constraints imposed on the system. We show that, even in this setup, memoryless schemes are strictly suboptimal in general. This strengthens our earlier observations in Section III-F and suggests that commonly used memoryless schemes are generally outperformed by quantization-based schemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Setup and Statement of Result</head><p>Let X and Y be the alphabets associated with the transmitter and the legitimate receiver, respectively. The transmitter and the legitimate receiver are connected through a noiseless channel of rate R, and share common randomness K n ∈ K n = {0, 1} nr , where K n is uniformly distributed over K n , and r &gt; 0 is the rate of the key. The transmitter observes an n-length message</p><formula xml:id="formula_81">X n = (X 1 , X 2 , • • • , X n ), independent of K n ,</formula><p>and wishes to communicate it to the receiver. Let f and h be, respectively, the transmitter's encoding and the receiver's decoding functions. The transmitter then sends a message M n = f (X n , K n ), M n ∈ M n = {0, 1} nR , and the receiver generates a reconstruction Y n = h(M n , K n ). We allow the functions f and h to be randomized (beyond the private randomness in K n ). For a given distortion function d : X × Y → R + , distortion level D, and excess distortion probability α, we require that Pr(d</p><formula xml:id="formula_82">(X n , Y n ) &gt; D) ≤ 2 -nα , where d(X n , Y n ) = 1 n n i=1 d(X i , Y i ).</formula><p>An eavesdropper intercepts the message M . We assume they know the source statistics as well as the encoding and decoding functions, but do not have access to the key K n .</p><p>The primary user aims to minimize the maximal leakage to the eavesdropper L (X n →M n ). We characterize the asymptotically-optimal normalized maximal leakage under the following assumptions </p><formula xml:id="formula_83">(A4) R &gt; max Q:D(Q||P )≤α R(Q, D), where R(Q, D) is</formula><p>the rate-distortion function for source distribution Q.</p><p>We denote the optimal limit by L(P, D, -→ R , α), where P is the source distribution, and</p><formula xml:id="formula_84">- → R = (R, r): L(P, D, - → R , α) = lim n→∞ min {fn∈Fn} 1 n L (X n →f (X n , K n )) ,</formula><p>where {F n } is the set of feasible schemes, i.e.,</p><formula xml:id="formula_85">F n = {f n : X n × {0, 1} nr → {0, 1} nR there exists g : {0, 1} nR × {0, 1} nr → Y n satisfying Pr d X n , g f (X n , K n ) , K n ≤ 2 -nα }.</formula><p>It will be more notationally convenient in this section to give the answers in bits rather than nats. Hence we will use the logarithm to the base 2 when computing maximal leakage. To avoid confusion, we will explicitly mention the unit we are using.</p><p>The main result of this section is the characterization of the optimal limit as follows: </p><formula xml:id="formula_86">L(P, D, - → R , α) = max Q:D(Q||P )≤α [R(Q, D) -r] + (bits),<label>(35)</label></formula><p>where [a] + = max{0, a}.</p><p>Note that the case α = ∞ (i.e., when the distortion constraint is imposed almost surely) is included in the theorem. Moreover, in that case, the theorem holds even if the source is not memoryless, as long as the support of X n is X n . This follows from the fact that L (X n →M n ) and the constraint, when imposed almost surely, depend on the distribution of X n only through its support. Therefore, solving for any specific distribution on that support is equivalent to solving for all distributions on the same support. Before proving the theorem (in Sections IV-D and IV-E for achievability and converse, respectively), we discuss a variation using an expected distortion constraint and its implication on the performance of memoryless schemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Memoryless Schemes with Expected Distortion</head><p>Instead of requiring a decaying probability of violating the distortion constraint, we could require that the distortion constraint holds only in expectation-as is common in many works in the literature. That is, we require that</p><formula xml:id="formula_87">E[d(X n , Y n )] ≤ D.</formula><p>In that case, we modify assumption (A4) to be: </p><formula xml:id="formula_88">(A4') R &gt; R(P, D).</formula><p>Proof: The achievability argument follows by a similar manner as the one given in subsection IV-D. However, instead of encoding on a type-by-type basis, we simply use a good rate-distortion code that satisfies the expected distortion requirement and divide it into bins of size 2 nr . One could also derive it from Theorem 8 as follows:</p><formula xml:id="formula_90">L(P, D, - → R ) ≤ lim D →D + lim α→0 L(P, D , - → R , α) = [R(P, D) -r] + .</formula><p>As for the lower bound, we use the fact that I ∞ (X; Y ) ≥ I(X; Y ) <ref type="bibr" target="#b32">[33]</ref>. This problem, with mutual information replacing maximal leakage, has already been solved by Yamamoto <ref type="bibr" target="#b24">[25]</ref> and Schieler and Cuff <ref type="bibr" target="#b23">[24]</ref>. More specifically, Corollary 5 of <ref type="bibr" target="#b23">[24]</ref> yields that the optimal normalized mutual information is indeed given by [R(P, D) -r] + . With the expected distortion constraint, one might venture that the optimal limit is achievable with a memoryless scheme, in which the encoder passes the source through i.i.d copies of an optimal conditional distribution P Y |X . Counter to this common intuition, and counter to the case in which leakage is measured via mutual information, we show that this is generally not the case when the objective is maximal leakage.</p><p>To that end, consider the case in which r = 0 and R = log |Y| (cf. Figure <ref type="figure" target="#fig_1">4</ref>). By Theorem 9, L(P, D) = R(P, D). Now define</p><formula xml:id="formula_91">L mem n (P, D) = min PY |X :E[d(X,Y )]≤D 1 n L (X n →Y n ) ,<label>(37)</label></formula><p>where P X n Y n = n i=1 P Xi P Yi|Xi . By the additive property of maximal leakage, it follows straightforwardly that L mem n (P, D) does not depend on n, so we will drop the n subscript. The latter equality is not a sufficient condition, however. Hence, memoryless schemes are strictly suboptimal, except in very special cases.</p><p>We next strengthen this observation by relaxing the constraint in <ref type="bibr" target="#b36">(37)</ref> by allowing the choice of the conditional distribution P Yi|Xi to depend on the index i. So define</p><formula xml:id="formula_92">L mem,i n (P, D) = min PY n |X n :PY n |X n = n i=1 P (i) Y i |X i 1 n L (X n →Y n ) (38) subject to E[d(X n , Y n )] ≤ D.</formula><p>This is still not sufficient to achieve optimality in general, as the following lemma shows. 1-D/p in general (where the inequality can be checked using convexity), memoryless schemes are strictly suboptimal.</p><p>Proof: For any P Y n |X n in the minimization, let</p><formula xml:id="formula_93">D i = E[d(X i , Y i )] = Pr(X i = Y i ). Without loss of generality, we can assume D i ≤ p. Then L (X n →Y n ) = n i=1 L (X i →Y i ) ≥ n i=1 min PY i |X i : Pr(Xi =Yi)≤Di L (X i →Y i ) .</formula><p>We show in Appendix C that</p><formula xml:id="formula_94">min PY i |X i : Pr(Xi =Yi)≤Di L (X i →Y i ) = log 2 (2 -D i /p) (bits). (39) Thus, L (X n →Y n ) ≥ n i=1 log 2 (2 -D i /p) = n i=1 log 2 2-(D i /p)(1)-(1 -D i /p)(0) (a) ≥ n i=1 (D i /p) log 2 (1) + (1 -D i /p) log 2 (2) = n i=1 (1 -D i /p) (b) ≥ n(1 -D/p),</formula><p>where (a) follows from the fact that log 2 (2 -x) is concave in x, and (b) follows from the constraint in <ref type="bibr" target="#b37">(38)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Notation</head><p>In the following, Z is an arbitrary discrete set, and Z is a random variable over Z.</p><p>-For a sequence z n ∈ Z n , Q z n is the empirical PMF of z n , also referred to as its type. -Q n Z is the set of types in Z n , i.e., the set of rational PMF's with denominator n. </p><formula xml:id="formula_95">-For Q Z ∈ Q n Z , the type class of Q Z is T QZ {z n ∈ Z n : Q z n = Q Z }. -E Q [•], H Q (•)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Achievability Proof of Theorem 8</head><p>We will slightly abuse notation and shorten L(P, D, -→ R , α) to L in the following. We now show that the right-hand side of (35) upper-bounds L.</p><p>Consider any &gt; 0 and let n be large enough such that we can construct a rate-distortion code C n QX , for each type Q X ∈ Q n X , satisfying the following: each sequence x n ∈ T QX is covered and |C n QX | ≤ 2 n(R(QX ,D)+ ) . Such construction is guaranteed by the type covering lemma (Lemma 9.1 in <ref type="bibr" target="#b30">[31]</ref>). We divide the codebook C n QX into C n QX /2 nr bins, each of size 2 nr , except for possibly the last one. We denote by C n QX (i, •) the ith partition of the codebook, and by C n QX (i, j) the jth codeword in the ith partition. For each x n ∈ T QX , let i x n and j x n denote, respectively, the index of the partition containing the codeword associated with x n and the index of the codeword within the partition (Note that if more than one codeword can be associated with x n , we fix any one of them arbitrarily). Finally, let m(Q X , i, j) be a message consisting of the following:</p><formula xml:id="formula_96">• log 2 |Q n X | bits to describe the type Q X . • log 2 C n QX</formula><p>2 nr bits to describe the index i,</p><formula xml:id="formula_97">where 1 ≤ i ≤ C n QX 2 nr . • log 2 C n QX (i, •)</formula><p>bits to describe the index j,</p><formula xml:id="formula_98">where 0 ≤ j ≤ exp 2 log 2 C n QX (i, •) -1. Now, for any δ ∈ R, let Q(α, δ) = {Q X : D(Q X ||P ) ≤ α + δ}, Q n (α, δ) = {Q X ∈ Q n X : D(Q X ||P ) ≤ α+δ},</formula><p>and consider the following lemma.</p><p>Lemma 10:</p><formula xml:id="formula_99">lim δ→0 max QX ∈Q(α,δ) R(Q X , D) = max QX ∈Q(α,0) R(Q X , D).</formula><p>Proof: This follows directly from the convexity of D(Q||P ), and Propositions 12 and 13 in <ref type="bibr" target="#b27">[28]</ref>. Now let δ &gt; 0 be such that max QX ∈Q(α,δ) R(Q X , D) &lt; R (Such δ exists by Lemma 10 and (A4)). Finally, for each sequence x n , let s(x n ) = log C n QX (i x n , •) , and let K s(x n ) be the first s(x n ) bits of K n . The transmitter encodes as follows. Given</p><formula xml:id="formula_100">x n , if Q x n ∈ Q n (α, δ), then f (x n , K n ) = m Q x n , i x n , j x n ⊕ K s(x n ) ,<label>(40)</label></formula><p>where the XOR-operation is performed bitwise. Note that, in this case, the legitimate receiver can retrieve the type of the transmitted sequence and the index of the bin from the first two parts of the message, and the index of the sequence within the bin using the last part of the message and the key K n , so that h(M n , K n ) = C n Qxn (i x n , j x n ). Now, consider an m 0 ∈ M n that has not been used by the previous encoding (Assumption (A4) and the choice of δ ensures the existence of such m 0 ). Then, for all x n such that Q</p><formula xml:id="formula_101">x n / ∈ Q n (α, δ), f (x n , K n ) = m 0 .<label>(41)</label></formula><p>Remark 8: To verify that the suggested scheme satisfies the excess distortion probability constraint, consider the following:</p><formula xml:id="formula_102">Pr(d(X n , Y n ) &gt; D) ≤ QX / ∈Qn(α,δ) P (Q) ≤ QX / ∈Qn(α,δ) 2 -nD(QX ||P ) ≤ (n + 1) |X | 2 -n(α+δ) &lt; 2 -nα ,</formula><p>where the last inequality holds for large enough n.</p><p>Effectively, we are leaking the first two parts of the message Q X n and i X n , and hiding completely the last part j X n . Since there are only polynomially many types, the first part does not affect the normalized leakage. The second part, however, consists roughly of R(Q, D)r bits, whenever R(Q, D) &gt; r; otherwise, i.e., when R(Q, D) ≤ r, there is only one bin and there is no information to be leaked.</p><p>For a more rigorous analysis, let P f be the induced joint probability distribution of (X n , M n ). Then, for x n satisfying Q x n ∈ Q n (α, δ), we get from <ref type="bibr" target="#b39">(40)</ref>:</p><formula xml:id="formula_103">P f m(Q x n , i x n , j) x n = 2 -s(x n ) , 0 ≤ j ≤ 2 s(x n ) -1.</formula><p>Let S(x n ) = 2 s(x n ) . Note that we can equivalently denote S(x n ) by S(Q x n , i x n ), since the dependence on the sequence is only through the type and the index of the bin. Therefore, we get</p><formula xml:id="formula_104">exp 2 {L (X n →M n )} = m∈Mn max x n ∈X n P f (m|x n ) = max x n ∈X n P f (m 0 |x n )+ QX ∈ Qn(α,δ) |C n Q X |/2 nr i=1 S(QX ,i)-1 j=0 max x n ∈X n P f (m(Q X , i, j)|x n ) = 1 + QX ∈ Qn(α,δ) |C n Q X |/2 nr i=1 S(QX ,i)-1 j=0 S(Q X , i) -1 ≤ 1 + QX ∈Qn(α,δ)</formula><p>(2 n(R(QX ,D)+ -r) + 1)</p><formula xml:id="formula_105">≤ 1 + 2 QX ∈Qn(α,δ) 2 n max{R(QX ,D)+ -r,0} ≤ 4(n + 1) |X | exp 2 {n max QX ∈Qn(α,δ) [R(Q X , D) + -r] + }.<label>(42)</label></formula><p>Taking the limit as n tends to infinity, and noting that and δ were arbitrary, we get that</p><formula xml:id="formula_106">L ≤ max Q:D(Q||P )≤α [R(Q, D) -r] + ,</formula><p>where the inequality follows from Lemma 10 and the following lemma, the simple of proof of which is omitted.</p><p>Lemma 11:</p><formula xml:id="formula_107">lim n→∞ max Q∈Q n X :D(Q||P )≤α R(Q, D) = max Q:D(Q||P )≤α R(Q, D).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Converse Proof of Theorem 8</head><p>We now show that L is lower-bounded by the righthand side of <ref type="bibr" target="#b34">(35)</ref>. To that end, consider any valid encoding function f . To lower-bound L (X n →M n ), we consider a specific P U |X n . In particular, we consider the "shattering" P U |X n given in <ref type="bibr" target="#b12">(13)</ref>. Recall</p><formula xml:id="formula_108">P U |X n ((i u , j u )|x n ) =        p P (x n ) , i u = x n , 1 ≤ j u ≤ k(x n ) , 1 -( k(x n ) -1)p P (x n ) , i u = x n , j u = k(x n ) , 0, i u = x n , 1 ≤ j u ≤ k(i u ) .</formula><p>Therefore, max u∈U P U (u) = p . We will also consider a sub-optimal guessing function for U . The scheme is as follows: the eavesdropper first tries to guess the key K n by choosing an element uniformly at random from {0, 1} nr . We denote this guess by Kn . Then, proceeding by assuming that the key guess was correct, they try to guess the sequence x n using a guessing function given by Lemma 12 below. We denote this stage by g 1 . Finally, again proceeding by assuming that the source sequence guess was correct, the eavesdropper attempts to guess U by using the MAP rule. We denote this stage by g 2 , and we get for each x n ∈ X n , g 2 (x n ) = (x n , 1), and Pr(g</p><formula xml:id="formula_109">2 (x n ) = U n |x n ) = p P (x n ) . (<label>43</label></formula><formula xml:id="formula_110">)</formula><p>Lemma 12: There exists a function g 1 : Y n → X n such that, for all (x n , y n ) satisfying d(x n , y n ) ≤ D, Pr (x n = g(y n )) ≥ c n 2 -n(HQ x n (X)-R(Qxn ,D)) , where c n = (n + 1) -|X ||Y|(|X |+1) .</p><p>Proof: This is an application of Lemma 5 in <ref type="bibr" target="#b27">[28]</ref>. In particular, we set in Lemma 5 V to be X , d e to be the Hamming distortion function, and D e to be zero. Then, I P n (Qxnyn ) (X; V |Y ) (as defined in <ref type="bibr" target="#b27">[28]</ref>) satisfies:</p><formula xml:id="formula_111">I P n (Qxnyn ) (X; V |Y ) = H Qxnyn (X|Y ) = H Qxn (X) -H Qxn (X) + H Qxnyn (X|Y ) ≤ H Qxn (X) -R(Q x n , D).</formula><p>To analyze the above scheme, fix &gt; 0, and let P f denote the induced joint probability on (X n , K n , M n ). Furthermore, without loss of generality, we can assume that the decoding function h is a deterministic function of M n and K n . Finally, define</p><formula xml:id="formula_112">M D (x n , k) = {m ∈ M n : d(x n , h(m, k)) ≤ D}, x n ∈ X n , k ∈ K n ,<label>(44)</label></formula><p>and</p><formula xml:id="formula_113">A = {(x n , y n ) ∈ X n × Y n : d(x n , y n ) &gt; D}. (<label>45</label></formula><formula xml:id="formula_114">)</formula><p>Letting g be the concatenation of the two stages, we get</p><formula xml:id="formula_115">Pr(U = g(M )) =</formula><p>x n ∈X n u∈U k∈Kn m∈Mn</p><formula xml:id="formula_116">P (x n )P U |X n (u|x n )P Kn (k)• P f (m|x n , k)P (u = g(m)|x n , m, k) ≥ x n ∈X n u∈U k∈Kn m∈MD(x n ,k) P (x n )P U |X n (u|x n )P Kn (k)• P f (m|x n , k)P (u = g(m)|x n , m, k) ≥ x n ∈X n u∈U k∈Kn m∈MD(x n ,k) P (x n )P U |X n (u|x n )P Kn (k)• P f (m|x n , k)P ( Kn = k)P (g 1 (h(m, k)) = x n )• P (g 2 (x n ) = u|x n ) (a) ≥ c n x n ∈X n k∈Kn m∈MD(x n ,k) P (x n )P Kn (k)P f (m|x n , k)• 2 -nr 2 -n(HQ x n (X)-R(Qxn ,D)) p /P (x n ) = c n p 2 -nr QX ∈Q n X x n ∈TQ X k∈Kn m∈MD(x n ,k) P (x n )P Kn (k) P f (m|x n , k)2 -n(HQ X (X)-R(QX ,D)) /P (x n ) = c n p 2 -nr QX ∈Q n X x n ∈TQ X k∈Kn m∈MD(x n ,k) P (x n )P Kn (k)• P f (m|x n , k)2 n(R(QX ,D)+D(QX ||P )) = c n p 2 -nr QX ∈Q n X 2 n(R(QX ,D)+D(QX ||P )) P f (A c ∩ T QX ),<label>(46)</label></formula><p>where (a) follows from <ref type="bibr">Lemma 12,</ref><ref type="bibr" target="#b42">(43)</ref>, and <ref type="bibr" target="#b43">(44)</ref>. Now, note that for any Q,</p><formula xml:id="formula_117">P f (A c |T Q ) = 1 -P f (A|T Q ) ≥ 1 -min{1, P f (A)/P (T Q )} ≥ 1 -min{1, 2 -n(α-D(Q||P )-|X | n log(n+1)) } = max{0, 1 -2 -n(α-D(Q||P )-|X | n log(n+1)) }.</formula><p>Then, continuing <ref type="bibr" target="#b45">(46)</ref>, we get</p><formula xml:id="formula_118">Pr(U = g(M )) ≥ c n p 2 -nr QX ∈Q n X 2 n(R(QX ,D)+D(QX ||P )) P (T QX )• max{0, 1 -2 -n(α-D(QX ||P )-|X | n log(n+1)) } (a) ≥ c n p 2 -nr QX ∈Qn(α,-) 2 nR(QX ,D) • (1 -2 -n(α-D(QX ||P )-|X | n log(n+1)) ) (b) ≥ c n p 2 -nr QX ∈Qn(α,-) 2 nR(QX ,D) (1/2) ≥ (c n p /2) max QX ∈Qn(α,-) exp 2 {n(R(Q X , D) -r)},<label>(47)</label></formula><p>where (a) and (b) hold for large enough n, and c n = (n + 1) -|X | c n . Finally taking the ratio of Pr(U = g(M )) and max u P U (u), and taking the limit as n tends to infinity, and noting that is arbitrary, we get</p><formula xml:id="formula_119">L ≥ max Q:D(Q||P )≤α R(Q, D) -r,</formula><p>where the inequality follows from Lemmas 10 and 11.</p><p>Since L is positive by definition,</p><formula xml:id="formula_120">L ≥ [ max Q:D(Q||P )≤α R(Q, D) -r] + = max Q:D(Q||P )≤α [R(Q, D) -r] + .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. LEARNING MAXIMAL LEAKAGE FROM DATA</head><p>In the previous two sections, we analyzed leakagemitigating schemes for a simple model of the SSH sidechannel and derived the (asymptotically) optimal scheme for the Shannon cipher system. In general, computing the maximal leakage induced by a given scheme might become intractable for complicated schemes. Consider, for instance, an on-chip network with several processes sharing its memory. Suppose one of the processes is malicious and another process is decrypting a message using a secret key. As we mentioned in the introduction, a sidechannel exists between these two processes because the memory access patterns of the latter affect the memory access delays of the former. This side-channel, however, is determined by the operation of the memory controller which could depend on many variables, as well as the behavior of other processes on the chip which might be difficult to model.</p><p>For such complicated schemes, one might simulate the system and attempt to estimate maximal leakage from data traces. This section investigates the complexity of this task, i.e., the number of samples needed to estimate L (X→Y ), which we equivalently denote by L(P X ; P Y |X ). To this end, an estimator is defined as a randomized function f : (X × Y) → R, which maps a sequence of samples drawn from a joint distribution to an estimate of its maximal leakage. Given a desired level of accuracy δ and a probability of error , the sample complexity of an estimator f is defined as:</p><formula xml:id="formula_121">S δ, |X |, |Y| [f ] = min{n :<label>(48)</label></formula><formula xml:id="formula_122">P XY L(P X ; P Y |X ) -f (X n , Y n ) &gt; δ &lt; ,</formula><p>for all P XY ∈ P X ×Y },</p><p>where P XY ∈ P X ×Y is the set of all probability distributions on X × Y, and (X n , Y n ) are drawn independently from P XY . Then the sample complexity of maximal leakage is defined as:</p><formula xml:id="formula_123">S δ, |X |, |Y| = inf f S δ, |X |, |Y| [f ].<label>(49)</label></formula><p>We show that S δ, (|X |, |Y|) turns out to be infinity for interesting values of the parameters. Hence, the design of secure systems should take amenability to analysis into consideration. That is, it is preferable to design, for instance, a memory controller that we can study analytically, rather than one that follows complicated ad-hoc rules that are (only) believed to be secure.</p><p>The impossibility result is mainly due to the discontinuity of maximal leakage in the support of X. More precisely, let θ be a lower bound on the minimum strictly positive probability of an element in X , and define</p><formula xml:id="formula_124">P θ X ×Y = {P XY ∈ P X ×Y : min x∈X :PX (x)&gt;0 P X (x) ≥ θ},<label>(50)</label></formula><formula xml:id="formula_125">S δ, |X |, |Y|, θ = inf f min{n :<label>(51)</label></formula><formula xml:id="formula_126">P XY L(P X ; P Y |X )-f (X n , Y n ) &gt; δ &lt; ,</formula><p>for all P XY ∈ P θ X ×Y }.</p><p>Then the following lower bound holds.</p><p>Theorem 10: For = 0.1 and c 0 &lt; 1/2 there exists c such that for all θ, all |X |, all sufficiently large |Y|, and all 1/|Y| &lt; δ &lt; c 0 , we have</p><formula xml:id="formula_127">S δ, (|X |, |Y|, θ) ≥ c |Y| θ log |Y| log 2 1 δ . (<label>52</label></formula><formula xml:id="formula_128">)</formula><p>If θ → 0, the bound diverges to infinity, which justifies our earlier claim that S δ, (|X |, |Y|) is +∞. Nevertheless, if a lower bound θ is known, then the following upper bound holds.</p><p>Theorem 11: For all θ ∈ (0, 1), finite alphabets X and Y, δ &gt; 0, and ∈ (0, 1),</p><formula xml:id="formula_129">S δ, |X |, |Y|, θ ≤ 8 log(5/ ) + |Y| log |X | θ (2-e -δ )log(2-e -δ ) + e -δ -1 . (<label>53</label></formula><formula xml:id="formula_130">)</formula><p>For small δ, the denominator behaves as δ 2 . If θ is of the order of 1/|X |, we get S(θ, δ,</p><formula xml:id="formula_131">) ≤ O |X |(|Y| log |X | + log(1/ ))/δ 2 .</formula><p>Remark 9: In terms of the dependence on the alphabets and θ, the upper and lower bounds are within subpolynomial factors of each other.</p><p>We prove the achievability result in Section V-B and the converse result in Section V-C. Both proofs use the standard technique of Poisson sampling, so we now clarify the connection between Poisson and fixed-length sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Poisson Sampling</head><p>With Poisson sampling, for a given n, we first generate N ∼ Poi(n) and then generate (X N , Y N ) from P XY . So we define the Poisson sample complexity as follows:</p><formula xml:id="formula_132">S δ, |X |, |Y|, θ = inf f min{n : N ∼ Poi(n),<label>(54)</label></formula><p>Pr L(P X ;</p><formula xml:id="formula_133">P Y |X ) -f (X N , Y N ) &gt; δ &lt; ,</formula><p>for all P XY ∈ P θ X ×Y }.</p><p>The following lemma will be useful for our analysis. It is a simple application of the Chernoff bound, hence its proof is omitted.</p><p>Lemma 13: Consider δ ∈ (0, 1), λ &gt; 0, and let N ∼ Poi(λ).</p><formula xml:id="formula_134">Pr(N ≥ (1 + δ)λ) ≤ exp{λ(δ -(1 + δ) log(1 + δ))},<label>(55)</label></formula><p>and</p><formula xml:id="formula_135">Pr(N ≤ (1 -δ)λ) ≤ exp{λ(-δ-(1 -δ) log(1 -δ))}. (<label>56</label></formula><formula xml:id="formula_136">)</formula><p>Remark 10: It is a simple exercise to check that the exponents are negative for all δ ∈ (0, 1).</p><p>Remark 11: We will later slightly abuse notation and rewrite Pr(N ≥ z) where N ∼ Poi(λ) as Pr(Poi(λ) ≥ z).</p><p>We now show that fixed-length sampling and Poisson sampling are equivalent, up to constant factors.</p><p>Lemma 14: Fix ∈ (0, 1), δ &gt; 0, and θ ∈ (0, 1). Suppose there exists f such that, given n 1 ≥ log(5/ )/ log(4/e) and N ∼ Poi(n 1 ),</p><formula xml:id="formula_137">Pr L(P X ; P Y |X ) -f (X N , Y N ) &gt; δ &lt; 4 5 .</formula><p>Then</p><formula xml:id="formula_138">S δ, |X |, |Y|, θ ≤ 2n 1 . (<label>57</label></formula><formula xml:id="formula_139">)</formula><p>On the other hand, if there exists n 2 ≥ log(1/ )/ log(e/2) such that, for all estimators f ,</p><formula xml:id="formula_140">Pr L(P X ; P Y |X ) -f (X N , Y N ) &gt; δ &gt; 2 , where N ∼ Poi(n 2 ), then S δ, |X |, |Y|, θ ≥ n 2 2 . (<label>58</label></formula><formula xml:id="formula_141">)</formula><p>Proof: Consider an optimal fixed-length estimator with 2n 1 samples. Then, a Poi(n 1 ) estimator can outperform it only if N &gt; 2n 1 . However, by Lemma 13, Pr(Poi(n 1 ) &gt; 2n 1 ) ≤ e -n1(2 log 2-1) ≤ /5.</p><p>Conversely, consider an optimal fixed-length estimator n 2 /2 samples. Then, it can outperform a Poi(n 2 ) estimator only if N &lt; n 2 /2. However, by Lemma 13, (59)</p><formula xml:id="formula_142">Pr(Poi(n 2 ) &lt; n 2 /2) ≤ e -n2(1+log(1/2)) ≤ .</formula><p>It is straightforward to verify that a (1 -e -δ )multiplicative estimator for M (P X ; P Y |X ) translates to a δ-additive estimator for L(P X ; P Y |X ), where a δmultiplicative estimator means that |M -M | ≤ δM . Therefore, in the remainder, we will analyze multiplicative estimators of M . Now, consider n ∈ N and let</p><formula xml:id="formula_143">N ∼ Poi(n). Let (X 1 , Y 1 ), (X 2 , Y<label>2</label></formula><p>), . . . , (X N , Y N ) be N independent samples drawn from a distribution P XY .</p><p>For each x ∈ X and y ∈ Y, let N x denote the number of times x appears, N y the number of times y appears, and N x,y the number of times (x, y) appears in the sequence. Then, N x ∼ Poi(nP X (x)), N y ∼ Poi(nP Y (y)), and N x,y ∼ Poi(nP XY (x, y)). Now, let θ = θ/4. The estimator works as follows:</p><p>1) For each x ∈ X with N x &gt; 0, generate a random variable N x ∼ Poi(nθ ). If N x = 0, set N x = 0. 2) For each x ∈ X with N x &gt; 0, keep only the first N x samples containing x and disregard the rest.</p><p>a) If there are not enough samples for some x (i.e., N x &gt; N x ), then let M = 1. b) Otherwise, let</p><formula xml:id="formula_144">M = y∈Y max x∈X N x,y nθ ,<label>(60)</label></formula><p>where N x,y is the number of times (x, y) appears in the truncated sequence.</p><p>To analyze the above estimator, we first consider a slightly modified setting. In particular, suppose the estimator has access to an infinite sequence 1 , Y 1 ), (X 2 , Y 2 ), . . . Then, N x = +∞ with probability 1 for each x ∈ supp(X). In this case, for each (x, y) with P X (x) &gt; 0, N x,y ∼ Poi(nθ P Y |X (y|x)). For each y ∈ Y, let x(y) ∈ argmax x:PX (x)&gt;0 P Y |X (y|x). Let δ = 1 -e -δ , and consider the following:</p><formula xml:id="formula_145">Pr M -M ≤ -δM = Pr   y∈Y max x∈X N x,y /nθ ≤ (1 -δ)M   = Pr   y∈Y max x∈X N x,y ≤ (1 -δ)M nθ   ≤ Pr   y∈Y N x(y),y ≤ (1 -δ)M nθ   (a) = Pr Poi nθ M ≤ (1 -δ)M nθ (b) ≤ exp M nθ -δ -(1 -δ) log(1 -δ) (c) ≤ exp nθ -δ -(1 -δ) log(1 -δ) ,<label>(61)</label></formula><p>where (a) follows from the fact that N x,y 's are independent Poi nθ P Y |X (y|x(y)) , (b) follows from Lemma 13, and (c) follows from the fact that M ≥ 1. Now consider the probability that M exceeds M by a factor of at least δM :</p><formula xml:id="formula_146">Pr M -M ≥ δM = Pr   y∈Y max x∈X N x,y ≥ (1 + δ)M nθ   = Pr   (x1,...,x|Y|)∈X |Y|   y∈Y N xy,y ≥ (1 + δ)M nθ     = Pr   (x1,...,x|Y|)∈X |Y|   Poi   nθ y∈Y P Y |X (y|x y )   ≥ (1 + δ)M nθ (a) ≤ |X | |Y| Pr Poi(nθ M ) ≥ (1 + δ)M nθ (b) ≤ |X | |Y| exp M nθ δ -(1 + δ) log(1 + δ) (c) ≤ |X | |Y| exp nθ δ -(1 + δ) log(1 + δ) ,<label>(62)</label></formula><p>where (a) follows from Lemma 15 below and the fact that for any (x 1 , . . . , x |Y| ) ∈ X |Y| , y∈Y P Y |X (y|x y ) ≤ M , (b) follows from Lemma 13, and (c) follows from the fact that M ≥ 1.</p><p>Lemma 15: Consider λ 1 &gt; 0, λ 2 &gt; 0 such that λ 1 ≥ λ 2 , and let N 1 ∼ Poi(λ 1 ), and N 2 ∼ Poi(λ 2 ). Then, for all k,</p><formula xml:id="formula_147">Pr(N 1 ≥ k) ≥ Pr(N 2 ≥ k).</formula><p>The proof follows from a simple coupling argument and is omitted. Now let</p><formula xml:id="formula_148">n = log(5/ ) + |Y| log |X | θ (1 + δ) log(1 + δ) -δ . (<label>63</label></formula><formula xml:id="formula_149">)</formula><p>For such a choice, we get by ( <ref type="formula" target="#formula_145">61</ref>) and <ref type="bibr" target="#b61">(62)</ref>,</p><formula xml:id="formula_150">Pr | M -M | ≥ δM ≤ 2 /5. (<label>64</label></formula><formula xml:id="formula_151">)</formula><p>Remark 12: For all δ ∈ (0, 1), δ +(1-δ) log(1-δ) ≥ (1 + δ) log(1 + δ) -δ. Note that the Poisson estimator behaves identically to the infinite-sequence estimator unless there exists x ∈ supp(X) for which N x = 0 or N x &gt; N x . Therefore, we need to compute the probability of that event.</p><p>Pr there exists x ∈ supp(X) :</p><formula xml:id="formula_152">N x &gt; N x ≤ x∈supp(X) Pr( N x &gt; N x ) ≤ x∈supp(X) Pr Poi(n θ ) ≥ Poi (n P X (x)) (a) ≤ x∈supp(X) exp - n P X (x) - √ n θ 2 (b) ≤ x∈supp(X) exp - √ 4n θ - √ n θ 2 ≤ |X |e -n θ (c) ≤ /5,<label>(65)</label></formula><p>where (a) follows from the Chernoff bound, (b) follows from the fact that for all x ∈ supp(X), P X (x) ≥ θ = 4θ , and (c) follows from the fact that (1 + δ) log(1 + δ) -δ &lt; 2 log 2 -1 &lt; 1 for δ ∈ (0, 1). Similarly, Pr (there exists x ∈ supp(X) :</p><formula xml:id="formula_153">N x = 0) ≤ x∈supp(X) Pr(N x = 0) = x∈supp(X) e -n PX (x) ≤ |X |e -n θ ≤ /5. (<label>66</label></formula><formula xml:id="formula_154">)</formula><p>It follows from equations ( <ref type="formula" target="#formula_148">63</ref>), ( <ref type="formula" target="#formula_150">64</ref>), ( <ref type="formula" target="#formula_152">65</ref>), <ref type="bibr" target="#b66">(66)</ref>, and Lemma 14 that</p><formula xml:id="formula_155">S δ, (|X |, |Y|, θ) ≤ 2 log(5/ ) + |Y| log |X | θ (1 + δ) log(1 + δ) -δ .</formula><p>Remark 13: One can readily verify that n ≥ log(5/ )/ log(4/ ). Plugging in δ = 1-e -δ and θ = θ/4 yields Theorem 11.</p><p>Remark 14: The proof shows that the risk of overestimating leakage is what controls the sample complexity of the estimator. If one is merely interested in ensuring that the estimator does not underestimate the true leakage, which is often the case in practice, then from ( <ref type="formula" target="#formula_145">61</ref>) and ( <ref type="formula" target="#formula_152">65</ref>) the sample complexity is</p><formula xml:id="formula_156">8 log(5/ ) + log |X | θ (2 -e -δ ) log(2 -e -δ ) + e -δ -1 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Proof of Theorem 10</head><p>Let |Y| = k. We will derive a lower-bound on complexity by considering a i.e., we will restrict our attention to a subset of P θ X ×Y (cf. ( <ref type="formula" target="#formula_124">50</ref>)). In particular, consider P XY ∈ P θ X ×Y that satisfy P X (x 1 ) = θ ∈ (0, 1) and P Y |X that have the following form:</p><formula xml:id="formula_157">P Y |X =       p 1 p 2 • • • p k 1/k 1/k • • • 1/k . . . . . . . . . 1/k 1/k • • • 1/k       ,<label>(67)</label></formula><p>where</p><formula xml:id="formula_158">p Y = (p 1 , p 2 , • • • , p k ) is some distribution over Y. Now, for any distribution p Y over Y, define h(p Y ) = log   y∈Y max 1 k , p y   . (<label>68</label></formula><formula xml:id="formula_159">)</formula><p>Therefore,</p><formula xml:id="formula_160">L(P X ; P Y |X ) = h(P Y |X (•|x 1 )).<label>(69)</label></formula><p>Hence, estimating maximal leakage for this subproblem is the same as estimating a property of</p><formula xml:id="formula_161">P Y |X (•|x 1 ). Let S h δ, (|Y|) = inf f min{n : N ∼ Poi(n), Pr h(P Y ) -f (Y N ) &gt; δ &lt; , for all P Y ∈ P Y },<label>(70)</label></formula><p>where P Y is the set of all probability distributions on Y, and Y n is drawn independently according to P Y . Since sampling Poi(n) from P XY gives Poi(nθ) samples from</p><formula xml:id="formula_162">P Y |X (•|x 1 ), we get S δ, (|X |, |Y|, θ)) ≥ S h δ, (|Y|)/θ.<label>(71)</label></formula><p>It remains to show that</p><formula xml:id="formula_163">S h δ, (k) ≥ c • k log k log 2 1 δ .<label>(72)</label></formula><p>We shall show this by relating the problem of estimating h(p Y ) to the problem of estimating the support size of p Y . Consider any distribution p Y with the property that p Y (y) ≥ 1/k for all y such that p Y (y) &gt; 0.</p><p>Then we have</p><formula xml:id="formula_165">e h(pY ) = y∈Y max 1 k , p Y (y) = y:pY (y)=0 1 k + y:pY (y)≥1/k p Y (y) = k -|supp(p Y )| k + 1 = 2 - |supp(p Y )| k .<label>(74)</label></formula><p>Choose α such that αδ ≤ log 1 + δ 10 for all 0 &lt; δ &lt; 1/2 and let f (•) be an estimator such that</p><formula xml:id="formula_166">Pr(|h(p Y ) -f (Y N )| &gt; αδ) &lt;</formula><p>where N is Poisson with mean θn and Y N is i.i.d. P Y .</p><p>Then we have</p><formula xml:id="formula_167">Pr |h(p Y ) -f (Y N )| &gt; log(1 + δ 10 ) &lt; which, since log 1 + δ 10 = min log 1 + δ 10 , -log 1 - δ 10 implies that Pr |1 -e h(pY )-f (Y N ) | &gt; δ 10 &lt; .<label>(75)</label></formula><p>Since h(•) ≤ 2, we may assume that f (•) ≤ 2, in which case the previous inequality implies</p><formula xml:id="formula_168">Pr(|1 -e h(pY )-f (Y N ) | &gt; δe -f (Y N ) ) &lt; ,<label>(76)</label></formula><p>which, by defining</p><formula xml:id="formula_169">f (Y N ) = 2 -e f (Y N ) k, substituting<label>(74)</label></formula><p>, and rearranging, gives</p><formula xml:id="formula_170">Pr |supp(p Y )| -f (Y N ) &gt; δk &lt; .<label>(77)</label></formula><p>Thus f (•) estimates the support of p Y with accuracy δk with probability at least for all p Y satisfying <ref type="bibr" target="#b74">(73)</ref>. It then follows from, e.g., Wu and Yang [62, <ref type="bibr">Theorem 2]</ref> (where the role of and δ are reversed) that there exists a constant c such that for all k and all δ such that</p><formula xml:id="formula_171">1 k &lt; δ &lt; c 0 θn ≥ c k log k log 2 1 δ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. GUESSING FRAMEWORK TO INTERPRET LEAKAGE METRICS</head><p>Finally, we use the guessing framework to provide operational definitions for commonly used information leakage metrics. The new operational definitions clarify in which cases each metric should be used.</p><p>In particular, we show that Shannon capacity is suitable for covert channel analysis rather than side-channel analysis. Local differential privacy emerges when the system designer is extremely risk averse (i.e., the probability that U is revealed should be small for every possible realization y, regardless of the probability of the latter event). The analysis will naturally lead us to define an information metric that is intermediate between maximal leakage and local differential privacy, which we call maximal realizable leakage (cf. Section VI-B).</p><p>On the other hand, maximal correlation captures the multiplicative decrease, upon observing Y , of the variance of functions of X. Hence it is more suitable for estimation problems, rather than guessing problems. This also naturally leads to a cost-based notion of leakage, which considers reductions in costs and is investigated in Section VI-E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Shannon Capacity</head><p>Shannon justifies the choice of mutual information by arguing that "From the point of view of the cryptanalyst [i.e., the adversary], a secrecy system is almost identical with a noisy communication system" <ref type="bibr" target="#b2">[3]</ref>. This argument is not persuasive, however, because a noisy communication system (the rate of which is governed by mutual information) relies on coding, of which there is generally none in the side-channel setting. One could argue that Shannon is simply taking a "pessimistic" view by upperbounding leakage by assuming that the transmitter is a cooperative participant and thus willing to code. This reasoning is erroneous, however; Shannon capacity is generally lower than maximal leakage. The reason is that Shanon capacity is concerned with (the size of) message sets that can be reliably reconstructed at the receiver, whereas leakage does not impose any reliability constraint. This inspires the following definition.</p><p>Definition 7 (Recoverable Leakage): Given &gt; 0 and a conditional distribution P Y |X with finite alphabets X and Y, the recoverable leakage from X to Y is defined as</p><formula xml:id="formula_172">L C (X→Y ) = sup (U,X):U -X-Y Pr(U = Û (Y ))≥1- log Pr(U = Û (Y )) max u P U (u) ,<label>(78)</label></formula><p>where the support of U is finite but of arbitrary size, and Û (Y ) is the MAP estimator.</p><p>Theorem 12: For any conditional distribution P Y |X with finite alphabets X and Y and any 0 &lt; &lt; 1,</p><formula xml:id="formula_173">lim n→∞ 1 n L C (X n →Y n ) = C(P Y |X ) =: C,<label>(79)</label></formula><p>where</p><formula xml:id="formula_174">P Y n |X n = Π n i=1 P Yi|Xi ,<label>and</label></formula><formula xml:id="formula_175">C(P Y |X ) is the capacity of the channel P Y |X .</formula><p>Shannon capacity is a suitable metric for covert channel analysis, in which there are two adversaries attempting to (covertly) communicate through P Y |X . That is, they are indeed concerned with sending and reconstructing messages reliably. To compare with maximal leakage, suppose X has full support. Then,</p><formula xml:id="formula_176">L (X→Y ) (a) = lim n→∞ 1 n L (X n →Y n ) (b) = lim n→∞ 1 n sup (U,X n ): U -X n -Y n log Pr(U = Û (Y n )) max u P U (u) ≥ lim n→∞ 1 n sup (U,X n ): U -X n -Y n Pr(U = Û (Y n ))≥1- log Pr(U = Û (Y n )) max u P U (u) = C(P Y |X ),</formula><p>where (a) follows from the additivity of maximal leakage, and (b) follows from the fact that L (X→Y ) depends on P X only through its support. One can readily verify that the inequality can be strict.</p><formula xml:id="formula_177">Example 12: Consider X ∼ Ber(p), p ∈ (0, 1/2). If Y is the output of a BEC( ) ( ∈ (0, 1)) with input X, then L (X→Y ) = log(2-) &gt; (1-) log 2 = C(P Y |X ).</formula><p>Proof: To show that the left-hand side upper-bounds the right-hand side, consider</p><formula xml:id="formula_178">L C (X n →Y n ) = sup (U,X n ):U -X n -Y n Pr(U = Û (Y n ))≥1- log Pr(U = Û (Y n )) max u P U (u) ≥ sup (U,X n ):U -X n -Y n Pr(U = Û (Y n ))≥1- U ∼uniform log |U|+log(1 -).<label>(80)</label></formula><p>Note that the right-hand side of the above equation is exactly the channel coding setup: U is the uniform message, P X n |U is the (stochastic) encoding map, P Y |X is the memoryless channel, and is the allowed average probability of decoding error. Therefore, for any δ &gt; 0, any U with |U| &lt; 2 n(C-δ) is feasible for large enough n, yielding the lower bound.</p><p>For the reverse direction, fix 0 &lt; γ &lt; 1 -. For each n, let U n , X n , and Ûn (•) achieve the supremum in</p><formula xml:id="formula_179">sup (U,X n ):U -X n -Y n Pr(U = Û (Y n ))≥1- 1 n log Pr(U = Û (Y n )) max u P U (u)</formula><p>to within γ. The problem of sending U n over the channel X n → Y n can be viewed as one of joint source-channel coding. By [63, Lemma 3.8.2] (which explicitly allows for stochastic encoding), </p><formula xml:id="formula_180">≥ Pr 1 n log P Y n |X n (Y n |X n ) P Y n (Y n ) +γ ≤ 1 n log 1 P Un (U n ) -e -γn ≥ Pr 1 n log P Y n |X n (Y n |X n ) P Y n (Y n ) + γ ≤ C + 2γ, 1 n log 1 P Un (U n ) ≥ C + 2γ -e -γn ≥ Pr 1 n log P Y n |X n (Y n |X n ) P Y n (Y n ) ≤ C + γ -Pr 1 n log 1 P Un (U n ) &lt; C + 2γ -e -γn .</formula><formula xml:id="formula_181">lim n→∞ Pr 1 n log P Y n |X n (Y n |X n ) P Y n (Y n ) ≤ C + γ = 1.</formula><p>Thus for all sufficiently large n, we have</p><formula xml:id="formula_182">Pr 1 n log 1 P Un (U n ) &lt; C + 2γ ≥ 1 -γ -&gt; 0.</formula><p>It follows that, for such n,</p><formula xml:id="formula_183">min u 1 n log 1 P Un (u) &lt; C + 2γ</formula><p>and so</p><formula xml:id="formula_184">1 n L C (X n →Y n ) = sup (U,X n ):U -X n -Y n Pr(U = Û (Y n ))≥1- 1 n log Pr(U = Û (Y n )) max u P U (u) = 1 n log Pr(U n = Ûn (Y n )) max u P Un (u) + γ ≤ 1 n log 1 max u P Un (u) + γ &lt; C + 3γ.</formula><p>Taking n → ∞ and then γ → 0 yields the upper bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Maximal Realizable Leakage</head><p>We now consider a variation of the definition of maximal leakage, which captures a different scenario of interest. It will be also useful for interpreting local differential privacy in the guessing framework (cf. Section VI-C). In particular, maximal leakage considers the average guessing performance of the adversary, Pr(U = Û (Y )), for each U satisfying U -X -Y since our threat model "tolerates" realizations y of Y that lead to a high probability of correct guessing if the corresponding probabilities P Y (y)'s are very small. For scenarios in which such small probability events are still unacceptable, we need to consider the maximum instead of the average performance. This is the case, for example, when U represents an individual's medical data or when we do not expect leakage to be concentrated around Y (e.g., Y is a public database as opposed to a running stochastic process). This leads to the following definition.</p><p>Definition 8 (Maximal Realizable Leakage): Given a joint distribution P XY on finite alphabets X and Y, the maximal realizable leakage from X to Y is defined as</p><formula xml:id="formula_185">L r (X→Y ) = (81) sup U :U -X-Y log max y∈supp(Y ) max u∈U P U |Y (u|y) max u∈U P U (u) ,</formula><p>where the support U is finite but of arbitrary size.</p><p>Theorem 13: For any joint distribution P XY on finite alphabets X and Y, the maximal realizable leakage from X to Y is given by the Rényi Divergence of order infinity, D ∞ (P XY ||P X × P Y ). That is,</p><formula xml:id="formula_186">L r (X→Y ) = max (x,y)∈X ×Y PXY (x,y)&gt;0 log P Y |X (y|x) P Y (y) (82) = D ∞ (P XY ||P X × P Y ).</formula><p>In contrast,</p><formula xml:id="formula_187">L (X→Y ) = I ∞ (X; Y ) = inf QY D ∞ (P XY ||P X × Q Y ).</formula><p>Consequently, L r (X→Y ) depends on P X (as opposed to L (X→Y ) which only depends on the support) and is symmetric in X and Y . Note that it is equal to the maximum information rate, which is the random variable the expectation of which is mutual information. It follows straightforwardly from the definitions that L r (X→Y ) ≥ L (X→Y ). Moreover, L r (X→Y ) cannot be bounded in terms of |X | and |Y|: consider the BEC example (Example 12) where X ∼ Ber(p) (p ∈ (0, 1/2)) and Y is the output of a BEC( )</p><formula xml:id="formula_188">( ∈ (0, 1)) with input X, then L r (X→Y ) = log(1/p) p→0 ---→ ∞.</formula><p>Furthermore, L r (X→Y ) exhibits desirable properties of a leakage metric: it satisfies the data processing inequality, it is zero if and only X and Y are independent, and it is additive over independent pairs {(X i , Y i )}. These properties are known for Rényi divergence of order ∞ <ref type="bibr" target="#b65">[65]</ref>.</p><p>Remark 15: The fact that using the max in (81) and the average in (1) both lead to quantities with desirable properties suggests that we could also consider weighted averages, i.e., replace the numerator by y P Y (y) max u P α U |Y (u|y)</p><formula xml:id="formula_189">1/α</formula><p>, for some α &gt; 0. See also <ref type="bibr" target="#b66">[66]</ref>.</p><p>Proof: That L r (X→Y ) ≤ D ∞ (P XY ||P X × P Y ) follows directly from Proposition 5. For the reverse direction, we again consider the shattering P U |X (cf. equation ( <ref type="formula">13</ref>)). It is a simple exercise to check that this choice yields the desired lower bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Local Differential Privacy</head><p>Differential privacy <ref type="bibr" target="#b68">[67]</ref> is a widely adopted metric in the database security literature. Roughly speaking, it requires that, for any two neighboring databases, the probabilities of any given output do not differ significantly. Local differential privacy <ref type="bibr" target="#b34">[35]</ref> adapts that notion to the setting of a given conditional distribution P Y |X . It is defined as:</p><formula xml:id="formula_190">L dp (X→Y ) = max y∈Y, x,x ∈X log P Y |X (y|x) P Y |X (y|x ) .<label>(83)</label></formula><p>Local differential privacy is known to be pessimistic <ref type="bibr" target="#b34">[35]</ref>. It is indeed very strict: for the example (Example 12) where X ∼ Ber(p) (p ∈ (0, 1/2)) and Y is the output of a BEC( ) ( ∈ (0, 1)) with input X, L dp (X→Y ) = ∞. Interestingly, we also noted in the previous section that</p><formula xml:id="formula_191">lim p→0 L r (X→Y ) = ∞.</formula><p>So what operational problem is local differential privacy solving? Similarly to maximal realizable leakage, local differential privacy is concerned with worst-case analysis over the realizations of Y . Moreover, being a function of P Y |X , it is robust against the worst-case distribution P X . Hence, differential privacy is suitable for database security problems in which we do not tolerate low risk, and we do not make any assumptions about the distribution generating the data. This yields the following definition. </p><p>Clearly, L dp (X→Y ) ≥ L r (X→Y ) ≥ L (X→Y ). Theorems 13 and 14 imply that L dp (X→Y ) = L r (X→Y ) if and only if X and Y are independent. Thus, L dp (X→ Y ) = L (X→Y ) if and only if X and Y are independent. Moreover, an interesting implication of (84) is that one could incorporate information about the marginal P X by restricting the optimization set of the sup. Proof: By Theorem 13, we can rewrite (84) as</p><formula xml:id="formula_193">L dp (X→Y ) = sup PX max (x,y)∈X ×Y PXY (x,y)&gt;0 log P Y |X (y|x) P Y (y) .</formula><p>The upper bound thus follows from the fact that P Y (y) ≥ min x P Y |X (y|x). For the lower bound, consider the following. Let y be an element achieving the max in (83). Let x 0 ∈ argmin x P Y |X (y |x) and x 1 ∈ argmax x P Y |X (y |x). Finally, for a given α &gt; 0, let P X (x 0 ) = 1 -α and P X (x 1 ) = α. Then</p><formula xml:id="formula_194">L dp (X→Y ) ≥ log max x P Y |X (y |x) P Y (y ) = log P Y |X (y |x 1 ) (1-α)P Y |X (y |x 0 )+αP Y |X (y |x 1 ) α→0 ---→ log P Y |X (y |x 1 ) P Y |X (y |x 0 ) = L dp (X→Y ).</formula><p>It is worth noting that Dwork et al. <ref type="bibr" target="#b54">[55]</ref> provide an operational definition closely related to the above definition. In particular, a simple modification of their result yields that</p><formula xml:id="formula_195">L dp (X→Y ) = sup PX sup f :X →{0,1} y∈Y log Pr(f (X) = 1|Y = y) Pr(f (X) = 1)</formula><p>.</p><p>Alternatively, Kairouz et al. <ref type="bibr" target="#b55">[56]</ref> give an operational definition of ( , δ)-differential privacy in the framework of hypothesis testing. They show that it determines the trade-off between the probabilities of false alarm and detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Maximal Correlation</head><p>Given a joint distribution P XY , the Hirschfeld-Gebelein-Rényi maximal correlation [50,68,69] ρ m (X; Y ) is defined as</p><formula xml:id="formula_196">ρ m (X; Y ) = sup f,g: E[f ]=E[g]=0 E[f 2 ]=E[g 2 ]=1 E[f (X)g(Y )].<label>(86)</label></formula><p>Calmon et al. showed that, when the alphabet X is finite,</p><formula xml:id="formula_197">sup N,f :X →[N ] sup f (•) Pr(f (X) = f (Y )) -max k∈[N ] P f (k) ≤ ρ m (X; Y ),</formula><p>where the supremum is over deterministic functions <ref type="bibr" target="#b37">[38,</ref><ref type="bibr">Theorem 9]</ref>. However, as we saw in the introduction, the left-hand side can be zero even when X and Y are dependent. We posit that maximal correlation is more precisely capturing the change in variance. That is, we define variance leakage as follows.</p><p>Definition 10 (Variance Leakage): Given a joint distribution P XY on alphabets X and Y, the variance leakage from X to Y is defined as</p><formula xml:id="formula_198">L v (X→Y ) = sup U :U -X-Y var(U )&gt;0 log var(U ) E[(U -E[U |Y ]) 2 ] .<label>(87)</label></formula><p>Lemma 16: For any joint distribution P XY on alphabets X and Y, the variance leakage from X to Y is given by</p><formula xml:id="formula_199">L v (X→Y ) = -log(1 -ρ 2 m (X; Y )),<label>(88)</label></formula><p>where ρ m (X; Y ) is the maximal correlation.</p><p>As such, maximal correlation is capturing the multiplicative decrease in variance. If the U of interest is discrete, which is often the case in practice (e.g., U is a password, a social security number, etc.), the probability of correct guessing is arguably the more relevant quantity. This holds true even in the case of location privacy, in which (as we saw earlier) typical functions of interest, such as work/home addresses or political affiliations, are discrete.</p><p>Proof: The proof is a simple rewriting of Rényi's equivalent characterization, taking into account randomized functions of X. We include it here for completeness. Without loss of generality, we can restrict the optimization in (87) to U 's that satisfy E[U ] = 0, and E[U 2 ] = 1. So, we rewrite</p><formula xml:id="formula_200">L v (X→Y ) = sup U :U -X-Y E[U ]=0, E[U 2 ]=1 log 1 E[U 2 ] -E[E[U |Y ] 2 ] = sup U :U -X-Y E[U ]=0, E[U 2 ]=1 -log 1 -E E[U |Y ] 2 .</formula><p>(89) Also, we can rewrite maximal correlation using Rényi's equivalent characterization <ref type="bibr" target="#b49">[50]</ref>:</p><formula xml:id="formula_201">ρ m (X; Y ) = sup f :E[f (X)]=0 E[f 2 (X)]=1 E [E[f (X)|Y ] 2 ].<label>(90)</label></formula><p>Now note that</p><formula xml:id="formula_202">ρ 2 m (X; Y ) = sup f : E[f ]=0, E[f 2 ]=1 E E[f (X)|Y ] 2<label>(a)</label></formula><p>≤ sup</p><formula xml:id="formula_203">U :U -X-Y E[U ]=0, E[U 2 ]=1 E E[U |Y ] 2 ≤ sup U :U -X-Y E[U ]=0, E[U 2 ]=1 sup h: E[h(U )]=0, E[h 2 (U )]=1 E E[h(U )|Y ] 2 = sup U :U -X-Y E[U ]=0, E[U 2 ]=1 ρ 2 m (U ; Y ) (b) ≤ ρ 2 m (X; Y ),<label>(91)</label></formula><p>where (b) follows from the fact that maximal correlation obeys the data processing inequality, which can be shown using standard properties of conditional expectation. Therefore (a) is in fact an equality. Plugging it in (89) yields our desired result. Definition 10, with the restriction that U = X, has also been recently investigated by Asoodeh et al. <ref type="bibr" target="#b71">[70]</ref>.</p><p>Note that it can be rewritten as</p><formula xml:id="formula_204">L v (X→Y ) = sup U :U -X-Y var(U )&gt;0 log inf u E[(U -u) 2 ] inf u(•) E[(U -u(Y )) 2 ] .<label>(92)</label></formula><p>Hence, L v (X → Y ) measures the reduction in cost incurred by the adversary, where cost is measured by the mean squared error. In the next section, we consider a natural extension in which we do not assume the cost function is known a priori.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Maximal Cost Leakage</head><p>In this section, we introduce a leakage metric that is dual to maximal leakage. Whereas maximal leakage considers the maximum gain that the adversary achieves, we could alternatively consider the maximum reduction in cost they incur.</p><p>Definition 11 (Maximal Cost Leakage): Given a joint distribution P XY on alphabets X and Y, the maximal cost leakage from X to Y is defined as</p><formula xml:id="formula_205">L c (X→Y ) = sup U :U -X-Y Û , d: Û×U→R+ log inf û∈ Û E[d(U, û)] inf û(•) E[d(U, û(Y ))] ,</formula><p>(93) where U takes value in a finite (but arbitrary) alphabet, and 0 0 = 1 by convention. It is important to note that the gain-based approach is more operationally meaningful (for side-channel analysis) than the cost-based approach. To illustrate this, suppose d is the Hamming distortion and consider sup</p><formula xml:id="formula_206">U :U -X-Y log 1 -max u∈U P U (u) 1 -sup û(•) Pr(U = û(Y )) . (<label>94</label></formula><formula xml:id="formula_207">)</formula><p>Recall that, in the definition of maximal leakage, we considered the ratio of the guessing probabilities (as opposed to the difference) because we are typically interested in functions that are hard to guess (e.g., passwords). However, the quantity in (94) is much more sensitive to changes for functions that are easy to guess: suppose for some U , max u P U (u) = 1 -10 -9 and sup û(•) Pr(U = û(Y )) = 1, then the ratio in (94) is ∞. On the other hand, if max u P U (u) = 10 -9 and sup û(•) Pr(U = û(Y )) = 10 -3 , the ratio is only ≈ 1.001 despite the significant change. More generally, it is more intuitive to associate a gain to the adversary if they compromise the system, rather than a cost if they fail to do so<ref type="foot" target="#foot_1">2</ref> (an adversary does not "lose" if the system is not compromised). Even in the rate-distortionbased approach to information leakage, the more robust metric is the probability that the adversary incurs a small distortion <ref type="bibr" target="#b27">[28]</ref> rather than (say) the expected value of the distortion. That is, the probability-metric falls under the gain approach (similar to maximal locational leakage (cf. Definition 3) or maximal gain leakage (cf. Definition 5)), albeit the gain is defined indirectly through a distortion function.</p><p>Nevertheless, maximal cost leakage admits a simple form for discrete X and Y , given in the following theorem.</p><p>Theorem 15: For any joint distribution P XY on finite alphabets X and Y, the maximal cost leakage from X to Y is given by</p><formula xml:id="formula_208">L c (X→Y ) = -log y∈Y min x∈X : PX (x)&gt;0 P Y |X (y|x).<label>(95)</label></formula><p>It is worth noting that L c (X→Y ), similarly to maximal leakage, depends on P XY only through P Y |X and the support of P X . Moreover, a relation analogous to <ref type="bibr" target="#b1">(2)</ref> holds for L c (X→Y ):</p><formula xml:id="formula_209">L c (X→Y ) = inf QY D ∞ (P X × Q Y ||P XY ).<label>(96)</label></formula><p>The proofs for Theorem 15 and the above relation are given in Appendices D-A and D-B, respectively. The following corollary, the proof of which is given in Appendix D-C, summarizes useful properties of L c (X→Y ).</p><p>Corollary 5: For any joint distribution P XY on finite alphabets X and Y, 1) (Data Processing Inequality) If the Markov chain X -Y -Z holds for a discrete random variable Z,</p><formula xml:id="formula_210">then L c (X→Z) ≤ min{L c (X→Y ) , L c (Y →Z)}. 2) L c (X→Y ) = 0 iff X and Y are independent. 3) (Additivity) If {(X i , Y i )} i=1 are mutually indepen- dent, then L c X 1 →Y 1 = i=1 L c (X i →Y i ) .</formula><p>4) For any non-trivial deterministic law P Y |X (i.e., |{y : P Y (y) &gt; 0}| &gt; 1), L c (X→Y ) = +∞.</p><formula xml:id="formula_211">5) L c (X→Y ) is not symmetric in X and Y . 6) L c (X→Y ) ≤ L dp (X→Y ). 7) L c (X→Y ) is convex in P Y |X for fixed P X .</formula><p>Thus maximal cost leakage satisfies axiomatic properties of a leakage measure. However, it cannot be bounded in terms of |X | and |Y|. Indeed, even if X is a single bit, X ∼ Ber(p) for p ∈ (0, 1), L c (X→X) = +∞. We evaluate L c (X→Y ) for some other examples.</p><p>Example 13: If X ∼ Ber(q), 0 &lt; q &lt; 1, and Y is the output of a BSC with input X and parameter p, 0 ≤ p ≤ 1/2, then L c (X→Y ) = -log(2p).</p><p>Example 14: If X ∼ Ber(q), 0 &lt; q &lt; 1, and Y is the output of a BEC with input X and parameter , 0 ≤ &lt; 1, then L c (X→Y ) = -log( ), and L c (Y →X) = +∞. 1) Comparison with Maximal Correlation: Definition 11 restricted U to be discrete, but the proof of the upper bound in Theorem 15 does not need this assumption. That is, if we take the supremum over all real-valued U 's, the theorem still holds. Comparing with (92), we get L c (X→Y ) ≥ L v (X → Y ). We can rewrite this inequality as follows.</p><p>Corollary 6: For any joint distribution P XY on finite alphabets X and Y,</p><formula xml:id="formula_212">ρ m (X; Y ) ≤ 1 -e -L c (X→Y ) .<label>(97)</label></formula><p>Consequently, for a fixed conditional distribution Note that inequality (97) is tight in the extremal cases, i.e., if X and Y are independent, if Y is a deterministic function of X, or if X is a deterministic function of Y (it can be readily verified in this case that y min x P Y |X (y|x) = 0, unless X or Y is determinstic). The second inequality follows from the fact that</p><formula xml:id="formula_213">P Y |X , sup PX s (X; Y ) ≤ 1 -</formula><formula xml:id="formula_214">sup PX s (X; Y ) = sup PX ρ 2 m (X; Y ) [71, Theorem 8].</formula><p>2) Maximal Realizable Cost: Similarly to the modification of maximal leakage to maximal realizable leakage, we could consider the minimum cost incurred at the adversary, instead of the average cost. We show next that this yields the maximum of the negative of the information rate. Maximizing it over the input distribution also yields local differential privacy.</p><p>Definition 12 (Maximal Realizable Cost): Given a joint distribution P XY on alphabets X and Y, the maximal realizable cost from X to Y is defined as</p><formula xml:id="formula_215">L rc (X→Y ) = (98) sup U :U -X-Y Û , d: Û×U→R+ log inf û∈ Û E[d(U, û)] min y∈supp(Y ) inf û∈ Û E[d(U, û)|Y = y] ,</formula><p>where Û is a finite alphabet, and 0 0 = 1 by convention. Theorem 16: For any joint distribution P XY on finite alphabets X and Y, the maximal realizable cost from X to Y is given by the Rényi divergence of order infinity, D ∞ (P X × P Y ||P XY ). That is,</p><formula xml:id="formula_216">L rc (X→Y ) = log max x,y: PX (x)PY (y)&gt;0 P Y (y) P Y |X (y|x)<label>(99)</label></formula><p>= D ∞ (P X × P Y ||P XY ).</p><p>Similarly to maximal realizable leakage, L rc (X→Y ) depends on P X not only through its support. They are also analogous in that the former is equal to ∞ (P XY ||P X × P Y ) and the latter is equal to D ∞ (P X × P Y ||P XY ). </p><p>A consequence of Theorem 14 and Corollary 7 is that local differential privacy is concerned with both worst-case reductions in costs incurred and worst-case increases in gains achieved at the adversary. The proofs of Theorem 16 and Corollary 7 are given in Appendices D-D and D-E, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. DISCUSSION</head><p>It is worth noting that Sibson's mutual information of infinite order (2) has appeared in the data compression literature as the Shtarkov sum <ref type="bibr" target="#b73">[72]</ref>, which evaluates the worst-case regret. More recently, it has also been used as a complexity measure in the study of communication complexity <ref type="bibr" target="#b74">[73]</ref>.</p><p>If X is binary and not deterministic and Y = X, then the maximal leakage from X to Y is one bit. Thus if X represents, say, whether Alice has a stigmatized disease, and Alice reveals this information to Bob, maximal leakage would declare that only one bit has been leaked to him. Maximal leakage would likewise declare that one bit has been leaked if Alice revealed the first bit of her phone number or whether she was born on an even-or odd-numbered day. Thus maximal leakage fails to capture the gravity of revealing highly-confidential quantities if those quantities can only take a few possible values. The reason is simply that maximal leakage measures the extent to which randomized functions of X that are difficult to guess a priori become easy to guess after observing Y . Any binary-valued function can be guessed a priori with probability at least 1/2. Therefore the increase in the guessing probability upon observing Y cannot be large. According to maximal leakage, revealing whether Alice has a particular disease is not a concern because Bob already has a reasonably high probability of guessing correctly even without any information from Alice. Thus maximal leakage is an appropriate metric when the goal is to prevent Bob from guessing quantities, such as passwords or keys, that are a priori hard to guess. Other metrics, such as differential privacy (83) are more appropriate in the above scenario in which revealing a single bit represents a significant breach.</p><p>Following the publication of an early version of this work, maximal leakage was used as a privacy metric in the context of hypothesis testing <ref type="bibr" target="#b75">[74]</ref>, and in a more general setup of privacy-utility trade-offs <ref type="bibr">[75]</ref>. Variations on the definition of maximal leakage that yield Sibson mutual information of finite orders have also been considered <ref type="bibr" target="#b66">[66]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors thank Emre Telatar for pointing out the connection between the Sibson mutual information of infinite order and the Shtarkov sum and for suggesting that no scalar multiple of I(X; Y ) can upper-bound L (X→Y ) in Lemma 2. They also thank the reviewers for their careful reading of the paper and the suggestion that Theorem 12 could be strengthened to its present form. This research was supported by the US National Science Foundation under grant CCF-1704443 and the US Army Research Office under grant W911NF-18-1-0426.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A PROOFS FOR SECTION II</head><p>A. Proof of Lemma 1</p><formula xml:id="formula_218">1) Consider any discrete U satisfying U -X -Y and define G(U ; Y ) = sup Û :U -Y -Û log Pr(U = Û ) maxu∈U PU (u) . Clearly if U -X -Y -Z holds, then G(U ; Z) ≤ G(U ; Y ). So if X -Y -Z holds, L (X→Z) = sup U :U -X-Z G(U ; Z) = sup U :U -X-Y -Z G(U ; Z) ≤ sup U :U -X-Y -Z G(U ; Y ) = L (X→Y ) , Similarly, L (X→Z) = sup U :U -X-Z G(U ; Z) = sup U :U -X-Y -Z G(U ; Z) ≤ sup U :U -Y -Z G(U ; Z) = L (Y →Z) . 2) If Y is discrete, then for any discrete U sup Û :U -X-Y - Û Pr U = Û = y∈supp(Y ) max u∈U P U Y (u, y) ≤ y∈supp(Y ) max u∈U P U (u) = |supp(Y )| max u∈U P U (u).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hence for any</head><formula xml:id="formula_219">U satisfying U -X -Y , G(U ; Y ) ≤ log |supp(Y )| and subsequently L (X→Y ) ≤ log |supp(Y )|. 3) If X is discrete, then L (X→Y ) ≤ L (X→X) ≤ log |supp(X)|</formula><p>, where the first inequality follows from 1) and the second from 2). 4) If X and Y are independent, then any U satisfying U -X -Y is independent from Y . Hence G(U ; Y ) = 0 for all U , which implies L (X→Y ) = 0. The non-negativity is obvious. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Proof of</head><formula xml:id="formula_220">P Y |X (y|x) (c) = log y∈Y max x∈X :PX (x)&gt;0 P Y |X (y|x) = L(X → Y ),</formula><p>where (a) is Jensen's inequality, and (c) follows from the fact that P Y (y) = 0 implies that max x∈X :PX (x)&gt;0 P Y |X (y|x) = 0. Now, note that (b) is an equality if and only if condition 1) holds. Given condition 1), it can be seen that condition 2) is necessary and sufficient for (a) to become equality (by expanding P Y (y) = x:PXY (x,y)&gt;0 P X (x)P Y |X (y|x)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B PROOFS FOR SECTION III</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Proof of Theorem 4</head><p>To show L (k) (X→Y ) ≥ L (X→Y ), we consider an arbitrary P U |X and construct</p><formula xml:id="formula_221">P V |X such that L (k) (X→Y ) [V ] = L (X→Y ) [U ].</formula><p>In particular, for a given P U |X and associated alphabet U, let V = u∈U {(u, 1), (u, 2), . . . , (u, k)},</p><formula xml:id="formula_222">and P V |X (v|x) = P V |X ((a v , b v )|x) = P U |X (a v |x)/k.</formula><p>Then the probability of correctly guessing V with k guesses after observing Y is:</p><formula xml:id="formula_223">sup X-Y -( Vi) k i=1 Pr(V = V1 ∨ • • • ∨ V = Vk ) = y∈Y max v1,v2,...,vk vi =vj,i =j k i=1 x∈X P X (x)P V |X (v i |x)P Y |X (y|x) = y∈Y k i=1 max vi =v1,...,vi-1 x∈X P X (x)P V |X (v i |x)P Y |X (y|x) (a) = y∈Y max u x∈X P X (x)P U |X (u|x)P Y |X (y|x),<label>(101)</label></formula><p>where (a) follows by setting v i = (u , i), where u = argmax </p><formula xml:id="formula_224">(X→Y ) [V ] = L (k) (X→Y ) [U ], which establishes L (X→Y ) ≥ L (k) (X→Y ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Proof of Theorem 6</head><p>Assume, without loss of generality, that X and Z have full marginal support. To show that the left-hand side is upper-bounded by the right-hand side, fix P U |XZ and consider the following.</p><formula xml:id="formula_225">Pr(U = Û (Y, Z)) Pr(U = Ũ (Z)) = z p(z) y p(y|z) max u p(u|y,z) z p(z) max u p(u|z)</formula><p>≤ max z y p(y|z) max u p(u|y, z) max u p(u|z) .</p><p>Then by noting that the ratio being maximized is exp{L(X→Y |Z = z)}, we get </p><formula xml:id="formula_226">z =z p(z) n + p(z )p = (1 -p(z )) n + p(z )p y max x:PX|Z (x|z )&gt;0 P Y |XZ (y|x, z ) (1 -p(z )) n + p(z )p ≤ log y max x:PX (x)&gt;0 P Y |X (y|x) = L (X→Y ) ,</formula><p>where the inequality follows from the fact that supp(X) ⊇ supp(X|Z = z) for any z ∈ supp(Z). Note that the inequality becomes an equality if for some z ∈ supp(Z), supp(X) = supp(X|Z = z). where (a) follows from the fact that P X|Z (x|z) = 0, P X (x) &gt; 0 and P Z (z) &gt; 0 implies that P Z|X (z|x) = 0, so that the maximum is achieved outside this set. To show the reverse direction, we will show it first for discrete X, and then extend the result by discretizing more general X's. Suppose X has a finite alphabet. In this case, σ(X) is generated by a finite set, and P XY P X ×P Y since I(X; Y ) ≤ H(X) &lt; ∞. Without loss of generality, suppose X has full support. Consider the "shattering" P U |X . Recall: p = min x∈X P X (x). For each x ∈ X , let k(x) = P X (x)/p , and let U = x∈X {(x, 1), (x, 2), . . . , (x, k(x) )}. For each u = (i u , j u ) ∈ U and x ∈ X , let P U |X (u|x) be:</p><formula xml:id="formula_227">P U |X ((i u , j u )|x) =        p PX (x) , i u = x, 1 ≤ j u ≤ k(x) ,</formula><p>1 -( k(x) -1)p</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PX (x)</head><p>, i u = x, j u = k(x) , The proof for the discrete case is completed by noticing that p = max u P U (u). Now, consider the more general case. Let {A n } ∞ n=1 be a countable collection of sets generating σ(X). We will prove the result by considering a series of discretizations of X, each of which is a refinement of previous one. To that end, let n be the finite partition generating σ(∪ n i=1 A i ). It can be readily verified that S n+1 is a refinement of S n . Let N n = |S n |, S n = {S n,1 , S n,2 , • • • , S n,Nn }, and define Let S n (x) be the set in S n containing x. Then we can view f n (u n , y) as a function of (x, y):</p><formula xml:id="formula_228">0, i u = x, 1 ≤ j u ≤ k(i u ) .</formula><p>f n (x, y) = Sn(x) f (x, y)P X (dx)</p><p>Sn(x) P X (dx)</p><p>.</p><p>We can rewrite f n (x, y) = E[f (X, y)|X ∈ S n (x)], so that f n (X, y) = E[f (X, y)|σ(S n )]. P X -a.s.</p><p>Since S n 's are refinements, f n (X, y) is a martingale process, and it follows by Levy's upward Theorem [76, Theorem 14.2] that f n (X, y)</p><formula xml:id="formula_230">a.s. → E [f (X, y)|σ (∪ ∞ i=1 S i )] .<label>(103)</label></formula><p>Then   f n (x, y) ≥ ess-sup PX f (X, y) (107) for all y. To that end, let B = {α : P X (f (X, y) &gt; α) &gt; 0}. Consider r ∈ B and let E r = {x : f (x, y) &gt; r}. Then P X (E r ) &gt; 0. Therefore, by ( <ref type="formula" target="#formula_230">103</ref>) and (104), f n (X, y) converges almost everywhere to f (X, y) on E r . By Egoroff's Theorem [77, Theorem 7.12], for every δ &gt; 0, there exists E δ such that P X (E δ ) &lt; δ and f n converges uniformly to f on E r \E δ . Call the latter set E r\δ . So fix δ &gt; 0 small such that P X (E r\δ ) &gt; 0. f n (x, y) ≥ sup B = ess-sup PX f (X, y), (108) as desired.</p><formula xml:id="formula_231">E [f (X, y)|σ (∪ ∞ i=1 S i )] = E [f (X, y)|σ (∪ ∞ i=1 A i )] = E [f (X, y)|σ (X)]</formula><p>Proof of 2): If absolute continuity does not hold, then I(X; Y ) = +∞, and there exists a sequence of discretizations (X n , Y n ) such that I(X n ; Y n ) → +∞ (e.g., <ref type="bibr">[64, p. 37]</ref>). The result then follows by noting that L (X→Y ) ≥ L (X n →Y n ) ≥ I(X n ; Y n ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Proof of Lemma 7</head><p>Suppose P X1Y1 P X1 × P Y1 and let dP X1Y1 = f 1 (x, y)d(P X1 × P Y1 ). Then for every A ∈ σ X and B ∈ σ Y ,  where (a) follows from Theorem 7, and (b) follows from the fact that for any function h : X → R, ess-sup PX h(X) = ess-sup PX 1 h(X) when P X1 ≡ P X . Now consider P X2 satisfying P X2 ≡ P X1 and let g(x) = I{y ∈ B}f 1 (x, y)P Y1 (dy)P X1 (dx).</p><p>Hence P Y2 (B) = 0 implies that for (P X2 × P Y1 )-almost all (x, y), I{y ∈ B}f 1 (x, y) = 0. Since P X1 P X2 , this implies that for (P X1 × P Y1 )-almost all (x, y), I{y ∈ B}f 1 (x, y) = 0 [78, p. 22, Ex. 19]. Hence P Y1 (B) = 0, which implies that P Y1 P Y2 . Therefore, we get</p><formula xml:id="formula_232">P X2Y2 P X1Y1 P X1 × P Y1<label>(a)</label></formula><p>P X2 × P Y2 , where (a) follows from the fact that P X1 P X2 and P Y1 P Y2 . By symmetry we also get P Y2 P Y1 , hence P Y1 ≡ P Y2 . By choosing P X1 to be the representative of the equivalence classes of P X2 and noting that P Y2 P Y1 , the first part of the lemma yields L (X 2 →Y 2 ) = log  If for every y ∈ Y there exists x ∈ supp(P X ) such that P Y |X (y|x) = 0, then for any Q Y the above quantity is ∞. By Theorem 15, L c (X→Y ) is also ∞ in this case. Now assume y∈Y min x:PX (x)&gt;0 P Y |X (y|x) &gt; 0. We have </p><p>achieves the infimum in <ref type="bibr" target="#b4">(5)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Proof of Corollary 5</head><p>In the following, assume X has full support.</p><p>1) The data processing inequality follows directly from the definition. 2) The "if" direction is straightforward. The "only if" direction follows from the fact that, for each y, min The reverse direction follows by using the same d as in (115).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Proof of Corollary 7</head><p>To show sup PX L rc (X→Y ) ≤ L dp (X→Y ), note that P Y (y) ≤ max x P Y |X (y|x). For the reverse direction, consider the following. Let y be an element achieving the max of L dp . Let x 0 ∈ argmin x P Y |X (y |x) and x 1 ∈ argmax x P Y |X (y |x). Finally, for a given α &gt; 0, let P X (x 0 ) = 1 -α and P X (x 1 ) = α. Then, </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Remark 3 :</head><label>3</label><figDesc>A joint distribution satisfying condition 1) is called singular [51]. Moreover, if X has full support, L (X→Y ) = I(X; Y ) ⇒ L (X→Y ) = C(P Y |X ), where C(P Y |X ) is the Shannon capacity of P Y |X .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Corollary 4 :</head><label>4</label><figDesc>If X and Y are jointly continuous real random variables,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>[0, τ ]. Conditioned on X τ = N , the arrival times are distributed as the ordered statistics of N independent uniform random variables over [0, τ ] [61, Ch. 4, Theorem 4A]. Therefore, the conditional average waiting time is τ /2. Hence, the average waiting time is τ /2. Finally, the upper bound on P e is an application of the Chernoff bound to Poisson random variables. c) Inject dummy packets: Song et al. [1] suggest using dummy packets to keep the rate of transmission fixed. That is, they use accumulate-and-dump with an extra parameter m b ∈ N. If in a given interval N &lt; m b packets are received, we inject m b -N dummy packets. -m b + 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Information blurring system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1 :(</head><label>1</label><figDesc>A1) The alphabets X and Y are finite. (A2) The source is memoryless and has full support. (A3) The distortion function d is bounded, i.e., there exists D max such that, for all x ∈ X and y ∈ Y, d(x, y) ≤ D max . Moreover, D ≥ D min , where D min = max x∈X min y∈Y d(x, y).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Theorem 8 :</head><label>8</label><figDesc>Under assumptions (A1)-(A4), for any DMS P and distortion function d with associated distortion level D ≥ D min and distortion excess probability α &gt; 0:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Theorem 9 :</head><label>9</label><figDesc>Under assumptions (A1)-(A3) and (A4'), for any DMS P and distortion function d with associated distortion level D ≥ D min : L(P, D, -→ R ) = [R(P, D) -r] + (bits).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Lemma 8 :</head><label>8</label><figDesc>L mem (P, D) = R(P, D) if and only if there exists P Y |X that achieves the rate-distortion function and satisfies 1) P XY (x, y)P XY (x , y) &gt; 0 ⇒ P Y |X (y|x) = P Y |X (y|x ), and 2) x:PXY (x,y)&gt;0 P X (x) = x :PXY (x ,y )&gt;0 P X (x ) for all y, y ∈ supp(Y ). Proof: The proof follows straightforwardly from Lemma 2. The above conditions imply that for some conditional achieving the rate-distortion function P Y |X , L mem (P, D) = L (X→Y ) = I(X; Y ) = R(P, D). If X has full support, then L (X→Y ) = I(X; Y ) ⇒ L (X→Y ) = C(P Y |X ). Hence, R(P, D) = C(P Y |X ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Lemma 9 :</head><label>9</label><figDesc>Suppose X n is i.i.d ∼ Ber(p), p ∈ (0, 1/2], d is the Hamming distortion, and D ∈ [0, p]. Then L mem,i n (P, D) ≥ (1 -D/p) (bits). On the other hand, by Theorem 9, L(P, D) = R(P, D) = H(p) -H(D). Since H(p) -H(D) &lt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>, and I Q (•; •) denote respectively expectation, entropy, and mutual information taken with respect to distribution Q.exp 2 {.} denotes 2(•) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>B. Proof of Theorem 11 LetM</head><label>11</label><figDesc>(P X ; P Y |X ) := exp{L(P X ; P Y |X )} = y∈Y max x∈X : PX (x)&gt;0 P Y |X (y|x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Now the discrete memoryless channel P Y n |X n satisfies the "strong converse property" [64, Theorem 5.8.5], which implies<ref type="bibr" target="#b62">[63,</ref> Corollary 3.5.1]    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Definition 9 :Theorem 14 :</head><label>914</label><figDesc>Given a conditional distribution P Y |X from X to Y, where X and Y are finite alphabets, let L dp (X→Y ) = sup PX sup U :U -X-Y log maxymax u P U |Y (u|y) max u P U (u) = sup PX L r (X→Y ) . (84) For any conditional distribution P Y |X from X to Y, where X and Y are finite alphabets, L dp (X→Y ) = L dp (X→Y ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Remark 16 :</head><label>16</label><figDesc>One can note that in each of the examples above, L c (X→Y ) ≥ L (X→Y ). This is always true when |X | = |Y| = 2, but it is not necessarily true in general. As a counter example, say X has full support andP Y |X = Then exp{L (X→Y )} = 1.2and exp{L c (X→Y )} = 1/0.9 = 1. 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>y∈Y min x∈X P</head><label>x∈X</label><figDesc>Y |X (y|x), where s (X; Y ) := sup U :U -X-Y I(U ;Y ) I(U ;X) is the strong data processing coefficient.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Corollary 7 :</head><label>7</label><figDesc>For any conditional distribution P Y |X from X to Y, where X and Y are finite alphabets, max PX L rc (X→Y ) = L dp (X→Y ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>P 1 )P</head><label>1</label><figDesc>Y |XZ (y|x, z).To get the reverse inequality, let n = 1/n for n ∈ N, z ∈ argmax y max x:PX|Z (x|z)&gt;0 P Y |XZ (y|x, z), and p = min x:p(x|z )&gt;0 p(x|z ). Construct P U |XZ as follows. If Z = z , then P U |X,Z=z is the "shattering" conditional with respect to the distribution P X|Z=z (cf. equation (13)). If Z = z , then U ∼ Unif([n]), independent of X.Using Proposition 4, we get the equality shown at the bottom of the page. Letting n → ∞ (i.e., n → 0) yields our lower bound. C. Proof of Corollary 2 The data processing inequality follows directly from the definition as in the unconditional case. 2) The upper bound follows from Theorem 6 and Lemma 1. 3-4) The independence and additivity properties follow straightforwardly from the theorem. 5) I(X; Y |Z) ≤ max z∈supp(Z) I(X; Y |Z = z) ≤ max z∈supp(Z) L (X→Y |Z = z) = L (X→Y |Z). 6) The asymmetry follows immediately from the unconditional case. 7) Let Z -X -Y be a Markov chain. Then L (X→Y |Z) Y |X (y|x) Pr(U = Û (Y, Z)) Pr(U = Ũ (Z)) = z =z p(z) y p(y|z) max u p(u|y, z) + p(z ) y p(y|z ) max u p(u|y, z ) z =z p(z) max u p(u|z) + p(z ) max u p(u|z ) = z =z p(z) n + p(z )p y max x:PX|Z (x|z )&gt;0 P Y |XZ (y|x, z )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>8 )Ly</head><label>8</label><figDesc>(X→(Y, Z)) -L (X→Z) = log z,y max x:PX (x)&gt;0 P Y Z|X (y, z|x) z max x:PX (x)&gt;0 P Z|X (z|x) ≤ log max z∈supp(Z) y max x:PX (x)&gt;0 P Y Z|X (y, z|x) max x:PX (x)&gt;0 P Z|X (z|x) = log max z∈supp(Z) y max x:PX (x)&gt;0 P (z|x)P (y|x, z) max x:PX (x)&gt;0 P (z|x) max x:P (x|z)&gt;0 P (z|x)P (y|x, z) max x:P (x)&gt;0 P (z|x) = log max z∈supp(Z) y max x:PX|Z (x|z)&gt;0 P Y |XZ (y|x, z)• P Z|X (z|x) max x :PX (x )&gt;0 P Z|X (z|x ) ≤ log max z∈supp(Z) y max x:PX|Z (x|z)&gt;0 P Y |XZ (y|x, z) = L (X→Y |Z) ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>D. Proof of Theorem 7 P</head><label>7</label><figDesc>Proof of 1): To show that the right-hand side upperbounds the left-hand side, fix any P U |X , and consider the U |X (u|x)P XY (dxdy) = Y max u∈U X P U |X (u|x)f (x, y)P X (dx)P Y (dy) ≤ Y max u∈U X P (u|x)(ess-sup PX f (X, y))P X (dx)P Y (dy) = Y (ess-sup PX f (X, y))(max u∈U X P (u|x)P X (dx))P Y (dy) = (max u∈U P U (u)) Y (ess-sup PX f (X, y))P Y (dy).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>ju)∈U x∈X P ((i u , j u )|x)f (x, y)P X (x)P Y (dy) = Y max (iu,1)∈U p f (i u , y)P Y (dy) = p Y max x∈X f (x, y)P Y (dy).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>i</head><label></label><figDesc>I{X ∈ S n,i },where I{.} is the indicator function. Then we getL(X → Y ) ≥ L(U n → Y ) since U n -X -Y is a Markov chain,and the data processing inequality holds by Lemma 1. By the earlier result for finite X, we haveL(U n → Y ) = log Y sup un:PU n (un)&gt;0 f n (u n , y)P Y (dy), where f n (u n , y) = dPU n Y d(PU n ×PY ) . We next compute f n (u n , y). Let A ⊆ U n × Y. Then P Un,Y (A) = Y un I{(u n , y) ∈ A}• X P Un|X (u n |x)f (x, y)P X (dx)P Y (dy) = Y un I{(u n , y) ∈ A}• Sn,u n f (x, y)P X (dx) P Y (dy) = Y un:PU n (un)&gt;0 I{(u n , y) ∈ A}• Sn,u n f (x, y)P X (dx) Sn,u n P X (dx) P Un (u n )P Y (dy), so that f n (u n , y) =Sn,u n f (x, y)P X (dx)Sn,u n P X (dx) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>→ Y ) ≥ lim sup n→∞ L(U n → Y ) = lim sup n→∞ log Y sup u: PU n (un)&gt;0 f n (u n , y)P Y (dy) (x))&gt;0f n (x, y)P Y (dy).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>S n+1 is a refinement of S n , the integrand is nondecreasing with n. Therefore, by the monotone convergence theorem,L(X → Y ) ≥ log Y lim n→∞ sup x:PX (Sn(x))&gt;0f n (x, y)P Y (dy).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head></head><label></label><figDesc>For each n, let S n (E r\δ ) be a collection of sets in S n satisfying: ∪ S∈Sn(Er\δ) ⊇ E r\δ and S ∈ S n (E r\δ ) ⇒ S ∩ E r\δ = ∅. Then there must exist S ∈ S n (E r\δ ) satisfying P (S) &gt; 0. Denote the latter set by S n (E r\δ ). Hence,lim n→∞ sup x:PX (Sn(x))&gt;0 f n (x, y)where (a) follows from the fact that P X (S n (E r\δ )) &gt; 0, (b) follows from the fact that S n (E r\δ ) ∩ E r\δ = ∅, and (c) follows from the fact that f n (x, y) converges uniformly to f on E r\δ . Finally, since r was chosen arbitrarily from B, we get lim n→∞ sup x:PX (Sn(x))&gt;0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>X Y 1 (</head><label>1</label><figDesc>y ∈ B)dµ(x, dy) 1(x ∈ A)dP X1 (dx) = X Y 1(y ∈ B)f 1 (x, y)dP Y1 (dy) 1(x ∈ A)dP X1 (dx).Since this holds true for all A we must have, P X1 -a.s., Y 1(y ∈ B)dµ(x, dy) = Y 1(y ∈ B)f 1 (x, y)dP Y1 (dy).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>1 (</head><label>1</label><figDesc>µ(x, •) P Y1 and f 1 (x, y) = dµ(x,•) dPY y). Let P X be an arbitrary representative of the equivalence class of P X1 and Q Y be any measure satisfyingP Y1 Q Y . Then L (X 1 →Y 1 ) PX dµ(X, •) dQ Y (y) Q Y (dy),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>dPX 2 dPX 1 .</head><label>1</label><figDesc>For any set A ∈ σ XY ,P X2Y2 (A) = X Y I{(x, y) ∈ A}µ(x, dy)P X2 (dx) = X Y g(x)I{(x, y) ∈ A}µ(x, dy)P X1 (dx), hence P X2Y2 P X1Y1 . Similarly, for any set B ∈ σ Y , P Y2 (B) = X Y I{y ∈ B}µ(x, dy)P X2 (dx) = X YI{y ∈ B}f 1 (x, y)P Y1 (dy)P X2 (dx), andP Y1 (B) = X Y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Y</head><label></label><figDesc>ess-sup PX 1 dµ(X, •) dP Y1 P Y1 (dy)= L (X 1 →Y 1 ) .APPENDIX C PROOF OF EQUATION (39)Let P Y |X = 1 -W 10 W 10 W 01 1 -W 01(where the first column corresponds to y = 0, the second to y = 1).Dropping the logarithm, we can rewrite the problem as:minimize max{1 -W 10 , W 01 } + max{W 10 , 1 -W 01 }(110)subject to(1 -p)W 10 + pW 01 ≤ D, 0 ≤ W 10 , W 01 ≤ 1. p)W 10 + pW 01 ) follows because p ≤ 1/2, (b) follows from the constraint in (110), and (c) follows because D ≤ p. Using (111), we can rewrite (110) as minimize 2 -(W 10 + W 01 ) (112) subject to(1 -p)W 10 + pW 01 ≤ D, 0 ≤ W 10 , W 01 ≤ 1. Therefore, we need to maximize (W 10 +W 01 ). By (111), the sum is upper-bounded by D/p. The upper bound can be achieved by setting W 10 = 0 and W 01 = D/p, (113) which clearly satisfies the constraint in (110). Therefore, min PY |X : E[d(X,Y )]≤D L (X→Y ) = log 2 (2 -D/p) (bits).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>PPP 1 PXP</head><label>1</label><figDesc>ofTheorem 15    To show that the left-hand side is upper-bounded by the right-hand side, fix U , Û and d, and consider:inf û(•) E[d(U, û(Y ))] = y∈Y inf û P Y (y)E[d(U, û)|Y = y] X (x, y)E[d(U, û)|X = x, Y = y] X (x)P Y |X (y|x)E[d(U, û)|X = x] ≥ y∈Y min x∈supp(X) P Y |X (y|x) inf û x∈supp(X) P X (x)E[d(U, û)|X = x] Y |X (y|x) inf û E[d(U, û)] ,where the third equality follows from the Markov chain U -X -Y . For the reverse direction, let U = X, X = supp(X), andd(x, x) = X (x)P Y |X (y|x)d(x, x) = min x∈supp(X) P Y |X (y|x),(117)which concludes the proof.B. Proof of equation (96)Fix any distribution Q Y on Y. Thenexp{D ∞ (P X × Q Y ||P XY )} = max x,y: PX (x)QY (y)&gt;0 Q Y (y) P Y |X (y|x)= max y:QY (y)&gt;0 Q Y (y) min x:PX (x)&gt;0 P Y |X (y|x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>.Remark 17 :</head><label>17</label><figDesc>exp{D ∞ (P X × Q Y ||P XY )} = max y:QY (y)&gt;0 Q Y (y) min x:PX (x)&gt;0 P Y |X (y|x) ≥ y∈Y Q Y (y) y∈Y min x:PX (x)&gt;0 P Y |X (y|x) . Noting that y Q Y (y) = 1, we get inf QY D ∞ (P X × Q Y ||P XY )} ≥ L c (X→Y ).One can readily verify that the lower bound is achievable by settingQ Y (y) = min x:PX (x)&gt;0 P Y |X (y|x) y ∈Y min x:PX (x)&gt;0 P Y |X (y |x) In the case of I ∞ (X; Y ) (cf. (2)), one can readily verify that Q Y (y) = max x:PX (x)&gt;0 P Y |X (y|x) y ∈Y max x:PX (x)&gt;0 P Y |X (y |x)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>1 y 7 )</head><label>17</label><figDesc>x P Y |X (y|x) ≤ P Y (y). Thus, y min x P Y |X (y|x) = 1 ⇒ ∀y, min x P Y |X (y|x) = P Y (y) ⇒ X and Y are independent.<ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref> The additivity property and the equality in 4) can be readily verified. Example 14 illustrates 5). 6) Local-differential privacy upper-bounds maximal cost leakage since:min x P Y |X (y|x) = y P Y (y) y min x P Y |X (y|x) ≤ max y P Y (y) min x P Y |X (y|x) ≤ max x,x ,y P Y |X (y|x ) P Y |X (y|x). Convexity follows from the fact that min x P Y |X (y|x) is concave in P Y |X , and (-log) is a non-increasing convex function.D. Proof of Theorem 16Without loss of generality, assume X and Y have full marginal support. To show L rc (X → Y ) ≤ D ∞ (P X × P Y ||P XY ), fix any X , d and y ∈ Y, and consider:inf û∈ Û E[d(U, û)|Y = y] = inf û∈ Û u∈U P U |Y (u|y)d(u, û) = inf û∈ Û u∈U x∈X P X|Y (x|y)P U |X (u|x)d(u, û) = inf û∈ Û u∈U x∈X P Y |X (y|x) P Y (y) P X (x)P U |X (u|x)d(u, û) ≥ inf û∈ Û min x P Y |X (y|x ) P Y (y) •u∈U x∈X P X (x)P U |X (u|x)d(u, û) = min x P Y |X (y|x ) P Y (y) inf û∈ Û E[d(U, û)].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head></head><label></label><figDesc>sup PX L rc (X→Y ) ≥ log P Y (y ) P Y |X (y |x 0 ) = log (1 -α)P Y |X (y |x 0 ) + αP Y |X (y |x 1 ) P Y |X (y |x 0 ) α→1 ---→ log P Y |X (y |x 1 ) P Y |X (y |x 0 ) = L dp (X → Y ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>max x∈supp(X) P Y |X (y|x) = 1. Hence, y∈Y max x∈supp(X) P Y |X (y|x) = y∈Y P Y (y). Since max x∈supp(X) P Y |X (y|x) equality holds if and only if for all y ∈ Y, max x∈X P Y |X (y|x) = x∈X P Y |X (y|x). This condition holds if and only if for all y ∈ Y, there exists a unique x y such that P Y |X (y|x y ) &gt; 0. Finally, the latter condition holds if and only if for all y ∈ Y, there exists x y such that P X|Y (x y |y) = 1. 4) The equality is straightforward to verify. 5) The asymmetry is illustrated in Example 5. 6) Convexity in P Y |X follows from the fact that for each y ∈ Y, max x P Y |X (y|x) is convex in P Y |X . 7) Concavity in P X follows from the fact that for any λ ∈ (0, 1) and any two distributions P 1 and P</figDesc><table><row><cell></cell><cell cols="5">Corollary 1</cell><cell></cell><cell>= log</cell><cell>max</cell></row><row><cell>1) If</cell><cell cols="5">L (X→Y )</cell><cell></cell><cell>=</cell><cell>0,</cell><cell>then</cell><cell>PY (y)&gt;0 y∈Y:</cell><cell>x∈X :PX (x)&gt;0</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>≥</cell><cell>P Y (y)</cell></row><row><cell cols="5">for every y</cell><cell></cell><cell>∈</cell><cell>Y, it follows that</cell></row><row><cell cols="8">max x∈supp(X) P Y |X (y|x) = P Y (y) for all</cell></row><row><cell cols="8">y ∈ Y. Therefore, X and Y are independent. The</cell></row><row><cell cols="8">reverse direction follows from Lemma 1.</cell></row><row><cell cols="8">2) The additivity property is known for</cell></row><row><cell cols="6">I ∞ (X; Y ) [32,33].</cell><cell></cell></row><row><cell cols="2">3) Since</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>y∈Y</cell><cell cols="2">max x∈X</cell><cell cols="5">P Y |X (y|x) ≤</cell><cell>y∈Y x∈X</cell><cell>P Y |X (y|x) = |X |,</cell></row><row><cell cols="5">C. Proof of Lemma 2</cell><cell></cell><cell></cell></row><row><cell cols="8">Consider the following chain of inequalities.</cell></row><row><cell cols="2">I(X; Y ) =</cell><cell cols="3">x∈X ,y∈Y</cell><cell cols="3">P XY (x, y) log</cell><cell>P Y |X (y|x) P Y (y)</cell></row><row><cell></cell><cell>=</cell><cell></cell><cell cols="3">x∈X ,y∈Y:</cell><cell cols="2">P XY (x, y) log</cell><cell>P Y |X (y|x) P Y (y)</cell></row><row><cell></cell><cell></cell><cell cols="4">PXY (x,y)&gt;0</cell><cell></cell></row><row><cell></cell><cell cols="3">(a) ≤ log</cell><cell cols="3">x∈X ,y∈Y:</cell><cell>P XY (x, y)</cell><cell>P Y |X (y|x) P Y (y)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">PXY (x,y)&gt;0</cell></row><row><cell></cell><cell cols="3">= log</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">x∈X ,y∈Y:</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">PXY (x,y)&gt;0</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x ∈X :</cell><cell>P Y |X (y|x )</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>PX (x )&gt;0</cell></row></table><note><p>y∈Y 2 on X , supp(λP 1 + (1 -λ)P 2 ) = supp(P 1 ) ∪ supp(P 2 ). P X|Y (x|y)P Y |X (y|x) (b) ≤ log x∈X ,y∈Y: PXY (x,y)&gt;0 P X|Y (x|y) max</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>It remains to show L (X→Y ) ≥ L (k) (X→Y ). For any P V |X , we construct P U |X such that L (X→Y ) [U ] = L (k) (X→Y ) [V ]. So let P V |X be given, with associated alphabet V, and let |V| ≥ k. Now, let</figDesc><table><row><cell cols="2">and P U |X (u|x) = c where c = 1/ -1 k-1 . Then, observing Y , the probability v∈u P V |X (v|x), of guessing U correctly with a single guess is sup X-Y -Û Pr(U = Û ) = y∈Y max u∈U x∈X P X (x)P U |X (u|x)P Y |X (y|x) P U = {S ⊂ V : |S| = k}, = y∈Y max x∈X u∈U P X (x)</cell></row><row><cell>u∈U</cell><cell>x∈X</cell></row></table><note><p><p><p>X (x)P U |X (u|x)P Y |X (y|x). Now note that (101) is simply the probability of guessing U correctly with a single guess after observing Y . A similar argument shows that, with no Y observation, the probability of guessing V correctly with k guesses is equal to the probability of guessing U correctly with a single guess, hence</p>L (k) (X→Y ) [V ] = L (X→Y ) [U ], which establishes L (k) (X→Y ) ≥ L (X→Y ). v∈u P V |X (v|x)P Y |X (y|x)c = c y∈Y max v1,v2,...,vk vi =vj,i =j x∈X k i=1 P X (x)P V |X (v i |x)P Y |X (y|x),</p>which is the probability, normalized by c, of guessing V correctly with k guesses after observing Y . A similar argument shows that, with no Y observation, the probability of guessing U correctly with a single guess is equal to the probability, normalized by c, of guessing V correctly with k guesses, hence L</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Note that it is necessary to have R ≥ max Q:D(Q||P )≤α R(Q, D)for the primary user's problem to be feasible.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The cost and gain approaches may be equivalent if we are interested in the difference between the incurred cost (or achieved gain) when Y is observed versus when no observations are made. This is not the case, however, if we are considering the ratio instead of the difference.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Timing analysis of keystrokes and timing attacks on SSH</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Security Symposium</title>
		<meeting>the 10th USENIX Security Symposium<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Capacity limit of queueing timing channel in shared FCFS schedulers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghassami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kiyavash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Symposium on Information Theory (ISIT)</title>
		<imprint>
			<date type="published" when="2015-06">June 2015</date>
			<biblScope unit="page" from="789" to="793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Communication theory of secrecy systems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell System Technical Journal</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="656" to="715" />
			<date type="published" when="1949">1949</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The wire-tap channel</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Wyner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell System Technical Journal</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1355" to="1387" />
			<date type="published" when="1975-10">Oct. 1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Gaussian wire-tap channel</title>
		<author>
			<persName><forename type="first">S</forename><surname>Leung-Yan-Cheong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hellman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="451" to="456" />
			<date type="published" when="1978-07">Jul. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hiding the rumor source</title>
		<author>
			<persName><forename type="first">G</forename><surname>Fanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kairouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Viswanath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6679" to="6713" />
			<date type="published" when="2017-10">Oct 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Rumors in a network: Who&apos;s the culprit?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zaman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="5163" to="5181" />
			<date type="published" when="2011-08">Aug 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The loss of location privacy in the cellular age</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Wicker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="60" to="68" />
			<date type="published" when="2012-08">aug 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The effect of location granularity on semantic location inferences</title>
		<author>
			<persName><forename type="first">K</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Wicker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 49th Hawaii International Conference on System Sciences (HICSS)</title>
		<imprint>
			<date type="published" when="2016-01">Jan 2016</date>
			<biblScope unit="page" from="2197" to="2204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Peeping tom in the neighborhood: Keystroke eavesdropping on multi-user systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://www.usenix.org/node/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th USENIX Security Symposium (USENIX Security 09)</title>
		<meeting>the 18th USENIX Security Symposium (USENIX Security 09)<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient timing channel protection for on-chip networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth IEEE/ACM International Symposium on</title>
		<imprint>
			<date type="published" when="2012-05">2012. May 2012</date>
			<biblScope unit="page" from="142" to="151" />
		</imprint>
	</monogr>
	<note>Networks on Chip (NoCS)</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mitigating timing side channel in shared schedulers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kadloor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kiyavash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Venkitasubramaniam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Networking</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Timing attacks on implementations of Diffie-Hellman, RSA, DSS, and other systems</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Kocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual International Cryptology Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="104" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Differential power analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jaffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual International Cryptology Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="388" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exploitation of unintentional information leakage from integrated circuits</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Cobb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DTIC Document, Tech. Rep</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Effects of architecture on information leakage of a hardware advanced encryption standard implementation</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Koziel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DTIC Document, Tech. Rep</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hey, you, get off of my cloud: Exploring information leakage in third-party compute clouds</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ristenpart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tromer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shacham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savage</surname></persName>
		</author>
		<idno type="DOI">10.1145/1653662.1653687</idno>
		<ptr target="http://doi.acm.org/10.1145/1653662.1653687" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM Conference on Computer and Communications Security, ser. CCS &apos;09</title>
		<meeting>the 16th ACM Conference on Computer and Communications Security, ser. CCS &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="199" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the secrecy capacity of fading channels</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Gopala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">El</forename><surname>Gamal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4687" to="4698" />
			<date type="published" when="2008-10">Oct. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Broadcast channels with confidential messages</title>
		<author>
			<persName><forename type="first">I</forename><surname>Csiszár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Körner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="339" to="348" />
			<date type="published" when="1978-05">May 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Lossless compression with security constraints</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gunduz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Erkip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Poor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Inf. Theory (ISIT)</title>
		<meeting>IEEE Int. Symp. Inf. Theory (ISIT)</meeting>
		<imprint>
			<date type="published" when="2008-07">July 2008</date>
			<biblScope unit="page" from="111" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Utility-privacy tradeoffs in databases: An information-theoretic approach</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajagopalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Poor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE. Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="838" to="852" />
			<date type="published" when="2013-06">June 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Coding theorems for Shannon&apos;s cipher system with correlated source outputs, and common information</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yamamoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="85" to="95" />
			<date type="published" when="1994-01">Jan 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On the foundations of quantitative information flow</title>
		<author>
			<persName><forename type="first">G</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of Software Science and Computational Structures, ser. Lecture Notes in Computer Science, L. de Alfaro</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5504</biblScope>
			<biblScope unit="page" from="288" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rate-distortion theory for secrecy systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Schieler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cuff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="7584" to="7605" />
			<date type="published" when="2014-12">Dec 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Rate-distortion theory for the Shannon cipher system</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yamamoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="827" to="835" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The Shannon cipher system with a guessing wiretapper</title>
		<author>
			<persName><forename type="first">N</forename><surname>Merhav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Arıkan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1860" to="1866" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Coding theorems for the Shannon cipher system with a guessing wiretapper and correlated source outputs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yamamoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2808" to="2817" />
			<date type="published" when="2008-06">June 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Measuring secrecy by the probability of a successful guess</title>
		<author>
			<persName><forename type="first">I</forename><surname>Issa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3783" to="3803" />
			<date type="published" when="2017-06">June 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A large-deviations notion of perfect secrecy</title>
		<author>
			<persName><forename type="first">N</forename><surname>Merhav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="506" to="508" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A large deviations approach to secure lossy compression</title>
		<author>
			<persName><forename type="first">N</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Merhav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2533" to="2559" />
			<date type="published" when="2017-04">April 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Information theory: coding theorems for discrete memoryless systems</title>
		<author>
			<persName><forename type="first">I</forename><surname>Csiszar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Körner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Information radius</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sibson</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF00537520</idno>
		<ptr target="http://dx.doi.org/10.1007/BF00537520" />
	</analytic>
	<monogr>
		<title level="m">Zeitschrift für Wahrscheinlichkeitstheorie und Verwandte Gebiete</title>
		<imprint>
			<date type="published" when="1969">1969</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="149" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">α-mutual information</title>
		<author>
			<persName><forename type="first">S</forename><surname>Verdú</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Theory and Applications Workshop (ITA)</title>
		<imprint>
			<date type="published" when="2015-02">2015. Feb 2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The henchman problem: Measuring secrecy by the minimum distortion in a list</title>
		<author>
			<persName><forename type="first">C</forename><surname>Schieler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cuff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3436" to="3450" />
			<date type="published" when="2016-06">June 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Local privacy and statistical minimax rates</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of Computer Science (FOCS), 2013 IEEE 54th Annual Symposium on</title>
		<imprint>
			<date type="published" when="2013-10">Oct 2013</date>
			<biblScope unit="page" from="429" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Maximal correlation secrecy</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Gamal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="3916" to="3926" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Bounds on inference</title>
		<author>
			<persName><forename type="first">F</forename><surname>Calmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Varia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Médard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Duffy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tessaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">51st Annual Allerton Conference on Communication, Control, and Computing (Allerton)</title>
		<imprint>
			<date type="published" when="2013-10">Oct 2013</date>
			<biblScope unit="page" from="567" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Principal inertia components and applications</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D P</forename><surname>Calmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Makhdoumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Médard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Varia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Duffy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="5011" to="5038" />
			<date type="published" when="2017-08">Aug 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Quantitative notions of leakage for one-try attacks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chatzikokolakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Palamidessi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Electronic Notes in Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">249</biblScope>
			<biblScope unit="page" from="75" to="91" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Measuring information leakage using generalized gain functions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alvim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chatzikokolakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Palamidessi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Security Foundations Symposium (CSF)</title>
		<imprint>
			<date type="published" when="2012-06">2012. June 2012</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="265" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Min-entropy as a resource</title>
		<author>
			<persName><forename type="first">B</forename><surname>Espinoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Computation</title>
		<imprint>
			<biblScope unit="volume">226</biblScope>
			<biblScope unit="page" from="57" to="75" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>special Issue: Information Security as a Resource</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Additive and multiplicative notions of leakage, and their capacities</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Alvim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chatzikokolakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mciver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Palamidessi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 27th Computer Security Foundations Symposium</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="308" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Recent developments in quantitative information flow</title>
		<author>
			<persName><forename type="first">G</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science</title>
		<imprint>
			<date type="published" when="2015-07">July 2015</date>
			<biblScope unit="page" from="23" to="31" />
		</imprint>
	</monogr>
	<note>invited tutorial</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Probabilistic encryption</title>
		<author>
			<persName><forename type="first">S</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Micali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="270" to="299" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">How to fool an unbounded adversary with a short key</title>
		<author>
			<persName><forename type="first">A</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1130" to="1140" />
			<date type="published" when="2006-03">March 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Entropic security and the encryption of high entropy messages</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Dodis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of Cryptography, ser</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Kilian</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3378</biblScope>
			<biblScope unit="page" from="556" to="577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Semantic security for the wiretap channel</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bellare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tessaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vardy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Cryptology-CRYPTO 2012</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="294" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Technical privacy metrics: a systematic survey</title>
		<author>
			<persName><forename type="first">I</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eckhoff</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.00327</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Convexity/concavity of Rényi entropy and α-mutual information</title>
		<author>
			<persName><forename type="first">S.-W</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Verdú</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intl. Symp. Inf. Theory</title>
		<meeting>IEEE Intl. Symp. Inf. Theory</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="745" to="749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">On measures of dependence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rényi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta mathematica hungarica</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="441" to="451" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Refinement of the random coding bound</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Altug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6005" to="6023" />
			<date type="published" when="2014-10">Oct 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Information theoretic security for encryption based on conditional Rényi entropies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Iwamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shikata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICITS 2013, ser</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Padró</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8317</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Inference attacks on location tracks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Krumm</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="127" to="143" />
		</imprint>
	</monogr>
	<note>Pervasive computing</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Anonymous networking amidst eavesdroppers</title>
		<author>
			<persName><forename type="first">P</forename><surname>Venkitasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2770" to="2784" />
			<date type="published" when="2008-06">June 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Calibrating noise to sensitivity in private data analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Theory of Cryptography, ser. TCC&apos;06</title>
		<meeting>the Third Conference on Theory of Cryptography, ser. TCC&apos;06<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="265" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The composition theorem for differential privacy</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kairouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Viswanath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning, ICML 2015</title>
		<meeting>the 32nd International Conference on Machine Learning, ICML 2015<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07-11">6-11 July 2015, 2015</date>
			<biblScope unit="page" from="1376" to="1385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Zero-rate reliability of the exponential-server timing channel</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Anantharam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="447" to="465" />
			<date type="published" when="2005-02">Feb 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Point processes and queues: martingale dynamics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Brémaud</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Probability and Mathematical Statistics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Billingsley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Probability and measure</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">L</forename><surname>Kleinrock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Queueing Systems</title>
		<imprint>
			<biblScope unit="volume">I: Theory</biblScope>
			<date type="published" when="1975">1975</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Parzen</surname></persName>
		</author>
		<title level="m">Stochastic processes. SIAM</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Chebyshev polynomials, moment matching, and optimal estimation of the unseen</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.01227</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Han</surname></persName>
		</author>
		<title level="m">Information-Spectrum Methods in Information Theory</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Hiroki</forename><surname>Springer</surname></persName>
		</author>
		<author>
			<persName><surname>Koga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Gallager</surname></persName>
		</author>
		<title level="m">Information Theory and Reliable Communication</title>
		<imprint>
			<publisher>John Wiley and Sons</publisher>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Rényi divergence and Kullback-Leibler divergence</title>
		<author>
			<persName><forename type="first">T</forename><surname>Van Erven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Harremos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3797" to="3820" />
			<date type="published" when="2014-07">July 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">A general framework for information leakage</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kosut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Calmon</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<ptr target="http://sankar.engineering.asu.edu/wp-content/uploads/2015/02/" />
		<title level="m">A-General-Framework-for-Information-Leakage-Privacy-Utility-Trade-offs1</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Differential privacy: A survey of results</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory and applications of models of computation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A connection between correlation and contingency</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">O</forename><surname>Hirschfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Proceedings of the Cambridge Philosophical Society</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="520" to="524" />
			<date type="published" when="1935">1935</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Das statistische problem der korrelation als variations-und eigenwertproblem und sein zusammenhang mit der ausgleichsrechnung</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gebelein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ZAMM-Journal of Applied Mathematics and Mechanics/Zeitschrift für Angewandte Mathematik und Mechanik</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="364" to="379" />
			<date type="published" when="1941">1941</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Asoodeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Alajaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Linder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.02409</idno>
		<title level="m">Estimation efficiency under privacy constraints</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Spreading of sets in product spaces and hypercontraction of the markov operator</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ahlswede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gács</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Prob</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="925" to="939" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Universal sequential coding of single messages</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Shtar'kov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Problemy Peredachi Informatsii</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="3" to="17" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Rényi Information Complexity and an Information Theoretic Characterization of the Partition Bound</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Prabhakaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">43rd International Colloquium on Automata, Languages, and Programming</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Chatzigiannakis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Mitzenmacher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Rabani</surname></persName>
		</editor>
		<editor>
			<persName><surname>Sangiorgi</surname></persName>
		</editor>
		<meeting><address><addrLine>Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="1" to="88" />
		</imprint>
	</monogr>
	<note>Leibniz International Proceedings in Informatics (LIPIcs), I.</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Hypothesis testing under maximal leakage privacy constraints</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Calmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Y F</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Symp. Inf. Theory (ISIT)</title>
		<imprint>
			<date type="published" when="2017-06">June 2017</date>
			<biblScope unit="page" from="779" to="783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Privacy-utility tradeoffs under constrained data release mechanisms</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">O</forename><surname>Basciftci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ishwar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09295</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Probability with martingales</title>
		<author>
			<persName><forename type="first">D</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">The elements of integration and Lebesgue measure</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Bartle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Kallenberg</surname></persName>
		</author>
		<title level="m">Foundations of Modern Probability</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
